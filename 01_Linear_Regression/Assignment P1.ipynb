{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"./boston.csv\", dtype=np.float32, delimiter=\",\", names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(6.32000e-03,  18. ,  2.31, 0., 0.538 , 6.575,  65.2,  4.09  ,  1., 296., 15.3, 3.9690e+02,  4.98, 24. ),\n",
       "       (2.73100e-02,   0. ,  7.07, 0., 0.469 , 6.421,  78.9,  4.9671,  2., 242., 17.8, 3.9690e+02,  9.14, 21.6),\n",
       "       (2.72900e-02,   0. ,  7.07, 0., 0.469 , 7.185,  61.1,  4.9671,  2., 242., 17.8, 3.9283e+02,  4.03, 34.7),\n",
       "       (3.23700e-02,   0. ,  2.18, 0., 0.458 , 6.998,  45.8,  6.0622,  3., 222., 18.7, 3.9463e+02,  2.94, 33.4),\n",
       "       (6.90500e-02,   0. ,  2.18, 0., 0.458 , 7.147,  54.2,  6.0622,  3., 222., 18.7, 3.9690e+02,  5.33, 36.2),\n",
       "       (2.98500e-02,   0. ,  2.18, 0., 0.458 , 6.43 ,  58.7,  6.0622,  3., 222., 18.7, 3.9412e+02,  5.21, 28.7),\n",
       "       (8.82900e-02,  12.5,  7.87, 0., 0.524 , 6.012,  66.6,  5.5605,  5., 311., 15.2, 3.9560e+02, 12.43, 22.9),\n",
       "       (1.44550e-01,  12.5,  7.87, 0., 0.524 , 6.172,  96.1,  5.9505,  5., 311., 15.2, 3.9690e+02, 19.15, 27.1),\n",
       "       (2.11240e-01,  12.5,  7.87, 0., 0.524 , 5.631, 100. ,  6.0821,  5., 311., 15.2, 3.8663e+02, 29.93, 16.5),\n",
       "       (1.70040e-01,  12.5,  7.87, 0., 0.524 , 6.004,  85.9,  6.5921,  5., 311., 15.2, 3.8671e+02, 17.1 , 18.9),\n",
       "       (2.24890e-01,  12.5,  7.87, 0., 0.524 , 6.377,  94.3,  6.3467,  5., 311., 15.2, 3.9252e+02, 20.45, 15. ),\n",
       "       (1.17470e-01,  12.5,  7.87, 0., 0.524 , 6.009,  82.9,  6.2267,  5., 311., 15.2, 3.9690e+02, 13.27, 18.9),\n",
       "       (9.37800e-02,  12.5,  7.87, 0., 0.524 , 5.889,  39. ,  5.4509,  5., 311., 15.2, 3.9050e+02, 15.71, 21.7),\n",
       "       (6.29760e-01,   0. ,  8.14, 0., 0.538 , 5.949,  61.8,  4.7075,  4., 307., 21. , 3.9690e+02,  8.26, 20.4),\n",
       "       (6.37960e-01,   0. ,  8.14, 0., 0.538 , 6.096,  84.5,  4.4619,  4., 307., 21. , 3.8002e+02, 10.26, 18.2),\n",
       "       (6.27390e-01,   0. ,  8.14, 0., 0.538 , 5.834,  56.5,  4.4986,  4., 307., 21. , 3.9562e+02,  8.47, 19.9),\n",
       "       (1.05393e+00,   0. ,  8.14, 0., 0.538 , 5.935,  29.3,  4.4986,  4., 307., 21. , 3.8685e+02,  6.58, 23.1),\n",
       "       (7.84200e-01,   0. ,  8.14, 0., 0.538 , 5.99 ,  81.7,  4.2579,  4., 307., 21. , 3.8675e+02, 14.67, 17.5),\n",
       "       (8.02710e-01,   0. ,  8.14, 0., 0.538 , 5.456,  36.6,  3.7965,  4., 307., 21. , 2.8899e+02, 11.69, 20.2),\n",
       "       (7.25800e-01,   0. ,  8.14, 0., 0.538 , 5.727,  69.5,  3.7965,  4., 307., 21. , 3.9095e+02, 11.28, 18.2),\n",
       "       (1.25179e+00,   0. ,  8.14, 0., 0.538 , 5.57 ,  98.1,  3.7979,  4., 307., 21. , 3.7657e+02, 21.02, 13.6),\n",
       "       (8.52040e-01,   0. ,  8.14, 0., 0.538 , 5.965,  89.2,  4.0123,  4., 307., 21. , 3.9253e+02, 13.83, 19.6),\n",
       "       (1.23247e+00,   0. ,  8.14, 0., 0.538 , 6.142,  91.7,  3.9769,  4., 307., 21. , 3.9690e+02, 18.72, 15.2),\n",
       "       (9.88430e-01,   0. ,  8.14, 0., 0.538 , 5.813, 100. ,  4.0952,  4., 307., 21. , 3.9454e+02, 19.88, 14.5),\n",
       "       (7.50260e-01,   0. ,  8.14, 0., 0.538 , 5.924,  94.1,  4.3996,  4., 307., 21. , 3.9433e+02, 16.3 , 15.6),\n",
       "       (8.40540e-01,   0. ,  8.14, 0., 0.538 , 5.599,  85.7,  4.4546,  4., 307., 21. , 3.0342e+02, 16.51, 13.9),\n",
       "       (6.71910e-01,   0. ,  8.14, 0., 0.538 , 5.813,  90.3,  4.682 ,  4., 307., 21. , 3.7688e+02, 14.81, 16.6),\n",
       "       (9.55770e-01,   0. ,  8.14, 0., 0.538 , 6.047,  88.8,  4.4534,  4., 307., 21. , 3.0638e+02, 17.28, 14.8),\n",
       "       (7.72990e-01,   0. ,  8.14, 0., 0.538 , 6.495,  94.4,  4.4547,  4., 307., 21. , 3.8794e+02, 12.8 , 18.4),\n",
       "       (1.00245e+00,   0. ,  8.14, 0., 0.538 , 6.674,  87.3,  4.239 ,  4., 307., 21. , 3.8023e+02, 11.98, 21. ),\n",
       "       (1.13081e+00,   0. ,  8.14, 0., 0.538 , 5.713,  94.1,  4.233 ,  4., 307., 21. , 3.6017e+02, 22.6 , 12.7),\n",
       "       (1.35472e+00,   0. ,  8.14, 0., 0.538 , 6.072, 100. ,  4.175 ,  4., 307., 21. , 3.7673e+02, 13.04, 14.5),\n",
       "       (1.38799e+00,   0. ,  8.14, 0., 0.538 , 5.95 ,  82. ,  3.99  ,  4., 307., 21. , 2.3260e+02, 27.71, 13.2),\n",
       "       (1.15172e+00,   0. ,  8.14, 0., 0.538 , 5.701,  95. ,  3.7872,  4., 307., 21. , 3.5877e+02, 18.35, 13.1),\n",
       "       (1.61282e+00,   0. ,  8.14, 0., 0.538 , 6.096,  96.9,  3.7598,  4., 307., 21. , 2.4831e+02, 20.34, 13.5),\n",
       "       (6.41700e-02,   0. ,  5.96, 0., 0.499 , 5.933,  68.2,  3.3603,  5., 279., 19.2, 3.9690e+02,  9.68, 18.9),\n",
       "       (9.74400e-02,   0. ,  5.96, 0., 0.499 , 5.841,  61.4,  3.3779,  5., 279., 19.2, 3.7756e+02, 11.41, 20. ),\n",
       "       (8.01400e-02,   0. ,  5.96, 0., 0.499 , 5.85 ,  41.5,  3.9342,  5., 279., 19.2, 3.9690e+02,  8.77, 21. ),\n",
       "       (1.75050e-01,   0. ,  5.96, 0., 0.499 , 5.966,  30.2,  3.8473,  5., 279., 19.2, 3.9343e+02, 10.13, 24.7),\n",
       "       (2.76300e-02,  75. ,  2.95, 0., 0.428 , 6.595,  21.8,  5.4011,  3., 252., 18.3, 3.9563e+02,  4.32, 30.8),\n",
       "       (3.35900e-02,  75. ,  2.95, 0., 0.428 , 7.024,  15.8,  5.4011,  3., 252., 18.3, 3.9562e+02,  1.98, 34.9),\n",
       "       (1.27440e-01,   0. ,  6.91, 0., 0.448 , 6.77 ,   2.9,  5.7209,  3., 233., 17.9, 3.8541e+02,  4.84, 26.6),\n",
       "       (1.41500e-01,   0. ,  6.91, 0., 0.448 , 6.169,   6.6,  5.7209,  3., 233., 17.9, 3.8337e+02,  5.81, 25.3),\n",
       "       (1.59360e-01,   0. ,  6.91, 0., 0.448 , 6.211,   6.5,  5.7209,  3., 233., 17.9, 3.9446e+02,  7.44, 24.7),\n",
       "       (1.22690e-01,   0. ,  6.91, 0., 0.448 , 6.069,  40. ,  5.7209,  3., 233., 17.9, 3.8939e+02,  9.55, 21.2),\n",
       "       (1.71420e-01,   0. ,  6.91, 0., 0.448 , 5.682,  33.8,  5.1004,  3., 233., 17.9, 3.9690e+02, 10.21, 19.3),\n",
       "       (1.88360e-01,   0. ,  6.91, 0., 0.448 , 5.786,  33.3,  5.1004,  3., 233., 17.9, 3.9690e+02, 14.15, 20. ),\n",
       "       (2.29270e-01,   0. ,  6.91, 0., 0.448 , 6.03 ,  85.5,  5.6894,  3., 233., 17.9, 3.9274e+02, 18.8 , 16.6),\n",
       "       (2.53870e-01,   0. ,  6.91, 0., 0.448 , 5.399,  95.3,  5.87  ,  3., 233., 17.9, 3.9690e+02, 30.81, 14.4),\n",
       "       (2.19770e-01,   0. ,  6.91, 0., 0.448 , 5.602,  62. ,  6.0877,  3., 233., 17.9, 3.9690e+02, 16.2 , 19.4),\n",
       "       (8.87300e-02,  21. ,  5.64, 0., 0.439 , 5.963,  45.7,  6.8147,  4., 243., 16.8, 3.9556e+02, 13.45, 19.7),\n",
       "       (4.33700e-02,  21. ,  5.64, 0., 0.439 , 6.115,  63. ,  6.8147,  4., 243., 16.8, 3.9397e+02,  9.43, 20.5),\n",
       "       (5.36000e-02,  21. ,  5.64, 0., 0.439 , 6.511,  21.1,  6.8147,  4., 243., 16.8, 3.9690e+02,  5.28, 25. ),\n",
       "       (4.98100e-02,  21. ,  5.64, 0., 0.439 , 5.998,  21.4,  6.8147,  4., 243., 16.8, 3.9690e+02,  8.43, 23.4),\n",
       "       (1.36000e-02,  75. ,  4.  , 0., 0.41  , 5.888,  47.6,  7.3197,  3., 469., 21.1, 3.9690e+02, 14.8 , 18.9),\n",
       "       (1.31100e-02,  90. ,  1.22, 0., 0.403 , 7.249,  21.9,  8.6966,  5., 226., 17.9, 3.9593e+02,  4.81, 35.4),\n",
       "       (2.05500e-02,  85. ,  0.74, 0., 0.41  , 6.383,  35.7,  9.1876,  2., 313., 17.3, 3.9690e+02,  5.77, 24.7),\n",
       "       (1.43200e-02, 100. ,  1.32, 0., 0.411 , 6.816,  40.5,  8.3248,  5., 256., 15.1, 3.9290e+02,  3.95, 31.6),\n",
       "       (1.54450e-01,  25. ,  5.13, 0., 0.453 , 6.145,  29.2,  7.8148,  8., 284., 19.7, 3.9068e+02,  6.86, 23.3),\n",
       "       (1.03280e-01,  25. ,  5.13, 0., 0.453 , 5.927,  47.2,  6.932 ,  8., 284., 19.7, 3.9690e+02,  9.22, 19.6),\n",
       "       (1.49320e-01,  25. ,  5.13, 0., 0.453 , 5.741,  66.2,  7.2254,  8., 284., 19.7, 3.9511e+02, 13.15, 18.7),\n",
       "       (1.71710e-01,  25. ,  5.13, 0., 0.453 , 5.966,  93.4,  6.8185,  8., 284., 19.7, 3.7808e+02, 14.44, 16. ),\n",
       "       (1.10270e-01,  25. ,  5.13, 0., 0.453 , 6.456,  67.8,  7.2255,  8., 284., 19.7, 3.9690e+02,  6.73, 22.2),\n",
       "       (1.26500e-01,  25. ,  5.13, 0., 0.453 , 6.762,  43.4,  7.9809,  8., 284., 19.7, 3.9558e+02,  9.5 , 25. ),\n",
       "       (1.95100e-02,  17.5,  1.38, 0., 0.4161, 7.104,  59.5,  9.2229,  3., 216., 18.6, 3.9324e+02,  8.05, 33. ),\n",
       "       (3.58400e-02,  80. ,  3.37, 0., 0.398 , 6.29 ,  17.8,  6.6115,  4., 337., 16.1, 3.9690e+02,  4.67, 23.5),\n",
       "       (4.37900e-02,  80. ,  3.37, 0., 0.398 , 5.787,  31.1,  6.6115,  4., 337., 16.1, 3.9690e+02, 10.24, 19.4),\n",
       "       (5.78900e-02,  12.5,  6.07, 0., 0.409 , 5.878,  21.4,  6.498 ,  4., 345., 18.9, 3.9621e+02,  8.1 , 22. ),\n",
       "       (1.35540e-01,  12.5,  6.07, 0., 0.409 , 5.594,  36.8,  6.498 ,  4., 345., 18.9, 3.9690e+02, 13.09, 17.4),\n",
       "       (1.28160e-01,  12.5,  6.07, 0., 0.409 , 5.885,  33. ,  6.498 ,  4., 345., 18.9, 3.9690e+02,  8.79, 20.9),\n",
       "       (8.82600e-02,   0. , 10.81, 0., 0.413 , 6.417,   6.6,  5.2873,  4., 305., 19.2, 3.8373e+02,  6.72, 24.2),\n",
       "       (1.58760e-01,   0. , 10.81, 0., 0.413 , 5.961,  17.5,  5.2873,  4., 305., 19.2, 3.7694e+02,  9.88, 21.7),\n",
       "       (9.16400e-02,   0. , 10.81, 0., 0.413 , 6.065,   7.8,  5.2873,  4., 305., 19.2, 3.9091e+02,  5.52, 22.8),\n",
       "       (1.95390e-01,   0. , 10.81, 0., 0.413 , 6.245,   6.2,  5.2873,  4., 305., 19.2, 3.7717e+02,  7.54, 23.4),\n",
       "       (7.89600e-02,   0. , 12.83, 0., 0.437 , 6.273,   6. ,  4.2515,  5., 398., 18.7, 3.9492e+02,  6.78, 24.1),\n",
       "       (9.51200e-02,   0. , 12.83, 0., 0.437 , 6.286,  45. ,  4.5026,  5., 398., 18.7, 3.8323e+02,  8.94, 21.4),\n",
       "       (1.01530e-01,   0. , 12.83, 0., 0.437 , 6.279,  74.5,  4.0522,  5., 398., 18.7, 3.7366e+02, 11.97, 20. ),\n",
       "       (8.70700e-02,   0. , 12.83, 0., 0.437 , 6.14 ,  45.8,  4.0905,  5., 398., 18.7, 3.8696e+02, 10.27, 20.8),\n",
       "       (5.64600e-02,   0. , 12.83, 0., 0.437 , 6.232,  53.7,  5.0141,  5., 398., 18.7, 3.8640e+02, 12.34, 21.2),\n",
       "       (8.38700e-02,   0. , 12.83, 0., 0.437 , 5.874,  36.6,  4.5026,  5., 398., 18.7, 3.9606e+02,  9.1 , 20.3),\n",
       "       (4.11300e-02,  25. ,  4.86, 0., 0.426 , 6.727,  33.5,  5.4007,  4., 281., 19. , 3.9690e+02,  5.29, 28. ),\n",
       "       (4.46200e-02,  25. ,  4.86, 0., 0.426 , 6.619,  70.4,  5.4007,  4., 281., 19. , 3.9563e+02,  7.22, 23.9),\n",
       "       (3.65900e-02,  25. ,  4.86, 0., 0.426 , 6.302,  32.2,  5.4007,  4., 281., 19. , 3.9690e+02,  6.72, 24.8),\n",
       "       (3.55100e-02,  25. ,  4.86, 0., 0.426 , 6.167,  46.7,  5.4007,  4., 281., 19. , 3.9064e+02,  7.51, 22.9),\n",
       "       (5.05900e-02,   0. ,  4.49, 0., 0.449 , 6.389,  48. ,  4.7794,  3., 247., 18.5, 3.9690e+02,  9.62, 23.9),\n",
       "       (5.73500e-02,   0. ,  4.49, 0., 0.449 , 6.63 ,  56.1,  4.4377,  3., 247., 18.5, 3.9230e+02,  6.53, 26.6),\n",
       "       (5.18800e-02,   0. ,  4.49, 0., 0.449 , 6.015,  45.1,  4.4272,  3., 247., 18.5, 3.9599e+02, 12.86, 22.5),\n",
       "       (7.15100e-02,   0. ,  4.49, 0., 0.449 , 6.121,  56.8,  3.7476,  3., 247., 18.5, 3.9515e+02,  8.44, 22.2),\n",
       "       (5.66000e-02,   0. ,  3.41, 0., 0.489 , 7.007,  86.3,  3.4217,  2., 270., 17.8, 3.9690e+02,  5.5 , 23.6),\n",
       "       (5.30200e-02,   0. ,  3.41, 0., 0.489 , 7.079,  63.1,  3.4145,  2., 270., 17.8, 3.9606e+02,  5.7 , 28.7),\n",
       "       (4.68400e-02,   0. ,  3.41, 0., 0.489 , 6.417,  66.1,  3.0923,  2., 270., 17.8, 3.9218e+02,  8.81, 22.6),\n",
       "       (3.93200e-02,   0. ,  3.41, 0., 0.489 , 6.405,  73.9,  3.0921,  2., 270., 17.8, 3.9355e+02,  8.2 , 22. ),\n",
       "       (4.20300e-02,  28. , 15.04, 0., 0.464 , 6.442,  53.6,  3.6659,  4., 270., 18.2, 3.9501e+02,  8.16, 22.9),\n",
       "       (2.87500e-02,  28. , 15.04, 0., 0.464 , 6.211,  28.9,  3.6659,  4., 270., 18.2, 3.9633e+02,  6.21, 25. ),\n",
       "       (4.29400e-02,  28. , 15.04, 0., 0.464 , 6.249,  77.3,  3.615 ,  4., 270., 18.2, 3.9690e+02, 10.59, 20.6),\n",
       "       (1.22040e-01,   0. ,  2.89, 0., 0.445 , 6.625,  57.8,  3.4952,  2., 276., 18. , 3.5798e+02,  6.65, 28.4),\n",
       "       (1.15040e-01,   0. ,  2.89, 0., 0.445 , 6.163,  69.6,  3.4952,  2., 276., 18. , 3.9183e+02, 11.34, 21.4),\n",
       "       (1.20830e-01,   0. ,  2.89, 0., 0.445 , 8.069,  76. ,  3.4952,  2., 276., 18. , 3.9690e+02,  4.21, 38.7),\n",
       "       (8.18700e-02,   0. ,  2.89, 0., 0.445 , 7.82 ,  36.9,  3.4952,  2., 276., 18. , 3.9353e+02,  3.57, 43.8),\n",
       "       (6.86000e-02,   0. ,  2.89, 0., 0.445 , 7.416,  62.5,  3.4952,  2., 276., 18. , 3.9690e+02,  6.19, 33.2),\n",
       "       (1.48660e-01,   0. ,  8.56, 0., 0.52  , 6.727,  79.9,  2.7778,  5., 384., 20.9, 3.9476e+02,  9.42, 27.5),\n",
       "       (1.14320e-01,   0. ,  8.56, 0., 0.52  , 6.781,  71.3,  2.8561,  5., 384., 20.9, 3.9558e+02,  7.67, 26.5),\n",
       "       (2.28760e-01,   0. ,  8.56, 0., 0.52  , 6.405,  85.4,  2.7147,  5., 384., 20.9, 7.0800e+01, 10.63, 18.6),\n",
       "       (2.11610e-01,   0. ,  8.56, 0., 0.52  , 6.137,  87.4,  2.7147,  5., 384., 20.9, 3.9447e+02, 13.44, 19.3),\n",
       "       (1.39600e-01,   0. ,  8.56, 0., 0.52  , 6.167,  90. ,  2.421 ,  5., 384., 20.9, 3.9269e+02, 12.33, 20.1),\n",
       "       (1.32620e-01,   0. ,  8.56, 0., 0.52  , 5.851,  96.7,  2.1069,  5., 384., 20.9, 3.9405e+02, 16.47, 19.5),\n",
       "       (1.71200e-01,   0. ,  8.56, 0., 0.52  , 5.836,  91.9,  2.211 ,  5., 384., 20.9, 3.9567e+02, 18.66, 19.5),\n",
       "       (1.31170e-01,   0. ,  8.56, 0., 0.52  , 6.127,  85.2,  2.1224,  5., 384., 20.9, 3.8769e+02, 14.09, 20.4),\n",
       "       (1.28020e-01,   0. ,  8.56, 0., 0.52  , 6.474,  97.1,  2.4329,  5., 384., 20.9, 3.9524e+02, 12.27, 19.8),\n",
       "       (2.63630e-01,   0. ,  8.56, 0., 0.52  , 6.229,  91.2,  2.5451,  5., 384., 20.9, 3.9123e+02, 15.55, 19.4),\n",
       "       (1.07930e-01,   0. ,  8.56, 0., 0.52  , 6.195,  54.4,  2.7778,  5., 384., 20.9, 3.9349e+02, 13.  , 21.7),\n",
       "       (1.00840e-01,   0. , 10.01, 0., 0.547 , 6.715,  81.6,  2.6775,  6., 432., 17.8, 3.9559e+02, 10.16, 22.8),\n",
       "       (1.23290e-01,   0. , 10.01, 0., 0.547 , 5.913,  92.9,  2.3534,  6., 432., 17.8, 3.9495e+02, 16.21, 18.8),\n",
       "       (2.22120e-01,   0. , 10.01, 0., 0.547 , 6.092,  95.4,  2.548 ,  6., 432., 17.8, 3.9690e+02, 17.09, 18.7),\n",
       "       (1.42310e-01,   0. , 10.01, 0., 0.547 , 6.254,  84.2,  2.2565,  6., 432., 17.8, 3.8874e+02, 10.45, 18.5),\n",
       "       (1.71340e-01,   0. , 10.01, 0., 0.547 , 5.928,  88.2,  2.4631,  6., 432., 17.8, 3.4491e+02, 15.76, 18.3),\n",
       "       (1.31580e-01,   0. , 10.01, 0., 0.547 , 6.176,  72.5,  2.7301,  6., 432., 17.8, 3.9330e+02, 12.04, 21.2),\n",
       "       (1.50980e-01,   0. , 10.01, 0., 0.547 , 6.021,  82.6,  2.7474,  6., 432., 17.8, 3.9451e+02, 10.3 , 19.2),\n",
       "       (1.30580e-01,   0. , 10.01, 0., 0.547 , 5.872,  73.1,  2.4775,  6., 432., 17.8, 3.3863e+02, 15.37, 20.4),\n",
       "       (1.44760e-01,   0. , 10.01, 0., 0.547 , 5.731,  65.2,  2.7592,  6., 432., 17.8, 3.9150e+02, 13.61, 19.3),\n",
       "       (6.89900e-02,   0. , 25.65, 0., 0.581 , 5.87 ,  69.7,  2.2577,  2., 188., 19.1, 3.8915e+02, 14.37, 22. ),\n",
       "       (7.16500e-02,   0. , 25.65, 0., 0.581 , 6.004,  84.1,  2.1974,  2., 188., 19.1, 3.7767e+02, 14.27, 20.3),\n",
       "       (9.29900e-02,   0. , 25.65, 0., 0.581 , 5.961,  92.9,  2.0869,  2., 188., 19.1, 3.7809e+02, 17.93, 20.5),\n",
       "       (1.50380e-01,   0. , 25.65, 0., 0.581 , 5.856,  97. ,  1.9444,  2., 188., 19.1, 3.7031e+02, 25.41, 17.3),\n",
       "       (9.84900e-02,   0. , 25.65, 0., 0.581 , 5.879,  95.8,  2.0063,  2., 188., 19.1, 3.7938e+02, 17.58, 18.8),\n",
       "       (1.69020e-01,   0. , 25.65, 0., 0.581 , 5.986,  88.4,  1.9929,  2., 188., 19.1, 3.8502e+02, 14.81, 21.4),\n",
       "       (3.87350e-01,   0. , 25.65, 0., 0.581 , 5.613,  95.6,  1.7572,  2., 188., 19.1, 3.5929e+02, 27.26, 15.7),\n",
       "       (2.59150e-01,   0. , 21.89, 0., 0.624 , 5.693,  96. ,  1.7883,  4., 437., 21.2, 3.9211e+02, 17.19, 16.2),\n",
       "       (3.25430e-01,   0. , 21.89, 0., 0.624 , 6.431,  98.8,  1.8125,  4., 437., 21.2, 3.9690e+02, 15.39, 18. ),\n",
       "       (8.81250e-01,   0. , 21.89, 0., 0.624 , 5.637,  94.7,  1.9799,  4., 437., 21.2, 3.9690e+02, 18.34, 14.3),\n",
       "       (3.40060e-01,   0. , 21.89, 0., 0.624 , 6.458,  98.9,  2.1185,  4., 437., 21.2, 3.9504e+02, 12.6 , 19.2),\n",
       "       (1.19294e+00,   0. , 21.89, 0., 0.624 , 6.326,  97.7,  2.271 ,  4., 437., 21.2, 3.9690e+02, 12.26, 19.6),\n",
       "       (5.90050e-01,   0. , 21.89, 0., 0.624 , 6.372,  97.9,  2.3274,  4., 437., 21.2, 3.8576e+02, 11.12, 23. ),\n",
       "       (3.29820e-01,   0. , 21.89, 0., 0.624 , 5.822,  95.4,  2.4699,  4., 437., 21.2, 3.8869e+02, 15.03, 18.4),\n",
       "       (9.76170e-01,   0. , 21.89, 0., 0.624 , 5.757,  98.4,  2.346 ,  4., 437., 21.2, 2.6276e+02, 17.31, 15.6),\n",
       "       (5.57780e-01,   0. , 21.89, 0., 0.624 , 6.335,  98.2,  2.1107,  4., 437., 21.2, 3.9467e+02, 16.96, 18.1),\n",
       "       (3.22640e-01,   0. , 21.89, 0., 0.624 , 5.942,  93.5,  1.9669,  4., 437., 21.2, 3.7825e+02, 16.9 , 17.4),\n",
       "       (3.52330e-01,   0. , 21.89, 0., 0.624 , 6.454,  98.4,  1.8498,  4., 437., 21.2, 3.9408e+02, 14.59, 17.1),\n",
       "       (2.49800e-01,   0. , 21.89, 0., 0.624 , 5.857,  98.2,  1.6686,  4., 437., 21.2, 3.9204e+02, 21.32, 13.3),\n",
       "       (5.44520e-01,   0. , 21.89, 0., 0.624 , 6.151,  97.9,  1.6687,  4., 437., 21.2, 3.9690e+02, 18.46, 17.8),\n",
       "       (2.90900e-01,   0. , 21.89, 0., 0.624 , 6.174,  93.6,  1.6119,  4., 437., 21.2, 3.8808e+02, 24.16, 14. ),\n",
       "       (1.62864e+00,   0. , 21.89, 0., 0.624 , 5.019, 100. ,  1.4394,  4., 437., 21.2, 3.9690e+02, 34.41, 14.4),\n",
       "       (3.32105e+00,   0. , 19.58, 1., 0.871 , 5.403, 100. ,  1.3216,  5., 403., 14.7, 3.9690e+02, 26.82, 13.4),\n",
       "       (4.09740e+00,   0. , 19.58, 0., 0.871 , 5.468, 100. ,  1.4118,  5., 403., 14.7, 3.9690e+02, 26.42, 15.6),\n",
       "       (2.77974e+00,   0. , 19.58, 0., 0.871 , 4.903,  97.8,  1.3459,  5., 403., 14.7, 3.9690e+02, 29.29, 11.8),\n",
       "       (2.37934e+00,   0. , 19.58, 0., 0.871 , 6.13 , 100. ,  1.4191,  5., 403., 14.7, 1.7291e+02, 27.8 , 13.8),\n",
       "       (2.15505e+00,   0. , 19.58, 0., 0.871 , 5.628, 100. ,  1.5166,  5., 403., 14.7, 1.6927e+02, 16.65, 15.6),\n",
       "       (2.36862e+00,   0. , 19.58, 0., 0.871 , 4.926,  95.7,  1.4608,  5., 403., 14.7, 3.9171e+02, 29.53, 14.6),\n",
       "       (2.33099e+00,   0. , 19.58, 0., 0.871 , 5.186,  93.8,  1.5296,  5., 403., 14.7, 3.5699e+02, 28.32, 17.8),\n",
       "       (2.73397e+00,   0. , 19.58, 0., 0.871 , 5.597,  94.9,  1.5257,  5., 403., 14.7, 3.5185e+02, 21.45, 15.4),\n",
       "       (1.65660e+00,   0. , 19.58, 0., 0.871 , 6.122,  97.3,  1.618 ,  5., 403., 14.7, 3.7280e+02, 14.1 , 21.5),\n",
       "       (1.49632e+00,   0. , 19.58, 0., 0.871 , 5.404, 100. ,  1.5916,  5., 403., 14.7, 3.4160e+02, 13.28, 19.6),\n",
       "       (1.12658e+00,   0. , 19.58, 1., 0.871 , 5.012,  88. ,  1.6102,  5., 403., 14.7, 3.4328e+02, 12.12, 15.3),\n",
       "       (2.14918e+00,   0. , 19.58, 0., 0.871 , 5.709,  98.5,  1.6232,  5., 403., 14.7, 2.6195e+02, 15.79, 19.4),\n",
       "       (1.41385e+00,   0. , 19.58, 1., 0.871 , 6.129,  96. ,  1.7494,  5., 403., 14.7, 3.2102e+02, 15.12, 17. ),\n",
       "       (3.53501e+00,   0. , 19.58, 1., 0.871 , 6.152,  82.6,  1.7455,  5., 403., 14.7, 8.8010e+01, 15.02, 15.6),\n",
       "       (2.44668e+00,   0. , 19.58, 0., 0.871 , 5.272,  94. ,  1.7364,  5., 403., 14.7, 8.8630e+01, 16.14, 13.1),\n",
       "       (1.22358e+00,   0. , 19.58, 0., 0.605 , 6.943,  97.4,  1.8773,  5., 403., 14.7, 3.6343e+02,  4.59, 41.3),\n",
       "       (1.34284e+00,   0. , 19.58, 0., 0.605 , 6.066, 100. ,  1.7573,  5., 403., 14.7, 3.5389e+02,  6.43, 24.3),\n",
       "       (1.42502e+00,   0. , 19.58, 0., 0.871 , 6.51 , 100. ,  1.7659,  5., 403., 14.7, 3.6431e+02,  7.39, 23.3),\n",
       "       (1.27346e+00,   0. , 19.58, 1., 0.605 , 6.25 ,  92.6,  1.7984,  5., 403., 14.7, 3.3892e+02,  5.5 , 27. ),\n",
       "       (1.46336e+00,   0. , 19.58, 0., 0.605 , 7.489,  90.8,  1.9709,  5., 403., 14.7, 3.7443e+02,  1.73, 50. ),\n",
       "       (1.83377e+00,   0. , 19.58, 1., 0.605 , 7.802,  98.2,  2.0407,  5., 403., 14.7, 3.8961e+02,  1.92, 50. ),\n",
       "       (1.51902e+00,   0. , 19.58, 1., 0.605 , 8.375,  93.9,  2.162 ,  5., 403., 14.7, 3.8845e+02,  3.32, 50. ),\n",
       "       (2.24236e+00,   0. , 19.58, 0., 0.605 , 5.854,  91.8,  2.422 ,  5., 403., 14.7, 3.9511e+02, 11.64, 22.7),\n",
       "       (2.92400e+00,   0. , 19.58, 0., 0.605 , 6.101,  93. ,  2.2834,  5., 403., 14.7, 2.4016e+02,  9.81, 25. ),\n",
       "       (2.01019e+00,   0. , 19.58, 0., 0.605 , 7.929,  96.2,  2.0459,  5., 403., 14.7, 3.6930e+02,  3.7 , 50. ),\n",
       "       (1.80028e+00,   0. , 19.58, 0., 0.605 , 5.877,  79.2,  2.4259,  5., 403., 14.7, 2.2761e+02, 12.14, 23.8),\n",
       "       (2.30040e+00,   0. , 19.58, 0., 0.605 , 6.319,  96.1,  2.1   ,  5., 403., 14.7, 2.9709e+02, 11.1 , 23.8),\n",
       "       (2.44953e+00,   0. , 19.58, 0., 0.605 , 6.402,  95.2,  2.2625,  5., 403., 14.7, 3.3004e+02, 11.32, 22.3),\n",
       "       (1.20742e+00,   0. , 19.58, 0., 0.605 , 5.875,  94.6,  2.4259,  5., 403., 14.7, 2.9229e+02, 14.43, 17.4),\n",
       "       (2.31390e+00,   0. , 19.58, 0., 0.605 , 5.88 ,  97.3,  2.3887,  5., 403., 14.7, 3.4813e+02, 12.03, 19.1),\n",
       "       (1.39140e-01,   0. ,  4.05, 0., 0.51  , 5.572,  88.5,  2.5961,  5., 296., 16.6, 3.9690e+02, 14.69, 23.1),\n",
       "       (9.17800e-02,   0. ,  4.05, 0., 0.51  , 6.416,  84.1,  2.6463,  5., 296., 16.6, 3.9550e+02,  9.04, 23.6),\n",
       "       (8.44700e-02,   0. ,  4.05, 0., 0.51  , 5.859,  68.7,  2.7019,  5., 296., 16.6, 3.9323e+02,  9.64, 22.6),\n",
       "       (6.66400e-02,   0. ,  4.05, 0., 0.51  , 6.546,  33.1,  3.1323,  5., 296., 16.6, 3.9096e+02,  5.33, 29.4),\n",
       "       (7.02200e-02,   0. ,  4.05, 0., 0.51  , 6.02 ,  47.2,  3.5549,  5., 296., 16.6, 3.9323e+02, 10.11, 23.2),\n",
       "       (5.42500e-02,   0. ,  4.05, 0., 0.51  , 6.315,  73.4,  3.3175,  5., 296., 16.6, 3.9560e+02,  6.29, 24.6),\n",
       "       (6.64200e-02,   0. ,  4.05, 0., 0.51  , 6.86 ,  74.4,  2.9153,  5., 296., 16.6, 3.9127e+02,  6.92, 29.9),\n",
       "       (5.78000e-02,   0. ,  2.46, 0., 0.488 , 6.98 ,  58.4,  2.829 ,  3., 193., 17.8, 3.9690e+02,  5.04, 37.2),\n",
       "       (6.58800e-02,   0. ,  2.46, 0., 0.488 , 7.765,  83.3,  2.741 ,  3., 193., 17.8, 3.9556e+02,  7.56, 39.8),\n",
       "       (6.88800e-02,   0. ,  2.46, 0., 0.488 , 6.144,  62.2,  2.5979,  3., 193., 17.8, 3.9690e+02,  9.45, 36.2),\n",
       "       (9.10300e-02,   0. ,  2.46, 0., 0.488 , 7.155,  92.2,  2.7006,  3., 193., 17.8, 3.9412e+02,  4.82, 37.9),\n",
       "       (1.00080e-01,   0. ,  2.46, 0., 0.488 , 6.563,  95.6,  2.847 ,  3., 193., 17.8, 3.9690e+02,  5.68, 32.5),\n",
       "       (8.30800e-02,   0. ,  2.46, 0., 0.488 , 5.604,  89.8,  2.9879,  3., 193., 17.8, 3.9100e+02, 13.98, 26.4),\n",
       "       (6.04700e-02,   0. ,  2.46, 0., 0.488 , 6.153,  68.8,  3.2797,  3., 193., 17.8, 3.8711e+02, 13.15, 29.6),\n",
       "       (5.60200e-02,   0. ,  2.46, 0., 0.488 , 7.831,  53.6,  3.1992,  3., 193., 17.8, 3.9263e+02,  4.45, 50. ),\n",
       "       (7.87500e-02,  45. ,  3.44, 0., 0.437 , 6.782,  41.1,  3.7886,  5., 398., 15.2, 3.9387e+02,  6.68, 32. ),\n",
       "       (1.25790e-01,  45. ,  3.44, 0., 0.437 , 6.556,  29.1,  4.5667,  5., 398., 15.2, 3.8284e+02,  4.56, 29.8),\n",
       "       (8.37000e-02,  45. ,  3.44, 0., 0.437 , 7.185,  38.9,  4.5667,  5., 398., 15.2, 3.9690e+02,  5.39, 34.9),\n",
       "       (9.06800e-02,  45. ,  3.44, 0., 0.437 , 6.951,  21.5,  6.4798,  5., 398., 15.2, 3.7768e+02,  5.1 , 37. ),\n",
       "       (6.91100e-02,  45. ,  3.44, 0., 0.437 , 6.739,  30.8,  6.4798,  5., 398., 15.2, 3.8971e+02,  4.69, 30.5),\n",
       "       (8.66400e-02,  45. ,  3.44, 0., 0.437 , 7.178,  26.3,  6.4798,  5., 398., 15.2, 3.9049e+02,  2.87, 36.4),\n",
       "       (2.18700e-02,  60. ,  2.93, 0., 0.401 , 6.8  ,   9.9,  6.2196,  1., 265., 15.6, 3.9337e+02,  5.03, 31.1),\n",
       "       (1.43900e-02,  60. ,  2.93, 0., 0.401 , 6.604,  18.8,  6.2196,  1., 265., 15.6, 3.7670e+02,  4.38, 29.1),\n",
       "       (1.38100e-02,  80. ,  0.46, 0., 0.422 , 7.875,  32. ,  5.6484,  4., 255., 14.4, 3.9423e+02,  2.97, 50. ),\n",
       "       (4.01100e-02,  80. ,  1.52, 0., 0.404 , 7.287,  34.1,  7.309 ,  2., 329., 12.6, 3.9690e+02,  4.08, 33.3),\n",
       "       (4.66600e-02,  80. ,  1.52, 0., 0.404 , 7.107,  36.6,  7.309 ,  2., 329., 12.6, 3.5431e+02,  8.61, 30.3),\n",
       "       (3.76800e-02,  80. ,  1.52, 0., 0.404 , 7.274,  38.3,  7.309 ,  2., 329., 12.6, 3.9220e+02,  6.62, 34.6),\n",
       "       (3.15000e-02,  95. ,  1.47, 0., 0.403 , 6.975,  15.3,  7.6534,  3., 402., 17. , 3.9690e+02,  4.56, 34.9),\n",
       "       (1.77800e-02,  95. ,  1.47, 0., 0.403 , 7.135,  13.9,  7.6534,  3., 402., 17. , 3.8430e+02,  4.45, 32.9),\n",
       "       (3.44500e-02,  82.5,  2.03, 0., 0.415 , 6.162,  38.4,  6.27  ,  2., 348., 14.7, 3.9377e+02,  7.43, 24.1),\n",
       "       (2.17700e-02,  82.5,  2.03, 0., 0.415 , 7.61 ,  15.7,  6.27  ,  2., 348., 14.7, 3.9538e+02,  3.11, 42.3),\n",
       "       (3.51000e-02,  95. ,  2.68, 0., 0.4161, 7.853,  33.2,  5.118 ,  4., 224., 14.7, 3.9278e+02,  3.81, 48.5),\n",
       "       (2.00900e-02,  95. ,  2.68, 0., 0.4161, 8.034,  31.9,  5.118 ,  4., 224., 14.7, 3.9055e+02,  2.88, 50. ),\n",
       "       (1.36420e-01,   0. , 10.59, 0., 0.489 , 5.891,  22.3,  3.9454,  4., 277., 18.6, 3.9690e+02, 10.87, 22.6),\n",
       "       (2.29690e-01,   0. , 10.59, 0., 0.489 , 6.326,  52.5,  4.3549,  4., 277., 18.6, 3.9487e+02, 10.97, 24.4),\n",
       "       (2.51990e-01,   0. , 10.59, 0., 0.489 , 5.783,  72.7,  4.3549,  4., 277., 18.6, 3.8943e+02, 18.06, 22.5),\n",
       "       (1.35870e-01,   0. , 10.59, 1., 0.489 , 6.064,  59.1,  4.2392,  4., 277., 18.6, 3.8132e+02, 14.66, 24.4),\n",
       "       (4.35710e-01,   0. , 10.59, 1., 0.489 , 5.344, 100. ,  3.875 ,  4., 277., 18.6, 3.9690e+02, 23.09, 20. ),\n",
       "       (1.74460e-01,   0. , 10.59, 1., 0.489 , 5.96 ,  92.1,  3.8771,  4., 277., 18.6, 3.9325e+02, 17.27, 21.7),\n",
       "       (3.75780e-01,   0. , 10.59, 1., 0.489 , 5.404,  88.6,  3.665 ,  4., 277., 18.6, 3.9524e+02, 23.98, 19.3),\n",
       "       (2.17190e-01,   0. , 10.59, 1., 0.489 , 5.807,  53.8,  3.6526,  4., 277., 18.6, 3.9094e+02, 16.03, 22.4),\n",
       "       (1.40520e-01,   0. , 10.59, 0., 0.489 , 6.375,  32.3,  3.9454,  4., 277., 18.6, 3.8581e+02,  9.38, 28.1),\n",
       "       (2.89550e-01,   0. , 10.59, 0., 0.489 , 5.412,   9.8,  3.5875,  4., 277., 18.6, 3.4893e+02, 29.55, 23.7),\n",
       "       (1.98020e-01,   0. , 10.59, 0., 0.489 , 6.182,  42.4,  3.9454,  4., 277., 18.6, 3.9363e+02,  9.47, 25. ),\n",
       "       (4.56000e-02,   0. , 13.89, 1., 0.55  , 5.888,  56. ,  3.1121,  5., 276., 16.4, 3.9280e+02, 13.51, 23.3),\n",
       "       (7.01300e-02,   0. , 13.89, 0., 0.55  , 6.642,  85.1,  3.4211,  5., 276., 16.4, 3.9278e+02,  9.69, 28.7),\n",
       "       (1.10690e-01,   0. , 13.89, 1., 0.55  , 5.951,  93.8,  2.8893,  5., 276., 16.4, 3.9690e+02, 17.92, 21.5),\n",
       "       (1.14250e-01,   0. , 13.89, 1., 0.55  , 6.373,  92.4,  3.3633,  5., 276., 16.4, 3.9374e+02, 10.5 , 23. ),\n",
       "       (3.58090e-01,   0. ,  6.2 , 1., 0.507 , 6.951,  88.5,  2.8617,  8., 307., 17.4, 3.9170e+02,  9.71, 26.7),\n",
       "       (4.07710e-01,   0. ,  6.2 , 1., 0.507 , 6.164,  91.3,  3.048 ,  8., 307., 17.4, 3.9524e+02, 21.46, 21.7),\n",
       "       (6.23560e-01,   0. ,  6.2 , 1., 0.507 , 6.879,  77.7,  3.2721,  8., 307., 17.4, 3.9039e+02,  9.93, 27.5),\n",
       "       (6.14700e-01,   0. ,  6.2 , 0., 0.507 , 6.618,  80.8,  3.2721,  8., 307., 17.4, 3.9690e+02,  7.6 , 30.1),\n",
       "       (3.15330e-01,   0. ,  6.2 , 0., 0.504 , 8.266,  78.3,  2.8944,  8., 307., 17.4, 3.8505e+02,  4.14, 44.8),\n",
       "       (5.26930e-01,   0. ,  6.2 , 0., 0.504 , 8.725,  83. ,  2.8944,  8., 307., 17.4, 3.8200e+02,  4.63, 50. ),\n",
       "       (3.82140e-01,   0. ,  6.2 , 0., 0.504 , 8.04 ,  86.5,  3.2157,  8., 307., 17.4, 3.8738e+02,  3.13, 37.6),\n",
       "       (4.12380e-01,   0. ,  6.2 , 0., 0.504 , 7.163,  79.9,  3.2157,  8., 307., 17.4, 3.7208e+02,  6.36, 31.6),\n",
       "       (2.98190e-01,   0. ,  6.2 , 0., 0.504 , 7.686,  17. ,  3.3751,  8., 307., 17.4, 3.7751e+02,  3.92, 46.7),\n",
       "       (4.41780e-01,   0. ,  6.2 , 0., 0.504 , 6.552,  21.4,  3.3751,  8., 307., 17.4, 3.8034e+02,  3.76, 31.5),\n",
       "       (5.37000e-01,   0. ,  6.2 , 0., 0.504 , 5.981,  68.1,  3.6715,  8., 307., 17.4, 3.7835e+02, 11.65, 24.3),\n",
       "       (4.62960e-01,   0. ,  6.2 , 0., 0.504 , 7.412,  76.9,  3.6715,  8., 307., 17.4, 3.7614e+02,  5.25, 31.7),\n",
       "       (5.75290e-01,   0. ,  6.2 , 0., 0.507 , 8.337,  73.3,  3.8384,  8., 307., 17.4, 3.8591e+02,  2.47, 41.7),\n",
       "       (3.31470e-01,   0. ,  6.2 , 0., 0.507 , 8.247,  70.4,  3.6519,  8., 307., 17.4, 3.7895e+02,  3.95, 48.3),\n",
       "       (4.47910e-01,   0. ,  6.2 , 1., 0.507 , 6.726,  66.5,  3.6519,  8., 307., 17.4, 3.6020e+02,  8.05, 29. ),\n",
       "       (3.30450e-01,   0. ,  6.2 , 0., 0.507 , 6.086,  61.5,  3.6519,  8., 307., 17.4, 3.7675e+02, 10.88, 24. ),\n",
       "       (5.20580e-01,   0. ,  6.2 , 1., 0.507 , 6.631,  76.5,  4.148 ,  8., 307., 17.4, 3.8845e+02,  9.54, 25.1),\n",
       "       (5.11830e-01,   0. ,  6.2 , 0., 0.507 , 7.358,  71.6,  4.148 ,  8., 307., 17.4, 3.9007e+02,  4.73, 31.5),\n",
       "       (8.24400e-02,  30. ,  4.93, 0., 0.428 , 6.481,  18.5,  6.1899,  6., 300., 16.6, 3.7941e+02,  6.36, 23.7),\n",
       "       (9.25200e-02,  30. ,  4.93, 0., 0.428 , 6.606,  42.2,  6.1899,  6., 300., 16.6, 3.8378e+02,  7.37, 23.3),\n",
       "       (1.13290e-01,  30. ,  4.93, 0., 0.428 , 6.897,  54.3,  6.3361,  6., 300., 16.6, 3.9125e+02, 11.38, 22. ),\n",
       "       (1.06120e-01,  30. ,  4.93, 0., 0.428 , 6.095,  65.1,  6.3361,  6., 300., 16.6, 3.9462e+02, 12.4 , 20.1),\n",
       "       (1.02900e-01,  30. ,  4.93, 0., 0.428 , 6.358,  52.9,  7.0355,  6., 300., 16.6, 3.7275e+02, 11.22, 22.2),\n",
       "       (1.27570e-01,  30. ,  4.93, 0., 0.428 , 6.393,   7.8,  7.0355,  6., 300., 16.6, 3.7471e+02,  5.19, 23.7),\n",
       "       (2.06080e-01,  22. ,  5.86, 0., 0.431 , 5.593,  76.5,  7.9549,  7., 330., 19.1, 3.7249e+02, 12.5 , 17.6),\n",
       "       (1.91330e-01,  22. ,  5.86, 0., 0.431 , 5.605,  70.2,  7.9549,  7., 330., 19.1, 3.8913e+02, 18.46, 18.5),\n",
       "       (3.39830e-01,  22. ,  5.86, 0., 0.431 , 6.108,  34.9,  8.0555,  7., 330., 19.1, 3.9018e+02,  9.16, 24.3),\n",
       "       (1.96570e-01,  22. ,  5.86, 0., 0.431 , 6.226,  79.2,  8.0555,  7., 330., 19.1, 3.7614e+02, 10.15, 20.5),\n",
       "       (1.64390e-01,  22. ,  5.86, 0., 0.431 , 6.433,  49.1,  7.8265,  7., 330., 19.1, 3.7471e+02,  9.52, 24.5),\n",
       "       (1.90730e-01,  22. ,  5.86, 0., 0.431 , 6.718,  17.5,  7.8265,  7., 330., 19.1, 3.9374e+02,  6.56, 26.2),\n",
       "       (1.40300e-01,  22. ,  5.86, 0., 0.431 , 6.487,  13. ,  7.3967,  7., 330., 19.1, 3.9628e+02,  5.9 , 24.4),\n",
       "       (2.14090e-01,  22. ,  5.86, 0., 0.431 , 6.438,   8.9,  7.3967,  7., 330., 19.1, 3.7707e+02,  3.59, 24.8),\n",
       "       (8.22100e-02,  22. ,  5.86, 0., 0.431 , 6.957,   6.8,  8.9067,  7., 330., 19.1, 3.8609e+02,  3.53, 29.6),\n",
       "       (3.68940e-01,  22. ,  5.86, 0., 0.431 , 8.259,   8.4,  8.9067,  7., 330., 19.1, 3.9690e+02,  3.54, 42.8),\n",
       "       (4.81900e-02,  80. ,  3.64, 0., 0.392 , 6.108,  32. ,  9.2203,  1., 315., 16.4, 3.9289e+02,  6.57, 21.9),\n",
       "       (3.54800e-02,  80. ,  3.64, 0., 0.392 , 5.876,  19.1,  9.2203,  1., 315., 16.4, 3.9518e+02,  9.25, 20.9),\n",
       "       (1.53800e-02,  90. ,  3.75, 0., 0.394 , 7.454,  34.2,  6.3361,  3., 244., 15.9, 3.8634e+02,  3.11, 44. ),\n",
       "       (6.11540e-01,  20. ,  3.97, 0., 0.647 , 8.704,  86.9,  1.801 ,  5., 264., 13. , 3.8970e+02,  5.12, 50. ),\n",
       "       (6.63510e-01,  20. ,  3.97, 0., 0.647 , 7.333, 100. ,  1.8946,  5., 264., 13. , 3.8329e+02,  7.79, 36. ),\n",
       "       (6.56650e-01,  20. ,  3.97, 0., 0.647 , 6.842, 100. ,  2.0107,  5., 264., 13. , 3.9193e+02,  6.9 , 30.1),\n",
       "       (5.40110e-01,  20. ,  3.97, 0., 0.647 , 7.203,  81.8,  2.1121,  5., 264., 13. , 3.9280e+02,  9.59, 33.8),\n",
       "       (5.34120e-01,  20. ,  3.97, 0., 0.647 , 7.52 ,  89.4,  2.1398,  5., 264., 13. , 3.8837e+02,  7.26, 43.1),\n",
       "       (5.20140e-01,  20. ,  3.97, 0., 0.647 , 8.398,  91.5,  2.2885,  5., 264., 13. , 3.8686e+02,  5.91, 48.8),\n",
       "       (8.25260e-01,  20. ,  3.97, 0., 0.647 , 7.327,  94.5,  2.0788,  5., 264., 13. , 3.9342e+02, 11.25, 31. ),\n",
       "       (5.50070e-01,  20. ,  3.97, 0., 0.647 , 7.206,  91.6,  1.9301,  5., 264., 13. , 3.8789e+02,  8.1 , 36.5),\n",
       "       (7.61620e-01,  20. ,  3.97, 0., 0.647 , 5.56 ,  62.8,  1.9865,  5., 264., 13. , 3.9240e+02, 10.45, 22.8),\n",
       "       (7.85700e-01,  20. ,  3.97, 0., 0.647 , 7.014,  84.6,  2.1329,  5., 264., 13. , 3.8407e+02, 14.79, 30.7),\n",
       "       (5.78340e-01,  20. ,  3.97, 0., 0.575 , 8.297,  67. ,  2.4216,  5., 264., 13. , 3.8454e+02,  7.44, 50. ),\n",
       "       (5.40500e-01,  20. ,  3.97, 0., 0.575 , 7.47 ,  52.6,  2.872 ,  5., 264., 13. , 3.9030e+02,  3.16, 43.5),\n",
       "       (9.06500e-02,  20. ,  6.96, 1., 0.464 , 5.92 ,  61.5,  3.9175,  3., 223., 18.6, 3.9134e+02, 13.65, 20.7),\n",
       "       (2.99160e-01,  20. ,  6.96, 0., 0.464 , 5.856,  42.1,  4.429 ,  3., 223., 18.6, 3.8865e+02, 13.  , 21.1),\n",
       "       (1.62110e-01,  20. ,  6.96, 0., 0.464 , 6.24 ,  16.3,  4.429 ,  3., 223., 18.6, 3.9690e+02,  6.59, 25.2),\n",
       "       (1.14600e-01,  20. ,  6.96, 0., 0.464 , 6.538,  58.7,  3.9175,  3., 223., 18.6, 3.9496e+02,  7.73, 24.4),\n",
       "       (2.21880e-01,  20. ,  6.96, 1., 0.464 , 7.691,  51.8,  4.3665,  3., 223., 18.6, 3.9077e+02,  6.58, 35.2),\n",
       "       (5.64400e-02,  40. ,  6.41, 1., 0.447 , 6.758,  32.9,  4.0776,  4., 254., 17.6, 3.9690e+02,  3.53, 32.4),\n",
       "       (9.60400e-02,  40. ,  6.41, 0., 0.447 , 6.854,  42.8,  4.2673,  4., 254., 17.6, 3.9690e+02,  2.98, 32. ),\n",
       "       (1.04690e-01,  40. ,  6.41, 1., 0.447 , 7.267,  49. ,  4.7872,  4., 254., 17.6, 3.8925e+02,  6.05, 33.2),\n",
       "       (6.12700e-02,  40. ,  6.41, 1., 0.447 , 6.826,  27.6,  4.8628,  4., 254., 17.6, 3.9345e+02,  4.16, 33.1),\n",
       "       (7.97800e-02,  40. ,  6.41, 0., 0.447 , 6.482,  32.1,  4.1403,  4., 254., 17.6, 3.9690e+02,  7.19, 29.1),\n",
       "       (2.10380e-01,  20. ,  3.33, 0., 0.4429, 6.812,  32.2,  4.1007,  5., 216., 14.9, 3.9690e+02,  4.85, 35.1),\n",
       "       (3.57800e-02,  20. ,  3.33, 0., 0.4429, 7.82 ,  64.5,  4.6947,  5., 216., 14.9, 3.8731e+02,  3.76, 45.4),\n",
       "       (3.70500e-02,  20. ,  3.33, 0., 0.4429, 6.968,  37.2,  5.2447,  5., 216., 14.9, 3.9223e+02,  4.59, 35.4),\n",
       "       (6.12900e-02,  20. ,  3.33, 1., 0.4429, 7.645,  49.7,  5.2119,  5., 216., 14.9, 3.7707e+02,  3.01, 46. ),\n",
       "       (1.50100e-02,  90. ,  1.21, 1., 0.401 , 7.923,  24.8,  5.885 ,  1., 198., 13.6, 3.9552e+02,  3.16, 50. ),\n",
       "       (9.06000e-03,  90. ,  2.97, 0., 0.4   , 7.088,  20.8,  7.3073,  1., 285., 15.3, 3.9472e+02,  7.85, 32.2),\n",
       "       (1.09600e-02,  55. ,  2.25, 0., 0.389 , 6.453,  31.9,  7.3073,  1., 300., 15.3, 3.9472e+02,  8.23, 22. ),\n",
       "       (1.96500e-02,  80. ,  1.76, 0., 0.385 , 6.23 ,  31.5,  9.0892,  1., 241., 18.2, 3.4160e+02, 12.93, 20.1),\n",
       "       (3.87100e-02,  52.5,  5.32, 0., 0.405 , 6.209,  31.3,  7.3172,  6., 293., 16.6, 3.9690e+02,  7.14, 23.2),\n",
       "       (4.59000e-02,  52.5,  5.32, 0., 0.405 , 6.315,  45.6,  7.3172,  6., 293., 16.6, 3.9690e+02,  7.6 , 22.3),\n",
       "       (4.29700e-02,  52.5,  5.32, 0., 0.405 , 6.565,  22.9,  7.3172,  6., 293., 16.6, 3.7172e+02,  9.51, 24.8),\n",
       "       (3.50200e-02,  80. ,  4.95, 0., 0.411 , 6.861,  27.9,  5.1167,  4., 245., 19.2, 3.9690e+02,  3.33, 28.5),\n",
       "       (7.88600e-02,  80. ,  4.95, 0., 0.411 , 7.148,  27.7,  5.1167,  4., 245., 19.2, 3.9690e+02,  3.56, 37.3),\n",
       "       (3.61500e-02,  80. ,  4.95, 0., 0.411 , 6.63 ,  23.4,  5.1167,  4., 245., 19.2, 3.9690e+02,  4.7 , 27.9),\n",
       "       (8.26500e-02,   0. , 13.92, 0., 0.437 , 6.127,  18.4,  5.5027,  4., 289., 16. , 3.9690e+02,  8.58, 23.9),\n",
       "       (8.19900e-02,   0. , 13.92, 0., 0.437 , 6.009,  42.3,  5.5027,  4., 289., 16. , 3.9690e+02, 10.4 , 21.7),\n",
       "       (1.29320e-01,   0. , 13.92, 0., 0.437 , 6.678,  31.1,  5.9604,  4., 289., 16. , 3.9690e+02,  6.27, 28.6),\n",
       "       (5.37200e-02,   0. , 13.92, 0., 0.437 , 6.549,  51. ,  5.9604,  4., 289., 16. , 3.9285e+02,  7.39, 27.1),\n",
       "       (1.41030e-01,   0. , 13.92, 0., 0.437 , 5.79 ,  58. ,  6.32  ,  4., 289., 16. , 3.9690e+02, 15.84, 20.3),\n",
       "       (6.46600e-02,  70. ,  2.24, 0., 0.4   , 6.345,  20.1,  7.8278,  5., 358., 14.8, 3.6824e+02,  4.97, 22.5),\n",
       "       (5.56100e-02,  70. ,  2.24, 0., 0.4   , 7.041,  10. ,  7.8278,  5., 358., 14.8, 3.7158e+02,  4.74, 29. ),\n",
       "       (4.41700e-02,  70. ,  2.24, 0., 0.4   , 6.871,  47.4,  7.8278,  5., 358., 14.8, 3.9086e+02,  6.07, 24.8),\n",
       "       (3.53700e-02,  34. ,  6.09, 0., 0.433 , 6.59 ,  40.4,  5.4917,  7., 329., 16.1, 3.9575e+02,  9.5 , 22. ),\n",
       "       (9.26600e-02,  34. ,  6.09, 0., 0.433 , 6.495,  18.4,  5.4917,  7., 329., 16.1, 3.8361e+02,  8.67, 26.4),\n",
       "       (1.00000e-01,  34. ,  6.09, 0., 0.433 , 6.982,  17.7,  5.4917,  7., 329., 16.1, 3.9043e+02,  4.86, 33.1),\n",
       "       (5.51500e-02,  33. ,  2.18, 0., 0.472 , 7.236,  41.1,  4.022 ,  7., 222., 18.4, 3.9368e+02,  6.93, 36.1),\n",
       "       (5.47900e-02,  33. ,  2.18, 0., 0.472 , 6.616,  58.1,  3.37  ,  7., 222., 18.4, 3.9336e+02,  8.93, 28.4),\n",
       "       (7.50300e-02,  33. ,  2.18, 0., 0.472 , 7.42 ,  71.9,  3.0992,  7., 222., 18.4, 3.9690e+02,  6.47, 33.4),\n",
       "       (4.93200e-02,  33. ,  2.18, 0., 0.472 , 6.849,  70.3,  3.1827,  7., 222., 18.4, 3.9690e+02,  7.53, 28.2),\n",
       "       (4.92980e-01,   0. ,  9.9 , 0., 0.544 , 6.635,  82.5,  3.3175,  4., 304., 18.4, 3.9690e+02,  4.54, 22.8),\n",
       "       (3.49400e-01,   0. ,  9.9 , 0., 0.544 , 5.972,  76.7,  3.1025,  4., 304., 18.4, 3.9624e+02,  9.97, 20.3),\n",
       "       (2.63548e+00,   0. ,  9.9 , 0., 0.544 , 4.973,  37.8,  2.5194,  4., 304., 18.4, 3.5045e+02, 12.64, 16.1),\n",
       "       (7.90410e-01,   0. ,  9.9 , 0., 0.544 , 6.122,  52.8,  2.6403,  4., 304., 18.4, 3.9690e+02,  5.98, 22.1),\n",
       "       (2.61690e-01,   0. ,  9.9 , 0., 0.544 , 6.023,  90.4,  2.834 ,  4., 304., 18.4, 3.9630e+02, 11.72, 19.4),\n",
       "       (2.69380e-01,   0. ,  9.9 , 0., 0.544 , 6.266,  82.8,  3.2628,  4., 304., 18.4, 3.9339e+02,  7.9 , 21.6),\n",
       "       (3.69200e-01,   0. ,  9.9 , 0., 0.544 , 6.567,  87.3,  3.6023,  4., 304., 18.4, 3.9569e+02,  9.28, 23.8),\n",
       "       (2.53560e-01,   0. ,  9.9 , 0., 0.544 , 5.705,  77.7,  3.945 ,  4., 304., 18.4, 3.9642e+02, 11.5 , 16.2),\n",
       "       (3.18270e-01,   0. ,  9.9 , 0., 0.544 , 5.914,  83.2,  3.9986,  4., 304., 18.4, 3.9070e+02, 18.33, 17.8),\n",
       "       (2.45220e-01,   0. ,  9.9 , 0., 0.544 , 5.782,  71.7,  4.0317,  4., 304., 18.4, 3.9690e+02, 15.94, 19.8),\n",
       "       (4.02020e-01,   0. ,  9.9 , 0., 0.544 , 6.382,  67.2,  3.5325,  4., 304., 18.4, 3.9521e+02, 10.36, 23.1),\n",
       "       (4.75470e-01,   0. ,  9.9 , 0., 0.544 , 6.113,  58.8,  4.0019,  4., 304., 18.4, 3.9623e+02, 12.73, 21. ),\n",
       "       (1.67600e-01,   0. ,  7.38, 0., 0.493 , 6.426,  52.3,  4.5404,  5., 287., 19.6, 3.9690e+02,  7.2 , 23.8),\n",
       "       (1.81590e-01,   0. ,  7.38, 0., 0.493 , 6.376,  54.3,  4.5404,  5., 287., 19.6, 3.9690e+02,  6.87, 23.1),\n",
       "       (3.51140e-01,   0. ,  7.38, 0., 0.493 , 6.041,  49.9,  4.7211,  5., 287., 19.6, 3.9690e+02,  7.7 , 20.4),\n",
       "       (2.83920e-01,   0. ,  7.38, 0., 0.493 , 5.708,  74.3,  4.7211,  5., 287., 19.6, 3.9113e+02, 11.74, 18.5),\n",
       "       (3.41090e-01,   0. ,  7.38, 0., 0.493 , 6.415,  40.1,  4.7211,  5., 287., 19.6, 3.9690e+02,  6.12, 25. ),\n",
       "       (1.91860e-01,   0. ,  7.38, 0., 0.493 , 6.431,  14.7,  5.4159,  5., 287., 19.6, 3.9368e+02,  5.08, 24.6),\n",
       "       (3.03470e-01,   0. ,  7.38, 0., 0.493 , 6.312,  28.9,  5.4159,  5., 287., 19.6, 3.9690e+02,  6.15, 23. ),\n",
       "       (2.41030e-01,   0. ,  7.38, 0., 0.493 , 6.083,  43.7,  5.4159,  5., 287., 19.6, 3.9690e+02, 12.79, 22.2),\n",
       "       (6.61700e-02,   0. ,  3.24, 0., 0.46  , 5.868,  25.8,  5.2146,  4., 430., 16.9, 3.8244e+02,  9.97, 19.3),\n",
       "       (6.72400e-02,   0. ,  3.24, 0., 0.46  , 6.333,  17.2,  5.2146,  4., 430., 16.9, 3.7521e+02,  7.34, 22.6),\n",
       "       (4.54400e-02,   0. ,  3.24, 0., 0.46  , 6.144,  32.2,  5.8736,  4., 430., 16.9, 3.6857e+02,  9.09, 19.8),\n",
       "       (5.02300e-02,  35. ,  6.06, 0., 0.4379, 5.706,  28.4,  6.6407,  1., 304., 16.9, 3.9402e+02, 12.43, 17.1),\n",
       "       (3.46600e-02,  35. ,  6.06, 0., 0.4379, 6.031,  23.3,  6.6407,  1., 304., 16.9, 3.6225e+02,  7.83, 19.4),\n",
       "       (5.08300e-02,   0. ,  5.19, 0., 0.515 , 6.316,  38.1,  6.4584,  5., 224., 20.2, 3.8971e+02,  5.68, 22.2),\n",
       "       (3.73800e-02,   0. ,  5.19, 0., 0.515 , 6.31 ,  38.5,  6.4584,  5., 224., 20.2, 3.8940e+02,  6.75, 20.7),\n",
       "       (3.96100e-02,   0. ,  5.19, 0., 0.515 , 6.037,  34.5,  5.9853,  5., 224., 20.2, 3.9690e+02,  8.01, 21.1),\n",
       "       (3.42700e-02,   0. ,  5.19, 0., 0.515 , 5.869,  46.3,  5.2311,  5., 224., 20.2, 3.9690e+02,  9.8 , 19.5),\n",
       "       (3.04100e-02,   0. ,  5.19, 0., 0.515 , 5.895,  59.6,  5.615 ,  5., 224., 20.2, 3.9481e+02, 10.56, 18.5),\n",
       "       (3.30600e-02,   0. ,  5.19, 0., 0.515 , 6.059,  37.3,  4.8122,  5., 224., 20.2, 3.9614e+02,  8.51, 20.6),\n",
       "       (5.49700e-02,   0. ,  5.19, 0., 0.515 , 5.985,  45.4,  4.8122,  5., 224., 20.2, 3.9690e+02,  9.74, 19. ),\n",
       "       (6.15100e-02,   0. ,  5.19, 0., 0.515 , 5.968,  58.5,  4.8122,  5., 224., 20.2, 3.9690e+02,  9.29, 18.7),\n",
       "       (1.30100e-02,  35. ,  1.52, 0., 0.442 , 7.241,  49.3,  7.0379,  1., 284., 15.5, 3.9474e+02,  5.49, 32.7),\n",
       "       (2.49800e-02,   0. ,  1.89, 0., 0.518 , 6.54 ,  59.7,  6.2669,  1., 422., 15.9, 3.8996e+02,  8.65, 16.5),\n",
       "       (2.54300e-02,  55. ,  3.78, 0., 0.484 , 6.696,  56.4,  5.7321,  5., 370., 17.6, 3.9690e+02,  7.18, 23.9),\n",
       "       (3.04900e-02,  55. ,  3.78, 0., 0.484 , 6.874,  28.1,  6.4654,  5., 370., 17.6, 3.8797e+02,  4.61, 31.2),\n",
       "       (3.11300e-02,   0. ,  4.39, 0., 0.442 , 6.014,  48.5,  8.0136,  3., 352., 18.8, 3.8564e+02, 10.53, 17.5),\n",
       "       (6.16200e-02,   0. ,  4.39, 0., 0.442 , 5.898,  52.3,  8.0136,  3., 352., 18.8, 3.6461e+02, 12.67, 17.2),\n",
       "       (1.87000e-02,  85. ,  4.15, 0., 0.429 , 6.516,  27.7,  8.5353,  4., 351., 17.9, 3.9243e+02,  6.36, 23.1),\n",
       "       (1.50100e-02,  80. ,  2.01, 0., 0.435 , 6.635,  29.7,  8.344 ,  4., 280., 17. , 3.9094e+02,  5.99, 24.5),\n",
       "       (2.89900e-02,  40. ,  1.25, 0., 0.429 , 6.939,  34.5,  8.7921,  1., 335., 19.7, 3.8985e+02,  5.89, 26.6),\n",
       "       (6.21100e-02,  40. ,  1.25, 0., 0.429 , 6.49 ,  44.4,  8.7921,  1., 335., 19.7, 3.9690e+02,  5.98, 22.9),\n",
       "       (7.95000e-02,  60. ,  1.69, 0., 0.411 , 6.579,  35.9, 10.7103,  4., 411., 18.3, 3.7078e+02,  5.49, 24.1),\n",
       "       (7.24400e-02,  60. ,  1.69, 0., 0.411 , 5.884,  18.5, 10.7103,  4., 411., 18.3, 3.9233e+02,  7.79, 18.6),\n",
       "       (1.70900e-02,  90. ,  2.02, 0., 0.41  , 6.728,  36.1, 12.1265,  5., 187., 17. , 3.8446e+02,  4.5 , 30.1),\n",
       "       (4.30100e-02,  80. ,  1.91, 0., 0.413 , 5.663,  21.9, 10.5857,  4., 334., 22. , 3.8280e+02,  8.05, 18.2),\n",
       "       (1.06590e-01,  80. ,  1.91, 0., 0.413 , 5.936,  19.5, 10.5857,  4., 334., 22. , 3.7604e+02,  5.57, 20.6),\n",
       "       (8.98296e+00,   0. , 18.1 , 1., 0.77  , 6.212,  97.4,  2.1222, 24., 666., 20.2, 3.7773e+02, 17.6 , 17.8),\n",
       "       (3.84970e+00,   0. , 18.1 , 1., 0.77  , 6.395,  91. ,  2.5052, 24., 666., 20.2, 3.9134e+02, 13.27, 21.7),\n",
       "       (5.20177e+00,   0. , 18.1 , 1., 0.77  , 6.127,  83.4,  2.7227, 24., 666., 20.2, 3.9543e+02, 11.48, 22.7),\n",
       "       (4.26131e+00,   0. , 18.1 , 0., 0.77  , 6.112,  81.3,  2.5091, 24., 666., 20.2, 3.9074e+02, 12.67, 22.6),\n",
       "       (4.54192e+00,   0. , 18.1 , 0., 0.77  , 6.398,  88. ,  2.5182, 24., 666., 20.2, 3.7456e+02,  7.79, 25. ),\n",
       "       (3.83684e+00,   0. , 18.1 , 0., 0.77  , 6.251,  91.1,  2.2955, 24., 666., 20.2, 3.5065e+02, 14.19, 19.9),\n",
       "       (3.67822e+00,   0. , 18.1 , 0., 0.77  , 5.362,  96.2,  2.1036, 24., 666., 20.2, 3.8079e+02, 10.19, 20.8),\n",
       "       (4.22239e+00,   0. , 18.1 , 1., 0.77  , 5.803,  89. ,  1.9047, 24., 666., 20.2, 3.5304e+02, 14.64, 16.8),\n",
       "       (3.47428e+00,   0. , 18.1 , 1., 0.718 , 8.78 ,  82.9,  1.9047, 24., 666., 20.2, 3.5455e+02,  5.29, 21.9),\n",
       "       (4.55587e+00,   0. , 18.1 , 0., 0.718 , 3.561,  87.9,  1.6132, 24., 666., 20.2, 3.5470e+02,  7.12, 27.5),\n",
       "       (3.69695e+00,   0. , 18.1 , 0., 0.718 , 4.963,  91.4,  1.7523, 24., 666., 20.2, 3.1603e+02, 14.  , 21.9),\n",
       "       (1.35222e+01,   0. , 18.1 , 0., 0.631 , 3.863, 100. ,  1.5106, 24., 666., 20.2, 1.3142e+02, 13.33, 23.1),\n",
       "       (4.89822e+00,   0. , 18.1 , 0., 0.631 , 4.97 , 100. ,  1.3325, 24., 666., 20.2, 3.7552e+02,  3.26, 50. ),\n",
       "       (5.66998e+00,   0. , 18.1 , 1., 0.631 , 6.683,  96.8,  1.3567, 24., 666., 20.2, 3.7533e+02,  3.73, 50. ),\n",
       "       (6.53876e+00,   0. , 18.1 , 1., 0.631 , 7.016,  97.5,  1.2024, 24., 666., 20.2, 3.9205e+02,  2.96, 50. ),\n",
       "       (9.23230e+00,   0. , 18.1 , 0., 0.631 , 6.216, 100. ,  1.1691, 24., 666., 20.2, 3.6615e+02,  9.53, 50. ),\n",
       "       (8.26725e+00,   0. , 18.1 , 1., 0.668 , 5.875,  89.6,  1.1296, 24., 666., 20.2, 3.4788e+02,  8.88, 50. ),\n",
       "       (1.11081e+01,   0. , 18.1 , 0., 0.668 , 4.906, 100. ,  1.1742, 24., 666., 20.2, 3.9690e+02, 34.77, 13.8),\n",
       "       (1.84982e+01,   0. , 18.1 , 0., 0.668 , 4.138, 100. ,  1.137 , 24., 666., 20.2, 3.9690e+02, 37.97, 13.8),\n",
       "       (1.96091e+01,   0. , 18.1 , 0., 0.671 , 7.313,  97.9,  1.3163, 24., 666., 20.2, 3.9690e+02, 13.44, 15. ),\n",
       "       (1.52880e+01,   0. , 18.1 , 0., 0.671 , 6.649,  93.3,  1.3449, 24., 666., 20.2, 3.6302e+02, 23.24, 13.9),\n",
       "       (9.82349e+00,   0. , 18.1 , 0., 0.671 , 6.794,  98.8,  1.358 , 24., 666., 20.2, 3.9690e+02, 21.24, 13.3),\n",
       "       (2.36482e+01,   0. , 18.1 , 0., 0.671 , 6.38 ,  96.2,  1.3861, 24., 666., 20.2, 3.9690e+02, 23.69, 13.1),\n",
       "       (1.78667e+01,   0. , 18.1 , 0., 0.671 , 6.223, 100. ,  1.3861, 24., 666., 20.2, 3.9374e+02, 21.78, 10.2),\n",
       "       (8.89762e+01,   0. , 18.1 , 0., 0.671 , 6.968,  91.9,  1.4165, 24., 666., 20.2, 3.9690e+02, 17.21, 10.4),\n",
       "       (1.58744e+01,   0. , 18.1 , 0., 0.671 , 6.545,  99.1,  1.5192, 24., 666., 20.2, 3.9690e+02, 21.08, 10.9),\n",
       "       (9.18702e+00,   0. , 18.1 , 0., 0.7   , 5.536, 100. ,  1.5804, 24., 666., 20.2, 3.9690e+02, 23.6 , 11.3),\n",
       "       (7.99248e+00,   0. , 18.1 , 0., 0.7   , 5.52 , 100. ,  1.5331, 24., 666., 20.2, 3.9690e+02, 24.56, 12.3),\n",
       "       (2.00849e+01,   0. , 18.1 , 0., 0.7   , 4.368,  91.2,  1.4395, 24., 666., 20.2, 2.8583e+02, 30.63,  8.8),\n",
       "       (1.68118e+01,   0. , 18.1 , 0., 0.7   , 5.277,  98.1,  1.4261, 24., 666., 20.2, 3.9690e+02, 30.81,  7.2),\n",
       "       (2.43938e+01,   0. , 18.1 , 0., 0.7   , 4.652, 100. ,  1.4672, 24., 666., 20.2, 3.9690e+02, 28.28, 10.5),\n",
       "       (2.25971e+01,   0. , 18.1 , 0., 0.7   , 5.   ,  89.5,  1.5184, 24., 666., 20.2, 3.9690e+02, 31.99,  7.4),\n",
       "       (1.43337e+01,   0. , 18.1 , 0., 0.7   , 4.88 , 100. ,  1.5895, 24., 666., 20.2, 3.7292e+02, 30.62, 10.2),\n",
       "       (8.15174e+00,   0. , 18.1 , 0., 0.7   , 5.39 ,  98.9,  1.7281, 24., 666., 20.2, 3.9690e+02, 20.85, 11.5),\n",
       "       (6.96215e+00,   0. , 18.1 , 0., 0.7   , 5.713,  97. ,  1.9265, 24., 666., 20.2, 3.9443e+02, 17.11, 15.1),\n",
       "       (5.29305e+00,   0. , 18.1 , 0., 0.7   , 6.051,  82.5,  2.1678, 24., 666., 20.2, 3.7838e+02, 18.76, 23.2),\n",
       "       (1.15779e+01,   0. , 18.1 , 0., 0.7   , 5.036,  97. ,  1.77  , 24., 666., 20.2, 3.9690e+02, 25.68,  9.7),\n",
       "       (8.64476e+00,   0. , 18.1 , 0., 0.693 , 6.193,  92.6,  1.7912, 24., 666., 20.2, 3.9690e+02, 15.17, 13.8),\n",
       "       (1.33598e+01,   0. , 18.1 , 0., 0.693 , 5.887,  94.7,  1.7821, 24., 666., 20.2, 3.9690e+02, 16.35, 12.7),\n",
       "       (8.71675e+00,   0. , 18.1 , 0., 0.693 , 6.471,  98.8,  1.7257, 24., 666., 20.2, 3.9198e+02, 17.12, 13.1),\n",
       "       (5.87205e+00,   0. , 18.1 , 0., 0.693 , 6.405,  96. ,  1.6768, 24., 666., 20.2, 3.9690e+02, 19.37, 12.5),\n",
       "       (7.67202e+00,   0. , 18.1 , 0., 0.693 , 5.747,  98.9,  1.6334, 24., 666., 20.2, 3.9310e+02, 19.92,  8.5),\n",
       "       (3.83518e+01,   0. , 18.1 , 0., 0.693 , 5.453, 100. ,  1.4896, 24., 666., 20.2, 3.9690e+02, 30.59,  5. ),\n",
       "       (9.91655e+00,   0. , 18.1 , 0., 0.693 , 5.852,  77.8,  1.5004, 24., 666., 20.2, 3.3816e+02, 29.97,  6.3),\n",
       "       (2.50461e+01,   0. , 18.1 , 0., 0.693 , 5.987, 100. ,  1.5888, 24., 666., 20.2, 3.9690e+02, 26.77,  5.6),\n",
       "       (1.42362e+01,   0. , 18.1 , 0., 0.693 , 6.343, 100. ,  1.5741, 24., 666., 20.2, 3.9690e+02, 20.32,  7.2),\n",
       "       (9.59571e+00,   0. , 18.1 , 0., 0.693 , 6.404, 100. ,  1.639 , 24., 666., 20.2, 3.7611e+02, 20.31, 12.1),\n",
       "       (2.48017e+01,   0. , 18.1 , 0., 0.693 , 5.349,  96. ,  1.7028, 24., 666., 20.2, 3.9690e+02, 19.77,  8.3),\n",
       "       (4.15292e+01,   0. , 18.1 , 0., 0.693 , 5.531,  85.4,  1.6074, 24., 666., 20.2, 3.2946e+02, 27.38,  8.5),\n",
       "       (6.79208e+01,   0. , 18.1 , 0., 0.693 , 5.683, 100. ,  1.4254, 24., 666., 20.2, 3.8497e+02, 22.98,  5. ),\n",
       "       (2.07162e+01,   0. , 18.1 , 0., 0.659 , 4.138, 100. ,  1.1781, 24., 666., 20.2, 3.7022e+02, 23.34, 11.9),\n",
       "       (1.19511e+01,   0. , 18.1 , 0., 0.659 , 5.608, 100. ,  1.2852, 24., 666., 20.2, 3.3209e+02, 12.13, 27.9),\n",
       "       (7.40389e+00,   0. , 18.1 , 0., 0.597 , 5.617,  97.9,  1.4547, 24., 666., 20.2, 3.1464e+02, 26.4 , 17.2),\n",
       "       (1.44383e+01,   0. , 18.1 , 0., 0.597 , 6.852, 100. ,  1.4655, 24., 666., 20.2, 1.7936e+02, 19.78, 27.5),\n",
       "       (5.11358e+01,   0. , 18.1 , 0., 0.597 , 5.757, 100. ,  1.413 , 24., 666., 20.2, 2.6000e+00, 10.11, 15. ),\n",
       "       (1.40507e+01,   0. , 18.1 , 0., 0.597 , 6.657, 100. ,  1.5275, 24., 666., 20.2, 3.5050e+01, 21.22, 17.2),\n",
       "       (1.88110e+01,   0. , 18.1 , 0., 0.597 , 4.628, 100. ,  1.5539, 24., 666., 20.2, 2.8790e+01, 34.37, 17.9),\n",
       "       (2.86558e+01,   0. , 18.1 , 0., 0.597 , 5.155, 100. ,  1.5894, 24., 666., 20.2, 2.1097e+02, 20.08, 16.3),\n",
       "       (4.57461e+01,   0. , 18.1 , 0., 0.693 , 4.519, 100. ,  1.6582, 24., 666., 20.2, 8.8270e+01, 36.98,  7. ),\n",
       "       (1.80846e+01,   0. , 18.1 , 0., 0.679 , 6.434, 100. ,  1.8347, 24., 666., 20.2, 2.7250e+01, 29.05,  7.2),\n",
       "       (1.08342e+01,   0. , 18.1 , 0., 0.679 , 6.782,  90.8,  1.8195, 24., 666., 20.2, 2.1570e+01, 25.79,  7.5),\n",
       "       (2.59406e+01,   0. , 18.1 , 0., 0.679 , 5.304,  89.1,  1.6475, 24., 666., 20.2, 1.2736e+02, 26.64, 10.4),\n",
       "       (7.35341e+01,   0. , 18.1 , 0., 0.679 , 5.957, 100. ,  1.8026, 24., 666., 20.2, 1.6450e+01, 20.62,  8.8),\n",
       "       (1.18123e+01,   0. , 18.1 , 0., 0.718 , 6.824,  76.5,  1.794 , 24., 666., 20.2, 4.8450e+01, 22.74,  8.4),\n",
       "       (1.10874e+01,   0. , 18.1 , 0., 0.718 , 6.411, 100. ,  1.8589, 24., 666., 20.2, 3.1875e+02, 15.02, 16.7),\n",
       "       (7.02259e+00,   0. , 18.1 , 0., 0.718 , 6.006,  95.3,  1.8746, 24., 666., 20.2, 3.1998e+02, 15.7 , 14.2),\n",
       "       (1.20482e+01,   0. , 18.1 , 0., 0.614 , 5.648,  87.6,  1.9512, 24., 666., 20.2, 2.9155e+02, 14.1 , 20.8),\n",
       "       (7.05042e+00,   0. , 18.1 , 0., 0.614 , 6.103,  85.1,  2.0218, 24., 666., 20.2, 2.5200e+00, 23.29, 13.4),\n",
       "       (8.79212e+00,   0. , 18.1 , 0., 0.584 , 5.565,  70.6,  2.0635, 24., 666., 20.2, 3.6500e+00, 17.16, 11.7),\n",
       "       (1.58603e+01,   0. , 18.1 , 0., 0.679 , 5.896,  95.4,  1.9096, 24., 666., 20.2, 7.6800e+00, 24.39,  8.3),\n",
       "       (1.22472e+01,   0. , 18.1 , 0., 0.584 , 5.837,  59.7,  1.9976, 24., 666., 20.2, 2.4650e+01, 15.69, 10.2),\n",
       "       (3.76619e+01,   0. , 18.1 , 0., 0.679 , 6.202,  78.7,  1.8629, 24., 666., 20.2, 1.8820e+01, 14.52, 10.9),\n",
       "       (7.36711e+00,   0. , 18.1 , 0., 0.679 , 6.193,  78.1,  1.9356, 24., 666., 20.2, 9.6730e+01, 21.52, 11. ),\n",
       "       (9.33889e+00,   0. , 18.1 , 0., 0.679 , 6.38 ,  95.6,  1.9682, 24., 666., 20.2, 6.0720e+01, 24.08,  9.5),\n",
       "       (8.49213e+00,   0. , 18.1 , 0., 0.584 , 6.348,  86.1,  2.0527, 24., 666., 20.2, 8.3450e+01, 17.64, 14.5),\n",
       "       (1.00623e+01,   0. , 18.1 , 0., 0.584 , 6.833,  94.3,  2.0882, 24., 666., 20.2, 8.1330e+01, 19.69, 14.1),\n",
       "       (6.44405e+00,   0. , 18.1 , 0., 0.584 , 6.425,  74.8,  2.2004, 24., 666., 20.2, 9.7950e+01, 12.03, 16.1),\n",
       "       (5.58107e+00,   0. , 18.1 , 0., 0.713 , 6.436,  87.9,  2.3158, 24., 666., 20.2, 1.0019e+02, 16.22, 14.3),\n",
       "       (1.39134e+01,   0. , 18.1 , 0., 0.713 , 6.208,  95. ,  2.2222, 24., 666., 20.2, 1.0063e+02, 15.17, 11.7),\n",
       "       (1.11604e+01,   0. , 18.1 , 0., 0.74  , 6.629,  94.6,  2.1247, 24., 666., 20.2, 1.0985e+02, 23.27, 13.4),\n",
       "       (1.44208e+01,   0. , 18.1 , 0., 0.74  , 6.461,  93.3,  2.0026, 24., 666., 20.2, 2.7490e+01, 18.05,  9.6),\n",
       "       (1.51772e+01,   0. , 18.1 , 0., 0.74  , 6.152, 100. ,  1.9142, 24., 666., 20.2, 9.3200e+00, 26.45,  8.7),\n",
       "       (1.36781e+01,   0. , 18.1 , 0., 0.74  , 5.935,  87.9,  1.8206, 24., 666., 20.2, 6.8950e+01, 34.02,  8.4),\n",
       "       (9.39063e+00,   0. , 18.1 , 0., 0.74  , 5.627,  93.9,  1.8172, 24., 666., 20.2, 3.9690e+02, 22.88, 12.8),\n",
       "       (2.20511e+01,   0. , 18.1 , 0., 0.74  , 5.818,  92.4,  1.8662, 24., 666., 20.2, 3.9145e+02, 22.11, 10.5),\n",
       "       (9.72418e+00,   0. , 18.1 , 0., 0.74  , 6.406,  97.2,  2.0651, 24., 666., 20.2, 3.8596e+02, 19.52, 17.1),\n",
       "       (5.66637e+00,   0. , 18.1 , 0., 0.74  , 6.219, 100. ,  2.0048, 24., 666., 20.2, 3.9569e+02, 16.59, 18.4),\n",
       "       (9.96654e+00,   0. , 18.1 , 0., 0.74  , 6.485, 100. ,  1.9784, 24., 666., 20.2, 3.8673e+02, 18.85, 15.4),\n",
       "       (1.28023e+01,   0. , 18.1 , 0., 0.74  , 5.854,  96.6,  1.8956, 24., 666., 20.2, 2.4052e+02, 23.79, 10.8),\n",
       "       (1.06718e+01,   0. , 18.1 , 0., 0.74  , 6.459,  94.8,  1.9879, 24., 666., 20.2, 4.3060e+01, 23.98, 11.8),\n",
       "       (6.28807e+00,   0. , 18.1 , 0., 0.74  , 6.341,  96.4,  2.072 , 24., 666., 20.2, 3.1801e+02, 17.79, 14.9),\n",
       "       (9.92485e+00,   0. , 18.1 , 0., 0.74  , 6.251,  96.6,  2.198 , 24., 666., 20.2, 3.8852e+02, 16.44, 12.6),\n",
       "       (9.32909e+00,   0. , 18.1 , 0., 0.713 , 6.185,  98.7,  2.2616, 24., 666., 20.2, 3.9690e+02, 18.13, 14.1),\n",
       "       (7.52601e+00,   0. , 18.1 , 0., 0.713 , 6.417,  98.3,  2.185 , 24., 666., 20.2, 3.0421e+02, 19.31, 13. ),\n",
       "       (6.71772e+00,   0. , 18.1 , 0., 0.713 , 6.749,  92.6,  2.3236, 24., 666., 20.2, 3.2000e-01, 17.44, 13.4),\n",
       "       (5.44114e+00,   0. , 18.1 , 0., 0.713 , 6.655,  98.2,  2.3552, 24., 666., 20.2, 3.5529e+02, 17.73, 15.2),\n",
       "       (5.09017e+00,   0. , 18.1 , 0., 0.713 , 6.297,  91.8,  2.3682, 24., 666., 20.2, 3.8509e+02, 17.27, 16.1),\n",
       "       (8.24809e+00,   0. , 18.1 , 0., 0.713 , 7.393,  99.3,  2.4527, 24., 666., 20.2, 3.7587e+02, 16.74, 17.8),\n",
       "       (9.51363e+00,   0. , 18.1 , 0., 0.713 , 6.728,  94.1,  2.4961, 24., 666., 20.2, 6.6800e+00, 18.71, 14.9),\n",
       "       (4.75237e+00,   0. , 18.1 , 0., 0.713 , 6.525,  86.5,  2.4358, 24., 666., 20.2, 5.0920e+01, 18.13, 14.1),\n",
       "       (4.66883e+00,   0. , 18.1 , 0., 0.713 , 5.976,  87.9,  2.5806, 24., 666., 20.2, 1.0480e+01, 19.01, 12.7),\n",
       "       (8.20058e+00,   0. , 18.1 , 0., 0.713 , 5.936,  80.3,  2.7792, 24., 666., 20.2, 3.5000e+00, 16.94, 13.5),\n",
       "       (7.75223e+00,   0. , 18.1 , 0., 0.713 , 6.301,  83.7,  2.7831, 24., 666., 20.2, 2.7221e+02, 16.23, 14.9),\n",
       "       (6.80117e+00,   0. , 18.1 , 0., 0.713 , 6.081,  84.4,  2.7175, 24., 666., 20.2, 3.9690e+02, 14.7 , 20. ),\n",
       "       (4.81213e+00,   0. , 18.1 , 0., 0.713 , 6.701,  90. ,  2.5975, 24., 666., 20.2, 2.5523e+02, 16.42, 16.4),\n",
       "       (3.69311e+00,   0. , 18.1 , 0., 0.713 , 6.376,  88.4,  2.5671, 24., 666., 20.2, 3.9143e+02, 14.65, 17.7),\n",
       "       (6.65492e+00,   0. , 18.1 , 0., 0.713 , 6.317,  83. ,  2.7344, 24., 666., 20.2, 3.9690e+02, 13.99, 19.5),\n",
       "       (5.82115e+00,   0. , 18.1 , 0., 0.713 , 6.513,  89.9,  2.8016, 24., 666., 20.2, 3.9382e+02, 10.29, 20.2),\n",
       "       (7.83932e+00,   0. , 18.1 , 0., 0.655 , 6.209,  65.4,  2.9634, 24., 666., 20.2, 3.9690e+02, 13.22, 21.4),\n",
       "       (3.16360e+00,   0. , 18.1 , 0., 0.655 , 5.759,  48.2,  3.0665, 24., 666., 20.2, 3.3440e+02, 14.13, 19.9),\n",
       "       (3.77498e+00,   0. , 18.1 , 0., 0.655 , 5.952,  84.7,  2.8715, 24., 666., 20.2, 2.2010e+01, 17.15, 19. ),\n",
       "       (4.42228e+00,   0. , 18.1 , 0., 0.584 , 6.003,  94.5,  2.5403, 24., 666., 20.2, 3.3129e+02, 21.32, 19.1),\n",
       "       (1.55757e+01,   0. , 18.1 , 0., 0.58  , 5.926,  71. ,  2.9084, 24., 666., 20.2, 3.6874e+02, 18.13, 19.1),\n",
       "       (1.30751e+01,   0. , 18.1 , 0., 0.58  , 5.713,  56.7,  2.8237, 24., 666., 20.2, 3.9690e+02, 14.76, 20.1),\n",
       "       (4.34879e+00,   0. , 18.1 , 0., 0.58  , 6.167,  84. ,  3.0334, 24., 666., 20.2, 3.9690e+02, 16.29, 19.9),\n",
       "       (4.03841e+00,   0. , 18.1 , 0., 0.532 , 6.229,  90.7,  3.0993, 24., 666., 20.2, 3.9533e+02, 12.87, 19.6),\n",
       "       (3.56868e+00,   0. , 18.1 , 0., 0.58  , 6.437,  75. ,  2.8965, 24., 666., 20.2, 3.9337e+02, 14.36, 23.2),\n",
       "       (4.64689e+00,   0. , 18.1 , 0., 0.614 , 6.98 ,  67.6,  2.5329, 24., 666., 20.2, 3.7468e+02, 11.66, 29.8),\n",
       "       (8.05579e+00,   0. , 18.1 , 0., 0.584 , 5.427,  95.4,  2.4298, 24., 666., 20.2, 3.5258e+02, 18.14, 13.8),\n",
       "       (6.39312e+00,   0. , 18.1 , 0., 0.584 , 6.162,  97.4,  2.206 , 24., 666., 20.2, 3.0276e+02, 24.1 , 13.3),\n",
       "       (4.87141e+00,   0. , 18.1 , 0., 0.614 , 6.484,  93.6,  2.3053, 24., 666., 20.2, 3.9621e+02, 18.68, 16.7),\n",
       "       (1.50234e+01,   0. , 18.1 , 0., 0.614 , 5.304,  97.3,  2.1007, 24., 666., 20.2, 3.4948e+02, 24.91, 12. ),\n",
       "       (1.02330e+01,   0. , 18.1 , 0., 0.614 , 6.185,  96.7,  2.1705, 24., 666., 20.2, 3.7970e+02, 18.03, 14.6),\n",
       "       (1.43337e+01,   0. , 18.1 , 0., 0.614 , 6.229,  88. ,  1.9512, 24., 666., 20.2, 3.8332e+02, 13.11, 21.4),\n",
       "       (5.82401e+00,   0. , 18.1 , 0., 0.532 , 6.242,  64.7,  3.4242, 24., 666., 20.2, 3.9690e+02, 10.74, 23. ),\n",
       "       (5.70818e+00,   0. , 18.1 , 0., 0.532 , 6.75 ,  74.9,  3.3317, 24., 666., 20.2, 3.9307e+02,  7.74, 23.7),\n",
       "       (5.73116e+00,   0. , 18.1 , 0., 0.532 , 7.061,  77. ,  3.4106, 24., 666., 20.2, 3.9528e+02,  7.01, 25. ),\n",
       "       (2.81838e+00,   0. , 18.1 , 0., 0.532 , 5.762,  40.3,  4.0983, 24., 666., 20.2, 3.9292e+02, 10.42, 21.8),\n",
       "       (2.37857e+00,   0. , 18.1 , 0., 0.583 , 5.871,  41.9,  3.724 , 24., 666., 20.2, 3.7073e+02, 13.34, 20.6),\n",
       "       (3.67367e+00,   0. , 18.1 , 0., 0.583 , 6.312,  51.9,  3.9917, 24., 666., 20.2, 3.8862e+02, 10.58, 21.2),\n",
       "       (5.69175e+00,   0. , 18.1 , 0., 0.583 , 6.114,  79.8,  3.5459, 24., 666., 20.2, 3.9268e+02, 14.98, 19.1),\n",
       "       (4.83567e+00,   0. , 18.1 , 0., 0.583 , 5.905,  53.2,  3.1523, 24., 666., 20.2, 3.8822e+02, 11.45, 20.6),\n",
       "       (1.50860e-01,   0. , 27.74, 0., 0.609 , 5.454,  92.7,  1.8209,  4., 711., 20.1, 3.9509e+02, 18.06, 15.2),\n",
       "       (1.83370e-01,   0. , 27.74, 0., 0.609 , 5.414,  98.3,  1.7554,  4., 711., 20.1, 3.4405e+02, 23.97,  7. ),\n",
       "       (2.07460e-01,   0. , 27.74, 0., 0.609 , 5.093,  98. ,  1.8226,  4., 711., 20.1, 3.1843e+02, 29.68,  8.1),\n",
       "       (1.05740e-01,   0. , 27.74, 0., 0.609 , 5.983,  98.8,  1.8681,  4., 711., 20.1, 3.9011e+02, 18.07, 13.6),\n",
       "       (1.11320e-01,   0. , 27.74, 0., 0.609 , 5.983,  83.5,  2.1099,  4., 711., 20.1, 3.9690e+02, 13.35, 20.1),\n",
       "       (1.73310e-01,   0. ,  9.69, 0., 0.585 , 5.707,  54. ,  2.3817,  6., 391., 19.2, 3.9690e+02, 12.01, 21.8),\n",
       "       (2.79570e-01,   0. ,  9.69, 0., 0.585 , 5.926,  42.6,  2.3817,  6., 391., 19.2, 3.9690e+02, 13.59, 24.5),\n",
       "       (1.78990e-01,   0. ,  9.69, 0., 0.585 , 5.67 ,  28.8,  2.7986,  6., 391., 19.2, 3.9329e+02, 17.6 , 23.1),\n",
       "       (2.89600e-01,   0. ,  9.69, 0., 0.585 , 5.39 ,  72.9,  2.7986,  6., 391., 19.2, 3.9690e+02, 21.14, 19.7),\n",
       "       (2.68380e-01,   0. ,  9.69, 0., 0.585 , 5.794,  70.6,  2.8927,  6., 391., 19.2, 3.9690e+02, 14.1 , 18.3),\n",
       "       (2.39120e-01,   0. ,  9.69, 0., 0.585 , 6.019,  65.3,  2.4091,  6., 391., 19.2, 3.9690e+02, 12.92, 21.2),\n",
       "       (1.77830e-01,   0. ,  9.69, 0., 0.585 , 5.569,  73.5,  2.3999,  6., 391., 19.2, 3.9577e+02, 15.1 , 17.5),\n",
       "       (2.24380e-01,   0. ,  9.69, 0., 0.585 , 6.027,  79.7,  2.4982,  6., 391., 19.2, 3.9690e+02, 14.33, 16.8),\n",
       "       (6.26300e-02,   0. , 11.93, 0., 0.573 , 6.593,  69.1,  2.4786,  1., 273., 21. , 3.9199e+02,  9.67, 22.4),\n",
       "       (4.52700e-02,   0. , 11.93, 0., 0.573 , 6.12 ,  76.7,  2.2875,  1., 273., 21. , 3.9690e+02,  9.08, 20.6),\n",
       "       (6.07600e-02,   0. , 11.93, 0., 0.573 , 6.976,  91. ,  2.1675,  1., 273., 21. , 3.9690e+02,  5.64, 23.9),\n",
       "       (1.09590e-01,   0. , 11.93, 0., 0.573 , 6.794,  89.3,  2.3889,  1., 273., 21. , 3.9345e+02,  6.48, 22. ),\n",
       "       (4.74100e-02,   0. , 11.93, 0., 0.573 , 6.03 ,  80.8,  2.505 ,  1., 273., 21. , 3.9690e+02,  7.88, 11.9)],\n",
       "      dtype=[('CRIM', '<f4'), ('ZN', '<f4'), ('INDUS', '<f4'), ('CHAS', '<f4'), ('NOX', '<f4'), ('RM', '<f4'), ('AGE', '<f4'), ('DIS', '<f4'), ('RAD', '<f4'), ('TAX', '<f4'), ('PT', '<f4'), ('B', '<f4'), ('LSTAT', '<f4'), ('MV', '<f4')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([i[0] for i in data])\n",
    "x2 = np.array([i[1] for i in data])\n",
    "x3 = np.array([i[2] for i in data])\n",
    "x4 = np.array([i[3] for i in data])\n",
    "x5 = np.array([i[4] for i in data])\n",
    "x6 = np.array([i[5] for i in data])\n",
    "x7 = np.array([i[6] for i in data])\n",
    "x8 = np.array([i[7] for i in data])\n",
    "x9 = np.array([i[8] for i in data])\n",
    "x10 = np.array([i[9] for i in data])\n",
    "x11 = np.array([i[10] for i in data])\n",
    "x12 = np.array([i[11] for i in data])\n",
    "x13 = np.array([i[12] for i in data])\n",
    "y = np.array([i[13] for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = (x1 - x1.mean())/np.std(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = (x2 - x2.mean())/np.std(x2)\n",
    "x3 = (x3 - x3.mean())/np.std(x3)\n",
    "x4 = (x4 - x4.mean())/np.std(x4)\n",
    "x5 = (x5 - x5.mean())/np.std(x5)\n",
    "x6 = (x6 - x6.mean())/np.std(x6)\n",
    "x7 = (x7 - x7.mean())/np.std(x7)\n",
    "x8 = (x8 - x8.mean())/np.std(x8)\n",
    "x9 = (x9 - x9.mean())/np.std(x9)\n",
    "x10 = (x10 - x10.mean())/np.std(x10)\n",
    "x11 = (x11 - x11.mean())/np.std(x11)\n",
    "x12 = (x12 - x12.mean())/np.std(x12)\n",
    "x13 = (x13 - x13.mean())/np.std(x13)\n",
    "y = (y - y.mean())/np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 5-fold sample indices for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(data)\n",
    "np.random.seed(6754)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_range = np.array([i for i in range(m)])\n",
    "validation_choose_set = [i for i in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sample1 = np.random.choice(validation_choose_set, size=int(m/5))\n",
    "validation_choose_set = np.setdiff1d(validation_choose_set, validation_sample1)\n",
    "validation_sample2 = np.random.choice(validation_choose_set, size=int(m/5))\n",
    "validation_choose_set = np.setdiff1d(validation_choose_set, validation_sample2)\n",
    "validation_sample3 = np.random.choice(validation_choose_set, size=int(m/5))\n",
    "validation_choose_set = np.setdiff1d(validation_choose_set, validation_sample3)\n",
    "validation_sample4 = np.random.choice(validation_choose_set, size=int(m/5))\n",
    "validation_choose_set = np.setdiff1d(validation_choose_set, validation_sample4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   3,   4,   5,   6,  10,  11,  16,  21,  31,  33,  34,\n",
       "        40,  41,  43,  46,  48,  49,  52,  53,  54,  55,  56,  58,  59,\n",
       "        60,  63,  65,  67,  68,  71,  72,  78,  79,  83,  84,  90,  95,\n",
       "        97,  99, 102, 106, 107, 108, 115, 117, 119, 120, 129, 131, 133,\n",
       "       135, 136, 138, 139, 143, 145, 146, 151, 157, 158, 159, 165, 170,\n",
       "       174, 175, 180, 186, 187, 190, 194, 196, 202, 210, 211, 212, 219,\n",
       "       220, 222, 232, 234, 238, 241, 248, 253, 256, 260, 261, 270, 272,\n",
       "       274, 276, 278, 282, 283, 287, 290, 291, 296, 297, 298, 301, 308,\n",
       "       310, 311, 312, 314, 321, 329, 338, 341, 355, 357, 361, 369, 373,\n",
       "       375, 385, 386, 391, 393, 402, 407, 408, 412, 416, 417, 418, 419,\n",
       "       423, 425, 429, 430, 431, 436, 441, 443, 450, 451, 454, 457, 459,\n",
       "       460, 468, 470, 472, 474, 475, 476, 478, 482, 485, 486, 488, 493,\n",
       "       500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_sample5 = validation_choose_set[:]\n",
    "validation_sample5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.41978195,  0.28482988, ..., -1.45900023,\n",
       "         0.44105175, -1.07556236],\n",
       "       [ 1.        , -0.4173393 , -0.48772237, ..., -0.30309463,\n",
       "         0.44105175, -0.49243939],\n",
       "       [ 1.        , -0.41734159, -0.48772237, ..., -0.30309463,\n",
       "         0.39642674, -1.20872748],\n",
       "       ...,\n",
       "       [ 1.        , -0.41344661, -0.48772237, ...,  1.17646551,\n",
       "         0.44105175, -0.98304766],\n",
       "       [ 1.        , -0.40776408, -0.48772237, ...,  1.17646551,\n",
       "         0.40322492, -0.86530167],\n",
       "       [ 1.        , -0.41500017, -0.48772237, ...,  1.17646551,\n",
       "         0.44105175, -0.66905838]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.column_stack((np.ones(len(x1)), x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7001304 ,  0.2032206 , -0.28654805,  0.2902907 , -0.330083  ,\n",
       "       -0.0688731 , -0.4171529 ,  0.06173196,  0.17056945, -1.3096204 ,\n",
       "       -0.7001304 , -0.6892466 , -1.0701779 ,  0.03996439, -0.8851542 ,\n",
       "       -0.9722241 , -0.4171529 , -0.30831543,  1.487503  , -1.5708302 ,\n",
       "        0.42089558, -1.3422716 , -0.03622173,  0.03996439, -0.31919923,\n",
       "        0.82359433, -0.02533814, -1.3096204 ,  1.3460144 ,  0.60591936,\n",
       "        1.0848043 ,  0.9324318 , -0.03622173, -0.23212932, -1.0157591 ,\n",
       "       -0.05798931,  0.17056945,  0.82359433,  0.0290806 , -0.4389205 ,\n",
       "       -0.64571166, -0.38450176, -0.17771058, -0.5804091 , -0.03622173,\n",
       "        0.08349933,  1.3460144 ,  0.26852313,  1.3460144 , -1.3422716 ,\n",
       "       -0.12329184,  2.9894602 ,  1.3460144 , -1.9082265 ,  0.09438313,\n",
       "       -1.0701779 , -0.23212932,  0.9324318 , -0.09064047, -1.0701779 ,\n",
       "       -0.05798931, -0.7110142 , -1.842924  ,  0.98685056, -0.83073545,\n",
       "       -0.22124553, -0.29743186,  0.3991282 ,  0.19233681,  1.0521531 ,\n",
       "       -1.5055279 , -0.75454915,  1.487503  , -0.02533814,  0.2032206 ,\n",
       "        1.0303855 ,  0.99773437, -0.23212932, -0.330083  ,  2.858855  ,\n",
       "        2.9894602 , -0.05798931, -0.547758  , -1.1790154 , -0.86338663,\n",
       "        0.19233681,  2.9894602 ,  0.98685056, -1.0919454 , -1.3205042 ,\n",
       "        1.5201542 ,  0.79094297,  0.17056945,  0.05084817, -0.5151068 ,\n",
       "        1.6398753 ,  2.9894602 , -0.28654805, -0.8089679 , -0.29743186,\n",
       "        0.07261576], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[validation_sample1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation_sample1, x's, y, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(X, y, sample):\n",
    "    RANGE = len(X)\n",
    "    train_sample = np.setdiff1d(np.array([i for i in range(RANGE)]), sample)\n",
    "    test_sample = sample[:]\n",
    "    X_train = X[train_sample]\n",
    "    X_test = X[test_sample]\n",
    "    y_train = y[train_sample]\n",
    "    y_test = y[test_sample]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_func(X, y, theta, j):   \n",
    "    temp = np.zeros(len(X))\n",
    "    for i in range(len(theta)):\n",
    "        temp += theta[i]*X[:,i]\n",
    "        \n",
    "    return np.matmul((temp - y), X[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_train, y_train, X_test, y_test, learning_rate=0.01):\n",
    "    \n",
    "    #init\n",
    "    n = len(X_train[0])\n",
    "    theta = np.array([1.5 for i in range(n)])\n",
    "    number_of_iterations = 0\n",
    "    train_error = []\n",
    "    valid_error = []\n",
    "    y_hat = np.zeros((len(y), 1))\n",
    "    err = 1000000\n",
    "    \n",
    "    #Gradient Descent\n",
    "    while True:\n",
    "        print (\"==========\"*10)\n",
    "        print (\"Iteration: \", number_of_iterations)\n",
    "\n",
    "        prev_theta = theta[:]\n",
    "\n",
    "        print (\"Previous theta : \", prev_theta)\n",
    "        number_of_iterations += 1\n",
    "\n",
    "        # Updating all thetas simultaneously\n",
    "        for i in range(n):\n",
    "            theta[i] = theta[i] - (learning_rate/100.0)*input_func(X_train, y_train, theta, i)\n",
    "\n",
    "\n",
    "        print(\"New theta_0 :\", theta)\n",
    "\n",
    "        # Training Error\n",
    "        y_hat = np.matmul(X_train, theta)\n",
    "        new_err = np.linalg.norm(y_hat-y_train)\n",
    "        train_error.append(new_err)\n",
    "        print (\"Training Error: \", new_err)\n",
    "\n",
    "\n",
    "        # Validation error\n",
    "        y_hat_v = np.matmul(X_test, theta)\n",
    "        err_valid = np.linalg.norm(y_hat_v-y_test)\n",
    "        valid_error.append(err_valid)\n",
    "\n",
    "        if (err-new_err) <= 0.000001:\n",
    "            return train_error, valid_error, theta\n",
    "\n",
    "        err = new_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  0\n",
      "Previous theta :  [1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5]\n",
      "New theta_0 : [1.43657636 1.32176092 1.58031992 1.29002223 1.45126221 1.30141329\n",
      " 1.58098839 1.32405606 1.63110727 1.27869766 1.28339453 1.37177964\n",
      " 1.5678441  1.33770187]\n",
      "Training Error:  122.94026750741165\n",
      "====================================================================================================\n",
      "Iteration:  1\n",
      "Previous theta :  [1.43657636 1.32176092 1.58031992 1.29002223 1.45126221 1.30141329\n",
      " 1.58098839 1.32405606 1.63110727 1.27869766 1.28339453 1.37177964\n",
      " 1.5678441  1.33770187]\n",
      "New theta_0 : [1.37675038 1.17902455 1.62854992 1.12718664 1.40400266 1.14845956\n",
      " 1.63765328 1.18777134 1.72394186 1.09920199 1.10848981 1.2668929\n",
      " 1.61226694 1.20976934]\n",
      "Training Error:  105.72319786036884\n",
      "====================================================================================================\n",
      "Iteration:  2\n",
      "Previous theta :  [1.37675038 1.17902455 1.62854992 1.12718664 1.40400266 1.14845956\n",
      " 1.63765328 1.18777134 1.72394186 1.09920199 1.10848981 1.2668929\n",
      " 1.61226694 1.20976934]\n",
      "New theta_0 : [1.32013362 1.06394936 1.65249761 1.00072372 1.35821638 1.0306602\n",
      " 1.67570132 1.08197868 1.78746676 0.95241401 0.96613375 1.18020611\n",
      " 1.63871648 1.10834013]\n",
      "Training Error:  93.32559660611774\n",
      "====================================================================================================\n",
      "Iteration:  3\n",
      "Previous theta :  [1.32013362 1.06394936 1.65249761 1.00072372 1.35821638 1.0306602\n",
      " 1.67570132 1.08197868 1.78746676 0.95241401 0.96613375 1.18020611\n",
      " 1.63871648 1.10834013]\n",
      "New theta_0 : [1.26640901 0.97046681 1.65817168 0.90231957 1.31388928 0.93992798\n",
      " 1.69953236 0.99960841 1.82859308 0.83128716 0.84924274 1.1077479\n",
      " 1.65140248 1.02734648]\n",
      "Training Error:  84.41067170781398\n",
      "====================================================================================================\n",
      "Iteration:  4\n",
      "Previous theta :  [1.26640901 0.97046681 1.65817168 0.90231957 1.31388928 0.93992798\n",
      " 1.69953236 0.99960841 1.82859308 0.83128716 0.84924274 1.1077479\n",
      " 1.65140248 1.02734648]\n",
      "New theta_0 : [1.21531526 0.89387827 1.65019249 0.82555649 1.27100038 0.87002214\n",
      " 1.71253746 0.93521011 1.8526479  0.73036079 0.75233133 1.04644483\n",
      " 1.65357811 0.96210629]\n",
      "Training Error:  77.9372451095145\n",
      "====================================================================================================\n",
      "Iteration:  5\n",
      "Previous theta :  [1.21531526 0.89387827 1.65019249 0.82555649 1.27100038 0.87002214\n",
      " 1.71253746 0.93521011 1.8526479  0.73036079 0.75233133 1.04644483\n",
      " 1.65357811 0.96210629]\n",
      "New theta_0 : [1.1666348  0.83054368 1.63210924 0.76548093 1.22952371 0.81612762\n",
      " 1.7173289  0.88458331 1.86373554 0.64539992 0.67114899 0.99391718\n",
      " 1.64775742 0.90900734]\n",
      "Training Error:  73.13014530985947\n",
      "====================================================================================================\n",
      "Iteration:  6\n",
      "Previous theta :  [1.1666348  0.83054368 1.63210924 0.76548093 1.22952371 0.81612762\n",
      " 1.7173289  0.88458331 1.86373554 0.64539992 0.67114899 0.99391718\n",
      " 1.64775742 0.90900734]\n",
      "New theta_0 : [1.12018446 0.77764109 1.60664477 0.71826987 1.1894296  0.77453016\n",
      " 1.71591792 0.84449232 1.86501644 0.57311699 0.60239956 0.94832121\n",
      " 1.63588338 0.86526342]\n",
      "Training Error:  69.43868028212451\n",
      "====================================================================================================\n",
      "Iteration:  7\n",
      "Previous theta :  [1.12018446 0.77764109 1.60664477 0.71826987 1.1894296  0.77453016\n",
      " 1.71591792 0.84449232 1.86501644 0.57311699 0.60239956 0.94832121\n",
      " 1.63588338 0.86526342]\n",
      "New theta_0 : [1.07580819 0.73298092 1.5758846  0.68097321 1.15068583 0.74236533\n",
      " 1.70985185 0.81244602 1.85892264 0.5109569  0.54352456 0.90822738\n",
      " 1.61945758 0.82872607]\n",
      "Training Error:  66.48729851794859\n",
      "====================================================================================================\n",
      "Iteration:  8\n",
      "Previous theta :  [1.07580819 0.73298092 1.5758846  0.68097321 1.15068583 0.74236533\n",
      " 1.70985185 0.81244602 1.85892264 0.5109569  0.54352456 0.90822738\n",
      " 1.61945758 0.82872607]\n",
      "New theta_0 : [1.03337151 0.69486251 1.54142286 0.65131483 1.11325839 0.71742481\n",
      " 1.70032005 0.7865279  1.84732407 0.45693098 0.49253578 0.87252625\n",
      " 1.59964049 0.79773912]\n",
      "Training Error:  64.02783376000289\n",
      "====================================================================================================\n",
      "Iteration:  9\n",
      "Previous theta :  [1.03337151 0.69486251 1.54142286 0.65131483 1.11325839 0.71742481\n",
      " 1.70032005 0.7865279  1.84732407 0.45693098 0.49253578 0.87252625\n",
      " 1.59964049 0.79773912]\n",
      "New theta_0 : [0.99275712 0.66196328 1.50447497 0.62753891 1.07711216 0.69800673\n",
      " 1.68823573 0.76526469 1.83165697 0.40948875 0.44788601 0.84035584\n",
      " 1.57732889 0.77102642]\n",
      "Training Error:  61.89985604986529\n",
      "====================================================================================================\n",
      "Iteration:  10\n",
      "Previous theta :  [0.99275712 0.66196328 1.50447497 0.62753891 1.07711216 0.69800673\n",
      " 1.68823573 0.76526469 1.83165697 0.40948875 0.44788601 0.84035584\n",
      " 1.57732889 0.77102642]\n",
      "New theta_0 : [0.95386152 0.63325314 1.46596461 0.60829134 1.0422114  0.68280016\n",
      " 1.67429908 0.74752511 1.81302304 0.36741882 0.40836919 0.81104545\n",
      " 1.55321567 0.74760515]\n",
      "Training Error:  60.00104264753214\n",
      "====================================================================================================\n",
      "Iteration:  11\n",
      "Previous theta :  [0.95386152 0.63325314 1.46596461 0.60829134 1.0422114  0.68280016\n",
      " 1.67429908 0.74752511 1.81302304 0.36741882 0.40836919 0.81104545\n",
      " 1.55321567 0.74760515]\n",
      "New theta_0 : [0.91659239 0.60792833 1.42659082 0.5925281  1.0085201  0.6707959\n",
      " 1.65904599 0.73244154 1.792266   0.32977233 0.37304321 0.78407236\n",
      " 1.52783604 0.72671884]\n",
      "Training Error:  58.266536181854576\n",
      "====================================================================================================\n",
      "Iteration:  12\n",
      "Previous theta :  [0.91659239 0.60792833 1.42659082 0.5925281  1.0085201  0.6707959\n",
      " 1.65904599 0.73244154 1.792266   0.32977233 0.37304321 0.78407236\n",
      " 1.52783604 0.72671884]\n",
      "New theta_0 : [0.8808665  0.58536029 1.38687985 0.57944451 0.97600228 0.66121755\n",
      " 1.64288579 0.71934963 1.77003068 0.29580381 0.34117029 0.75902829\n",
      " 1.50160325 0.70778569]\n",
      "Training Error:  56.655210246022676\n",
      "====================================================================================================\n",
      "Iteration:  13\n",
      "Previous theta :  [0.8808665  0.58536029 1.38687985 0.57944451 0.97600228 0.66121755\n",
      " 1.64288579 0.71934963 1.77003068 0.29580381 0.34117029 0.75902829\n",
      " 1.50160325 0.70778569]\n",
      "New theta_0 : [0.84660816 0.56505624 1.34722508 0.56842064 0.94462222 0.65346839\n",
      " 1.62613019 0.70774172 1.74680864 0.26492545 0.31217099 0.73559356\n",
      " 1.47483618 0.69035864]\n",
      "Training Error:  55.140800075746824\n",
      "====================================================================================================\n",
      "Iteration:  14\n",
      "Previous theta :  [0.84660816 0.56505624 1.34722508 0.56842064 0.94462222 0.65346839\n",
      " 1.62613019 0.70774172 1.74680864 0.26492545 0.31217099 0.73559356\n",
      " 1.47483618 0.69035864]\n",
      "New theta_0 : [0.81374791 0.54662859 1.30791791 0.55897909 0.91434459 0.64709025\n",
      " 1.60901579 0.69723075 1.7229734  0.2366718  0.28558853 0.71351707\n",
      " 1.44778063 0.67409455]\n",
      "Training Error:  53.70628486846076\n",
      "====================================================================================================\n",
      "Iteration:  15\n",
      "Previous theta :  [0.81374791 0.54662859 1.30791791 0.55897909 0.91434459 0.64709025\n",
      " 1.60901579 0.69723075 1.7229734  0.2366718  0.28558853 0.71351707\n",
      " 1.44778063 0.67409455]\n",
      "New theta_0 : [0.78222158 0.52977141 1.26917151 0.5507525  0.88513465 0.64173185\n",
      " 1.59172138 0.68752258 1.69880759 0.2106724  0.26106134 0.69260087\n",
      " 1.42062585 0.65873045]\n",
      "Training Error:  52.340374167273495\n",
      "====================================================================================================\n",
      "Iteration:  16\n",
      "Previous theta :  [0.78222158 0.52977141 1.26917151 0.5507525  0.88513465 0.64173185\n",
      " 1.59172138 0.68752258 1.69880759 0.2106724  0.26106134 0.69260087\n",
      " 1.42062585 0.65873045]\n",
      "New theta_0 : [0.75196944 0.51424214 1.23113918 0.5434583  0.85695824 0.63712429\n",
      " 1.57438125 0.67839449 1.67452397 0.18663073 0.23830176 0.67268822\n",
      " 1.39351723 0.64406508]\n",
      "Training Error:  51.03532831268619\n",
      "====================================================================================================\n",
      "Iteration:  17\n",
      "Previous theta :  [0.75196944 0.51424214 1.23113918 0.5434583  0.85695824 0.63712429\n",
      " 1.57438125 0.67839449 1.67452397 0.18663073 0.23830176 0.67268822\n",
      " 1.39351723 0.64406508]\n",
      "New theta_0 : [0.72293568 0.4998475  1.1939285  0.53687942 0.82978194 0.63306218\n",
      " 1.55709556 0.66967867 1.65028154 0.16430781 0.21707961 0.65365434\n",
      " 1.3665662  0.6299448 ]\n",
      "Training Error:  49.78561381575289\n",
      "====================================================================================================\n",
      "Iteration:  18\n",
      "Previous theta :  [0.72293568 0.4998475  1.1939285  0.53687942 0.82978194 0.63306218\n",
      " 1.55709556 0.66967867 1.65028154 0.16430781 0.21707961 0.65365434\n",
      " 1.3665662  0.6299448 ]\n",
      "New theta_0 : [0.6950678  0.48643263 1.15761219 0.53084922 0.80357308 0.62938906\n",
      " 1.53993823 0.66124945 1.62619811 0.14350958 0.19720947 0.63539933\n",
      " 1.33985784 0.61625259]\n",
      "Training Error:  48.58707683817128\n",
      "====================================================================================================\n",
      "Iteration:  19\n",
      "Previous theta :  [0.6950678  0.48643263 1.15761219 0.53084922 0.80357308 0.62938906\n",
      " 1.53993823 0.66124945 1.62619811 0.14350958 0.19720947 0.63539933\n",
      " 1.33985784 0.61625259]\n",
      "New theta_0 : [0.66831632 0.47387257 1.12223654 0.52523996 0.77829976 0.6259861\n",
      " 1.52296315 0.65301346 1.60235984 0.12407713 0.17854084 0.6178426\n",
      " 1.31345674 0.60289962]\n",
      "Training Error:  47.43643633877544\n",
      "====================================================================================================\n",
      "Iteration:  20\n",
      "Previous theta :  [0.66831632 0.47387257 1.12223654 0.52523996 0.77829976 0.6259861\n",
      " 1.52296315 0.65301346 1.60235984 0.12407713 0.17854084 0.6178426\n",
      " 1.31345674 0.60289962]\n",
      "New theta_0 : [0.6426344  0.46206578 1.08782784 0.51995387 0.75393089 0.62276346\n",
      " 1.50620881 0.64490208 1.57882873 0.10587912 0.16095053 0.60091862\n",
      " 1.28741161 0.58981874]\n",
      "Training Error:  46.330973647312106\n",
      "====================================================================================================\n",
      "Iteration:  21\n",
      "Previous theta :  [0.6426344  0.46206578 1.08782784 0.51995387 0.75393089 0.62276346\n",
      " 1.50620881 0.64490208 1.57882873 0.10587912 0.16095053 0.60091862\n",
      " 1.28741161 0.58981874]\n",
      "New theta_0 : [0.61797757 0.45092907 1.05439737 0.51491625 0.7304362  0.61965358\n",
      " 1.48970202 0.63686554 1.55564832 0.08880588 0.14433675 0.58457364\n",
      " 1.2617588  0.57695943]\n",
      "Training Error:  45.26834236426727\n",
      "====================================================================================================\n",
      "Iteration:  22\n",
      "Previous theta :  [0.61797757 0.45092907 1.05439737 0.51491625 0.7304362  0.61965358\n",
      " 1.48970202 0.63686554 1.55564832 0.08880588 0.14433675 0.58457364\n",
      " 1.2617588  0.57695943]\n",
      "New theta_0 : [0.59430355 0.44039363 1.02194517 0.51007016 0.70778627 0.61660598\n",
      " 1.47346068 0.62886848 1.53284808 0.07276488 0.12861454 0.56876312\n",
      " 1.23652503 0.56428394]\n",
      "Training Error:  44.24645178161716\n",
      "====================================================================================================\n",
      "Iteration:  23\n",
      "Previous theta :  [0.59430355 0.44039363 1.02194517 0.51007016 0.70778627 0.61660598\n",
      " 1.47346068 0.62886848 1.53284808 0.07276488 0.12861454 0.56876312\n",
      " 1.23652503 0.56428394]\n",
      "New theta_0 : [0.57157208 0.43040207 0.99046303 0.50537233 0.68595246 0.61358331\n",
      " 1.45749596 0.62088643 1.51044681 0.05767719 0.11371225 0.55344973\n",
      " 1.21172951 0.55176429]\n",
      "Training Error:  43.26339512497418\n",
      "====================================================================================================\n",
      "Iteration:  24\n",
      "Previous theta :  [0.57157208 0.43040207 0.99046303 0.50537233 0.68595246 0.61358331\n",
      " 1.45749596 0.62088643 1.51044681 0.05767719 0.11371225 0.55344973\n",
      " 1.21172951 0.55176429]\n",
      "New theta_0 : [0.5497447  0.42090598 0.95993667 0.50078997 0.66490699 0.61055827\n",
      " 1.44181393 0.61290318 1.48845528 0.04347472 0.09956876 0.53860188\n",
      " 1.18738561 0.53937997]\n",
      "Training Error:  42.31740506395296\n",
      "====================================================================================================\n",
      "Iteration:  25\n",
      "Previous theta :  [0.5497447  0.42090598 0.95993667 0.50078997 0.66490699 0.61055827\n",
      " 1.44181393 0.61290318 1.48845528 0.04347472 0.09956876 0.53860188\n",
      " 1.18738561 0.53937997]\n",
      "New theta_0 : [0.52878469 0.41186413 0.93034751 0.49629836 0.64462288 0.6075112\n",
      " 1.42641688 0.60490871 1.46687817 0.0300981  0.08613135 0.52419244\n",
      " 1.16350211 0.52711615]\n",
      "Training Error:  41.40682577994813\n",
      "====================================================================================================\n",
      "Iteration:  26\n",
      "Previous theta :  [0.52878469 0.41186413 0.93034751 0.49629836 0.64462288 0.6075112\n",
      " 1.42641688 0.60490871 1.46687817 0.0300981  0.08613135 0.52419244\n",
      " 1.16350211 0.52711615]\n",
      "New theta_0 : [0.50865695 0.40324102 0.90167393 0.49187893 0.62507395 0.60442832\n",
      " 1.41130426 0.59689763 1.4457157  0.01749499 0.07335405 0.5101979\n",
      " 1.14008422 0.51496231]\n",
      "Training Error:  40.530095071025535\n",
      "====================================================================================================\n",
      "Iteration:  27\n",
      "Previous theta :  [0.50865695 0.40324102 0.90167393 0.49187893 0.62507395 0.60442832\n",
      " 1.41130426 0.59689763 1.4457157  0.01749499 0.07335405 0.5101979\n",
      " 1.14008422 0.51496231]\n",
      "New theta_0 : [0.48932786 0.39500581 0.87389229 0.48751786 0.60623481 0.60130026\n",
      " 1.39647344 0.58886799 1.42496473 0.00561878 0.06119632 0.49659761\n",
      " 1.11713436 0.50291124]\n",
      "Training Error:  39.685732534654704\n",
      "====================================================================================================\n",
      "Iteration:  28\n",
      "Previous theta :  [0.48932786 0.39500581 0.87389229 0.48751786 0.60623481 0.60130026\n",
      " 1.39647344 0.58886799 1.42496473 0.00561878 0.06119632 0.49659761\n",
      " 1.11713436 0.50291124]\n",
      "New theta_0 : [ 0.47076524  0.38713137  0.84697769  0.48320492  0.58808086  0.59812102\n",
      "  1.38192032  0.58082032  1.40461972 -0.00557242  0.04962207  0.48337322\n",
      "  1.09465272  0.49095814]\n",
      "Training Error:  38.87233143090903\n",
      "====================================================================================================\n",
      "Iteration:  29\n",
      "Previous theta :  [ 0.47076524  0.38713137  0.84697769  0.48320492  0.58808086  0.59812102\n",
      "  1.38192032  0.58082032  1.40461972 -0.00557242  0.04962207  0.48337322\n",
      "  1.09465272  0.49095814]\n",
      "New theta_0 : [ 0.45293827  0.37959367  0.82090453  0.47893264  0.57058825  0.59488715\n",
      "  1.36763973  0.57275696  1.38467339 -0.01611657  0.03859883  0.47050826\n",
      "  1.07263779  0.47910007]\n",
      "Training Error:  38.08855277917832\n",
      "====================================================================================================\n",
      "Iteration:  30\n",
      "Previous theta :  [ 0.45293827  0.37959367  0.82090453  0.47893264  0.57058825  0.59488715\n",
      "  1.36763973  0.57275696  1.38467339 -0.01611657  0.03859883  0.47050826\n",
      "  1.07263779  0.47910007]\n",
      "New theta_0 : [ 0.43581738  0.37237122  0.79564691  0.47469561  0.55373387  0.59159705\n",
      "  1.35362575  0.56468149  1.36511726 -0.02604839  0.02809715  0.45798781\n",
      "  1.05108668  0.46733545]\n",
      "Training Error:  37.33312081829838\n",
      "====================================================================================================\n",
      "Iteration:  31\n",
      "Previous theta :  [ 0.43581738  0.37237122  0.79564691  0.47469561  0.55373387  0.59159705\n",
      "  1.35362575  0.56468149  1.36511726 -0.02604839  0.02809715  0.45798781\n",
      "  1.05108668  0.46733545]\n",
      "New theta_0 : [ 0.41937425  0.36544462  0.77117899  0.47049004  0.53749537  0.58825055\n",
      "  1.33987203  0.55659836  1.34594205 -0.03539978  0.01809012  0.44579818\n",
      "  1.02999545  0.45566369]\n",
      "Training Error:  36.60481930908179\n",
      "====================================================================================================\n",
      "Iteration:  32\n",
      "Previous theta :  [ 0.41937425  0.36544462  0.77117899  0.47049004  0.53749537  0.58825055\n",
      "  1.33987203  0.55659836  1.34594205 -0.03539978  0.01809012  0.44579818\n",
      "  1.02999545  0.45566369]\n",
      "New theta_0 : [ 0.40358169  0.35879625  0.74747521  0.46631329  0.52185108  0.5848485\n",
      "  1.3263719   0.54851257  1.32713796 -0.0442003   0.00855294  0.43392678\n",
      "  1.00935929  0.4440849 ]\n",
      "Training Error:  35.90248836871839\n",
      "====================================================================================================\n",
      "Iteration:  33\n",
      "Previous theta :  [ 0.40358169  0.35879625  0.74747521  0.46631329  0.52185108  0.5848485\n",
      "  1.3263719   0.54851257  1.32713796 -0.0442003   0.00855294  0.43392678\n",
      "  1.00935929  0.4440849 ]\n",
      "New theta_0 : [ 3.88413644e-01  3.52410028e-01  7.24510431e-01  4.62163642e-01\n",
      "  5.06780048e-01  5.81392468e-01  1.31311858e+00  5.40429401e-01\n",
      "  1.30869495e+00 -5.24774082e-02 -5.37331406e-04  4.22361896e-01\n",
      "  9.89172775e-01  4.32599712e-01]\n",
      "Training Error:  35.22502165287605\n",
      "====================================================================================================\n",
      "Iteration:  34\n",
      "Previous theta :  [ 3.88413644e-01  3.52410028e-01  7.24510431e-01  4.62163642e-01\n",
      "  5.06780048e-01  5.81392468e-01  1.31311858e+00  5.40429401e-01\n",
      "  1.30869495e+00 -5.24774082e-02 -5.37331406e-04  4.22361896e-01\n",
      "  9.89172775e-01  4.32599712e-01]\n",
      "New theta_0 : [ 0.3738451   0.34627114  0.70226008  0.45804001  0.49226198  0.57788457\n",
      "  1.30010525  0.53235431  1.29060286 -0.06025679 -0.00920208  0.41109257\n",
      "  0.96942992  0.42120909]\n",
      "Training Error:  34.57136377678499\n",
      "====================================================================================================\n",
      "Iteration:  35\n",
      "Previous theta :  [ 0.3738451   0.34627114  0.70226008  0.45804001  0.49226198  0.57788457\n",
      "  1.30010525  0.53235431  1.29060286 -0.06025679 -0.00920208  0.41109257\n",
      "  0.96942992  0.42120909]\n",
      "New theta_0 : [ 0.35985205  0.3403659   0.68070024  0.4539418   0.47827727  0.57432727\n",
      "  1.28732513  0.52429275  1.27285155 -0.06756252 -0.0174613   0.4001085\n",
      "  0.95012437  0.40991422]\n",
      "Training Error:  33.9405079113446\n",
      "====================================================================================================\n",
      "Iteration:  36\n",
      "Previous theta :  [ 0.35985205  0.3403659   0.68070024  0.4539418   0.47827727  0.57432727\n",
      "  1.28732513  0.52429275  1.27285155 -0.06756252 -0.0174613   0.4001085\n",
      "  0.95012437  0.40991422]\n",
      "New theta_0 : [ 0.34641148  0.33468162  0.65980766  0.44986877  0.46480693  0.57072324\n",
      "  1.27477156  0.51625011  1.25543101 -0.07441725 -0.02533375  0.38939999\n",
      "  0.93124943  0.3987164 ]\n",
      "Training Error:  33.33149351661919\n",
      "====================================================================================================\n",
      "Iteration:  37\n",
      "Previous theta :  [ 0.34641148  0.33468162  0.65980766  0.44986877  0.46480693  0.57072324\n",
      "  1.27477156  0.51625011  1.25543101 -0.07441725 -0.02533375  0.38939999\n",
      "  0.93124943  0.3987164 ]\n",
      "New theta_0 : [ 0.33350129  0.32920649  0.63955985  0.44582094  0.45183261  0.56707531\n",
      "  1.26243801  0.5082316   1.2383314  -0.08084235 -0.03283711  0.37895782\n",
      "  0.91279817  0.38761699]\n",
      "Training Error:  32.74340419041588\n",
      "====================================================================================================\n",
      "Iteration:  38\n",
      "Previous theta :  [ 0.33350129  0.32920649  0.63955985  0.44582094  0.45183261  0.56707531\n",
      "  1.26243801  0.5082316   1.2383314  -0.08084235 -0.03283711  0.37895782\n",
      "  0.91279817  0.38761699]\n",
      "New theta_0 : [ 0.32110026  0.32392947  0.61993505  0.44179848  0.43933657  0.56338637\n",
      "  1.25031814  0.50024228  1.22154312 -0.08685803 -0.03998808  0.36877323\n",
      "  0.8947635   0.37661736]\n",
      "Training Error:  32.175365618444104\n",
      "====================================================================================================\n",
      "Iteration:  39\n",
      "Previous theta :  [ 0.32110026  0.32392947  0.61993505  0.44179848  0.43933657  0.56338637\n",
      "  1.25031814  0.50024228  1.22154312 -0.08685803 -0.03998808  0.36877323\n",
      "  0.8947635   0.37661736]\n",
      "New theta_0 : [ 0.30918804  0.31884021  0.60091224  0.43780168  0.42730166  0.5596593\n",
      "  1.23840579  0.49228694  1.20505683 -0.09248342 -0.04680246  0.35883789\n",
      "  0.87713818  0.36571885]\n",
      "Training Error:  31.626543617532516\n",
      "====================================================================================================\n",
      "Iteration:  40\n",
      "Previous theta :  [ 0.30918804  0.31884021  0.60091224  0.43780168  0.42730166  0.5596593\n",
      "  1.23840579  0.49228694  1.20505683 -0.09248342 -0.04680246  0.35883789\n",
      "  0.87713818  0.36571885]\n",
      "New theta_0 : [ 0.29774509  0.31392902  0.58247115  0.43383093  0.41571132  0.55589698\n",
      "  1.22669501  0.48437017  1.18886347 -0.09773668 -0.05329523  0.34914382\n",
      "  0.85991489  0.35492273]\n",
      "Training Error:  31.09614226613316\n",
      "====================================================================================================\n",
      "Iteration:  41\n",
      "Previous theta :  [ 0.29774509  0.31392902  0.58247115  0.43383093  0.41571132  0.55589698\n",
      "  1.22669501  0.48437017  1.18886347 -0.09773668 -0.05329523  0.34914382\n",
      "  0.85991489  0.35492273]\n",
      "New theta_0 : [ 0.28675265  0.30918678  0.56459225  0.42988661  0.40454952  0.55210221\n",
      "  1.21518006  0.47649627  1.17295427 -0.10263504 -0.05948063  0.33968339\n",
      "  0.84308622  0.3442302 ]\n",
      "Training Error:  30.583402117826765\n",
      "====================================================================================================\n",
      "Iteration:  42\n",
      "Previous theta :  [ 0.28675265  0.30918678  0.56459225  0.42988661  0.40454952  0.55210221\n",
      "  1.21518006  0.47649627  1.17295427 -0.10263504 -0.05948063  0.33968339\n",
      "  0.84308622  0.3442302 ]\n",
      "New theta_0 : [ 0.27619272  0.30460489  0.54725671  0.42596915  0.39380079  0.54827774\n",
      "  1.2038554   0.46866929  1.15732077 -0.10719489 -0.06537218  0.3304493\n",
      "  0.82664475  0.33364236]\n",
      "Training Error:  30.08759849431776\n",
      "====================================================================================================\n",
      "Iteration:  43\n",
      "Previous theta :  [ 0.27619272  0.30460489  0.54725671  0.42596915  0.39380079  0.54827774\n",
      "  1.2038554   0.46866929  1.15732077 -0.10719489 -0.06537218  0.3304493\n",
      "  0.82664475  0.33364236]\n",
      "New theta_0 : [ 0.26604802  0.30017528  0.53044643  0.42207896  0.38345018  0.5444262\n",
      "  1.19271572  0.46089302  1.14195481 -0.11143184 -0.07098277  0.32143452\n",
      "  0.81058305  0.32316022]\n",
      "Training Error:  29.608039854798037\n",
      "====================================================================================================\n",
      "Iteration:  44\n",
      "Previous theta :  [ 0.26604802  0.30017528  0.53044643  0.42207896  0.38345018  0.5444262\n",
      "  1.19271572  0.46089302  1.14195481 -0.11143184 -0.07098277  0.32143452\n",
      "  0.81058305  0.32316022]\n",
      "New theta_0 : [ 0.25630196  0.29589028  0.51414395  0.41821645  0.37348328  0.54055016\n",
      "  1.18175591  0.45317099  1.12684852 -0.11536074 -0.07632468  0.31263232\n",
      "  0.79489368  0.3127847 ]\n",
      "Training Error:  29.14406623875006\n",
      "====================================================================================================\n",
      "Iteration:  45\n",
      "Previous theta :  [ 0.25630196  0.29589028  0.51414395  0.41821645  0.37348328  0.54055016\n",
      "  1.18175591  0.45317099  1.12684852 -0.11536074 -0.07632468  0.31263232\n",
      "  0.79489368  0.3127847 ]\n",
      "New theta_0 : [ 0.24693863  0.2917427   0.49833248  0.414382    0.36388612  0.53665204\n",
      "  1.17097106  0.44550649  1.11199432 -0.11899576 -0.08140962  0.30403621\n",
      "  0.77956924  0.30251657]\n",
      "Training Error:  28.695047779356827\n",
      "====================================================================================================\n",
      "Iteration:  46\n",
      "Previous theta :  [ 0.24693863  0.2917427   0.49833248  0.414382    0.36388612  0.53665204\n",
      "  1.17097106  0.44550649  1.11199432 -0.11899576 -0.08140962  0.30403621\n",
      "  0.77956924  0.30251657]\n",
      "New theta_0 : [ 0.23794272  0.28772571  0.48299589  0.41057595  0.35464526  0.53273421\n",
      "  1.16035647  0.43790254  1.09738493 -0.12235038 -0.08624876  0.29563996\n",
      "  0.76460235  0.29235655]\n",
      "Training Error:  28.26038328474345\n",
      "====================================================================================================\n",
      "Iteration:  47\n",
      "Previous theta :  [ 0.23794272  0.28772571  0.48299589  0.41057595  0.35464526  0.53273421\n",
      "  1.16035647  0.43790254  1.09738493 -0.12235038 -0.08624876  0.29563996\n",
      "  0.76460235  0.29235655]\n",
      "New theta_0 : [ 0.22929959  0.28383287  0.4681186   0.40679861  0.3457477   0.52879887\n",
      "  1.1499076   0.43036195  1.08301334 -0.12543748 -0.09085276  0.28743754\n",
      "  0.74998568  0.28230522]\n",
      "Training Error:  27.839498884322627\n",
      "====================================================================================================\n",
      "Iteration:  48\n",
      "Previous theta :  [ 0.22929959  0.28383287  0.4681186   0.40679861  0.3457477   0.52879887\n",
      "  1.1499076   0.43036195  1.08301334 -0.12543748 -0.09085276  0.28743754\n",
      "  0.74998568  0.28230522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.22099513  0.28005806  0.45368568  0.40305028  0.3371809   0.52484818\n",
      "  1.13962014  0.42288728  1.06887281 -0.12826935 -0.09523181  0.27942319\n",
      "  0.73571198  0.27236305]\n",
      "Training Error:  27.431846737565948\n",
      "====================================================================================================\n",
      "Iteration:  49\n",
      "Previous theta :  [ 0.22099513  0.28005806  0.45368568  0.40305028  0.3371809   0.52484818\n",
      "  1.13962014  0.42288728  1.06887281 -0.12826935 -0.09523181  0.27942319\n",
      "  0.73571198  0.27236305]\n",
      "New theta_0 : [ 0.21301584  0.27639552  0.43968271  0.39933119  0.32893276  0.52088415\n",
      "  1.12948991  0.41548088  1.05495687 -0.13085772 -0.09939564  0.27159132\n",
      "  0.72177402  0.26253046]\n",
      "Training Error:  27.03690380258113\n",
      "====================================================================================================\n",
      "Iteration:  50\n",
      "Previous theta :  [ 0.21301584  0.27639552  0.43968271  0.39933119  0.32893276  0.52088415\n",
      "  1.12948991  0.41548088  1.05495687 -0.13085772 -0.09939564  0.27159132\n",
      "  0.72177402  0.26253046]\n",
      "New theta_0 : [ 0.20534874  0.27283977  0.42609584  0.39564156  0.32099159  0.5169087\n",
      "  1.11951294  0.40814492  1.04125927 -0.13321377 -0.10335355  0.26393654\n",
      "  0.70816468  0.25280771]\n",
      "Training Error:  26.654170661941937\n",
      "====================================================================================================\n",
      "Iteration:  51\n",
      "Previous theta :  [ 0.20534874  0.27283977  0.42609584  0.39564156  0.32099159  0.5169087\n",
      "  1.11951294  0.40814492  1.04125927 -0.13321377 -0.10335355  0.26393654\n",
      "  0.70816468  0.25280771]\n",
      "New theta_0 : [ 0.19798137  0.26938563  0.41291173  0.39198157  0.31334612  0.51292366\n",
      "  1.1096854   0.40088133  1.02777404 -0.1353482  -0.10711444  0.25645367\n",
      "  0.6948769   0.24319502]\n",
      "Training Error:  26.283170403292264\n",
      "====================================================================================================\n",
      "Iteration:  52\n",
      "Previous theta :  [ 0.19798137  0.26938563  0.41291173  0.39198157  0.31334612  0.51292366\n",
      "  1.1096854   0.40088133  1.02777404 -0.1353482  -0.10711444  0.25645367\n",
      "  0.6948769   0.24319502]\n",
      "New theta_0 : [ 0.19090178  0.2660282   0.40011754  0.38835134  0.30598547  0.50893076\n",
      "  1.10000362  0.39369189  1.01449541 -0.13727122 -0.11068682  0.24913771\n",
      "  0.68190372  0.2336925 ]\n",
      "Training Error:  25.923447552325896\n",
      "====================================================================================================\n",
      "Iteration:  53\n",
      "Previous theta :  [ 0.19090178  0.2660282   0.40011754  0.38835134  0.30598547  0.50893076\n",
      "  1.10000362  0.39369189  1.01449541 -0.13727122 -0.11068682  0.24913771\n",
      "  0.68190372  0.2336925 ]\n",
      "New theta_0 : [ 0.18409848  0.26276282  0.3877009   0.38475099  0.29889915  0.50493164\n",
      "  1.09046407  0.38657819  1.00141785 -0.13899258 -0.11407881  0.24198381\n",
      "  0.66923825  0.22430018]\n",
      "Training Error:  25.57456705582807\n",
      "====================================================================================================\n",
      "Iteration:  54\n",
      "Previous theta :  [ 0.18409848  0.26276282  0.3877009   0.38475099  0.29889915  0.50493164\n",
      "  1.09046407  0.38657819  1.00141785 -0.13899258 -0.11407881  0.24198381\n",
      "  0.66923825  0.22430018]\n",
      "New theta_0 : [ 0.17756048  0.25958509  0.3756499   0.38118061  0.29207705  0.50092786\n",
      "  1.08106338  0.37954164  0.98853602 -0.1405216  -0.11729821  0.2349873\n",
      "  0.65687371  0.21501801]\n",
      "Training Error:  25.236113312550966\n",
      "====================================================================================================\n",
      "Iteration:  55\n",
      "Previous theta :  [ 0.17756048  0.25958509  0.3756499   0.38118061  0.29207705  0.50092786\n",
      "  1.08106338  0.37954164  0.98853602 -0.1405216  -0.11729821  0.2349873\n",
      "  0.65687371  0.21501801]\n",
      "New theta_0 : [ 0.17127718  0.25649083  0.36395307  0.37764023  0.28550939  0.49692088\n",
      "  1.0717983   0.37258351  0.9758448  -0.1418672  -0.12035245  0.2281437\n",
      "  0.64480339  0.20584588]\n",
      "Training Error:  24.907689249782244\n",
      "====================================================================================================\n",
      "Iteration:  56\n",
      "Previous theta :  [ 0.17127718  0.25649083  0.36395307  0.37764023  0.28550939  0.49692088\n",
      "  1.0717983   0.37258351  0.9758448  -0.1418672  -0.12035245  0.2281437\n",
      "  0.64480339  0.20584588]\n",
      "New theta_0 : [ 0.16523845  0.25347607  0.35259936  0.37412988  0.27918677  0.49291209\n",
      "  1.06266571  0.36570492  0.96333926 -0.14303787 -0.12324867  0.22144863\n",
      "  0.6330207   0.19678358]\n",
      "Training Error:  24.588915443551986\n",
      "====================================================================================================\n",
      "Iteration:  57\n",
      "Previous theta :  [ 0.16523845  0.25347607  0.35259936  0.37412988  0.27918677  0.49291209\n",
      "  1.06266571  0.36570492  0.96333926 -0.14303787 -0.12324867  0.22144863\n",
      "  0.6330207   0.19678358]\n",
      "New theta_0 : [ 0.15943453  0.25053706  0.3415781   0.37064956  0.2731001   0.4889028\n",
      "  1.05366262  0.35890684  0.95101466 -0.14404176 -0.12599369  0.21489789\n",
      "  0.62151915  0.18783085]\n",
      "Training Error:  24.27942928050814\n",
      "====================================================================================================\n",
      "Iteration:  58\n",
      "Previous theta :  [ 0.15943453  0.25053706  0.3415781   0.37064956  0.2731001   0.4889028\n",
      "  1.05366262  0.35890684  0.95101466 -0.14404176 -0.12599369  0.21489789\n",
      "  0.62151915  0.18783085]\n",
      "New theta_0 : [ 0.15385608  0.24767025  0.33087905  0.36719923  0.26724064  0.48489426\n",
      "  1.04478615  0.35219012  0.93886642 -0.14488664 -0.12859404  0.20848742\n",
      "  0.61029235  0.17898738]\n",
      "Training Error:  23.978884159573198\n",
      "====================================================================================================\n",
      "Iteration:  59\n",
      "Previous theta :  [ 0.15385608  0.24767025  0.33087905  0.36719923  0.26724064  0.48489426\n",
      "  1.04478615  0.35219012  0.93886642 -0.14488664 -0.12859404  0.20848742\n",
      "  0.61029235  0.17898738]\n",
      "New theta_0 : [ 0.14849413  0.24487224  0.3204923   0.36377885  0.26159994  0.48088764\n",
      "  1.03603352  0.34555548  0.92689015 -0.14557995 -0.13105596  0.20221329\n",
      "  0.59933401  0.17025279]\n",
      "Training Error:  23.68694873157499\n",
      "====================================================================================================\n",
      "Iteration:  60\n",
      "Previous theta :  [ 0.14849413  0.24487224  0.3204923   0.36377885  0.26159994  0.48088764\n",
      "  1.03603352  0.34555548  0.92689015 -0.14557995 -0.13105596  0.20221329\n",
      "  0.59933401  0.17025279]\n",
      "New theta_0 : [ 0.14334005  0.24213984  0.31040831  0.36038834  0.25616986  0.47688404\n",
      "  1.02740208  0.33900353  0.9150816  -0.14612879 -0.13338546  0.1960717\n",
      "  0.58863795  0.16162663]\n",
      "Training Error:  23.40330617512166\n",
      "====================================================================================================\n",
      "Iteration:  61\n",
      "Previous theta :  [ 0.14334005  0.24213984  0.31040831  0.36038834  0.25616986  0.47688404\n",
      "  1.02740208  0.33900353  0.9150816  -0.14612879 -0.13338546  0.1960717\n",
      "  0.58863795  0.16162663]\n",
      "New theta_0 : [ 0.13838557  0.23947     0.30061788  0.35702763  0.25094257  0.47288451\n",
      "  1.01888925  0.33253474  0.90343671 -0.14653997 -0.13558825  0.19005898\n",
      "  0.57819809  0.15310843]\n",
      "Training Error:  23.127653507065375\n",
      "====================================================================================================\n",
      "Iteration:  62\n",
      "Previous theta :  [ 0.13838557  0.23947     0.30061788  0.35702763  0.25094257  0.47288451\n",
      "  1.01888925  0.33253474  0.90343671 -0.14653997 -0.13558825  0.19005898\n",
      "  0.57819809  0.15310843]\n",
      "New theta_0 : [ 0.13362276  0.23685986  0.29111212  0.35369659  0.24591049  0.46889003\n",
      "  1.01049258  0.32614953  0.89195152 -0.14681997 -0.13766983  0.18417158\n",
      "  0.56800847  0.14469765]\n",
      "Training Error:  22.859700925970706\n",
      "====================================================================================================\n",
      "Iteration:  63\n",
      "Previous theta :  [ 0.13362276  0.23685986  0.29111212  0.35369659  0.24591049  0.46889003\n",
      "  1.01049258  0.32614953  0.89195152 -0.14681997 -0.13766983  0.18417158\n",
      "  0.56800847  0.14469765]\n",
      "New theta_0 : [ 0.12904401  0.23430666  0.28188247  0.35039512  0.24106636  0.46490153\n",
      "  1.00220968  0.31984817  0.88062225 -0.14697503 -0.13963545  0.17840606\n",
      "  0.55806323  0.13639371]\n",
      "Training Error:  22.599171187071917\n",
      "====================================================================================================\n",
      "Iteration:  64\n",
      "Previous theta :  [ 0.12904401  0.23430666  0.28188247  0.35039512  0.24106636  0.46490153\n",
      "  1.00220968  0.31984817  0.88062225 -0.14697503 -0.13963545  0.17840606\n",
      "  0.55806323  0.13639371]\n",
      "New theta_0 : [ 0.12464198  0.23180783  0.27292066  0.34712306  0.23640313  0.46091988\n",
      "  0.99403826  0.31363088  0.86944525 -0.14701107 -0.14149016  0.17275912\n",
      "  0.54835661  0.12819599]\n",
      "Training Error:  22.345799007269093\n",
      "====================================================================================================\n",
      "Iteration:  65\n",
      "Previous theta :  [ 0.12464198  0.23180783  0.27292066  0.34712306  0.23640313  0.46091988\n",
      "  0.99403826  0.31363088  0.86944525 -0.14701107 -0.14149016  0.17275912\n",
      "  0.54835661  0.12819599]\n",
      "New theta_0 : [ 0.12040968  0.22936089  0.2642187   0.34388028  0.23191405  0.45694591\n",
      "  0.98597612  0.30749778  0.85841698 -0.14693379 -0.14323878  0.16722752\n",
      "  0.53888298  0.12010382]\n",
      "Training Error:  22.099330498775682\n",
      "====================================================================================================\n",
      "Iteration:  66\n",
      "Previous theta :  [ 0.12040968  0.22936089  0.2642187   0.34388028  0.23191405  0.45694591\n",
      "  0.98597612  0.30749778  0.85841698 -0.14693379 -0.14323878  0.16722752\n",
      "  0.53888298  0.12010382]\n",
      "New theta_0 : [ 0.11634035  0.22696352  0.25576891  0.3406666   0.22759259  0.45298039\n",
      "  0.97802111  0.30144889  0.84753404 -0.14674863 -0.14488593  0.16180817\n",
      "  0.52963681  0.11211652]\n",
      "Training Error:  21.859522630090144\n",
      "====================================================================================================\n",
      "Iteration:  67\n",
      "Previous theta :  [ 0.11634035  0.22696352  0.25576891  0.3406666   0.22759259  0.45298039\n",
      "  0.97802111  0.30144889  0.84753404 -0.14674863 -0.14488593  0.16180817\n",
      "  0.52963681  0.11211652]\n",
      "New theta_0 : [ 0.11242753  0.22461349  0.24756382  0.33748187  0.22343247  0.44902406\n",
      "  0.97017118  0.2954842   0.83679314 -0.14646078 -0.14643603  0.15649805\n",
      "  0.52061267  0.10423335]\n",
      "Training Error:  21.626142713021757\n",
      "====================================================================================================\n",
      "Iteration:  68\n",
      "Previous theta :  [ 0.11242753  0.22461349  0.24756382  0.33748187  0.22343247  0.44902406\n",
      "  0.97017118  0.2954842   0.83679314 -0.14646078 -0.14643603  0.15649805\n",
      "  0.52061267  0.10423335]\n",
      "New theta_0 : [ 0.10866501  0.22230872  0.23959626  0.33432589  0.21942764  0.44507759\n",
      "  0.96242434  0.28960359  0.82619112 -0.14607522 -0.14789335  0.15129426\n",
      "  0.51180523  0.09645355]\n",
      "Training Error:  21.398967914555858\n",
      "====================================================================================================\n",
      "Iteration:  69\n",
      "Previous theta :  [ 0.10866501  0.22230872  0.23959626  0.33432589  0.21942764  0.44507759\n",
      "  0.96242434  0.28960359  0.82619112 -0.14607522 -0.14789335  0.15129426\n",
      "  0.51180523  0.09645355]\n",
      "New theta_0 : [ 0.10504683  0.22004719  0.23185928  0.33119847  0.21557226  0.44114164\n",
      "  0.95477867  0.2838069   0.8157249  -0.14559672 -0.14926192  0.14619397\n",
      "  0.5032093   0.08877634]\n",
      "Training Error:  21.17778479239629\n",
      "====================================================================================================\n",
      "Iteration:  70\n",
      "Previous theta :  [ 0.10504683  0.22004719  0.23185928  0.33119847  0.21557226  0.44114164\n",
      "  0.95477867  0.2838069   0.8157249  -0.14559672 -0.14926192  0.14619397\n",
      "  0.5032093   0.08877634]\n",
      "New theta_0 : [ 0.10156728  0.21782703  0.22434616  0.32809942  0.21186072  0.43721681\n",
      "  0.94723231  0.2780939   0.80539154 -0.14502982 -0.15054567  0.14119446\n",
      "  0.49481976  0.0812009 ]\n",
      "Training Error:  20.962388853073534\n",
      "====================================================================================================\n",
      "Iteration:  71\n",
      "Previous theta :  [ 0.10156728  0.21782703  0.22434616  0.32809942  0.21186072  0.43721681\n",
      "  0.94723231  0.2780939   0.80539154 -0.14502982 -0.15054567  0.14119446\n",
      "  0.49481976  0.0812009 ]\n",
      "New theta_0 : [ 0.09822086  0.21564642  0.21705043  0.32502853  0.2082876   0.43330367\n",
      "  0.93978348  0.2724643   0.79518816 -0.14437888 -0.15174832  0.13629309\n",
      "  0.48663162  0.0737264 ]\n",
      "Training Error:  20.752584131555196\n",
      "====================================================================================================\n",
      "Iteration:  72\n",
      "Previous theta :  [ 0.09822086  0.21564642  0.21705043  0.32502853  0.2082876   0.43330367\n",
      "  0.93978348  0.2724643   0.79518816 -0.14437888 -0.15174832  0.13629309\n",
      "  0.48663162  0.0737264 ]\n",
      "New theta_0 : [ 0.0950023   0.21350368  0.2099658   0.32198559  0.2048477   0.42940275\n",
      "  0.93243042  0.26691777  0.78511201 -0.14364808 -0.15287344  0.13148729\n",
      "  0.47863998  0.06635196]\n",
      "Training Error:  20.5481827913422\n",
      "====================================================================================================\n",
      "Iteration:  73\n",
      "Previous theta :  [ 0.0950023   0.21350368  0.2099658   0.32198559  0.2048477   0.42940275\n",
      "  0.93243042  0.26691777  0.78511201 -0.14364808 -0.15287344  0.13148729\n",
      "  0.47863998  0.06635196]\n",
      "New theta_0 : [ 0.09190655  0.21139718  0.20308622  0.31897038  0.20153598  0.42551455\n",
      "  0.92517145  0.26145391  0.7751604  -0.14284139 -0.15392448  0.12677459\n",
      "  0.47084007  0.05907672]\n",
      "Training Error:  20.349004744078293\n",
      "====================================================================================================\n",
      "Iteration:  74\n",
      "Previous theta :  [ 0.09190655  0.21139718  0.20308622  0.31897038  0.20153598  0.42551455\n",
      "  0.92517145  0.26145391  0.7751604  -0.14284139 -0.15392448  0.12677459\n",
      "  0.47084007  0.05907672]\n",
      "New theta_0 : [ 0.08892875  0.20932538  0.19640583  0.31598268  0.19834762  0.42163954\n",
      "  0.91800495  0.25607231  0.76533077 -0.14196264 -0.15490472  0.1221526\n",
      "  0.46322717  0.05189978]\n",
      "Training Error:  20.154877287743396\n",
      "====================================================================================================\n",
      "Iteration:  75\n",
      "Previous theta :  [ 0.08892875  0.20932538  0.19640583  0.31598268  0.19834762  0.42163954\n",
      "  0.91800495  0.25607231  0.76533077 -0.14196264 -0.15490472  0.1221526\n",
      "  0.46322717  0.05189978]\n",
      "New theta_0 : [ 0.08606423  0.20728683  0.18991894  0.31302227  0.19527796  0.41777817\n",
      "  0.91092934  0.25077248  0.7556206  -0.14101548 -0.15581731  0.11761898\n",
      "  0.45579672  0.04482022]\n",
      "Training Error:  19.965634762542223\n",
      "====================================================================================================\n",
      "Iteration:  76\n",
      "Previous theta :  [ 0.08606423  0.20728683  0.18991894  0.31302227  0.19527796  0.41777817\n",
      "  0.91092934  0.25077248  0.7556206  -0.14101548 -0.15581731  0.11761898\n",
      "  0.45579672  0.04482022]\n",
      "New theta_0 : [ 0.08330853  0.20528015  0.18362007  0.31008891  0.19232251  0.41393083\n",
      "  0.90394307  0.24555392  0.74602747 -0.14000339 -0.15666528  0.11317148\n",
      "  0.44854423  0.03783711]\n",
      "Training Error:  19.781118223639034\n",
      "====================================================================================================\n",
      "Iteration:  77\n",
      "Previous theta :  [ 0.08330853  0.20528015  0.18362007  0.31008891  0.19232251  0.41393083\n",
      "  0.90394307  0.24555392  0.74602747 -0.14000339 -0.15666528  0.11317148\n",
      "  0.44854423  0.03783711]\n",
      "New theta_0 : [ 0.08065736  0.20330402  0.17750391  0.30718237  0.18947696  0.41009791\n",
      "  0.89704467  0.24041607  0.73654904 -0.13892974 -0.15745152  0.10880792\n",
      "  0.44146531  0.03094951]\n",
      "Training Error:  19.601175129927128\n",
      "====================================================================================================\n",
      "Iteration:  78\n",
      "Previous theta :  [ 0.08065736  0.20330402  0.17750391  0.30718237  0.18947696  0.41009791\n",
      "  0.89704467  0.24041607  0.73654904 -0.13892974 -0.15745152  0.10880792\n",
      "  0.44146531  0.03094951]\n",
      "New theta_0 : [ 0.07810658  0.20135719  0.17156531  0.30430242  0.18673715  0.40627977\n",
      "  0.89023268  0.23535835  0.72718304 -0.13779771 -0.15817881  0.10452619\n",
      "  0.43455567  0.02415647]\n",
      "Training Error:  19.425659048057987\n",
      "====================================================================================================\n",
      "Iteration:  79\n",
      "Previous theta :  [ 0.07810658  0.20135719  0.17156531  0.30430242  0.18673715  0.40627977\n",
      "  0.89023268  0.23535835  0.72718304 -0.13779771 -0.15817881  0.10452619\n",
      "  0.43455567  0.02415647]\n",
      "New theta_0 : [ 0.07565224  0.19943848  0.16579931  0.30144882  0.18409907  0.40247675\n",
      "  0.88350571  0.23038017  0.71792727 -0.13661036 -0.15884981  0.10032423\n",
      "  0.42781112  0.01745703]\n",
      "Training Error:  19.25442937098987\n",
      "====================================================================================================\n",
      "Iteration:  80\n",
      "Previous theta :  [ 0.07565224  0.19943848  0.16579931  0.30144882  0.18409907  0.40247675\n",
      "  0.88350571  0.23038017  0.71792727 -0.13661036 -0.15884981  0.10032423\n",
      "  0.42781112  0.01745703]\n",
      "New theta_0 : [ 0.07329055  0.19754678  0.16020107  0.29862134  0.18155888  0.39868914\n",
      "  0.87686238  0.22548086  0.70877959 -0.13537063 -0.15946709  0.09620006\n",
      "  0.42122756  0.01085021]\n",
      "Training Error:  19.087351050349064\n",
      "====================================================================================================\n",
      "Iteration:  81\n",
      "Previous theta :  [ 0.07329055  0.19754678  0.16020107  0.29862134  0.18155888  0.39868914\n",
      "  0.87686238  0.22548086  0.70877959 -0.13537063 -0.15946709  0.09620006\n",
      "  0.42122756  0.01085021]\n",
      "New theta_0 : [ 0.07101786  0.195681    0.15476594  0.29581974  0.17911285  0.39491725\n",
      "  0.87030138  0.22065978  0.69973796 -0.13408132 -0.16003308  0.09215175\n",
      "  0.41480099  0.00433502]\n",
      "Training Error:  18.92429434192913\n",
      "====================================================================================================\n",
      "Iteration:  82\n",
      "Previous theta :  [ 0.07101786  0.195681    0.15476594  0.29581974  0.17911285  0.39491725\n",
      "  0.87030138  0.22065978  0.69973796 -0.13408132 -0.16003308  0.09215175\n",
      "  0.41480099  0.00433502]\n",
      "New theta_0 : [ 0.06883066  0.19384015  0.14948938  0.29304377  0.17675742  0.39116133\n",
      "  0.86382142  0.21591623  0.69080035 -0.13274512 -0.16055013  0.08817743\n",
      "  0.4085275  -0.0020895 ]\n",
      "Training Error:  18.76513456368441\n",
      "====================================================================================================\n",
      "Iteration:  83\n",
      "Previous theta :  [ 0.06883066  0.19384015  0.14948938  0.29304377  0.17675742  0.39116133\n",
      "  0.86382142  0.21591623  0.69080035 -0.13274512 -0.16055013  0.08817743\n",
      "  0.4085275  -0.0020895 ]\n",
      "New theta_0 : [ 0.06672561  0.19202325  0.14436703  0.2902932   0.17448916  0.38742163\n",
      "  0.85742123  0.21124951  0.68196482 -0.13136459 -0.1610205   0.0842753\n",
      "  0.40240327 -0.00842436]\n",
      "Training Error:  18.609751865603506\n",
      "====================================================================================================\n",
      "Iteration:  84\n",
      "Previous theta :  [ 0.06672561  0.19202325  0.14436703  0.2902932   0.17448916  0.38742163\n",
      "  0.85742123  0.21124951  0.68196482 -0.13136459 -0.1610205   0.0842753\n",
      "  0.40240327 -0.00842436]\n",
      "New theta_0 : [ 0.06469947  0.19022939  0.13939463  0.28756778  0.17230474  0.38369839\n",
      "  0.85109959  0.20665888  0.67322951 -0.12994218 -0.16144636  0.08044359\n",
      "  0.39642456 -0.01467055]\n",
      "Training Error:  18.458031010877004\n",
      "====================================================================================================\n",
      "Iteration:  85\n",
      "Previous theta :  [ 0.06469947  0.19022939  0.13939463  0.28756778  0.17230474  0.38369839\n",
      "  0.85109959  0.20665888  0.67322951 -0.12994218 -0.16144636  0.08044359\n",
      "  0.39642456 -0.01467055]\n",
      "New theta_0 : [ 0.06274914  0.18845771  0.13456808  0.28486729  0.17020098  0.37999181\n",
      "  0.84485531  0.20214359  0.66459256 -0.12848026 -0.16182975  0.07668059\n",
      "  0.39058773 -0.02082908]\n",
      "Training Error:  18.309861167800833\n",
      "====================================================================================================\n",
      "Iteration:  86\n",
      "Previous theta :  [ 0.06274914  0.18845771  0.13456808  0.28486729  0.17020098  0.37999181\n",
      "  0.84485531  0.20214359  0.66459256 -0.12848026 -0.16182975  0.07668059\n",
      "  0.39058773 -0.02082908]\n",
      "New theta_0 : [ 0.06087166  0.18670739  0.12988337  0.28219147  0.16817483  0.37630208\n",
      "  0.83868724  0.1977029   0.65605222 -0.12698107 -0.16217269  0.07298467\n",
      "  0.38488922 -0.02690093]\n",
      "Training Error:  18.165135711882897\n",
      "====================================================================================================\n",
      "Iteration:  87\n",
      "Previous theta :  [ 0.06087166  0.18670739  0.12988337  0.28219147  0.16817483  0.37630208\n",
      "  0.83868724  0.1977029   0.65605222 -0.12698107 -0.16217269  0.07298467\n",
      "  0.38488922 -0.02690093]\n",
      "New theta_0 : [ 0.05906418  0.18497764  0.12533665  0.2795401   0.16622332  0.37262939\n",
      "  0.83259422  0.19333601  0.64760675 -0.12544676 -0.16247706  0.0693542\n",
      "  0.37932555 -0.03288712]\n",
      "Training Error:  18.02375203764558\n",
      "====================================================================================================\n",
      "Iteration:  88\n",
      "Previous theta :  [ 0.05906418  0.18497764  0.12533665  0.2795401   0.16622332  0.37262939\n",
      "  0.83259422  0.19333601  0.64760675 -0.12544676 -0.16247706  0.0693542\n",
      "  0.37932555 -0.03288712]\n",
      "New theta_0 : [ 0.05732395  0.18326772  0.12092417  0.27691293  0.16434361  0.3689739\n",
      "  0.82657517  0.18904214  0.63925448 -0.1238794  -0.16274469  0.06578764\n",
      "  0.37389335 -0.03878865]\n",
      "Training Error:  17.885611379640785\n",
      "====================================================================================================\n",
      "Iteration:  89\n",
      "Previous theta :  [ 0.05732395  0.18326772  0.12092417  0.27691293  0.16434361  0.3689739\n",
      "  0.82657517  0.18904214  0.63925448 -0.1238794  -0.16274469  0.06578764\n",
      "  0.37389335 -0.03878865]\n",
      "New theta_0 : [ 0.05564834  0.18157692  0.11664229  0.27430973  0.16253297  0.36533576\n",
      "  0.820629    0.18482049  0.63099379 -0.12228096 -0.16297735  0.06228348\n",
      "  0.36858928 -0.04460652]\n",
      "Training Error:  17.75061864221718\n",
      "====================================================================================================\n",
      "Iteration:  90\n",
      "Previous theta :  [ 0.05564834  0.18157692  0.11664229  0.27430973  0.16253297  0.36533576\n",
      "  0.820629    0.18482049  0.63099379 -0.12228096 -0.16297735  0.06228348\n",
      "  0.36858928 -0.04460652]\n",
      "New theta_0 : [ 0.05403483  0.17990458  0.11248748  0.27173026  0.16078878  0.36171509\n",
      "  0.81475465  0.18067025  0.62282309 -0.12065332 -0.1631767   0.05884024\n",
      "  0.36341014 -0.05034173]\n",
      "Training Error:  17.618682237601295\n",
      "====================================================================================================\n",
      "Iteration:  91\n",
      "Previous theta :  [ 0.05403483  0.17990458  0.11248748  0.27173026  0.16078878  0.36171509\n",
      "  0.81475465  0.18067025  0.62282309 -0.12065332 -0.1631767   0.05884024\n",
      "  0.36341014 -0.05034173]\n",
      "New theta_0 : [ 0.052481    0.17825006  0.10845633  0.26917429  0.15910849  0.35811203\n",
      "  0.80895109  0.17659061  0.61474084 -0.11899829 -0.16334437  0.05545651\n",
      "  0.35835275 -0.05599529]\n",
      "Training Error:  17.489713931875286\n",
      "====================================================================================================\n",
      "Iteration:  92\n",
      "Previous theta :  [ 0.052481    0.17825006  0.10845633  0.26917429  0.15910849  0.35811203\n",
      "  0.80895109  0.17659061  0.61474084 -0.11899829 -0.16334437  0.05545651\n",
      "  0.35835275 -0.05599529]\n",
      "New theta_0 : [ 0.05098452  0.17661275  0.1045455   0.26664159  0.15748968  0.35452669\n",
      "  0.80321732  0.17258072  0.60674556 -0.11731759 -0.16348189  0.0521309\n",
      "  0.35341406 -0.06156819]\n",
      "Training Error:  17.363628698454338\n",
      "====================================================================================================\n",
      "Iteration:  93\n",
      "Previous theta :  [ 0.05098452  0.17661275  0.1045455   0.26664159  0.15748968  0.35452669\n",
      "  0.80321732  0.17258072  0.60674556 -0.11731759 -0.16348189  0.0521309\n",
      "  0.35341406 -0.06156819]\n",
      "New theta_0 : [ 0.04954316  0.17499208  0.10075178  0.26413193  0.15592999  0.35095916\n",
      "  0.79755235  0.16863977  0.59883579 -0.11561289 -0.16359074  0.04886206\n",
      "  0.34859105 -0.06706144]\n",
      "Training Error:  17.240344578685946\n",
      "====================================================================================================\n",
      "Iteration:  94\n",
      "Previous theta :  [ 0.04954316  0.17499208  0.10075178  0.26413193  0.15592999  0.35095916\n",
      "  0.79755235  0.16863977  0.59883579 -0.11561289 -0.16359074  0.04886206\n",
      "  0.34859105 -0.06706144]\n",
      "New theta_0 : [ 0.04815477  0.17338751  0.09707204  0.26164508  0.15442718  0.34740953\n",
      "  0.79195522  0.16476692  0.59101011 -0.11388576 -0.16367236  0.04564871\n",
      "  0.3438808  -0.07247601]\n",
      "Training Error:  17.119782549211823\n",
      "====================================================================================================\n",
      "Iteration:  95\n",
      "Previous theta :  [ 0.04815477  0.17338751  0.09707204  0.26164508  0.15442718  0.34740953\n",
      "  0.79195522  0.16476692  0.59101011 -0.11388576 -0.16367236  0.04564871\n",
      "  0.3438808  -0.07247601]\n",
      "New theta_0 : [ 0.04681729  0.17179851  0.09350324  0.25918081  0.15297907  0.34387787\n",
      "  0.78642498  0.16096132  0.58326714 -0.11213771 -0.1637281   0.04248957\n",
      "  0.33928046 -0.0778129 ]\n",
      "Training Error:  17.001866395750817\n",
      "====================================================================================================\n",
      "Iteration:  96\n",
      "Previous theta :  [ 0.04681729  0.17179851  0.09350324  0.25918081  0.15297907  0.34387787\n",
      "  0.78642498  0.16096132  0.58326714 -0.11213771 -0.1637281   0.04248957\n",
      "  0.33928046 -0.0778129 ]\n",
      "New theta_0 : [ 0.04552875  0.1702246   0.09004243  0.2567389   0.15158357  0.34036426\n",
      "  0.7809607   0.15722213  0.57560556 -0.1103702  -0.16375927  0.03938341\n",
      "  0.33478724 -0.0830731 ]\n",
      "Training Error:  16.88652259297806\n",
      "====================================================================================================\n",
      "Iteration:  97\n",
      "Previous theta :  [ 0.04552875  0.1702246   0.09004243  0.2567389   0.15158357  0.34036426\n",
      "  0.7809607   0.15722213  0.57560556 -0.1103702  -0.16375927  0.03938341\n",
      "  0.33478724 -0.0830731 ]\n",
      "New theta_0 : [ 0.04428725  0.1686653   0.08668675  0.25431914  0.15023868  0.33686876\n",
      "  0.77556149  0.1535485   0.56802404 -0.1085846  -0.16376713  0.03632903\n",
      "  0.33039843 -0.08825759]\n",
      "Training Error:  16.773680190191733\n",
      "====================================================================================================\n",
      "Iteration:  98\n",
      "Previous theta :  [ 0.04428725  0.1686653   0.08668675  0.25431914  0.15023868  0.33686876\n",
      "  0.77556149  0.1535485   0.56802404 -0.1085846  -0.16376713  0.03632903\n",
      "  0.33039843 -0.08825759]\n",
      "New theta_0 : [ 0.04309097  0.16712018  0.08343342  0.25192128  0.14894246  0.3333914\n",
      "  0.77022646  0.14993959  0.56052133 -0.10678224 -0.16375288  0.03332528\n",
      "  0.32611137 -0.09336733]\n",
      "Training Error:  16.66327070247404\n",
      "====================================================================================================\n",
      "Iteration:  99\n",
      "Previous theta :  [ 0.04309097  0.16712018  0.08343342  0.25192128  0.14894246  0.3333914\n",
      "  0.77022646  0.14993959  0.56052133 -0.10678224 -0.16375288  0.03332528\n",
      "  0.32611137 -0.09336733]\n",
      "New theta_0 : [ 0.04193815  0.1655888   0.08027974  0.24954514  0.14769306  0.32993225\n",
      "  0.76495473  0.14639455  0.55309618 -0.10496438 -0.16371767  0.03037103\n",
      "  0.3219235  -0.0984033 ]\n",
      "Training Error:  16.5552280070679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  100\n",
      "Previous theta :  [ 0.04193815  0.1655888   0.08027974  0.24954514  0.14769306  0.32993225\n",
      "  0.76495473  0.14639455  0.55309618 -0.10496438 -0.16371767  0.03037103\n",
      "  0.3219235  -0.0984033 ]\n",
      "New theta_0 : [ 0.04082712  0.16407078  0.07722307  0.24719047  0.14648868  0.32649131\n",
      "  0.75974546  0.14291252  0.54574739 -0.10313225 -0.1636626   0.02746519\n",
      "  0.31783228 -0.10336646]\n",
      "Training Error:  16.449488244704593\n",
      "====================================================================================================\n",
      "Iteration:  101\n",
      "Previous theta :  [ 0.04082712  0.16407078  0.07722307  0.24719047  0.14648868  0.32649131\n",
      "  0.75974546  0.14291252  0.54574739 -0.10313225 -0.1636626   0.02746519\n",
      "  0.31783228 -0.10336646]\n",
      "New theta_0 : [ 0.03975627  0.16256572  0.07426088  0.24485708  0.1453276   0.32306864\n",
      "  0.7545978   0.13949266  0.53847378 -0.10128699 -0.16358875  0.02460668\n",
      "  0.31383528 -0.10825777]\n",
      "Training Error:  16.345989725631128\n",
      "====================================================================================================\n",
      "Iteration:  102\n",
      "Previous theta :  [ 0.03975627  0.16256572  0.07426088  0.24485708  0.1453276   0.32306864\n",
      "  0.7545978   0.13949266  0.53847378 -0.10128699 -0.16358875  0.02460668\n",
      "  0.31383528 -0.10825777]\n",
      "New theta_0 : [ 0.03872404  0.16107326  0.07139069  0.24254475  0.14420817  0.31966423\n",
      "  0.74951094  0.13613413  0.5312742  -0.09942971 -0.16349713  0.02179447\n",
      "  0.30993009 -0.11307817]\n",
      "Training Error:  16.244672840098684\n",
      "====================================================================================================\n",
      "Iteration:  103\n",
      "Previous theta :  [ 0.03872404  0.16107326  0.07139069  0.24254475  0.14420817  0.31966423\n",
      "  0.74951094  0.13613413  0.5312742  -0.09942971 -0.16349713  0.02179447\n",
      "  0.30993009 -0.11307817]\n",
      "New theta_0 : [ 0.03772894  0.15959307  0.06861007  0.24025328  0.1431288   0.31627811\n",
      "  0.74448408  0.13283607  0.52414754 -0.09756147 -0.16338871  0.01902756\n",
      "  0.30611438 -0.11782861]\n",
      "Training Error:  16.14547997308569\n",
      "====================================================================================================\n",
      "Iteration:  104\n",
      "Previous theta :  [ 0.03772894  0.15959307  0.06861007  0.24025328  0.1431288   0.31627811\n",
      "  0.74448408  0.13283607  0.52414754 -0.09756147 -0.16338871  0.01902756\n",
      "  0.30611438 -0.11782861]\n",
      "New theta_0 : [ 0.03676956  0.15812481  0.0659167   0.23798246  0.14208795  0.31291027\n",
      "  0.73951641  0.12959764  0.5170927  -0.09568329 -0.16326443  0.01630496\n",
      "  0.30238588 -0.12251003]\n",
      "Training Error:  16.048355423040533\n",
      "====================================================================================================\n",
      "Iteration:  105\n",
      "Previous theta :  [ 0.03676956  0.15812481  0.0659167   0.23798246  0.14208795  0.31291027\n",
      "  0.73951641  0.12959764  0.5170927  -0.09568329 -0.16326443  0.01630496\n",
      "  0.30238588 -0.12251003]\n",
      "New theta_0 : [ 0.03584451  0.15666817  0.06330829  0.23573208  0.14108415  0.30956073\n",
      "  0.73460716  0.12641802  0.51010863 -0.09379613 -0.16312518  0.01362572\n",
      "  0.29874239 -0.12712334]\n",
      "Training Error:  15.953245324439985\n",
      "====================================================================================================\n",
      "Iteration:  106\n",
      "Previous theta :  [ 0.03584451  0.15666817  0.06330829  0.23573208  0.14108415  0.30956073\n",
      "  0.73460716  0.12641802  0.51010863 -0.09379613 -0.16312518  0.01362572\n",
      "  0.29874239 -0.12712334]\n",
      "New theta_0 : [ 0.03495248  0.15522285  0.06078264  0.23350194  0.14011599  0.30622947\n",
      "  0.72975557  0.12329636  0.50319427 -0.09190091 -0.16297183  0.01098893\n",
      "  0.29518173 -0.13166948]\n",
      "Training Error:  15.860097573969755\n",
      "====================================================================================================\n",
      "Iteration:  107\n",
      "Previous theta :  [ 0.03495248  0.15522285  0.06078264  0.23350194  0.14011599  0.30622947\n",
      "  0.72975557  0.12329636  0.50319427 -0.09190091 -0.16297183  0.01098893\n",
      "  0.29518173 -0.13166948]\n",
      "New theta_0 : [ 0.03409221  0.15378857  0.05833759  0.23129185  0.1391821   0.30291648\n",
      "  0.72496089  0.12023182  0.49634862 -0.08999852 -0.16280519  0.00839366\n",
      "  0.29170181 -0.13614935]\n",
      "Training Error:  15.76886176014367\n",
      "====================================================================================================\n",
      "Iteration:  108\n",
      "Previous theta :  [ 0.03409221  0.15378857  0.05833759  0.23129185  0.1391821   0.30291648\n",
      "  0.72496089  0.12023182  0.49634862 -0.08999852 -0.16280519  0.00839366\n",
      "  0.29170181 -0.13614935]\n",
      "New theta_0 : [ 0.03326248  0.15236507  0.05597105  0.22910161  0.13828117  0.29962175\n",
      "  0.72022238  0.11722359  0.48957068 -0.08808981 -0.16262607  0.00583906\n",
      "  0.28830058 -0.14056386]\n",
      "Training Error:  15.679489096187297\n",
      "====================================================================================================\n",
      "Iteration:  109\n",
      "Previous theta :  [ 0.03326248  0.15236507  0.05597105  0.22910161  0.13828117  0.29962175\n",
      "  0.72022238  0.11722359  0.48957068 -0.08808981 -0.16262607  0.00583906\n",
      "  0.28830058 -0.14056386]\n",
      "New theta_0 : [ 0.03246213  0.15095209  0.05368098  0.22693103  0.13741194  0.29634526\n",
      "  0.71553932  0.11427084  0.4828595  -0.08617557 -0.16243522  0.00332426\n",
      "  0.28497603 -0.14491391]\n",
      "Training Error:  15.59193235602089\n",
      "====================================================================================================\n",
      "Iteration:  110\n",
      "Previous theta :  [ 0.03246213  0.15095209  0.05368098  0.22693103  0.13741194  0.29634526\n",
      "  0.71553932  0.11427084  0.4828595  -0.08617557 -0.16243522  0.00332426\n",
      "  0.28497603 -0.14491391]\n",
      "New theta_0 : [ 0.03169003  0.14954939  0.05146539  0.22477992  0.1365732   0.29308697\n",
      "  0.71091099  0.11137275  0.47621412 -0.08425658 -0.16223336  0.00084844\n",
      "  0.28172624 -0.14920037]\n",
      "Training Error:  15.506145813185098\n",
      "====================================================================================================\n",
      "Iteration:  111\n",
      "Previous theta :  [ 0.03169003  0.14954939  0.05146539  0.22477992  0.1365732   0.29308697\n",
      "  0.71091099  0.11137275  0.47621412 -0.08425658 -0.16223336  0.00084844\n",
      "  0.28172624 -0.14920037]\n",
      "New theta_0 : [ 0.0309451   0.14815673  0.04932238  0.22264808  0.13576377  0.28984687\n",
      "  0.70633669  0.10852852  0.46963361 -0.08233358 -0.16202119 -0.00158922\n",
      "  0.27854929 -0.15342414]\n",
      "Training Error:  15.42208518256094\n",
      "====================================================================================================\n",
      "Iteration:  112\n",
      "Previous theta :  [ 0.0309451   0.14815673  0.04932238  0.22264808  0.13576377  0.28984687\n",
      "  0.70633669  0.10852852  0.46963361 -0.08233358 -0.16202119 -0.00158922\n",
      "  0.27854929 -0.15342414]\n",
      "New theta_0 : [ 0.03022632  0.1467739   0.04725005  0.22053533  0.13498255  0.28662492\n",
      "  0.70181573  0.10573733  0.46311709 -0.08040727 -0.16179937 -0.00398949\n",
      "  0.27544334 -0.15758608]\n",
      "Training Error:  15.339707564743307\n",
      "====================================================================================================\n",
      "Iteration:  113\n",
      "Previous theta :  [ 0.03022632  0.1467739   0.04725005  0.22053533  0.13498255  0.28662492\n",
      "  0.70181573  0.10573733  0.46311709 -0.08040727 -0.16179937 -0.00398949\n",
      "  0.27544334 -0.15758608]\n",
      "New theta_0 : [ 0.0295327   0.14540069  0.04524659  0.21844149  0.13422846  0.28342108\n",
      "  0.69734744  0.10299838  0.45666366 -0.07847831 -0.16156855 -0.00635315\n",
      "  0.2724066  -0.16168705]\n",
      "Training Error:  15.258971392934551\n",
      "====================================================================================================\n",
      "Iteration:  114\n",
      "Previous theta :  [ 0.0295327   0.14540069  0.04524659  0.21844149  0.13422846  0.28342108\n",
      "  0.69734744  0.10299838  0.45666366 -0.07847831 -0.16156855 -0.00635315\n",
      "  0.2724066  -0.16168705]\n",
      "New theta_0 : [ 0.02886327  0.1440369   0.04331022  0.21636637  0.13350044  0.2802353\n",
      "  0.69293113  0.10031089  0.45027246 -0.07654735 -0.16132934 -0.00868093\n",
      "  0.2694373  -0.16572791]\n",
      "Training Error:  15.179836382231683\n",
      "====================================================================================================\n",
      "Iteration:  115\n",
      "Previous theta :  [ 0.02886327  0.1440369   0.04331022  0.21636637  0.13350044  0.2802353\n",
      "  0.69293113  0.10031089  0.45027246 -0.07654735 -0.16132934 -0.00868093\n",
      "  0.2694373  -0.16572791]\n",
      "New theta_0 : [ 0.02821712  0.14268235  0.04143921  0.21430981  0.13279752  0.27706756\n",
      "  0.68856616  0.09767407  0.44394264 -0.074615   -0.16108232 -0.01097358\n",
      "  0.26653375 -0.1697095 ]\n",
      "Training Error:  15.102263481187322\n",
      "====================================================================================================\n",
      "Iteration:  116\n",
      "Previous theta :  [ 0.02821712  0.14268235  0.04143921  0.21430981  0.13279752  0.27706756\n",
      "  0.68856616  0.09767407  0.44394264 -0.074615   -0.16108232 -0.01097358\n",
      "  0.26653375 -0.1697095 ]\n",
      "New theta_0 : [ 0.02759337  0.14133684  0.03963188  0.21227161  0.13211873  0.2739178\n",
      "  0.68425188  0.09508713  0.43767339 -0.07268184 -0.16082806 -0.01323179\n",
      "  0.26369428 -0.17363265]\n",
      "Training Error:  15.026214825530749\n",
      "====================================================================================================\n",
      "Iteration:  117\n",
      "Previous theta :  [ 0.02759337  0.14133684  0.03963188  0.21227161  0.13211873  0.2739178\n",
      "  0.68425188  0.09508713  0.43767339 -0.07268184 -0.16082806 -0.01323179\n",
      "  0.26369428 -0.17363265]\n",
      "New theta_0 : [ 0.02699118  0.14000021  0.03788659  0.21025161  0.13146314  0.27078596\n",
      "  0.67998764  0.09254931  0.4314639  -0.07074843 -0.16056709 -0.01545625\n",
      "  0.26091727 -0.17749819]\n",
      "Training Error:  14.951653693941418\n",
      "====================================================================================================\n",
      "Iteration:  118\n",
      "Previous theta :  [ 0.02699118  0.14000021  0.03788659  0.21025161  0.13146314  0.27078596\n",
      "  0.67998764  0.09254931  0.4314639  -0.07074843 -0.16056709 -0.01545625\n",
      "  0.26091727 -0.17749819]\n",
      "New theta_0 : [ 0.02640974  0.1386723   0.03620175  0.20824963  0.13082987  0.26767201\n",
      "  0.67577282  0.09005983  0.42531336 -0.06881529 -0.16029993 -0.01764763\n",
      "  0.25820115 -0.18130694]\n",
      "Training Error:  14.878544465772881\n",
      "====================================================================================================\n",
      "Iteration:  119\n",
      "Previous theta :  [ 0.02640974  0.1386723   0.03620175  0.20824963  0.13082987  0.26767201\n",
      "  0.67577282  0.09005983  0.42531336 -0.06881529 -0.16029993 -0.01764763\n",
      "  0.25820115 -0.18130694]\n",
      "New theta_0 : [ 0.02584826  0.13735295  0.03457581  0.2062655   0.13021807  0.26457588\n",
      "  0.67160681  0.08761794  0.41922102 -0.06688293 -0.16002708 -0.01980659\n",
      "  0.25554437 -0.1850597 ]\n",
      "Training Error:  14.80685258063041\n",
      "====================================================================================================\n",
      "Iteration:  120\n",
      "Previous theta :  [ 0.02584826  0.13735295  0.03457581  0.2062655   0.13021807  0.26457588\n",
      "  0.67160681  0.08761794  0.41922102 -0.06688293 -0.16002708 -0.01980659\n",
      "  0.25554437 -0.1850597 ]\n",
      "New theta_0 : [ 0.02530599  0.13604201  0.03300725  0.20429906  0.12962692  0.26149751\n",
      "  0.66748897  0.08522289  0.41318611 -0.06495183 -0.159749   -0.02193377\n",
      "  0.25294544 -0.18875727]\n",
      "Training Error:  14.73654449971072\n",
      "====================================================================================================\n",
      "Iteration:  121\n",
      "Previous theta :  [ 0.02530599  0.13604201  0.03300725  0.20429906  0.12962692  0.26149751\n",
      "  0.66748897  0.08522289  0.41318611 -0.06495183 -0.159749   -0.02193377\n",
      "  0.25294544 -0.18875727]\n",
      "New theta_0 : [ 0.02478222  0.13473935  0.0314946   0.20235014  0.12905563  0.25843685\n",
      "  0.66341873  0.08287394  0.40720788 -0.06302246 -0.15946615 -0.02402978\n",
      "  0.2504029  -0.19240045]\n",
      "Training Error:  14.667587668816937\n",
      "====================================================================================================\n",
      "Iteration:  122\n",
      "Previous theta :  [ 0.02478222  0.13473935  0.0314946   0.20235014  0.12905563  0.25843685\n",
      "  0.66341873  0.08287394  0.40720788 -0.06302246 -0.15946615 -0.02402978\n",
      "  0.2504029  -0.19240045]\n",
      "New theta_0 : [ 0.02427626  0.13344482  0.03003643  0.20041857  0.12850345  0.25539383\n",
      "  0.65939547  0.08057035  0.40128562 -0.06109523 -0.15917896 -0.02609524\n",
      "  0.24791534 -0.19599001]\n",
      "Training Error:  14.599950482966552\n",
      "====================================================================================================\n",
      "Iteration:  123\n",
      "Previous theta :  [ 0.02427626  0.13344482  0.03003643  0.20041857  0.12850345  0.25539383\n",
      "  0.65939547  0.08057035  0.40128562 -0.06109523 -0.15917896 -0.02609524\n",
      "  0.24791534 -0.19599001]\n",
      "New theta_0 : [ 0.02378744  0.1321583   0.02863134  0.19850421  0.12796964  0.2523684\n",
      "  0.65541863  0.07831139  0.3954186  -0.05917058 -0.15888784 -0.02813072\n",
      "  0.24548136 -0.19952672]\n",
      "Training Error:  14.533602252514372\n",
      "====================================================================================================\n",
      "Iteration:  124\n",
      "Previous theta :  [ 0.02378744  0.1321583   0.02863134  0.19850421  0.12796964  0.2523684\n",
      "  0.65541863  0.07831139  0.3954186  -0.05917058 -0.15888784 -0.02813072\n",
      "  0.24548136 -0.19952672]\n",
      "New theta_0 : [ 0.02331511  0.13087967  0.02727796  0.19660688  0.1274535   0.24936047\n",
      "  0.65148761  0.07609634  0.38960614 -0.0572489  -0.1585932  -0.03013682\n",
      "  0.24309963 -0.20301134]\n",
      "Training Error:  14.46851317071662\n",
      "====================================================================================================\n",
      "Iteration:  125\n",
      "Previous theta :  [ 0.02331511  0.13087967  0.02727796  0.19660688  0.1274535   0.24936047\n",
      "  0.65148761  0.07609634  0.38960614 -0.0572489  -0.1585932  -0.03013682\n",
      "  0.24309963 -0.20301134]\n",
      "New theta_0 : [ 0.02285868  0.1296088   0.02597499  0.19472643  0.12695437  0.24637\n",
      "  0.64760186  0.07392449  0.38384754 -0.05533056 -0.1582954  -0.03211408\n",
      "  0.24076883 -0.20644462]\n",
      "Training Error:  14.40465428266612\n",
      "====================================================================================================\n",
      "Iteration:  126\n",
      "Previous theta :  [ 0.02285868  0.1296088   0.02597499  0.19472643  0.12695437  0.24637\n",
      "  0.64760186  0.07392449  0.38384754 -0.05533056 -0.1582954  -0.03211408\n",
      "  0.24076883 -0.20644462]\n",
      "New theta_0 : [ 0.02241754  0.1283456   0.02472112  0.1928627   0.12647158  0.24339691\n",
      "  0.64376081  0.07179514  0.37814214 -0.05341592 -0.15799482 -0.03406306\n",
      "  0.23848769 -0.20982732]\n",
      "Training Error:  14.341997455532287\n",
      "====================================================================================================\n",
      "Iteration:  127\n",
      "Previous theta :  [ 0.02241754  0.1283456   0.02472112  0.1928627   0.12647158  0.24339691\n",
      "  0.64376081  0.07179514  0.37814214 -0.05341592 -0.15799482 -0.03406306\n",
      "  0.23848769 -0.20982732]\n",
      "New theta_0 : [ 0.02199113  0.12708994  0.02351509  0.19101555  0.12600453  0.24044112\n",
      "  0.63996391  0.06970759  0.37248928 -0.05150532 -0.15769179 -0.03598429\n",
      "  0.23625496 -0.21316015]\n",
      "Training Error:  14.280515350042958\n",
      "====================================================================================================\n",
      "Iteration:  128\n",
      "Previous theta :  [ 0.02199113  0.12708994  0.02351509  0.19101555  0.12600453  0.24044112\n",
      "  0.63996391  0.06970759  0.37248928 -0.05150532 -0.15769179 -0.03598429\n",
      "  0.23625496 -0.21316015]\n",
      "New theta_0 : [ 0.02157891  0.12584174  0.02235568  0.18918481  0.12555261  0.23750257\n",
      "  0.63621061  0.06766116  0.36688832 -0.04959909 -0.15738666 -0.03787829\n",
      "  0.23406943 -0.21644386]\n",
      "Training Error:  14.22018139314855\n",
      "====================================================================================================\n",
      "Iteration:  129\n",
      "Previous theta :  [ 0.02157891  0.12584174  0.02235568  0.18918481  0.12555261  0.23750257\n",
      "  0.63621061  0.06766116  0.36688832 -0.04959909 -0.15738666 -0.03787829\n",
      "  0.23406943 -0.21644386]\n",
      "New theta_0 : [ 0.02118035  0.12460089  0.02124169  0.18737035  0.12511525  0.23458119\n",
      "  0.63250038  0.06565516  0.36133861 -0.04769752 -0.15707974 -0.03974557\n",
      "  0.23192992 -0.21967914]\n",
      "Training Error:  14.160969751812008\n",
      "====================================================================================================\n",
      "Iteration:  130\n",
      "Previous theta :  [ 0.02118035  0.12460089  0.02124169  0.18737035  0.12511525  0.23458119\n",
      "  0.63250038  0.06565516  0.36133861 -0.04769752 -0.15707974 -0.03974557\n",
      "  0.23192992 -0.21967914]\n",
      "New theta_0 : [ 0.02079495  0.1233673   0.02017196  0.18557202  0.1246919   0.2316769\n",
      "  0.62883269  0.06368893  0.35583954 -0.04580091 -0.15677132 -0.04158662\n",
      "  0.22983529 -0.22286671]\n",
      "Training Error:  14.102855307871002\n",
      "====================================================================================================\n",
      "Iteration:  131\n",
      "Previous theta :  [ 0.02079495  0.1233673   0.02017196  0.18557202  0.1246919   0.2316769\n",
      "  0.62883269  0.06368893  0.35583954 -0.04580091 -0.15677132 -0.04158662\n",
      "  0.22983529 -0.22286671]\n",
      "New theta_0 : [ 0.02042223  0.12214088  0.01914536  0.18378966  0.12428202  0.22878962\n",
      "  0.625207    0.06176181  0.35039051 -0.04390955 -0.1564617  -0.04340194\n",
      "  0.22778441 -0.22600726]\n",
      "Training Error:  14.045813633921652\n",
      "====================================================================================================\n",
      "Iteration:  132\n",
      "Previous theta :  [ 0.02042223  0.12214088  0.01914536  0.18378966  0.12428202  0.22878962\n",
      "  0.625207    0.06176181  0.35039051 -0.04390955 -0.1564617  -0.04340194\n",
      "  0.22778441 -0.22600726]\n",
      "New theta_0 : [ 0.02006172  0.12092156  0.01816077  0.18202314  0.1238851   0.22591928\n",
      "  0.62162281  0.05987313  0.34499091 -0.04202368 -0.15615116 -0.04519198\n",
      "  0.22577621 -0.22910149]\n",
      "Training Error:  13.98982097017564\n",
      "====================================================================================================\n",
      "Iteration:  133\n",
      "Previous theta :  [ 0.02006172  0.12092156  0.01816077  0.18202314  0.1238851   0.22591928\n",
      "  0.62162281  0.05987313  0.34499091 -0.04202368 -0.15615116 -0.04519198\n",
      "  0.22577621 -0.22910149]\n",
      "New theta_0 : [ 0.01971298  0.11970924  0.01721712  0.18027231  0.12350065  0.22306581\n",
      "  0.6180796   0.05802226  0.33964016 -0.04014355 -0.15583995 -0.04695723\n",
      "  0.22380961 -0.23215007]\n",
      "Training Error:  13.93485420224505\n",
      "====================================================================================================\n",
      "Iteration:  134\n",
      "Previous theta :  [ 0.01971298  0.11970924  0.01721712  0.18027231  0.12350065  0.22306581\n",
      "  0.6180796   0.05802226  0.33964016 -0.04014355 -0.15583995 -0.04695723\n",
      "  0.22380961 -0.23215007]\n",
      "New theta_0 : [ 0.01937557  0.11850385  0.01631336  0.17853704  0.1231282   0.22022911\n",
      "  0.61457688  0.05620856  0.33433767 -0.03826941 -0.15552833 -0.04869811\n",
      "  0.22188359 -0.23515367]\n",
      "Training Error:  13.880890839811778\n",
      "====================================================================================================\n",
      "Iteration:  135\n",
      "Previous theta :  [ 0.01937557  0.11850385  0.01631336  0.17853704  0.1231282   0.22022911\n",
      "  0.61457688  0.05620856  0.33433767 -0.03826941 -0.15552833 -0.04869811\n",
      "  0.22188359 -0.23515367]\n",
      "New theta_0 : [ 0.01904908  0.11730531  0.01544845  0.17681719  0.1227673   0.21740913\n",
      "  0.61111414  0.0544314   0.3290829  -0.03640147 -0.15521655 -0.05041508\n",
      "  0.21999714 -0.23811295]\n",
      "Training Error:  13.827908996140327\n",
      "====================================================================================================\n",
      "Iteration:  136\n",
      "Previous theta :  [ 0.01904908  0.11730531  0.01544845  0.17681719  0.1227673   0.21740913\n",
      "  0.61111414  0.0544314   0.3290829  -0.03640147 -0.15521655 -0.05041508\n",
      "  0.21999714 -0.23811295]\n",
      "New theta_0 : [ 0.01873313  0.11611356  0.01462141  0.17511262  0.1224175   0.21460577\n",
      "  0.6076909   0.05269015  0.32387527 -0.03453994 -0.15490482 -0.05210856\n",
      "  0.21814928 -0.24102857]\n",
      "Training Error:  13.775887368395235\n",
      "====================================================================================================\n",
      "Iteration:  137\n",
      "Previous theta :  [ 0.01873313  0.11611356  0.01462141  0.17511262  0.1224175   0.21460577\n",
      "  0.6076909   0.05269015  0.32387527 -0.03453994 -0.15490482 -0.05210856\n",
      "  0.21814928 -0.24102857]\n",
      "New theta_0 : [ 0.01842731  0.11492853  0.01383126  0.17342319  0.1220784   0.21181896\n",
      "  0.60430666  0.05098421  0.31871425 -0.03268502 -0.15459336 -0.05377898\n",
      "  0.21633907 -0.24390117]\n",
      "Training Error:  13.724805218726104\n",
      "====================================================================================================\n",
      "Iteration:  138\n",
      "Previous theta :  [ 0.01842731  0.11492853  0.01383126  0.17342319  0.1220784   0.21181896\n",
      "  0.60430666  0.05098421  0.31871425 -0.03268502 -0.15459336 -0.05377898\n",
      "  0.21633907 -0.24390117]\n",
      "New theta_0 : [ 0.01813128  0.11375015  0.01307704  0.17174878  0.12174958  0.20904861\n",
      "  0.60096096  0.04931297  0.31359929 -0.0308369  -0.15428239 -0.05542673\n",
      "  0.21456557 -0.24673138]\n",
      "Training Error:  13.674642356085249\n",
      "====================================================================================================\n",
      "Iteration:  139\n",
      "Previous theta :  [ 0.01813128  0.11375015  0.01307704  0.17174878  0.12174958  0.20904861\n",
      "  0.60096096  0.04931297  0.31359929 -0.0308369  -0.15428239 -0.05542673\n",
      "  0.21456557 -0.24673138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.01784467  0.11257836  0.01235783  0.17008925  0.12143066  0.20629465\n",
      "  0.59765333  0.04767584  0.30852988 -0.02899576 -0.1539721  -0.05705224\n",
      "  0.21282788 -0.24951984]\n",
      "Training Error:  13.625379118744746\n",
      "====================================================================================================\n",
      "Iteration:  140\n",
      "Previous theta :  [ 0.01784467  0.11257836  0.01235783  0.17008925  0.12143066  0.20629465\n",
      "  0.59765333  0.04767584  0.30852988 -0.02899576 -0.1539721  -0.05705224\n",
      "  0.21282788 -0.24951984]\n",
      "New theta_0 : [ 0.01756715  0.1114131   0.01167273  0.16844447  0.12112127  0.203557\n",
      "  0.59438329  0.04607223  0.30350549 -0.02716175 -0.15366268 -0.05865587\n",
      "  0.21112512 -0.25226715]\n",
      "Training Error:  13.576996357481319\n",
      "====================================================================================================\n",
      "Iteration:  141\n",
      "Previous theta :  [ 0.01756715  0.1114131   0.01167273  0.16844447  0.12112127  0.203557\n",
      "  0.59438329  0.04607223  0.30350549 -0.02716175 -0.15366268 -0.05865587\n",
      "  0.21112512 -0.25226715]\n",
      "New theta_0 : [ 0.01729839  0.1102543   0.01102085  0.16681431  0.12082104  0.20083557\n",
      "  0.59115038  0.04450155  0.29852562 -0.02533504 -0.15335431 -0.06023803\n",
      "  0.20945643 -0.25497394]\n",
      "Training Error:  13.529475419399121\n",
      "====================================================================================================\n",
      "Iteration:  142\n",
      "Previous theta :  [ 0.01729839  0.1102543   0.01102085  0.16681431  0.12082104  0.20083557\n",
      "  0.59115038  0.04450155  0.29852562 -0.02533504 -0.15335431 -0.06023803\n",
      "  0.20945643 -0.25497394]\n",
      "New theta_0 : [ 0.01703807  0.10910193  0.01040134  0.16519866  0.12052965  0.19813027\n",
      "  0.58795417  0.04296325  0.29358977 -0.02351577 -0.15304716 -0.06179907\n",
      "  0.20782098 -0.25764079]\n",
      "Training Error:  13.482798132362014\n",
      "====================================================================================================\n",
      "Iteration:  143\n",
      "Previous theta :  [ 0.01703807  0.10910193  0.01040134  0.16519866  0.12052965  0.19813027\n",
      "  0.58795417  0.04296325  0.29358977 -0.02351577 -0.15304716 -0.06179907\n",
      "  0.20782098 -0.25764079]\n",
      "New theta_0 : [ 0.0167859   0.10795592  0.00981335  0.16359737  0.12024674  0.19544104\n",
      "  0.58479419  0.04145675  0.28869744 -0.02170408 -0.15274138 -0.06333938\n",
      "  0.20621797 -0.26026831]\n",
      "Training Error:  13.436946790008328\n",
      "====================================================================================================\n",
      "Iteration:  144\n",
      "Previous theta :  [ 0.0167859   0.10795592  0.00981335  0.16359737  0.12024674  0.19544104\n",
      "  0.58479419  0.04145675  0.28869744 -0.02170408 -0.15274138 -0.06333938\n",
      "  0.20621797 -0.26026831]\n",
      "New theta_0 : [ 0.01654159  0.10681622  0.00925606  0.16201033  0.11997202  0.19276778\n",
      "  0.58167     0.0399815   0.28384814 -0.0199001  -0.15243715 -0.0648593\n",
      "  0.20464659 -0.26285707]\n",
      "Training Error:  13.391904137322484\n",
      "====================================================================================================\n",
      "Iteration:  145\n",
      "Previous theta :  [ 0.01654159  0.10681622  0.00925606  0.16201033  0.11997202  0.19276778\n",
      "  0.58167     0.0399815   0.28384814 -0.0199001  -0.15243715 -0.0648593\n",
      "  0.20464659 -0.26285707]\n",
      "New theta_0 : [ 0.01630485  0.10568278  0.00872869  0.16043742  0.11970516  0.19011042\n",
      "  0.57858117  0.03853696  0.27904142 -0.01810394 -0.1521346  -0.06635918\n",
      "  0.20310608 -0.26540766]\n",
      "Training Error:  13.347653356739134\n",
      "====================================================================================================\n",
      "Iteration:  146\n",
      "Previous theta :  [ 0.01630485  0.10568278  0.00872869  0.16043742  0.11970516  0.19011042\n",
      "  0.57858117  0.03853696  0.27904142 -0.01810394 -0.1521346  -0.06635918\n",
      "  0.20310608 -0.26540766]\n",
      "New theta_0 : [ 0.01607542  0.10455556  0.00823045  0.15887851  0.11944588  0.18746887\n",
      "  0.57552727  0.03712258  0.27427679 -0.01631574 -0.15183387 -0.06783936\n",
      "  0.20159569 -0.26792065]\n",
      "Training Error:  13.304178054756653\n",
      "====================================================================================================\n",
      "Iteration:  147\n",
      "Previous theta :  [ 0.01607542  0.10455556  0.00823045  0.15887851  0.11944588  0.18746887\n",
      "  0.57552727  0.03712258  0.27427679 -0.01631574 -0.15183387 -0.06783936\n",
      "  0.20159569 -0.26792065]\n",
      "New theta_0 : [ 0.01585304  0.10343451  0.00776057  0.15733349  0.1191939   0.18484304\n",
      "  0.57250787  0.03573783  0.2695538  -0.01453557 -0.15153509 -0.06930019\n",
      "  0.20011469 -0.27039658]\n",
      "Training Error:  13.261462249038036\n",
      "====================================================================================================\n",
      "Iteration:  148\n",
      "Previous theta :  [ 0.01585304  0.10343451  0.00776057  0.15733349  0.1191939   0.18484304\n",
      "  0.57250787  0.03573783  0.2695538  -0.01453557 -0.15153509 -0.06930019\n",
      "  0.20011469 -0.27039658]\n",
      "New theta_0 : [ 0.01563746  0.10231959  0.00731833  0.15580224  0.11894894  0.18223286\n",
      "  0.56952256  0.0343822   0.26487199 -0.01276356 -0.15123839 -0.07074198\n",
      "  0.19866237 -0.27283602]\n",
      "Training Error:  13.219490355978273\n",
      "====================================================================================================\n",
      "Iteration:  149\n",
      "Previous theta :  [ 0.01563746  0.10231959  0.00731833  0.15580224  0.11894894  0.18223286\n",
      "  0.56952256  0.0343822   0.26487199 -0.01276356 -0.15123839 -0.07074198\n",
      "  0.19866237 -0.27283602]\n",
      "New theta_0 : [ 0.01542844  0.10121074  0.00690299  0.15428464  0.11871075  0.17963823\n",
      "  0.56657091  0.03305516  0.26023093 -0.01099977 -0.15094388 -0.07216507\n",
      "  0.19723804 -0.27523951]\n",
      "Training Error:  13.178247178718333\n",
      "====================================================================================================\n",
      "Iteration:  150\n",
      "Previous theta :  [ 0.01542844  0.10121074  0.00690299  0.15428464  0.11871075  0.17963823\n",
      "  0.56657091  0.03305516  0.26023093 -0.01099977 -0.15094388 -0.07216507\n",
      "  0.19723804 -0.27523951]\n",
      "New theta_0 : [ 0.01522576  0.10010794  0.00651386  0.15278057  0.11847907  0.17705909\n",
      "  0.56365251  0.0317562   0.25563016 -0.00924431 -0.15065168 -0.07356974\n",
      "  0.19584102 -0.27760758]\n",
      "Training Error:  13.137717895586846\n",
      "====================================================================================================\n",
      "Iteration:  151\n",
      "Previous theta :  [ 0.01522576  0.10010794  0.00651386  0.15278057  0.11847907  0.17705909\n",
      "  0.56365251  0.0317562   0.25563016 -0.00924431 -0.15065168 -0.07356974\n",
      "  0.19584102 -0.27760758]\n",
      "New theta_0 : [ 0.01502919  0.09901115  0.00615023  0.15128992  0.11825366  0.17449534\n",
      "  0.56076697  0.03048483  0.25106927 -0.00749725 -0.1503619  -0.07495633\n",
      "  0.19447066 -0.27994077]\n",
      "Training Error:  13.097888048951562\n",
      "====================================================================================================\n",
      "Iteration:  152\n",
      "Previous theta :  [ 0.01502919  0.09901115  0.00615023  0.15128992  0.11825366  0.17449534\n",
      "  0.56076697  0.03048483  0.25106927 -0.00749725 -0.1503619  -0.07495633\n",
      "  0.19447066 -0.27994077]\n",
      "New theta_0 : [ 0.01483851  0.09792031  0.00581145  0.14981259  0.11803429  0.1719469\n",
      "  0.55791389  0.02924056  0.24654781 -0.00575865 -0.15007463 -0.07632512\n",
      "  0.19312631 -0.2822396 ]\n",
      "Training Error:  13.058743534463385\n",
      "====================================================================================================\n",
      "Iteration:  153\n",
      "Previous theta :  [ 0.01483851  0.09792031  0.00581145  0.14981259  0.11803429  0.1719469\n",
      "  0.55791389  0.02924056  0.24654781 -0.00575865 -0.15007463 -0.07632512\n",
      "  0.19312631 -0.2822396 ]\n",
      "New theta_0 : [ 0.01465353  0.0968354   0.00549685  0.14834845  0.11782074  0.16941369\n",
      "  0.55509286  0.02802289  0.24206539 -0.00402859 -0.14978997 -0.07767641\n",
      "  0.19180737 -0.28450458]\n",
      "Training Error:  13.020270590676802\n",
      "====================================================================================================\n",
      "Iteration:  154\n",
      "Previous theta :  [ 0.01465353  0.0968354   0.00549685  0.14834845  0.11782074  0.16941369\n",
      "  0.55509286  0.02802289  0.24206539 -0.00402859 -0.14978997 -0.07767641\n",
      "  0.19180737 -0.28450458]\n",
      "New theta_0 : [ 0.01447405  0.09575639  0.0052058   0.14689739  0.1176128   0.16689563\n",
      "  0.5523035   0.02683136  0.23762158 -0.00230712 -0.149508   -0.07901049\n",
      "  0.19051321 -0.28673622]\n",
      "Training Error:  12.982455789031134\n",
      "====================================================================================================\n",
      "Iteration:  155\n",
      "Previous theta :  [ 0.01447405  0.09575639  0.0052058   0.14689739  0.1176128   0.16689563\n",
      "  0.5523035   0.02683136  0.23762158 -0.00230712 -0.149508   -0.07901049\n",
      "  0.19051321 -0.28673622]\n",
      "New theta_0 : [ 0.01429987  0.09468322  0.00493767  0.14545931  0.11741026  0.16439263\n",
      "  0.54954543  0.02566548  0.23321598 -0.0005943  -0.14922881 -0.08032763\n",
      "  0.18924326 -0.28893502]\n",
      "Training Error:  12.945286024177893\n",
      "====================================================================================================\n",
      "Iteration:  156\n",
      "Previous theta :  [ 0.01429987  0.09468322  0.00493767  0.14545931  0.11741026  0.16439263\n",
      "  0.54954543  0.02566548  0.23321598 -0.0005943  -0.14922881 -0.08032763\n",
      "  0.18924326 -0.28893502]\n",
      "New theta_0 : [ 0.01413082  0.09361588  0.00469185  0.1440341   0.11721292  0.1619046\n",
      "  0.54681826  0.0245248   0.22884818  0.00110982 -0.14895248 -0.08162812\n",
      "  0.18799693 -0.29110146]\n",
      "Training Error:  12.908748504640158\n",
      "====================================================================================================\n",
      "Iteration:  157\n",
      "Previous theta :  [ 0.01413082  0.09361588  0.00469185  0.1440341   0.11721292  0.1619046\n",
      "  0.54681826  0.0245248   0.22884818  0.00110982 -0.14895248 -0.08162812\n",
      "  0.18799693 -0.29110146]\n",
      "New theta_0 : [ 0.01396672  0.09255433  0.00446774  0.14262165  0.11702059  0.15943148\n",
      "  0.54412162  0.02340887  0.22451781  0.0028052  -0.14867909 -0.08291222\n",
      "  0.18677368 -0.29323604]\n",
      "Training Error:  12.872830743790614\n",
      "====================================================================================================\n",
      "Iteration:  158\n",
      "Previous theta :  [ 0.01396672  0.09255433  0.00446774  0.14262165  0.11702059  0.15943148\n",
      "  0.54412162  0.02340887  0.22451781  0.0028052  -0.14867909 -0.08291222\n",
      "  0.18677368 -0.29323604]\n",
      "New theta_0 : [ 0.01380739  0.09149853  0.00426478  0.14122186  0.11683309  0.15697317\n",
      "  0.54145513  0.02231722  0.22022446  0.0044918  -0.1484087  -0.0841802\n",
      "  0.18557294 -0.29533923]\n",
      "Training Error:  12.837520551135437\n",
      "====================================================================================================\n",
      "Iteration:  159\n",
      "Previous theta :  [ 0.01380739  0.09149853  0.00426478  0.14122186  0.11683309  0.15697317\n",
      "  0.54145513  0.02231722  0.22022446  0.0044918  -0.1484087  -0.0841802\n",
      "  0.18557294 -0.29533923]\n",
      "New theta_0 : [ 0.01365269  0.09044846  0.00408239  0.13983462  0.11665025  0.15452959\n",
      "  0.53881845  0.02124943  0.21596776  0.00616957 -0.14814137 -0.08543231\n",
      "  0.1843942  -0.2974115 ]\n",
      "Training Error:  12.802806023891897\n",
      "====================================================================================================\n",
      "Iteration:  160\n",
      "Previous theta :  [ 0.01365269  0.09044846  0.00408239  0.13983462  0.11665025  0.15452959\n",
      "  0.53881845  0.02124943  0.21596776  0.00616957 -0.14814137 -0.08543231\n",
      "  0.1843942  -0.2974115 ]\n",
      "New theta_0 : [ 0.01350244  0.08940409  0.00392001  0.13845983  0.1164719   0.15210066\n",
      "  0.53621119  0.02020505  0.21174733  0.0078385  -0.14787718 -0.08666881\n",
      "  0.18323694 -0.29945333]\n",
      "Training Error:  12.768675538848077\n",
      "====================================================================================================\n",
      "Iteration:  161\n",
      "Previous theta :  [ 0.01350244  0.08940409  0.00392001  0.13845983  0.1164719   0.15210066\n",
      "  0.53621119  0.02020505  0.21174733  0.0078385  -0.14787718 -0.08666881\n",
      "  0.18323694 -0.29945333]\n",
      "New theta_0 : [ 0.0133565   0.08836538  0.00377711  0.13709738  0.11629787  0.1496863\n",
      "  0.53363301  0.01918366  0.2075628   0.00949856 -0.14761616 -0.08788995\n",
      "  0.18210064 -0.30146515]\n",
      "Training Error:  12.735117744493579\n",
      "====================================================================================================\n",
      "Iteration:  162\n",
      "Previous theta :  [ 0.0133565   0.08836538  0.00377711  0.13709738  0.11629787  0.1496863\n",
      "  0.53363301  0.01918366  0.2075628   0.00949856 -0.14761616 -0.08788995\n",
      "  0.18210064 -0.30146515]\n",
      "New theta_0 : [ 0.01321472  0.0873323   0.00365316  0.13574717  0.11612801  0.14728643\n",
      "  0.53108355  0.01818483  0.2034138   0.01114972 -0.14735839 -0.08909597\n",
      "  0.18098483 -0.30344743]\n",
      "Training Error:  12.702121553410738\n",
      "====================================================================================================\n",
      "Iteration:  163\n",
      "Previous theta :  [ 0.01321472  0.0873323   0.00365316  0.13574717  0.11612801  0.14728643\n",
      "  0.53108355  0.01818483  0.2034138   0.01114972 -0.14735839 -0.08909597\n",
      "  0.18098483 -0.30344743]\n",
      "New theta_0 : [ 0.01307697  0.08630484  0.00354765  0.1344091   0.11596217  0.14490097\n",
      "  0.52856246  0.01720816  0.19929997  0.01279196 -0.1471039  -0.09028711\n",
      "  0.17988903 -0.30540061]\n",
      "Training Error:  12.669676134916202\n",
      "====================================================================================================\n",
      "Iteration:  164\n",
      "Previous theta :  [ 0.01307697  0.08630484  0.00354765  0.1344091   0.11596217  0.14490097\n",
      "  0.52856246  0.01720816  0.19929997  0.01279196 -0.1471039  -0.09028711\n",
      "  0.17988903 -0.30540061]\n",
      "New theta_0 : [ 0.0129431   0.08528295  0.00346008  0.13308308  0.11580021  0.14252982\n",
      "  0.52606941  0.01625323  0.19522097  0.01442527 -0.14685275 -0.0914636\n",
      "  0.17881277 -0.30732512]\n",
      "Training Error:  12.637770907943263\n",
      "====================================================================================================\n",
      "Iteration:  165\n",
      "Previous theta :  [ 0.0129431   0.08528295  0.00346008  0.13308308  0.11580021  0.14252982\n",
      "  0.52606941  0.01625323  0.19522097  0.01442527 -0.14685275 -0.0914636\n",
      "  0.17881277 -0.30732512]\n",
      "New theta_0 : [ 0.012813    0.08426662  0.00338995  0.13176901  0.11564199  0.14017293\n",
      "  0.52360404  0.01531965  0.19117643  0.01604963 -0.14660497 -0.09262567\n",
      "  0.17775559 -0.3092214 ]\n",
      "Training Error:  12.606395534155775\n",
      "====================================================================================================\n",
      "Iteration:  166\n",
      "Previous theta :  [ 0.012813    0.08426662  0.00338995  0.13176901  0.11564199  0.14017293\n",
      "  0.52360404  0.01531965  0.19117643  0.01604963 -0.14660497 -0.09262567\n",
      "  0.17775559 -0.3092214 ]\n",
      "New theta_0 : [ 0.01268652  0.08325581  0.00333678  0.13046677  0.11548737  0.13783019\n",
      "  0.52116604  0.01440701  0.18716601  0.01766504 -0.1463606  -0.09377355\n",
      "  0.17671707 -0.31108987]\n",
      "Training Error:  12.575539911284825\n",
      "====================================================================================================\n",
      "Iteration:  167\n",
      "Previous theta :  [ 0.01268652  0.08325581  0.00333678  0.13046677  0.11548737  0.13783019\n",
      "  0.52116604  0.01440701  0.18716601  0.01766504 -0.1463606  -0.09377355\n",
      "  0.17671707 -0.31108987]\n",
      "New theta_0 : [ 0.01256356  0.08225051  0.00330012  0.12917629  0.11533623  0.13550155\n",
      "  0.51875505  0.01351494  0.18318937  0.0192715  -0.14611968 -0.09490745\n",
      "  0.17569676 -0.31293095]\n",
      "Training Error:  12.54519416667982\n",
      "====================================================================================================\n",
      "Iteration:  168\n",
      "Previous theta :  [ 0.01256356  0.08225051  0.00330012  0.12917629  0.11533623  0.13550155\n",
      "  0.51875505  0.01351494  0.18318937  0.0192715  -0.14611968 -0.09490745\n",
      "  0.17569676 -0.31293095]\n",
      "New theta_0 : [ 0.012444    0.08125068  0.0032795   0.12789746  0.11518845  0.1331869\n",
      "  0.51637077  0.01264304  0.17924619  0.02086899 -0.14588224 -0.0960276\n",
      "  0.17469425 -0.31474505]\n",
      "Training Error:  12.515348651065937\n",
      "====================================================================================================\n",
      "Iteration:  169\n",
      "Previous theta :  [ 0.012444    0.08125068  0.0032795   0.12789746  0.11518845  0.1331869\n",
      "  0.51637077  0.01264304  0.17924619  0.02086899 -0.14588224 -0.0960276\n",
      "  0.17469425 -0.31474505]\n",
      "New theta_0 : [ 0.01232772  0.0802563   0.00327448  0.1266302   0.11504391  0.13088618\n",
      "  0.51401286  0.01179094  0.17533611  0.02245753 -0.14564831 -0.0971342\n",
      "  0.17370914 -0.31653258]\n",
      "Training Error:  12.48599393250023\n",
      "====================================================================================================\n",
      "Iteration:  170\n",
      "Previous theta :  [ 0.01232772  0.0802563   0.00327448  0.1266302   0.11504391  0.13088618\n",
      "  0.51401286  0.01179094  0.17533611  0.02245753 -0.14564831 -0.0971342\n",
      "  0.17370914 -0.31653258]\n",
      "New theta_0 : [ 0.01221461  0.07926735  0.00328463  0.12537439  0.11490249  0.1285993\n",
      "  0.511681    0.01095828  0.17145882  0.0240371  -0.14541792 -0.09822746\n",
      "  0.17274101 -0.31829393]\n",
      "Training Error:  12.45712079051915\n",
      "====================================================================================================\n",
      "Iteration:  171\n",
      "Previous theta :  [ 0.01221461  0.07926735  0.00328463  0.12537439  0.11490249  0.1285993\n",
      "  0.511681    0.01095828  0.17145882  0.0240371  -0.14541792 -0.09822746\n",
      "  0.17274101 -0.31829393]\n",
      "New theta_0 : [ 0.01210458  0.07828379  0.00330951  0.12412996  0.11476409  0.12632619\n",
      "  0.50937489  0.01014469  0.167614    0.02560773 -0.14519109 -0.09930759\n",
      "  0.1717895  -0.3200295 ]\n",
      "Training Error:  12.428720210470349\n",
      "====================================================================================================\n",
      "Iteration:  172\n",
      "Previous theta :  [ 0.01210458  0.07828379  0.00330951  0.12412996  0.11476409  0.12632619\n",
      "  0.50937489  0.01014469  0.167614    0.02560773 -0.14519109 -0.09930759\n",
      "  0.1717895  -0.3200295 ]\n",
      "New theta_0 : [ 0.01199752  0.07730562  0.00334873  0.12289681  0.1146286   0.12406677\n",
      "  0.5070942   0.00934981  0.16380133  0.02716941 -0.14496785 -0.10037478\n",
      "  0.17085422 -0.32173968]\n",
      "Training Error:  12.400783378022107\n",
      "====================================================================================================\n",
      "Iteration:  173\n",
      "Previous theta :  [ 0.01199752  0.07730562  0.00334873  0.12289681  0.1146286   0.12406677\n",
      "  0.5070942   0.00934981  0.16380133  0.02716941 -0.14496785 -0.10037478\n",
      "  0.17085422 -0.32173968]\n",
      "New theta_0 : [ 0.01189334  0.0763328   0.00340186  0.12167484  0.11449592  0.12182095\n",
      "  0.50483864  0.00857329  0.16002049  0.02872216 -0.14474821 -0.10142924\n",
      "  0.16993481 -0.32342484]\n",
      "Training Error:  12.373301673843946\n",
      "====================================================================================================\n",
      "Iteration:  174\n",
      "Previous theta :  [ 0.01189334  0.0763328   0.00340186  0.12167484  0.11449592  0.12182095\n",
      "  0.50483864  0.00857329  0.16002049  0.02872216 -0.14474821 -0.10142924\n",
      "  0.16993481 -0.32342484]\n",
      "New theta_0 : [ 0.01179194  0.07536532  0.00346852  0.12046398  0.11436595  0.11958867\n",
      "  0.5026079   0.00781478  0.15627117  0.03026599 -0.14453219 -0.10247114\n",
      "  0.1690309  -0.32508537]\n",
      "Training Error:  12.346266668452243\n",
      "====================================================================================================\n",
      "Iteration:  175\n",
      "Previous theta :  [ 0.01179194  0.07536532  0.00346852  0.12046398  0.11436595  0.11958867\n",
      "  0.5026079   0.00781478  0.15627117  0.03026599 -0.14453219 -0.10247114\n",
      "  0.1690309  -0.32508537]\n",
      "New theta_0 : [ 0.01169324  0.07440314  0.00354833  0.11926412  0.11423861  0.11736985\n",
      "  0.50040168  0.00707395  0.15255307  0.03180091 -0.1443198  -0.10350069\n",
      "  0.16814215 -0.32672164]\n",
      "Training Error:  12.319670117214947\n",
      "====================================================================================================\n",
      "Iteration:  176\n",
      "Previous theta :  [ 0.01169324  0.07440314  0.00354833  0.11926412  0.11423861  0.11736985\n",
      "  0.50040168  0.00707395  0.15255307  0.03180091 -0.1443198  -0.10350069\n",
      "  0.16814215 -0.32672164]\n",
      "New theta_0 : [ 0.01159714  0.07344625  0.0036409   0.11807518  0.11411381  0.11516439\n",
      "  0.49821968  0.00635046  0.14886589  0.03332695 -0.14411106 -0.10451807\n",
      "  0.16726822 -0.32833401]\n",
      "Training Error:  12.293503955509756\n",
      "====================================================================================================\n",
      "Iteration:  177\n",
      "Previous theta :  [ 0.01159714  0.07344625  0.0036409   0.11807518  0.11411381  0.11516439\n",
      "  0.49821968  0.00635046  0.14886589  0.03332695 -0.14411106 -0.10451807\n",
      "  0.16726822 -0.32833401]\n",
      "New theta_0 : [ 0.01150356  0.07249462  0.00374587  0.11689707  0.11399144  0.11297224\n",
      "  0.49606161  0.00564399  0.14520932  0.03484412 -0.14390598 -0.10552345\n",
      "  0.16640879 -0.32992284]\n",
      "Training Error:  12.267760294030305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  178\n",
      "Previous theta :  [ 0.01150356  0.07249462  0.00374587  0.11689707  0.11399144  0.11297224\n",
      "  0.49606161  0.00564399  0.14520932  0.03484412 -0.14390598 -0.10552345\n",
      "  0.16640879 -0.32992284]\n",
      "New theta_0 : [ 0.01141243  0.07154823  0.00386288  0.1157297   0.11387145  0.11079332\n",
      "  0.49392719  0.0049542   0.14158308  0.03635245 -0.14370456 -0.10651703\n",
      "  0.16556352 -0.33148848]\n",
      "Training Error:  12.242431414235178\n",
      "====================================================================================================\n",
      "Iteration:  179\n",
      "Previous theta :  [ 0.01141243  0.07154823  0.00386288  0.1157297   0.11387145  0.11079332\n",
      "  0.49392719  0.0049542   0.14158308  0.03635245 -0.14370456 -0.10651703\n",
      "  0.16556352 -0.33148848]\n",
      "New theta_0 : [ 0.01132367  0.07060707  0.00399159  0.114573    0.11375374  0.10862754\n",
      "  0.49181613  0.00428078  0.13798688  0.03785194 -0.14350682 -0.10749896\n",
      "  0.1647321  -0.33303128]\n",
      "Training Error:  12.217509763934752\n",
      "====================================================================================================\n",
      "Iteration:  180\n",
      "Previous theta :  [ 0.01132367  0.07060707  0.00399159  0.114573    0.11375374  0.10862754\n",
      "  0.49181613  0.00428078  0.13798688  0.03785194 -0.14350682 -0.10749896\n",
      "  0.1647321  -0.33303128]\n",
      "New theta_0 : [ 0.01123719  0.0696711   0.00413164  0.11342686  0.11363823  0.10647484\n",
      "  0.48972814  0.00362342  0.13442042  0.03934264 -0.14331275 -0.10846943\n",
      "  0.16391423 -0.33455159]\n",
      "Training Error:  12.192987953011084\n",
      "====================================================================================================\n",
      "Iteration:  181\n",
      "Previous theta :  [ 0.01123719  0.0696711   0.00413164  0.11342686  0.11363823  0.10647484\n",
      "  0.48972814  0.00362342  0.13442042  0.03934264 -0.14331275 -0.10846943\n",
      "  0.16391423 -0.33455159]\n",
      "New theta_0 : [ 0.01115293  0.06874031  0.0042827   0.11229121  0.11352487  0.10433513\n",
      "  0.48766295  0.00298182  0.13088343  0.04082456 -0.14312236 -0.1094286\n",
      "  0.16310961 -0.33604975]\n",
      "Training Error:  12.16885874926625\n",
      "====================================================================================================\n",
      "Iteration:  182\n",
      "Previous theta :  [ 0.01115293  0.06874031  0.0042827   0.11229121  0.11352487  0.10433513\n",
      "  0.48766295  0.00298182  0.13088343  0.04082456 -0.14312236 -0.1094286\n",
      "  0.16310961 -0.33604975]\n",
      "New theta_0 : [ 0.01107083  0.06781468  0.00444446  0.11116595  0.11341357  0.10220834\n",
      "  0.48562029  0.00235566  0.12737562  0.04229774 -0.14293566 -0.11037664\n",
      "  0.16231795 -0.33752608]\n",
      "Training Error:  12.145115074394704\n",
      "====================================================================================================\n",
      "Iteration:  183\n",
      "Previous theta :  [ 0.01107083  0.06781468  0.00444446  0.11116595  0.11341357  0.10220834\n",
      "  0.48562029  0.00235566  0.12737562  0.04229774 -0.14293566 -0.11037664\n",
      "  0.16231795 -0.33752608]\n",
      "New theta_0 : [ 0.0109908   0.06689419  0.00461658  0.11005102  0.11330427  0.10009441\n",
      "  0.48359988  0.00174466  0.12389673  0.04376219 -0.14275264 -0.11131371\n",
      "  0.16153896 -0.33898092]\n",
      "Training Error:  12.121750000075465\n",
      "====================================================================================================\n",
      "Iteration:  184\n",
      "Previous theta :  [ 0.0109908   0.06689419  0.00461658  0.11005102  0.11330427  0.10009441\n",
      "  0.48359988  0.00174466  0.12389673  0.04376219 -0.14275264 -0.11131371\n",
      "  0.16153896 -0.33898092]\n",
      "New theta_0 : [ 0.01091279  0.06597881  0.00479877  0.10894632  0.1131969   0.09799324\n",
      "  0.48160146  0.00114853  0.12044647  0.04521796 -0.1425733  -0.11223998\n",
      "  0.16077238 -0.34041458]\n",
      "Training Error:  12.098756744180005\n",
      "====================================================================================================\n",
      "Iteration:  185\n",
      "Previous theta :  [ 0.01091279  0.06597881  0.00479877  0.10894632  0.1131969   0.09799324\n",
      "  0.48160146  0.00114853  0.12044647  0.04521796 -0.1425733  -0.11223998\n",
      "  0.16077238 -0.34041458]\n",
      "New theta_0 : [ 0.01083674  0.06506852  0.00499071  0.10785178  0.1130914   0.09590478\n",
      "  0.47962476  0.00056696  0.11702458  0.04666507 -0.14239763 -0.11315559\n",
      "  0.16001793 -0.34182739]\n",
      "Training Error:  12.076128667091973\n",
      "====================================================================================================\n",
      "Iteration:  186\n",
      "Previous theta :  [ 0.01083674  0.06506852  0.00499071  0.10785178  0.1130914   0.09590478\n",
      "  0.47962476  0.00056696  0.11702458  0.04666507 -0.14239763 -0.11315559\n",
      "  0.16001793 -0.34182739]\n",
      "New theta_0 : [ 1.07625816e-02  6.41633112e-02  5.19211099e-03  1.06767302e-01\n",
      "  1.12987714e-01  9.38289443e-02  4.77669518e-01 -3.03504871e-07\n",
      "  1.13630788e-01  4.81035618e-02 -1.42225643e-01 -1.14060699e-01\n",
      "  1.59275342e-01 -3.43219666e-01]\n",
      "Training Error:  12.053859268134984\n",
      "====================================================================================================\n",
      "Iteration:  187\n",
      "Previous theta :  [ 1.07625816e-02  6.41633112e-02  5.19211099e-03  1.06767302e-01\n",
      "  1.12987714e-01  9.38289443e-02  4.77669518e-01 -3.03504871e-07\n",
      "  1.13630788e-01  4.81035618e-02 -1.42225643e-01 -1.14060699e-01\n",
      "  1.59275342e-01 -3.43219666e-01]\n",
      "New theta_0 : [ 0.01069026  0.06326315  0.00540269  0.10569282  0.11288578  0.09176566\n",
      "  0.47573548 -0.00055355  0.11026484  0.04953346 -0.14205732 -0.11495546\n",
      "  0.15854437 -0.34459171]\n",
      "Training Error:  12.031942182104824\n",
      "====================================================================================================\n",
      "Iteration:  188\n",
      "Previous theta :  [ 0.01069026  0.06326315  0.00540269  0.10569282  0.11288578  0.09176566\n",
      "  0.47573548 -0.00055355  0.11026484  0.04953346 -0.14205732 -0.11495546\n",
      "  0.15854437 -0.34459171]\n",
      "New theta_0 : [ 0.01061972  0.06236803  0.00562215  0.10462824  0.11278554  0.08971486\n",
      "  0.4738224  -0.00109306  0.10692647  0.0509548  -0.14189266 -0.11584003\n",
      "  0.15782477 -0.34594382]\n",
      "Training Error:  12.010371175902678\n",
      "====================================================================================================\n",
      "Iteration:  189\n",
      "Previous theta :  [ 0.01061972  0.06236803  0.00562215  0.10462824  0.11278554  0.08971486\n",
      "  0.4738224  -0.00109306  0.10692647  0.0509548  -0.14189266 -0.11584003\n",
      "  0.15782477 -0.34594382]\n",
      "New theta_0 : [ 0.0105509   0.06147792  0.00585023  0.1035735   0.11268695  0.08767647\n",
      "  0.47193001 -0.00161908  0.10361543  0.05236762 -0.14173164 -0.11671455\n",
      "  0.15711629 -0.34727631]\n",
      "Training Error:  11.989140145265932\n",
      "====================================================================================================\n",
      "Iteration:  190\n",
      "Previous theta :  [ 0.0105509   0.06147792  0.00585023  0.1035735   0.11268695  0.08767647\n",
      "  0.47193001 -0.00161908  0.10361543  0.05236762 -0.14173164 -0.11671455\n",
      "  0.15711629 -0.34727631]\n",
      "New theta_0 : [ 0.01048376  0.0605928   0.00608665  0.1025285   0.11258994  0.08565042\n",
      "  0.47005807 -0.00213189  0.10033146  0.05377196 -0.14157428 -0.11757916\n",
      "  0.15641869 -0.34858946]\n",
      "Training Error:  11.96824311159342\n",
      "====================================================================================================\n",
      "Iteration:  191\n",
      "Previous theta :  [ 0.01048376  0.0605928   0.00608665  0.1025285   0.11258994  0.08565042\n",
      "  0.47005807 -0.00213189  0.10033146  0.05377196 -0.14157428 -0.11757916\n",
      "  0.15641869 -0.34858946]\n",
      "New theta_0 : [ 0.01041824  0.05971266  0.00633116  0.10149318  0.11249448  0.08363664\n",
      "  0.46820634 -0.00263174  0.09707431  0.05516786 -0.14142054 -0.118434\n",
      "  0.15573176 -0.34988356]\n",
      "Training Error:  11.947674218861986\n",
      "====================================================================================================\n",
      "Iteration:  192\n",
      "Previous theta :  [ 0.01041824  0.05971266  0.00633116  0.10149318  0.11249448  0.08363664\n",
      "  0.46820634 -0.00263174  0.09707431  0.05516786 -0.14142054 -0.118434\n",
      "  0.15573176 -0.34988356]\n",
      "New theta_0 : [ 0.01035429  0.05883747  0.00658349  0.10046746  0.11240052  0.08163505\n",
      "  0.46637457 -0.00311889  0.09384373  0.05655535 -0.14127043 -0.11927921\n",
      "  0.15505525 -0.35115891]\n",
      "Training Error:  11.92742773063136\n",
      "====================================================================================================\n",
      "Iteration:  193\n",
      "Previous theta :  [ 0.01035429  0.05883747  0.00658349  0.10046746  0.11240052  0.08163505\n",
      "  0.46637457 -0.00311889  0.09384373  0.05655535 -0.14127043 -0.11927921\n",
      "  0.15505525 -0.35115891]\n",
      "New theta_0 : [ 0.01029187  0.05796721  0.00684339  0.09945125  0.11230801  0.07964559\n",
      "  0.46456252 -0.00359358  0.09063948  0.05793447 -0.14112392 -0.12011493\n",
      "  0.15438895 -0.35241579]\n",
      "Training Error:  11.907498027134524\n",
      "====================================================================================================\n",
      "Iteration:  194\n",
      "Previous theta :  [ 0.01029187  0.05796721  0.00684339  0.09945125  0.11230801  0.07964559\n",
      "  0.46456252 -0.00359358  0.09063948  0.05793447 -0.14112392 -0.12011493\n",
      "  0.15438895 -0.35241579]\n",
      "New theta_0 : [ 0.01023094  0.05710187  0.00711063  0.09844448  0.1122169   0.07766818\n",
      "  0.46276996 -0.00405606  0.08746132  0.05930527 -0.14098102 -0.12094129\n",
      "  0.15373266 -0.35365446]\n",
      "Training Error:  11.887879602450765\n",
      "====================================================================================================\n",
      "Iteration:  195\n",
      "Previous theta :  [ 0.01023094  0.05710187  0.00711063  0.09844448  0.1122169   0.07766818\n",
      "  0.46276996 -0.00405606  0.08746132  0.05930527 -0.14098102 -0.12094129\n",
      "  0.15373266 -0.35365446]\n",
      "New theta_0 : [ 0.01017144  0.05624143  0.00738496  0.09744708  0.11212715  0.07570275\n",
      "  0.46099666 -0.00450656  0.08430901  0.06066778 -0.14084169 -0.12175842\n",
      "  0.15308615 -0.35487521]\n",
      "Training Error:  11.868567061758775\n",
      "====================================================================================================\n",
      "Iteration:  196\n",
      "Previous theta :  [ 0.01017144  0.05624143  0.00738496  0.09744708  0.11212715  0.07570275\n",
      "  0.46099666 -0.00450656  0.08430901  0.06066778 -0.14084169 -0.12175842\n",
      "  0.15308615 -0.35487521]\n",
      "New theta_0 : [ 0.01011333  0.05538585  0.00766615  0.09645897  0.11203873  0.07374925\n",
      "  0.45924238 -0.00494534  0.08118232  0.06202204 -0.14070593 -0.12256646\n",
      "  0.15244923 -0.3560783 ]\n",
      "Training Error:  11.849555118667213\n",
      "====================================================================================================\n",
      "Iteration:  197\n",
      "Previous theta :  [ 0.01011333  0.05538585  0.00766615  0.09645897  0.11203873  0.07374925\n",
      "  0.45924238 -0.00494534  0.08118232  0.06202204 -0.14070593 -0.12256646\n",
      "  0.15244923 -0.3560783 ]\n",
      "New theta_0 : [ 0.01005658  0.05453514  0.00795397  0.09548008  0.11195159  0.07180759\n",
      "  0.4575069  -0.00537261  0.078081    0.06336811 -0.14057372 -0.12336553\n",
      "  0.1518217  -0.35726399]\n",
      "Training Error:  11.83083859262029\n",
      "====================================================================================================\n",
      "Iteration:  198\n",
      "Previous theta :  [ 0.01005658  0.05453514  0.00795397  0.09548008  0.11195159  0.07180759\n",
      "  0.4575069  -0.00537261  0.078081    0.06336811 -0.14057372 -0.12336553\n",
      "  0.1518217  -0.35726399]\n",
      "New theta_0 : [ 0.01000114  0.05368926  0.0082482   0.09451033  0.1118657   0.06987771\n",
      "  0.45579    -0.00578861  0.07500483  0.06470601 -0.14044505 -0.12415575\n",
      "  0.15120336 -0.35843256]\n",
      "Training Error:  11.81241240637594\n",
      "====================================================================================================\n",
      "Iteration:  199\n",
      "Previous theta :  [ 0.01000114  0.05368926  0.0082482   0.09451033  0.1118657   0.06987771\n",
      "  0.45579    -0.00578861  0.07500483  0.06470601 -0.14044505 -0.12415575\n",
      "  0.15120336 -0.35843256]\n",
      "New theta_0 : [ 0.00994698  0.0528482   0.00854863  0.09354965  0.11178101  0.06795954\n",
      "  0.45409145 -0.00619355  0.07195359  0.0660358  -0.1403199  -0.12493725\n",
      "  0.15059403 -0.35958425]\n",
      "Training Error:  11.79427158355433\n",
      "====================================================================================================\n",
      "Iteration:  200\n",
      "Previous theta :  [ 0.00994698  0.0528482   0.00854863  0.09354965  0.11178101  0.06795954\n",
      "  0.45409145 -0.00619355  0.07195359  0.0660358  -0.1403199  -0.12493725\n",
      "  0.15059403 -0.35958425]\n",
      "New theta_0 : [ 0.00989406  0.05201193  0.00885504  0.09259796  0.1116975   0.06605301\n",
      "  0.45241103 -0.00658767  0.06892704  0.06735752 -0.14019824 -0.12571014\n",
      "  0.14999353 -0.36071931]\n",
      "Training Error:  11.776411246254474\n",
      "====================================================================================================\n",
      "Iteration:  201\n",
      "Previous theta :  [ 0.00989406  0.05201193  0.00885504  0.09259796  0.1116975   0.06605301\n",
      "  0.45241103 -0.00658767  0.06892704  0.06735752 -0.14019824 -0.12571014\n",
      "  0.14999353 -0.36071931]\n",
      "New theta_0 : [ 0.00984234  0.05118045  0.00916722  0.0916552   0.11161513  0.06415806\n",
      "  0.45074853 -0.00697117  0.06592497  0.06867121 -0.14008007 -0.12647456\n",
      "  0.14940166 -0.361838  ]\n",
      "Training Error:  11.758826612736787\n",
      "====================================================================================================\n",
      "Iteration:  202\n",
      "Previous theta :  [ 0.00984234  0.05118045  0.00916722  0.0916552   0.11161513  0.06415806\n",
      "  0.45074853 -0.00697117  0.06592497  0.06867121 -0.14008007 -0.12647456\n",
      "  0.14940166 -0.361838  ]\n",
      "New theta_0 : [ 0.00979179  0.05035372  0.00948497  0.09072129  0.11153388  0.06227462\n",
      "  0.44910373 -0.00734426  0.06294715  0.06997691 -0.13996536 -0.12723061\n",
      "  0.14881827 -0.36294056]\n",
      "Training Error:  11.741512995169549\n",
      "====================================================================================================\n",
      "Iteration:  203\n",
      "Previous theta :  [ 0.00979179  0.05035372  0.00948497  0.09072129  0.11153388  0.06227462\n",
      "  0.44910373 -0.00734426  0.06294715  0.06997691 -0.13996536 -0.12723061\n",
      "  0.14881827 -0.36294056]\n",
      "New theta_0 : [ 0.00974238  0.04953173  0.00980811  0.08979616  0.11145369  0.06040262\n",
      "  0.44747643 -0.00770717  0.05999337  0.07127468 -0.13985409 -0.12797841\n",
      "  0.14824318 -0.36402723]\n",
      "Training Error:  11.72446579743729\n",
      "====================================================================================================\n",
      "Iteration:  204\n",
      "Previous theta :  [ 0.00974238  0.04953173  0.00980811  0.08979616  0.11145369  0.06040262\n",
      "  0.44747643 -0.00770717  0.05999337  0.07127468 -0.13985409 -0.12797841\n",
      "  0.14824318 -0.36402723]\n",
      "New theta_0 : [ 0.00969406  0.04871446  0.01013643  0.08887974  0.11137456  0.05854199\n",
      "  0.44586642 -0.00806008  0.05706341  0.07256455 -0.13974625 -0.12871807\n",
      "  0.14767622 -0.36509826]\n",
      "Training Error:  11.707680513009139\n",
      "====================================================================================================\n",
      "Iteration:  205\n",
      "Previous theta :  [ 0.00969406  0.04871446  0.01013643  0.08887974  0.11137456  0.05854199\n",
      "  0.44586642 -0.00806008  0.05706341  0.07256455 -0.13974625 -0.12871807\n",
      "  0.14767622 -0.36509826]\n",
      "New theta_0 : [ 0.00964682  0.04790189  0.01046974  0.08797195  0.11129645  0.05669268\n",
      "  0.44427348 -0.0084032   0.05415705  0.07384658 -0.13964181 -0.1294497\n",
      "  0.14711724 -0.36615386]\n",
      "Training Error:  11.691152722865299\n",
      "====================================================================================================\n",
      "Iteration:  206\n",
      "Previous theta :  [ 0.00964682  0.04790189  0.01046974  0.08797195  0.11129645  0.05669268\n",
      "  0.44427348 -0.0084032   0.05415705  0.07384658 -0.13964181 -0.1294497\n",
      "  0.14711724 -0.36615386]\n",
      "New theta_0 : [ 0.00960062  0.04709401  0.01080787  0.08707274  0.11121933  0.05485461\n",
      "  0.44269743 -0.00873674  0.05127409  0.07512081 -0.13954075 -0.13017342\n",
      "  0.14656606 -0.36719428]\n",
      "Training Error:  11.674878093479897\n",
      "====================================================================================================\n",
      "Iteration:  207\n",
      "Previous theta :  [ 0.00960062  0.04709401  0.01080787  0.08707274  0.11121933  0.05485461\n",
      "  0.44269743 -0.00873674  0.05127409  0.07512081 -0.13954075 -0.13017342\n",
      "  0.14656606 -0.36719428]\n",
      "New theta_0 : [ 0.00955543  0.04629078  0.01115064  0.08618203  0.11114317  0.05302772\n",
      "  0.44113806 -0.00906087  0.04841433  0.07638728 -0.13944305 -0.13088932\n",
      "  0.14602255 -0.36821974]\n",
      "Training Error:  11.658852374858395\n",
      "====================================================================================================\n",
      "Iteration:  208\n",
      "Previous theta :  [ 0.00955543  0.04629078  0.01115064  0.08618203  0.11114317  0.05302772\n",
      "  0.44113806 -0.00906087  0.04841433  0.07638728 -0.13944305 -0.13088932\n",
      "  0.14602255 -0.36821974]\n",
      "New theta_0 : [ 0.00951122  0.0454922   0.01149787  0.08529975  0.11106795  0.05121194\n",
      "  0.43959516 -0.0093758   0.04557754  0.07764604 -0.13934869 -0.13159753\n",
      "  0.14548654 -0.36923046]\n",
      "Training Error:  11.64307139862797\n",
      "====================================================================================================\n",
      "Iteration:  209\n",
      "Previous theta :  [ 0.00951122  0.0454922   0.01149787  0.08529975  0.11106795  0.05121194\n",
      "  0.43959516 -0.0093758   0.04557754  0.07764604 -0.13934869 -0.13159753\n",
      "  0.14548654 -0.36923046]\n",
      "New theta_0 : [ 0.00946797  0.04469825  0.01184939  0.08442584  0.11099365  0.04940721\n",
      "  0.43806856 -0.00968171  0.04276354  0.07889714 -0.13925764 -0.13229813\n",
      "  0.14495789 -0.37022667]\n",
      "Training Error:  11.627531076179201\n",
      "====================================================================================================\n",
      "Iteration:  210\n",
      "Previous theta :  [ 0.00946797  0.04469825  0.01184939  0.08442584  0.11099365  0.04940721\n",
      "  0.43806856 -0.00968171  0.04276354  0.07889714 -0.13925764 -0.13229813\n",
      "  0.14495789 -0.37022667]\n",
      "New theta_0 : [ 0.00942565  0.0439089   0.01220503  0.08356022  0.11092024  0.04761347\n",
      "  0.43655804 -0.00997878  0.03997211  0.08014063 -0.13916989 -0.13299124\n",
      "  0.14443646 -0.37120858]\n",
      "Training Error:  11.61222739685752\n",
      "====================================================================================================\n",
      "Iteration:  211\n",
      "Previous theta :  [ 0.00942565  0.0439089   0.01220503  0.08356022  0.11092024  0.04761347\n",
      "  0.43655804 -0.00997878  0.03997211  0.08014063 -0.13916989 -0.13299124\n",
      "  0.14443646 -0.37120858]\n",
      "New theta_0 : [ 0.00938424  0.04312413  0.01256464  0.08270283  0.11084769  0.04583065\n",
      "  0.43506343 -0.01026719  0.03720306  0.08137655 -0.13908541 -0.13367694\n",
      "  0.14392211 -0.3721764 ]\n",
      "Training Error:  11.597156426202924\n",
      "====================================================================================================\n",
      "Iteration:  212\n",
      "Previous theta :  [ 0.00938424  0.04312413  0.01256464  0.08270283  0.11084769  0.04583065\n",
      "  0.43506343 -0.01026719  0.03720306  0.08137655 -0.13908541 -0.13367694\n",
      "  0.14392211 -0.3721764 ]\n",
      "New theta_0 : [ 0.0093437   0.04234394  0.01292806  0.0818536   0.11077599  0.04405869\n",
      "  0.43358454 -0.01054713  0.0344562   0.08260495 -0.13900417 -0.13435536\n",
      "  0.1434147  -0.37313034]\n",
      "Training Error:  11.582314304236485\n",
      "====================================================================================================\n",
      "Iteration:  213\n",
      "Previous theta :  [ 0.0093437   0.04234394  0.01292806  0.0818536   0.11077599  0.04405869\n",
      "  0.43358454 -0.01054713  0.0344562   0.08260495 -0.13900417 -0.13435536\n",
      "  0.1434147  -0.37313034]\n",
      "New theta_0 : [ 0.00930402  0.04156829  0.01329512  0.08101247  0.11070512  0.04229753\n",
      "  0.43212117 -0.01081875  0.03173132  0.08382587 -0.13892616 -0.13502657\n",
      "  0.1429141  -0.37407062]\n",
      "Training Error:  11.567697243792233\n",
      "====================================================================================================\n",
      "Iteration:  214\n",
      "Previous theta :  [ 0.00930402  0.04156829  0.01329512  0.08101247  0.11070512  0.04229753\n",
      "  0.43212117 -0.01081875  0.03173132  0.08382587 -0.13892616 -0.13502657\n",
      "  0.1429141  -0.37407062]\n",
      "New theta_0 : [ 0.00926517  0.04079716  0.01366569  0.08017937  0.11063505  0.0405471\n",
      "  0.43067315 -0.01108225  0.02902823  0.08503937 -0.13885134 -0.13569068\n",
      "  0.14242017 -0.37499742]\n",
      "Training Error:  11.55330152889309\n",
      "====================================================================================================\n",
      "Iteration:  215\n",
      "Previous theta :  [ 0.00926517  0.04079716  0.01366569  0.08017937  0.11063505  0.0405471\n",
      "  0.43067315 -0.01108225  0.02902823  0.08503937 -0.13885134 -0.13569068\n",
      "  0.14242017 -0.37499742]\n",
      "New theta_0 : [ 0.00922712  0.04003055  0.01403961  0.07935424  0.11056576  0.03880734\n",
      "  0.4292403  -0.01133777  0.02634674  0.08624549 -0.13877971 -0.13634778\n",
      "  0.1419328  -0.37591097]\n",
      "Training Error:  11.5391235131695\n",
      "====================================================================================================\n",
      "Iteration:  216\n",
      "Previous theta :  [ 0.00922712  0.04003055  0.01403961  0.07935424  0.11056576  0.03880734\n",
      "  0.4292403  -0.01133777  0.02634674  0.08624549 -0.13877971 -0.13634778\n",
      "  0.1419328  -0.37591097]\n",
      "New theta_0 : [ 0.00918987  0.03926843  0.01441674  0.07853701  0.11049724  0.0370782\n",
      "  0.42782244 -0.01158549  0.02368667  0.08744428 -0.13871122 -0.13699796\n",
      "  0.14145185 -0.37681144]\n",
      "Training Error:  11.525159618319497\n",
      "====================================================================================================\n",
      "Iteration:  217\n",
      "Previous theta :  [ 0.00918987  0.03926843  0.01441674  0.07853701  0.11049724  0.0370782\n",
      "  0.42782244 -0.01158549  0.02368667  0.08744428 -0.13871122 -0.13699796\n",
      "  0.14145185 -0.37681144]\n",
      "New theta_0 : [ 0.00915338  0.03851077  0.01479694  0.07772761  0.11042947  0.0353596\n",
      "  0.42641939 -0.01182557  0.02104782  0.08863578 -0.13864586 -0.13764132\n",
      "  0.14097721 -0.37769904]\n",
      "Training Error:  11.511406332608994\n",
      "====================================================================================================\n",
      "Iteration:  218\n",
      "Previous theta :  [ 0.00915338  0.03851077  0.01479694  0.07772761  0.11042947  0.0353596\n",
      "  0.42641939 -0.01182557  0.02104782  0.08863578 -0.13864586 -0.13764132\n",
      "  0.14097721 -0.37769904]\n",
      "New theta_0 : [ 0.00911764  0.03775757  0.01518008  0.07692599  0.11036242  0.03365149\n",
      "  0.42503098 -0.01205816  0.01843002  0.08982005 -0.1385836  -0.13827794\n",
      "  0.14050876 -0.37857396]\n",
      "Training Error:  11.497860209411057\n",
      "====================================================================================================\n",
      "Iteration:  219\n",
      "Previous theta :  [ 0.00911764  0.03775757  0.01518008  0.07692599  0.11036242  0.03365149\n",
      "  0.42503098 -0.01205816  0.01843002  0.08982005 -0.1385836  -0.13827794\n",
      "  0.14050876 -0.37857396]\n",
      "New theta_0 : [ 0.00908262  0.03700881  0.01556602  0.07613208  0.11029609  0.0319538\n",
      "  0.42365703 -0.01228343  0.01583307  0.09099713 -0.13852442 -0.13890792\n",
      "  0.14004638 -0.37943638]\n",
      "Training Error:  11.484517865783081\n",
      "====================================================================================================\n",
      "Iteration:  220\n",
      "Previous theta :  [ 0.00908262  0.03700881  0.01556602  0.07613208  0.11029609  0.0319538\n",
      "  0.42365703 -0.01228343  0.01583307  0.09099713 -0.13852442 -0.13890792\n",
      "  0.14004638 -0.37943638]\n",
      "New theta_0 : [ 0.00904831  0.03626445  0.01595463  0.07534582  0.11023045  0.03026648\n",
      "  0.42229738 -0.01250152  0.0132568   0.09216707 -0.13846828 -0.13953134\n",
      "  0.13958996 -0.3802865 ]\n",
      "Training Error:  11.471375981080673\n",
      "====================================================================================================\n",
      "Iteration:  221\n",
      "Previous theta :  [ 0.00904831  0.03626445  0.01595463  0.07534582  0.11023045  0.03026648\n",
      "  0.42229738 -0.01250152  0.0132568   0.09216707 -0.13846828 -0.13953134\n",
      "  0.13958996 -0.3802865 ]\n",
      "New theta_0 : [ 0.00901468  0.03552449  0.01634579  0.07456714  0.11016549  0.02858947\n",
      "  0.42095186 -0.01271258  0.01070103  0.09332991 -0.13841518 -0.14014828\n",
      "  0.13913938 -0.38112449]\n",
      "Training Error:  11.458431295607246\n",
      "====================================================================================================\n",
      "Iteration:  222\n",
      "Previous theta :  [ 0.00901468  0.03552449  0.01634579  0.07456714  0.11016549  0.02858947\n",
      "  0.42095186 -0.01271258  0.01070103  0.09332991 -0.13841518 -0.14014828\n",
      "  0.13913938 -0.38112449]\n",
      "New theta_0 : [ 0.00898173  0.03478891  0.01673937  0.07379599  0.1101012   0.02692271\n",
      "  0.4196203  -0.01291677  0.00816558  0.09448571 -0.13836508 -0.14075884\n",
      "  0.13869456 -0.38195053]\n",
      "Training Error:  11.445680609298188\n",
      "====================================================================================================\n",
      "Iteration:  223\n",
      "Previous theta :  [ 0.00898173  0.03478891  0.01673937  0.07379599  0.1101012   0.02692271\n",
      "  0.4196203  -0.01291677  0.00816558  0.09448571 -0.13836508 -0.14075884\n",
      "  0.13869456 -0.38195053]\n",
      "New theta_0 : [ 0.00894943  0.03405768  0.01713525  0.07303229  0.11003755  0.02526613\n",
      "  0.41830255 -0.01311422  0.00565028  0.09563451 -0.13831795 -0.14136309\n",
      "  0.13825537 -0.38276481]\n",
      "Training Error:  11.43312078043869\n",
      "====================================================================================================\n",
      "Iteration:  224\n",
      "Previous theta :  [ 0.00894943  0.03405768  0.01713525  0.07303229  0.11003755  0.02526613\n",
      "  0.41830255 -0.01311422  0.00565028  0.09563451 -0.13831795 -0.14136309\n",
      "  0.13825537 -0.38276481]\n",
      "New theta_0 : [ 0.00891776  0.03333078  0.01753331  0.072276    0.10997455  0.02361968\n",
      "  0.41699843 -0.01330507  0.00315494  0.09677636 -0.13827377 -0.14196112\n",
      "  0.13782171 -0.38356749]\n",
      "Training Error:  11.420748724414183\n",
      "====================================================================================================\n",
      "Iteration:  225\n",
      "Previous theta :  [ 0.00891776  0.03333078  0.01753331  0.072276    0.10997455  0.02361968\n",
      "  0.41699843 -0.01330507  0.00315494  0.09677636 -0.13827377 -0.14196112\n",
      "  0.13782171 -0.38356749]\n",
      "New theta_0 : [ 0.00888671  0.03260821  0.01793345  0.07152705  0.10991216  0.0219833\n",
      "  0.41570779 -0.01348948  0.0006794   0.0979113  -0.13823252 -0.14255301\n",
      "  0.13739349 -0.38435875]\n",
      "Training Error:  11.408561412492464\n",
      "====================================================================================================\n",
      "Iteration:  226\n",
      "Previous theta :  [ 0.00888671  0.03260821  0.01793345  0.07152705  0.10991216  0.0219833\n",
      "  0.41570779 -0.01348948  0.0006794   0.0979113  -0.13823252 -0.14255301\n",
      "  0.13739349 -0.38435875]\n",
      "New theta_0 : [ 0.00885627  0.03188993  0.01833554  0.07078538  0.10985038  0.02035693\n",
      "  0.41443048 -0.01366757 -0.0017765   0.09903939 -0.13819417 -0.14313884\n",
      "  0.13697061 -0.38513876]\n",
      "Training Error:  11.396555870636606\n",
      "====================================================================================================\n",
      "Iteration:  227\n",
      "Previous theta :  [ 0.00885627  0.03188993  0.01833554  0.07078538  0.10985038  0.02035693\n",
      "  0.41443048 -0.01366757 -0.0017765   0.09903939 -0.13819417 -0.14313884\n",
      "  0.13697061 -0.38513876]\n",
      "New theta_0 : [ 0.00882641  0.03117593  0.01873948  0.07005093  0.1097892   0.01874051\n",
      "  0.41316633 -0.01383947 -0.00421295  0.10016066 -0.13815869 -0.14371868\n",
      "  0.13655297 -0.38590768]\n",
      "Training Error:  11.384729178347735\n",
      "====================================================================================================\n",
      "Iteration:  228\n",
      "Previous theta :  [ 0.00882641  0.03117593  0.01873948  0.07005093  0.1097892   0.01874051\n",
      "  0.41316633 -0.01383947 -0.00421295  0.10016066 -0.13815869 -0.14371868\n",
      "  0.13655297 -0.38590768]\n",
      "New theta_0 : [ 0.00879713  0.03046619  0.01914516  0.06932364  0.1097286   0.01713399\n",
      "  0.4119152  -0.01400532 -0.0066301   0.10127518 -0.13812605 -0.14429261\n",
      "  0.13614048 -0.38666568]\n",
      "Training Error:  11.373078467536846\n",
      "====================================================================================================\n",
      "Iteration:  229\n",
      "Previous theta :  [ 0.00879713  0.03046619  0.01914516  0.06932364  0.1097286   0.01713399\n",
      "  0.4119152  -0.01400532 -0.0066301   0.10127518 -0.13812605 -0.14429261\n",
      "  0.13614048 -0.38666568]\n",
      "New theta_0 : [ 0.0087684   0.0297607   0.01955248  0.06860345  0.10966857  0.01553731\n",
      "  0.41067693 -0.01416525 -0.00902813  0.10238297 -0.13809624 -0.14486072\n",
      "  0.13573305 -0.38741292]\n",
      "Training Error:  11.361600921424786\n",
      "====================================================================================================\n",
      "Iteration:  230\n",
      "Previous theta :  [ 0.0087684   0.0297607   0.01955248  0.06860345  0.10966857  0.01553731\n",
      "  0.41067693 -0.01416525 -0.00902813  0.10238297 -0.13809624 -0.14486072\n",
      "  0.13573305 -0.38741292]\n",
      "New theta_0 : [ 0.00874022  0.02905942  0.01996134  0.06789031  0.1096091   0.01395041\n",
      "  0.40945137 -0.01431938 -0.01140719  0.1034841  -0.13806923 -0.14542306\n",
      "  0.13533059 -0.38814956]\n",
      "Training Error:  11.350293773469653\n",
      "====================================================================================================\n",
      "Iteration:  231\n",
      "Previous theta :  [ 0.00874022  0.02905942  0.01996134  0.06789031  0.1096091   0.01395041\n",
      "  0.40945137 -0.01431938 -0.01140719  0.1034841  -0.13806923 -0.14542306\n",
      "  0.13533059 -0.38814956]\n",
      "New theta_0 : [ 0.00871257  0.02836235  0.02037164  0.06718415  0.10955018  0.01237323\n",
      "  0.40823838 -0.01446784 -0.01376745  0.1045786  -0.13804498 -0.14597972\n",
      "  0.13493301 -0.38887575]\n",
      "Training Error:  11.339154306320763\n",
      "====================================================================================================\n",
      "Iteration:  232\n",
      "Previous theta :  [ 0.00871257  0.02836235  0.02037164  0.06718415  0.10955018  0.01237323\n",
      "  0.40823838 -0.01446784 -0.01376745  0.1045786  -0.13804498 -0.14597972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.13493301 -0.38887575]\n",
      "New theta_0 : [ 0.00868543  0.02766946  0.02078329  0.06648492  0.10949179  0.01080572\n",
      "  0.40703781 -0.01461075 -0.01610906  0.10566653 -0.13802348 -0.14653078\n",
      "  0.13454023 -0.38959166]\n",
      "Training Error:  11.328179850798483\n",
      "====================================================================================================\n",
      "Iteration:  233\n",
      "Previous theta :  [ 0.00868543  0.02766946  0.02078329  0.06648492  0.10949179  0.01080572\n",
      "  0.40703781 -0.01461075 -0.01610906  0.10566653 -0.13802348 -0.14653078\n",
      "  0.13454023 -0.38959166]\n",
      "New theta_0 : [ 0.0086588   0.02698073  0.02119618  0.06579256  0.10943394  0.00924782\n",
      "  0.40584952 -0.01474824 -0.0184322   0.10674793 -0.1380047  -0.14707629\n",
      "  0.13415216 -0.39029742]\n",
      "Training Error:  11.31736778489917\n",
      "====================================================================================================\n",
      "Iteration:  234\n",
      "Previous theta :  [ 0.0086588   0.02698073  0.02119618  0.06579256  0.10943394  0.00924782\n",
      "  0.40584952 -0.01474824 -0.0184322   0.10674793 -0.1380047  -0.14707629\n",
      "  0.13415216 -0.39029742]\n",
      "New theta_0 : [ 0.00863266  0.02629615  0.02161024  0.06510702  0.1093766   0.00769948\n",
      "  0.40467336 -0.0148804  -0.020737    0.10782284 -0.13798861 -0.14761633\n",
      "  0.13376873 -0.3909932 ]\n",
      "Training Error:  11.306715532824517\n",
      "====================================================================================================\n",
      "Iteration:  235\n",
      "Previous theta :  [ 0.00863266  0.02629615  0.02161024  0.06510702  0.1093766   0.00769948\n",
      "  0.40467336 -0.0148804  -0.020737    0.10782284 -0.13798861 -0.14761633\n",
      "  0.13376873 -0.3909932 ]\n",
      "New theta_0 : [ 0.008607    0.0256157   0.02202536  0.06442824  0.10931977  0.00616064\n",
      "  0.4035092  -0.01500737 -0.02302363  0.10889131 -0.13797519 -0.14815098\n",
      "  0.13338984 -0.39167913]\n",
      "Training Error:  11.296220564034602\n",
      "====================================================================================================\n",
      "Iteration:  236\n",
      "Previous theta :  [ 0.008607    0.0256157   0.02202536  0.06442824  0.10931977  0.00616064\n",
      "  0.4035092  -0.01500737 -0.02302363  0.10889131 -0.13797519 -0.14815098\n",
      "  0.13338984 -0.39167913]\n",
      "New theta_0 : [ 0.00858181  0.02493935  0.02244147  0.06375616  0.10926344  0.00463125\n",
      "  0.4023569  -0.01512926 -0.02529225  0.10995338 -0.13796441 -0.14868029\n",
      "  0.13301544 -0.39235537]\n",
      "Training Error:  11.285880392323982\n",
      "====================================================================================================\n",
      "Iteration:  237\n",
      "Previous theta :  [ 0.00858181  0.02493935  0.02244147  0.06375616  0.10926344  0.00463125\n",
      "  0.4023569  -0.01512926 -0.02529225  0.10995338 -0.13796441 -0.14868029\n",
      "  0.13301544 -0.39235537]\n",
      "New theta_0 : [ 0.00855707  0.02426709  0.02285848  0.06309072  0.10920759  0.00311124\n",
      "  0.40121631 -0.01524617 -0.027543    0.11100911 -0.13795625 -0.14920434\n",
      "  0.13264544 -0.39302206]\n",
      "Training Error:  11.275692574920205\n",
      "====================================================================================================\n",
      "Iteration:  238\n",
      "Previous theta :  [ 0.00855707  0.02426709  0.02285848  0.06309072  0.10920759  0.00311124\n",
      "  0.40121631 -0.01524617 -0.027543    0.11100911 -0.13795625 -0.14920434\n",
      "  0.13264544 -0.39302206]\n",
      "New theta_0 : [ 0.00853278  0.0235989   0.02327631  0.06243188  0.10915223  0.00160057\n",
      "  0.40008731 -0.01535822 -0.02977604  0.11205854 -0.13795067 -0.1497232\n",
      "  0.13227976 -0.39367933]\n",
      "Training Error:  11.265654711604068\n",
      "====================================================================================================\n",
      "Iteration:  239\n",
      "Previous theta :  [ 0.00853278  0.0235989   0.02327631  0.06243188  0.10915223  0.00160057\n",
      "  0.40008731 -0.01535822 -0.02977604  0.11205854 -0.13795067 -0.1497232\n",
      "  0.13227976 -0.39367933]\n",
      "New theta_0 : [ 8.50892555e-03  2.29347569e-02  2.36948694e-02  6.17795711e-02\n",
      "  1.09097333e-01  9.91872342e-05  3.98969756e-01 -1.54655051e-02\n",
      " -3.19915088e-02  1.13101709e-01 -1.37947663e-01 -1.50236916e-01\n",
      "  1.31918336e-01 -3.94327326e-01]\n",
      "Training Error:  11.255764443851065\n",
      "====================================================================================================\n",
      "Iteration:  240\n",
      "Previous theta :  [ 8.50892555e-03  2.29347569e-02  2.36948694e-02  6.17795711e-02\n",
      "  1.09097333e-01  9.91872342e-05  3.98969756e-01 -1.54655051e-02\n",
      " -3.19915088e-02  1.13101709e-01 -1.37947663e-01 -1.50236916e-01\n",
      "  1.31918336e-01 -3.94327326e-01]\n",
      "New theta_0 : [ 0.00848549  0.02227464  0.02411409  0.06113375  0.1090429  -0.00139297\n",
      "  0.39786353 -0.01556814 -0.03418956  0.11413866 -0.13794719 -0.15074557\n",
      "  0.1315611  -0.39496619]\n",
      "Training Error:  11.246019453993393\n",
      "====================================================================================================\n",
      "Iteration:  241\n",
      "Previous theta :  [ 0.00848549  0.02227464  0.02411409  0.06113375  0.1090429  -0.00139297\n",
      "  0.39786353 -0.01556814 -0.03418956  0.11413866 -0.13794719 -0.15074557\n",
      "  0.1315611  -0.39496619]\n",
      "New theta_0 : [ 0.00846247  0.02161854  0.0245339   0.06049435  0.10898893 -0.00287595\n",
      "  0.39676848 -0.01566622 -0.03637035  0.11516945 -0.13794923 -0.15124921\n",
      "  0.13120797 -0.39559604]\n",
      "Training Error:  11.236417464401972\n",
      "====================================================================================================\n",
      "Iteration:  242\n",
      "Previous theta :  [ 0.00846247  0.02161854  0.0245339   0.06049435  0.10898893 -0.00287595\n",
      "  0.39676848 -0.01566622 -0.03637035  0.11516945 -0.13794923 -0.15124921\n",
      "  0.13120797 -0.39559604]\n",
      "New theta_0 : [ 0.00843986  0.02096643  0.02495422  0.05986133  0.1089354  -0.00434981\n",
      "  0.39568451 -0.01575986 -0.03853401  0.11619411 -0.13795377 -0.15174792\n",
      "  0.13085889 -0.39621703]\n",
      "Training Error:  11.22695623668792\n",
      "====================================================================================================\n",
      "Iteration:  243\n",
      "Previous theta :  [ 0.00843986  0.02096643  0.02495422  0.05986133  0.1089354  -0.00434981\n",
      "  0.39568451 -0.01575986 -0.03853401  0.11619411 -0.13795377 -0.15174792\n",
      "  0.13085889 -0.39621703]\n",
      "New theta_0 : [ 0.00841764  0.0203183   0.02537497  0.05923464  0.10888231 -0.00581461\n",
      "  0.39461146 -0.01584914 -0.04068069  0.11721269 -0.13796076 -0.15224174\n",
      "  0.13051379 -0.39682928]\n",
      "Training Error:  11.217633570922937\n",
      "====================================================================================================\n",
      "Iteration:  244\n",
      "Previous theta :  [ 0.00841764  0.0203183   0.02537497  0.05923464  0.10888231 -0.00581461\n",
      "  0.39461146 -0.01584914 -0.04068069  0.11721269 -0.13796076 -0.15224174\n",
      "  0.13051379 -0.39682928]\n",
      "New theta_0 : [ 0.0083958   0.01967411  0.02579609  0.05861421  0.10882966 -0.00727038\n",
      "  0.39354923 -0.01593417 -0.04281053  0.11822524 -0.13797019 -0.15273074\n",
      "  0.13017261 -0.39743291]\n",
      "Training Error:  11.208447304878089\n",
      "====================================================================================================\n",
      "Iteration:  245\n",
      "Previous theta :  [ 0.0083958   0.01967411  0.02579609  0.05861421  0.10882966 -0.00727038\n",
      "  0.39354923 -0.01593417 -0.04281053  0.11822524 -0.13797019 -0.15273074\n",
      "  0.13017261 -0.39743291]\n",
      "New theta_0 : [ 0.00837434  0.01903386  0.02621752  0.058       0.10877743 -0.0087172\n",
      "  0.39249768 -0.01601504 -0.04492368  0.11923179 -0.13798204 -0.15321498\n",
      "  0.12983528 -0.39802806]\n",
      "Training Error:  11.199395313280482\n",
      "====================================================================================================\n",
      "Iteration:  246\n",
      "Previous theta :  [ 0.00837434  0.01903386  0.02621752  0.058       0.10877743 -0.0087172\n",
      "  0.39249768 -0.01601504 -0.04492368  0.11923179 -0.13798204 -0.15321498\n",
      "  0.12983528 -0.39802806]\n",
      "New theta_0 : [ 0.00835325  0.01839753  0.02663917  0.05739195  0.10872562 -0.0101551\n",
      "  0.39145669 -0.01609184 -0.04702026  0.1202324  -0.13799627 -0.15369452\n",
      "  0.12950173 -0.39861484]\n",
      "Training Error:  11.190475507087344\n",
      "====================================================================================================\n",
      "Iteration:  247\n",
      "Previous theta :  [ 0.00835325  0.01839753  0.02663917  0.05739195  0.10872562 -0.0101551\n",
      "  0.39145669 -0.01609184 -0.04702026  0.1202324  -0.13799627 -0.15369452\n",
      "  0.12950173 -0.39861484]\n",
      "New theta_0 : [ 0.00833251  0.0177651   0.027061    0.05679001  0.10867422 -0.01158414\n",
      "  0.39042615 -0.01616467 -0.04910043  0.12122709 -0.13801287 -0.15416942\n",
      "  0.12917192 -0.39919339]\n",
      "Training Error:  11.181685832777022\n",
      "====================================================================================================\n",
      "Iteration:  248\n",
      "Previous theta :  [ 0.00833251  0.0177651   0.027061    0.05679001  0.10867422 -0.01158414\n",
      "  0.39042615 -0.01616467 -0.04910043  0.12122709 -0.13801287 -0.15416942\n",
      "  0.12917192 -0.39919339]\n",
      "New theta_0 : [ 0.00831213  0.01713654  0.02748292  0.05619414  0.10862322 -0.01300438\n",
      "  0.38940593 -0.01623361 -0.05116431  0.12221593 -0.1380318  -0.15463972\n",
      "  0.12884578 -0.39976382]\n",
      "Training Error:  11.173024271656464\n",
      "====================================================================================================\n",
      "Iteration:  249\n",
      "Previous theta :  [ 0.00831213  0.01713654  0.02748292  0.05619414  0.10862322 -0.01300438\n",
      "  0.38940593 -0.01623361 -0.05116431  0.12221593 -0.1380318  -0.15463972\n",
      "  0.12884578 -0.39976382]\n",
      "New theta_0 : [ 0.00829208  0.01651184  0.0279049   0.05560428  0.10857263 -0.01441586\n",
      "  0.38839593 -0.01629876 -0.05321205  0.12319894 -0.13805305 -0.1551055\n",
      "  0.12852325 -0.40032625]\n",
      "Training Error:  11.16448883918471\n",
      "====================================================================================================\n",
      "Iteration:  250\n",
      "Previous theta :  [ 0.00829208  0.01651184  0.0279049   0.05560428  0.10857263 -0.01441586\n",
      "  0.38839593 -0.01629876 -0.05321205  0.12319894 -0.13805305 -0.1551055\n",
      "  0.12852325 -0.40032625]\n",
      "New theta_0 : [ 0.00827238  0.01589098  0.02832685  0.05502038  0.10852243 -0.01581863\n",
      "  0.38739601 -0.0163602  -0.05524378  0.12417617 -0.13807659 -0.1555668\n",
      "  0.12820427 -0.4008808 ]\n",
      "Training Error:  11.15607758431197\n",
      "====================================================================================================\n",
      "Iteration:  251\n",
      "Previous theta :  [ 0.00827238  0.01589098  0.02832685  0.05502038  0.10852243 -0.01581863\n",
      "  0.38739601 -0.0163602  -0.05524378  0.12417617 -0.13807659 -0.1555668\n",
      "  0.12820427 -0.4008808 ]\n",
      "New theta_0 : [ 0.00825299  0.01527393  0.02874874  0.05444239  0.10847261 -0.01721275\n",
      "  0.38640607 -0.01641801 -0.05725962  0.12514767 -0.13810239 -0.15602368\n",
      "  0.1278888  -0.40142758]\n",
      "Training Error:  11.147788588833881\n",
      "====================================================================================================\n",
      "Iteration:  252\n",
      "Previous theta :  [ 0.00825299  0.01527393  0.02874874  0.05444239  0.10847261 -0.01721275\n",
      "  0.38640607 -0.01641801 -0.05725962  0.12514767 -0.13810239 -0.15602368\n",
      "  0.1278888  -0.40142758]\n",
      "New theta_0 : [ 0.00823393  0.0146607   0.02917049  0.05387026  0.10842318 -0.01859826\n",
      "  0.38542599 -0.01647228 -0.05925972  0.12611348 -0.13813043 -0.15647619\n",
      "  0.12757677 -0.40196671]\n",
      "Training Error:  11.139619966760536\n",
      "====================================================================================================\n",
      "Iteration:  253\n",
      "Previous theta :  [ 0.00823393  0.0146607   0.02917049  0.05387026  0.10842318 -0.01859826\n",
      "  0.38542599 -0.01647228 -0.05925972  0.12611348 -0.13813043 -0.15647619\n",
      "  0.12757677 -0.40196671]\n",
      "New theta_0 : [ 0.00821518  0.01405124  0.02959206  0.05330394  0.10837412 -0.01997522\n",
      "  0.38445567 -0.01652309 -0.0612442   0.12707363 -0.13816069 -0.15692439\n",
      "  0.12726813 -0.4024983 ]\n",
      "Training Error:  11.131569863699836\n",
      "====================================================================================================\n",
      "Iteration:  254\n",
      "Previous theta :  [ 0.00821518  0.01405124  0.02959206  0.05330394  0.10837412 -0.01997522\n",
      "  0.38445567 -0.01652309 -0.0612442   0.12707363 -0.13816069 -0.15692439\n",
      "  0.12726813 -0.4024983 ]\n",
      "New theta_0 : [ 0.00819673  0.01344555  0.03001339  0.05274338  0.10832543 -0.02134367\n",
      "  0.38349498 -0.01657052 -0.0632132   0.12802817 -0.13819314 -0.15736833\n",
      "  0.12696283 -0.40302246]\n",
      "Training Error:  11.123636456254882\n",
      "====================================================================================================\n",
      "Iteration:  255\n",
      "Previous theta :  [ 0.00819673  0.01344555  0.03001339  0.05274338  0.10832543 -0.02134367\n",
      "  0.38349498 -0.01657052 -0.0632132   0.12802817 -0.13819314 -0.15736833\n",
      "  0.12696283 -0.40302246]\n",
      "New theta_0 : [ 0.00817858  0.0128436   0.03043443  0.05218853  0.10827711 -0.02270367\n",
      "  0.38254383 -0.01661464 -0.06516683  0.12897713 -0.13822776 -0.15780805\n",
      "  0.12666082 -0.40353929]\n",
      "Training Error:  11.115817951434936\n",
      "====================================================================================================\n",
      "Iteration:  256\n",
      "Previous theta :  [ 0.00817858  0.0128436   0.03043443  0.05218853  0.10827711 -0.02270367\n",
      "  0.38254383 -0.01661464 -0.06516683  0.12897713 -0.13822776 -0.15780805\n",
      "  0.12666082 -0.40353929]\n",
      "New theta_0 : [ 0.00816073  0.01224538  0.03085513  0.05163935  0.10822915 -0.02405526\n",
      "  0.38160211 -0.01665554 -0.06710523  0.12992057 -0.13826453 -0.15824362\n",
      "  0.12636204 -0.40404891]\n",
      "Training Error:  11.108112586079647\n",
      "====================================================================================================\n",
      "Iteration:  257\n",
      "Previous theta :  [ 0.00816073  0.01224538  0.03085513  0.05163935  0.10822915 -0.02405526\n",
      "  0.38160211 -0.01665554 -0.06710523  0.12992057 -0.13826453 -0.15824362\n",
      "  0.12636204 -0.40404891]\n",
      "New theta_0 : [ 0.00814315  0.01165086  0.03127544  0.05109579  0.10818154 -0.0253985\n",
      "  0.3806697  -0.01669329 -0.06902853  0.13085853 -0.13830341 -0.15867508\n",
      "  0.12606646 -0.40455142]\n",
      "Training Error:  11.100518626296187\n",
      "====================================================================================================\n",
      "Iteration:  258\n",
      "Previous theta :  [ 0.00814315  0.01165086  0.03127544  0.05109579  0.10818154 -0.0253985\n",
      "  0.3806697  -0.01669329 -0.06902853  0.13085853 -0.13830341 -0.15867508\n",
      "  0.12606646 -0.40455142]\n",
      "New theta_0 : [ 0.00812586  0.01106003  0.03169532  0.05055779  0.10813429 -0.02673342\n",
      "  0.37974651 -0.01672796 -0.07093685  0.13179103 -0.1383444  -0.15910247\n",
      "  0.12577402 -0.40504692]\n",
      "Training Error:  11.093034366908926\n",
      "====================================================================================================\n",
      "Iteration:  259\n",
      "Previous theta :  [ 0.00812586  0.01106003  0.03169532  0.05055779  0.10813429 -0.02673342\n",
      "  0.37974651 -0.01672796 -0.07093685  0.13179103 -0.1383444  -0.15910247\n",
      "  0.12577402 -0.40504692]\n",
      "New theta_0 : [ 0.00810884  0.01047288  0.03211471  0.05002531  0.10808737 -0.02806009\n",
      "  0.37883243 -0.01675963 -0.0728303   0.13271812 -0.13838746 -0.15952586\n",
      "  0.12548468 -0.40553551]\n",
      "Training Error:  11.08565813092135\n",
      "====================================================================================================\n",
      "Iteration:  260\n",
      "Previous theta :  [ 0.00810884  0.01047288  0.03211471  0.05002531  0.10808737 -0.02806009\n",
      "  0.37883243 -0.01675963 -0.0728303   0.13271812 -0.13838746 -0.15952586\n",
      "  0.12548468 -0.40553551]\n",
      "New theta_0 : [ 0.00809208  0.00988937  0.03253357  0.04949831  0.1080408  -0.02937855\n",
      "  0.37792735 -0.01678836 -0.07470903  0.13363984 -0.13843256 -0.15994528\n",
      "  0.12519838 -0.4060173 ]\n",
      "Training Error:  11.078388268989904\n",
      "====================================================================================================\n",
      "Iteration:  261\n",
      "Previous theta :  [ 0.00809208  0.00988937  0.03253357  0.04949831  0.1080408  -0.02937855\n",
      "  0.37792735 -0.01678836 -0.07470903  0.13363984 -0.13843256 -0.15994528\n",
      "  0.12519838 -0.4060173 ]\n",
      "New theta_0 : [ 0.00807558  0.00930949  0.03295186  0.04897674  0.10799457 -0.03068884\n",
      "  0.37703119 -0.01681423 -0.07657313  0.13455624 -0.1384797  -0.16036079\n",
      "  0.12491509 -0.40649239]\n",
      "Training Error:  11.071223158909387\n",
      "====================================================================================================\n",
      "Iteration:  262\n",
      "Previous theta :  [ 0.00807558  0.00930949  0.03295186  0.04897674  0.10799457 -0.03068884\n",
      "  0.37703119 -0.01681423 -0.07657313  0.13455624 -0.1384797  -0.16036079\n",
      "  0.12491509 -0.40649239]\n",
      "New theta_0 : [ 0.00805934  0.00873323  0.03336953  0.04846055  0.10794866 -0.03199101\n",
      "  0.37614383 -0.01683731 -0.07842275  0.13546734 -0.13852885 -0.16077242\n",
      "  0.12463476 -0.40696087]\n",
      "Training Error:  11.064161205109702\n",
      "====================================================================================================\n",
      "Iteration:  263\n",
      "Previous theta :  [ 0.00805934  0.00873323  0.03336953  0.04846055  0.10794866 -0.03199101\n",
      "  0.37614383 -0.01683731 -0.07842275  0.13546734 -0.13852885 -0.16077242\n",
      "  0.12463476 -0.40696087]\n",
      "New theta_0 : [ 0.00804335  0.00816056  0.03378655  0.04794969  0.10790309 -0.03328512\n",
      "  0.37526518 -0.01685765 -0.08025799  0.1363732  -0.13857997 -0.16118024\n",
      "  0.12435734 -0.40742284]\n",
      "Training Error:  11.057200838163569\n",
      "====================================================================================================\n",
      "Iteration:  264\n",
      "Previous theta :  [ 0.00804335  0.00816056  0.03378655  0.04794969  0.10790309 -0.03328512\n",
      "  0.37526518 -0.01685765 -0.08025799  0.1363732  -0.13857997 -0.16118024\n",
      "  0.12435734 -0.40742284]\n",
      "New theta_0 : [ 0.0080276   0.00759147  0.03420287  0.04744412  0.10785784 -0.0345712\n",
      "  0.37439514 -0.01687534 -0.08207897  0.13727383 -0.13863306 -0.16158427\n",
      "  0.1240828  -0.40787839]\n",
      "Training Error:  11.050340514304976\n",
      "====================================================================================================\n",
      "Iteration:  265\n",
      "Previous theta :  [ 0.0080276   0.00759147  0.03420287  0.04744412  0.10785784 -0.0345712\n",
      "  0.37439514 -0.01687534 -0.08207897  0.13727383 -0.13863306 -0.16158427\n",
      "  0.1240828  -0.40787839]\n",
      "New theta_0 : [ 0.0080121   0.00702594  0.03461846  0.0469438   0.1078129  -0.03584932\n",
      "  0.37353362 -0.01689042 -0.08388581  0.1381693  -0.13868808 -0.16198457\n",
      "  0.12381109 -0.40832761]\n",
      "Training Error:  11.043578714958079\n",
      "====================================================================================================\n",
      "Iteration:  266\n",
      "Previous theta :  [ 0.0080121   0.00702594  0.03461846  0.0469438   0.1078129  -0.03584932\n",
      "  0.37353362 -0.01689042 -0.08388581  0.1381693  -0.13868808 -0.16198457\n",
      "  0.12381109 -0.40832761]\n",
      "New theta_0 : [ 0.00799682  0.00646394  0.03503327  0.04644868  0.10776829 -0.0371195\n",
      "  0.37268052 -0.01690297 -0.08567862  0.13905963 -0.13874502 -0.16238119\n",
      "  0.12354217 -0.40877061]\n",
      "Training Error:  11.036913946276252\n",
      "====================================================================================================\n",
      "Iteration:  267\n",
      "Previous theta :  [ 0.00799682  0.00646394  0.03503327  0.04644868  0.10776829 -0.0371195\n",
      "  0.37268052 -0.01690297 -0.08567862  0.13905963 -0.13874502 -0.16238119\n",
      "  0.12354217 -0.40877061]\n",
      "New theta_0 : [ 0.00798177  0.00590546  0.03544728  0.04595871  0.10772398 -0.0383818\n",
      "  0.37183574 -0.01691304 -0.08745753  0.13994486 -0.13880386 -0.16277415\n",
      "  0.12327601 -0.40920746]\n",
      "Training Error:  11.030344738691094\n",
      "====================================================================================================\n",
      "Iteration:  268\n",
      "Previous theta :  [ 0.00798177  0.00590546  0.03544728  0.04595871  0.10772398 -0.0383818\n",
      "  0.37183574 -0.01691304 -0.08745753  0.13994486 -0.13880386 -0.16277415\n",
      "  0.12327601 -0.40920746]\n",
      "New theta_0 : [ 0.00796695  0.00535049  0.03586044  0.04547385  0.10767998 -0.03963627\n",
      "  0.3709992  -0.0169207  -0.08922264  0.14082503 -0.13886456 -0.16316351\n",
      "  0.12301256 -0.40963826]\n",
      "Training Error:  11.023869646471054\n",
      "====================================================================================================\n",
      "Iteration:  269\n",
      "Previous theta :  [ 0.00796695  0.00535049  0.03586044  0.04547385  0.10767998 -0.03963627\n",
      "  0.3709992  -0.0169207  -0.08922264  0.14082503 -0.13886456 -0.16316351\n",
      "  0.12301256 -0.40963826]\n",
      "New theta_0 : [ 0.00795234  0.004799    0.03627272  0.04499405  0.10763629 -0.04088294\n",
      "  0.3701708  -0.01692601 -0.09097406  0.14170017 -0.13892712 -0.16354931\n",
      "  0.12275178 -0.41006309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  11.017487247289516\n",
      "====================================================================================================\n",
      "Iteration:  270\n",
      "Previous theta :  [ 0.00795234  0.004799    0.03627272  0.04499405  0.10763629 -0.04088294\n",
      "  0.3701708  -0.01692601 -0.09097406  0.14170017 -0.13892712 -0.16354931\n",
      "  0.12275178 -0.41006309]\n",
      "New theta_0 : [ 0.00793795  0.00425097  0.03668409  0.04451928  0.10759289 -0.04212187\n",
      "  0.36935045 -0.01692902 -0.09271191  0.14257033 -0.1389915  -0.16393159\n",
      "  0.12249364 -0.41048205]\n",
      "Training Error:  11.011196141802031\n",
      "====================================================================================================\n",
      "Iteration:  271\n",
      "Previous theta :  [ 0.00793795  0.00425097  0.03668409  0.04451928  0.10759289 -0.04212187\n",
      "  0.36935045 -0.01692902 -0.09271191  0.14257033 -0.1389915  -0.16393159\n",
      "  0.12249364 -0.41048205]\n",
      "New theta_0 : [ 0.00792377  0.00370639  0.03709452  0.04404949  0.10754979 -0.04335311\n",
      "  0.36853807 -0.01692979 -0.0944363   0.14343554 -0.1390577  -0.16431039\n",
      "  0.1222381  -0.41089521]\n",
      "Training Error:  11.004994953232513\n",
      "====================================================================================================\n",
      "Iteration:  272\n",
      "Previous theta :  [ 0.00792377  0.00370639  0.03709452  0.04404949  0.10754979 -0.04335311\n",
      "  0.36853807 -0.01692979 -0.0944363   0.14343554 -0.1390577  -0.16431039\n",
      "  0.1222381  -0.41089521]\n",
      "New theta_0 : [ 0.0079098   0.00316523  0.03750397  0.04358463  0.10750699 -0.04457669\n",
      "  0.36773357 -0.01692838 -0.09614734  0.14429583 -0.13912567 -0.16468576\n",
      "  0.12198513 -0.41130267]\n",
      "Training Error:  10.998882326968161\n",
      "====================================================================================================\n",
      "Iteration:  273\n",
      "Previous theta :  [ 0.0079098   0.00316523  0.03750397  0.04358463  0.10750699 -0.04457669\n",
      "  0.36773357 -0.01692838 -0.09614734  0.14429583 -0.13912567 -0.16468576\n",
      "  0.12198513 -0.41130267]\n",
      "New theta_0 : [ 0.00789602  0.00262749  0.03791241  0.04312467  0.10746447 -0.04579266\n",
      "  0.36693685 -0.01692484 -0.09784514  0.14515125 -0.13919541 -0.16505772\n",
      "  0.12173469 -0.41170449]\n",
      "Training Error:  10.99285693016287\n",
      "====================================================================================================\n",
      "Iteration:  274\n",
      "Previous theta :  [ 0.00789602  0.00262749  0.03791241  0.04312467  0.10746447 -0.04579266\n",
      "  0.36693685 -0.01692484 -0.09784514  0.14515125 -0.13919541 -0.16505772\n",
      "  0.12173469 -0.41170449]\n",
      "New theta_0 : [ 0.00788245  0.00209314  0.03831982  0.04266956  0.10742225 -0.04700106\n",
      "  0.36614783 -0.01691922 -0.0995298   0.14600182 -0.1392669  -0.16542633\n",
      "  0.12148674 -0.41210078]\n",
      "Training Error:  10.986917451348951\n",
      "====================================================================================================\n",
      "Iteration:  275\n",
      "Previous theta :  [ 0.00788245  0.00209314  0.03831982  0.04266956  0.10742225 -0.04700106\n",
      "  0.36614783 -0.01691922 -0.0995298   0.14600182 -0.1392669  -0.16542633\n",
      "  0.12148674 -0.41210078]\n",
      "New theta_0 : [ 0.00786906  0.00156216  0.03872616  0.04221925  0.1073803  -0.04820195\n",
      "  0.36536643 -0.01691159 -0.10120143  0.14684759 -0.13934011 -0.16579161\n",
      "  0.12124125 -0.41249159]\n",
      "Training Error:  10.98106260005693\n",
      "====================================================================================================\n",
      "Iteration:  276\n",
      "Previous theta :  [ 0.00786906  0.00156216  0.03872616  0.04221925  0.1073803  -0.04820195\n",
      "  0.36536643 -0.01691159 -0.10120143  0.14684759 -0.13934011 -0.16579161\n",
      "  0.12124125 -0.41249159]\n",
      "New theta_0 : [ 0.00785587  0.00103453  0.03913141  0.04177372  0.10733864 -0.04939536\n",
      "  0.36459257 -0.01690198 -0.10286014  0.14768859 -0.13941502 -0.16615361\n",
      "  0.12099819 -0.41287702]\n",
      "Training Error:  10.975291106443239\n",
      "====================================================================================================\n",
      "Iteration:  277\n",
      "Previous theta :  [ 0.00785587  0.00103453  0.03913141  0.04177372  0.10733864 -0.04939536\n",
      "  0.36459257 -0.01690198 -0.10286014  0.14768859 -0.13941502 -0.16615361\n",
      "  0.12099819 -0.41287702]\n",
      "New theta_0 : [ 0.00784286  0.00051024  0.03953554  0.04133291  0.10729725 -0.05058134\n",
      "  0.36382615 -0.01689045 -0.10450603  0.14852485 -0.13949161 -0.16651237\n",
      "  0.12075752 -0.41325714]\n",
      "Training Error:  10.969601720925578\n",
      "====================================================================================================\n",
      "Iteration:  278\n",
      "Previous theta :  [ 0.00784286  0.00051024  0.03953554  0.04133291  0.10729725 -0.05058134\n",
      "  0.36382615 -0.01689045 -0.10450603  0.14852485 -0.13949161 -0.16651237\n",
      "  0.12075752 -0.41325714]\n",
      "New theta_0 : [ 7.83003077e-03 -1.07305792e-05  3.99385312e-02  4.08967793e-02\n",
      "  1.07256136e-01 -5.17599363e-02  3.63067105e-01 -1.68770557e-02\n",
      " -1.06139200e-01  1.49356407e-01 -1.39569868e-01 -1.66867922e-01\n",
      "  1.20519221e-01 -4.13632028e-01]\n",
      "Training Error:  10.96399321382582\n",
      "====================================================================================================\n",
      "Iteration:  279\n",
      "Previous theta :  [ 7.83003077e-03 -1.07305792e-05  3.99385312e-02  4.08967793e-02\n",
      "  1.07256136e-01 -5.17599363e-02  3.63067105e-01 -1.68770557e-02\n",
      " -1.06139200e-01  1.49356407e-01 -1.39569868e-01 -1.66867922e-01\n",
      "  1.20519221e-01 -4.13632028e-01]\n",
      "New theta_0 : [ 0.00781738 -0.0005284   0.04034035  0.0404653   0.10721529 -0.05293118\n",
      "  0.36231535 -0.01686184 -0.10775976  0.1501833  -0.13964976 -0.1672203\n",
      "  0.12028325 -0.41400176]\n",
      "Training Error:  10.95846437502018\n",
      "====================================================================================================\n",
      "Iteration:  280\n",
      "Previous theta :  [ 0.00781738 -0.0005284   0.04034035  0.0404653   0.10721529 -0.05293118\n",
      "  0.36231535 -0.01686184 -0.10775976  0.1501833  -0.13964976 -0.1672203\n",
      "  0.12028325 -0.41400176]\n",
      "New theta_0 : [ 0.0078049  -0.00104279  0.04074098  0.04003841  0.10717472 -0.05409513\n",
      "  0.3615708  -0.01684484 -0.10936781  0.15100556 -0.13973128 -0.16756955\n",
      "  0.12004958 -0.41436641]\n",
      "Training Error:  10.95301401359659\n",
      "====================================================================================================\n",
      "Iteration:  281\n",
      "Previous theta :  [ 0.0078049  -0.00104279  0.04074098  0.04003841  0.10717472 -0.05409513\n",
      "  0.3615708  -0.01684484 -0.10936781  0.15100556 -0.13973128 -0.16756955\n",
      "  0.12004958 -0.41436641]\n",
      "New theta_0 : [ 0.0077926  -0.00155391  0.04114038  0.0396161   0.10713441 -0.05525182\n",
      "  0.36083338 -0.01682612 -0.11096346  0.15182322 -0.1398144  -0.16791569\n",
      "  0.11981817 -0.41472605]\n",
      "Training Error:  10.947640957518976\n",
      "====================================================================================================\n",
      "Iteration:  282\n",
      "Previous theta :  [ 0.0077926  -0.00155391  0.04114038  0.0396161   0.10713441 -0.05525182\n",
      "  0.36083338 -0.01682612 -0.11096346  0.15182322 -0.1398144  -0.16791569\n",
      "  0.11981817 -0.41472605]\n",
      "New theta_0 : [ 0.00778046 -0.00206179  0.04153855  0.0391983   0.10709437 -0.05640129\n",
      "  0.36010301 -0.01680572 -0.11254679  0.15263632 -0.1398991  -0.16825878\n",
      "  0.11958901 -0.41508075]\n",
      "Training Error:  10.942344053298378\n",
      "====================================================================================================\n",
      "Iteration:  283\n",
      "Previous theta :  [ 0.00778046 -0.00206179  0.04153855  0.0391983   0.10709437 -0.05640129\n",
      "  0.36010301 -0.01680572 -0.11254679  0.15263632 -0.1398991  -0.16825878\n",
      "  0.11958901 -0.41508075]\n",
      "New theta_0 : [ 0.00776848 -0.00256644  0.04193546  0.03878499  0.10705458 -0.05754359\n",
      "  0.35937962 -0.01678368 -0.11411792  0.15344489 -0.13998537 -0.16859883\n",
      "  0.11936206 -0.41543058]\n",
      "Training Error:  10.937122165670687\n",
      "====================================================================================================\n",
      "Iteration:  284\n",
      "Previous theta :  [ 0.00776848 -0.00256644  0.04193546  0.03878499  0.10705458 -0.05754359\n",
      "  0.35937962 -0.01678368 -0.11411792  0.15344489 -0.13998537 -0.16859883\n",
      "  0.11936206 -0.41543058]\n",
      "New theta_0 : [ 0.00775667 -0.00306788  0.04233109  0.03837612  0.10701505 -0.05867876\n",
      "  0.35866312 -0.01676004 -0.11567693  0.15424896 -0.14007318 -0.16893589\n",
      "  0.11913729 -0.41577562]\n",
      "Training Error:  10.931974177280852\n",
      "====================================================================================================\n",
      "Iteration:  285\n",
      "Previous theta :  [ 0.00775667 -0.00306788  0.04233109  0.03837612  0.10701505 -0.05867876\n",
      "  0.35866312 -0.01676004 -0.11567693  0.15424896 -0.14007318 -0.16893589\n",
      "  0.11913729 -0.41577562]\n",
      "New theta_0 : [ 0.00774501 -0.00356613  0.04272541  0.03797165  0.10697577 -0.05980684\n",
      "  0.35795345 -0.01673485 -0.11722394  0.15504856 -0.14016251 -0.16926999\n",
      "  0.11891467 -0.41611593]\n",
      "Training Error:  10.926898988373422\n",
      "====================================================================================================\n",
      "Iteration:  286\n",
      "Previous theta :  [ 0.00774501 -0.00356613  0.04272541  0.03797165  0.10697577 -0.05980684\n",
      "  0.35795345 -0.01673485 -0.11722394  0.15504856 -0.14016251 -0.16926999\n",
      "  0.11891467 -0.41611593]\n",
      "New theta_0 : [ 0.00773351 -0.0040612   0.04311842  0.03757155  0.10693675 -0.06092787\n",
      "  0.35725053 -0.01670816 -0.11875902  0.15584373 -0.14025335 -0.16960116\n",
      "  0.11869419 -0.41645158]\n",
      "Training Error:  10.92189551648925\n",
      "====================================================================================================\n",
      "Iteration:  287\n",
      "Previous theta :  [ 0.00773351 -0.0040612   0.04311842  0.03757155  0.10693675 -0.06092787\n",
      "  0.35725053 -0.01670816 -0.11875902  0.15584373 -0.14025335 -0.16960116\n",
      "  0.11869419 -0.41645158]\n",
      "New theta_0 : [ 0.00772216 -0.00455312  0.04351008  0.03717578  0.10689798 -0.0620419\n",
      "  0.35655429 -0.01668    -0.12028228  0.1566345  -0.14034568 -0.16992944\n",
      "  0.1184758  -0.41678264]\n",
      "Training Error:  10.916962696168207\n",
      "====================================================================================================\n",
      "Iteration:  288\n",
      "Previous theta :  [ 0.00772216 -0.00455312  0.04351008  0.03717578  0.10689798 -0.0620419\n",
      "  0.35655429 -0.01668    -0.12028228  0.1566345  -0.14034568 -0.16992944\n",
      "  0.1184758  -0.41678264]\n",
      "New theta_0 : [ 0.00771096 -0.00504189  0.04390038  0.0367843   0.10685945 -0.06314896\n",
      "  0.35586465 -0.01665041 -0.12179382  0.15742091 -0.14043947 -0.17025485\n",
      "  0.11825948 -0.41710917]\n",
      "Training Error:  10.912099478657801\n",
      "====================================================================================================\n",
      "Iteration:  289\n",
      "Previous theta :  [ 0.00771096 -0.00504189  0.04390038  0.0367843   0.10685945 -0.06314896\n",
      "  0.35586465 -0.01665041 -0.12179382  0.15742091 -0.14043947 -0.17025485\n",
      "  0.11825948 -0.41710917]\n",
      "New theta_0 : [ 0.0076999  -0.00552755  0.04428931  0.03639707  0.10682117 -0.0642491\n",
      "  0.35518154 -0.01661943 -0.12329373  0.15820297 -0.14053472 -0.17057743\n",
      "  0.11804521 -0.41743124]\n",
      "Training Error:  10.907304831627519\n",
      "====================================================================================================\n",
      "Iteration:  290\n",
      "Previous theta :  [ 0.0076999  -0.00552755  0.04428931  0.03639707  0.10682117 -0.0642491\n",
      "  0.35518154 -0.01661943 -0.12329373  0.15820297 -0.14053472 -0.17057743\n",
      "  0.11804521 -0.41743124]\n",
      "New theta_0 : [ 0.00768899 -0.00601009  0.04467685  0.03601405  0.10678313 -0.06534235\n",
      "  0.35450489 -0.0165871  -0.1247821   0.15898073 -0.14063139 -0.17089722\n",
      "  0.11783296 -0.41774891]\n",
      "Training Error:  10.902577738888779\n",
      "====================================================================================================\n",
      "Iteration:  291\n",
      "Previous theta :  [ 0.00768899 -0.00601009  0.04467685  0.03601405  0.10678313 -0.06534235\n",
      "  0.35450489 -0.0165871  -0.1247821   0.15898073 -0.14063139 -0.17089722\n",
      "  0.11783296 -0.41774891]\n",
      "New theta_0 : [ 0.00767822 -0.00648956  0.04506297  0.03563521  0.10674532 -0.06642877\n",
      "  0.35383464 -0.01655346 -0.12625902  0.15975422 -0.14072948 -0.17121423\n",
      "  0.11762271 -0.41806225]\n",
      "Training Error:  10.897917200120371\n",
      "====================================================================================================\n",
      "Iteration:  292\n",
      "Previous theta :  [ 0.00767822 -0.00648956  0.04506297  0.03563521  0.10674532 -0.06642877\n",
      "  0.35383464 -0.01655346 -0.12625902  0.15975422 -0.14072948 -0.17121423\n",
      "  0.11762271 -0.41806225]\n",
      "New theta_0 : [ 0.00766758 -0.00696595  0.04544767  0.0352605   0.10670776 -0.06750838\n",
      "  0.35317071 -0.01651855 -0.12772459  0.16052347 -0.14082897 -0.17152851\n",
      "  0.11741442 -0.41837131]\n",
      "Training Error:  10.893322230599226\n",
      "====================================================================================================\n",
      "Iteration:  293\n",
      "Previous theta :  [ 0.00766758 -0.00696595  0.04544767  0.0352605   0.10670776 -0.06750838\n",
      "  0.35317071 -0.01651855 -0.12772459  0.16052347 -0.14082897 -0.17152851\n",
      "  0.11741442 -0.41837131]\n",
      "New theta_0 : [ 0.00765708 -0.00743929  0.04583094  0.0348899   0.10667043 -0.06858124\n",
      "  0.35251304 -0.0164824  -0.12917889  0.16128851 -0.14092983 -0.17184008\n",
      "  0.11720809 -0.41867617]\n",
      "Training Error:  10.88879186093643\n",
      "====================================================================================================\n",
      "Iteration:  294\n",
      "Previous theta :  [ 0.00765708 -0.00743929  0.04583094  0.0348899   0.10667043 -0.06858124\n",
      "  0.35251304 -0.0164824  -0.12917889  0.16128851 -0.14092983 -0.17184008\n",
      "  0.11720809 -0.41867617]\n",
      "New theta_0 : [ 0.00764671 -0.0079096   0.04621274  0.03452337  0.10663333 -0.06964737\n",
      "  0.35186155 -0.01644504 -0.13062202  0.16204936 -0.14103205 -0.17214898\n",
      "  0.11700367 -0.41897687]\n",
      "Training Error:  10.88432513681832\n",
      "====================================================================================================\n",
      "Iteration:  295\n",
      "Previous theta :  [ 0.00764671 -0.0079096   0.04621274  0.03452337  0.10663333 -0.06964737\n",
      "  0.35186155 -0.01644504 -0.13062202  0.16204936 -0.14103205 -0.17214898\n",
      "  0.11700367 -0.41897687]\n",
      "New theta_0 : [ 0.00763647 -0.00837689  0.04659309  0.03416086  0.10659647 -0.07070682\n",
      "  0.35121618 -0.01640652 -0.13205407  0.16280607 -0.14113562 -0.17245522\n",
      "  0.11680116 -0.41927347]\n",
      "Training Error:  10.8799211187526\n",
      "====================================================================================================\n",
      "Iteration:  296\n",
      "Previous theta :  [ 0.00763647 -0.00837689  0.04659309  0.03416086  0.10659647 -0.07070682\n",
      "  0.35121618 -0.01640652 -0.13205407  0.16280607 -0.14113562 -0.17245522\n",
      "  0.11680116 -0.41927347]\n",
      "New theta_0 : [ 0.00762636 -0.00884117  0.04697195  0.03380235  0.10655983 -0.07175963\n",
      "  0.35057687 -0.01636686 -0.13347512  0.16355865 -0.14124051 -0.17275885\n",
      "  0.11660052 -0.41956605]\n",
      "Training Error:  10.875578881819287\n",
      "====================================================================================================\n",
      "Iteration:  297\n",
      "Previous theta :  [ 0.00762636 -0.00884117  0.04697195  0.03380235  0.10655983 -0.07175963\n",
      "  0.35057687 -0.01636686 -0.13347512  0.16355865 -0.14124051 -0.17275885\n",
      "  0.11660052 -0.41956605]\n",
      "New theta_0 : [ 0.00761637 -0.00930248  0.04734932  0.03344779  0.10652341 -0.07280584\n",
      "  0.34994355 -0.01632611 -0.13488527  0.16430715 -0.14134671 -0.17305989\n",
      "  0.11640173 -0.41985465]\n",
      "Training Error:  10.871297515426452\n",
      "====================================================================================================\n",
      "Iteration:  298\n",
      "Previous theta :  [ 0.00761637 -0.00930248  0.04734932  0.03344779  0.10652341 -0.07280584\n",
      "  0.34994355 -0.01632611 -0.13488527  0.16430715 -0.14134671 -0.17305989\n",
      "  0.11640173 -0.41985465]\n",
      "New theta_0 : [ 0.0076065  -0.00976082  0.04772518  0.03309716  0.10648722 -0.07384548\n",
      "  0.34931616 -0.01628429 -0.1362846   0.16505158 -0.1414542  -0.17335836\n",
      "  0.11620478 -0.42013932]\n",
      "Training Error:  10.867076123070605\n",
      "====================================================================================================\n",
      "Iteration:  299\n",
      "Previous theta :  [ 0.0076065  -0.00976082  0.04772518  0.03309716  0.10648722 -0.07384548\n",
      "  0.34931616 -0.01628429 -0.1362846   0.16505158 -0.1414542  -0.17335836\n",
      "  0.11620478 -0.42013932]\n",
      "New theta_0 : [ 0.00759676 -0.01021621  0.04809952  0.03275042  0.10645126 -0.0748786\n",
      "  0.34869464 -0.01624143 -0.13767319  0.16579198 -0.14156297 -0.1736543\n",
      "  0.11600963 -0.42042014]\n",
      "Training Error:  10.862913822101618\n",
      "====================================================================================================\n",
      "Iteration:  300\n",
      "Previous theta :  [ 0.00759676 -0.01021621  0.04809952  0.03275042  0.10645126 -0.0748786\n",
      "  0.34869464 -0.01624143 -0.13767319  0.16579198 -0.14156297 -0.1736543\n",
      "  0.11600963 -0.42042014]\n",
      "New theta_0 : [ 0.00758713 -0.01066867  0.04847234  0.03240753  0.10641551 -0.07590524\n",
      "  0.34807891 -0.01619756 -0.13905113  0.16652838 -0.14167299 -0.17394774\n",
      "  0.11581628 -0.42069715]\n",
      "Training Error:  10.858809743492111\n",
      "====================================================================================================\n",
      "Iteration:  301\n",
      "Previous theta :  [ 0.00758713 -0.01066867  0.04847234  0.03240753  0.10641551 -0.07590524\n",
      "  0.34807891 -0.01619756 -0.13905113  0.16652838 -0.14167299 -0.17394774\n",
      "  0.11581628 -0.42069715]\n",
      "New theta_0 : [ 0.00757762 -0.01111821  0.04884362  0.03206846  0.10637998 -0.07692543\n",
      "  0.34746892 -0.01615273 -0.14041851  0.16726081 -0.14178425 -0.17423869\n",
      "  0.11562468 -0.4209704 ]\n",
      "Training Error:  10.854763031611169\n",
      "====================================================================================================\n",
      "Iteration:  302\n",
      "Previous theta :  [ 0.00757762 -0.01111821  0.04884362  0.03206846  0.10637998 -0.07692543\n",
      "  0.34746892 -0.01615273 -0.14041851  0.16726081 -0.14178425 -0.17423869\n",
      "  0.11562468 -0.4209704 ]\n",
      "New theta_0 : [ 0.00756823 -0.01156486  0.04921336  0.03173317  0.10634466 -0.07793921\n",
      "  0.34686461 -0.01610695 -0.14177541  0.16798929 -0.14189674 -0.1745272\n",
      "  0.11543484 -0.42123995]\n",
      "Training Error:  10.85077284400231\n",
      "====================================================================================================\n",
      "Iteration:  303\n",
      "Previous theta :  [ 0.00756823 -0.01156486  0.04921336  0.03173317  0.10634466 -0.07793921\n",
      "  0.34686461 -0.01610695 -0.14177541  0.16798929 -0.14189674 -0.1745272\n",
      "  0.11543484 -0.42123995]\n",
      "New theta_0 : [ 0.00755894 -0.01200862  0.04958153  0.03140163  0.10630956 -0.07894662\n",
      "  0.34626592 -0.01606025 -0.14312191  0.16871385 -0.14201044 -0.17481328\n",
      "  0.11524672 -0.42150585]\n",
      "Training Error:  10.846838351165623\n",
      "====================================================================================================\n",
      "Iteration:  304\n",
      "Previous theta :  [ 0.00755894 -0.01200862  0.04958153  0.03140163  0.10630956 -0.07894662\n",
      "  0.34626592 -0.01606025 -0.14312191  0.16871385 -0.14201044 -0.17481328\n",
      "  0.11524672 -0.42150585]\n",
      "New theta_0 : [ 0.00754976 -0.01244952  0.04994814  0.03107381  0.10627467 -0.07994769\n",
      "  0.34567279 -0.01601267 -0.1444581   0.16943453 -0.14212533 -0.17509695\n",
      "  0.1150603  -0.42176816]\n",
      "Training Error:  10.842958736343943\n",
      "====================================================================================================\n",
      "Iteration:  305\n",
      "Previous theta :  [ 0.00754976 -0.01244952  0.04994814  0.03107381  0.10627467 -0.07994769\n",
      "  0.34567279 -0.01601267 -0.1444581   0.16943453 -0.14212533 -0.17509695\n",
      "  0.1150603  -0.42176816]\n",
      "New theta_0 : [ 0.0075407  -0.01288758  0.05031317  0.03074967  0.10623999 -0.08094248\n",
      "  0.34508516 -0.01596424 -0.14578406  0.17015135 -0.14224139 -0.17537826\n",
      "  0.11487557 -0.42202692]\n",
      "Training Error:  10.839133195313032\n",
      "====================================================================================================\n",
      "Iteration:  306\n",
      "Previous theta :  [ 0.0075407  -0.01288758  0.05031317  0.03074967  0.10623999 -0.08094248\n",
      "  0.34508516 -0.01596424 -0.14578406  0.17015135 -0.14224139 -0.17537826\n",
      "  0.11487557 -0.42202692]\n",
      "New theta_0 : [ 0.00753173 -0.0133228   0.05067662  0.03042918  0.10620552 -0.081931\n",
      "  0.34450297 -0.01591497 -0.14709987  0.17086433 -0.14235862 -0.17565721\n",
      "  0.1146925  -0.42228219]\n",
      "Training Error:  10.835360936175595\n",
      "====================================================================================================\n",
      "Iteration:  307\n",
      "Previous theta :  [ 0.00753173 -0.0133228   0.05067662  0.03042918  0.10620552 -0.081931\n",
      "  0.34450297 -0.01591497 -0.14709987  0.17086433 -0.14235862 -0.17565721\n",
      "  0.1146925  -0.42228219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00752288 -0.01375521  0.05103848  0.0301123   0.10617125 -0.08291331\n",
      "  0.34392616 -0.0158649  -0.1484056   0.17157351 -0.14247699 -0.17593384\n",
      "  0.11451108 -0.42253401]\n",
      "Training Error:  10.831641179159165\n",
      "====================================================================================================\n",
      "Iteration:  308\n",
      "Previous theta :  [ 0.00752288 -0.01375521  0.05103848  0.0301123   0.10617125 -0.08291331\n",
      "  0.34392616 -0.0158649  -0.1484056   0.17157351 -0.14247699 -0.17593384\n",
      "  0.11451108 -0.42253401]\n",
      "New theta_0 : [ 0.00751412 -0.01418481  0.05139874  0.02979901  0.10613719 -0.08388943\n",
      "  0.34335468 -0.01581406 -0.14970135  0.17227891 -0.1425965  -0.17620817\n",
      "  0.11433129 -0.42278243]\n",
      "Training Error:  10.827973156417638\n",
      "====================================================================================================\n",
      "Iteration:  309\n",
      "Previous theta :  [ 0.00751412 -0.01418481  0.05139874  0.02979901  0.10613719 -0.08388943\n",
      "  0.34335468 -0.01581406 -0.14970135  0.17227891 -0.1425965  -0.17620817\n",
      "  0.11433129 -0.42278243]\n",
      "New theta_0 : [ 0.00750546 -0.01461164  0.0517574   0.02948927  0.10610333 -0.0848594\n",
      "  0.34278847 -0.01576246 -0.15098719  0.17298056 -0.14271711 -0.17648023\n",
      "  0.11415311 -0.42302751]\n",
      "Training Error:  10.824356111836494\n",
      "====================================================================================================\n",
      "Iteration:  310\n",
      "Previous theta :  [ 0.00750546 -0.01461164  0.0517574   0.02948927  0.10610333 -0.0848594\n",
      "  0.34278847 -0.01576246 -0.15098719  0.17298056 -0.14271711 -0.17648023\n",
      "  0.11415311 -0.42302751]\n",
      "New theta_0 : [ 0.00749691 -0.0150357   0.05211444  0.02918305  0.10606966 -0.08582327\n",
      "  0.34222747 -0.01571014 -0.15226319  0.17367849 -0.14283883 -0.17675004\n",
      "  0.11397652 -0.42326929]\n",
      "Training Error:  10.820789300841549\n",
      "====================================================================================================\n",
      "Iteration:  311\n",
      "Previous theta :  [ 0.00749691 -0.0150357   0.05211444  0.02918305  0.10606966 -0.08582327\n",
      "  0.34222747 -0.01571014 -0.15226319  0.17367849 -0.14283883 -0.17675004\n",
      "  0.11397652 -0.42326929]\n",
      "New theta_0 : [ 0.00748845 -0.01545702  0.05246987  0.02888032  0.1060362  -0.08678106\n",
      "  0.34167164 -0.01565712 -0.15352944  0.17437272 -0.14296163 -0.17701762\n",
      "  0.1138015  -0.42350781]\n",
      "Training Error:  10.817271990211207\n",
      "====================================================================================================\n",
      "Iteration:  312\n",
      "Previous theta :  [ 0.00748845 -0.01545702  0.05246987  0.02888032  0.1060362  -0.08678106\n",
      "  0.34167164 -0.01565712 -0.15352944  0.17437272 -0.14296163 -0.17701762\n",
      "  0.1138015  -0.42350781]\n",
      "New theta_0 : [ 0.00748008 -0.0158756   0.05282367  0.02858104  0.10600294 -0.08773282\n",
      "  0.34112091 -0.01560342 -0.15478601  0.17506327 -0.1430855  -0.17728299\n",
      "  0.11362803 -0.42374313]\n",
      "Training Error:  10.8138034578921\n",
      "====================================================================================================\n",
      "Iteration:  313\n",
      "Previous theta :  [ 0.00748008 -0.0158756   0.05282367  0.02858104  0.10600294 -0.08773282\n",
      "  0.34112091 -0.01560342 -0.15478601  0.17506327 -0.1430855  -0.17728299\n",
      "  0.11362803 -0.42374313]\n",
      "New theta_0 : [ 0.00747181 -0.01629146  0.05317585  0.02828519  0.10596987 -0.08867857\n",
      "  0.34057524 -0.01554907 -0.15603298  0.17575018 -0.14321042 -0.17754619\n",
      "  0.1134561  -0.42397528]\n",
      "Training Error:  10.810382992818084\n",
      "====================================================================================================\n",
      "Iteration:  314\n",
      "Previous theta :  [ 0.00747181 -0.01629146  0.05317585  0.02828519  0.10596987 -0.08867857\n",
      "  0.34057524 -0.01554907 -0.15603298  0.17575018 -0.14321042 -0.17754619\n",
      "  0.1134561  -0.42397528]\n",
      "New theta_0 : [ 0.00746363 -0.01670463  0.05352639  0.02799272  0.10593699 -0.08961836\n",
      "  0.34003456 -0.01549409 -0.15727043  0.17643348 -0.14333639 -0.17780723\n",
      "  0.1132857  -0.42420432]\n",
      "Training Error:  10.807009894732484\n",
      "====================================================================================================\n",
      "Iteration:  315\n",
      "Previous theta :  [ 0.00746363 -0.01670463  0.05352639  0.02799272  0.10593699 -0.08961836\n",
      "  0.34003456 -0.01549409 -0.15727043  0.17643348 -0.14333639 -0.17780723\n",
      "  0.1132857  -0.42420432]\n",
      "New theta_0 : [ 0.00745554 -0.01711511  0.05387529  0.02770362  0.10590431 -0.09055223\n",
      "  0.33949884 -0.0154385  -0.15849842  0.17711318 -0.14346338 -0.17806613\n",
      "  0.1131168  -0.42443028]\n",
      "Training Error:  10.803683474013544\n",
      "====================================================================================================\n",
      "Iteration:  316\n",
      "Previous theta :  [ 0.00745554 -0.01711511  0.05387529  0.02770362  0.10590431 -0.09055223\n",
      "  0.33949884 -0.0154385  -0.15849842  0.17711318 -0.14346338 -0.17806613\n",
      "  0.1131168  -0.42443028]\n",
      "New theta_0 : [ 0.00744754 -0.01752292  0.05422255  0.02741786  0.10587181 -0.09148019\n",
      "  0.33896801 -0.01538233 -0.15971704  0.17778931 -0.14359138 -0.17832292\n",
      "  0.11294938 -0.42465321]\n",
      "Training Error:  10.800403051502991\n",
      "====================================================================================================\n",
      "Iteration:  317\n",
      "Previous theta :  [ 0.00744754 -0.01752292  0.05422255  0.02741786  0.10587181 -0.09148019\n",
      "  0.33896801 -0.01538233 -0.15971704  0.17778931 -0.14359138 -0.17832292\n",
      "  0.11294938 -0.42465321]\n",
      "New theta_0 : [ 0.00743962 -0.01792808  0.05456817  0.02713539  0.10583951 -0.0924023\n",
      "  0.33844202 -0.01532559 -0.16092636  0.17846189 -0.14372038 -0.17857763\n",
      "  0.11278343 -0.42487316]\n",
      "Training Error:  10.797167958337674\n",
      "====================================================================================================\n",
      "Iteration:  318\n",
      "Previous theta :  [ 0.00743962 -0.01792808  0.05456817  0.02713539  0.10583951 -0.0924023\n",
      "  0.33844202 -0.01532559 -0.16092636  0.17846189 -0.14372038 -0.17857763\n",
      "  0.11278343 -0.42487316]\n",
      "New theta_0 : [ 0.00743179 -0.01833061  0.05491213  0.02685619  0.10580739 -0.09331859\n",
      "  0.33792083 -0.01526832 -0.16212645  0.17913096 -0.14385037 -0.17883026\n",
      "  0.11261894 -0.42509016]\n",
      "Training Error:  10.793977535784204\n",
      "====================================================================================================\n",
      "Iteration:  319\n",
      "Previous theta :  [ 0.00743179 -0.01833061  0.05491213  0.02685619  0.10580739 -0.09331859\n",
      "  0.33792083 -0.01526832 -0.16212645  0.17913096 -0.14385037 -0.17883026\n",
      "  0.11261894 -0.42509016]\n",
      "New theta_0 : [ 0.00742405 -0.01873051  0.05525444  0.02658023  0.10577546 -0.09422909\n",
      "  0.33740438 -0.01521052 -0.16331739  0.17979654 -0.14398132 -0.17908084\n",
      "  0.11245589 -0.42530425]\n",
      "Training Error:  10.790831135076512\n",
      "====================================================================================================\n",
      "Iteration:  320\n",
      "Previous theta :  [ 0.00742405 -0.01873051  0.05525444  0.02658023  0.10577546 -0.09422909\n",
      "  0.33740438 -0.01521052 -0.16331739  0.17979654 -0.14398132 -0.17908084\n",
      "  0.11245589 -0.42530425]\n",
      "New theta_0 : [ 0.00741638 -0.01912781  0.0555951   0.02630748  0.10574371 -0.09513383\n",
      "  0.33689263 -0.01515222 -0.16449924  0.18045865 -0.14411323 -0.1793294\n",
      "  0.11229426 -0.42551549]\n",
      "Training Error:  10.787728117256298\n",
      "====================================================================================================\n",
      "Iteration:  321\n",
      "Previous theta :  [ 0.00741638 -0.01912781  0.0555951   0.02630748  0.10574371 -0.09513383\n",
      "  0.33689263 -0.01515222 -0.16449924  0.18045865 -0.14411323 -0.1793294\n",
      "  0.11229426 -0.42551549]\n",
      "New theta_0 : [ 0.0074088  -0.01952252  0.0559341   0.02603792  0.10571214 -0.09603286\n",
      "  0.33638553 -0.01509344 -0.16567208  0.18111731 -0.14424608 -0.17957596\n",
      "  0.11213404 -0.4257239 ]\n",
      "Training Error:  10.784667853016291\n",
      "====================================================================================================\n",
      "Iteration:  322\n",
      "Previous theta :  [ 0.0074088  -0.01952252  0.0559341   0.02603792  0.10571214 -0.09603286\n",
      "  0.33638553 -0.01509344 -0.16567208  0.18111731 -0.14424608 -0.17957596\n",
      "  0.11213404 -0.4257239 ]\n",
      "New theta_0 : [ 0.0074013  -0.01991466  0.05627144  0.0257715   0.10568075 -0.0969262\n",
      "  0.33588302 -0.0150342  -0.16683598  0.18177256 -0.14437986 -0.17982053\n",
      "  0.11197522 -0.42592953]\n",
      "Training Error:  10.78164972254626\n",
      "====================================================================================================\n",
      "Iteration:  323\n",
      "Previous theta :  [ 0.0074013  -0.01991466  0.05627144  0.0257715   0.10568075 -0.0969262\n",
      "  0.33588302 -0.0150342  -0.16683598  0.18177256 -0.14437986 -0.17982053\n",
      "  0.11197522 -0.42592953]\n",
      "New theta_0 : [ 0.00739388 -0.02030424  0.05660711  0.02550821  0.10564954 -0.09781389\n",
      "  0.33538507 -0.01497451 -0.16799101  0.18242441 -0.14451455 -0.18006313\n",
      "  0.11181777 -0.42613242]\n",
      "Training Error:  10.77867311538175\n",
      "====================================================================================================\n",
      "Iteration:  324\n",
      "Previous theta :  [ 0.00739388 -0.02030424  0.05660711  0.02550821  0.10564954 -0.09781389\n",
      "  0.33538507 -0.01497451 -0.16799101  0.18242441 -0.14451455 -0.18006313\n",
      "  0.11181777 -0.42613242]\n",
      "New theta_0 : [ 0.00738654 -0.02069128  0.05694112  0.02524801  0.10561851 -0.09869596\n",
      "  0.33489162 -0.0149144  -0.16913724  0.18307288 -0.14465015 -0.18030379\n",
      "  0.11166168 -0.4263326 ]\n",
      "Training Error:  10.77573743025542\n",
      "====================================================================================================\n",
      "Iteration:  325\n",
      "Previous theta :  [ 0.00738654 -0.02069128  0.05694112  0.02524801  0.10561851 -0.09869596\n",
      "  0.33489162 -0.0149144  -0.16913724  0.18307288 -0.14465015 -0.18030379\n",
      "  0.11166168 -0.4263326 ]\n",
      "New theta_0 : [ 0.00737927 -0.02107579  0.05727347  0.02499087  0.10558765 -0.09957245\n",
      "  0.33440262 -0.01485388 -0.17027473  0.18371801 -0.14478663 -0.18054253\n",
      "  0.11150694 -0.42653012]\n",
      "Training Error:  10.772842074951026\n",
      "====================================================================================================\n",
      "Iteration:  326\n",
      "Previous theta :  [ 0.00737927 -0.02107579  0.05727347  0.02499087  0.10558765 -0.09957245\n",
      "  0.33440262 -0.01485388 -0.17027473  0.18371801 -0.14478663 -0.18054253\n",
      "  0.11150694 -0.42653012]\n",
      "New theta_0 : [ 0.00737207 -0.02145779  0.05760415  0.02473678  0.10555697 -0.10044339\n",
      "  0.33391804 -0.01479298 -0.17140357  0.18435982 -0.144924   -0.18077936\n",
      "  0.11135354 -0.42672501]\n",
      "Training Error:  10.769986466159901\n",
      "====================================================================================================\n",
      "Iteration:  327\n",
      "Previous theta :  [ 0.00737207 -0.02145779  0.05760415  0.02473678  0.10555697 -0.10044339\n",
      "  0.33391804 -0.01479298 -0.17140357  0.18435982 -0.144924   -0.18077936\n",
      "  0.11135354 -0.42672501]\n",
      "New theta_0 : [ 0.00736495 -0.02183729  0.05793316  0.02448569  0.10552647 -0.10130882\n",
      "  0.33343782 -0.0147317  -0.1725238   0.18499832 -0.14506222 -0.1810143\n",
      "  0.11120145 -0.4269173 ]\n",
      "Training Error:  10.76717002933996\n",
      "====================================================================================================\n",
      "Iteration:  328\n",
      "Previous theta :  [ 0.00736495 -0.02183729  0.05793316  0.02448569  0.10552647 -0.10130882\n",
      "  0.33343782 -0.0147317  -0.1725238   0.18499832 -0.14506222 -0.1810143\n",
      "  0.11120145 -0.4269173 ]\n",
      "New theta_0 : [ 0.0073579  -0.02221431  0.0582605   0.02423758  0.10549613 -0.10216876\n",
      "  0.33296193 -0.01467007 -0.17363551  0.18563354 -0.1452013  -0.18124738\n",
      "  0.11105067 -0.42710704]\n",
      "Training Error:  10.7643921985771\n",
      "====================================================================================================\n",
      "Iteration:  329\n",
      "Previous theta :  [ 0.0073579  -0.02221431  0.0582605   0.02423758  0.10549613 -0.10216876\n",
      "  0.33296193 -0.01467007 -0.17363551  0.18563354 -0.1452013  -0.18124738\n",
      "  0.11105067 -0.42710704]\n",
      "New theta_0 : [ 0.00735093 -0.02258887  0.05858617  0.02399243  0.10546596 -0.10302325\n",
      "  0.33249031 -0.0146081  -0.17473876  0.18626551 -0.14534121 -0.18147861\n",
      "  0.11090119 -0.42729426]\n",
      "Training Error:  10.761652416449047\n",
      "====================================================================================================\n",
      "Iteration:  330\n",
      "Previous theta :  [ 0.00735093 -0.02258887  0.05858617  0.02399243  0.10546596 -0.10302325\n",
      "  0.33249031 -0.0146081  -0.17473876  0.18626551 -0.14534121 -0.18147861\n",
      "  0.11090119 -0.42729426]\n",
      "New theta_0 : [ 0.00734402 -0.02296097  0.05891018  0.0237502   0.10543596 -0.10387233\n",
      "  0.33202293 -0.01454581 -0.17583362  0.18689424 -0.14548195 -0.18170801\n",
      "  0.11075298 -0.427479  ]\n",
      "Training Error:  10.758950133891496\n",
      "====================================================================================================\n",
      "Iteration:  331\n",
      "Previous theta :  [ 0.00734402 -0.02296097  0.05891018  0.0237502   0.10543596 -0.10387233\n",
      "  0.33202293 -0.01454581 -0.17583362  0.18689424 -0.14548195 -0.18170801\n",
      "  0.11075298 -0.427479  ]\n",
      "New theta_0 : [ 0.00733718 -0.02333064  0.05923251  0.02351087  0.10540613 -0.10471602\n",
      "  0.33155973 -0.01448322 -0.17692014  0.18751976 -0.1456235  -0.1819356\n",
      "  0.11060605 -0.42766129]\n",
      "Training Error:  10.756284810066571\n",
      "====================================================================================================\n",
      "Iteration:  332\n",
      "Previous theta :  [ 0.00733718 -0.02333064  0.05923251  0.02351087  0.10540613 -0.10471602\n",
      "  0.33155973 -0.01448322 -0.17692014  0.18751976 -0.1456235  -0.1819356\n",
      "  0.11060605 -0.42766129]\n",
      "New theta_0 : [ 0.00733041 -0.02369789  0.05955318  0.02327441  0.10537647 -0.10555436\n",
      "  0.33110069 -0.01442033 -0.1779984   0.1881421  -0.14576586 -0.1821614\n",
      "  0.11046036 -0.42784116]\n",
      "Training Error:  10.753655912233537\n",
      "====================================================================================================\n",
      "Iteration:  333\n",
      "Previous theta :  [ 0.00733041 -0.02369789  0.05955318  0.02327441  0.10537647 -0.10555436\n",
      "  0.33110069 -0.01442033 -0.1779984   0.1881421  -0.14576586 -0.1821614\n",
      "  0.11046036 -0.42784116]\n",
      "New theta_0 : [ 0.00732371 -0.02406274  0.05987218  0.0230408   0.10534697 -0.10638738\n",
      "  0.33064574 -0.01435717 -0.17906846  0.18876126 -0.145909   -0.18238543\n",
      "  0.11031591 -0.42801865]\n",
      "Training Error:  10.751062915621713\n",
      "====================================================================================================\n",
      "Iteration:  334\n",
      "Previous theta :  [ 0.00732371 -0.02406274  0.05987218  0.0230408   0.10534697 -0.10638738\n",
      "  0.33064574 -0.01435717 -0.17906846  0.18876126 -0.145909   -0.18238543\n",
      "  0.11031591 -0.42801865]\n",
      "New theta_0 : [ 0.00731707 -0.02442519  0.06018951  0.02281     0.10531763 -0.10721511\n",
      "  0.33019486 -0.01429374 -0.18013039  0.18937728 -0.14605292 -0.18260769\n",
      "  0.11017269 -0.4281938 ]\n",
      "Training Error:  10.74850530330555\n",
      "====================================================================================================\n",
      "Iteration:  335\n",
      "Previous theta :  [ 0.00731707 -0.02442519  0.06018951  0.02281     0.10531763 -0.10721511\n",
      "  0.33019486 -0.01429374 -0.18013039  0.18937728 -0.14605292 -0.18260769\n",
      "  0.11017269 -0.4281938 ]\n",
      "New theta_0 : [ 0.0073105  -0.02478527  0.06050518  0.022582    0.10528846 -0.10803759\n",
      "  0.329748   -0.01423007 -0.18118425  0.18999018 -0.14619761 -0.18282822\n",
      "  0.11003069 -0.42836662]\n",
      "Training Error:  10.745982566081823\n",
      "====================================================================================================\n",
      "Iteration:  336\n",
      "Previous theta :  [ 0.0073105  -0.02478527  0.06050518  0.022582    0.10528846 -0.10803759\n",
      "  0.329748   -0.01423007 -0.18118425  0.18999018 -0.14619761 -0.18282822\n",
      "  0.11003069 -0.42836662]\n",
      "New theta_0 : [ 0.00730399 -0.02514298  0.06081918  0.02235676  0.10525944 -0.10885484\n",
      "  0.32930513 -0.01416617 -0.18223009  0.19059998 -0.14634305 -0.18304702\n",
      "  0.10988989 -0.42853717]\n",
      "Training Error:  10.743494202348934\n",
      "====================================================================================================\n",
      "Iteration:  337\n",
      "Previous theta :  [ 0.00730399 -0.02514298  0.06081918  0.02235676  0.10525944 -0.10885484\n",
      "  0.32930513 -0.01416617 -0.18223009  0.19059998 -0.14634305 -0.18304702\n",
      "  0.10988989 -0.42853717]\n",
      "New theta_0 : [ 0.00729754 -0.02549835  0.06113151  0.02213426  0.10523059 -0.10966691\n",
      "  0.32886619 -0.01410205 -0.18326799  0.1912067  -0.14648923 -0.18326412\n",
      "  0.10975028 -0.42870547]\n",
      "Training Error:  10.741039717988208\n",
      "====================================================================================================\n",
      "Iteration:  338\n",
      "Previous theta :  [ 0.00729754 -0.02549835  0.06113151  0.02213426  0.10523059 -0.10966691\n",
      "  0.32886619 -0.01410205 -0.18326799  0.1912067  -0.14648923 -0.18326412\n",
      "  0.10975028 -0.42870547]\n",
      "New theta_0 : [ 0.00729116 -0.02585138  0.06144219  0.02191448  0.10520189 -0.11047381\n",
      "  0.32843115 -0.01403772 -0.18429801  0.19181035 -0.14663614 -0.18347953\n",
      "  0.10961185 -0.42887154]\n",
      "Training Error:  10.738618626247225\n",
      "====================================================================================================\n",
      "Iteration:  339\n",
      "Previous theta :  [ 0.00729116 -0.02585138  0.06144219  0.02191448  0.10520189 -0.11047381\n",
      "  0.32843115 -0.01403772 -0.18429801  0.19181035 -0.14663614 -0.18347953\n",
      "  0.10961185 -0.42887154]\n",
      "New theta_0 : [ 0.00728484 -0.0262021   0.0617512   0.02169738  0.10517335 -0.11127558\n",
      "  0.32799997 -0.0139732  -0.1853202   0.19241097 -0.14678378 -0.18369327\n",
      "  0.10947458 -0.42903543]\n",
      "Training Error:  10.73623044762511\n",
      "====================================================================================================\n",
      "Iteration:  340\n",
      "Previous theta :  [ 0.00728484 -0.0262021   0.0617512   0.02169738  0.10517335 -0.11127558\n",
      "  0.32799997 -0.0139732  -0.1853202   0.19241097 -0.14678378 -0.18369327\n",
      "  0.10947458 -0.42903543]\n",
      "New theta_0 : [ 0.00727857 -0.02655052  0.06205856  0.02148295  0.10514496 -0.11207226\n",
      "  0.32757262 -0.0139085  -0.18633464  0.19300857 -0.14693212 -0.18390535\n",
      "  0.10933847 -0.42919717]\n",
      "Training Error:  10.733874709759728\n",
      "====================================================================================================\n",
      "Iteration:  341\n",
      "Previous theta :  [ 0.00727857 -0.02655052  0.06205856  0.02148295  0.10514496 -0.11207226\n",
      "  0.32757262 -0.0139085  -0.18633464  0.19300857 -0.14693212 -0.18390535\n",
      "  0.10933847 -0.42919717]\n",
      "New theta_0 : [ 0.00727237 -0.02689664  0.06236426  0.02127115  0.10511673 -0.11286386\n",
      "  0.32714904 -0.01384364 -0.18734137  0.19360318 -0.14708116 -0.18411579\n",
      "  0.1092035  -0.42935677]\n",
      "Training Error:  10.731550947316796\n",
      "====================================================================================================\n",
      "Iteration:  342\n",
      "Previous theta :  [ 0.00727237 -0.02689664  0.06236426  0.02127115  0.10511673 -0.11286386\n",
      "  0.32714904 -0.01384364 -0.18734137  0.19360318 -0.14708116 -0.18411579\n",
      "  0.1092035  -0.42935677]\n",
      "New theta_0 : [ 0.00726622 -0.02724049  0.06266831  0.02106197  0.10508865 -0.11365043\n",
      "  0.32672922 -0.01377862 -0.18834046  0.19419481 -0.14723088 -0.18432461\n",
      "  0.10906966 -0.42951428]\n",
      "Training Error:  10.729258701880822\n",
      "====================================================================================================\n",
      "Iteration:  343\n",
      "Previous theta :  [ 0.00726622 -0.02724049  0.06266831  0.02106197  0.10508865 -0.11365043\n",
      "  0.32672922 -0.01377862 -0.18834046  0.19419481 -0.14723088 -0.18432461\n",
      "  0.10906966 -0.42951428]\n",
      "New theta_0 : [ 0.00726013 -0.02758208  0.0629707   0.02085538  0.10506072 -0.114432\n",
      "  0.3263131  -0.01371345 -0.18933197  0.19478348 -0.14738128 -0.18453182\n",
      "  0.10893695 -0.42966972]\n",
      "Training Error:  10.72699752184787\n",
      "====================================================================================================\n",
      "Iteration:  344\n",
      "Previous theta :  [ 0.00726013 -0.02758208  0.0629707   0.02085538  0.10506072 -0.114432\n",
      "  0.3263131  -0.01371345 -0.18933197  0.19478348 -0.14738128 -0.18453182\n",
      "  0.10893695 -0.42966972]\n",
      "New theta_0 : [ 0.0072541  -0.02792143  0.06327145  0.02065135  0.10503295 -0.11520859\n",
      "  0.32590064 -0.01364816 -0.19031596  0.19536921 -0.14753234 -0.18473744\n",
      "  0.10880534 -0.42982312]\n",
      "Training Error:  10.724766962320125\n",
      "====================================================================================================\n",
      "Iteration:  345\n",
      "Previous theta :  [ 0.0072541  -0.02792143  0.06327145  0.02065135  0.10503295 -0.11520859\n",
      "  0.32590064 -0.01364816 -0.19031596  0.19536921 -0.14753234 -0.18473744\n",
      "  0.10880534 -0.42982312]\n",
      "New theta_0 : [ 0.00724812 -0.02825854  0.06357055  0.02044986  0.10500532 -0.11598023\n",
      "  0.32549183 -0.01358274 -0.19129248  0.19595203 -0.14768406 -0.18494148\n",
      "  0.10867484 -0.4299745 ]\n",
      "Training Error:  10.722566585002173\n",
      "====================================================================================================\n",
      "Iteration:  346\n",
      "Previous theta :  [ 0.00724812 -0.02825854  0.06357055  0.02044986  0.10500532 -0.11598023\n",
      "  0.32549183 -0.01358274 -0.19129248  0.19595203 -0.14768406 -0.18494148\n",
      "  0.10867484 -0.4299745 ]\n",
      "New theta_0 : [ 0.00724219 -0.02859343  0.063868    0.02025089  0.10497784 -0.11674696\n",
      "  0.3250866  -0.01351722 -0.1922616   0.19653196 -0.14783642 -0.18514396\n",
      "  0.10854542 -0.43012391]\n",
      "Training Error:  10.72039595809903\n",
      "====================================================================================================\n",
      "Iteration:  347\n",
      "Previous theta :  [ 0.00724219 -0.02859343  0.063868    0.02025089  0.10497784 -0.11674696\n",
      "  0.3250866  -0.01351722 -0.1922616   0.19653196 -0.14783642 -0.18514396\n",
      "  0.10854542 -0.43012391]\n",
      "New theta_0 : [ 0.00723633 -0.02892612  0.06416382  0.02005441  0.1049505  -0.1175088\n",
      "  0.32468494 -0.01345159 -0.19322337  0.197109   -0.14798941 -0.1853449\n",
      "  0.10841708 -0.43027136]\n",
      "Training Error:  10.718254656215839\n",
      "====================================================================================================\n",
      "Iteration:  348\n",
      "Previous theta :  [ 0.00723633 -0.02892612  0.06416382  0.02005441  0.1049505  -0.1175088\n",
      "  0.32468494 -0.01345159 -0.19322337  0.197109   -0.14798941 -0.1853449\n",
      "  0.10841708 -0.43027136]\n",
      "New theta_0 : [ 0.00723051 -0.02925661  0.064458    0.01986039  0.10492332 -0.11826579\n",
      "  0.32428681 -0.01338588 -0.19417785  0.19768319 -0.14814303 -0.1855443\n",
      "  0.1082898  -0.43041688]\n",
      "Training Error:  10.716142260259222\n",
      "====================================================================================================\n",
      "Iteration:  349\n",
      "Previous theta :  [ 0.00723051 -0.02925661  0.064458    0.01986039  0.10492332 -0.11826579\n",
      "  0.32428681 -0.01338588 -0.19417785  0.19768319 -0.14814303 -0.1855443\n",
      "  0.1082898  -0.43041688]\n",
      "New theta_0 : [ 0.00722474 -0.02958494  0.06475055  0.01966882  0.10489627 -0.11901795\n",
      "  0.32389216 -0.01332009 -0.19512509  0.19825454 -0.14829726 -0.18574218\n",
      "  0.10816358 -0.4305605 ]\n",
      "Training Error:  10.714058357340262\n",
      "====================================================================================================\n",
      "Iteration:  350\n",
      "Previous theta :  [ 0.00722474 -0.02958494  0.06475055  0.01966882  0.10489627 -0.11901795\n",
      "  0.32389216 -0.01332009 -0.19512509  0.19825454 -0.14829726 -0.18574218\n",
      "  0.10816358 -0.4305605 ]\n",
      "New theta_0 : [ 0.00721903 -0.02991109  0.06504146  0.01947968  0.10486937 -0.11976532\n",
      "  0.32350096 -0.01325423 -0.19606516  0.19882308 -0.14845209 -0.18593857\n",
      "  0.10803841 -0.43070225]\n",
      "Training Error:  10.712002540679068\n",
      "====================================================================================================\n",
      "Iteration:  351\n",
      "Previous theta :  [ 0.00721903 -0.02991109  0.06504146  0.01947968  0.10486937 -0.11976532\n",
      "  0.32350096 -0.01325423 -0.19606516  0.19882308 -0.14845209 -0.18593857\n",
      "  0.10803841 -0.43070225]\n",
      "New theta_0 : [ 0.00721337 -0.0302351   0.06533076  0.01929293  0.10484261 -0.12050791\n",
      "  0.32311319 -0.01318832 -0.1969981   0.19938881 -0.14860751 -0.18613346\n",
      "  0.10791427 -0.43084215]\n",
      "Training Error:  10.709974409510917\n",
      "====================================================================================================\n",
      "Iteration:  352\n",
      "Previous theta :  [ 0.00721337 -0.0302351   0.06533076  0.01929293  0.10484261 -0.12050791\n",
      "  0.32311319 -0.01318832 -0.1969981   0.19938881 -0.14860751 -0.18613346\n",
      "  0.10791427 -0.43084215]\n",
      "New theta_0 : [ 0.00720776 -0.03055697  0.06561842  0.01910856  0.104816   -0.12124577\n",
      "  0.32272881 -0.01312235 -0.19792397  0.19995176 -0.14876352 -0.18632688\n",
      "  0.10779116 -0.43098022]\n",
      "Training Error:  10.707973568993909\n",
      "====================================================================================================\n",
      "Iteration:  353\n",
      "Previous theta :  [ 0.00720776 -0.03055697  0.06561842  0.01910856  0.104816   -0.12124577\n",
      "  0.32272881 -0.01312235 -0.19792397  0.19995176 -0.14876352 -0.18632688\n",
      "  0.10779116 -0.43098022]\n",
      "New theta_0 : [ 0.00720219 -0.03087672  0.06590448  0.01892654  0.10478952 -0.12197892\n",
      "  0.32234777 -0.01305635 -0.19884284  0.20051195 -0.14892009 -0.18651884\n",
      "  0.10766907 -0.4311165 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.705999630118157\n",
      "====================================================================================================\n",
      "Iteration:  354\n",
      "Previous theta :  [ 0.00720219 -0.03087672  0.06590448  0.01892654  0.10478952 -0.12197892\n",
      "  0.32234777 -0.01305635 -0.19884284  0.20051195 -0.14892009 -0.18651884\n",
      "  0.10766907 -0.4311165 ]\n",
      "New theta_0 : [ 0.00719668 -0.03119437  0.06618891  0.01874685  0.10476318 -0.12270739\n",
      "  0.32197006 -0.01299032 -0.19975474  0.20106939 -0.14907723 -0.18670936\n",
      "  0.10754798 -0.431251  ]\n",
      "Training Error:  10.704052209616435\n",
      "====================================================================================================\n",
      "Iteration:  355\n",
      "Previous theta :  [ 0.00719668 -0.03119437  0.06618891  0.01874685  0.10476318 -0.12270739\n",
      "  0.32197006 -0.01299032 -0.19975474  0.20106939 -0.14907723 -0.18670936\n",
      "  0.10754798 -0.431251  ]\n",
      "New theta_0 : [ 0.00719121 -0.03150991  0.06647174  0.01856947  0.10473698 -0.12343121\n",
      "  0.32159563 -0.01292426 -0.20065974  0.20162411 -0.14923493 -0.18689844\n",
      "  0.10742789 -0.43138376]\n",
      "Training Error:  10.702130929876292\n",
      "====================================================================================================\n",
      "Iteration:  356\n",
      "Previous theta :  [ 0.00719121 -0.03150991  0.06647174  0.01856947  0.10473698 -0.12343121\n",
      "  0.32159563 -0.01292426 -0.20065974  0.20162411 -0.14923493 -0.18689844\n",
      "  0.10742789 -0.43138376]\n",
      "New theta_0 : [ 0.00718579 -0.03182338  0.06675296  0.01839437  0.10471091 -0.1241504\n",
      "  0.32122445 -0.01285819 -0.20155789  0.20217612 -0.14939316 -0.1870861\n",
      "  0.10730879 -0.43151479]\n",
      "Training Error:  10.700235418853577\n",
      "====================================================================================================\n",
      "Iteration:  357\n",
      "Previous theta :  [ 0.00718579 -0.03182338  0.06675296  0.01839437  0.10471091 -0.1241504\n",
      "  0.32122445 -0.01285819 -0.20155789  0.20217612 -0.14939316 -0.1870861\n",
      "  0.10730879 -0.43151479]\n",
      "New theta_0 : [ 0.00718042 -0.03213477  0.06703258  0.01822154  0.10468498 -0.12486499\n",
      "  0.3208565  -0.01279212 -0.20244924  0.20272544 -0.14955194 -0.18727235\n",
      "  0.10719066 -0.43164413]\n",
      "Training Error:  10.698365309987375\n",
      "====================================================================================================\n",
      "Iteration:  358\n",
      "Previous theta :  [ 0.00718042 -0.03213477  0.06703258  0.01822154  0.10468498 -0.12486499\n",
      "  0.3208565  -0.01279212 -0.20244924  0.20272544 -0.14955194 -0.18727235\n",
      "  0.10719066 -0.43164413]\n",
      "New theta_0 : [ 0.00717509 -0.03244411  0.0673106   0.01805095  0.10465919 -0.12557502\n",
      "  0.32049173 -0.01272605 -0.20333384  0.20327209 -0.14971123 -0.18745722\n",
      "  0.10707351 -0.43177178]\n",
      "Training Error:  10.696520242116334\n",
      "====================================================================================================\n",
      "Iteration:  359\n",
      "Previous theta :  [ 0.00717509 -0.03244411  0.0673106   0.01805095  0.10465919 -0.12557502\n",
      "  0.32049173 -0.01272605 -0.20333384  0.20327209 -0.14971123 -0.18745722\n",
      "  0.10707351 -0.43177178]\n",
      "New theta_0 : [ 0.00716981 -0.03275141  0.06758703  0.01788258  0.10463353 -0.12628051\n",
      "  0.32013013 -0.01265999 -0.20421176  0.20381608 -0.14987104 -0.1876407\n",
      "  0.10695731 -0.43189779]\n",
      "Training Error:  10.694699859396303\n",
      "====================================================================================================\n",
      "Iteration:  360\n",
      "Previous theta :  [ 0.00716981 -0.03275141  0.06758703  0.01788258  0.10463353 -0.12628051\n",
      "  0.32013013 -0.01265999 -0.20421176  0.20381608 -0.14987104 -0.1876407\n",
      "  0.10695731 -0.43189779]\n",
      "New theta_0 : [ 0.00716457 -0.03305667  0.06786187  0.01771641  0.104608   -0.12698149\n",
      "  0.31977165 -0.01259395 -0.20508303  0.20435744 -0.15003136 -0.18782282\n",
      "  0.10684206 -0.43202216]\n",
      "Training Error:  10.692903811219342\n",
      "====================================================================================================\n",
      "Iteration:  361\n",
      "Previous theta :  [ 0.00716457 -0.03305667  0.06786187  0.01771641  0.104608   -0.12698149\n",
      "  0.31977165 -0.01259395 -0.20508303  0.20435744 -0.15003136 -0.18782282\n",
      "  0.10684206 -0.43202216]\n",
      "New theta_0 : [ 0.00715938 -0.03335993  0.06813513  0.01755242  0.1045826  -0.12767799\n",
      "  0.31941626 -0.01252794 -0.20594771  0.20489618 -0.15019218 -0.18800358\n",
      "  0.10672776 -0.43214492]\n",
      "Training Error:  10.691131752133995\n",
      "====================================================================================================\n",
      "Iteration:  362\n",
      "Previous theta :  [ 0.00715938 -0.03335993  0.06813513  0.01755242  0.1045826  -0.12767799\n",
      "  0.31941626 -0.01252794 -0.20594771  0.20489618 -0.15019218 -0.18800358\n",
      "  0.10672776 -0.43214492]\n",
      "New theta_0 : [ 0.00715423 -0.03366117  0.06840681  0.01739059  0.10455733 -0.12837002\n",
      "  0.31906395 -0.01246196 -0.20680585  0.20543232 -0.15035349 -0.188183\n",
      "  0.10661439 -0.4322661 ]\n",
      "Training Error:  10.689383341766868\n",
      "====================================================================================================\n",
      "Iteration:  363\n",
      "Previous theta :  [ 0.00715423 -0.03366117  0.06840681  0.01739059  0.10455733 -0.12837002\n",
      "  0.31906395 -0.01246196 -0.20680585  0.20543232 -0.15035349 -0.188183\n",
      "  0.10661439 -0.4322661 ]\n",
      "New theta_0 : [ 0.00714912 -0.03396043  0.06867692  0.01723089  0.10453219 -0.12905763\n",
      "  0.31871467 -0.01239603 -0.20765751  0.20596587 -0.15051527 -0.18836109\n",
      "  0.10650194 -0.43238572]\n",
      "Training Error:  10.687658244745474\n",
      "====================================================================================================\n",
      "Iteration:  364\n",
      "Previous theta :  [ 0.00714912 -0.03396043  0.06867692  0.01723089  0.10453219 -0.12905763\n",
      "  0.31871467 -0.01239603 -0.20765751  0.20596587 -0.15051527 -0.18836109\n",
      "  0.10650194 -0.43238572]\n",
      "New theta_0 : [ 0.00714406 -0.03425771  0.06894546  0.01707331  0.10450718 -0.12974084\n",
      "  0.31836839 -0.01233014 -0.20850272  0.20649686 -0.15067753 -0.18853786\n",
      "  0.10639041 -0.4325038 ]\n",
      "Training Error:  10.685956130622271\n",
      "====================================================================================================\n",
      "Iteration:  365\n",
      "Previous theta :  [ 0.00714406 -0.03425771  0.06894546  0.01707331  0.10450718 -0.12974084\n",
      "  0.31836839 -0.01233014 -0.20850272  0.20649686 -0.15067753 -0.18853786\n",
      "  0.10639041 -0.4325038 ]\n",
      "New theta_0 : [ 0.00713904 -0.03455302  0.06921244  0.01691782  0.1044823  -0.13041967\n",
      "  0.31802509 -0.0122643  -0.20934155  0.20702529 -0.15084025 -0.18871333\n",
      "  0.10627979 -0.43262035]\n",
      "Training Error:  10.684276673799955\n",
      "====================================================================================================\n",
      "Iteration:  366\n",
      "Previous theta :  [ 0.00713904 -0.03455302  0.06921244  0.01691782  0.1044823  -0.13041967\n",
      "  0.31802509 -0.0122643  -0.20934155  0.20702529 -0.15084025 -0.18871333\n",
      "  0.10627979 -0.43262035]\n",
      "New theta_0 : [ 0.00713405 -0.03484638  0.06947786  0.01676441  0.10445754 -0.13109415\n",
      "  0.31768474 -0.01219853 -0.21017404  0.20755119 -0.15100342 -0.18888751\n",
      "  0.10617006 -0.43273541]\n",
      "Training Error:  10.682619553457927\n",
      "====================================================================================================\n",
      "Iteration:  367\n",
      "Previous theta :  [ 0.00713405 -0.03484638  0.06947786  0.01676441  0.10445754 -0.13109415\n",
      "  0.31768474 -0.01219853 -0.21017404  0.20755119 -0.15100342 -0.18888751\n",
      "  0.10617006 -0.43273541]\n",
      "New theta_0 : [ 0.00712911 -0.0351378   0.06974172  0.01661305  0.10443291 -0.13176431\n",
      "  0.3173473  -0.01213283 -0.21100023  0.20807457 -0.15116704 -0.1890604\n",
      "  0.10606123 -0.43284898]\n",
      "Training Error:  10.680984453479939\n",
      "====================================================================================================\n",
      "Iteration:  368\n",
      "Previous theta :  [ 0.00712911 -0.0351378   0.06974172  0.01661305  0.10443291 -0.13176431\n",
      "  0.3173473  -0.01213283 -0.21100023  0.20807457 -0.15116704 -0.1890604\n",
      "  0.10606123 -0.43284898]\n",
      "New theta_0 : [ 0.00712421 -0.03542729  0.07000405  0.01646372  0.1044084  -0.13243018\n",
      "  0.31701276 -0.01206719 -0.21182019  0.20859545 -0.15133109 -0.18923203\n",
      "  0.10595328 -0.4329611 ]\n",
      "Training Error:  10.679371062382875\n",
      "====================================================================================================\n",
      "Iteration:  369\n",
      "Previous theta :  [ 0.00712421 -0.03542729  0.07000405  0.01646372  0.1044084  -0.13243018\n",
      "  0.31701276 -0.01206719 -0.21182019  0.20859545 -0.15133109 -0.18923203\n",
      "  0.10595328 -0.4329611 ]\n",
      "New theta_0 : [ 0.00711935 -0.03571487  0.07026483  0.01631641  0.10438402 -0.13309178\n",
      "  0.31668108 -0.01200164 -0.21263395  0.20911385 -0.15149558 -0.18940239\n",
      "  0.1058462  -0.43307178]\n",
      "Training Error:  10.677779073246686\n",
      "====================================================================================================\n",
      "Iteration:  370\n",
      "Previous theta :  [ 0.00711935 -0.03571487  0.07026483  0.01631641  0.10438402 -0.13309178\n",
      "  0.31668108 -0.01200164 -0.21263395  0.20911385 -0.15149558 -0.18940239\n",
      "  0.1058462  -0.43307178]\n",
      "New theta_0 : [ 0.00711453 -0.03600054  0.07052407  0.0161711   0.10435975 -0.13374913\n",
      "  0.31635223 -0.01193618 -0.21344156  0.20962978 -0.15166048 -0.18957151\n",
      "  0.10573999 -0.43318104]\n",
      "Training Error:  10.676208183645418\n",
      "====================================================================================================\n",
      "Iteration:  371\n",
      "Previous theta :  [ 0.00711453 -0.03600054  0.07052407  0.0161711   0.10435975 -0.13374913\n",
      "  0.31635223 -0.01193618 -0.21344156  0.20962978 -0.15166048 -0.18957151\n",
      "  0.10573999 -0.43318104]\n",
      "New theta_0 : [ 0.00710974 -0.03628433  0.07078178  0.01602776  0.10433561 -0.13440227\n",
      "  0.31602619 -0.01187081 -0.21424308  0.21014326 -0.1518258  -0.1897394\n",
      "  0.10563463 -0.43328891]\n",
      "Training Error:  10.674658095579343\n",
      "====================================================================================================\n",
      "Iteration:  372\n",
      "Previous theta :  [ 0.00710974 -0.03628433  0.07078178  0.01602776  0.10433561 -0.13440227\n",
      "  0.31602619 -0.01187081 -0.21424308  0.21014326 -0.1518258  -0.1897394\n",
      "  0.10563463 -0.43328891]\n",
      "New theta_0 : [ 0.007105   -0.03656623  0.07103797  0.01588638  0.10431159 -0.13505122\n",
      "  0.31570292 -0.01180553 -0.21503854  0.2106543  -0.15199153 -0.18990606\n",
      "  0.10553013 -0.43339539]\n",
      "Training Error:  10.673128515408154\n",
      "====================================================================================================\n",
      "Iteration:  373\n",
      "Previous theta :  [ 0.007105   -0.03656623  0.07103797  0.01588638  0.10431159 -0.13505122\n",
      "  0.31570292 -0.01180553 -0.21503854  0.2106543  -0.15199153 -0.18990606\n",
      "  0.10553013 -0.43339539]\n",
      "New theta_0 : [ 0.00710029 -0.03684627  0.07129264  0.01574694  0.10428769 -0.13569601\n",
      "  0.31538241 -0.01174036 -0.215828    0.21116292 -0.15215764 -0.1900715\n",
      "  0.10542647 -0.43350051]\n",
      "Training Error:  10.671619153785223\n",
      "====================================================================================================\n",
      "Iteration:  374\n",
      "Previous theta :  [ 0.00710029 -0.03684627  0.07129264  0.01574694  0.10428769 -0.13569601\n",
      "  0.31538241 -0.01174036 -0.215828    0.21116292 -0.15215764 -0.1900715\n",
      "  0.10542647 -0.43350051]\n",
      "New theta_0 : [ 0.00709561 -0.03712446  0.0715458   0.01560941  0.10426391 -0.13633665\n",
      "  0.31506463 -0.01167529 -0.2166115   0.21166913 -0.15232415 -0.19023575\n",
      "  0.10532364 -0.43360429]\n",
      "Training Error:  10.670129725592899\n",
      "====================================================================================================\n",
      "Iteration:  375\n",
      "Previous theta :  [ 0.00709561 -0.03712446  0.0715458   0.01560941  0.10426391 -0.13633665\n",
      "  0.31506463 -0.01167529 -0.2166115   0.21166913 -0.15232415 -0.19023575\n",
      "  0.10532364 -0.43360429]\n",
      "New theta_0 : [ 0.00709098 -0.0374008   0.07179745  0.01547378  0.10424024 -0.13697318\n",
      "  0.31474954 -0.01161034 -0.21738909  0.21217295 -0.15249104 -0.1903988\n",
      "  0.10522165 -0.43370675]\n",
      "Training Error:  10.668659949878805\n",
      "====================================================================================================\n",
      "Iteration:  376\n",
      "Previous theta :  [ 0.00709098 -0.0374008   0.07179745  0.01547378  0.10424024 -0.13697318\n",
      "  0.31474954 -0.01161034 -0.21738909  0.21217295 -0.15249104 -0.1903988\n",
      "  0.10522165 -0.43370675]\n",
      "New theta_0 : [ 0.00708638 -0.03767532  0.0720476   0.01534004  0.1042167  -0.13760563\n",
      "  0.31443713 -0.0115455  -0.21816081  0.2126744  -0.1526583  -0.19056067\n",
      "  0.10512047 -0.4338079 ]\n",
      "Training Error:  10.667209549793162\n",
      "====================================================================================================\n",
      "Iteration:  377\n",
      "Previous theta :  [ 0.00708638 -0.03767532  0.0720476   0.01534004  0.1042167  -0.13760563\n",
      "  0.31443713 -0.0115455  -0.21816081  0.2126744  -0.1526583  -0.19056067\n",
      "  0.10512047 -0.4338079 ]\n",
      "New theta_0 : [ 0.00708182 -0.03794801  0.07229625  0.01520815  0.10419326 -0.13823401\n",
      "  0.31412736 -0.01148079 -0.2189267   0.21317349 -0.15282593 -0.19072137\n",
      "  0.1050201  -0.43390777]\n",
      "Training Error:  10.665778252527085\n",
      "====================================================================================================\n",
      "Iteration:  378\n",
      "Previous theta :  [ 0.00708182 -0.03794801  0.07229625  0.01520815  0.10419326 -0.13823401\n",
      "  0.31412736 -0.01148079 -0.2189267   0.21317349 -0.15282593 -0.19072137\n",
      "  0.1050201  -0.43390777]\n",
      "New theta_0 : [ 0.00707729 -0.0382189   0.07254342  0.01507811  0.10416995 -0.13885835\n",
      "  0.31382022 -0.01141621 -0.21968682  0.21367024 -0.15299392 -0.19088091\n",
      "  0.10492054 -0.43400637]\n",
      "Training Error:  10.664365789251839\n",
      "====================================================================================================\n",
      "Iteration:  379\n",
      "Previous theta :  [ 0.00707729 -0.0382189   0.07254342  0.01507811  0.10416995 -0.13885835\n",
      "  0.31382022 -0.01141621 -0.21968682  0.21367024 -0.15299392 -0.19088091\n",
      "  0.10492054 -0.43400637]\n",
      "New theta_0 : [ 0.00707279 -0.03848799  0.0727891   0.0149499   0.10414674 -0.13947869\n",
      "  0.31351567 -0.01135175 -0.2204412   0.21416466 -0.15316225 -0.1910393\n",
      "  0.10482178 -0.43410371]\n",
      "Training Error:  10.66297189505907\n",
      "====================================================================================================\n",
      "Iteration:  380\n",
      "Previous theta :  [ 0.00707279 -0.03848799  0.0727891   0.0149499   0.10414674 -0.13947869\n",
      "  0.31351567 -0.01135175 -0.2204412   0.21416466 -0.15316225 -0.1910393\n",
      "  0.10482178 -0.43410371]\n",
      "New theta_0 : [ 0.00706833 -0.03875531  0.0730333   0.01482349  0.10412366 -0.14009503\n",
      "  0.31321369 -0.01128744 -0.2211899   0.21465676 -0.15333093 -0.19119655\n",
      "  0.10472381 -0.43419982]\n",
      "Training Error:  10.661596308901942\n",
      "====================================================================================================\n",
      "Iteration:  381\n",
      "Previous theta :  [ 0.00706833 -0.03875531  0.0730333   0.01482349  0.10412366 -0.14009503\n",
      "  0.31321369 -0.01128744 -0.2211899   0.21465676 -0.15333093 -0.19119655\n",
      "  0.10472381 -0.43419982]\n",
      "New theta_0 : [ 0.00706391 -0.03902085  0.07327604  0.01469888  0.10410068 -0.14070741\n",
      "  0.31291426 -0.01122326 -0.22193295  0.21514657 -0.15349995 -0.19135267\n",
      "  0.10462663 -0.43429471]\n",
      "Training Error:  10.660238773537221\n",
      "====================================================================================================\n",
      "Iteration:  382\n",
      "Previous theta :  [ 0.00706391 -0.03902085  0.07327604  0.01469888  0.10410068 -0.14070741\n",
      "  0.31291426 -0.01122326 -0.22193295  0.21514657 -0.15349995 -0.19135267\n",
      "  0.10462663 -0.43429471]\n",
      "New theta_0 : [ 0.00705952 -0.03928463  0.0735173   0.01457603  0.10407781 -0.14131585\n",
      "  0.31261735 -0.01115923 -0.2226704   0.21563409 -0.15366929 -0.19150768\n",
      "  0.10453022 -0.43438841]\n",
      "Training Error:  10.658899035468245\n",
      "====================================================================================================\n",
      "Iteration:  383\n",
      "Previous theta :  [ 0.00705952 -0.03928463  0.0735173   0.01457603  0.10407781 -0.14131585\n",
      "  0.31261735 -0.01115923 -0.2226704   0.21563409 -0.15366929 -0.19150768\n",
      "  0.10453022 -0.43438841]\n",
      "New theta_0 : [ 0.00705516 -0.03954666  0.07375711  0.01445494  0.10405506 -0.14192038\n",
      "  0.31232294 -0.01109535 -0.22340228  0.21611934 -0.15383896 -0.19166157\n",
      "  0.10443458 -0.43448091]\n",
      "Training Error:  10.657576844888787\n",
      "====================================================================================================\n",
      "Iteration:  384\n",
      "Previous theta :  [ 0.00705516 -0.03954666  0.07375711  0.01445494  0.10405506 -0.14192038\n",
      "  0.31232294 -0.01109535 -0.22340228  0.21611934 -0.15383896 -0.19166157\n",
      "  0.10443458 -0.43448091]\n",
      "New theta_0 : [ 0.00705083 -0.03980696  0.07399547  0.01433559  0.10403241 -0.14252102\n",
      "  0.31203101 -0.01103162 -0.22412865  0.21660234 -0.15400894 -0.19181436\n",
      "  0.1043397  -0.43457225]\n",
      "Training Error:  10.656271955627801\n",
      "====================================================================================================\n",
      "Iteration:  385\n",
      "Previous theta :  [ 0.00705083 -0.03980696  0.07399547  0.01433559  0.10403241 -0.14252102\n",
      "  0.31203101 -0.01103162 -0.22412865  0.21660234 -0.15400894 -0.19181436\n",
      "  0.1043397  -0.43457225]\n",
      "New theta_0 : [ 0.00704653 -0.04006553  0.07423238  0.01421796  0.10400988 -0.14311779\n",
      "  0.31174152 -0.01096804 -0.22484955  0.21708309 -0.15417923 -0.19196606\n",
      "  0.10424558 -0.43466244]\n",
      "Training Error:  10.654984125095014\n",
      "====================================================================================================\n",
      "Iteration:  386\n",
      "Previous theta :  [ 0.00704653 -0.04006553  0.07423238  0.01421796  0.10400988 -0.14311779\n",
      "  0.31174152 -0.01096804 -0.22484955  0.21708309 -0.15417923 -0.19196606\n",
      "  0.10424558 -0.43466244]\n",
      "New theta_0 : [ 0.00704227 -0.04032239  0.07446786  0.01410203  0.10398745 -0.14371072\n",
      "  0.31145447 -0.01090463 -0.22556501  0.21756162 -0.15434982 -0.19211668\n",
      "  0.10415221 -0.43475149]\n",
      "Training Error:  10.653713114227374\n",
      "====================================================================================================\n",
      "Iteration:  387\n",
      "Previous theta :  [ 0.00704227 -0.04032239  0.07446786  0.01410203  0.10398745 -0.14371072\n",
      "  0.31145447 -0.01090463 -0.22556501  0.21756162 -0.15434982 -0.19211668\n",
      "  0.10415221 -0.43475149]\n",
      "New theta_0 : [ 0.00703804 -0.04057754  0.07470189  0.01398779  0.10396513 -0.14429983\n",
      "  0.31116981 -0.01084138 -0.22627509  0.21803794 -0.1545207  -0.19226623\n",
      "  0.10405959 -0.43483942]\n",
      "Training Error:  10.65245868743632\n",
      "====================================================================================================\n",
      "Iteration:  388\n",
      "Previous theta :  [ 0.00703804 -0.04057754  0.07470189  0.01398779  0.10396513 -0.14429983\n",
      "  0.31116981 -0.01084138 -0.22627509  0.21803794 -0.1545207  -0.19226623\n",
      "  0.10405959 -0.43483942]\n",
      "New theta_0 : [ 0.00703384 -0.040831    0.07493451  0.01387521  0.10394292 -0.14488514\n",
      "  0.31088754 -0.01077829 -0.22697981  0.21851205 -0.15469187 -0.19241471\n",
      "  0.1039677  -0.43492624]\n",
      "Training Error:  10.651220612555893\n",
      "====================================================================================================\n",
      "Iteration:  389\n",
      "Previous theta :  [ 0.00703384 -0.040831    0.07493451  0.01387521  0.10394292 -0.14488514\n",
      "  0.31088754 -0.01077829 -0.22697981  0.21851205 -0.15469187 -0.19241471\n",
      "  0.1039677  -0.43492624]\n",
      "New theta_0 : [ 0.00702967 -0.04108278  0.0751657   0.01376429  0.10392081 -0.14546669\n",
      "  0.31060763 -0.01071538 -0.22767922  0.21898399 -0.15486332 -0.19256215\n",
      "  0.10387654 -0.43501198]\n",
      "Training Error:  10.649998660791596\n",
      "====================================================================================================\n",
      "Iteration:  390\n",
      "Previous theta :  [ 0.00702967 -0.04108278  0.0751657   0.01376429  0.10392081 -0.14546669\n",
      "  0.31060763 -0.01071538 -0.22767922  0.21898399 -0.15486332 -0.19256215\n",
      "  0.10387654 -0.43501198]\n",
      "New theta_0 : [ 0.00702553 -0.0413329   0.07539548  0.01365501  0.10389881 -0.14604449\n",
      "  0.31033005 -0.01065264 -0.22837337  0.21945375 -0.15503504 -0.19270853\n",
      "  0.10378611 -0.43509664]\n",
      "Training Error:  10.64879260667012\n",
      "====================================================================================================\n",
      "Iteration:  391\n",
      "Previous theta :  [ 0.00702553 -0.0413329   0.07539548  0.01365501  0.10389881 -0.14604449\n",
      "  0.31033005 -0.01065264 -0.22837337  0.21945375 -0.15503504 -0.19270853\n",
      "  0.10378611 -0.43509664]\n",
      "New theta_0 : [ 0.00702142 -0.04158135  0.07562385  0.01354734  0.10387691 -0.14661856\n",
      "  0.31005479 -0.01059008 -0.22906229  0.21992135 -0.15520704 -0.19285389\n",
      "  0.10369639 -0.43518023]\n",
      "Training Error:  10.647602227989792\n",
      "====================================================================================================\n",
      "Iteration:  392\n",
      "Previous theta :  [ 0.00702142 -0.04158135  0.07562385  0.01354734  0.10387691 -0.14661856\n",
      "  0.31005479 -0.01059008 -0.22906229  0.21992135 -0.15520704 -0.19285389\n",
      "  0.10369639 -0.43518023]\n",
      "New theta_0 : [ 0.00701735 -0.04182816  0.07585082  0.01344128  0.10385511 -0.14718893\n",
      "  0.30978181 -0.01052769 -0.22974602  0.22038681 -0.15537929 -0.19299821\n",
      "  0.10360738 -0.43526278]\n",
      "Training Error:  10.646427305771795\n",
      "====================================================================================================\n",
      "Iteration:  393\n",
      "Previous theta :  [ 0.00701735 -0.04182816  0.07585082  0.01344128  0.10385511 -0.14718893\n",
      "  0.30978181 -0.01052769 -0.22974602  0.22038681 -0.15537929 -0.19299821\n",
      "  0.10360738 -0.43526278]\n",
      "New theta_0 : [ 0.0070133  -0.04207333  0.07607639  0.01333681  0.10383342 -0.14775562\n",
      "  0.30951111 -0.01046549 -0.2304246   0.22085014 -0.15555179 -0.19314152\n",
      "  0.10351908 -0.4353443 ]\n",
      "Training Error:  10.645267624212167\n",
      "====================================================================================================\n",
      "Iteration:  394\n",
      "Previous theta :  [ 0.0070133  -0.04207333  0.07607639  0.01333681  0.10383342 -0.14775562\n",
      "  0.30951111 -0.01046549 -0.2304246   0.22085014 -0.15555179 -0.19314152\n",
      "  0.10351908 -0.4353443 ]\n",
      "New theta_0 : [ 0.00700927 -0.04231687  0.07630058  0.01323391  0.10381183 -0.14831866\n",
      "  0.30924266 -0.01040347 -0.23109808  0.22131135 -0.15572455 -0.19328382\n",
      "  0.10343148 -0.43542481]\n",
      "Training Error:  10.644122970634516\n",
      "====================================================================================================\n",
      "Iteration:  395\n",
      "Previous theta :  [ 0.00700927 -0.04231687  0.07630058  0.01323391  0.10381183 -0.14831866\n",
      "  0.30924266 -0.01040347 -0.23109808  0.22131135 -0.15572455 -0.19328382\n",
      "  0.10343148 -0.43542481]\n",
      "New theta_0 : [ 0.00700528 -0.0425588   0.07652339  0.01313256  0.10379034 -0.14887807\n",
      "  0.30897643 -0.01034164 -0.23176648  0.22177046 -0.15589754 -0.19342512\n",
      "  0.10334457 -0.43550431]\n",
      "Training Error:  10.642993135443463\n",
      "====================================================================================================\n",
      "Iteration:  396\n",
      "Previous theta :  [ 0.00700528 -0.0425588   0.07652339  0.01313256  0.10379034 -0.14887807\n",
      "  0.30897643 -0.01034164 -0.23176648  0.22177046 -0.15589754 -0.19342512\n",
      "  0.10334457 -0.43550431]\n",
      "New theta_0 : [ 0.00700132 -0.04279913  0.07674482  0.01303275  0.10376896 -0.14943386\n",
      "  0.30871241 -0.01028    -0.23242986  0.22222747 -0.15607077 -0.19356543\n",
      "  0.10325835 -0.43558281]\n",
      "Training Error:  10.641877912078822\n",
      "====================================================================================================\n",
      "Iteration:  397\n",
      "Previous theta :  [ 0.00700132 -0.04279913  0.07674482  0.01303275  0.10376896 -0.14943386\n",
      "  0.30871241 -0.01028    -0.23242986  0.22222747 -0.15607077 -0.19356543\n",
      "  0.10325835 -0.43558281]\n",
      "New theta_0 : [ 0.00699738 -0.04303786  0.07696488  0.01293447  0.10374767 -0.14998607\n",
      "  0.30845058 -0.01021856 -0.23308824  0.22268241 -0.15624423 -0.19370475\n",
      "  0.10317281 -0.43566035]\n",
      "Training Error:  10.640777096970458\n",
      "====================================================================================================\n",
      "Iteration:  398\n",
      "Previous theta :  [ 0.00699738 -0.04303786  0.07696488  0.01293447  0.10374767 -0.14998607\n",
      "  0.30845058 -0.01021856 -0.23308824  0.22268241 -0.15624423 -0.19370475\n",
      "  0.10317281 -0.43566035]\n",
      "New theta_0 : [ 0.00699347 -0.04327501  0.07718358  0.0128377   0.10372648 -0.15053472\n",
      "  0.30819091 -0.01015731 -0.23374166  0.22313528 -0.15641792 -0.1938431\n",
      "  0.10308794 -0.43573692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.639690489493852\n",
      "====================================================================================================\n",
      "Iteration:  399\n",
      "Previous theta :  [ 0.00699347 -0.04327501  0.07718358  0.0128377   0.10372648 -0.15053472\n",
      "  0.30819091 -0.01015731 -0.23374166  0.22313528 -0.15641792 -0.1938431\n",
      "  0.10308794 -0.43573692]\n",
      "New theta_0 : [ 0.00698959 -0.04351058  0.07740093  0.01274242  0.10370539 -0.15107982\n",
      "  0.30793339 -0.01009625 -0.23439018  0.2235861  -0.15659182 -0.19398049\n",
      "  0.10300374 -0.43581253]\n",
      "Training Error:  10.638617891926344\n",
      "====================================================================================================\n",
      "Iteration:  400\n",
      "Previous theta :  [ 0.00698959 -0.04351058  0.07740093  0.01274242  0.10370539 -0.15107982\n",
      "  0.30793339 -0.01009625 -0.23439018  0.2235861  -0.15659182 -0.19398049\n",
      "  0.10300374 -0.43581253]\n",
      "New theta_0 : [ 0.00698574 -0.0437446   0.07761693  0.01264862  0.10368439 -0.15162139\n",
      "  0.30767799 -0.0100354  -0.23503381  0.22403488 -0.15676593 -0.19411691\n",
      "  0.10292021 -0.43588722]\n",
      "Training Error:  10.637559109404059\n",
      "====================================================================================================\n",
      "Iteration:  401\n",
      "Previous theta :  [ 0.00698574 -0.0437446   0.07761693  0.01264862  0.10368439 -0.15162139\n",
      "  0.30767799 -0.0100354  -0.23503381  0.22403488 -0.15676593 -0.19411691\n",
      "  0.10292021 -0.43588722]\n",
      "New theta_0 : [ 0.00698191 -0.04397706  0.07783159  0.01255629  0.1036635  -0.15215947\n",
      "  0.30742469 -0.00997475 -0.2356726   0.22448164 -0.15694025 -0.19425238\n",
      "  0.10283733 -0.43596097]\n",
      "Training Error:  10.636513949879465\n",
      "====================================================================================================\n",
      "Iteration:  402\n",
      "Previous theta :  [ 0.00698191 -0.04397706  0.07783159  0.01255629  0.1036635  -0.15215947\n",
      "  0.30742469 -0.00997475 -0.2356726   0.22448164 -0.15694025 -0.19425238\n",
      "  0.10283733 -0.43596097]\n",
      "New theta_0 : [ 0.00697811 -0.04420798  0.07804491  0.0124654   0.1036427  -0.15269408\n",
      "  0.30717349 -0.0099143  -0.23630658  0.22492638 -0.15711476 -0.19438691\n",
      "  0.10275511 -0.43603382]\n",
      "Training Error:  10.635482224079608\n",
      "====================================================================================================\n",
      "Iteration:  403\n",
      "Previous theta :  [ 0.00697811 -0.04420798  0.07804491  0.0124654   0.1036427  -0.15269408\n",
      "  0.30717349 -0.0099143  -0.23630658  0.22492638 -0.15711476 -0.19438691\n",
      "  0.10275511 -0.43603382]\n",
      "New theta_0 : [ 0.00697434 -0.04443737  0.07825691  0.01237595  0.10362199 -0.15322523\n",
      "  0.30692434 -0.00985406 -0.2369358   0.22536912 -0.15728947 -0.19452051\n",
      "  0.10267353 -0.43610577]\n",
      "Training Error:  10.634463745464968\n",
      "====================================================================================================\n",
      "Iteration:  404\n",
      "Previous theta :  [ 0.00697434 -0.04443737  0.07825691  0.01237595  0.10362199 -0.15322523\n",
      "  0.30692434 -0.00985406 -0.2369358   0.22536912 -0.15728947 -0.19452051\n",
      "  0.10267353 -0.43610577]\n",
      "New theta_0 : [ 0.00697059 -0.04466523  0.07846758  0.01228791  0.10360138 -0.15375294\n",
      "  0.30667724 -0.00979402 -0.23756029  0.22580986 -0.15746437 -0.19465318\n",
      "  0.10259259 -0.43617683]\n",
      "Training Error:  10.63345833018896\n",
      "====================================================================================================\n",
      "Iteration:  405\n",
      "Previous theta :  [ 0.00697059 -0.04466523  0.07846758  0.01228791  0.10360138 -0.15375294\n",
      "  0.30667724 -0.00979402 -0.23756029  0.22580986 -0.15746437 -0.19465318\n",
      "  0.10259259 -0.43617683]\n",
      "New theta_0 : [ 0.00696687 -0.04489159  0.07867694  0.01220129  0.10358087 -0.15427724\n",
      "  0.30643217 -0.0097342  -0.23818008  0.22624863 -0.15763945 -0.19478492\n",
      "  0.10251229 -0.43624701]\n",
      "Training Error:  10.632465797058025\n",
      "====================================================================================================\n",
      "Iteration:  406\n",
      "Previous theta :  [ 0.00696687 -0.04489159  0.07867694  0.01220129  0.10358087 -0.15427724\n",
      "  0.30643217 -0.0097342  -0.23818008  0.22624863 -0.15763945 -0.19478492\n",
      "  0.10251229 -0.43624701]\n",
      "New theta_0 : [ 0.00696317 -0.04511644  0.07888499  0.01211605  0.10356044 -0.15479815\n",
      "  0.30618911 -0.00967458 -0.23879521  0.22668544 -0.15781471 -0.19491576\n",
      "  0.10243262 -0.43631634]\n",
      "Training Error:  10.631485967492361\n",
      "====================================================================================================\n",
      "Iteration:  407\n",
      "Previous theta :  [ 0.00696317 -0.04511644  0.07888499  0.01211605  0.10356044 -0.15479815\n",
      "  0.30618911 -0.00967458 -0.23879521  0.22668544 -0.15781471 -0.19491576\n",
      "  0.10243262 -0.43631634]\n",
      "New theta_0 : [ 0.0069595  -0.04533981  0.07909174  0.01203219  0.10354011 -0.15531569\n",
      "  0.30594804 -0.00961518 -0.23940572  0.22712029 -0.15799014 -0.19504569\n",
      "  0.10235358 -0.43638481]\n",
      "Training Error:  10.630518665487237\n",
      "====================================================================================================\n",
      "Iteration:  408\n",
      "Previous theta :  [ 0.0069595  -0.04533981  0.07909174  0.01203219  0.10354011 -0.15531569\n",
      "  0.30594804 -0.00961518 -0.23940572  0.22712029 -0.15799014 -0.19504569\n",
      "  0.10235358 -0.43638481]\n",
      "New theta_0 : [ 0.00695585 -0.04556169  0.0792972   0.0119497   0.10351988 -0.15582988\n",
      "  0.30570893 -0.009556   -0.24001164  0.2275532  -0.15816573 -0.19517473\n",
      "  0.10227515 -0.43645244]\n",
      "Training Error:  10.629563717574893\n",
      "====================================================================================================\n",
      "Iteration:  409\n",
      "Previous theta :  [ 0.00695585 -0.04556169  0.0792972   0.0119497   0.10351988 -0.15582988\n",
      "  0.30570893 -0.009556   -0.24001164  0.2275532  -0.15816573 -0.19517473\n",
      "  0.10227515 -0.43645244]\n",
      "New theta_0 : [ 0.00695223 -0.0457821   0.07950137  0.01186855  0.10349973 -0.15634075\n",
      "  0.30547178 -0.00949703 -0.240613    0.22798418 -0.15834148 -0.19530288\n",
      "  0.10219734 -0.43651924]\n",
      "Training Error:  10.628620952787026\n",
      "====================================================================================================\n",
      "Iteration:  410\n",
      "Previous theta :  [ 0.00695223 -0.0457821   0.07950137  0.01186855  0.10349973 -0.15634075\n",
      "  0.30547178 -0.00949703 -0.240613    0.22798418 -0.15834148 -0.19530288\n",
      "  0.10219734 -0.43651924]\n",
      "New theta_0 : [ 0.00694863 -0.04600105  0.07970426  0.01178874  0.10347967 -0.15684831\n",
      "  0.30523657 -0.00943827 -0.24120985  0.22841324 -0.15851739 -0.19543014\n",
      "  0.10212013 -0.43658523]\n",
      "Training Error:  10.627690202617844\n",
      "====================================================================================================\n",
      "Iteration:  411\n",
      "Previous theta :  [ 0.00694863 -0.04600105  0.07970426  0.01178874  0.10347967 -0.15684831\n",
      "  0.30523657 -0.00943827 -0.24120985  0.22841324 -0.15851739 -0.19543014\n",
      "  0.10212013 -0.43658523]\n",
      "New theta_0 : [ 0.00694506 -0.04621855  0.07990587  0.01171025  0.10345971 -0.15735258\n",
      "  0.30500327 -0.00937974 -0.24180221  0.2288404  -0.15869345 -0.19555653\n",
      "  0.10204354 -0.43665041]\n",
      "Training Error:  10.626771300987684\n",
      "====================================================================================================\n",
      "Iteration:  412\n",
      "Previous theta :  [ 0.00694506 -0.04621855  0.07990587  0.01171025  0.10345971 -0.15735258\n",
      "  0.30500327 -0.00937974 -0.24180221  0.2288404  -0.15869345 -0.19555653\n",
      "  0.10204354 -0.43665041]\n",
      "New theta_0 : [ 0.00694151 -0.04643461  0.08010622  0.01163307  0.10343983 -0.15785358\n",
      "  0.30477187 -0.00932143 -0.24239011  0.22926566 -0.15886966 -0.19568205\n",
      "  0.10196754 -0.4367148 ]\n",
      "Training Error:  10.62586408420718\n",
      "====================================================================================================\n",
      "Iteration:  413\n",
      "Previous theta :  [ 0.00694151 -0.04643461  0.08010622  0.01163307  0.10343983 -0.15785358\n",
      "  0.30477187 -0.00932143 -0.24239011  0.22926566 -0.15886966 -0.19568205\n",
      "  0.10196754 -0.4367148 ]\n",
      "New theta_0 : [ 0.00693799 -0.04664923  0.0803053   0.01155718  0.10342005 -0.15835134\n",
      "  0.30454235 -0.00926333 -0.24297361  0.22968903 -0.159046   -0.19580671\n",
      "  0.10189213 -0.4367784 ]\n",
      "Training Error:  10.624968390941973\n",
      "====================================================================================================\n",
      "Iteration:  414\n",
      "Previous theta :  [ 0.00693799 -0.04664923  0.0803053   0.01155718  0.10342005 -0.15835134\n",
      "  0.30454235 -0.00926333 -0.24297361  0.22968903 -0.159046   -0.19580671\n",
      "  0.10189213 -0.4367784 ]\n",
      "New theta_0 : [ 0.00693448 -0.04686243  0.08050313  0.01148257  0.10340035 -0.15884588\n",
      "  0.30431469 -0.00920546 -0.24355271  0.23011054 -0.15922248 -0.19593052\n",
      "  0.10181731 -0.43684123]\n",
      "Training Error:  10.624084062177959\n",
      "====================================================================================================\n",
      "Iteration:  415\n",
      "Previous theta :  [ 0.00693448 -0.04686243  0.08050313  0.01148257  0.10340035 -0.15884588\n",
      "  0.30431469 -0.00920546 -0.24355271  0.23011054 -0.15922248 -0.19593052\n",
      "  0.10181731 -0.43684123]\n",
      "New theta_0 : [ 0.006931   -0.04707422  0.08069972  0.01140923  0.10338074 -0.15933721\n",
      "  0.30408888 -0.00914782 -0.24412747  0.23053018 -0.15939908 -0.19605348\n",
      "  0.10174308 -0.43690329]\n",
      "Training Error:  10.62321094118706\n",
      "====================================================================================================\n",
      "Iteration:  416\n",
      "Previous theta :  [ 0.006931   -0.04707422  0.08069972  0.01140923  0.10338074 -0.15933721\n",
      "  0.30408888 -0.00914782 -0.24412747  0.23053018 -0.15939908 -0.19605348\n",
      "  0.10174308 -0.43690329]\n",
      "New theta_0 : [ 0.00692755 -0.04728461  0.08089506  0.01133715  0.10336121 -0.15982535\n",
      "  0.30386491 -0.0090904  -0.24469792  0.23094798 -0.15957581 -0.1961756\n",
      "  0.10166942 -0.43696461]\n",
      "Training Error:  10.622348873493518\n",
      "====================================================================================================\n",
      "Iteration:  417\n",
      "Previous theta :  [ 0.00692755 -0.04728461  0.08089506  0.01133715  0.10336121 -0.15982535\n",
      "  0.30386491 -0.0090904  -0.24469792  0.23094798 -0.15957581 -0.1961756\n",
      "  0.10166942 -0.43696461]\n",
      "New theta_0 : [ 0.00692411 -0.0474936   0.08108917  0.01126631  0.10334177 -0.16031033\n",
      "  0.30364274 -0.0090332  -0.24526407  0.23136393 -0.15975266 -0.19629689\n",
      "  0.10159634 -0.43702518]\n",
      "Training Error:  10.621497706840696\n",
      "====================================================================================================\n",
      "Iteration:  418\n",
      "Previous theta :  [ 0.00692411 -0.0474936   0.08108917  0.01126631  0.10334177 -0.16031033\n",
      "  0.30364274 -0.0090332  -0.24526407  0.23136393 -0.15975266 -0.19629689\n",
      "  0.10159634 -0.43702518]\n",
      "New theta_0 : [ 0.0069207  -0.0477012   0.08128205  0.0111967   0.10332242 -0.16079217\n",
      "  0.30342237 -0.00897624 -0.24582598  0.23177806 -0.15992963 -0.19641735\n",
      "  0.10152383 -0.43708502]\n",
      "Training Error:  10.620657291158382\n",
      "====================================================================================================\n",
      "Iteration:  419\n",
      "Previous theta :  [ 0.0069207  -0.0477012   0.08128205  0.0111967   0.10332242 -0.16079217\n",
      "  0.30342237 -0.00897624 -0.24582598  0.23177806 -0.15992963 -0.19641735\n",
      "  0.10152383 -0.43708502]\n",
      "New theta_0 : [ 0.00691731 -0.04790743  0.08147372  0.0111283   0.10330316 -0.16127088\n",
      "  0.30320378 -0.0089195  -0.24638367  0.23219038 -0.1601067  -0.19653699\n",
      "  0.10145188 -0.43714414]\n",
      "Training Error:  10.619827478530587\n",
      "====================================================================================================\n",
      "Iteration:  420\n",
      "Previous theta :  [ 0.00691731 -0.04790743  0.08147372  0.0111283   0.10330316 -0.16127088\n",
      "  0.30320378 -0.0089195  -0.24638367  0.23219038 -0.1601067  -0.19653699\n",
      "  0.10145188 -0.43714414]\n",
      "New theta_0 : [ 0.00691394 -0.04811229  0.08166416  0.01106111  0.10328397 -0.16174649\n",
      "  0.30298695 -0.00886298 -0.24693717  0.23260088 -0.16028388 -0.19665582\n",
      "  0.10138049 -0.43720254]\n",
      "Training Error:  10.619008123163821\n",
      "====================================================================================================\n",
      "Iteration:  421\n",
      "Previous theta :  [ 0.00691394 -0.04811229  0.08166416  0.01106111  0.10328397 -0.16174649\n",
      "  0.30298695 -0.00886298 -0.24693717  0.23260088 -0.16028388 -0.19665582\n",
      "  0.10138049 -0.43720254]\n",
      "New theta_0 : [ 0.0069106  -0.0483158   0.0818534   0.01099511  0.10326487 -0.16221901\n",
      "  0.30277187 -0.0088067  -0.24748651  0.2330096  -0.16046115 -0.19677384\n",
      "  0.10130966 -0.43726024]\n",
      "Training Error:  10.61819908135587\n",
      "====================================================================================================\n",
      "Iteration:  422\n",
      "Previous theta :  [ 0.0069106  -0.0483158   0.0818534   0.01099511  0.10326487 -0.16221901\n",
      "  0.30277187 -0.0088067  -0.24748651  0.2330096  -0.16046115 -0.19677384\n",
      "  0.10130966 -0.43726024]\n",
      "New theta_0 : [ 0.00690727 -0.04851796  0.08204145  0.01093028  0.10324586 -0.16268846\n",
      "  0.30255852 -0.00875065 -0.24803173  0.23341653 -0.16063853 -0.19689107\n",
      "  0.10123937 -0.43731725]\n",
      "Training Error:  10.617400211465018\n",
      "====================================================================================================\n",
      "Iteration:  423\n",
      "Previous theta :  [ 0.00690727 -0.04851796  0.08204145  0.01093028  0.10324586 -0.16268846\n",
      "  0.30255852 -0.00875065 -0.24803173  0.23341653 -0.16063853 -0.19689107\n",
      "  0.10123937 -0.43731725]\n",
      "New theta_0 : [ 0.00690397 -0.04871877  0.08222829  0.01086663  0.10322693 -0.16315487\n",
      "  0.30234688 -0.00869483 -0.24857286  0.23382168 -0.16081599 -0.1970075\n",
      "  0.10116964 -0.43737358]\n",
      "Training Error:  10.616611373879747\n",
      "====================================================================================================\n",
      "Iteration:  424\n",
      "Previous theta :  [ 0.00690397 -0.04871877  0.08222829  0.01086663  0.10322693 -0.16315487\n",
      "  0.30234688 -0.00869483 -0.24857286  0.23382168 -0.16081599 -0.1970075\n",
      "  0.10116964 -0.43737358]\n",
      "New theta_0 : [ 0.00690069 -0.04891826  0.08241395  0.01080412  0.10320808 -0.16361825\n",
      "  0.30213694 -0.00863924 -0.24910993  0.23422507 -0.16099354 -0.19712314\n",
      "  0.10110044 -0.43742923]\n",
      "Training Error:  10.615832430988894\n",
      "====================================================================================================\n",
      "Iteration:  425\n",
      "Previous theta :  [ 0.00690069 -0.04891826  0.08241395  0.01080412  0.10320808 -0.16361825\n",
      "  0.30213694 -0.00863924 -0.24910993  0.23422507 -0.16099354 -0.19712314\n",
      "  0.10110044 -0.43742923]\n",
      "New theta_0 : [ 0.00689743 -0.04911643  0.08259843  0.01074277  0.10318931 -0.16407862\n",
      "  0.30192869 -0.00858388 -0.24964297  0.23462671 -0.16117117 -0.197238\n",
      "  0.10103178 -0.43748421]\n",
      "Training Error:  10.615063247152252\n",
      "====================================================================================================\n",
      "Iteration:  426\n",
      "Previous theta :  [ 0.00689743 -0.04911643  0.08259843  0.01074277  0.10318931 -0.16407862\n",
      "  0.30192869 -0.00858388 -0.24964297  0.23462671 -0.16117117 -0.197238\n",
      "  0.10103178 -0.43748421]\n",
      "New theta_0 : [ 0.00689419 -0.04931328  0.08278174  0.01068254  0.10317062 -0.164536\n",
      "  0.30172211 -0.00852875 -0.250172    0.23502661 -0.16134888 -0.19735208\n",
      "  0.10096365 -0.43753854]\n",
      "Training Error:  10.614303688671615\n",
      "====================================================================================================\n",
      "Iteration:  427\n",
      "Previous theta :  [ 0.00689419 -0.04931328  0.08278174  0.01068254  0.10317062 -0.164536\n",
      "  0.30172211 -0.00852875 -0.250172    0.23502661 -0.16134888 -0.19735208\n",
      "  0.10096365 -0.43753854]\n",
      "New theta_0 : [ 0.00689097 -0.04950883  0.08296388  0.01062343  0.10315201 -0.16499041\n",
      "  0.30151718 -0.00847386 -0.25069707  0.23542477 -0.16152666 -0.1974654\n",
      "  0.10089606 -0.43759222]\n",
      "Training Error:  10.613553623762263\n",
      "====================================================================================================\n",
      "Iteration:  428\n",
      "Previous theta :  [ 0.00689097 -0.04950883  0.08296388  0.01062343  0.10315201 -0.16499041\n",
      "  0.30151718 -0.00847386 -0.25069707  0.23542477 -0.16152666 -0.1974654\n",
      "  0.10089606 -0.43759222]\n",
      "New theta_0 : [ 0.00688777 -0.04970309  0.08314486  0.01056542  0.10313349 -0.16544187\n",
      "  0.30131388 -0.0084192  -0.2512182   0.23582122 -0.16170451 -0.19757795\n",
      "  0.10082898 -0.43764527]\n",
      "Training Error:  10.612812922524867\n",
      "====================================================================================================\n",
      "Iteration:  429\n",
      "Previous theta :  [ 0.00688777 -0.04970309  0.08314486  0.01056542  0.10313349 -0.16544187\n",
      "  0.30131388 -0.0084192  -0.2512182   0.23582122 -0.16170451 -0.19757795\n",
      "  0.10082898 -0.43764527]\n",
      "New theta_0 : [ 0.00688459 -0.04989606  0.08332468  0.01050852  0.10311504 -0.16589039\n",
      "  0.30111222 -0.00836478 -0.25173541  0.23621595 -0.16188242 -0.19768975\n",
      "  0.10076242 -0.43769768]\n",
      "Training Error:  10.612081456917824\n",
      "====================================================================================================\n",
      "Iteration:  430\n",
      "Previous theta :  [ 0.00688459 -0.04989606  0.08332468  0.01050852  0.10311504 -0.16589039\n",
      "  0.30111222 -0.00836478 -0.25173541  0.23621595 -0.16188242 -0.19768975\n",
      "  0.10076242 -0.43769768]\n",
      "New theta_0 : [ 0.00688144 -0.05008776  0.08350336  0.01045269  0.10309667 -0.166336\n",
      "  0.30091216 -0.00831059 -0.25224875  0.23660898 -0.16206039 -0.19780079\n",
      "  0.10069638 -0.43774947]\n",
      "Training Error:  10.611359100729999\n",
      "====================================================================================================\n",
      "Iteration:  431\n",
      "Previous theta :  [ 0.00688144 -0.05008776  0.08350336  0.01045269  0.10309667 -0.166336\n",
      "  0.30091216 -0.00831059 -0.25224875  0.23660898 -0.16206039 -0.19780079\n",
      "  0.10069638 -0.43774947]\n",
      "New theta_0 : [ 0.0068783  -0.05027818  0.0836809   0.01039794  0.10307838 -0.16677871\n",
      "  0.30071369 -0.00825663 -0.25275824  0.23700032 -0.16223841 -0.19791109\n",
      "  0.10063085 -0.43780065]\n",
      "Training Error:  10.610645729553895\n",
      "====================================================================================================\n",
      "Iteration:  432\n",
      "Previous theta :  [ 0.0068783  -0.05027818  0.0836809   0.01039794  0.10307838 -0.16677871\n",
      "  0.30071369 -0.00825663 -0.25275824  0.23700032 -0.16223841 -0.19791109\n",
      "  0.10063085 -0.43780065]\n",
      "New theta_0 : [ 0.00687518 -0.05046735  0.0838573   0.01034425  0.10306017 -0.16721854\n",
      "  0.3005168  -0.00820291 -0.25326391  0.23738998 -0.16241649 -0.19802065\n",
      "  0.10056583 -0.43785122]\n",
      "Training Error:  10.609941220759193\n",
      "====================================================================================================\n",
      "Iteration:  433\n",
      "Previous theta :  [ 0.00687518 -0.05046735  0.0838573   0.01034425  0.10306017 -0.16721854\n",
      "  0.3005168  -0.00820291 -0.25326391  0.23738998 -0.16241649 -0.19802065\n",
      "  0.10056583 -0.43785122]\n",
      "New theta_0 : [ 0.00687208 -0.05065526  0.08403257  0.01029161  0.10304203 -0.16765551\n",
      "  0.30032148 -0.00814942 -0.25376578  0.23777796 -0.16259461 -0.19812948\n",
      "  0.10050131 -0.4379012 ]\n",
      "Training Error:  10.609245453466723\n",
      "====================================================================================================\n",
      "Iteration:  434\n",
      "Previous theta :  [ 0.00687208 -0.05065526  0.08403257  0.01029161  0.10304203 -0.16765551\n",
      "  0.30032148 -0.00814942 -0.25376578  0.23777796 -0.16259461 -0.19812948\n",
      "  0.10050131 -0.4379012 ]\n",
      "New theta_0 : [ 0.006869   -0.05084193  0.08420673  0.01024     0.10302398 -0.16808965\n",
      "  0.30012771 -0.00809617 -0.25426389  0.23816429 -0.16277278 -0.19823758\n",
      "  0.10043728 -0.43795059]\n",
      "Training Error:  10.608558308522802\n",
      "====================================================================================================\n",
      "Iteration:  435\n",
      "Previous theta :  [ 0.006869   -0.05084193  0.08420673  0.01024     0.10302398 -0.16808965\n",
      "  0.30012771 -0.00809617 -0.25426389  0.23816429 -0.16277278 -0.19823758\n",
      "  0.10043728 -0.43795059]\n",
      "New theta_0 : [ 0.00686594 -0.05102737  0.08437977  0.01018943  0.10300599 -0.16852095\n",
      "  0.29993548 -0.00804316 -0.25475826  0.23854896 -0.16295099 -0.19834496\n",
      "  0.10037375 -0.4379994 ]\n",
      "Training Error:  10.607879668473966\n",
      "====================================================================================================\n",
      "Iteration:  436\n",
      "Previous theta :  [ 0.00686594 -0.05102737  0.08437977  0.01018943  0.10300599 -0.16852095\n",
      "  0.29993548 -0.00804316 -0.25475826  0.23854896 -0.16295099 -0.19834496\n",
      "  0.10037375 -0.4379994 ]\n",
      "New theta_0 : [ 0.0068629  -0.05121157  0.0845517   0.01013987  0.10298809 -0.16894945\n",
      "  0.29974477 -0.00799038 -0.25524893  0.23893199 -0.16312923 -0.19845162\n",
      "  0.10031071 -0.43804763]\n",
      "Training Error:  10.607209417542078\n",
      "====================================================================================================\n",
      "Iteration:  437\n",
      "Previous theta :  [ 0.0068629  -0.05121157  0.0845517   0.01013987  0.10298809 -0.16894945\n",
      "  0.29974477 -0.00799038 -0.25524893  0.23893199 -0.16312923 -0.19845162\n",
      "  0.10031071 -0.43804763]\n",
      "New theta_0 : [ 0.00685987 -0.05139457  0.08472253  0.01009132  0.10297026 -0.16937516\n",
      "  0.29955557 -0.00793783 -0.25573592  0.23931338 -0.1633075  -0.19855757\n",
      "  0.10024816 -0.4380953 ]\n",
      "Training Error:  10.60654744159981\n",
      "====================================================================================================\n",
      "Iteration:  438\n",
      "Previous theta :  [ 0.00685987 -0.05139457  0.08472253  0.01009132  0.10297026 -0.16937516\n",
      "  0.29955557 -0.00793783 -0.25573592  0.23931338 -0.1633075  -0.19855757\n",
      "  0.10024816 -0.4380953 ]\n",
      "New theta_0 : [ 0.00685687 -0.05157635  0.08489226  0.01004377  0.1029525  -0.1697981\n",
      "  0.29936786 -0.00788552 -0.25621926  0.23969316 -0.16348579 -0.19866282\n",
      "  0.10018609 -0.43814242]\n",
      "Training Error:  10.605893628146488\n",
      "====================================================================================================\n",
      "Iteration:  439\n",
      "Previous theta :  [ 0.00685687 -0.05157635  0.08489226  0.01004377  0.1029525  -0.1697981\n",
      "  0.29936786 -0.00788552 -0.25621926  0.23969316 -0.16348579 -0.19866282\n",
      "  0.10018609 -0.43814242]\n",
      "New theta_0 : [ 0.00685388 -0.05175693  0.08506091  0.00999719  0.10293482 -0.17021829\n",
      "  0.29918164 -0.00783345 -0.25669897  0.24007131 -0.16366411 -0.19876737\n",
      "  0.10012449 -0.43818898]\n",
      "Training Error:  10.605247866284301\n",
      "====================================================================================================\n",
      "Iteration:  440\n",
      "Previous theta :  [ 0.00685388 -0.05175693  0.08506091  0.00999719  0.10293482 -0.17021829\n",
      "  0.29918164 -0.00783345 -0.25669897  0.24007131 -0.16366411 -0.19876737\n",
      "  0.10012449 -0.43818898]\n",
      "New theta_0 : [ 0.00685092 -0.05193631  0.08522847  0.0099516   0.10291721 -0.17063574\n",
      "  0.29899688 -0.00778161 -0.25717509  0.24044787 -0.16384245 -0.19887122\n",
      "  0.10006337 -0.438235  ]\n",
      "Training Error:  10.604610046694868\n",
      "====================================================================================================\n",
      "Iteration:  441\n",
      "Previous theta :  [ 0.00685092 -0.05193631  0.08522847  0.0099516   0.10291721 -0.17063574\n",
      "  0.29899688 -0.00778161 -0.25717509  0.24044787 -0.16384245 -0.19887122\n",
      "  0.10006337 -0.438235  ]\n",
      "New theta_0 : [ 0.00684797 -0.05211452  0.08539496  0.00990696  0.10289968 -0.17105047\n",
      "  0.29881359 -0.00773001 -0.25764764  0.24082282 -0.1640208  -0.19897438\n",
      "  0.10000273 -0.43828049]\n",
      "Training Error:  10.603980061616147\n",
      "====================================================================================================\n",
      "Iteration:  442\n",
      "Previous theta :  [ 0.00684797 -0.05211452  0.08539496  0.00990696  0.10289968 -0.17105047\n",
      "  0.29881359 -0.00773001 -0.25764764  0.24082282 -0.1640208  -0.19897438\n",
      "  0.10000273 -0.43828049]\n",
      "New theta_0 : [ 0.00684503 -0.05229154  0.08556038  0.00986328  0.10288221 -0.1714625\n",
      "  0.29863173 -0.00767865 -0.25811665  0.24119619 -0.16419917 -0.19907686\n",
      "  0.09994254 -0.43832544]\n",
      "Training Error:  10.603357804819701\n",
      "====================================================================================================\n",
      "Iteration:  443\n",
      "Previous theta :  [ 0.00684503 -0.05229154  0.08556038  0.00986328  0.10288221 -0.1714625\n",
      "  0.29863173 -0.00767865 -0.25811665  0.24119619 -0.16419917 -0.19907686\n",
      "  0.09994254 -0.43832544]\n",
      "New theta_0 : [ 0.00684212 -0.05246739  0.08572474  0.00982055  0.10286482 -0.17187184\n",
      "  0.29845131 -0.00762752 -0.25858214  0.24156799 -0.16437754 -0.19917866\n",
      "  0.09988282 -0.43836988]\n",
      "Training Error:  10.602743171588287\n",
      "====================================================================================================\n",
      "Iteration:  444\n",
      "Previous theta :  [ 0.00684212 -0.05246739  0.08572474  0.00982055  0.10286482 -0.17187184\n",
      "  0.29845131 -0.00762752 -0.25858214  0.24156799 -0.16437754 -0.19917866\n",
      "  0.09988282 -0.43836988]\n",
      "New theta_0 : [ 0.00683923 -0.05264209  0.08588803  0.00977874  0.10284751 -0.17227852\n",
      "  0.2982723  -0.00757662 -0.25904415  0.24193821 -0.16455592 -0.19927978\n",
      "  0.09982356 -0.4384138 ]\n",
      "Training Error:  10.602136058693802\n",
      "====================================================================================================\n",
      "Iteration:  445\n",
      "Previous theta :  [ 0.00683923 -0.05264209  0.08588803  0.00977874  0.10284751 -0.17227852\n",
      "  0.2982723  -0.00757662 -0.25904415  0.24193821 -0.16455592 -0.19927978\n",
      "  0.09982356 -0.4384138 ]\n",
      "New theta_0 : [ 0.00683635 -0.05281563  0.08605028  0.00973787  0.10283026 -0.17268255\n",
      "  0.29809469 -0.00752596 -0.25950269  0.24230688 -0.16473429 -0.19938024\n",
      "  0.09976476 -0.43845722]\n",
      "Training Error:  10.601536364375521\n",
      "====================================================================================================\n",
      "Iteration:  446\n",
      "Previous theta :  [ 0.00683635 -0.05281563  0.08605028  0.00973787  0.10283026 -0.17268255\n",
      "  0.29809469 -0.00752596 -0.25950269  0.24230688 -0.16473429 -0.19938024\n",
      "  0.09976476 -0.43845722]\n",
      "New theta_0 : [ 0.00683349 -0.05298802  0.08621149  0.0096979   0.10281308 -0.17308394\n",
      "  0.29791848 -0.00747554 -0.2599578   0.24267399 -0.16491267 -0.19948004\n",
      "  0.0997064  -0.43850014]\n",
      "Training Error:  10.600943988318711\n",
      "====================================================================================================\n",
      "Iteration:  447\n",
      "Previous theta :  [ 0.00683349 -0.05298802  0.08621149  0.0096979   0.10281308 -0.17308394\n",
      "  0.29791848 -0.00747554 -0.2599578   0.24267399 -0.16491267 -0.19948004\n",
      "  0.0997064  -0.43850014]\n",
      "New theta_0 : [ 0.00683064 -0.05315928  0.08637165  0.00965884  0.10279598 -0.17348272\n",
      "  0.29774365 -0.00742535 -0.26040949  0.24303956 -0.16509103 -0.19957918\n",
      "  0.09964849 -0.43854256]\n",
      "Training Error:  10.600358831633516\n",
      "====================================================================================================\n",
      "Iteration:  448\n",
      "Previous theta :  [ 0.00683064 -0.05315928  0.08637165  0.00965884  0.10279598 -0.17348272\n",
      "  0.29774365 -0.00742535 -0.26040949  0.24303956 -0.16509103 -0.19957918\n",
      "  0.09964849 -0.43854256]\n",
      "New theta_0 : [ 0.00682782 -0.0533294   0.08653079  0.00962067  0.10277894 -0.1738789\n",
      "  0.29757019 -0.00737539 -0.26085781  0.2434036  -0.16526939 -0.19967766\n",
      "  0.09959103 -0.4385845 ]\n",
      "Training Error:  10.599780796834175\n",
      "====================================================================================================\n",
      "Iteration:  449\n",
      "Previous theta :  [ 0.00682782 -0.0533294   0.08653079  0.00962067  0.10277894 -0.1738789\n",
      "  0.29757019 -0.00737539 -0.26085781  0.2434036  -0.16526939 -0.19967766\n",
      "  0.09959103 -0.4385845 ]\n",
      "New theta_0 : [ 0.00682501 -0.05349841  0.0866889   0.00958338  0.10276198 -0.17427249\n",
      "  0.29739808 -0.00732567 -0.26130276  0.24376612 -0.16544773 -0.19977549\n",
      "  0.09953401 -0.43862595]\n",
      "Training Error:  10.599209787818564\n",
      "====================================================================================================\n",
      "Iteration:  450\n",
      "Previous theta :  [ 0.00682501 -0.05349841  0.0866889   0.00958338  0.10276198 -0.17427249\n",
      "  0.29739808 -0.00732567 -0.26130276  0.24376612 -0.16544773 -0.19977549\n",
      "  0.09953401 -0.43862595]\n",
      "New theta_0 : [ 0.00682221 -0.0536663   0.08684599  0.00954697  0.10274508 -0.17466351\n",
      "  0.29722731 -0.00727618 -0.26174438  0.24412712 -0.16562605 -0.19987269\n",
      "  0.09947742 -0.43866694]\n",
      "Training Error:  10.598645709848022\n",
      "====================================================================================================\n",
      "Iteration:  451\n",
      "Previous theta :  [ 0.00682221 -0.0536663   0.08684599  0.00954697  0.10274508 -0.17466351\n",
      "  0.29722731 -0.00727618 -0.26174438  0.24412712 -0.16562605 -0.19987269\n",
      "  0.09947742 -0.43866694]\n",
      "New theta_0 : [ 0.00681944 -0.05383308  0.08700207  0.00951143  0.10272825 -0.17505199\n",
      "  0.29705787 -0.00722693 -0.26218269  0.24448661 -0.16580436 -0.19996924\n",
      "  0.09942127 -0.43870745]\n",
      "Training Error:  10.59808846952747\n",
      "====================================================================================================\n",
      "Iteration:  452\n",
      "Previous theta :  [ 0.00681944 -0.05383308  0.08700207  0.00951143  0.10272825 -0.17505199\n",
      "  0.29705787 -0.00722693 -0.26218269  0.24448661 -0.16580436 -0.19996924\n",
      "  0.09942127 -0.43870745]\n",
      "New theta_0 : [ 0.00681668 -0.05399876  0.08715714  0.00947674  0.10271149 -0.17543793\n",
      "  0.29688975 -0.00717791 -0.26261772  0.24484461 -0.16598264 -0.20006516\n",
      "  0.09936555 -0.43874751]\n",
      "Training Error:  10.597537974785862\n",
      "====================================================================================================\n",
      "Iteration:  453\n",
      "Previous theta :  [ 0.00681668 -0.05399876  0.08715714  0.00947674  0.10271149 -0.17543793\n",
      "  0.29688975 -0.00717791 -0.26261772  0.24484461 -0.16598264 -0.20006516\n",
      "  0.09936555 -0.43874751]\n",
      "New theta_0 : [ 0.00681393 -0.05416335  0.08731121  0.00944289  0.1026948  -0.17582135\n",
      "  0.29672295 -0.00712913 -0.2630495   0.24520111 -0.16616089 -0.20016045\n",
      "  0.09931025 -0.43878711]\n",
      "Training Error:  10.596994134856885\n",
      "====================================================================================================\n",
      "Iteration:  454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous theta :  [ 0.00681393 -0.05416335  0.08731121  0.00944289  0.1026948  -0.17582135\n",
      "  0.29672295 -0.00712913 -0.2630495   0.24520111 -0.16616089 -0.20016045\n",
      "  0.09931025 -0.43878711]\n",
      "New theta_0 : [ 0.00681121 -0.05432685  0.08746428  0.00940989  0.10267817 -0.17620226\n",
      "  0.29655743 -0.00708057 -0.26347803  0.24555614 -0.16633911 -0.20025512\n",
      "  0.09925538 -0.43882626]\n",
      "Training Error:  10.59645686025998\n",
      "====================================================================================================\n",
      "Iteration:  455\n",
      "Previous theta :  [ 0.00681121 -0.05432685  0.08746428  0.00940989  0.10267817 -0.17620226\n",
      "  0.29655743 -0.00708057 -0.26347803  0.24555614 -0.16633911 -0.20025512\n",
      "  0.09925538 -0.43882626]\n",
      "New theta_0 : [ 0.0068085  -0.05448928  0.08761637  0.00937771  0.10266161 -0.1765807\n",
      "  0.2963932  -0.00703225 -0.26390336  0.24590969 -0.1665173  -0.20034917\n",
      "  0.09920093 -0.43886497]\n",
      "Training Error:  10.595926062781611\n",
      "====================================================================================================\n",
      "Iteration:  456\n",
      "Previous theta :  [ 0.0068085  -0.05448928  0.08761637  0.00937771  0.10266161 -0.1765807\n",
      "  0.2963932  -0.00703225 -0.26390336  0.24590969 -0.1665173  -0.20034917\n",
      "  0.09920093 -0.43886497]\n",
      "New theta_0 : [ 0.0068058  -0.05465064  0.08776748  0.00934635  0.10264512 -0.17695665\n",
      "  0.29623025 -0.00698416 -0.26432551  0.24626178 -0.16669545 -0.2004426\n",
      "  0.09914689 -0.43890325]\n",
      "Training Error:  10.59540165545685\n",
      "====================================================================================================\n",
      "Iteration:  457\n",
      "Previous theta :  [ 0.0068058  -0.05465064  0.08776748  0.00934635  0.10264512 -0.17695665\n",
      "  0.29623025 -0.00698416 -0.26432551  0.24626178 -0.16669545 -0.2004426\n",
      "  0.09914689 -0.43890325]\n",
      "New theta_0 : [ 0.00680312 -0.05481093  0.08791761  0.0093158   0.1026287  -0.17733016\n",
      "  0.29606855 -0.0069363  -0.26474449  0.2466124  -0.16687356 -0.20053542\n",
      "  0.09909327 -0.43894109]\n",
      "Training Error:  10.594883552551199\n",
      "====================================================================================================\n",
      "Iteration:  458\n",
      "Previous theta :  [ 0.00680312 -0.05481093  0.08791761  0.0093158   0.1026287  -0.17733016\n",
      "  0.29606855 -0.0069363  -0.26474449  0.2466124  -0.16687356 -0.20053542\n",
      "  0.09909327 -0.43894109]\n",
      "New theta_0 : [ 0.00680046 -0.05497017  0.08806677  0.00928605  0.10261233 -0.17770122\n",
      "  0.29590811 -0.00688867 -0.26516033  0.24696159 -0.16705162 -0.20062764\n",
      "  0.09904005 -0.43897851]\n",
      "Training Error:  10.59437166954271\n",
      "====================================================================================================\n",
      "Iteration:  459\n",
      "Previous theta :  [ 0.00680046 -0.05497017  0.08806677  0.00928605  0.10261233 -0.17770122\n",
      "  0.29590811 -0.00688867 -0.26516033  0.24696159 -0.16705162 -0.20062764\n",
      "  0.09904005 -0.43897851]\n",
      "New theta_0 : [ 0.00679781 -0.05512836  0.08821496  0.0092571   0.10259604 -0.17806986\n",
      "  0.2957489  -0.00684127 -0.26557307  0.24730933 -0.16722964 -0.20071925\n",
      "  0.09898724 -0.4390155 ]\n",
      "Training Error:  10.59386592310435\n",
      "====================================================================================================\n",
      "Iteration:  460\n",
      "Previous theta :  [ 0.00679781 -0.05512836  0.08821496  0.0092571   0.10259604 -0.17806986\n",
      "  0.2957489  -0.00684127 -0.26557307  0.24730933 -0.16722964 -0.20071925\n",
      "  0.09898724 -0.4390155 ]\n",
      "New theta_0 : [ 0.00679518 -0.05528551  0.0883622   0.00922893  0.10257981 -0.1784361\n",
      "  0.29559093 -0.00679411 -0.26598271  0.24765563 -0.16740761 -0.20081027\n",
      "  0.09893484 -0.43905209]\n",
      "Training Error:  10.593366231086646\n",
      "====================================================================================================\n",
      "Iteration:  461\n",
      "Previous theta :  [ 0.00679518 -0.05528551  0.0883622   0.00922893  0.10257981 -0.1784361\n",
      "  0.29559093 -0.00679411 -0.26598271  0.24765563 -0.16740761 -0.20081027\n",
      "  0.09893484 -0.43905209]\n",
      "New theta_0 : [ 0.00679257 -0.05544163  0.08850848  0.00920153  0.10256364 -0.17879993\n",
      "  0.29543417 -0.00674717 -0.26638928  0.24800052 -0.16758553 -0.20090069\n",
      "  0.09888283 -0.43908827]\n",
      "Training Error:  10.592872512500566\n",
      "====================================================================================================\n",
      "Iteration:  462\n",
      "Previous theta :  [ 0.00679257 -0.05544163  0.08850848  0.00920153  0.10256364 -0.17879993\n",
      "  0.29543417 -0.00674717 -0.26638928  0.24800052 -0.16758553 -0.20090069\n",
      "  0.09888283 -0.43908827]\n",
      "New theta_0 : [ 0.00678997 -0.05559672  0.08865382  0.0091749   0.10254754 -0.1791614\n",
      "  0.29527862 -0.00670046 -0.26679281  0.24834399 -0.16776339 -0.20099053\n",
      "  0.09883122 -0.43912404]\n",
      "Training Error:  10.592384687500672\n",
      "====================================================================================================\n",
      "Iteration:  463\n",
      "Previous theta :  [ 0.00678997 -0.05559672  0.08865382  0.0091749   0.10254754 -0.1791614\n",
      "  0.29527862 -0.00670046 -0.26679281  0.24834399 -0.16776339 -0.20099053\n",
      "  0.09883122 -0.43912404]\n",
      "New theta_0 : [ 0.00678738 -0.05575078  0.08879822  0.00914903  0.1025315  -0.17952049\n",
      "  0.29512426 -0.00665397 -0.26719332  0.24868604 -0.16794119 -0.20107979\n",
      "  0.09878001 -0.43915942]\n",
      "Training Error:  10.591902677368514\n",
      "====================================================================================================\n",
      "Iteration:  464\n",
      "Previous theta :  [ 0.00678738 -0.05575078  0.08879822  0.00914903  0.1025315  -0.17952049\n",
      "  0.29512426 -0.00665397 -0.26719332  0.24868604 -0.16794119 -0.20107979\n",
      "  0.09878001 -0.43915942]\n",
      "New theta_0 : [ 0.00678481 -0.05590384  0.08894168  0.00912391  0.10251552 -0.17987724\n",
      "  0.2949711  -0.00660772 -0.26759084  0.2490267  -0.16811893 -0.20116846\n",
      "  0.09872918 -0.4391944 ]\n",
      "Training Error:  10.59142640449627\n",
      "====================================================================================================\n",
      "Iteration:  465\n",
      "Previous theta :  [ 0.00678481 -0.05590384  0.08894168  0.00912391  0.10251552 -0.17987724\n",
      "  0.2949711  -0.00660772 -0.26759084  0.2490267  -0.16811893 -0.20116846\n",
      "  0.09872918 -0.4391944 ]\n",
      "New theta_0 : [ 0.00678225 -0.05605589  0.08908422  0.00909952  0.10249961 -0.18023166\n",
      "  0.2948191  -0.00656169 -0.26798537  0.24936597 -0.1682966  -0.20125656\n",
      "  0.09867875 -0.439229  ]\n",
      "Training Error:  10.59095579237063\n",
      "====================================================================================================\n",
      "Iteration:  466\n",
      "Previous theta :  [ 0.00678225 -0.05605589  0.08908422  0.00909952  0.10249961 -0.18023166\n",
      "  0.2948191  -0.00656169 -0.26798537  0.24936597 -0.1682966  -0.20125656\n",
      "  0.09867875 -0.439229  ]\n",
      "New theta_0 : [ 0.00677971 -0.05620694  0.08922583  0.00907588  0.10248376 -0.18058376\n",
      "  0.29466828 -0.00651589 -0.26837696  0.24970385 -0.16847421 -0.20134409\n",
      "  0.09862869 -0.43926322]\n",
      "Training Error:  10.590490765556916\n",
      "====================================================================================================\n",
      "Iteration:  467\n",
      "Previous theta :  [ 0.00677971 -0.05620694  0.08922583  0.00907588  0.10248376 -0.18058376\n",
      "  0.29466828 -0.00651589 -0.26837696  0.24970385 -0.16847421 -0.20134409\n",
      "  0.09862869 -0.43926322]\n",
      "New theta_0 : [ 0.00677719 -0.056357    0.08936653  0.00905295  0.10246797 -0.18093355\n",
      "  0.29451861 -0.00647032 -0.26876561  0.25004035 -0.16865175 -0.20143105\n",
      "  0.09857902 -0.43929706]\n",
      "Training Error:  10.590031249683445\n",
      "====================================================================================================\n",
      "Iteration:  468\n",
      "Previous theta :  [ 0.00677719 -0.056357    0.08936653  0.00905295  0.10246797 -0.18093355\n",
      "  0.29451861 -0.00647032 -0.26876561  0.25004035 -0.16865175 -0.20143105\n",
      "  0.09857902 -0.43929706]\n",
      "New theta_0 : [ 0.00677468 -0.05650607  0.08950631  0.00903075  0.10245224 -0.18128106\n",
      "  0.29437008 -0.00642497 -0.26915136  0.25037548 -0.16882921 -0.20151745\n",
      "  0.09852972 -0.43933054]\n",
      "Training Error:  10.589577171426109\n",
      "====================================================================================================\n",
      "Iteration:  469\n",
      "Previous theta :  [ 0.00677468 -0.05650607  0.08950631  0.00903075  0.10245224 -0.18128106\n",
      "  0.29437008 -0.00642497 -0.26915136  0.25037548 -0.16882921 -0.20151745\n",
      "  0.09852972 -0.43933054]\n",
      "New theta_0 : [ 0.00677218 -0.05665416  0.08964519  0.00900925  0.10243658 -0.1816263\n",
      "  0.29422269 -0.00637984 -0.26953422  0.25070925 -0.1690066  -0.20160329\n",
      "  0.0984808  -0.43936364]\n",
      "Training Error:  10.589128458493192\n",
      "====================================================================================================\n",
      "Iteration:  470\n",
      "Previous theta :  [ 0.00677218 -0.05665416  0.08964519  0.00900925  0.10243658 -0.1816263\n",
      "  0.29422269 -0.00637984 -0.26953422  0.25070925 -0.1690066  -0.20160329\n",
      "  0.0984808  -0.43936364]\n",
      "New theta_0 : [ 0.0067697  -0.05680128  0.08978317  0.00898845  0.10242097 -0.18196927\n",
      "  0.29407642 -0.00633494 -0.26991421  0.25104167 -0.16918391 -0.20168858\n",
      "  0.09843225 -0.43939638]\n",
      "Training Error:  10.58868503961042\n",
      "====================================================================================================\n",
      "Iteration:  471\n",
      "Previous theta :  [ 0.0067697  -0.05680128  0.08978317  0.00898845  0.10242097 -0.18196927\n",
      "  0.29407642 -0.00633494 -0.26991421  0.25104167 -0.16918391 -0.20168858\n",
      "  0.09843225 -0.43939638]\n",
      "New theta_0 : [ 0.00676723 -0.05694744  0.08992025  0.00896835  0.10240543 -0.18231\n",
      "  0.29393127 -0.00629026 -0.27029136  0.25137273 -0.16936113 -0.20177331\n",
      "  0.09838407 -0.43942877]\n",
      "Training Error:  10.588246844506207\n",
      "====================================================================================================\n",
      "Iteration:  472\n",
      "Previous theta :  [ 0.00676723 -0.05694744  0.08992025  0.00896835  0.10240543 -0.18231\n",
      "  0.29393127 -0.00629026 -0.27029136  0.25137273 -0.16936113 -0.20177331\n",
      "  0.09838407 -0.43942877]\n",
      "New theta_0 : [ 0.00676477 -0.05709264  0.09005645  0.00894893  0.10238994 -0.1826485\n",
      "  0.29378722 -0.00624581 -0.27066569  0.25170246 -0.16953828 -0.2018575\n",
      "  0.09833626 -0.43946081]\n",
      "Training Error:  10.587813803897143\n",
      "====================================================================================================\n",
      "Iteration:  473\n",
      "Previous theta :  [ 0.00676477 -0.05709264  0.09005645  0.00894893  0.10238994 -0.1826485\n",
      "  0.29378722 -0.00624581 -0.27066569  0.25170246 -0.16953828 -0.2018575\n",
      "  0.09833626 -0.43946081]\n",
      "New theta_0 : [ 0.00676233 -0.05723688  0.09019177  0.00893019  0.10237452 -0.18298478\n",
      "  0.29364428 -0.00620157 -0.27103721  0.25203085 -0.16971533 -0.20194115\n",
      "  0.0982888  -0.4394925 ]\n",
      "Training Error:  10.587385849473689\n",
      "====================================================================================================\n",
      "Iteration:  474\n",
      "Previous theta :  [ 0.00676233 -0.05723688  0.09019177  0.00893019  0.10237452 -0.18298478\n",
      "  0.29364428 -0.00620157 -0.27103721  0.25203085 -0.16971533 -0.20194115\n",
      "  0.0982888  -0.4394925 ]\n",
      "New theta_0 : [ 0.00675991 -0.05738018  0.0903262   0.00891212  0.10235915 -0.18331886\n",
      "  0.29350241 -0.00615756 -0.27140596  0.25235792 -0.1698923  -0.20202426\n",
      "  0.09824171 -0.43952384]\n",
      "Training Error:  10.586962913886072\n",
      "====================================================================================================\n",
      "Iteration:  475\n",
      "Previous theta :  [ 0.00675991 -0.05738018  0.0903262   0.00891212  0.10235915 -0.18331886\n",
      "  0.29350241 -0.00615756 -0.27140596  0.25235792 -0.1698923  -0.20202426\n",
      "  0.09824171 -0.43952384]\n",
      "New theta_0 : [ 0.0067575  -0.05752254  0.09045977  0.00889472  0.10234384 -0.18365076\n",
      "  0.29336163 -0.00611377 -0.27177195  0.25268367 -0.17006917 -0.20210684\n",
      "  0.09819498 -0.43955485]\n",
      "Training Error:  10.58654493073041\n",
      "====================================================================================================\n",
      "Iteration:  476\n",
      "Previous theta :  [ 0.0067575  -0.05752254  0.09045977  0.00889472  0.10234384 -0.18365076\n",
      "  0.29336163 -0.00611377 -0.27177195  0.25268367 -0.17006917 -0.20210684\n",
      "  0.09819498 -0.43955485]\n",
      "New theta_0 : [ 0.0067551  -0.05766397  0.09059247  0.00887796  0.1023286  -0.18398048\n",
      "  0.29322191 -0.0060702  -0.2721352   0.25300811 -0.17024595 -0.20218888\n",
      "  0.0981486  -0.43958553]\n",
      "Training Error:  10.586131834535017\n",
      "====================================================================================================\n",
      "Iteration:  477\n",
      "Previous theta :  [ 0.0067551  -0.05766397  0.09059247  0.00887796  0.1023286  -0.18398048\n",
      "  0.29322191 -0.0060702  -0.2721352   0.25300811 -0.17024595 -0.20218888\n",
      "  0.0981486  -0.43958553]\n",
      "New theta_0 : [ 0.00675271 -0.05780446  0.09072431  0.00886186  0.10231341 -0.18430803\n",
      "  0.29308325 -0.00602684 -0.27249573  0.25333125 -0.17042264 -0.2022704\n",
      "  0.09810257 -0.43961587]\n",
      "Training Error:  10.58572356074693\n",
      "====================================================================================================\n",
      "Iteration:  478\n",
      "Previous theta :  [ 0.00675271 -0.05780446  0.09072431  0.00886186  0.10231341 -0.18430803\n",
      "  0.29308325 -0.00602684 -0.27249573  0.25333125 -0.17042264 -0.2022704\n",
      "  0.09810257 -0.43961587]\n",
      "New theta_0 : [ 0.00675034 -0.05794404  0.09085529  0.00884639  0.10229827 -0.18463345\n",
      "  0.29294564 -0.00598371 -0.27285357  0.25365308 -0.17059922 -0.20235139\n",
      "  0.09805689 -0.4396459 ]\n",
      "Training Error:  10.585320045718621\n",
      "====================================================================================================\n",
      "Iteration:  479\n",
      "Previous theta :  [ 0.00675034 -0.05794404  0.09085529  0.00884639  0.10229827 -0.18463345\n",
      "  0.29294564 -0.00598371 -0.27285357  0.25365308 -0.17059922 -0.20235139\n",
      "  0.09805689 -0.4396459 ]\n",
      "New theta_0 : [ 0.00674798 -0.05808271  0.09098543  0.00883156  0.1022832  -0.18495673\n",
      "  0.29280907 -0.00594079 -0.27320873  0.25397363 -0.1707757  -0.20243187\n",
      "  0.09801156 -0.4396756 ]\n",
      "Training Error:  10.584921226694917\n",
      "====================================================================================================\n",
      "Iteration:  480\n",
      "Previous theta :  [ 0.00674798 -0.05808271  0.09098543  0.00883156  0.1022832  -0.18495673\n",
      "  0.29280907 -0.00594079 -0.27320873  0.25397363 -0.1707757  -0.20243187\n",
      "  0.09801156 -0.4396756 ]\n",
      "New theta_0 : [ 0.00674564 -0.05822047  0.09111472  0.00881736  0.10226818 -0.18527789\n",
      "  0.29267353 -0.00589808 -0.27356123  0.2542929  -0.17095208 -0.20251182\n",
      "  0.09796657 -0.43970499]\n",
      "Training Error:  10.5845270418001\n",
      "====================================================================================================\n",
      "Iteration:  481\n",
      "Previous theta :  [ 0.00674564 -0.05822047  0.09111472  0.00881736  0.10226818 -0.18527789\n",
      "  0.29267353 -0.00589808 -0.27356123  0.2542929  -0.17095208 -0.20251182\n",
      "  0.09796657 -0.43970499]\n",
      "New theta_0 : [ 0.00674331 -0.05835732  0.09124317  0.00880377  0.10225322 -0.18559695\n",
      "  0.29253902 -0.0058556  -0.2739111   0.25461088 -0.17112835 -0.20259127\n",
      "  0.09792192 -0.43973406]\n",
      "Training Error:  10.58413743002521\n",
      "====================================================================================================\n",
      "Iteration:  482\n",
      "Previous theta :  [ 0.00674331 -0.05835732  0.09124317  0.00880377  0.10225322 -0.18559695\n",
      "  0.29253902 -0.0058556  -0.2739111   0.25461088 -0.17112835 -0.20259127\n",
      "  0.09792192 -0.43973406]\n",
      "New theta_0 : [ 0.00674099 -0.05849329  0.09137079  0.0087908   0.10223832 -0.18591391\n",
      "  0.29240551 -0.00581333 -0.27425834  0.2549276  -0.17130451 -0.20267021\n",
      "  0.09787761 -0.43976283]\n",
      "Training Error:  10.58375233121552\n",
      "====================================================================================================\n",
      "Iteration:  483\n",
      "Previous theta :  [ 0.00674099 -0.05849329  0.09137079  0.0087908   0.10223832 -0.18591391\n",
      "  0.29240551 -0.00581333 -0.27425834  0.2549276  -0.17130451 -0.20267021\n",
      "  0.09787761 -0.43976283]\n",
      "New theta_0 : [ 0.00673869 -0.05862836  0.09149758  0.00877843  0.10222347 -0.1862288\n",
      "  0.29227302 -0.00577127 -0.274603    0.25524306 -0.17148056 -0.20274865\n",
      "  0.09783363 -0.4397913 ]\n",
      "Training Error:  10.583371686058207\n",
      "====================================================================================================\n",
      "Iteration:  484\n",
      "Previous theta :  [ 0.00673869 -0.05862836  0.09149758  0.00877843  0.10222347 -0.1862288\n",
      "  0.29227302 -0.00577127 -0.274603    0.25524306 -0.17148056 -0.20274865\n",
      "  0.09783363 -0.4397913 ]\n",
      "New theta_0 : [ 0.0067364  -0.05876255  0.09162355  0.00876665  0.10220868 -0.18654162\n",
      "  0.29214151 -0.00572942 -0.27494507  0.25555726 -0.17165649 -0.20282658\n",
      "  0.09778998 -0.43981947]\n",
      "Training Error:  10.582995436070204\n",
      "====================================================================================================\n",
      "Iteration:  485\n",
      "Previous theta :  [ 0.0067364  -0.05876255  0.09162355  0.00876665  0.10220868 -0.18654162\n",
      "  0.29214151 -0.00572942 -0.27494507  0.25555726 -0.17165649 -0.20282658\n",
      "  0.09778998 -0.43981947]\n",
      "New theta_0 : [ 0.00673412 -0.05889586  0.09174871  0.00875547  0.10219394 -0.18685239\n",
      "  0.292011   -0.00568779 -0.27528459  0.25587021 -0.17183231 -0.20290402\n",
      "  0.09774667 -0.43984734]\n",
      "Training Error:  10.582623523586225\n",
      "====================================================================================================\n",
      "Iteration:  486\n",
      "Previous theta :  [ 0.00673412 -0.05889586  0.09174871  0.00875547  0.10219394 -0.18685239\n",
      "  0.292011   -0.00568779 -0.27528459  0.25587021 -0.17183231 -0.20290402\n",
      "  0.09774667 -0.43984734]\n",
      "New theta_0 : [ 0.00673185 -0.0590283   0.09187305  0.00874487  0.10217926 -0.18716112\n",
      "  0.29188147 -0.00564637 -0.27562156  0.25618192 -0.17200801 -0.20298096\n",
      "  0.09770368 -0.43987492]\n",
      "Training Error:  10.582255891746968\n",
      "====================================================================================================\n",
      "Iteration:  487\n",
      "Previous theta :  [ 0.00673185 -0.0590283   0.09187305  0.00874487  0.10217926 -0.18716112\n",
      "  0.29188147 -0.00564637 -0.27562156  0.25618192 -0.17200801 -0.20298096\n",
      "  0.09770368 -0.43987492]\n",
      "New theta_0 : [ 0.0067296  -0.05915988  0.09199658  0.00873485  0.10216463 -0.18746783\n",
      "  0.2917529  -0.00560516 -0.27595602  0.2564924  -0.17218359 -0.20305741\n",
      "  0.09766102 -0.43990221]\n",
      "Training Error:  10.581892484487494\n",
      "====================================================================================================\n",
      "Iteration:  488\n",
      "Previous theta :  [ 0.0067296  -0.05915988  0.09199658  0.00873485  0.10216463 -0.18746783\n",
      "  0.2917529  -0.00560516 -0.27595602  0.2564924  -0.17218359 -0.20305741\n",
      "  0.09766102 -0.43990221]\n",
      "New theta_0 : [ 0.00672736 -0.0592906   0.09211932  0.0087254   0.10215006 -0.18777253\n",
      "  0.2916253  -0.00556416 -0.27628797  0.25680165 -0.17235904 -0.20313337\n",
      "  0.09761868 -0.43992922]\n",
      "Training Error:  10.581533246525773\n",
      "====================================================================================================\n",
      "Iteration:  489\n",
      "Previous theta :  [ 0.00672736 -0.0592906   0.09211932  0.0087254   0.10215006 -0.18777253\n",
      "  0.2916253  -0.00556416 -0.27628797  0.25680165 -0.17235904 -0.20313337\n",
      "  0.09761868 -0.43992922]\n",
      "New theta_0 : [ 0.00672513 -0.05942046  0.09224126  0.00871652  0.10213554 -0.18807522\n",
      "  0.29149865 -0.00552338 -0.27661745  0.25710967 -0.17253437 -0.20320886\n",
      "  0.09757666 -0.43995595]\n",
      "Training Error:  10.581178123351405\n",
      "====================================================================================================\n",
      "Iteration:  490\n",
      "Previous theta :  [ 0.00672513 -0.05942046  0.09224126  0.00871652  0.10213554 -0.18807522\n",
      "  0.29149865 -0.00552338 -0.27661745  0.25710967 -0.17253437 -0.20320886\n",
      "  0.09757666 -0.43995595]\n",
      "New theta_0 : [ 0.00672292 -0.05954948  0.0923624   0.00870819  0.10212108 -0.18837593\n",
      "  0.29137295 -0.00548279 -0.27694446  0.25741648 -0.17270957 -0.20328386\n",
      "  0.09753496 -0.43998241]\n",
      "Training Error:  10.580827061214498\n",
      "====================================================================================================\n",
      "Iteration:  491\n",
      "Previous theta :  [ 0.00672292 -0.05954948  0.0923624   0.00870819  0.10212108 -0.18837593\n",
      "  0.29137295 -0.00548279 -0.27694446  0.25741648 -0.17270957 -0.20328386\n",
      "  0.09753496 -0.43998241]\n",
      "New theta_0 : [ 0.00672071 -0.05967765  0.09248276  0.00870041  0.10210667 -0.18867466\n",
      "  0.29124819 -0.00544242 -0.27726902  0.25772207 -0.17288465 -0.20335838\n",
      "  0.09749357 -0.44000859]\n",
      "Training Error:  10.580480007114714\n",
      "====================================================================================================\n",
      "Iteration:  492\n",
      "Previous theta :  [ 0.00672071 -0.05967765  0.09248276  0.00870041  0.10210667 -0.18867466\n",
      "  0.29124819 -0.00544242 -0.27726902  0.25772207 -0.17288465 -0.20335838\n",
      "  0.09749357 -0.44000859]\n",
      "New theta_0 : [ 0.00671852 -0.05980499  0.09260235  0.00869318  0.10209231 -0.18897144\n",
      "  0.29112435 -0.00540225 -0.27759116  0.25802647 -0.17305959 -0.20343243\n",
      "  0.09745249 -0.4400345 ]\n",
      "Training Error:  10.580136908790477\n",
      "====================================================================================================\n",
      "Iteration:  493\n",
      "Previous theta :  [ 0.00671852 -0.05980499  0.09260235  0.00869318  0.10209231 -0.18897144\n",
      "  0.29112435 -0.00540225 -0.27759116  0.25802647 -0.17305959 -0.20343243\n",
      "  0.09745249 -0.4400345 ]\n",
      "New theta_0 : [ 0.00671634 -0.05993151  0.09272115  0.00868648  0.10207801 -0.18926626\n",
      "  0.29100144 -0.00536229 -0.27791089  0.25832967 -0.17323439 -0.20350602\n",
      "  0.09741172 -0.44006015]\n",
      "Training Error:  10.57979771470834\n",
      "====================================================================================================\n",
      "Iteration:  494\n",
      "Previous theta :  [ 0.00671634 -0.05993151  0.09272115  0.00868648  0.10207801 -0.18926626\n",
      "  0.29100144 -0.00536229 -0.27791089  0.25832967 -0.17323439 -0.20350602\n",
      "  0.09741172 -0.44006015]\n",
      "New theta_0 : [ 0.00671418 -0.06005719  0.09283919  0.00868032  0.10206376 -0.18955915\n",
      "  0.29087944 -0.00532253 -0.27822823  0.25863167 -0.17340906 -0.20357913\n",
      "  0.09737126 -0.44008554]\n",
      "Training Error:  10.579462374052497\n",
      "====================================================================================================\n",
      "Iteration:  495\n",
      "Previous theta :  [ 0.00671418 -0.06005719  0.09283919  0.00868032  0.10206376 -0.18955915\n",
      "  0.29087944 -0.00532253 -0.27822823  0.25863167 -0.17340906 -0.20357913\n",
      "  0.09737126 -0.44008554]\n",
      "New theta_0 : [ 0.00671203 -0.06018206  0.09295646  0.00867468  0.10204956 -0.18985012\n",
      "  0.29075835 -0.00528298 -0.27854319  0.2589325  -0.1735836  -0.20365178\n",
      "  0.09733111 -0.44011067]\n",
      "Training Error:  10.57913083671447\n",
      "====================================================================================================\n",
      "Iteration:  496\n",
      "Previous theta :  [ 0.00671203 -0.06018206  0.09295646  0.00867468  0.10204956 -0.18985012\n",
      "  0.29075835 -0.00528298 -0.27854319  0.2589325  -0.1735836  -0.20365178\n",
      "  0.09733111 -0.44011067]\n",
      "New theta_0 : [ 0.00670988 -0.06030611  0.09307297  0.00866957  0.10203541 -0.19013917\n",
      "  0.29063816 -0.00524363 -0.2788558   0.25923214 -0.17375799 -0.20372397\n",
      "  0.09729125 -0.44013554]\n",
      "Training Error:  10.578803053282925\n",
      "====================================================================================================\n",
      "Iteration:  497\n",
      "Previous theta :  [ 0.00670988 -0.06030611  0.09307297  0.00866957  0.10203541 -0.19013917\n",
      "  0.29063816 -0.00524363 -0.2788558   0.25923214 -0.17375799 -0.20372397\n",
      "  0.09729125 -0.44013554]\n",
      "New theta_0 : [ 0.00670775 -0.06042936  0.09318872  0.00866496  0.10202132 -0.19042633\n",
      "  0.29051886 -0.00520448 -0.27916608  0.25953062 -0.17393224 -0.20379571\n",
      "  0.0972517  -0.44016017]\n",
      "Training Error:  10.578478975033656\n",
      "====================================================================================================\n",
      "Iteration:  498\n",
      "Previous theta :  [ 0.00670775 -0.06042936  0.09318872  0.00866496  0.10202132 -0.19042633\n",
      "  0.29051886 -0.00520448 -0.27916608  0.25953062 -0.17393224 -0.20379571\n",
      "  0.0972517  -0.44016017]\n",
      "New theta_0 : [ 0.00670564 -0.06055181  0.09330373  0.00866087  0.10200727 -0.1907116\n",
      "  0.29040044 -0.00516554 -0.27947403  0.25982792 -0.17410635 -0.20386699\n",
      "  0.09721245 -0.44018455]\n",
      "Training Error:  10.578158553919701\n",
      "====================================================================================================\n",
      "Iteration:  499\n",
      "Previous theta :  [ 0.00670564 -0.06055181  0.09330373  0.00866087  0.10200727 -0.1907116\n",
      "  0.29040044 -0.00516554 -0.27947403  0.25982792 -0.17410635 -0.20386699\n",
      "  0.09721245 -0.44018455]\n",
      "New theta_0 : [ 0.00670353 -0.06067346  0.09341799  0.00865727  0.10199328 -0.19099499\n",
      "  0.2902829  -0.00512679 -0.27977968  0.26012407 -0.17428031 -0.20393782\n",
      "  0.09717349 -0.44020868]\n",
      "Training Error:  10.577841742561613\n",
      "====================================================================================================\n",
      "Iteration:  500\n",
      "Previous theta :  [ 0.00670353 -0.06067346  0.09341799  0.00865727  0.10199328 -0.19099499\n",
      "  0.2902829  -0.00512679 -0.27977968  0.26012407 -0.17428031 -0.20393782\n",
      "  0.09717349 -0.44020868]\n",
      "New theta_0 : [ 0.00670144 -0.06079431  0.09353151  0.00865417  0.10197934 -0.19127653\n",
      "  0.29016622 -0.00508824 -0.28008305  0.26041907 -0.17445412 -0.20400821\n",
      "  0.09713482 -0.44023257]\n",
      "Training Error:  10.577528494237866\n",
      "====================================================================================================\n",
      "Iteration:  501\n",
      "Previous theta :  [ 0.00670144 -0.06079431  0.09353151  0.00865417  0.10197934 -0.19127653\n",
      "  0.29016622 -0.00508824 -0.28008305  0.26041907 -0.17445412 -0.20400821\n",
      "  0.09713482 -0.44023257]\n",
      "New theta_0 : [ 0.00669935 -0.06091439  0.09364429  0.00865156  0.10196545 -0.19155621\n",
      "  0.29005041 -0.0050499  -0.28038415  0.26071292 -0.17462778 -0.20407814\n",
      "  0.09709644 -0.44025622]\n",
      "Training Error:  10.57721876287541\n",
      "====================================================================================================\n",
      "Iteration:  502\n",
      "Previous theta :  [ 0.00669935 -0.06091439  0.09364429  0.00865156  0.10196545 -0.19155621\n",
      "  0.29005041 -0.0050499  -0.28038415  0.26071292 -0.17462778 -0.20407814\n",
      "  0.09709644 -0.44025622]\n",
      "New theta_0 : [ 0.00669728 -0.06103368  0.09375634  0.00864944  0.10195161 -0.19183405\n",
      "  0.28993545 -0.00501175 -0.28068299  0.26100562 -0.1748013  -0.20414764\n",
      "  0.09705835 -0.44027964]\n",
      "Training Error:  10.576912503040354\n",
      "====================================================================================================\n",
      "Iteration:  503\n",
      "Previous theta :  [ 0.00669728 -0.06103368  0.09375634  0.00864944  0.10195161 -0.19183405\n",
      "  0.28993545 -0.00501175 -0.28068299  0.26100562 -0.1748013  -0.20414764\n",
      "  0.09705835 -0.44027964]\n",
      "New theta_0 : [ 0.00669522 -0.0611522   0.09386767  0.00864779  0.10193782 -0.19211007\n",
      "  0.28982134 -0.00497379 -0.28097961  0.26129719 -0.17497465 -0.2042167\n",
      "  0.09702055 -0.44030283]\n",
      "Training Error:  10.576609669928802\n",
      "====================================================================================================\n",
      "Iteration:  504\n",
      "Previous theta :  [ 0.00669522 -0.0611522   0.09386767  0.00864779  0.10193782 -0.19211007\n",
      "  0.28982134 -0.00497379 -0.28097961  0.26129719 -0.17497465 -0.2042167\n",
      "  0.09702055 -0.44030283]\n",
      "New theta_0 : [ 0.00669317 -0.06126995  0.09397827  0.00864662  0.10192408 -0.19238427\n",
      "  0.28970807 -0.00493604 -0.28127401  0.26158764 -0.17514786 -0.20428533\n",
      "  0.09698303 -0.44032578]\n",
      "Training Error:  10.576310219357799\n",
      "====================================================================================================\n",
      "Iteration:  505\n",
      "Previous theta :  [ 0.00669317 -0.06126995  0.09397827  0.00864662  0.10192408 -0.19238427\n",
      "  0.28970807 -0.00493604 -0.28127401  0.26158764 -0.17514786 -0.20428533\n",
      "  0.09698303 -0.44032578]\n",
      "New theta_0 : [ 0.00669114 -0.06138693  0.09408816  0.00864591  0.10191039 -0.19265667\n",
      "  0.28959562 -0.00489847 -0.2815662   0.26187695 -0.1753209  -0.20435352\n",
      "  0.0969458  -0.44034852]\n",
      "Training Error:  10.576014107756432\n",
      "====================================================================================================\n",
      "Iteration:  506\n",
      "Previous theta :  [ 0.00669114 -0.06138693  0.09408816  0.00864591  0.10191039 -0.19265667\n",
      "  0.28959562 -0.00489847 -0.2815662   0.26187695 -0.1753209  -0.20435352\n",
      "  0.0969458  -0.44034852]\n",
      "New theta_0 : [ 0.00668911 -0.06150316  0.09419734  0.00864566  0.10189674 -0.19292728\n",
      "  0.28948401 -0.00486111 -0.28185621  0.26216515 -0.17549379 -0.20442129\n",
      "  0.09690884 -0.44037103]\n",
      "Training Error:  10.57572129215705\n",
      "====================================================================================================\n",
      "Iteration:  507\n",
      "Previous theta :  [ 0.00668911 -0.06150316  0.09419734  0.00864566  0.10189674 -0.19292728\n",
      "  0.28948401 -0.00486111 -0.28185621  0.26216515 -0.17549379 -0.20442129\n",
      "  0.09690884 -0.44037103]\n",
      "New theta_0 : [ 0.0066871  -0.06161863  0.09430582  0.00864587  0.10188315 -0.19319611\n",
      "  0.28937321 -0.00482393 -0.28214406  0.26245224 -0.17566651 -0.20448862\n",
      "  0.09687216 -0.44039332]\n",
      "Training Error:  10.57543173018661\n",
      "====================================================================================================\n",
      "Iteration:  508\n",
      "Previous theta :  [ 0.0066871  -0.06161863  0.09430582  0.00864587  0.10188315 -0.19319611\n",
      "  0.28937321 -0.00482393 -0.28214406  0.26245224 -0.17566651 -0.20448862\n",
      "  0.09687216 -0.44039332]\n",
      "New theta_0 : [ 0.00668509 -0.06173336  0.09441358  0.00864652  0.10186961 -0.19346317\n",
      "  0.28926323 -0.00478695 -0.28242975  0.26273822 -0.17583908 -0.20455554\n",
      "  0.09683576 -0.44041539]\n",
      "Training Error:  10.575145380058164\n",
      "====================================================================================================\n",
      "Iteration:  509\n",
      "Previous theta :  [ 0.00668509 -0.06173336  0.09441358  0.00864652  0.10186961 -0.19346317\n",
      "  0.28926323 -0.00478695 -0.28242975  0.26273822 -0.17583908 -0.20455554\n",
      "  0.09683576 -0.44041539]\n",
      "New theta_0 : [ 0.0066831  -0.06184734  0.09452066  0.00864763  0.10185611 -0.19372848\n",
      "  0.28915404 -0.00475016 -0.28271331  0.2630231  -0.17601147 -0.20462203\n",
      "  0.09679962 -0.44043725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.57486220056245\n",
      "====================================================================================================\n",
      "Iteration:  510\n",
      "Previous theta :  [ 0.0066831  -0.06184734  0.09452066  0.00864763  0.10185611 -0.19372848\n",
      "  0.28915404 -0.00475016 -0.28271331  0.2630231  -0.17601147 -0.20462203\n",
      "  0.09679962 -0.44043725]\n",
      "New theta_0 : [ 0.00668112 -0.06196058  0.09462704  0.00864917  0.10184266 -0.19399203\n",
      "  0.28904566 -0.00471355 -0.28299475  0.26330689 -0.17618371 -0.20468811\n",
      "  0.09676376 -0.4404589 ]\n",
      "Training Error:  10.574582151059627\n",
      "====================================================================================================\n",
      "Iteration:  511\n",
      "Previous theta :  [ 0.00668112 -0.06196058  0.09462704  0.00864917  0.10184266 -0.19399203\n",
      "  0.28904566 -0.00471355 -0.28299475  0.26330689 -0.17618371 -0.20468811\n",
      "  0.09676376 -0.4404589 ]\n",
      "New theta_0 : [ 0.00667915 -0.06207309  0.09473273  0.00865115  0.10182926 -0.19425386\n",
      "  0.28893807 -0.00467714 -0.28327408  0.26358959 -0.17635577 -0.20475377\n",
      "  0.09672817 -0.44048034]\n",
      "Training Error:  10.574305191471108\n",
      "====================================================================================================\n",
      "Iteration:  512\n",
      "Previous theta :  [ 0.00667915 -0.06207309  0.09473273  0.00865115  0.10182926 -0.19425386\n",
      "  0.28893807 -0.00467714 -0.28327408  0.26358959 -0.17635577 -0.20475377\n",
      "  0.09672817 -0.44048034]\n",
      "New theta_0 : [ 0.00667719 -0.06218488  0.09483774  0.00865355  0.10181591 -0.19451396\n",
      "  0.28883126 -0.00464092 -0.28355133  0.2638712  -0.17652767 -0.20481903\n",
      "  0.09669284 -0.44050158]\n",
      "Training Error:  10.57403128227154\n",
      "====================================================================================================\n",
      "Iteration:  513\n",
      "Previous theta :  [ 0.00667719 -0.06218488  0.09483774  0.00865355  0.10181591 -0.19451396\n",
      "  0.28883126 -0.00464092 -0.28355133  0.2638712  -0.17652767 -0.20481903\n",
      "  0.09669284 -0.44050158]\n",
      "New theta_0 : [ 0.00667524 -0.06229594  0.09494207  0.00865638  0.10180261 -0.19477235\n",
      "  0.28872523 -0.00460488 -0.2838265   0.26415173 -0.17669939 -0.20488387\n",
      "  0.09665778 -0.44052261]\n",
      "Training Error:  10.57376038448087\n",
      "====================================================================================================\n",
      "Iteration:  514\n",
      "Previous theta :  [ 0.00667524 -0.06229594  0.09494207  0.00865638  0.10180261 -0.19477235\n",
      "  0.28872523 -0.00460488 -0.2838265   0.26415173 -0.17669939 -0.20488387\n",
      "  0.09665778 -0.44052261]\n",
      "New theta_0 : [ 0.0066733  -0.06240628  0.09504572  0.00865962  0.10178935 -0.19502904\n",
      "  0.28861997 -0.00456903 -0.28409962  0.2644312  -0.17687095 -0.20494831\n",
      "  0.09662298 -0.44054345]\n",
      "Training Error:  10.573492459656556\n",
      "====================================================================================================\n",
      "Iteration:  515\n",
      "Previous theta :  [ 0.0066733  -0.06240628  0.09504572  0.00865962  0.10178935 -0.19502904\n",
      "  0.28861997 -0.00456903 -0.28409962  0.2644312  -0.17687095 -0.20494831\n",
      "  0.09662298 -0.44054345]\n",
      "New theta_0 : [ 0.00667137 -0.0625159   0.0951487   0.00866328  0.10177614 -0.19528403\n",
      "  0.28851548 -0.00453337 -0.2843707   0.26470959 -0.17704233 -0.20501234\n",
      "  0.09658844 -0.44056408]\n",
      "Training Error:  10.573227469885872\n",
      "====================================================================================================\n",
      "Iteration:  516\n",
      "Previous theta :  [ 0.00667137 -0.0625159   0.0951487   0.00866328  0.10177614 -0.19528403\n",
      "  0.28851548 -0.00453337 -0.2843707   0.26470959 -0.17704233 -0.20501234\n",
      "  0.09658844 -0.44056408]\n",
      "New theta_0 : [ 0.00666946 -0.06262483  0.09525102  0.00866735  0.10176297 -0.19553735\n",
      "  0.28841175 -0.00449789 -0.28463975  0.26498692 -0.17721353 -0.20507597\n",
      "  0.09655416 -0.44058452]\n",
      "Training Error:  10.57296537777833\n",
      "====================================================================================================\n",
      "Iteration:  517\n",
      "Previous theta :  [ 0.00666946 -0.06262483  0.09525102  0.00866735  0.10176297 -0.19553735\n",
      "  0.28841175 -0.00449789 -0.28463975  0.26498692 -0.17721353 -0.20507597\n",
      "  0.09655416 -0.44058452]\n",
      "New theta_0 : [ 0.00666755 -0.06273304  0.09535268  0.00867182  0.10174985 -0.195789\n",
      "  0.28830876 -0.0044626  -0.28490679  0.2652632  -0.17738455 -0.20513921\n",
      "  0.09652014 -0.44060477]\n",
      "Training Error:  10.57270614645822\n",
      "====================================================================================================\n",
      "Iteration:  518\n",
      "Previous theta :  [ 0.00666755 -0.06273304  0.09535268  0.00867182  0.10174985 -0.195789\n",
      "  0.28830876 -0.0044626  -0.28490679  0.2652632  -0.17738455 -0.20513921\n",
      "  0.09652014 -0.44060477]\n",
      "New theta_0 : [ 0.00666566 -0.06284056  0.09545368  0.00867669  0.10173678 -0.196039\n",
      "  0.28820653 -0.00442749 -0.28517183  0.26553843 -0.1775554  -0.20520205\n",
      "  0.09648637 -0.44062483]\n",
      "Training Error:  10.572449739557252\n",
      "====================================================================================================\n",
      "Iteration:  519\n",
      "Previous theta :  [ 0.00666566 -0.06284056  0.09545368  0.00867669  0.10173678 -0.196039\n",
      "  0.28820653 -0.00442749 -0.28517183  0.26553843 -0.1775554  -0.20520205\n",
      "  0.09648637 -0.44062483]\n",
      "New theta_0 : [ 0.00666377 -0.06294739  0.09555403  0.00868195  0.10172376 -0.19628735\n",
      "  0.28810503 -0.00439256 -0.2854349   0.26581261 -0.17772607 -0.2052645\n",
      "  0.09645285 -0.44064471]\n",
      "Training Error:  10.572196121207302\n",
      "====================================================================================================\n",
      "Iteration:  520\n",
      "Previous theta :  [ 0.00666377 -0.06294739  0.09555403  0.00868195  0.10172376 -0.19628735\n",
      "  0.28810503 -0.00439256 -0.2854349   0.26581261 -0.17772607 -0.2052645\n",
      "  0.09645285 -0.44064471]\n",
      "New theta_0 : [ 0.00666189 -0.06305352  0.09565374  0.0086876   0.10171078 -0.19653406\n",
      "  0.28800427 -0.00435781 -0.28569599  0.26608575 -0.17789655 -0.20532656\n",
      "  0.09641959 -0.4406644 ]\n",
      "Training Error:  10.571945256033278\n",
      "====================================================================================================\n",
      "Iteration:  521\n",
      "Previous theta :  [ 0.00666189 -0.06305352  0.09565374  0.0086876   0.10171078 -0.19653406\n",
      "  0.28800427 -0.00435781 -0.28569599  0.26608575 -0.17789655 -0.20532656\n",
      "  0.09641959 -0.4406644 ]\n",
      "New theta_0 : [ 0.00666003 -0.06315897  0.09575279  0.00869364  0.10169784 -0.19677915\n",
      "  0.28790423 -0.00432324 -0.28595514  0.26635785 -0.17806685 -0.20538823\n",
      "  0.09638657 -0.4406839 ]\n",
      "Training Error:  10.571697109146067\n",
      "====================================================================================================\n",
      "Iteration:  522\n",
      "Previous theta :  [ 0.00666003 -0.06315897  0.09575279  0.00869364  0.10169784 -0.19677915\n",
      "  0.28790423 -0.00432324 -0.28595514  0.26635785 -0.17806685 -0.20538823\n",
      "  0.09638657 -0.4406839 ]\n",
      "New theta_0 : [ 0.00665817 -0.06326375  0.09585121  0.00870005  0.10168495 -0.19702262\n",
      "  0.28780492 -0.00428885 -0.28621235  0.26662893 -0.17823697 -0.20544952\n",
      "  0.0963538  -0.44070323]\n",
      "Training Error:  10.571451646135612\n",
      "====================================================================================================\n",
      "Iteration:  523\n",
      "Previous theta :  [ 0.00665817 -0.06326375  0.09585121  0.00870005  0.10168495 -0.19702262\n",
      "  0.28780492 -0.00428885 -0.28621235  0.26662893 -0.17823697 -0.20544952\n",
      "  0.0963538  -0.44070323]\n",
      "New theta_0 : [ 0.00665633 -0.06336784  0.095949    0.00870683  0.1016721  -0.19726449\n",
      "  0.28770632 -0.00425464 -0.28646764  0.26689898 -0.1784069  -0.20551043\n",
      "  0.09632127 -0.44072238]\n",
      "Training Error:  10.57120883306407\n",
      "====================================================================================================\n",
      "Iteration:  524\n",
      "Previous theta :  [ 0.00665633 -0.06336784  0.095949    0.00870683  0.1016721  -0.19726449\n",
      "  0.28770632 -0.00425464 -0.28646764  0.26689898 -0.1784069  -0.20551043\n",
      "  0.09632127 -0.44072238]\n",
      "New theta_0 : [ 0.0066545  -0.06347127  0.09604615  0.00871399  0.1016593  -0.19750476\n",
      "  0.28760843 -0.00422061 -0.28672102  0.26716801 -0.17857664 -0.20557096\n",
      "  0.09628899 -0.44074135]\n",
      "Training Error:  10.570968636459073\n",
      "====================================================================================================\n",
      "Iteration:  525\n",
      "Previous theta :  [ 0.0066545  -0.06347127  0.09604615  0.00871399  0.1016593  -0.19750476\n",
      "  0.28760843 -0.00422061 -0.28672102  0.26716801 -0.17857664 -0.20557096\n",
      "  0.09628899 -0.44074135]\n",
      "New theta_0 : [ 0.00665267 -0.06357403  0.09614268  0.00872151  0.10164655 -0.19774345\n",
      "  0.28751125 -0.00418675 -0.2869725   0.26743602 -0.1787462  -0.20563111\n",
      "  0.09625694 -0.44076016]\n",
      "Training Error:  10.570731023307093\n",
      "====================================================================================================\n",
      "Iteration:  526\n",
      "Previous theta :  [ 0.00665267 -0.06357403  0.09614268  0.00872151  0.10164655 -0.19774345\n",
      "  0.28751125 -0.00418675 -0.2869725   0.26743602 -0.1787462  -0.20563111\n",
      "  0.09625694 -0.44076016]\n",
      "New theta_0 : [ 0.00665086 -0.06367614  0.09623858  0.00872939  0.10163384 -0.19798057\n",
      "  0.28741476 -0.00415307 -0.28722211  0.26770303 -0.17891556 -0.20569088\n",
      "  0.09622514 -0.44077879]\n",
      "Training Error:  10.570495961046907\n",
      "====================================================================================================\n",
      "Iteration:  527\n",
      "Previous theta :  [ 0.00665086 -0.06367614  0.09623858  0.00872939  0.10163384 -0.19798057\n",
      "  0.28741476 -0.00415307 -0.28722211  0.26770303 -0.17891556 -0.20569088\n",
      "  0.09622514 -0.44077879]\n",
      "New theta_0 : [ 0.00664905 -0.06377758  0.09633387  0.00873763  0.10162117 -0.19821612\n",
      "  0.28731896 -0.00411957 -0.28746985  0.26796903 -0.17908473 -0.20575029\n",
      "  0.09619357 -0.44079725]\n",
      "Training Error:  10.570263417563138\n",
      "====================================================================================================\n",
      "Iteration:  528\n",
      "Previous theta :  [ 0.00664905 -0.06377758  0.09633387  0.00873763  0.10162117 -0.19821612\n",
      "  0.28731896 -0.00411957 -0.28746985  0.26796903 -0.17908473 -0.20575029\n",
      "  0.09619357 -0.44079725]\n",
      "New theta_0 : [ 0.00664726 -0.06387837  0.09642855  0.00874621  0.10160854 -0.19845012\n",
      "  0.28722385 -0.00408623 -0.28771574  0.26823404 -0.17925371 -0.20580933\n",
      "  0.09616224 -0.44081555]\n",
      "Training Error:  10.570033361179915\n",
      "====================================================================================================\n",
      "Iteration:  529\n",
      "Previous theta :  [ 0.00664726 -0.06387837  0.09642855  0.00874621  0.10160854 -0.19845012\n",
      "  0.28722385 -0.00408623 -0.28771574  0.26823404 -0.17925371 -0.20580933\n",
      "  0.09616224 -0.44081555]\n",
      "New theta_0 : [ 0.00664547 -0.06397852  0.09652261  0.00875515  0.10159596 -0.19868258\n",
      "  0.28712942 -0.00405307 -0.28795979  0.26849805 -0.1794225  -0.205868\n",
      "  0.09613114 -0.44083369]\n",
      "Training Error:  10.569805760654607\n",
      "====================================================================================================\n",
      "Iteration:  530\n",
      "Previous theta :  [ 0.00664547 -0.06397852  0.09652261  0.00875515  0.10159596 -0.19868258\n",
      "  0.28712942 -0.00405307 -0.28795979  0.26849805 -0.1794225  -0.205868\n",
      "  0.09613114 -0.44083369]\n",
      "New theta_0 : [ 0.0066437  -0.06407802  0.09661607  0.00876442  0.10158342 -0.19891351\n",
      "  0.28703567 -0.00402008 -0.28820202  0.26876107 -0.17959108 -0.2059263\n",
      "  0.09610027 -0.44085166]\n",
      "Training Error:  10.569580585171654\n",
      "====================================================================================================\n",
      "Iteration:  531\n",
      "Previous theta :  [ 0.0066437  -0.06407802  0.09661607  0.00876442  0.10158342 -0.19891351\n",
      "  0.28703567 -0.00402008 -0.28820202  0.26876107 -0.17959108 -0.2059263\n",
      "  0.09610027 -0.44085166]\n",
      "New theta_0 : [ 0.00664193 -0.06417689  0.09670893  0.00877403  0.10157093 -0.19914291\n",
      "  0.28694259 -0.00398727 -0.28844244  0.2690231  -0.17975948 -0.20598425\n",
      "  0.09606963 -0.44086947]\n",
      "Training Error:  10.56935780433649\n",
      "====================================================================================================\n",
      "Iteration:  532\n",
      "Previous theta :  [ 0.00664193 -0.06417689  0.09670893  0.00877403  0.10157093 -0.19914291\n",
      "  0.28694259 -0.00398727 -0.28844244  0.2690231  -0.17975948 -0.20598425\n",
      "  0.09606963 -0.44086947]\n",
      "New theta_0 : [ 0.00664017 -0.06427512  0.09680119  0.00878398  0.10155848 -0.1993708\n",
      "  0.28685016 -0.00395462 -0.28868106  0.26928416 -0.17992767 -0.20604184\n",
      "  0.09603922 -0.44088713]\n",
      "Training Error:  10.569137388169557\n",
      "====================================================================================================\n",
      "Iteration:  533\n",
      "Previous theta :  [ 0.00664017 -0.06427512  0.09680119  0.00878398  0.10155848 -0.1993708\n",
      "  0.28685016 -0.00395462 -0.28868106  0.26928416 -0.17992767 -0.20604184\n",
      "  0.09603922 -0.44088713]\n",
      "New theta_0 : [ 0.00663843 -0.06437272  0.09689286  0.00879425  0.10154607 -0.19959719\n",
      "  0.2867584  -0.00392214 -0.2889179   0.26954424 -0.18009566 -0.20609907\n",
      "  0.09600904 -0.44090463]\n",
      "Training Error:  10.568919307100392\n",
      "====================================================================================================\n",
      "Iteration:  534\n",
      "Previous theta :  [ 0.00663843 -0.06437272  0.09689286  0.00879425  0.10154607 -0.19959719\n",
      "  0.2867584  -0.00392214 -0.2889179   0.26954424 -0.18009566 -0.20609907\n",
      "  0.09600904 -0.44090463]\n",
      "New theta_0 : [ 0.00663669 -0.06446969  0.09698393  0.00880486  0.1015337  -0.19982208\n",
      "  0.28666729 -0.00388983 -0.28915297  0.26980335 -0.18026345 -0.20615594\n",
      "  0.09597908 -0.44092198]\n",
      "Training Error:  10.568703531961818\n",
      "====================================================================================================\n",
      "Iteration:  535\n",
      "Previous theta :  [ 0.00663669 -0.06446969  0.09698393  0.00880486  0.1015337  -0.19982208\n",
      "  0.28666729 -0.00388983 -0.28915297  0.26980335 -0.18026345 -0.20615594\n",
      "  0.09597908 -0.44092198]\n",
      "New theta_0 : [ 0.00663496 -0.06456605  0.09707443  0.00881578  0.10152138 -0.20004549\n",
      "  0.28657683 -0.00385769 -0.28938628  0.2700615  -0.18043104 -0.20621247\n",
      "  0.09594934 -0.44093918]\n",
      "Training Error:  10.568490033984203\n",
      "====================================================================================================\n",
      "Iteration:  536\n",
      "Previous theta :  [ 0.00663496 -0.06456605  0.09707443  0.00881578  0.10152138 -0.20004549\n",
      "  0.28657683 -0.00385769 -0.28938628  0.2700615  -0.18043104 -0.20621247\n",
      "  0.09594934 -0.44093918]\n",
      "New theta_0 : [ 0.00663325 -0.06466178  0.09716434  0.00882701  0.10150909 -0.20026743\n",
      "  0.28648701 -0.00382572 -0.28961785  0.27031868 -0.18059843 -0.20626864\n",
      "  0.09591983 -0.44095623]\n",
      "Training Error:  10.568278784789822\n",
      "====================================================================================================\n",
      "Iteration:  537\n",
      "Previous theta :  [ 0.00663325 -0.06466178  0.09716434  0.00882701  0.10150909 -0.20026743\n",
      "  0.28648701 -0.00382572 -0.28961785  0.27031868 -0.18059843 -0.20626864\n",
      "  0.09591983 -0.44095623]\n",
      "New theta_0 : [ 0.00663154 -0.06475691  0.09725367  0.00883856  0.10149685 -0.2004879\n",
      "  0.28639783 -0.0037939  -0.28984768  0.27057491 -0.18076561 -0.20632447\n",
      "  0.09589053 -0.44097313]\n",
      "Training Error:  10.568069756387276\n",
      "====================================================================================================\n",
      "Iteration:  538\n",
      "Previous theta :  [ 0.00663154 -0.06475691  0.09725367  0.00883856  0.10149685 -0.2004879\n",
      "  0.28639783 -0.0037939  -0.28984768  0.27057491 -0.18076561 -0.20632447\n",
      "  0.09589053 -0.44097313]\n",
      "New theta_0 : [ 0.00662984 -0.06485143  0.09734243  0.00885042  0.10148465 -0.20070692\n",
      "  0.28630928 -0.00376226 -0.2900758   0.2708302  -0.18093259 -0.20637995\n",
      "  0.09586146 -0.44098989]\n",
      "Training Error:  10.567862921166018\n",
      "====================================================================================================\n",
      "Iteration:  539\n",
      "Previous theta :  [ 0.00662984 -0.06485143  0.09734243  0.00885042  0.10148465 -0.20070692\n",
      "  0.28630928 -0.00376226 -0.2900758   0.2708302  -0.18093259 -0.20637995\n",
      "  0.09586146 -0.44098989]\n",
      "New theta_0 : [ 0.00662815 -0.06494534  0.09743062  0.00886258  0.10147249 -0.20092449\n",
      "  0.28622136 -0.00373078 -0.29030222  0.27108453 -0.18109936 -0.20643509\n",
      "  0.09583259 -0.4410065 ]\n",
      "Training Error:  10.567658251890933\n",
      "====================================================================================================\n",
      "Iteration:  540\n",
      "Previous theta :  [ 0.00662815 -0.06494534  0.09743062  0.00886258  0.10147249 -0.20092449\n",
      "  0.28622136 -0.00373078 -0.29030222  0.27108453 -0.18109936 -0.20643509\n",
      "  0.09583259 -0.4410065 ]\n",
      "New theta_0 : [ 0.00662647 -0.06503865  0.09751825  0.00887505  0.10146038 -0.20114062\n",
      "  0.28613405 -0.00369946 -0.29052694  0.27133792 -0.18126592 -0.20648989\n",
      "  0.09580394 -0.44102297]\n",
      "Training Error:  10.56745572169702\n",
      "====================================================================================================\n",
      "Iteration:  541\n",
      "Previous theta :  [ 0.00662647 -0.06503865  0.09751825  0.00887505  0.10146038 -0.20114062\n",
      "  0.28613405 -0.00369946 -0.29052694  0.27133792 -0.18126592 -0.20648989\n",
      "  0.09580394 -0.44102297]\n",
      "New theta_0 : [ 0.00662479 -0.06513137  0.09760531  0.00888781  0.1014483  -0.20135533\n",
      "  0.28604737 -0.0036683  -0.29074999  0.27159038 -0.18143228 -0.20654435\n",
      "  0.09577551 -0.4410393 ]\n",
      "Training Error:  10.56725530408414\n",
      "====================================================================================================\n",
      "Iteration:  542\n",
      "Previous theta :  [ 0.00662479 -0.06513137  0.09760531  0.00888781  0.1014483  -0.20135533\n",
      "  0.28604737 -0.0036683  -0.29074999  0.27159038 -0.18143228 -0.20654435\n",
      "  0.09577551 -0.4410393 ]\n",
      "New theta_0 : [ 0.00662313 -0.06522349  0.09769182  0.00890086  0.10143626 -0.20156862\n",
      "  0.28596129 -0.0036373  -0.29097136  0.2718419  -0.18159842 -0.20659848\n",
      "  0.09574729 -0.4410555 ]\n",
      "Training Error:  10.567056972911832\n",
      "====================================================================================================\n",
      "Iteration:  543\n",
      "Previous theta :  [ 0.00662313 -0.06522349  0.09769182  0.00890086  0.10143626 -0.20156862\n",
      "  0.28596129 -0.0036373  -0.29097136  0.2718419  -0.18159842 -0.20659848\n",
      "  0.09574729 -0.4410555 ]\n",
      "New theta_0 : [ 0.00662148 -0.06531503  0.09777777  0.0089142   0.10142427 -0.2017805\n",
      "  0.28587583 -0.00360647 -0.29119109  0.2720925  -0.18176435 -0.20665227\n",
      "  0.09571927 -0.44107156]\n",
      "Training Error:  10.566860702394225\n",
      "====================================================================================================\n",
      "Iteration:  544\n",
      "Previous theta :  [ 0.00662148 -0.06531503  0.09777777  0.0089142   0.10142427 -0.2017805\n",
      "  0.28587583 -0.00360647 -0.29119109  0.2720925  -0.18176435 -0.20665227\n",
      "  0.09571927 -0.44107156]\n",
      "New theta_0 : [ 0.00661983 -0.06540598  0.09786317  0.00892782  0.10141231 -0.20199099\n",
      "  0.28579096 -0.00357579 -0.29140917  0.27234217 -0.18193007 -0.20670573\n",
      "  0.09569146 -0.44108748]\n",
      "Training Error:  10.566666467095004\n",
      "====================================================================================================\n",
      "Iteration:  545\n",
      "Previous theta :  [ 0.00661983 -0.06540598  0.09786317  0.00892782  0.10141231 -0.20199099\n",
      "  0.28579096 -0.00357579 -0.29140917  0.27234217 -0.18193007 -0.20670573\n",
      "  0.09569146 -0.44108748]\n",
      "New theta_0 : [ 0.0066182  -0.06549635  0.09794803  0.00894173  0.1014004  -0.20220008\n",
      "  0.28570669 -0.00354527 -0.29162562  0.27259093 -0.18209558 -0.20675886\n",
      "  0.09566386 -0.44110328]\n",
      "Training Error:  10.566474241922457\n",
      "====================================================================================================\n",
      "Iteration:  546\n",
      "Previous theta :  [ 0.0066182  -0.06549635  0.09794803  0.00894173  0.1014004  -0.20220008\n",
      "  0.28570669 -0.00354527 -0.29162562  0.27259093 -0.18209558 -0.20675886\n",
      "  0.09566386 -0.44110328]\n",
      "New theta_0 : [ 0.00661657 -0.06558615  0.09803234  0.00895591  0.10138852 -0.2024078\n",
      "  0.28562301 -0.00351491 -0.29184045  0.27283877 -0.18226087 -0.20681167\n",
      "  0.09563646 -0.44111894]\n",
      "Training Error:  10.5662840021246\n",
      "====================================================================================================\n",
      "Iteration:  547\n",
      "Previous theta :  [ 0.00661657 -0.06558615  0.09803234  0.00895591  0.10138852 -0.2024078\n",
      "  0.28562301 -0.00351491 -0.29184045  0.27283877 -0.18226087 -0.20681167\n",
      "  0.09563646 -0.44111894]\n",
      "New theta_0 : [ 0.00661495 -0.06567538  0.09811611  0.00897037  0.10137669 -0.20261414\n",
      "  0.28553992 -0.00348471 -0.29205368  0.2730857  -0.18242595 -0.20686415\n",
      "  0.09560927 -0.44113447]\n",
      "Training Error:  10.566095723284363\n",
      "====================================================================================================\n",
      "Iteration:  548\n",
      "Previous theta :  [ 0.00661495 -0.06567538  0.09811611  0.00897037  0.10137669 -0.20261414\n",
      "  0.28553992 -0.00348471 -0.29205368  0.2730857  -0.18242595 -0.20686415\n",
      "  0.09560927 -0.44113447]\n",
      "New theta_0 : [ 0.00661334 -0.06576404  0.09819935  0.0089851   0.10136489 -0.20281912\n",
      "  0.28545741 -0.00345466 -0.29226531  0.27333172 -0.18259081 -0.20691631\n",
      "  0.09558228 -0.44114988]\n",
      "Training Error:  10.565909381314846\n",
      "====================================================================================================\n",
      "Iteration:  549\n",
      "Previous theta :  [ 0.00661334 -0.06576404  0.09819935  0.0089851   0.10136489 -0.20281912\n",
      "  0.28545741 -0.00345466 -0.29226531  0.27333172 -0.18259081 -0.20691631\n",
      "  0.09558228 -0.44114988]\n",
      "New theta_0 : [ 0.00661174 -0.06585213  0.09828205  0.00900009  0.10135313 -0.20302274\n",
      "  0.28537548 -0.00342476 -0.29247536  0.27357685 -0.18275545 -0.20696815\n",
      "  0.09555549 -0.44116516]\n",
      "Training Error:  10.565724952454648\n",
      "====================================================================================================\n",
      "Iteration:  550\n",
      "Previous theta :  [ 0.00661174 -0.06585213  0.09828205  0.00900009  0.10135313 -0.20302274\n",
      "  0.28537548 -0.00342476 -0.29247536  0.27357685 -0.18275545 -0.20696815\n",
      "  0.09555549 -0.44116516]\n",
      "New theta_0 : [ 0.00661015 -0.06593966  0.09836423  0.00901534  0.10134142 -0.20322502\n",
      "  0.28529412 -0.00339502 -0.29268385  0.27382108 -0.18291987 -0.20701967\n",
      "  0.09552889 -0.44118032]\n",
      "Training Error:  10.565542413263273\n",
      "====================================================================================================\n",
      "Iteration:  551\n",
      "Previous theta :  [ 0.00661015 -0.06593966  0.09836423  0.00901534  0.10134142 -0.20322502\n",
      "  0.28529412 -0.00339502 -0.29268385  0.27382108 -0.18291987 -0.20701967\n",
      "  0.09552889 -0.44118032]\n",
      "New theta_0 : [ 0.00660856 -0.06602664  0.09844588  0.00903086  0.10132974 -0.20342596\n",
      "  0.28521333 -0.00336543 -0.29289077  0.27406441 -0.18308407 -0.20707087\n",
      "  0.09550249 -0.44119535]\n",
      "Training Error:  10.565361740616579\n",
      "====================================================================================================\n",
      "Iteration:  552\n",
      "Previous theta :  [ 0.00660856 -0.06602664  0.09844588  0.00903086  0.10132974 -0.20342596\n",
      "  0.28521333 -0.00336543 -0.29289077  0.27406441 -0.18308407 -0.20707087\n",
      "  0.09550249 -0.44119535]\n",
      "New theta_0 : [ 0.00660699 -0.06611307  0.09852701  0.00904663  0.1013181  -0.20362558\n",
      "  0.2851331  -0.003336   -0.29309615  0.27430686 -0.18324806 -0.20712176\n",
      "  0.09547629 -0.44121027]\n",
      "Training Error:  10.565182911702308\n",
      "====================================================================================================\n",
      "Iteration:  553\n",
      "Previous theta :  [ 0.00660699 -0.06611307  0.09852701  0.00904663  0.1013181  -0.20362558\n",
      "  0.2851331  -0.003336   -0.29309615  0.27430686 -0.18324806 -0.20712176\n",
      "  0.09547629 -0.44121027]\n",
      "New theta_0 : [ 0.00660542 -0.06619895  0.09860762  0.00906265  0.1013065  -0.20382387\n",
      "  0.28505343 -0.00330671 -0.29329999  0.27454842 -0.18341182 -0.20717234\n",
      "  0.09545028 -0.44122506]\n",
      "Training Error:  10.565005904015683\n",
      "====================================================================================================\n",
      "Iteration:  554\n",
      "Previous theta :  [ 0.00660542 -0.06619895  0.09860762  0.00906265  0.1013065  -0.20382387\n",
      "  0.28505343 -0.00330671 -0.29329999  0.27454842 -0.18341182 -0.20717234\n",
      "  0.09545028 -0.44122506]\n",
      "New theta_0 : [ 0.00660386 -0.06628428  0.09868772  0.00907892  0.10129493 -0.20402086\n",
      "  0.28497432 -0.00327758 -0.29350231  0.27478911 -0.18357536 -0.2072226\n",
      "  0.09542447 -0.44123974]\n",
      "Training Error:  10.564830695355067\n",
      "====================================================================================================\n",
      "Iteration:  555\n",
      "Previous theta :  [ 0.00660386 -0.06628428  0.09868772  0.00907892  0.10129493 -0.20402086\n",
      "  0.28497432 -0.00327758 -0.29350231  0.27478911 -0.18357536 -0.2072226\n",
      "  0.09542447 -0.44123974]\n",
      "New theta_0 : [ 0.00660231 -0.06636907  0.09876731  0.00909543  0.10128341 -0.20421654\n",
      "  0.28489575 -0.0032486  -0.29370312  0.27502892 -0.18373868 -0.20727256\n",
      "  0.09539884 -0.4412543 ]\n",
      "Training Error:  10.564657263817676\n",
      "====================================================================================================\n",
      "Iteration:  556\n",
      "Previous theta :  [ 0.00660231 -0.06636907  0.09876731  0.00909543  0.10128341 -0.20421654\n",
      "  0.28489575 -0.0032486  -0.29370312  0.27502892 -0.18373868 -0.20727256\n",
      "  0.09539884 -0.4412543 ]\n",
      "New theta_0 : [ 0.00660077 -0.06645332  0.09884639  0.00911219  0.10127192 -0.20441093\n",
      "  0.28481773 -0.00321976 -0.29390242  0.27526785 -0.18390177 -0.20732222\n",
      "  0.09537341 -0.44126875]\n",
      "Training Error:  10.56448558779536\n",
      "====================================================================================================\n",
      "Iteration:  557\n",
      "Previous theta :  [ 0.00660077 -0.06645332  0.09884639  0.00911219  0.10127192 -0.20441093\n",
      "  0.28481773 -0.00321976 -0.29390242  0.27526785 -0.18390177 -0.20732222\n",
      "  0.09537341 -0.44126875]\n",
      "New theta_0 : [ 0.00659924 -0.06653704  0.09892497  0.00912918  0.10126047 -0.20460404\n",
      "  0.28474025 -0.00319107 -0.29410024  0.27550593 -0.18406464 -0.20737157\n",
      "  0.09534816 -0.44128308]\n",
      "Training Error:  10.564315645970455\n",
      "====================================================================================================\n",
      "Iteration:  558\n",
      "Previous theta :  [ 0.00659924 -0.06653704  0.09892497  0.00912918  0.10126047 -0.20460404\n",
      "  0.28474025 -0.00319107 -0.29410024  0.27550593 -0.18406464 -0.20737157\n",
      "  0.09534816 -0.44128308]\n",
      "New theta_0 : [ 0.00659771 -0.06662023  0.09900305  0.00914641  0.10124906 -0.20479587\n",
      "  0.28466331 -0.00316253 -0.29429658  0.27574313 -0.18422728 -0.20742062\n",
      "  0.0953231  -0.44129731]\n",
      "Training Error:  10.56414741731167\n",
      "====================================================================================================\n",
      "Iteration:  559\n",
      "Previous theta :  [ 0.00659771 -0.06662023  0.09900305  0.00914641  0.10124906 -0.20479587\n",
      "  0.28466331 -0.00316253 -0.29429658  0.27574313 -0.18422728 -0.20742062\n",
      "  0.0953231  -0.44129731]\n",
      "New theta_0 : [ 0.0065962  -0.0667029   0.09908063  0.00916388  0.10123768 -0.20498643\n",
      "  0.2845869  -0.00313414 -0.29449145  0.27597948 -0.18438969 -0.20746937\n",
      "  0.09529822 -0.44131142]\n",
      "Training Error:  10.563980881070062\n",
      "====================================================================================================\n",
      "Iteration:  560\n",
      "Previous theta :  [ 0.0065962  -0.0667029   0.09908063  0.00916388  0.10123768 -0.20498643\n",
      "  0.2845869  -0.00313414 -0.29449145  0.27597948 -0.18438969 -0.20746937\n",
      "  0.09529822 -0.44131142]\n",
      "New theta_0 : [ 0.00659469 -0.06678504  0.09915772  0.00918157  0.10122635 -0.20517573\n",
      "  0.28451102 -0.00310589 -0.29468486  0.27621498 -0.18455188 -0.20751782\n",
      "  0.09527353 -0.44132543]\n",
      "Training Error:  10.56381601677505\n",
      "====================================================================================================\n",
      "Iteration:  561\n",
      "Previous theta :  [ 0.00659469 -0.06678504  0.09915772  0.00918157  0.10122635 -0.20517573\n",
      "  0.28451102 -0.00310589 -0.29468486  0.27621498 -0.18455188 -0.20751782\n",
      "  0.09527353 -0.44132543]\n",
      "New theta_0 : [ 0.00659319 -0.06686666  0.09923432  0.00919948  0.10121505 -0.20536378\n",
      "  0.28443566 -0.00307779 -0.29487683  0.27644963 -0.18471383 -0.20756597\n",
      "  0.09524902 -0.44133932]\n",
      "Training Error:  10.563652804230495\n",
      "====================================================================================================\n",
      "Iteration:  562\n",
      "Previous theta :  [ 0.00659319 -0.06686666  0.09923432  0.00919948  0.10121505 -0.20536378\n",
      "  0.28443566 -0.00307779 -0.29487683  0.27644963 -0.18471383 -0.20756597\n",
      "  0.09524902 -0.44133932]\n",
      "New theta_0 : [ 0.0065917  -0.06694777  0.09931043  0.00921762  0.10120378 -0.20555059\n",
      "  0.28436082 -0.00304983 -0.29506736  0.27668342 -0.18487556 -0.20761383\n",
      "  0.09522468 -0.44135312]\n",
      "Training Error:  10.563491223510832\n",
      "====================================================================================================\n",
      "Iteration:  563\n",
      "Previous theta :  [ 0.0065917  -0.06694777  0.09931043  0.00921762  0.10120378 -0.20555059\n",
      "  0.28436082 -0.00304983 -0.29506736  0.27668342 -0.18487556 -0.20761383\n",
      "  0.09522468 -0.44135312]\n",
      "New theta_0 : [ 0.00659021 -0.06702836  0.09938606  0.00923597  0.10119256 -0.20573616\n",
      "  0.2842865  -0.00302201 -0.29525647  0.27691638 -0.18503706 -0.2076614\n",
      "  0.09520053 -0.44136681]\n",
      "Training Error:  10.56333125495726\n",
      "====================================================================================================\n",
      "Iteration:  564\n",
      "Previous theta :  [ 0.00659021 -0.06702836  0.09938606  0.00923597  0.10119256 -0.20573616\n",
      "  0.2842865  -0.00302201 -0.29525647  0.27691638 -0.18503706 -0.2076614\n",
      "  0.09520053 -0.44136681]\n",
      "New theta_0 : [ 0.00658873 -0.06710845  0.0994612   0.00925455  0.10118137 -0.2059205\n",
      "  0.28421269 -0.00299433 -0.29544417  0.2771485  -0.18519833 -0.20770868\n",
      "  0.09517656 -0.44138039]\n",
      "Training Error:  10.563172879173987\n",
      "====================================================================================================\n",
      "Iteration:  565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous theta :  [ 0.00658873 -0.06710845  0.0994612   0.00925455  0.10118137 -0.2059205\n",
      "  0.28421269 -0.00299433 -0.29544417  0.2771485  -0.18519833 -0.20770868\n",
      "  0.09517656 -0.44138039]\n",
      "New theta_0 : [ 0.00658727 -0.06718803  0.09953588  0.00927333  0.10117021 -0.20610362\n",
      "  0.28413939 -0.0029668  -0.29563046  0.27737978 -0.18535937 -0.20775567\n",
      "  0.09515276 -0.44139387]\n",
      "Training Error:  10.563016077024528\n",
      "====================================================================================================\n",
      "Iteration:  566\n",
      "Previous theta :  [ 0.00658727 -0.06718803  0.09953588  0.00927333  0.10117021 -0.20610362\n",
      "  0.28413939 -0.0029668  -0.29563046  0.27737978 -0.18535937 -0.20775567\n",
      "  0.09515276 -0.44139387]\n",
      "New theta_0 : [ 0.00658581 -0.06726711  0.09961007  0.00929232  0.1011591  -0.20628553\n",
      "  0.28406659 -0.0029394  -0.29581536  0.27761024 -0.18552017 -0.20780238\n",
      "  0.09512914 -0.44140726]\n",
      "Training Error:  10.56286082962807\n",
      "====================================================================================================\n",
      "Iteration:  567\n",
      "Previous theta :  [ 0.00658581 -0.06726711  0.09961007  0.00929232  0.1011591  -0.20628553\n",
      "  0.28406659 -0.0029394  -0.29581536  0.27761024 -0.18552017 -0.20780238\n",
      "  0.09512914 -0.44140726]\n",
      "New theta_0 : [ 0.00658435 -0.06734569  0.0996838   0.00931152  0.10114802 -0.20646624\n",
      "  0.28399428 -0.00291215 -0.29599887  0.27783986 -0.18568074 -0.2078488\n",
      "  0.0951057  -0.44142054]\n",
      "Training Error:  10.562707118355853\n",
      "====================================================================================================\n",
      "Iteration:  568\n",
      "Previous theta :  [ 0.00658435 -0.06734569  0.0996838   0.00931152  0.10114802 -0.20646624\n",
      "  0.28399428 -0.00291215 -0.29599887  0.27783986 -0.18568074 -0.2078488\n",
      "  0.0951057  -0.44142054]\n",
      "New theta_0 : [ 0.00658291 -0.06742378  0.09975706  0.00933093  0.10113697 -0.20664576\n",
      "  0.28392248 -0.00288503 -0.29618102  0.27806867 -0.18584107 -0.20789494\n",
      "  0.09508242 -0.44143373]\n",
      "Training Error:  10.562554924827648\n",
      "====================================================================================================\n",
      "Iteration:  569\n",
      "Previous theta :  [ 0.00658291 -0.06742378  0.09975706  0.00933093  0.10113697 -0.20664576\n",
      "  0.28392248 -0.00288503 -0.29618102  0.27806867 -0.18584107 -0.20789494\n",
      "  0.09508242 -0.44143373]\n",
      "New theta_0 : [ 0.00658147 -0.06750137  0.09982986  0.00935053  0.10112596 -0.20682408\n",
      "  0.28385116 -0.00285805 -0.2963618   0.27829665 -0.18600118 -0.20794079\n",
      "  0.09505932 -0.44144682]\n",
      "Training Error:  10.562404230908259\n",
      "====================================================================================================\n",
      "Iteration:  570\n",
      "Previous theta :  [ 0.00658147 -0.06750137  0.09982986  0.00935053  0.10112596 -0.20682408\n",
      "  0.28385116 -0.00285805 -0.2963618   0.27829665 -0.18600118 -0.20794079\n",
      "  0.09505932 -0.44144682]\n",
      "New theta_0 : [ 0.00658004 -0.06757848  0.0999022   0.00937033  0.10111499 -0.20700123\n",
      "  0.28378033 -0.00283121 -0.29654123  0.27852382 -0.18616104 -0.20798637\n",
      "  0.09503638 -0.44145982]\n",
      "Training Error:  10.562255018704077\n",
      "====================================================================================================\n",
      "Iteration:  571\n",
      "Previous theta :  [ 0.00658004 -0.06757848  0.0999022   0.00937033  0.10111499 -0.20700123\n",
      "  0.28378033 -0.00283121 -0.29654123  0.27852382 -0.18616104 -0.20798637\n",
      "  0.09503638 -0.44145982]\n",
      "New theta_0 : [ 0.00657862 -0.0676551   0.09997408  0.00939033  0.10110405 -0.2071772\n",
      "  0.28370999 -0.00280451 -0.29671932  0.27875018 -0.18632067 -0.20803167\n",
      "  0.09501362 -0.44147272]\n",
      "Training Error:  10.562107270559697\n",
      "====================================================================================================\n",
      "Iteration:  572\n",
      "Previous theta :  [ 0.00657862 -0.0676551   0.09997408  0.00939033  0.10110405 -0.2071772\n",
      "  0.28370999 -0.00280451 -0.29671932  0.27875018 -0.18632067 -0.20803167\n",
      "  0.09501362 -0.44147272]\n",
      "New theta_0 : [ 0.00657721 -0.06773125  0.1000455   0.00941052  0.10109314 -0.20735201\n",
      "  0.28364012 -0.00277794 -0.29689608  0.27897573 -0.18648006 -0.2080767\n",
      "  0.09499102 -0.44148553]\n",
      "Training Error:  10.56196096905456\n",
      "====================================================================================================\n",
      "Iteration:  573\n",
      "Previous theta :  [ 0.00657721 -0.06773125  0.1000455   0.00941052  0.10109314 -0.20735201\n",
      "  0.28364012 -0.00277794 -0.29689608  0.27897573 -0.18648006 -0.2080767\n",
      "  0.09499102 -0.44148553]\n",
      "New theta_0 : [ 0.0065758  -0.06780691  0.10011648  0.0094309   0.10108227 -0.20752566\n",
      "  0.28357073 -0.0027515  -0.29707152  0.27920048 -0.18663922 -0.20812145\n",
      "  0.09496859 -0.44149824]\n",
      "Training Error:  10.56181609699968\n",
      "====================================================================================================\n",
      "Iteration:  574\n",
      "Previous theta :  [ 0.0065758  -0.06780691  0.10011648  0.0094309   0.10108227 -0.20752566\n",
      "  0.28357073 -0.0027515  -0.29707152  0.27920048 -0.18663922 -0.20812145\n",
      "  0.09496859 -0.44149824]\n",
      "New theta_0 : [ 0.0065744  -0.0678821   0.100187    0.00945146  0.10107144 -0.20769817\n",
      "  0.28350181 -0.0027252  -0.29724565  0.27942443 -0.18679813 -0.20816593\n",
      "  0.09494632 -0.44151087]\n",
      "Training Error:  10.561672637434375\n",
      "====================================================================================================\n",
      "Iteration:  575\n",
      "Previous theta :  [ 0.0065744  -0.0678821   0.100187    0.00945146  0.10107144 -0.20769817\n",
      "  0.28350181 -0.0027252  -0.29724565  0.27942443 -0.18679813 -0.20816593\n",
      "  0.09494632 -0.44151087]\n",
      "New theta_0 : [ 0.00657301 -0.06795682  0.10025709  0.00947221  0.10106064 -0.20786953\n",
      "  0.28343336 -0.00269903 -0.29741847  0.27964758 -0.18695681 -0.20821014\n",
      "  0.09492422 -0.44152341]\n",
      "Training Error:  10.561530573623081\n",
      "====================================================================================================\n",
      "Iteration:  576\n",
      "Previous theta :  [ 0.00657301 -0.06795682  0.10025709  0.00947221  0.10106064 -0.20786953\n",
      "  0.28343336 -0.00269903 -0.29741847  0.27964758 -0.18695681 -0.20821014\n",
      "  0.09492422 -0.44152341]\n",
      "New theta_0 : [ 0.00657163 -0.06803106  0.10032673  0.00949313  0.10104988 -0.20803975\n",
      "  0.28336537 -0.002673   -0.29759     0.27986994 -0.18711525 -0.20825408\n",
      "  0.09490228 -0.44153586]\n",
      "Training Error:  10.561389889052194\n",
      "====================================================================================================\n",
      "Iteration:  577\n",
      "Previous theta :  [ 0.00657163 -0.06803106  0.10032673  0.00949313  0.10104988 -0.20803975\n",
      "  0.28336537 -0.002673   -0.29759     0.27986994 -0.18711525 -0.20825408\n",
      "  0.09490228 -0.44153586]\n",
      "New theta_0 : [ 0.00657025 -0.06810485  0.10039593  0.00951424  0.10103915 -0.20820885\n",
      "  0.28329785 -0.00264709 -0.29776025  0.28009151 -0.18727345 -0.20829776\n",
      "  0.0948805  -0.44154822]\n",
      "Training Error:  10.561250567426951\n",
      "====================================================================================================\n",
      "Iteration:  578\n",
      "Previous theta :  [ 0.00657025 -0.06810485  0.10039593  0.00951424  0.10103915 -0.20820885\n",
      "  0.28329785 -0.00264709 -0.29776025  0.28009151 -0.18727345 -0.20829776\n",
      "  0.0948805  -0.44154822]\n",
      "New theta_0 : [ 0.00656888 -0.06817817  0.10046469  0.00953552  0.10102845 -0.20837683\n",
      "  0.28323078 -0.00262132 -0.29792922  0.28031229 -0.1874314  -0.20834117\n",
      "  0.09485888 -0.4415605 ]\n",
      "Training Error:  10.561112592668385\n",
      "====================================================================================================\n",
      "Iteration:  579\n",
      "Previous theta :  [ 0.00656888 -0.06817817  0.10046469  0.00953552  0.10102845 -0.20837683\n",
      "  0.28323078 -0.00262132 -0.29792922  0.28031229 -0.1874314  -0.20834117\n",
      "  0.09485888 -0.4415605 ]\n",
      "New theta_0 : [ 0.00656752 -0.06825103  0.10053302  0.00955697  0.10101779 -0.2085437\n",
      "  0.28316417 -0.00259568 -0.29809693  0.2805323  -0.18758912 -0.20838432\n",
      "  0.09483742 -0.44157269]\n",
      "Training Error:  10.560975948910283\n",
      "====================================================================================================\n",
      "Iteration:  580\n",
      "Previous theta :  [ 0.00656752 -0.06825103  0.10053302  0.00955697  0.10101779 -0.2085437\n",
      "  0.28316417 -0.00259568 -0.29809693  0.2805323  -0.18758912 -0.20838432\n",
      "  0.09483742 -0.44157269]\n",
      "New theta_0 : [ 0.00656617 -0.06832344  0.10060093  0.0095786   0.10100716 -0.20870946\n",
      "  0.283098   -0.00257016 -0.29826339  0.28075153 -0.18774659 -0.20842721\n",
      "  0.09481611 -0.4415848 ]\n",
      "Training Error:  10.560840620496231\n",
      "====================================================================================================\n",
      "Iteration:  581\n",
      "Previous theta :  [ 0.00656617 -0.06832344  0.10060093  0.0095786   0.10100716 -0.20870946\n",
      "  0.283098   -0.00257016 -0.29826339  0.28075153 -0.18774659 -0.20842721\n",
      "  0.09481611 -0.4415848 ]\n",
      "New theta_0 : [ 0.00656482 -0.0683954   0.1006684   0.00960039  0.10099657 -0.20887413\n",
      "  0.28303228 -0.00254478 -0.2984286   0.28096998 -0.18790382 -0.20846984\n",
      "  0.09479497 -0.44159683]\n",
      "Training Error:  10.560706591976661\n",
      "====================================================================================================\n",
      "Iteration:  582\n",
      "Previous theta :  [ 0.00656482 -0.0683954   0.1006684   0.00960039  0.10099657 -0.20887413\n",
      "  0.28303228 -0.00254478 -0.2984286   0.28096998 -0.18790382 -0.20846984\n",
      "  0.09479497 -0.44159683]\n",
      "New theta_0 : [ 0.00656348 -0.06846691  0.10073545  0.00962234  0.10098601 -0.2090377\n",
      "  0.28296701 -0.00251952 -0.29859258  0.28118766 -0.18806081 -0.20851221\n",
      "  0.09477397 -0.44160877]\n",
      "Training Error:  10.560573848105967\n",
      "====================================================================================================\n",
      "Iteration:  583\n",
      "Previous theta :  [ 0.00656348 -0.06846691  0.10073545  0.00962234  0.10098601 -0.2090377\n",
      "  0.28296701 -0.00251952 -0.29859258  0.28118766 -0.18806081 -0.20851221\n",
      "  0.09477397 -0.44160877]\n",
      "New theta_0 : [ 0.00656215 -0.06853797  0.10080208  0.00964446  0.10097548 -0.20920019\n",
      "  0.28290217 -0.00249439 -0.29875533  0.28140457 -0.18821755 -0.20855432\n",
      "  0.09475313 -0.44162064]\n",
      "Training Error:  10.56044237383966\n",
      "====================================================================================================\n",
      "Iteration:  584\n",
      "Previous theta :  [ 0.00656215 -0.06853797  0.10080208  0.00964446  0.10097548 -0.20920019\n",
      "  0.28290217 -0.00249439 -0.29875533  0.28140457 -0.18821755 -0.20855432\n",
      "  0.09475313 -0.44162064]\n",
      "New theta_0 : [ 0.00656082 -0.06860858  0.10086829  0.00966673  0.10096499 -0.20936161\n",
      "  0.28283777 -0.00246938 -0.29891687  0.28162072 -0.18837405 -0.20859618\n",
      "  0.09473245 -0.44163242]\n",
      "Training Error:  10.56031215433155\n",
      "====================================================================================================\n",
      "Iteration:  585\n",
      "Previous theta :  [ 0.00656082 -0.06860858  0.10086829  0.00966673  0.10096499 -0.20936161\n",
      "  0.28283777 -0.00246938 -0.29891687  0.28162072 -0.18837405 -0.20859618\n",
      "  0.09473245 -0.44163242]\n",
      "New theta_0 : [ 0.00655951 -0.06867876  0.10093409  0.00968917  0.10095453 -0.20952196\n",
      "  0.2827738  -0.0024445  -0.29907719  0.28183611 -0.18853031 -0.20863778\n",
      "  0.09471191 -0.44164413]\n",
      "Training Error:  10.560183174930978\n",
      "====================================================================================================\n",
      "Iteration:  586\n",
      "Previous theta :  [ 0.00655951 -0.06867876  0.10093409  0.00968917  0.10095453 -0.20952196\n",
      "  0.2827738  -0.0024445  -0.29907719  0.28183611 -0.18853031 -0.20863778\n",
      "  0.09471191 -0.44164413]\n",
      "New theta_0 : [ 0.00655819 -0.0687485   0.10099947  0.00971176  0.1009441  -0.20968124\n",
      "  0.28271026 -0.00241975 -0.29923632  0.28205075 -0.18868631 -0.20867914\n",
      "  0.09469153 -0.44165576]\n",
      "Training Error:  10.560055421180095\n",
      "====================================================================================================\n",
      "Iteration:  587\n",
      "Previous theta :  [ 0.00655819 -0.0687485   0.10099947  0.00971176  0.1009441  -0.20968124\n",
      "  0.28271026 -0.00241975 -0.29923632  0.28205075 -0.18868631 -0.20867914\n",
      "  0.09469153 -0.44165576]\n",
      "New theta_0 : [ 0.00655689 -0.06881781  0.10106445  0.0097345   0.1009337  -0.20983947\n",
      "  0.28264715 -0.00239512 -0.29939425  0.28226463 -0.18884208 -0.20872024\n",
      "  0.09467129 -0.44166732]\n",
      "Training Error:  10.559928878811164\n",
      "====================================================================================================\n",
      "Iteration:  588\n",
      "Previous theta :  [ 0.00655689 -0.06881781  0.10106445  0.0097345   0.1009337  -0.20983947\n",
      "  0.28264715 -0.00239512 -0.29939425  0.28226463 -0.18884208 -0.20872024\n",
      "  0.09467129 -0.44166732]\n",
      "New theta_0 : [ 0.00655559 -0.06888668  0.10112902  0.00975738  0.10092334 -0.20999665\n",
      "  0.28258446 -0.00237061 -0.29955101  0.28247776 -0.18899759 -0.2087611\n",
      "  0.09465121 -0.44167879]\n",
      "Training Error:  10.55980353374391\n",
      "====================================================================================================\n",
      "Iteration:  589\n",
      "Previous theta :  [ 0.00655559 -0.06888668  0.10112902  0.00975738  0.10092334 -0.20999665\n",
      "  0.28258446 -0.00237061 -0.29955101  0.28247776 -0.18899759 -0.2087611\n",
      "  0.09465121 -0.44167879]\n",
      "New theta_0 : [ 0.0065543  -0.06895513  0.10119318  0.00978042  0.10091301 -0.21015279\n",
      "  0.28252218 -0.00234622 -0.29970659  0.28269014 -0.18915286 -0.20880171\n",
      "  0.09463127 -0.4416902 ]\n",
      "Training Error:  10.559679372082908\n",
      "====================================================================================================\n",
      "Iteration:  590\n",
      "Previous theta :  [ 0.0065543  -0.06895513  0.10119318  0.00978042  0.10091301 -0.21015279\n",
      "  0.28252218 -0.00234622 -0.29970659  0.28269014 -0.18915286 -0.20880171\n",
      "  0.09463127 -0.4416902 ]\n",
      "New theta_0 : [ 0.00655302 -0.06902315  0.10125694  0.0098036   0.10090272 -0.21030789\n",
      "  0.28246032 -0.00232196 -0.299861    0.28290179 -0.18930788 -0.20884208\n",
      "  0.09461147 -0.44170153]\n",
      "Training Error:  10.559556380115007\n",
      "====================================================================================================\n",
      "Iteration:  591\n",
      "Previous theta :  [ 0.00655302 -0.06902315  0.10125694  0.0098036   0.10090272 -0.21030789\n",
      "  0.28246032 -0.00232196 -0.299861    0.28290179 -0.18930788 -0.20884208\n",
      "  0.09461147 -0.44170153]\n",
      "New theta_0 : [ 0.00655174 -0.06909075  0.10132031  0.00982693  0.10089245 -0.21046197\n",
      "  0.28239888 -0.00229782 -0.30001427  0.28311269 -0.18946265 -0.2088822\n",
      "  0.09459182 -0.44171279]\n",
      "Training Error:  10.559434544306788\n",
      "====================================================================================================\n",
      "Iteration:  592\n",
      "Previous theta :  [ 0.00655174 -0.06909075  0.10132031  0.00982693  0.10089245 -0.21046197\n",
      "  0.28239888 -0.00229782 -0.30001427  0.28311269 -0.18946265 -0.2088822\n",
      "  0.09459182 -0.44171279]\n",
      "New theta_0 : [ 0.00655047 -0.06915792  0.10138328  0.00985039  0.10088222 -0.21061503\n",
      "  0.28233784 -0.00227379 -0.30016638  0.28332285 -0.18961718 -0.20892208\n",
      "  0.09457231 -0.44172398]\n",
      "Training Error:  10.55931385130207\n",
      "====================================================================================================\n",
      "Iteration:  593\n",
      "Previous theta :  [ 0.00655047 -0.06915792  0.10138328  0.00985039  0.10088222 -0.21061503\n",
      "  0.28233784 -0.00227379 -0.30016638  0.28332285 -0.18961718 -0.20892208\n",
      "  0.09457231 -0.44172398]\n",
      "New theta_0 : [ 0.00654921 -0.06922469  0.10144585  0.00987399  0.10087202 -0.21076707\n",
      "  0.28227721 -0.00224989 -0.30031736  0.28353229 -0.18977145 -0.20896172\n",
      "  0.09455295 -0.44173509]\n",
      "Training Error:  10.559194287919437\n",
      "====================================================================================================\n",
      "Iteration:  594\n",
      "Previous theta :  [ 0.00654921 -0.06922469  0.10144585  0.00987399  0.10087202 -0.21076707\n",
      "  0.28227721 -0.00224989 -0.30031736  0.28353229 -0.18977145 -0.20896172\n",
      "  0.09455295 -0.44173509]\n",
      "New theta_0 : [ 0.00654796 -0.06929104  0.10150804  0.00989773  0.10086185 -0.2109181\n",
      "  0.28221699 -0.00222611 -0.30046721  0.28374099 -0.18992548 -0.20900113\n",
      "  0.09453373 -0.44174614]\n",
      "Training Error:  10.559075841149802\n",
      "====================================================================================================\n",
      "Iteration:  595\n",
      "Previous theta :  [ 0.00654796 -0.06929104  0.10150804  0.00989773  0.10086185 -0.2109181\n",
      "  0.28221699 -0.00222611 -0.30046721  0.28374099 -0.18992548 -0.20900113\n",
      "  0.09453373 -0.44174614]\n",
      "New theta_0 : [ 0.00654671 -0.06935697  0.10156983  0.0099216   0.10085171 -0.21106814\n",
      "  0.28215716 -0.00220244 -0.30061594  0.28394897 -0.19007925 -0.20904029\n",
      "  0.09451465 -0.44175712]\n",
      "Training Error:  10.558958498154023\n",
      "====================================================================================================\n",
      "Iteration:  596\n",
      "Previous theta :  [ 0.00654671 -0.06935697  0.10156983  0.0099216   0.10085171 -0.21106814\n",
      "  0.28215716 -0.00220244 -0.30061594  0.28394897 -0.19007925 -0.20904029\n",
      "  0.09451465 -0.44175712]\n",
      "New theta_0 : [ 0.00654547 -0.0694225   0.10163125  0.0099456   0.10084161 -0.21121718\n",
      "  0.28209773 -0.00217889 -0.30076355  0.28415622 -0.19023278 -0.20907922\n",
      "  0.0944957  -0.44176803]\n",
      "Training Error:  10.558842246260527\n",
      "====================================================================================================\n",
      "Iteration:  597\n",
      "Previous theta :  [ 0.00654547 -0.0694225   0.10163125  0.0099456   0.10084161 -0.21121718\n",
      "  0.28209773 -0.00217889 -0.30076355  0.28415622 -0.19023278 -0.20907922\n",
      "  0.0944957  -0.44176803]\n",
      "New theta_0 : [ 0.00654423 -0.06948763  0.10169228  0.00996973  0.10083153 -0.21136523\n",
      "  0.28203869 -0.00215546 -0.30091006  0.28436276 -0.19038605 -0.20911792\n",
      "  0.0944769  -0.44177887]\n",
      "Training Error:  10.558727072962995\n",
      "====================================================================================================\n",
      "Iteration:  598\n",
      "Previous theta :  [ 0.00654423 -0.06948763  0.10169228  0.00996973  0.10083153 -0.21136523\n",
      "  0.28203869 -0.00215546 -0.30091006  0.28436276 -0.19038605 -0.20911792\n",
      "  0.0944769  -0.44177887]\n",
      "New theta_0 : [ 0.006543   -0.06955235  0.10175293  0.00999399  0.10082149 -0.2115123\n",
      "  0.28198004 -0.00213214 -0.30105547  0.28456858 -0.19053907 -0.20915638\n",
      "  0.09445823 -0.44178965]\n",
      "Training Error:  10.55861296591806\n",
      "====================================================================================================\n",
      "Iteration:  599\n",
      "Previous theta :  [ 0.006543   -0.06955235  0.10175293  0.00999399  0.10082149 -0.2115123\n",
      "  0.28198004 -0.00213214 -0.30105547  0.28456858 -0.19053907 -0.20915638\n",
      "  0.09445823 -0.44178965]\n",
      "New theta_0 : [ 0.00654178 -0.06961667  0.1018132   0.01001837  0.10081148 -0.21165839\n",
      "  0.28192178 -0.00210894 -0.3011998   0.28477368 -0.19069184 -0.20919461\n",
      "  0.0944397  -0.44180036]\n",
      "Training Error:  10.558499912943045\n",
      "====================================================================================================\n",
      "Iteration:  600\n",
      "Previous theta :  [ 0.00654178 -0.06961667  0.1018132   0.01001837  0.10081148 -0.21165839\n",
      "  0.28192178 -0.00210894 -0.3011998   0.28477368 -0.19069184 -0.20919461\n",
      "  0.0944397  -0.44180036]\n",
      "New theta_0 : [ 0.00654056 -0.06968059  0.1018731   0.01004288  0.1008015  -0.21180352\n",
      "  0.28186391 -0.00208585 -0.30134304  0.28497808 -0.19084436 -0.20923262\n",
      "  0.0944213  -0.44181101]\n",
      "Training Error:  10.55838790201373\n",
      "====================================================================================================\n",
      "Iteration:  601\n",
      "Previous theta :  [ 0.00654056 -0.06968059  0.1018731   0.01004288  0.1008015  -0.21180352\n",
      "  0.28186391 -0.00208585 -0.30134304  0.28497808 -0.19084436 -0.20923262\n",
      "  0.0944213  -0.44181101]\n",
      "New theta_0 : [ 0.00653935 -0.06974412  0.10193263  0.0100675   0.10079155 -0.21194768\n",
      "  0.28180641 -0.00206288 -0.30148521  0.28518176 -0.19099663 -0.20927039\n",
      "  0.09440304 -0.44182159]\n",
      "Training Error:  10.55827692126217\n",
      "====================================================================================================\n",
      "Iteration:  602\n",
      "Previous theta :  [ 0.00653935 -0.06974412  0.10193263  0.0100675   0.10079155 -0.21194768\n",
      "  0.28180641 -0.00206288 -0.30148521  0.28518176 -0.19099663 -0.20927039\n",
      "  0.09440304 -0.44182159]\n",
      "New theta_0 : [ 0.00653815 -0.06980726  0.10199179  0.01009224  0.10078163 -0.21209089\n",
      "  0.28174929 -0.00204002 -0.30162632  0.28538475 -0.19114864 -0.20930794\n",
      "  0.09438491 -0.44183211]\n",
      "Training Error:  10.558166958974503\n",
      "====================================================================================================\n",
      "Iteration:  603\n",
      "Previous theta :  [ 0.00653815 -0.06980726  0.10199179  0.01009224  0.10078163 -0.21209089\n",
      "  0.28174929 -0.00204002 -0.30162632  0.28538475 -0.19114864 -0.20930794\n",
      "  0.09438491 -0.44183211]\n",
      "New theta_0 : [ 0.00653695 -0.06987001  0.10205058  0.0101171   0.10077175 -0.21223315\n",
      "  0.28169255 -0.00201728 -0.30176638  0.28558703 -0.1913004  -0.20934526\n",
      "  0.09436691 -0.44184257]\n",
      "Training Error:  10.55805800358884\n",
      "====================================================================================================\n",
      "Iteration:  604\n",
      "Previous theta :  [ 0.00653695 -0.06987001  0.10205058  0.0101171   0.10077175 -0.21223315\n",
      "  0.28169255 -0.00201728 -0.30176638  0.28558703 -0.1913004  -0.20934526\n",
      "  0.09436691 -0.44184257]\n",
      "New theta_0 : [ 0.00653576 -0.06993237  0.102109    0.01014207  0.10076189 -0.21237447\n",
      "  0.28163618 -0.00199464 -0.30190538  0.28578862 -0.1914519  -0.20938236\n",
      "  0.09434905 -0.44185296]\n",
      "Training Error:  10.557950043693143\n",
      "====================================================================================================\n",
      "Iteration:  605\n",
      "Previous theta :  [ 0.00653576 -0.06993237  0.102109    0.01014207  0.10076189 -0.21237447\n",
      "  0.28163618 -0.00199464 -0.30190538  0.28578862 -0.1914519  -0.20938236\n",
      "  0.09434905 -0.44185296]\n",
      "New theta_0 : [ 0.00653458 -0.06999435  0.10216707  0.01016716  0.10075206 -0.21251484\n",
      "  0.28158019 -0.00197212 -0.30204334  0.28598951 -0.19160315 -0.20941924\n",
      "  0.09433131 -0.4418633 ]\n",
      "Training Error:  10.557843068023162\n",
      "====================================================================================================\n",
      "Iteration:  606\n",
      "Previous theta :  [ 0.00653458 -0.06999435  0.10216707  0.01016716  0.10075206 -0.21251484\n",
      "  0.28158019 -0.00197212 -0.30204334  0.28598951 -0.19160315 -0.20941924\n",
      "  0.09433131 -0.4418633 ]\n",
      "New theta_0 : [ 0.0065334  -0.07005595  0.10222477  0.01019235  0.10074227 -0.21265429\n",
      "  0.28152455 -0.0019497  -0.30218027  0.28618971 -0.19175415 -0.20945589\n",
      "  0.0943137  -0.44187358]\n",
      "Training Error:  10.55773706546038\n",
      "====================================================================================================\n",
      "Iteration:  607\n",
      "Previous theta :  [ 0.0065334  -0.07005595  0.10222477  0.01019235  0.10074227 -0.21265429\n",
      "  0.28152455 -0.0019497  -0.30218027  0.28618971 -0.19175415 -0.20945589\n",
      "  0.0943137  -0.44187358]\n",
      "New theta_0 : [ 0.00653223 -0.07011717  0.10228212  0.01021765  0.1007325  -0.21279281\n",
      "  0.28146928 -0.0019274  -0.30231618  0.28638923 -0.19190489 -0.20949233\n",
      "  0.09429622 -0.44188379]\n",
      "Training Error:  10.55763202503\n",
      "====================================================================================================\n",
      "Iteration:  608\n",
      "Previous theta :  [ 0.00653223 -0.07011717  0.10228212  0.01021765  0.1007325  -0.21279281\n",
      "  0.28146928 -0.0019274  -0.30231618  0.28638923 -0.19190489 -0.20949233\n",
      "  0.09429622 -0.44188379]\n",
      "New theta_0 : [ 0.00653107 -0.07017801  0.10233912  0.01024306  0.10072277 -0.21293042\n",
      "  0.28141438 -0.00190521 -0.30245107  0.28658805 -0.19205538 -0.20952855\n",
      "  0.09427887 -0.44189395]\n",
      "Training Error:  10.557527935898962\n",
      "====================================================================================================\n",
      "Iteration:  609\n",
      "Previous theta :  [ 0.00653107 -0.07017801  0.10233912  0.01024306  0.10072277 -0.21293042\n",
      "  0.28141438 -0.00190521 -0.30245107  0.28658805 -0.19205538 -0.20952855\n",
      "  0.09427887 -0.44189395]\n",
      "New theta_0 : [ 0.00652991 -0.07023848  0.10239576  0.01026857  0.10071306 -0.21306711\n",
      "  0.28135983 -0.00188312 -0.30258495  0.2867862  -0.19220561 -0.20956455\n",
      "  0.09426164 -0.44190406]\n",
      "Training Error:  10.557424787373986\n",
      "====================================================================================================\n",
      "Iteration:  610\n",
      "Previous theta :  [ 0.00652991 -0.07023848  0.10239576  0.01026857  0.10071306 -0.21306711\n",
      "  0.28135983 -0.00188312 -0.30258495  0.2867862  -0.19220561 -0.20956455\n",
      "  0.09426164 -0.44190406]\n",
      "New theta_0 : [ 0.00652876 -0.07029858  0.10245205  0.01029418  0.10070338 -0.2132029\n",
      "  0.28130563 -0.00186114 -0.30271782  0.28698367 -0.19235559 -0.20960034\n",
      "  0.09424454 -0.4419141 ]\n",
      "Training Error:  10.557322568899629\n",
      "====================================================================================================\n",
      "Iteration:  611\n",
      "Previous theta :  [ 0.00652876 -0.07029858  0.10245205  0.01029418  0.10070338 -0.2132029\n",
      "  0.28130563 -0.00186114 -0.30271782  0.28698367 -0.19235559 -0.20960034\n",
      "  0.09424454 -0.4419141 ]\n",
      "New theta_0 : [ 0.00652761 -0.07035831  0.102508    0.0103199   0.10069374 -0.21333778\n",
      "  0.28125179 -0.00183927 -0.3028497   0.28718046 -0.19250531 -0.20963591\n",
      "  0.09422756 -0.44192409]\n",
      "Training Error:  10.557221270056395\n",
      "====================================================================================================\n",
      "Iteration:  612\n",
      "Previous theta :  [ 0.00652761 -0.07035831  0.102508    0.0103199   0.10069374 -0.21333778\n",
      "  0.28125179 -0.00183927 -0.3028497   0.28718046 -0.19250531 -0.20963591\n",
      "  0.09422756 -0.44192409]\n",
      "New theta_0 : [ 0.00652647 -0.07041768  0.1025636   0.01034571  0.10068412 -0.21347177\n",
      "  0.2811983  -0.00181751 -0.3029806   0.28737658 -0.19265477 -0.20967127\n",
      "  0.09421071 -0.44193402]\n",
      "Training Error:  10.557120880558854\n",
      "====================================================================================================\n",
      "Iteration:  613\n",
      "Previous theta :  [ 0.00652647 -0.07041768  0.1025636   0.01034571  0.10068412 -0.21347177\n",
      "  0.2811983  -0.00181751 -0.3029806   0.28737658 -0.19265477 -0.20967127\n",
      "  0.09421071 -0.44193402]\n",
      "New theta_0 : [ 0.00652534 -0.07047668  0.10261886  0.01037162  0.10067453 -0.21360487\n",
      "  0.28114516 -0.00179585 -0.30311051  0.28757202 -0.19280398 -0.20970642\n",
      "  0.09419398 -0.4419439 ]\n",
      "Training Error:  10.557021390253789\n",
      "====================================================================================================\n",
      "Iteration:  614\n",
      "Previous theta :  [ 0.00652534 -0.07047668  0.10261886  0.01037162  0.10067453 -0.21360487\n",
      "  0.28114516 -0.00179585 -0.30311051  0.28757202 -0.19280398 -0.20970642\n",
      "  0.09419398 -0.4419439 ]\n",
      "New theta_0 : [ 0.00652421 -0.07053532  0.10267378  0.01039762  0.10066497 -0.21373709\n",
      "  0.28109236 -0.0017743  -0.30323945  0.2877668  -0.19295293 -0.20974136\n",
      "  0.09417737 -0.44195372]\n",
      "Training Error:  10.55692278911838\n",
      "====================================================================================================\n",
      "Iteration:  615\n",
      "Previous theta :  [ 0.00652421 -0.07053532  0.10267378  0.01039762  0.10066497 -0.21373709\n",
      "  0.28109236 -0.0017743  -0.30323945  0.2877668  -0.19295293 -0.20974136\n",
      "  0.09417737 -0.44195372]\n",
      "New theta_0 : [ 0.00652309 -0.0705936   0.10272836  0.01042372  0.10065544 -0.21386843\n",
      "  0.2810399  -0.00175285 -0.30336742  0.28796092 -0.19310162 -0.20977609\n",
      "  0.09416088 -0.4419635 ]\n",
      "Training Error:  10.556825067258401\n",
      "====================================================================================================\n",
      "Iteration:  616\n",
      "Previous theta :  [ 0.00652309 -0.0705936   0.10272836  0.01042372  0.10065544 -0.21386843\n",
      "  0.2810399  -0.00175285 -0.30336742  0.28796092 -0.19310162 -0.20977609\n",
      "  0.09416088 -0.4419635 ]\n",
      "New theta_0 : [ 0.00652197 -0.07065152  0.1027826   0.01044991  0.10064594 -0.2139989\n",
      "  0.28098778 -0.0017315  -0.30349444  0.28815438 -0.19325005 -0.20981061\n",
      "  0.09414451 -0.44197321]\n",
      "Training Error:  10.556728214906457\n",
      "====================================================================================================\n",
      "Iteration:  617\n",
      "Previous theta :  [ 0.00652197 -0.07065152  0.1027826   0.01044991  0.10064594 -0.2139989\n",
      "  0.28098778 -0.0017315  -0.30349444  0.28815438 -0.19325005 -0.20981061\n",
      "  0.09414451 -0.44197321]\n",
      "New theta_0 : [ 0.00652086 -0.0707091   0.10283652  0.01047618  0.10063647 -0.2141285\n",
      "  0.280936   -0.00171026 -0.30362051  0.28834717 -0.19339823 -0.20984493\n",
      "  0.09412826 -0.44198288]\n",
      "Training Error:  10.556632222420228\n",
      "====================================================================================================\n",
      "Iteration:  618\n",
      "Previous theta :  [ 0.00652086 -0.0707091   0.10283652  0.01047618  0.10063647 -0.2141285\n",
      "  0.280936   -0.00171026 -0.30362051  0.28834717 -0.19339823 -0.20984493\n",
      "  0.09412826 -0.44198288]\n",
      "New theta_0 : [ 0.00651976 -0.07076632  0.1028901   0.01050254  0.10062703 -0.21425725\n",
      "  0.28088455 -0.00168912 -0.30374563  0.28853931 -0.19354615 -0.20987905\n",
      "  0.09411213 -0.44199249]\n",
      "Training Error:  10.556537080280751\n",
      "====================================================================================================\n",
      "Iteration:  619\n",
      "Previous theta :  [ 0.00651976 -0.07076632  0.1028901   0.01050254  0.10062703 -0.21425725\n",
      "  0.28088455 -0.00168912 -0.30374563  0.28853931 -0.19354615 -0.20987905\n",
      "  0.09411213 -0.44199249]\n",
      "New theta_0 : [ 0.00651866 -0.07082319  0.10294335  0.01052899  0.10061762 -0.21438514\n",
      "  0.28083344 -0.00166809 -0.30386981  0.2887308  -0.19369381 -0.20991296\n",
      "  0.09409611 -0.44200206]\n",
      "Training Error:  10.55644277909073\n",
      "====================================================================================================\n",
      "Iteration:  620\n",
      "Previous theta :  [ 0.00651866 -0.07082319  0.10294335  0.01052899  0.10061762 -0.21438514\n",
      "  0.28083344 -0.00166809 -0.30386981  0.2887308  -0.19369381 -0.20991296\n",
      "  0.09409611 -0.44200206]\n",
      "New theta_0 : [ 0.00651757 -0.07087971  0.10299628  0.01055553  0.10060823 -0.21451218\n",
      "  0.28078265 -0.00164715 -0.30399306  0.28892164 -0.19384121 -0.20994666\n",
      "  0.09408021 -0.44201157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.556349309572854\n",
      "====================================================================================================\n",
      "Iteration:  621\n",
      "Previous theta :  [ 0.00651757 -0.07087971  0.10299628  0.01055553  0.10060823 -0.21451218\n",
      "  0.28078265 -0.00164715 -0.30399306  0.28892164 -0.19384121 -0.20994666\n",
      "  0.09408021 -0.44201157]\n",
      "New theta_0 : [ 0.00651648 -0.0709359   0.10304888  0.01058214  0.10059888 -0.21463837\n",
      "  0.28073219 -0.00162632 -0.30411539  0.28911183 -0.19398835 -0.20998017\n",
      "  0.09406442 -0.44202104]\n",
      "Training Error:  10.556256662568153\n",
      "====================================================================================================\n",
      "Iteration:  622\n",
      "Previous theta :  [ 0.00651648 -0.0709359   0.10304888  0.01058214  0.10059888 -0.21463837\n",
      "  0.28073219 -0.00162632 -0.30411539  0.28911183 -0.19398835 -0.20998017\n",
      "  0.09406442 -0.44202104]\n",
      "New theta_0 : [ 0.0065154  -0.07099174  0.10310117  0.01060884  0.10058955 -0.21476374\n",
      "  0.28068205 -0.00160559 -0.30423681  0.28930138 -0.19413523 -0.21001348\n",
      "  0.09404875 -0.44203045]\n",
      "Training Error:  10.556164829034373\n",
      "====================================================================================================\n",
      "Iteration:  623\n",
      "Previous theta :  [ 0.0065154  -0.07099174  0.10310117  0.01060884  0.10058955 -0.21476374\n",
      "  0.28068205 -0.00160559 -0.30423681  0.28930138 -0.19413523 -0.21001348\n",
      "  0.09404875 -0.44203045]\n",
      "New theta_0 : [ 0.00651433 -0.07104724  0.10315313  0.01063561  0.10058025 -0.21488826\n",
      "  0.28063224 -0.00158495 -0.30435731  0.28949029 -0.19428186 -0.21004659\n",
      "  0.09403319 -0.44203982]\n",
      "Training Error:  10.556073800044373\n",
      "====================================================================================================\n",
      "Iteration:  624\n",
      "Previous theta :  [ 0.00651433 -0.07104724  0.10315313  0.01063561  0.10058025 -0.21488826\n",
      "  0.28063224 -0.00158495 -0.30435731  0.28949029 -0.19428186 -0.21004659\n",
      "  0.09403319 -0.44203982]\n",
      "New theta_0 : [ 0.00651326 -0.0711024   0.10320477  0.01066246  0.10057098 -0.21501197\n",
      "  0.28058274 -0.00156442 -0.30447691  0.28967855 -0.19442822 -0.2100795\n",
      "  0.09401775 -0.44204914]\n",
      "Training Error:  10.555983566784548\n",
      "====================================================================================================\n",
      "Iteration:  625\n",
      "Previous theta :  [ 0.00651326 -0.0711024   0.10320477  0.01066246  0.10057098 -0.21501197\n",
      "  0.28058274 -0.00156442 -0.30447691  0.28967855 -0.19442822 -0.2100795\n",
      "  0.09401775 -0.44204914]\n",
      "New theta_0 : [ 0.0065122  -0.07115723  0.1032561   0.01068939  0.10056173 -0.21513485\n",
      "  0.28053357 -0.00154398 -0.30459561  0.28986619 -0.19457432 -0.21011222\n",
      "  0.09400241 -0.44205841]\n",
      "Training Error:  10.555894120553264\n",
      "====================================================================================================\n",
      "Iteration:  626\n",
      "Previous theta :  [ 0.0065122  -0.07115723  0.1032561   0.01068939  0.10056173 -0.21513485\n",
      "  0.28053357 -0.00154398 -0.30459561  0.28986619 -0.19457432 -0.21011222\n",
      "  0.09400241 -0.44205841]\n",
      "New theta_0 : [ 0.00651114 -0.07121172  0.10330712  0.01071639  0.10055252 -0.21525691\n",
      "  0.2804847  -0.00152364 -0.30471343  0.29005319 -0.19472017 -0.21014475\n",
      "  0.09398719 -0.44206763]\n",
      "Training Error:  10.555805452759337\n",
      "====================================================================================================\n",
      "Iteration:  627\n",
      "Previous theta :  [ 0.00651114 -0.07121172  0.10330712  0.01071639  0.10055252 -0.21525691\n",
      "  0.2804847  -0.00152364 -0.30471343  0.29005319 -0.19472017 -0.21014475\n",
      "  0.09398719 -0.44206763]\n",
      "New theta_0 : [ 0.00651009 -0.07126589  0.10335782  0.01074347  0.10054333 -0.21537817\n",
      "  0.28043615 -0.0015034  -0.30483036  0.29023955 -0.19486575 -0.21017708\n",
      "  0.09397208 -0.44207681]\n",
      "Training Error:  10.555717554920504\n",
      "====================================================================================================\n",
      "Iteration:  628\n",
      "Previous theta :  [ 0.00651009 -0.07126589  0.10335782  0.01074347  0.10054333 -0.21537817\n",
      "  0.28043615 -0.0015034  -0.30483036  0.29023955 -0.19486575 -0.21017708\n",
      "  0.09397208 -0.44207681]\n",
      "New theta_0 : [ 0.00650905 -0.07131972  0.10340822  0.01077061  0.10053417 -0.21549862\n",
      "  0.2803879  -0.00148326 -0.30494641  0.29042529 -0.19501108 -0.21020921\n",
      "  0.09395708 -0.44208595]\n",
      "Training Error:  10.55563041866195\n",
      "====================================================================================================\n",
      "Iteration:  629\n",
      "Previous theta :  [ 0.00650905 -0.07131972  0.10340822  0.01077061  0.10053417 -0.21549862\n",
      "  0.2803879  -0.00148326 -0.30494641  0.29042529 -0.19501108 -0.21020921\n",
      "  0.09395708 -0.44208595]\n",
      "New theta_0 : [ 0.00650801 -0.07137324  0.10345831  0.01079782  0.10052503 -0.21561827\n",
      "  0.28033997 -0.00146321 -0.3050616   0.29061041 -0.19515614 -0.21024116\n",
      "  0.09394218 -0.44209504]\n",
      "Training Error:  10.555544035714815\n",
      "====================================================================================================\n",
      "Iteration:  630\n",
      "Previous theta :  [ 0.00650801 -0.07137324  0.10345831  0.01079782  0.10052503 -0.21561827\n",
      "  0.28033997 -0.00146321 -0.3050616   0.29061041 -0.19515614 -0.21024116\n",
      "  0.09394218 -0.44209504]\n",
      "New theta_0 : [ 0.00650697 -0.07142642  0.1035081   0.0108251   0.10051593 -0.21573713\n",
      "  0.28029234 -0.00144326 -0.30517592  0.2907949  -0.19530094 -0.21027292\n",
      "  0.09392739 -0.44210408]\n",
      "Training Error:  10.555458397914766\n",
      "====================================================================================================\n",
      "Iteration:  631\n",
      "Previous theta :  [ 0.00650697 -0.07142642  0.1035081   0.0108251   0.10051593 -0.21573713\n",
      "  0.28029234 -0.00144326 -0.30517592  0.2907949  -0.19530094 -0.21027292\n",
      "  0.09392739 -0.44210408]\n",
      "New theta_0 : [ 0.00650594 -0.07147929  0.10355758  0.01085245  0.10050685 -0.2158552\n",
      "  0.28024501 -0.0014234  -0.30528939  0.29097878 -0.19544549 -0.21030449\n",
      "  0.09391271 -0.44211308]\n",
      "Training Error:  10.555373497200558\n",
      "====================================================================================================\n",
      "Iteration:  632\n",
      "Previous theta :  [ 0.00650594 -0.07147929  0.10355758  0.01085245  0.10050685 -0.2158552\n",
      "  0.28024501 -0.0014234  -0.30528939  0.29097878 -0.19544549 -0.21030449\n",
      "  0.09391271 -0.44211308]\n",
      "New theta_0 : [ 0.00650492 -0.07153184  0.10360676  0.01087986  0.1004978  -0.21597248\n",
      "  0.28019798 -0.00140363 -0.305402    0.29116204 -0.19558977 -0.21033587\n",
      "  0.09389814 -0.44212204]\n",
      "Training Error:  10.555289325612623\n",
      "====================================================================================================\n",
      "Iteration:  633\n",
      "Previous theta :  [ 0.00650492 -0.07153184  0.10360676  0.01087986  0.1004978  -0.21597248\n",
      "  0.28019798 -0.00140363 -0.305402    0.29116204 -0.19558977 -0.21033587\n",
      "  0.09389814 -0.44212204]\n",
      "New theta_0 : [ 0.0065039  -0.07158406  0.10365565  0.01090734  0.10048878 -0.21608899\n",
      "  0.28015125 -0.00138397 -0.30551377  0.29134468 -0.19573379 -0.21036707\n",
      "  0.09388367 -0.44213095]\n",
      "Training Error:  10.55520587529169\n",
      "====================================================================================================\n",
      "Iteration:  634\n",
      "Previous theta :  [ 0.0065039  -0.07158406  0.10365565  0.01090734  0.10048878 -0.21608899\n",
      "  0.28015125 -0.00138397 -0.30551377  0.29134468 -0.19573379 -0.21036707\n",
      "  0.09388367 -0.44213095]\n",
      "New theta_0 : [ 0.00650289 -0.07163598  0.10370424  0.01093487  0.10047978 -0.21620472\n",
      "  0.28010482 -0.00136439 -0.3056247   0.29152671 -0.19587754 -0.21039808\n",
      "  0.0938693  -0.44213983]\n",
      "Training Error:  10.55512313847741\n",
      "====================================================================================================\n",
      "Iteration:  635\n",
      "Previous theta :  [ 0.00650289 -0.07163598  0.10370424  0.01093487  0.10047978 -0.21620472\n",
      "  0.28010482 -0.00136439 -0.3056247   0.29152671 -0.19587754 -0.21039808\n",
      "  0.0938693  -0.44213983]\n",
      "New theta_0 : [ 0.00650188 -0.07168758  0.10375253  0.01096247  0.10047081 -0.21631968\n",
      "  0.28005867 -0.00134491 -0.3057348   0.29170813 -0.19602104 -0.21042891\n",
      "  0.09385504 -0.44214866]\n",
      "Training Error:  10.555041107507002\n",
      "====================================================================================================\n",
      "Iteration:  636\n",
      "Previous theta :  [ 0.00650188 -0.07168758  0.10375253  0.01096247  0.10047081 -0.21631968\n",
      "  0.28005867 -0.00134491 -0.3057348   0.29170813 -0.19602104 -0.21042891\n",
      "  0.09385504 -0.44214866]\n",
      "New theta_0 : [ 0.00650088 -0.07173887  0.10380053  0.01099013  0.10046187 -0.21643388\n",
      "  0.28001282 -0.00132551 -0.30584408  0.29188895 -0.19616428 -0.21045956\n",
      "  0.09384088 -0.44215745]\n",
      "Training Error:  10.554959774813936\n",
      "====================================================================================================\n",
      "Iteration:  637\n",
      "Previous theta :  [ 0.00650088 -0.07173887  0.10380053  0.01099013  0.10046187 -0.21643388\n",
      "  0.28001282 -0.00132551 -0.30584408  0.29188895 -0.19616428 -0.21045956\n",
      "  0.09384088 -0.44215745]\n",
      "New theta_0 : [ 0.00649988 -0.07178985  0.10384824  0.01101784  0.10045295 -0.21654733\n",
      "  0.27996726 -0.00130621 -0.30595253  0.29206916 -0.19630725 -0.21049002\n",
      "  0.09382682 -0.44216619]\n",
      "Training Error:  10.554879132926612\n",
      "====================================================================================================\n",
      "Iteration:  638\n",
      "Previous theta :  [ 0.00649988 -0.07178985  0.10384824  0.01101784  0.10045295 -0.21654733\n",
      "  0.27996726 -0.00130621 -0.30595253  0.29206916 -0.19630725 -0.21049002\n",
      "  0.09382682 -0.44216619]\n",
      "New theta_0 : [ 0.00649889 -0.07184053  0.10389567  0.01104561  0.10044406 -0.21666002\n",
      "  0.27992199 -0.00128701 -0.30606018  0.29224877 -0.19644996 -0.21052031\n",
      "  0.09381286 -0.4421749 ]\n",
      "Training Error:  10.554799174467066\n",
      "====================================================================================================\n",
      "Iteration:  639\n",
      "Previous theta :  [ 0.00649889 -0.07184053  0.10389567  0.01104561  0.10044406 -0.21666002\n",
      "  0.27992199 -0.00128701 -0.30606018  0.29224877 -0.19644996 -0.21052031\n",
      "  0.09381286 -0.4421749 ]\n",
      "New theta_0 : [ 0.00649791 -0.0718909   0.1039428   0.01107343  0.1004352  -0.21677196\n",
      "  0.279877   -0.00126789 -0.30616701  0.29242778 -0.19659241 -0.21055041\n",
      "  0.09379901 -0.44218357]\n",
      "Training Error:  10.5547198921497\n",
      "====================================================================================================\n",
      "Iteration:  640\n",
      "Previous theta :  [ 0.00649791 -0.0718909   0.1039428   0.01107343  0.1004352  -0.21677196\n",
      "  0.279877   -0.00126789 -0.30616701  0.29242778 -0.19659241 -0.21055041\n",
      "  0.09379901 -0.44218357]\n",
      "New theta_0 : [ 0.00649693 -0.07194097  0.10398966  0.01110131  0.10042636 -0.21688315\n",
      "  0.27983229 -0.00124886 -0.30627304  0.2926062  -0.1967346  -0.21058034\n",
      "  0.09378525 -0.4421922 ]\n",
      "Training Error:  10.554641278780027\n",
      "====================================================================================================\n",
      "Iteration:  641\n",
      "Previous theta :  [ 0.00649693 -0.07194097  0.10398966  0.01110131  0.10042636 -0.21688315\n",
      "  0.27983229 -0.00124886 -0.30627304  0.2926062  -0.1967346  -0.21058034\n",
      "  0.09378525 -0.4421922 ]\n",
      "New theta_0 : [ 0.00649595 -0.07199074  0.10403623  0.01112923  0.10041755 -0.21699361\n",
      "  0.27978786 -0.00122992 -0.30637828  0.29278402 -0.19687652 -0.21061009\n",
      "  0.0937716  -0.44220079]\n",
      "Training Error:  10.554563327253424\n",
      "====================================================================================================\n",
      "Iteration:  642\n",
      "Previous theta :  [ 0.00649595 -0.07199074  0.10403623  0.01112923  0.10041755 -0.21699361\n",
      "  0.27978786 -0.00122992 -0.30637828  0.29278402 -0.19687652 -0.21061009\n",
      "  0.0937716  -0.44220079]\n",
      "New theta_0 : [ 0.00649498 -0.07204021  0.10408252  0.01115721  0.10040876 -0.21710334\n",
      "  0.27974372 -0.00121107 -0.30648273  0.29296125 -0.19701818 -0.21063967\n",
      "  0.09375804 -0.44220934]\n",
      "Training Error:  10.554486030553921\n",
      "====================================================================================================\n",
      "Iteration:  643\n",
      "Previous theta :  [ 0.00649498 -0.07204021  0.10408252  0.01115721  0.10040876 -0.21710334\n",
      "  0.27974372 -0.00121107 -0.30648273  0.29296125 -0.19701818 -0.21063967\n",
      "  0.09375804 -0.44220934]\n",
      "New theta_0 : [ 0.00649402 -0.07208938  0.10412853  0.01118524  0.10040001 -0.21721234\n",
      "  0.27969984 -0.00119231 -0.30658639  0.2931379  -0.19715958 -0.21066907\n",
      "  0.09374457 -0.44221786]\n",
      "Training Error:  10.554409381752984\n",
      "====================================================================================================\n",
      "Iteration:  644\n",
      "Previous theta :  [ 0.00649402 -0.07208938  0.10412853  0.01118524  0.10040001 -0.21721234\n",
      "  0.27969984 -0.00119231 -0.30658639  0.2931379  -0.19715958 -0.21066907\n",
      "  0.09374457 -0.44221786]\n",
      "New theta_0 : [ 0.00649306 -0.07213826  0.10417427  0.01121331  0.10039127 -0.21732061\n",
      "  0.27965624 -0.00117363 -0.30668928  0.29331395 -0.19730072 -0.2106983\n",
      "  0.09373121 -0.44222633]\n",
      "Training Error:  10.554333374008346\n",
      "====================================================================================================\n",
      "Iteration:  645\n",
      "Previous theta :  [ 0.00649306 -0.07213826  0.10417427  0.01121331  0.10039127 -0.21732061\n",
      "  0.27965624 -0.00117363 -0.30668928  0.29331395 -0.19730072 -0.2106983\n",
      "  0.09373121 -0.44222633]\n",
      "New theta_0 : [ 0.0064921  -0.07218684  0.10421973  0.01124143  0.10038257 -0.21742817\n",
      "  0.27961292 -0.00115505 -0.30679139  0.29348943 -0.1974416  -0.21072736\n",
      "  0.09371794 -0.44223477]\n",
      "Training Error:  10.554258000562818\n",
      "====================================================================================================\n",
      "Iteration:  646\n",
      "Previous theta :  [ 0.0064921  -0.07218684  0.10421973  0.01124143  0.10038257 -0.21742817\n",
      "  0.27961292 -0.00115505 -0.30679139  0.29348943 -0.1974416  -0.21072736\n",
      "  0.09371794 -0.44223477]\n",
      "New theta_0 : [ 0.00649115 -0.07223514  0.10426491  0.0112696   0.10037389 -0.21753501\n",
      "  0.27956986 -0.00113655 -0.30689274  0.29366432 -0.19758221 -0.21075624\n",
      "  0.09370477 -0.44224318]\n",
      "Training Error:  10.55418325474315\n",
      "====================================================================================================\n",
      "Iteration:  647\n",
      "Previous theta :  [ 0.00649115 -0.07223514  0.10426491  0.0112696   0.10037389 -0.21753501\n",
      "  0.27956986 -0.00113655 -0.30689274  0.29366432 -0.19758221 -0.21075624\n",
      "  0.09370477 -0.44224318]\n",
      "New theta_0 : [ 0.00649021 -0.07228315  0.10430983  0.01129781  0.10036523 -0.21764114\n",
      "  0.27952707 -0.00111813 -0.30699333  0.29383863 -0.19772256 -0.21078496\n",
      "  0.09369169 -0.44225154]\n",
      "Training Error:  10.554109129958883\n",
      "====================================================================================================\n",
      "Iteration:  648\n",
      "Previous theta :  [ 0.00649021 -0.07228315  0.10430983  0.01129781  0.10036523 -0.21764114\n",
      "  0.27952707 -0.00111813 -0.30699333  0.29383863 -0.19772256 -0.21078496\n",
      "  0.09369169 -0.44225154]\n",
      "New theta_0 : [ 0.00648927 -0.07233087  0.10435448  0.01132606  0.1003566  -0.21774656\n",
      "  0.27948455 -0.00109981 -0.30709316  0.29401237 -0.19786265 -0.2108135\n",
      "  0.0936787  -0.44225987]\n",
      "Training Error:  10.554035619701235\n",
      "====================================================================================================\n",
      "Iteration:  649\n",
      "Previous theta :  [ 0.00648927 -0.07233087  0.10435448  0.01132606  0.1003566  -0.21774656\n",
      "  0.27948455 -0.00109981 -0.30709316  0.29401237 -0.19786265 -0.2108135\n",
      "  0.0936787  -0.44225987]\n",
      "New theta_0 : [ 0.00648834 -0.07237831  0.10439886  0.01135436  0.100348   -0.21785129\n",
      "  0.27944229 -0.00108156 -0.30719225  0.29418553 -0.19800247 -0.21084188\n",
      "  0.09366581 -0.44226817]\n",
      "Training Error:  10.553962717541994\n",
      "====================================================================================================\n",
      "Iteration:  650\n",
      "Previous theta :  [ 0.00648834 -0.07237831  0.10439886  0.01135436  0.100348   -0.21785129\n",
      "  0.27944229 -0.00108156 -0.30719225  0.29418553 -0.19800247 -0.21084188\n",
      "  0.09366581 -0.44226817]\n",
      "New theta_0 : [ 0.00648741 -0.07242546  0.10444297  0.01138269  0.10033942 -0.21795532\n",
      "  0.2794003  -0.0010634  -0.30729059  0.29435812 -0.19814203 -0.21087009\n",
      "  0.09365301 -0.44227643]\n",
      "Training Error:  10.553890417132424\n",
      "====================================================================================================\n",
      "Iteration:  651\n",
      "Previous theta :  [ 0.00648741 -0.07242546  0.10444297  0.01138269  0.10033942 -0.21795532\n",
      "  0.2794003  -0.0010634  -0.30729059  0.29435812 -0.19814203 -0.21087009\n",
      "  0.09365301 -0.44227643]\n",
      "New theta_0 : [ 0.00648648 -0.07247233  0.10448682  0.01141106  0.10033087 -0.21805866\n",
      "  0.27935856 -0.00104533 -0.30738819  0.29453014 -0.19828133 -0.21089813\n",
      "  0.0936403  -0.44228465]\n",
      "Training Error:  10.553818712202194\n",
      "====================================================================================================\n",
      "Iteration:  652\n",
      "Previous theta :  [ 0.00648648 -0.07247233  0.10448682  0.01141106  0.10033087 -0.21805866\n",
      "  0.27935856 -0.00104533 -0.30738819  0.29453014 -0.19828133 -0.21089813\n",
      "  0.0936403  -0.44228465]\n",
      "New theta_0 : [ 0.00648556 -0.07251893  0.10453041  0.01143947  0.10032234 -0.21816131\n",
      "  0.27931708 -0.00102734 -0.30748506  0.2947016  -0.19842036 -0.21092601\n",
      "  0.09362769 -0.44229285]\n",
      "Training Error:  10.55374759655832\n",
      "====================================================================================================\n",
      "Iteration:  653\n",
      "Previous theta :  [ 0.00648556 -0.07251893  0.10453041  0.01143947  0.10032234 -0.21816131\n",
      "  0.27931708 -0.00102734 -0.30748506  0.2947016  -0.19842036 -0.21092601\n",
      "  0.09362769 -0.44229285]\n",
      "New theta_0 : [ 0.00648465 -0.07256524  0.10457374  0.01146792  0.10031384 -0.21826328\n",
      "  0.27927586 -0.00100943 -0.3075812   0.29487249 -0.19855914 -0.21095373\n",
      "  0.09361516 -0.44230101]\n",
      "Training Error:  10.553677064084118\n",
      "====================================================================================================\n",
      "Iteration:  654\n",
      "Previous theta :  [ 0.00648465 -0.07256524  0.10457374  0.01146792  0.10031384 -0.21826328\n",
      "  0.27927586 -0.00100943 -0.3075812   0.29487249 -0.19855914 -0.21095373\n",
      "  0.09361516 -0.44230101]\n",
      "New theta_0 : [ 0.00648374 -0.07261128  0.10461681  0.0114964   0.10030536 -0.21836458\n",
      "  0.27923489 -0.00099161 -0.30767662  0.29504282 -0.19869765 -0.21098128\n",
      "  0.09360272 -0.44230913]\n",
      "Training Error:  10.553607108738177\n",
      "====================================================================================================\n",
      "Iteration:  655\n",
      "Previous theta :  [ 0.00648374 -0.07261128  0.10461681  0.0114964   0.10030536 -0.21836458\n",
      "  0.27923489 -0.00099161 -0.30767662  0.29504282 -0.19869765 -0.21098128\n",
      "  0.09360272 -0.44230913]\n",
      "New theta_0 : [ 0.00648284 -0.07265705  0.10465963  0.01152492  0.10029691 -0.2184652\n",
      "  0.27919418 -0.00097387 -0.30777132  0.29521259 -0.19883589 -0.21100868\n",
      "  0.09359038 -0.44231722]\n",
      "Training Error:  10.553537724553337\n",
      "====================================================================================================\n",
      "Iteration:  656\n",
      "Previous theta :  [ 0.00648284 -0.07265705  0.10465963  0.01152492  0.10029691 -0.2184652\n",
      "  0.27919418 -0.00097387 -0.30777132  0.29521259 -0.19883589 -0.21100868\n",
      "  0.09359038 -0.44231722]\n",
      "New theta_0 : [ 0.00648194 -0.07270255  0.10470219  0.01155346  0.10028848 -0.21856515\n",
      "  0.27915371 -0.00095621 -0.30786531  0.2953818  -0.19897387 -0.21103591\n",
      "  0.09357812 -0.44232528]\n",
      "Training Error:  10.553468905635699\n",
      "====================================================================================================\n",
      "Iteration:  657\n",
      "Previous theta :  [ 0.00648194 -0.07270255  0.10470219  0.01155346  0.10028848 -0.21856515\n",
      "  0.27915371 -0.00095621 -0.30786531  0.2953818  -0.19897387 -0.21103591\n",
      "  0.09357812 -0.44232528]\n",
      "New theta_0 : [ 0.00648104 -0.07274778  0.10474449  0.01158204  0.10028007 -0.21866444\n",
      "  0.2791135  -0.00093863 -0.3079586   0.29555045 -0.19911159 -0.21106298\n",
      "  0.09356595 -0.44233331]\n",
      "Training Error:  10.553400646163627\n",
      "====================================================================================================\n",
      "Iteration:  658\n",
      "Previous theta :  [ 0.00648104 -0.07274778  0.10474449  0.01158204  0.10028007 -0.21866444\n",
      "  0.2791135  -0.00093863 -0.3079586   0.29555045 -0.19911159 -0.21106298\n",
      "  0.09356595 -0.44233331]\n",
      "New theta_0 : [ 0.00648015 -0.07279274  0.10478655  0.01161066  0.1002717  -0.21876307\n",
      "  0.27907353 -0.00092113 -0.30805119  0.29571856 -0.19924905 -0.21108989\n",
      "  0.09355386 -0.4423413 ]\n",
      "Training Error:  10.553332940386786\n",
      "====================================================================================================\n",
      "Iteration:  659\n",
      "Previous theta :  [ 0.00648015 -0.07279274  0.10478655  0.01161066  0.1002717  -0.21876307\n",
      "  0.27907353 -0.00092113 -0.30805119  0.29571856 -0.19924905 -0.21108989\n",
      "  0.09355386 -0.4423413 ]\n",
      "New theta_0 : [ 0.00647927 -0.07283743  0.10482836  0.0116393   0.10026334 -0.21886105\n",
      "  0.27903381 -0.00090371 -0.30814308  0.29588611 -0.19938624 -0.21111664\n",
      "  0.09354186 -0.44234927]\n",
      "Training Error:  10.553265782625173\n",
      "====================================================================================================\n",
      "Iteration:  660\n",
      "Previous theta :  [ 0.00647927 -0.07283743  0.10482836  0.0116393   0.10026334 -0.21886105\n",
      "  0.27903381 -0.00090371 -0.30814308  0.29588611 -0.19938624 -0.21111664\n",
      "  0.09354186 -0.44234927]\n",
      "New theta_0 : [ 0.00647839 -0.07288186  0.10486991  0.01166797  0.10025501 -0.21895837\n",
      "  0.27899433 -0.00088637 -0.30823427  0.29605311 -0.19952317 -0.21114324\n",
      "  0.09352995 -0.4423572 ]\n",
      "Training Error:  10.553199167268177\n",
      "====================================================================================================\n",
      "Iteration:  661\n",
      "Previous theta :  [ 0.00647839 -0.07288186  0.10486991  0.01166797  0.10025501 -0.21895837\n",
      "  0.27899433 -0.00088637 -0.30823427  0.29605311 -0.19952317 -0.21114324\n",
      "  0.09352995 -0.4423572 ]\n",
      "New theta_0 : [ 0.00647751 -0.07292602  0.10491123  0.01169666  0.10024671 -0.21905505\n",
      "  0.27895509 -0.00086911 -0.30832479  0.29621957 -0.19965984 -0.21116969\n",
      "  0.09351812 -0.4423651 ]\n",
      "Training Error:  10.553133088773645\n",
      "====================================================================================================\n",
      "Iteration:  662\n",
      "Previous theta :  [ 0.00647751 -0.07292602  0.10491123  0.01169666  0.10024671 -0.21905505\n",
      "  0.27895509 -0.00086911 -0.30832479  0.29621957 -0.19965984 -0.21116969\n",
      "  0.09351812 -0.4423651 ]\n",
      "New theta_0 : [ 0.00647664 -0.07296993  0.10495229  0.01172538  0.10023843 -0.21915108\n",
      "  0.27891609 -0.00085193 -0.30841462  0.29638549 -0.19979625 -0.21119597\n",
      "  0.09350638 -0.44237297]\n",
      "Training Error:  10.553067541666966\n",
      "====================================================================================================\n",
      "Iteration:  663\n",
      "Previous theta :  [ 0.00647664 -0.07296993  0.10495229  0.01172538  0.10023843 -0.21915108\n",
      "  0.27891609 -0.00085193 -0.30841462  0.29638549 -0.19979625 -0.21119597\n",
      "  0.09350638 -0.44237297]\n",
      "New theta_0 : [ 0.00647577 -0.07301358  0.10499312  0.01175413  0.10023017 -0.21924648\n",
      "  0.27887732 -0.00083483 -0.30850378  0.29655086 -0.19993239 -0.21122211\n",
      "  0.09349472 -0.44238081]\n",
      "Training Error:  10.553002520540156\n",
      "====================================================================================================\n",
      "Iteration:  664\n",
      "Previous theta :  [ 0.00647577 -0.07301358  0.10499312  0.01175413  0.10023017 -0.21924648\n",
      "  0.27887732 -0.00083483 -0.30850378  0.29655086 -0.19993239 -0.21122211\n",
      "  0.09349472 -0.44238081]\n",
      "New theta_0 : [ 0.00647491 -0.07305697  0.1050337   0.0117829   0.10022194 -0.21934124\n",
      "  0.2788388  -0.00081781 -0.30859227  0.2967157  -0.20006826 -0.21124809\n",
      "  0.09348315 -0.44238863]\n",
      "Training Error:  10.552938020050972\n",
      "====================================================================================================\n",
      "Iteration:  665\n",
      "Previous theta :  [ 0.00647491 -0.07305697  0.1050337   0.0117829   0.10022194 -0.21934124\n",
      "  0.2788388  -0.00081781 -0.30859227  0.2967157  -0.20006826 -0.21124809\n",
      "  0.09348315 -0.44238863]\n",
      "New theta_0 : [ 0.00647406 -0.0731001   0.10507404  0.0118117   0.10021373 -0.21943538\n",
      "  0.27880051 -0.00080086 -0.3086801   0.29687999 -0.20020388 -0.21127392\n",
      "  0.09347165 -0.44239641]\n",
      "Training Error:  10.552874034922032\n",
      "====================================================================================================\n",
      "Iteration:  666\n",
      "Previous theta :  [ 0.00647406 -0.0731001   0.10507404  0.0118117   0.10021373 -0.21943538\n",
      "  0.27880051 -0.00080086 -0.3086801   0.29687999 -0.20020388 -0.21127392\n",
      "  0.09347165 -0.44239641]\n",
      "New theta_0 : [ 0.0064732  -0.07314298  0.10511415  0.01184051  0.10020554 -0.21952888\n",
      "  0.27876245 -0.00078399 -0.30876726  0.29704376 -0.20033923 -0.21129959\n",
      "  0.09346024 -0.44240416]\n",
      "Training Error:  10.55281055993994\n",
      "====================================================================================================\n",
      "Iteration:  667\n",
      "Previous theta :  [ 0.0064732  -0.07314298  0.10511415  0.01184051  0.10020554 -0.21952888\n",
      "  0.27876245 -0.00078399 -0.30876726  0.29704376 -0.20033923 -0.21129959\n",
      "  0.09346024 -0.44240416]\n",
      "New theta_0 : [ 0.00647236 -0.07318561  0.10515402  0.01186935  0.10019738 -0.21962177\n",
      "  0.27872462 -0.0007672  -0.30885377  0.29720699 -0.20047432 -0.21132512\n",
      "  0.09344891 -0.44241188]\n",
      "Training Error:  10.552747589954436\n",
      "====================================================================================================\n",
      "Iteration:  668\n",
      "Previous theta :  [ 0.00647236 -0.07318561  0.10515402  0.01186935  0.10019738 -0.21962177\n",
      "  0.27872462 -0.0007672  -0.30885377  0.29720699 -0.20047432 -0.21132512\n",
      "  0.09344891 -0.44241188]\n",
      "New theta_0 : [ 0.00647151 -0.07322798  0.10519365  0.01189821  0.10018925 -0.21971404\n",
      "  0.27868702 -0.00075048 -0.30893963  0.29736969 -0.20060915 -0.2113505\n",
      "  0.09343766 -0.44241958]\n",
      "Training Error:  10.55268511987754\n",
      "====================================================================================================\n",
      "Iteration:  669\n",
      "Previous theta :  [ 0.00647151 -0.07322798  0.10519365  0.01189821  0.10018925 -0.21971404\n",
      "  0.27868702 -0.00075048 -0.30893963  0.29736969 -0.20060915 -0.2113505\n",
      "  0.09343766 -0.44241958]\n",
      "New theta_0 : [ 0.00647067 -0.07327011  0.10523305  0.01192709  0.10018113 -0.2198057\n",
      "  0.27864965 -0.00073384 -0.30902484  0.29753186 -0.20074371 -0.21137573\n",
      "  0.09342649 -0.44242725]\n",
      "Training Error:  10.55262314468274\n",
      "====================================================================================================\n",
      "Iteration:  670\n",
      "Previous theta :  [ 0.00647067 -0.07327011  0.10523305  0.01192709  0.10018113 -0.2198057\n",
      "  0.27864965 -0.00073384 -0.30902484  0.29753186 -0.20074371 -0.21137573\n",
      "  0.09342649 -0.44242725]\n",
      "New theta_0 : [ 0.00646984 -0.07331199  0.10527222  0.01195598  0.10017304 -0.21989675\n",
      "  0.2786125  -0.00071727 -0.30910941  0.2976935  -0.20087801 -0.21140081\n",
      "  0.0934154  -0.44243489]\n",
      "Training Error:  10.552561659404146\n",
      "====================================================================================================\n",
      "Iteration:  671\n",
      "Previous theta :  [ 0.00646984 -0.07331199  0.10527222  0.01195598  0.10017304 -0.21989675\n",
      "  0.2786125  -0.00071727 -0.30910941  0.2976935  -0.20087801 -0.21140081\n",
      "  0.0934154  -0.44243489]\n",
      "New theta_0 : [ 0.00646901 -0.07335363  0.10531116  0.01198489  0.10016498 -0.21998719\n",
      "  0.27857558 -0.00070078 -0.30919335  0.29785462 -0.20101204 -0.21142575\n",
      "  0.09340439 -0.4424425 ]\n",
      "Training Error:  10.552500659135703\n",
      "====================================================================================================\n",
      "Iteration:  672\n",
      "Previous theta :  [ 0.00646901 -0.07335363  0.10531116  0.01198489  0.10016498 -0.21998719\n",
      "  0.27857558 -0.00070078 -0.30919335  0.29785462 -0.20101204 -0.21142575\n",
      "  0.09340439 -0.4424425 ]\n",
      "New theta_0 : [ 0.00646819 -0.07339502  0.10534987  0.01201382  0.10015693 -0.22007703\n",
      "  0.27853888 -0.00068436 -0.30927665  0.29801522 -0.20114582 -0.21145054\n",
      "  0.09339346 -0.44245008]\n",
      "Training Error:  10.552440139030377\n",
      "====================================================================================================\n",
      "Iteration:  673\n",
      "Previous theta :  [ 0.00646819 -0.07339502  0.10534987  0.01201382  0.10015693 -0.22007703\n",
      "  0.27853888 -0.00068436 -0.30927665  0.29801522 -0.20114582 -0.21145054\n",
      "  0.09339346 -0.44245008]\n",
      "New theta_0 : [ 0.00646736 -0.07343617  0.10538836  0.01204277  0.10014891 -0.22016628\n",
      "  0.27850241 -0.00066802 -0.30935933  0.2981753  -0.20127933 -0.21147519\n",
      "  0.09338261 -0.44245764]\n",
      "Training Error:  10.552380094299377\n",
      "====================================================================================================\n",
      "Iteration:  674\n",
      "Previous theta :  [ 0.00646736 -0.07343617  0.10538836  0.01204277  0.10014891 -0.22016628\n",
      "  0.27850241 -0.00066802 -0.30935933  0.2981753  -0.20127933 -0.21147519\n",
      "  0.09338261 -0.44245764]\n",
      "New theta_0 : [ 0.00646655 -0.07347708  0.10542662  0.01207172  0.10014092 -0.22025493\n",
      "  0.27846615 -0.00065175 -0.30944139  0.29833486 -0.20141258 -0.2114997\n",
      "  0.09337183 -0.44246517]\n",
      "Training Error:  10.552320520211374\n",
      "====================================================================================================\n",
      "Iteration:  675\n",
      "Previous theta :  [ 0.00646655 -0.07347708  0.10542662  0.01207172  0.10014092 -0.22025493\n",
      "  0.27846615 -0.00065175 -0.30944139  0.29833486 -0.20141258 -0.2114997\n",
      "  0.09337183 -0.44246517]\n",
      "New theta_0 : [ 0.00646574 -0.07351775  0.10546465  0.01210069  0.10013294 -0.220343\n",
      "  0.27843011 -0.00063555 -0.30952282  0.29849391 -0.20154557 -0.21152406\n",
      "  0.09336113 -0.44247268]\n",
      "Training Error:  10.55226141209174\n",
      "====================================================================================================\n",
      "Iteration:  676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous theta :  [ 0.00646574 -0.07351775  0.10546465  0.01210069  0.10013294 -0.220343\n",
      "  0.27843011 -0.00063555 -0.30952282  0.29849391 -0.20154557 -0.21152406\n",
      "  0.09336113 -0.44247268]\n",
      "New theta_0 : [ 0.00646493 -0.07355818  0.10550247  0.01212968  0.10012499 -0.22043047\n",
      "  0.27839428 -0.00061942 -0.30960365  0.29865244 -0.20167829 -0.21154828\n",
      "  0.0933505  -0.44248016]\n",
      "Training Error:  10.55220276532179\n",
      "====================================================================================================\n",
      "Iteration:  677\n",
      "Previous theta :  [ 0.00646493 -0.07355818  0.10550247  0.01212968  0.10012499 -0.22043047\n",
      "  0.27839428 -0.00061942 -0.30960365  0.29865244 -0.20167829 -0.21154828\n",
      "  0.0933505  -0.44248016]\n",
      "New theta_0 : [ 0.00646412 -0.07359838  0.10554006  0.01215867  0.10011706 -0.22051737\n",
      "  0.27835867 -0.00060337 -0.30968387  0.29881046 -0.20181075 -0.21157235\n",
      "  0.09333996 -0.44248761]\n",
      "Training Error:  10.55214457533804\n",
      "====================================================================================================\n",
      "Iteration:  678\n",
      "Previous theta :  [ 0.00646412 -0.07359838  0.10554006  0.01215867  0.10011706 -0.22051737\n",
      "  0.27835867 -0.00060337 -0.30968387  0.29881046 -0.20181075 -0.21157235\n",
      "  0.09333996 -0.44248761]\n",
      "New theta_0 : [ 0.00646333 -0.07363834  0.10557743  0.01218768  0.10010916 -0.22060369\n",
      "  0.27832327 -0.00058739 -0.30976348  0.29896797 -0.20194295 -0.21159629\n",
      "  0.09332948 -0.44249504]\n",
      "Training Error:  10.552086837631474\n",
      "====================================================================================================\n",
      "Iteration:  679\n",
      "Previous theta :  [ 0.00646333 -0.07363834  0.10557743  0.01218768  0.10010916 -0.22060369\n",
      "  0.27832327 -0.00058739 -0.30976348  0.29896797 -0.20194295 -0.21159629\n",
      "  0.09332948 -0.44249504]\n",
      "New theta_0 : [ 0.00646253 -0.07367807  0.10561459  0.01221669  0.10010128 -0.22068944\n",
      "  0.27828809 -0.00057148 -0.3098425   0.29912498 -0.20207489 -0.21162009\n",
      "  0.09331908 -0.44250244]\n",
      "Training Error:  10.552029547746825\n",
      "====================================================================================================\n",
      "Iteration:  680\n",
      "Previous theta :  [ 0.00646253 -0.07367807  0.10561459  0.01221669  0.10010128 -0.22068944\n",
      "  0.27828809 -0.00057148 -0.3098425   0.29912498 -0.20207489 -0.21162009\n",
      "  0.09331908 -0.44250244]\n",
      "New theta_0 : [ 0.00646174 -0.07371757  0.10565152  0.01224572  0.10009342 -0.22077462\n",
      "  0.27825311 -0.00055564 -0.30992092  0.29928148 -0.20220656 -0.21164375\n",
      "  0.09330876 -0.44250982]\n",
      "Training Error:  10.551972701281846\n",
      "====================================================================================================\n",
      "Iteration:  681\n",
      "Previous theta :  [ 0.00646174 -0.07371757  0.10565152  0.01224572  0.10009342 -0.22077462\n",
      "  0.27825311 -0.00055564 -0.30992092  0.29928148 -0.20220656 -0.21164375\n",
      "  0.09330876 -0.44250982]\n",
      "New theta_0 : [ 0.00646095 -0.07375684  0.10568825  0.01227475  0.10008558 -0.22085923\n",
      "  0.27821835 -0.00053987 -0.30999875  0.29943747 -0.20233797 -0.21166728\n",
      "  0.0932985  -0.44251717]\n",
      "Training Error:  10.551916293886626\n",
      "====================================================================================================\n",
      "Iteration:  682\n",
      "Previous theta :  [ 0.00646095 -0.07375684  0.10568825  0.01227475  0.10008558 -0.22085923\n",
      "  0.27821835 -0.00053987 -0.30999875  0.29943747 -0.20233797 -0.21166728\n",
      "  0.0932985  -0.44251717]\n",
      "New theta_0 : [ 0.00646017 -0.07379588  0.10572476  0.01230379  0.10007777 -0.22094328\n",
      "  0.27818378 -0.00052418 -0.31007599  0.29959297 -0.20246912 -0.21169067\n",
      "  0.09328832 -0.4425245 ]\n",
      "Training Error:  10.551860321262893\n",
      "====================================================================================================\n",
      "Iteration:  683\n",
      "Previous theta :  [ 0.00646017 -0.07379588  0.10572476  0.01230379  0.10007777 -0.22094328\n",
      "  0.27818378 -0.00052418 -0.31007599  0.29959297 -0.20246912 -0.21169067\n",
      "  0.09328832 -0.4425245 ]\n",
      "New theta_0 : [ 0.00645939 -0.0738347   0.10576106  0.01233283  0.10006998 -0.22102677\n",
      "  0.27814943 -0.00050855 -0.31015266  0.29974796 -0.20260001 -0.21171392\n",
      "  0.09327822 -0.4425318 ]\n",
      "Training Error:  10.551804779163314\n",
      "====================================================================================================\n",
      "Iteration:  684\n",
      "Previous theta :  [ 0.00645939 -0.0738347   0.10576106  0.01233283  0.10006998 -0.22102677\n",
      "  0.27814943 -0.00050855 -0.31015266  0.29974796 -0.20260001 -0.21171392\n",
      "  0.09327822 -0.4425318 ]\n",
      "New theta_0 : [ 0.00645862 -0.07387329  0.10579715  0.01236189  0.10006221 -0.22110971\n",
      "  0.27811528 -0.00049299 -0.31022874  0.29990246 -0.20273064 -0.21173703\n",
      "  0.09326818 -0.44253908]\n",
      "Training Error:  10.551749663390844\n",
      "====================================================================================================\n",
      "Iteration:  685\n",
      "Previous theta :  [ 0.00645862 -0.07387329  0.10579715  0.01236189  0.10006221 -0.22110971\n",
      "  0.27811528 -0.00049299 -0.31022874  0.29990246 -0.20273064 -0.21173703\n",
      "  0.09326818 -0.44253908]\n",
      "New theta_0 : [ 0.00645785 -0.07391165  0.10583302  0.01239094  0.10005446 -0.22119209\n",
      "  0.27808133 -0.0004775  -0.31030426  0.30005646 -0.202861   -0.21176002\n",
      "  0.09325821 -0.44254633]\n",
      "Training Error:  10.551694969798048\n",
      "====================================================================================================\n",
      "Iteration:  686\n",
      "Previous theta :  [ 0.00645785 -0.07391165  0.10583302  0.01239094  0.10005446 -0.22119209\n",
      "  0.27808133 -0.0004775  -0.31030426  0.30005646 -0.202861   -0.21176002\n",
      "  0.09325821 -0.44254633]\n",
      "New theta_0 : [ 0.00645709 -0.0739498   0.1058687   0.01242     0.10004674 -0.22127393\n",
      "  0.27804758 -0.00046207 -0.3103792   0.30020997 -0.20299111 -0.21178287\n",
      "  0.09324832 -0.44255357]\n",
      "Training Error:  10.551640694286442\n",
      "====================================================================================================\n",
      "Iteration:  687\n",
      "Previous theta :  [ 0.00645709 -0.0739498   0.1058687   0.01242     0.10004674 -0.22127393\n",
      "  0.27804758 -0.00046207 -0.3103792   0.30020997 -0.20299111 -0.21178287\n",
      "  0.09324832 -0.44255357]\n",
      "New theta_0 : [ 0.00645632 -0.07398772  0.10590416  0.01244906  0.10003904 -0.22135522\n",
      "  0.27801403 -0.00044672 -0.31045358  0.30036299 -0.20312095 -0.21180558\n",
      "  0.0932385  -0.44256078]\n",
      "Training Error:  10.551586832805864\n",
      "====================================================================================================\n",
      "Iteration:  688\n",
      "Previous theta :  [ 0.00645632 -0.07398772  0.10590416  0.01244906  0.10003904 -0.22135522\n",
      "  0.27801403 -0.00044672 -0.31045358  0.30036299 -0.20312095 -0.21180558\n",
      "  0.0932385  -0.44256078]\n",
      "New theta_0 : [ 6.45556782e-03 -7.40254245e-02  1.05939420e-01  1.24781283e-02\n",
      "  1.00031358e-01 -2.21435978e-01  2.77980680e-01 -4.31432973e-04\n",
      " -3.10527398e-01  3.00515521e-01 -2.03250530e-01 -2.11828169e-01\n",
      "  9.32287401e-02 -4.42567961e-01]\n",
      "Training Error:  10.551533381353815\n",
      "====================================================================================================\n",
      "Iteration:  689\n",
      "Previous theta :  [ 6.45556782e-03 -7.40254245e-02  1.05939420e-01  1.24781283e-02\n",
      "  1.00031358e-01 -2.21435978e-01  2.77980680e-01 -4.31432973e-04\n",
      " -3.10527398e-01  3.00515521e-01 -2.03250530e-01 -2.11828169e-01\n",
      "  9.32287401e-02 -4.42567961e-01]\n",
      "New theta_0 : [ 6.45481473e-03 -7.40629109e-02  1.05974476e-01  1.25071945e-02\n",
      "  1.00023700e-01 -2.21516196e-01  2.77947525e-01 -4.16213458e-04\n",
      " -3.10600662e-01  3.00667562e-01 -2.03379849e-01 -2.11850624e-01\n",
      "  9.32190542e-02 -4.42575124e-01]\n",
      "Training Error:  10.551480335974846\n",
      "====================================================================================================\n",
      "Iteration:  690\n",
      "Previous theta :  [ 6.45481473e-03 -7.40629109e-02  1.05974476e-01  1.25071945e-02\n",
      "  1.00023700e-01 -2.21516196e-01  2.77947525e-01 -4.16213458e-04\n",
      " -3.10600662e-01  3.00667562e-01 -2.03379849e-01 -2.11850624e-01\n",
      "  9.32190542e-02 -4.42575124e-01]\n",
      "New theta_0 : [ 6.45406567e-03 -7.41001810e-02  1.06009330e-01  1.25362615e-02\n",
      "  1.00016064e-01 -2.21595881e-01  2.77914566e-01 -4.01060770e-04\n",
      " -3.10673373e-01  3.00819118e-01 -2.03508908e-01 -2.11872949e-01\n",
      "  9.32094368e-02 -4.42582265e-01]\n",
      "Training Error:  10.551427692759937\n",
      "====================================================================================================\n",
      "Iteration:  691\n",
      "Previous theta :  [ 6.45406567e-03 -7.41001810e-02  1.06009330e-01  1.25362615e-02\n",
      "  1.00016064e-01 -2.21595881e-01  2.77914566e-01 -4.01060770e-04\n",
      " -3.10673373e-01  3.00819118e-01 -2.03508908e-01 -2.11872949e-01\n",
      "  9.32094368e-02 -4.42582265e-01]\n",
      "New theta_0 : [ 6.45332063e-03 -7.41372362e-02  1.06043983e-01  1.25653284e-02\n",
      "  1.00008450e-01 -2.21675036e-01  2.77881800e-01 -3.85974522e-04\n",
      " -3.10745536e-01  3.00970191e-01 -2.03637705e-01 -2.11895145e-01\n",
      "  9.31998873e-02 -4.42589383e-01]\n",
      "Training Error:  10.551375447845876\n",
      "====================================================================================================\n",
      "Iteration:  692\n",
      "Previous theta :  [ 6.45332063e-03 -7.41372362e-02  1.06043983e-01  1.25653284e-02\n",
      "  1.00008450e-01 -2.21675036e-01  2.77881800e-01 -3.85974522e-04\n",
      " -3.10745536e-01  3.00970191e-01 -2.03637705e-01 -2.11895145e-01\n",
      "  9.31998873e-02 -4.42589383e-01]\n",
      "New theta_0 : [ 6.45257959e-03 -7.41740781e-02  1.06078437e-01  1.25943944e-02\n",
      "  1.00000858e-01 -2.21753666e-01  2.77849227e-01 -3.70954329e-04\n",
      " -3.10817155e-01  3.01120782e-01 -2.03766242e-01 -2.11917213e-01\n",
      "  9.31904053e-02 -4.42596480e-01]\n",
      "Training Error:  10.551323597414665\n",
      "====================================================================================================\n",
      "Iteration:  693\n",
      "Previous theta :  [ 6.45257959e-03 -7.41740781e-02  1.06078437e-01  1.25943944e-02\n",
      "  1.00000858e-01 -2.21753666e-01  2.77849227e-01 -3.70954329e-04\n",
      " -3.10817155e-01  3.01120782e-01 -2.03766242e-01 -2.11917213e-01\n",
      "  9.31904053e-02 -4.42596480e-01]\n",
      "New theta_0 : [ 6.45184253e-03 -7.42107080e-02  1.06112692e-01  1.26234589e-02\n",
      "  9.99932871e-02 -2.21831773e-01  2.77816845e-01 -3.55999808e-04\n",
      " -3.10888235e-01  3.01270893e-01 -2.03894518e-01 -2.11939153e-01\n",
      "  9.31809903e-02 -4.42603554e-01]\n",
      "Training Error:  10.55127213769293\n",
      "====================================================================================================\n",
      "Iteration:  694\n",
      "Previous theta :  [ 6.45184253e-03 -7.42107080e-02  1.06112692e-01  1.26234589e-02\n",
      "  9.99932871e-02 -2.21831773e-01  2.77816845e-01 -3.55999808e-04\n",
      " -3.10888235e-01  3.01270893e-01 -2.03894518e-01 -2.11939153e-01\n",
      "  9.31809903e-02 -4.42603554e-01]\n",
      "New theta_0 : [ 6.45110942e-03 -7.42471273e-02  1.06146751e-01  1.26525212e-02\n",
      "  9.99857382e-02 -2.21909362e-01  2.77784652e-01 -3.41110581e-04\n",
      " -3.10958779e-01  3.01420527e-01 -2.04022534e-01 -2.11960967e-01\n",
      "  9.31716418e-02 -4.42610606e-01]\n",
      "Training Error:  10.551221064951319\n",
      "====================================================================================================\n",
      "Iteration:  695\n",
      "Previous theta :  [ 6.45110942e-03 -7.42471273e-02  1.06146751e-01  1.26525212e-02\n",
      "  9.99857382e-02 -2.21909362e-01  2.77784652e-01 -3.41110581e-04\n",
      " -3.10958779e-01  3.01420527e-01 -2.04022534e-01 -2.11960967e-01\n",
      "  9.31716418e-02 -4.42610606e-01]\n",
      "New theta_0 : [ 6.45038024e-03 -7.42833374e-02  1.06180614e-01  1.26815804e-02\n",
      "  9.99782108e-02 -2.21986435e-01  2.77752648e-01 -3.26286269e-04\n",
      " -3.11028791e-01  3.01569684e-01 -2.04150289e-01 -2.11982654e-01\n",
      "  9.31623593e-02 -4.42617638e-01]\n",
      "Training Error:  10.551170375503945\n",
      "====================================================================================================\n",
      "Iteration:  696\n",
      "Previous theta :  [ 6.45038024e-03 -7.42833374e-02  1.06180614e-01  1.26815804e-02\n",
      "  9.99782108e-02 -2.21986435e-01  2.77752648e-01 -3.26286269e-04\n",
      " -3.11028791e-01  3.01569684e-01 -2.04150289e-01 -2.11982654e-01\n",
      "  9.31623593e-02 -4.42617638e-01]\n",
      "New theta_0 : [ 6.44965497e-03 -7.43193396e-02  1.06214284e-01  1.27106358e-02\n",
      "  9.99707050e-02 -2.22062996e-01  2.77720831e-01 -3.11526497e-04\n",
      " -3.11098275e-01  3.01718368e-01 -2.04277784e-01 -2.12004217e-01\n",
      "  9.31531423e-02 -4.42624648e-01]\n",
      "Training Error:  10.551120065707796\n",
      "====================================================================================================\n",
      "Iteration:  697\n",
      "Previous theta :  [ 6.44965497e-03 -7.43193396e-02  1.06214284e-01  1.27106358e-02\n",
      "  9.99707050e-02 -2.22062996e-01  2.77720831e-01 -3.11526497e-04\n",
      " -3.11098275e-01  3.01718368e-01 -2.04277784e-01 -2.12004217e-01\n",
      "  9.31531423e-02 -4.42624648e-01]\n",
      "New theta_0 : [ 6.44893359e-03 -7.43551354e-02  1.06247760e-01  1.27396868e-02\n",
      "  9.99632205e-02 -2.22139048e-01  2.77689199e-01 -2.96830894e-04\n",
      " -3.11167235e-01  3.01866579e-01 -2.04405019e-01 -2.12025655e-01\n",
      "  9.31439903e-02 -4.42631636e-01]\n",
      "Training Error:  10.551070131962186\n",
      "====================================================================================================\n",
      "Iteration:  698\n",
      "Previous theta :  [ 6.44893359e-03 -7.43551354e-02  1.06247760e-01  1.27396868e-02\n",
      "  9.99632205e-02 -2.22139048e-01  2.77689199e-01 -2.96830894e-04\n",
      " -3.11167235e-01  3.01866579e-01 -2.04405019e-01 -2.12025655e-01\n",
      "  9.31439903e-02 -4.42631636e-01]\n",
      "New theta_0 : [ 6.44821608e-03 -7.43907262e-02  1.06281045e-01  1.27687327e-02\n",
      "  9.99557574e-02 -2.22214595e-01  2.77657751e-01 -2.82199091e-04\n",
      " -3.11235675e-01  3.02014320e-01 -2.04531994e-01 -2.12046970e-01\n",
      "  9.31349028e-02 -4.42638605e-01]\n",
      "Training Error:  10.551020570708207\n",
      "====================================================================================================\n",
      "Iteration:  699\n",
      "Previous theta :  [ 6.44821608e-03 -7.43907262e-02  1.06281045e-01  1.27687327e-02\n",
      "  9.99557574e-02 -2.22214595e-01  2.77657751e-01 -2.82199091e-04\n",
      " -3.11235675e-01  3.02014320e-01 -2.04531994e-01 -2.12046970e-01\n",
      "  9.31349028e-02 -4.42638605e-01]\n",
      "New theta_0 : [ 6.44750242e-03 -7.44261132e-02  1.06314139e-01  1.27977727e-02\n",
      "  9.99483156e-02 -2.22289641e-01  2.77626486e-01 -2.67630719e-04\n",
      " -3.11303599e-01  3.02161593e-01 -2.04658709e-01 -2.12068162e-01\n",
      "  9.31258793e-02 -4.42645552e-01]\n",
      "Training Error:  10.550971378428159\n",
      "====================================================================================================\n",
      "Iteration:  700\n",
      "Previous theta :  [ 6.44750242e-03 -7.44261132e-02  1.06314139e-01  1.27977727e-02\n",
      "  9.99483156e-02 -2.22289641e-01  2.77626486e-01 -2.67630719e-04\n",
      " -3.11303599e-01  3.02161593e-01 -2.04658709e-01 -2.12068162e-01\n",
      "  9.31258793e-02 -4.42645552e-01]\n",
      "New theta_0 : [ 6.44679259e-03 -7.44612978e-02  1.06347044e-01  1.28268062e-02\n",
      "  9.99408950e-02 -2.22364187e-01  2.77595403e-01 -2.53125414e-04\n",
      " -3.11371011e-01  3.02308399e-01 -2.04785165e-01 -2.12089231e-01\n",
      "  9.31169195e-02 -4.42652479e-01]\n",
      "Training Error:  10.550922551645034\n",
      "====================================================================================================\n",
      "Iteration:  701\n",
      "Previous theta :  [ 6.44679259e-03 -7.44612978e-02  1.06347044e-01  1.28268062e-02\n",
      "  9.99408950e-02 -2.22364187e-01  2.77595403e-01 -2.53125414e-04\n",
      " -3.11371011e-01  3.02308399e-01 -2.04785165e-01 -2.12089231e-01\n",
      "  9.31169195e-02 -4.42652479e-01]\n",
      "New theta_0 : [ 6.44608656e-03 -7.44962814e-02  1.06379762e-01  1.28558326e-02\n",
      "  9.99334955e-02 -2.22438239e-01  2.77564500e-01 -2.38682815e-04\n",
      " -3.11437914e-01  3.02454740e-01 -2.04911361e-01 -2.12110180e-01\n",
      "  9.31080227e-02 -4.42659386e-01]\n",
      "Training Error:  10.550874086921976\n",
      "====================================================================================================\n",
      "Iteration:  702\n",
      "Previous theta :  [ 6.44608656e-03 -7.44962814e-02  1.06379762e-01  1.28558326e-02\n",
      "  9.99334955e-02 -2.22438239e-01  2.77564500e-01 -2.38682815e-04\n",
      " -3.11437914e-01  3.02454740e-01 -2.04911361e-01 -2.12110180e-01\n",
      "  9.31080227e-02 -4.42659386e-01]\n",
      "New theta_0 : [ 6.44538432e-03 -7.45310652e-02  1.06412293e-01  1.28848510e-02\n",
      "  9.99261170e-02 -2.22511799e-01  2.77533776e-01 -2.24302561e-04\n",
      " -3.11504312e-01  3.02600618e-01 -2.05037298e-01 -2.12131008e-01\n",
      "  9.30991885e-02 -4.42666272e-01]\n",
      "Training Error:  10.550825980861756\n",
      "====================================================================================================\n",
      "Iteration:  703\n",
      "Previous theta :  [ 6.44538432e-03 -7.45310652e-02  1.06412293e-01  1.28848510e-02\n",
      "  9.99261170e-02 -2.22511799e-01  2.77533776e-01 -2.24302561e-04\n",
      " -3.11504312e-01  3.02600618e-01 -2.05037298e-01 -2.12131008e-01\n",
      "  9.30991885e-02 -4.42666272e-01]\n",
      "New theta_0 : [ 6.44468584e-03 -7.45656506e-02  1.06444639e-01  1.29138610e-02\n",
      "  9.99187595e-02 -2.22584870e-01  2.77503229e-01 -2.09984296e-04\n",
      " -3.11570210e-01  3.02746034e-01 -2.05162976e-01 -2.12151716e-01\n",
      "  9.30904166e-02 -4.42673139e-01]\n",
      "Training Error:  10.550778230106259\n",
      "====================================================================================================\n",
      "Iteration:  704\n",
      "Previous theta :  [ 6.44468584e-03 -7.45656506e-02  1.06444639e-01  1.29138610e-02\n",
      "  9.99187595e-02 -2.22584870e-01  2.77503229e-01 -2.09984296e-04\n",
      " -3.11570210e-01  3.02746034e-01 -2.05162976e-01 -2.12151716e-01\n",
      "  9.30904166e-02 -4.42673139e-01]\n",
      "New theta_0 : [ 6.44399111e-03 -7.46000390e-02  1.06476801e-01  1.29428618e-02\n",
      "  9.99114229e-02 -2.22657456e-01  2.77472860e-01 -1.95727664e-04\n",
      " -3.11635610e-01  3.02890992e-01 -2.05288396e-01 -2.12172305e-01\n",
      "  9.30817063e-02 -4.42679986e-01]\n",
      "Training Error:  10.550730831335969\n",
      "====================================================================================================\n",
      "Iteration:  705\n",
      "Previous theta :  [ 6.44399111e-03 -7.46000390e-02  1.06476801e-01  1.29428618e-02\n",
      "  9.99114229e-02 -2.22657456e-01  2.77472860e-01 -1.95727664e-04\n",
      " -3.11635610e-01  3.02890992e-01 -2.05288396e-01 -2.12172305e-01\n",
      "  9.30817063e-02 -4.42679986e-01]\n",
      "New theta_0 : [ 6.44330010e-03 -7.46342315e-02  1.06508781e-01  1.29718528e-02\n",
      "  9.99041071e-02 -2.22729560e-01  2.77442665e-01 -1.81532313e-04\n",
      " -3.11700516e-01  3.03035492e-01 -2.05413556e-01 -2.12192776e-01\n",
      "  9.30730573e-02 -4.42686814e-01]\n",
      "Training Error:  10.550683781269475\n",
      "====================================================================================================\n",
      "Iteration:  706\n",
      "Previous theta :  [ 6.44330010e-03 -7.46342315e-02  1.06508781e-01  1.29718528e-02\n",
      "  9.99041071e-02 -2.22729560e-01  2.77442665e-01 -1.81532313e-04\n",
      " -3.11700516e-01  3.03035492e-01 -2.05413556e-01 -2.12192776e-01\n",
      "  9.30730573e-02 -4.42686814e-01]\n",
      "New theta_0 : [ 6.44261280e-03 -7.46682295e-02  1.06540578e-01  1.30008334e-02\n",
      "  9.98968121e-02 -2.22801184e-01  2.77412644e-01 -1.67397894e-04\n",
      " -3.11764933e-01  3.03179536e-01 -2.05538458e-01 -2.12213129e-01\n",
      "  9.30644691e-02 -4.42693622e-01]\n",
      "Training Error:  10.550637076662964\n",
      "====================================================================================================\n",
      "Iteration:  707\n",
      "Previous theta :  [ 6.44261280e-03 -7.46682295e-02  1.06540578e-01  1.30008334e-02\n",
      "  9.98968121e-02 -2.22801184e-01  2.77412644e-01 -1.67397894e-04\n",
      " -3.11764933e-01  3.03179536e-01 -2.05538458e-01 -2.12213129e-01\n",
      "  9.30644691e-02 -4.42693622e-01]\n",
      "New theta_0 : [ 6.44192918e-03 -7.47020343e-02  1.06572196e-01  1.30298029e-02\n",
      "  9.98895378e-02 -2.22872333e-01  2.77382796e-01 -1.53324058e-04\n",
      " -3.11828863e-01  3.03323125e-01 -2.05663101e-01 -2.12233366e-01\n",
      "  9.30559413e-02 -4.42700411e-01]\n",
      "Training Error:  10.550590714309745\n",
      "====================================================================================================\n",
      "Iteration:  708\n",
      "Previous theta :  [ 6.44192918e-03 -7.47020343e-02  1.06572196e-01  1.30298029e-02\n",
      "  9.98895378e-02 -2.22872333e-01  2.77382796e-01 -1.53324058e-04\n",
      " -3.11828863e-01  3.03323125e-01 -2.05663101e-01 -2.12233366e-01\n",
      "  9.30559413e-02 -4.42700411e-01]\n",
      "New theta_0 : [ 6.44124922e-03 -7.47356471e-02  1.06603634e-01  1.30587607e-02\n",
      "  9.98822841e-02 -2.22943010e-01  2.77353120e-01 -1.39310461e-04\n",
      " -3.11892310e-01  3.03466263e-01 -2.05787487e-01 -2.12253486e-01\n",
      "  9.30474733e-02 -4.42707182e-01]\n",
      "Training Error:  10.550544691039757\n",
      "====================================================================================================\n",
      "Iteration:  709\n",
      "Previous theta :  [ 6.44124922e-03 -7.47356471e-02  1.06603634e-01  1.30587607e-02\n",
      "  9.98822841e-02 -2.22943010e-01  2.77353120e-01 -1.39310461e-04\n",
      " -3.11892310e-01  3.03466263e-01 -2.05787487e-01 -2.12253486e-01\n",
      "  9.30474733e-02 -4.42707182e-01]\n",
      "New theta_0 : [ 6.44057291e-03 -7.47690691e-02  1.06634894e-01  1.30877063e-02\n",
      "  9.98750510e-02 -2.23013217e-01  2.77323614e-01 -1.25356760e-04\n",
      " -3.11955279e-01  3.03608950e-01 -2.05911614e-01 -2.12273491e-01\n",
      "  9.30390648e-02 -4.42713933e-01]\n",
      "Training Error:  10.550499003719102\n",
      "====================================================================================================\n",
      "Iteration:  710\n",
      "Previous theta :  [ 6.44057291e-03 -7.47690691e-02  1.06634894e-01  1.30877063e-02\n",
      "  9.98750510e-02 -2.23013217e-01  2.77323614e-01 -1.25356760e-04\n",
      " -3.11955279e-01  3.03608950e-01 -2.05911614e-01 -2.12273491e-01\n",
      "  9.30390648e-02 -4.42713933e-01]\n",
      "New theta_0 : [ 6.43990022e-03 -7.48023018e-02  1.06665978e-01  1.31166390e-02\n",
      "  9.98678383e-02 -2.23082958e-01  2.77294277e-01 -1.11462614e-04\n",
      " -3.12017772e-01  3.03751188e-01 -2.06035484e-01 -2.12293381e-01\n",
      "  9.30307153e-02 -4.42720666e-01]\n",
      "Training Error:  10.550453649249569\n",
      "====================================================================================================\n",
      "Iteration:  711\n",
      "Previous theta :  [ 6.43990022e-03 -7.48023018e-02  1.06665978e-01  1.31166390e-02\n",
      "  9.98678383e-02 -2.23082958e-01  2.77294277e-01 -1.11462614e-04\n",
      " -3.12017772e-01  3.03751188e-01 -2.06035484e-01 -2.12293381e-01\n",
      "  9.30307153e-02 -4.42720666e-01]\n",
      "New theta_0 : [ 6.43923114e-03 -7.48353462e-02  1.06696886e-01  1.31455582e-02\n",
      "  9.98606460e-02 -2.23152235e-01  2.77265107e-01 -9.76276848e-05\n",
      " -3.12079792e-01  3.03892980e-01 -2.06159096e-01 -2.12313157e-01\n",
      "  9.30224245e-02 -4.42727380e-01]\n",
      "Training Error:  10.550408624568172\n",
      "====================================================================================================\n",
      "Iteration:  712\n",
      "Previous theta :  [ 6.43923114e-03 -7.48353462e-02  1.06696886e-01  1.31455582e-02\n",
      "  9.98606460e-02 -2.23152235e-01  2.77265107e-01 -9.76276848e-05\n",
      " -3.12079792e-01  3.03892980e-01 -2.06159096e-01 -2.12313157e-01\n",
      "  9.30224245e-02 -4.42727380e-01]\n",
      "New theta_0 : [ 6.43856565e-03 -7.48682036e-02  1.06727620e-01  1.31744634e-02\n",
      "  9.98534741e-02 -2.23221053e-01  2.77236105e-01 -8.38516368e-05\n",
      " -3.12141345e-01  3.04034325e-01 -2.06282451e-01 -2.12332820e-01\n",
      "  9.30141917e-02 -4.42734077e-01]\n",
      "Training Error:  10.550363926646702\n",
      "====================================================================================================\n",
      "Iteration:  713\n",
      "Previous theta :  [ 6.43856565e-03 -7.48682036e-02  1.06727620e-01  1.31744634e-02\n",
      "  9.98534741e-02 -2.23221053e-01  2.77236105e-01 -8.38516368e-05\n",
      " -3.12141345e-01  3.04034325e-01 -2.06282451e-01 -2.12332820e-01\n",
      "  9.30141917e-02 -4.42734077e-01]\n",
      "New theta_0 : [ 6.43790372e-03 -7.49008753e-02  1.06758180e-01  1.32033539e-02\n",
      "  9.98463225e-02 -2.23289413e-01  2.77207268e-01 -7.01341364e-05\n",
      " -3.12202432e-01  3.04175228e-01 -2.06405548e-01 -2.12352370e-01\n",
      "  9.30060167e-02 -4.42740755e-01]\n",
      "Training Error:  10.550319552491272\n",
      "====================================================================================================\n",
      "Iteration:  714\n",
      "Previous theta :  [ 6.43790372e-03 -7.49008753e-02  1.06758180e-01  1.32033539e-02\n",
      "  9.98463225e-02 -2.23289413e-01  2.77207268e-01 -7.01341364e-05\n",
      " -3.12202432e-01  3.04175228e-01 -2.06405548e-01 -2.12352370e-01\n",
      "  9.30060167e-02 -4.42740755e-01]\n",
      "New theta_0 : [ 6.43724533e-03 -7.49333625e-02  1.06788568e-01  1.32322292e-02\n",
      "  9.98391910e-02 -2.23357319e-01  2.77178595e-01 -5.64748522e-05\n",
      " -3.12263058e-01  3.04315688e-01 -2.06528389e-01 -2.12371809e-01\n",
      "  9.29978990e-02 -4.42747415e-01]\n",
      "Training Error:  10.550275499141872\n",
      "====================================================================================================\n",
      "Iteration:  715\n",
      "Previous theta :  [ 6.43724533e-03 -7.49333625e-02  1.06788568e-01  1.32322292e-02\n",
      "  9.98391910e-02 -2.23357319e-01  2.77178595e-01 -5.64748522e-05\n",
      " -3.12263058e-01  3.04315688e-01 -2.06528389e-01 -2.12371809e-01\n",
      "  9.29978990e-02 -4.42747415e-01]\n",
      "New theta_0 : [ 6.43659048e-03 -7.49656663e-02  1.06818786e-01  1.32610888e-02\n",
      "  9.98320797e-02 -2.23424775e-01  2.77150085e-01 -4.28734553e-05\n",
      " -3.12323225e-01  3.04455708e-01 -2.06650973e-01 -2.12391136e-01\n",
      "  9.29898381e-02 -4.42754057e-01]\n",
      "Training Error:  10.550231763671933\n",
      "====================================================================================================\n",
      "Iteration:  716\n",
      "Previous theta :  [ 6.43659048e-03 -7.49656663e-02  1.06818786e-01  1.32610888e-02\n",
      "  9.98320797e-02 -2.23424775e-01  2.77150085e-01 -4.28734553e-05\n",
      " -3.12323225e-01  3.04455708e-01 -2.06650973e-01 -2.12391136e-01\n",
      "  9.29898381e-02 -4.42754057e-01]\n",
      "New theta_0 : [ 6.43593913e-03 -7.49977880e-02  1.06848834e-01  1.32899320e-02\n",
      "  9.98249885e-02 -2.23491782e-01  2.77121738e-01 -2.93296187e-05\n",
      " -3.12382938e-01  3.04595290e-01 -2.06773300e-01 -2.12410353e-01\n",
      "  9.29818337e-02 -4.42760681e-01]\n",
      "Training Error:  10.5501883431879\n",
      "====================================================================================================\n",
      "Iteration:  717\n",
      "Previous theta :  [ 6.43593913e-03 -7.49977880e-02  1.06848834e-01  1.32899320e-02\n",
      "  9.98249885e-02 -2.23491782e-01  2.77121738e-01 -2.93296187e-05\n",
      " -3.12382938e-01  3.04595290e-01 -2.06773300e-01 -2.12410353e-01\n",
      "  9.29818337e-02 -4.42760681e-01]\n",
      "New theta_0 : [ 6.43529127e-03 -7.50297288e-02  1.06878713e-01  1.33187584e-02\n",
      "  9.98179172e-02 -2.23558345e-01  2.77093551e-01 -1.58430180e-05\n",
      " -3.12442200e-01  3.04734435e-01 -2.06895371e-01 -2.12429460e-01\n",
      "  9.29738853e-02 -4.42767288e-01]\n",
      "Training Error:  10.550145234828802\n",
      "====================================================================================================\n",
      "Iteration:  718\n",
      "Previous theta :  [ 6.43529127e-03 -7.50297288e-02  1.06878713e-01  1.33187584e-02\n",
      "  9.98179172e-02 -2.23558345e-01  2.77093551e-01 -1.58430180e-05\n",
      " -3.12442200e-01  3.04734435e-01 -2.06895371e-01 -2.12429460e-01\n",
      "  9.29738853e-02 -4.42767288e-01]\n",
      "New theta_0 : [ 6.43464688e-03 -7.50614898e-02  1.06908424e-01  1.33475673e-02\n",
      "  9.98108659e-02 -2.23624465e-01  2.77065524e-01 -2.41333076e-06\n",
      " -3.12501013e-01  3.04873144e-01 -2.07017186e-01 -2.12448458e-01\n",
      "  9.29659925e-02 -4.42773878e-01]\n",
      "Training Error:  10.550102435765833\n",
      "====================================================================================================\n",
      "Iteration:  719\n",
      "Previous theta :  [ 6.43464688e-03 -7.50614898e-02  1.06908424e-01  1.33475673e-02\n",
      "  9.98108659e-02 -2.23624465e-01  2.77065524e-01 -2.41333076e-06\n",
      " -3.12501013e-01  3.04873144e-01 -2.07017186e-01 -2.12448458e-01\n",
      "  9.29659925e-02 -4.42773878e-01]\n",
      "New theta_0 : [ 6.43400594e-03 -7.50930722e-02  1.06937969e-01  1.33763583e-02\n",
      "  9.98038345e-02 -2.23690147e-01  2.77037656e-01  1.09597632e-05\n",
      " -3.12559382e-01  3.05011420e-01 -2.07138745e-01 -2.12467347e-01\n",
      "  9.29581550e-02 -4.42780451e-01]\n",
      "Training Error:  10.55005994320194\n",
      "====================================================================================================\n",
      "Iteration:  720\n",
      "Previous theta :  [ 6.43400594e-03 -7.50930722e-02  1.06937969e-01  1.33763583e-02\n",
      "  9.98038345e-02 -2.23690147e-01  2.77037656e-01  1.09597632e-05\n",
      " -3.12559382e-01  3.05011420e-01 -2.07138745e-01 -2.12467347e-01\n",
      "  9.29581550e-02 -4.42780451e-01]\n",
      "New theta_0 : [ 6.43336843e-03 -7.51244773e-02  1.06967349e-01  1.34051309e-02\n",
      "  9.97968228e-02 -2.23755392e-01  2.77009945e-01  2.42765818e-05\n",
      " -3.12617309e-01  3.05149265e-01 -2.07260048e-01 -2.12486129e-01\n",
      "  9.29503722e-02 -4.42787006e-01]\n",
      "Training Error:  10.550017754371416\n",
      "====================================================================================================\n",
      "Iteration:  721\n",
      "Previous theta :  [ 6.43336843e-03 -7.51244773e-02  1.06967349e-01  1.34051309e-02\n",
      "  9.97968228e-02 -2.23755392e-01  2.77009945e-01  2.42765818e-05\n",
      " -3.12617309e-01  3.05149265e-01 -2.07260048e-01 -2.12486129e-01\n",
      "  9.29503722e-02 -4.42787006e-01]\n",
      "New theta_0 : [ 6.43273434e-03 -7.51557061e-02  1.06996564e-01  1.34338844e-02\n",
      "  9.97898309e-02 -2.23820204e-01  2.76982391e-01  3.75374409e-05\n",
      " -3.12674798e-01  3.05286679e-01 -2.07381096e-01 -2.12504803e-01\n",
      "  9.29426439e-02 -4.42793545e-01]\n",
      "Training Error:  10.549975866539492\n",
      "====================================================================================================\n",
      "Iteration:  722\n",
      "Previous theta :  [ 6.43273434e-03 -7.51557061e-02  1.06996564e-01  1.34338844e-02\n",
      "  9.97898309e-02 -2.23820204e-01  2.76982391e-01  3.75374409e-05\n",
      " -3.12674798e-01  3.05286679e-01 -2.07381096e-01 -2.12504803e-01\n",
      "  9.29426439e-02 -4.42793545e-01]\n",
      "New theta_0 : [ 6.43210364e-03 -7.51867598e-02  1.07025617e-01  1.34626184e-02\n",
      "  9.97828587e-02 -2.23884586e-01  2.76954992e-01  5.07426541e-05\n",
      " -3.12731853e-01  3.05423664e-01 -2.07501889e-01 -2.12523371e-01\n",
      "  9.29349695e-02 -4.42800067e-01]\n",
      "Training Error:  10.54993427700195\n",
      "====================================================================================================\n",
      "Iteration:  723\n",
      "Previous theta :  [ 6.43210364e-03 -7.51867598e-02  1.07025617e-01  1.34626184e-02\n",
      "  9.97828587e-02 -2.23884586e-01  2.76954992e-01  5.07426541e-05\n",
      " -3.12731853e-01  3.05423664e-01 -2.07501889e-01 -2.12523371e-01\n",
      "  9.29349695e-02 -4.42800067e-01]\n",
      "New theta_0 : [ 6.43147632e-03 -7.52176395e-02  1.07054507e-01  1.34913324e-02\n",
      "  9.97759060e-02 -2.23948540e-01  2.76927747e-01  6.38925330e-05\n",
      " -3.12788475e-01  3.05560223e-01 -2.07622426e-01 -2.12541833e-01\n",
      "  9.29273487e-02 -4.42806572e-01]\n",
      "Training Error:  10.549892983084721\n",
      "====================================================================================================\n",
      "Iteration:  724\n",
      "Previous theta :  [ 6.43147632e-03 -7.52176395e-02  1.07054507e-01  1.34913324e-02\n",
      "  9.97759060e-02 -2.23948540e-01  2.76927747e-01  6.38925330e-05\n",
      " -3.12788475e-01  3.05560223e-01 -2.07622426e-01 -2.12541833e-01\n",
      "  9.29273487e-02 -4.42806572e-01]\n",
      "New theta_0 : [ 6.43085235e-03 -7.52483464e-02  1.07083236e-01  1.35200260e-02\n",
      "  9.97689729e-02 -2.24012069e-01  2.76900656e-01  7.69873870e-05\n",
      " -3.12844670e-01  3.05696356e-01 -2.07742709e-01 -2.12560190e-01\n",
      "  9.29197812e-02 -4.42813061e-01]\n",
      "Training Error:  10.549851982143505\n",
      "====================================================================================================\n",
      "Iteration:  725\n",
      "Previous theta :  [ 6.43085235e-03 -7.52483464e-02  1.07083236e-01  1.35200260e-02\n",
      "  9.97689729e-02 -2.24012069e-01  2.76900656e-01  7.69873870e-05\n",
      " -3.12844670e-01  3.05696356e-01 -2.07742709e-01 -2.12560190e-01\n",
      "  9.29197812e-02 -4.42813061e-01]\n",
      "New theta_0 : [ 6.43023173e-03 -7.52788816e-02  1.07111806e-01  1.35486985e-02\n",
      "  9.97620593e-02 -2.24075177e-01  2.76873716e-01  9.00275232e-05\n",
      " -3.12900439e-01  3.05832066e-01 -2.07862738e-01 -2.12578443e-01\n",
      "  9.29122664e-02 -4.42819533e-01]\n",
      "Training Error:  10.549811271563389\n",
      "====================================================================================================\n",
      "Iteration:  726\n",
      "Previous theta :  [ 6.43023173e-03 -7.52788816e-02  1.07111806e-01  1.35486985e-02\n",
      "  9.97620593e-02 -2.24075177e-01  2.76873716e-01  9.00275232e-05\n",
      " -3.12900439e-01  3.05832066e-01 -2.07862738e-01 -2.12578443e-01\n",
      "  9.29122664e-02 -4.42819533e-01]\n",
      "New theta_0 : [ 6.42961443e-03 -7.53092463e-02  1.07140216e-01  1.35773495e-02\n",
      "  9.97551651e-02 -2.24137866e-01  2.76846928e-01  1.03013247e-04\n",
      " -3.12955786e-01  3.05967354e-01 -2.07982512e-01 -2.12596591e-01\n",
      "  9.29048041e-02 -4.42825989e-01]\n",
      "Training Error:  10.549770848758472\n",
      "====================================================================================================\n",
      "Iteration:  727\n",
      "Previous theta :  [ 6.42961443e-03 -7.53092463e-02  1.07140216e-01  1.35773495e-02\n",
      "  9.97551651e-02 -2.24137866e-01  2.76846928e-01  1.03013247e-04\n",
      " -3.12955786e-01  3.05967354e-01 -2.07982512e-01 -2.12596591e-01\n",
      "  9.29048041e-02 -4.42825989e-01]\n",
      "New theta_0 : [ 6.42900043e-03 -7.53394415e-02  1.07168469e-01  1.36059785e-02\n",
      "  9.97482902e-02 -2.24200139e-01  2.76820289e-01  1.15944861e-04\n",
      " -3.13010714e-01  3.06102221e-01 -2.08102032e-01 -2.12614637e-01\n",
      "  9.28973938e-02 -4.42832430e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.549730711171495\n",
      "====================================================================================================\n",
      "Iteration:  728\n",
      "Previous theta :  [ 6.42900043e-03 -7.53394415e-02  1.07168469e-01  1.36059785e-02\n",
      "  9.97482902e-02 -2.24200139e-01  2.76820289e-01  1.15944861e-04\n",
      " -3.13010714e-01  3.06102221e-01 -2.08102032e-01 -2.12614637e-01\n",
      "  9.28973938e-02 -4.42832430e-01]\n",
      "New theta_0 : [ 6.42838972e-03 -7.53694683e-02  1.07196565e-01  1.36345851e-02\n",
      "  9.97414346e-02 -2.24261998e-01  2.76793799e-01  1.28822668e-04\n",
      " -3.13065226e-01  3.06236669e-01 -2.08221298e-01 -2.12632579e-01\n",
      "  9.28900351e-02 -4.42838854e-01]\n",
      "Training Error:  10.549690856273475\n",
      "====================================================================================================\n",
      "Iteration:  729\n",
      "Previous theta :  [ 6.42838972e-03 -7.53694683e-02  1.07196565e-01  1.36345851e-02\n",
      "  9.97414346e-02 -2.24261998e-01  2.76793799e-01  1.28822668e-04\n",
      " -3.13065226e-01  3.06236669e-01 -2.08221298e-01 -2.12632579e-01\n",
      "  9.28900351e-02 -4.42838854e-01]\n",
      "New theta_0 : [ 6.42778227e-03 -7.53993279e-02  1.07224505e-01  1.36631688e-02\n",
      "  9.97345982e-02 -2.24323446e-01  2.76767458e-01  1.41646964e-04\n",
      " -3.13119325e-01  3.06370700e-01 -2.08340311e-01 -2.12650420e-01\n",
      "  9.28827278e-02 -4.42845262e-01]\n",
      "Training Error:  10.549651281563342\n",
      "====================================================================================================\n",
      "Iteration:  730\n",
      "Previous theta :  [ 6.42778227e-03 -7.53993279e-02  1.07224505e-01  1.36631688e-02\n",
      "  9.97345982e-02 -2.24323446e-01  2.76767458e-01  1.41646964e-04\n",
      " -3.13119325e-01  3.06370700e-01 -2.08340311e-01 -2.12650420e-01\n",
      "  9.28827278e-02 -4.42845262e-01]\n",
      "New theta_0 : [ 6.42717807e-03 -7.54290213e-02  1.07252291e-01  1.36917292e-02\n",
      "  9.97277810e-02 -2.24384487e-01  2.76741263e-01  1.54418049e-04\n",
      " -3.13173015e-01  3.06504316e-01 -2.08459070e-01 -2.12668160e-01\n",
      "  9.28754713e-02 -4.42851655e-01]\n",
      "Training Error:  10.549611984567589\n",
      "====================================================================================================\n",
      "Iteration:  731\n",
      "Previous theta :  [ 6.42717807e-03 -7.54290213e-02  1.07252291e-01  1.36917292e-02\n",
      "  9.97277810e-02 -2.24384487e-01  2.76741263e-01  1.54418049e-04\n",
      " -3.13173015e-01  3.06504316e-01 -2.08459070e-01 -2.12668160e-01\n",
      "  9.28754713e-02 -4.42851655e-01]\n",
      "New theta_0 : [ 6.42657711e-03 -7.54585496e-02  1.07279923e-01  1.37202657e-02\n",
      "  9.97209829e-02 -2.24445123e-01  2.76715214e-01  1.67136216e-04\n",
      " -3.13226298e-01  3.06637517e-01 -2.08577577e-01 -2.12685798e-01\n",
      "  9.28682653e-02 -4.42858032e-01]\n",
      "Training Error:  10.54957296283992\n",
      "====================================================================================================\n",
      "Iteration:  732\n",
      "Previous theta :  [ 6.42657711e-03 -7.54585496e-02  1.07279923e-01  1.37202657e-02\n",
      "  9.97209829e-02 -2.24445123e-01  2.76715214e-01  1.67136216e-04\n",
      " -3.13226298e-01  3.06637517e-01 -2.08577577e-01 -2.12685798e-01\n",
      "  9.28682653e-02 -4.42858032e-01]\n",
      "New theta_0 : [ 6.42597936e-03 -7.54879138e-02  1.07307402e-01  1.37487779e-02\n",
      "  9.97142038e-02 -2.24505356e-01  2.76689309e-01  1.79801758e-04\n",
      " -3.13279178e-01  3.06770306e-01 -2.08695830e-01 -2.12703337e-01\n",
      "  9.28611095e-02 -4.42864394e-01]\n",
      "Training Error:  10.549534213960897\n",
      "====================================================================================================\n",
      "Iteration:  733\n",
      "Previous theta :  [ 6.42597936e-03 -7.54879138e-02  1.07307402e-01  1.37487779e-02\n",
      "  9.97142038e-02 -2.24505356e-01  2.76689309e-01  1.79801758e-04\n",
      " -3.13279178e-01  3.06770306e-01 -2.08695830e-01 -2.12703337e-01\n",
      "  9.28611095e-02 -4.42864394e-01]\n",
      "New theta_0 : [ 6.42538480e-03 -7.55171151e-02  1.07334730e-01  1.37772654e-02\n",
      "  9.97074436e-02 -2.24565189e-01  2.76663549e-01  1.92414967e-04\n",
      " -3.13331657e-01  3.06902683e-01 -2.08813831e-01 -2.12720776e-01\n",
      "  9.28540035e-02 -4.42870740e-01]\n",
      "Training Error:  10.549495735537613\n",
      "====================================================================================================\n",
      "Iteration:  734\n",
      "Previous theta :  [ 6.42538480e-03 -7.55171151e-02  1.07334730e-01  1.37772654e-02\n",
      "  9.97074436e-02 -2.24565189e-01  2.76663549e-01  1.92414967e-04\n",
      " -3.13331657e-01  3.06902683e-01 -2.08813831e-01 -2.12720776e-01\n",
      "  9.28540035e-02 -4.42870740e-01]\n",
      "New theta_0 : [ 6.42479343e-03 -7.55461545e-02  1.07361907e-01  1.38057278e-02\n",
      "  9.97007024e-02 -2.24624625e-01  2.76637931e-01  2.04976131e-04\n",
      " -3.13383738e-01  3.07034652e-01 -2.08931580e-01 -2.12738117e-01\n",
      "  9.28469468e-02 -4.42877071e-01]\n",
      "Training Error:  10.549457525203344\n",
      "====================================================================================================\n",
      "Iteration:  735\n",
      "Previous theta :  [ 6.42479343e-03 -7.55461545e-02  1.07361907e-01  1.38057278e-02\n",
      "  9.97007024e-02 -2.24624625e-01  2.76637931e-01  2.04976131e-04\n",
      " -3.13383738e-01  3.07034652e-01 -2.08931580e-01 -2.12738117e-01\n",
      "  9.28469468e-02 -4.42877071e-01]\n",
      "New theta_0 : [ 6.42420522e-03 -7.55750331e-02  1.07388934e-01  1.38341646e-02\n",
      "  9.96939800e-02 -2.24683666e-01  2.76612455e-01  2.17485538e-04\n",
      " -3.13435425e-01  3.07166212e-01 -2.09049077e-01 -2.12755359e-01\n",
      "  9.28399393e-02 -4.42883387e-01]\n",
      "Training Error:  10.549419580617222\n",
      "====================================================================================================\n",
      "Iteration:  736\n",
      "Previous theta :  [ 6.42420522e-03 -7.55750331e-02  1.07388934e-01  1.38341646e-02\n",
      "  9.96939800e-02 -2.24683666e-01  2.76612455e-01  2.17485538e-04\n",
      " -3.13435425e-01  3.07166212e-01 -2.09049077e-01 -2.12755359e-01\n",
      "  9.28399393e-02 -4.42883387e-01]\n",
      "New theta_0 : [ 6.42362015e-03 -7.56037518e-02  1.07415813e-01  1.38625754e-02\n",
      "  9.96872764e-02 -2.24742316e-01  2.76587121e-01  2.29943472e-04\n",
      " -3.13486719e-01  3.07297366e-01 -2.09166322e-01 -2.12772503e-01\n",
      "  9.28329804e-02 -4.42889688e-01]\n",
      "Training Error:  10.549381899463906\n",
      "====================================================================================================\n",
      "Iteration:  737\n",
      "Previous theta :  [ 6.42362015e-03 -7.56037518e-02  1.07415813e-01  1.38625754e-02\n",
      "  9.96872764e-02 -2.24742316e-01  2.76587121e-01  2.29943472e-04\n",
      " -3.13486719e-01  3.07297366e-01 -2.09166322e-01 -2.12772503e-01\n",
      "  9.28329804e-02 -4.42889688e-01]\n",
      "New theta_0 : [ 6.42303821e-03 -7.56323118e-02  1.07442543e-01  1.38909597e-02\n",
      "  9.96805915e-02 -2.24800576e-01  2.76561925e-01  2.42350216e-04\n",
      " -3.13537625e-01  3.07428115e-01 -2.09283315e-01 -2.12789551e-01\n",
      "  9.28260698e-02 -4.42895974e-01]\n",
      "Training Error:  10.549344479453262\n",
      "====================================================================================================\n",
      "Iteration:  738\n",
      "Previous theta :  [ 6.42303821e-03 -7.56323118e-02  1.07442543e-01  1.38909597e-02\n",
      "  9.96805915e-02 -2.24800576e-01  2.76561925e-01  2.42350216e-04\n",
      " -3.13537625e-01  3.07428115e-01 -2.09283315e-01 -2.12789551e-01\n",
      "  9.28260698e-02 -4.42895974e-01]\n",
      "New theta_0 : [ 6.42245938e-03 -7.56607140e-02  1.07469128e-01  1.39193172e-02\n",
      "  9.96739253e-02 -2.24858450e-01  2.76536869e-01  2.54706052e-04\n",
      " -3.13588145e-01  3.07558460e-01 -2.09400057e-01 -2.12806502e-01\n",
      "  9.28192072e-02 -4.42902246e-01]\n",
      "Training Error:  10.549307318320041\n",
      "====================================================================================================\n",
      "Iteration:  739\n",
      "Previous theta :  [ 6.42245938e-03 -7.56607140e-02  1.07469128e-01  1.39193172e-02\n",
      "  9.96739253e-02 -2.24858450e-01  2.76536869e-01  2.54706052e-04\n",
      " -3.13588145e-01  3.07558460e-01 -2.09400057e-01 -2.12806502e-01\n",
      "  9.28192072e-02 -4.42902246e-01]\n",
      "New theta_0 : [ 6.42188364e-03 -7.56889595e-02  1.07495566e-01  1.39476475e-02\n",
      "  9.96672777e-02 -2.24915940e-01  2.76511951e-01  2.67011259e-04\n",
      " -3.13638282e-01  3.07688404e-01 -2.09516549e-01 -2.12823357e-01\n",
      "  9.28123923e-02 -4.42908502e-01]\n",
      "Training Error:  10.549270413823567\n",
      "====================================================================================================\n",
      "Iteration:  740\n",
      "Previous theta :  [ 6.42188364e-03 -7.56889595e-02  1.07495566e-01  1.39476475e-02\n",
      "  9.96672777e-02 -2.24915940e-01  2.76511951e-01  2.67011259e-04\n",
      " -3.13638282e-01  3.07688404e-01 -2.09516549e-01 -2.12823357e-01\n",
      "  9.28123923e-02 -4.42908502e-01]\n",
      "New theta_0 : [ 6.42131098e-03 -7.57170493e-02  1.07521860e-01  1.39759502e-02\n",
      "  9.96606486e-02 -2.24973048e-01  2.76487170e-01  2.79266115e-04\n",
      " -3.13688039e-01  3.07817947e-01 -2.09632789e-01 -2.12840117e-01\n",
      "  9.28056246e-02 -4.42914744e-01]\n",
      "Training Error:  10.549233763747429\n",
      "====================================================================================================\n",
      "Iteration:  741\n",
      "Previous theta :  [ 6.42131098e-03 -7.57170493e-02  1.07521860e-01  1.39759502e-02\n",
      "  9.96606486e-02 -2.24973048e-01  2.76487170e-01  2.79266115e-04\n",
      " -3.13688039e-01  3.07817947e-01 -2.09632789e-01 -2.12840117e-01\n",
      "  9.28056246e-02 -4.42914744e-01]\n",
      "New theta_0 : [ 6.42074138e-03 -7.57449844e-02  1.07548009e-01  1.40042248e-02\n",
      "  9.96540380e-02 -2.25029777e-01  2.76462525e-01  2.91470894e-04\n",
      " -3.13737418e-01  3.07947092e-01 -2.09748779e-01 -2.12856782e-01\n",
      "  9.27989038e-02 -4.42920972e-01]\n",
      "Training Error:  10.549197365899175\n",
      "====================================================================================================\n",
      "Iteration:  742\n",
      "Previous theta :  [ 6.42074138e-03 -7.57449844e-02  1.07548009e-01  1.40042248e-02\n",
      "  9.96540380e-02 -2.25029777e-01  2.76462525e-01  2.91470894e-04\n",
      " -3.13737418e-01  3.07947092e-01 -2.09748779e-01 -2.12856782e-01\n",
      "  9.27989038e-02 -4.42920972e-01]\n",
      "New theta_0 : [ 6.42017482e-03 -7.57727658e-02  1.07574016e-01  1.40324710e-02\n",
      "  9.96474458e-02 -2.25086130e-01  2.76438015e-01  3.03625871e-04\n",
      " -3.13786423e-01  3.08075839e-01 -2.09864519e-01 -2.12873353e-01\n",
      "  9.27922296e-02 -4.42927186e-01]\n",
      "Training Error:  10.549161218110008\n",
      "====================================================================================================\n",
      "Iteration:  743\n",
      "Previous theta :  [ 6.42017482e-03 -7.57727658e-02  1.07574016e-01  1.40324710e-02\n",
      "  9.96474458e-02 -2.25086130e-01  2.76438015e-01  3.03625871e-04\n",
      " -3.13786423e-01  3.08075839e-01 -2.09864519e-01 -2.12873353e-01\n",
      "  9.27922296e-02 -4.42927186e-01]\n",
      "New theta_0 : [ 6.41961129e-03 -7.58003945e-02  1.07599881e-01  1.40606883e-02\n",
      "  9.96408719e-02 -2.25142109e-01  2.76413639e-01  3.15731316e-04\n",
      " -3.13835056e-01  3.08204190e-01 -2.09980009e-01 -2.12889830e-01\n",
      "  9.27856017e-02 -4.42933385e-01]\n",
      "Training Error:  10.549125318234484\n",
      "====================================================================================================\n",
      "Iteration:  744\n",
      "Previous theta :  [ 6.41961129e-03 -7.58003945e-02  1.07599881e-01  1.40606883e-02\n",
      "  9.96408719e-02 -2.25142109e-01  2.76413639e-01  3.15731316e-04\n",
      " -3.13835056e-01  3.08204190e-01 -2.09980009e-01 -2.12889830e-01\n",
      "  9.27856017e-02 -4.42933385e-01]\n",
      "New theta_0 : [ 6.41905077e-03 -7.58278715e-02  1.07625605e-01  1.40888765e-02\n",
      "  9.96343164e-02 -2.25197716e-01  2.76389396e-01  3.27787501e-04\n",
      " -3.13883319e-01  3.08332147e-01 -2.10095249e-01 -2.12906215e-01\n",
      "  9.27790197e-02 -4.42939570e-01]\n",
      "Training Error:  10.549089664150237\n",
      "====================================================================================================\n",
      "Iteration:  745\n",
      "Previous theta :  [ 6.41905077e-03 -7.58278715e-02  1.07625605e-01  1.40888765e-02\n",
      "  9.96343164e-02 -2.25197716e-01  2.76389396e-01  3.27787501e-04\n",
      " -3.13883319e-01  3.08332147e-01 -2.10095249e-01 -2.12906215e-01\n",
      "  9.27790197e-02 -4.42939570e-01]\n",
      "New theta_0 : [ 6.41849324e-03 -7.58551977e-02  1.07651189e-01  1.41170351e-02\n",
      "  9.96277791e-02 -2.25252955e-01  2.76365286e-01  3.39794693e-04\n",
      " -3.13931217e-01  3.08459711e-01 -2.10210241e-01 -2.12922507e-01\n",
      "  9.27724832e-02 -4.42945741e-01]\n",
      "Training Error:  10.549054253757669\n",
      "====================================================================================================\n",
      "Iteration:  746\n",
      "Previous theta :  [ 6.41849324e-03 -7.58551977e-02  1.07651189e-01  1.41170351e-02\n",
      "  9.96277791e-02 -2.25252955e-01  2.76365286e-01  3.39794693e-04\n",
      " -3.13931217e-01  3.08459711e-01 -2.10210241e-01 -2.12922507e-01\n",
      "  9.27724832e-02 -4.42945741e-01]\n",
      "New theta_0 : [ 6.41793869e-03 -7.58823741e-02  1.07676633e-01  1.41451638e-02\n",
      "  9.96212600e-02 -2.25307827e-01  2.76341307e-01  3.51753158e-04\n",
      " -3.13978750e-01  3.08586884e-01 -2.10324983e-01 -2.12938708e-01\n",
      "  9.27659919e-02 -4.42951898e-01]\n",
      "Training Error:  10.549019084979676\n",
      "====================================================================================================\n",
      "Iteration:  747\n",
      "Previous theta :  [ 6.41793869e-03 -7.58823741e-02  1.07676633e-01  1.41451638e-02\n",
      "  9.96212600e-02 -2.25307827e-01  2.76341307e-01  3.51753158e-04\n",
      " -3.13978750e-01  3.08586884e-01 -2.10324983e-01 -2.12938708e-01\n",
      "  9.27659919e-02 -4.42951898e-01]\n",
      "New theta_0 : [ 6.41738709e-03 -7.59094018e-02  1.07701940e-01  1.41732622e-02\n",
      "  9.96147590e-02 -2.25362335e-01  2.76317459e-01  3.63663161e-04\n",
      " -3.14025923e-01  3.08713666e-01 -2.10439476e-01 -2.12954817e-01\n",
      "  9.27595456e-02 -4.42958042e-01]\n",
      "Training Error:  10.548984155761364\n",
      "====================================================================================================\n",
      "Iteration:  748\n",
      "Previous theta :  [ 6.41738709e-03 -7.59094018e-02  1.07701940e-01  1.41732622e-02\n",
      "  9.96147590e-02 -2.25362335e-01  2.76317459e-01  3.63663161e-04\n",
      " -3.14025923e-01  3.08713666e-01 -2.10439476e-01 -2.12954817e-01\n",
      "  9.27595456e-02 -4.42958042e-01]\n",
      "New theta_0 : [ 6.41683845e-03 -7.59362816e-02  1.07727109e-01  1.42013300e-02\n",
      "  9.96082761e-02 -2.25416482e-01  2.76293741e-01  3.75524965e-04\n",
      " -3.14072738e-01  3.08840060e-01 -2.10553721e-01 -2.12970835e-01\n",
      "  9.27531438e-02 -4.42964171e-01]\n",
      "Training Error:  10.548949464069773\n",
      "====================================================================================================\n",
      "Iteration:  749\n",
      "Previous theta :  [ 6.41683845e-03 -7.59362816e-02  1.07727109e-01  1.42013300e-02\n",
      "  9.96082761e-02 -2.25416482e-01  2.76293741e-01  3.75524965e-04\n",
      " -3.14072738e-01  3.08840060e-01 -2.10553721e-01 -2.12970835e-01\n",
      "  9.27531438e-02 -4.42964171e-01]\n",
      "New theta_0 : [ 6.41629273e-03 -7.59630145e-02  1.07752141e-01  1.42293667e-02\n",
      "  9.96018111e-02 -2.25470269e-01  2.76270151e-01  3.87338830e-04\n",
      " -3.14119197e-01  3.08966066e-01 -2.10667717e-01 -2.12986764e-01\n",
      "  9.27467863e-02 -4.42970287e-01]\n",
      "Training Error:  10.5489150078936\n",
      "====================================================================================================\n",
      "Iteration:  750\n",
      "Previous theta :  [ 6.41629273e-03 -7.59630145e-02  1.07752141e-01  1.42293667e-02\n",
      "  9.96018111e-02 -2.25470269e-01  2.76270151e-01  3.87338830e-04\n",
      " -3.14119197e-01  3.08966066e-01 -2.10667717e-01 -2.12986764e-01\n",
      "  9.27467863e-02 -4.42970287e-01]\n",
      "New theta_0 : [ 6.41574992e-03 -7.59896014e-02  1.07777038e-01  1.42573721e-02\n",
      "  9.95953642e-02 -2.25523699e-01  2.76246689e-01  3.99105016e-04\n",
      " -3.14165303e-01  3.09091687e-01 -2.10781466e-01 -2.13002602e-01\n",
      "  9.27404727e-02 -4.42976390e-01]\n",
      "Training Error:  10.548880785242927\n",
      "====================================================================================================\n",
      "Iteration:  751\n",
      "Previous theta :  [ 6.41574992e-03 -7.59896014e-02  1.07777038e-01  1.42573721e-02\n",
      "  9.95953642e-02 -2.25523699e-01  2.76246689e-01  3.99105016e-04\n",
      " -3.14165303e-01  3.09091687e-01 -2.10781466e-01 -2.13002602e-01\n",
      "  9.27404727e-02 -4.42976390e-01]\n",
      "New theta_0 : [ 6.41521000e-03 -7.60160434e-02  1.07801800e-01  1.42853459e-02\n",
      "  9.95889351e-02 -2.25576775e-01  2.76223354e-01  4.10823780e-04\n",
      " -3.14211059e-01  3.09216924e-01 -2.10894967e-01 -2.13018352e-01\n",
      "  9.27342027e-02 -4.42982478e-01]\n",
      "Training Error:  10.548846794148968\n",
      "====================================================================================================\n",
      "Iteration:  752\n",
      "Previous theta :  [ 6.41521000e-03 -7.60160434e-02  1.07801800e-01  1.42853459e-02\n",
      "  9.95889351e-02 -2.25576775e-01  2.76223354e-01  4.10823780e-04\n",
      " -3.14211059e-01  3.09216924e-01 -2.10894967e-01 -2.13018352e-01\n",
      "  9.27342027e-02 -4.42982478e-01]\n",
      "New theta_0 : [ 6.41467297e-03 -7.60423412e-02  1.07826428e-01  1.43132875e-02\n",
      "  9.95825239e-02 -2.25629500e-01  2.76200146e-01  4.22495377e-04\n",
      " -3.14256467e-01  3.09341777e-01 -2.11008221e-01 -2.13034013e-01\n",
      "  9.27279759e-02 -4.42988554e-01]\n",
      "Training Error:  10.548813032663787\n",
      "====================================================================================================\n",
      "Iteration:  753\n",
      "Previous theta :  [ 6.41467297e-03 -7.60423412e-02  1.07826428e-01  1.43132875e-02\n",
      "  9.95825239e-02 -2.25629500e-01  2.76200146e-01  4.22495377e-04\n",
      " -3.14256467e-01  3.09341777e-01 -2.11008221e-01 -2.13034013e-01\n",
      "  9.27279759e-02 -4.42988554e-01]\n",
      "New theta_0 : [ 6.41413880e-03 -7.60684959e-02  1.07850923e-01  1.43411969e-02\n",
      "  9.95761304e-02 -2.25681874e-01  2.76177062e-01  4.34120061e-04\n",
      " -3.14301530e-01  3.09466250e-01 -2.11121228e-01 -2.13049587e-01\n",
      "  9.27217922e-02 -4.42994616e-01]\n",
      "Training Error:  10.54877949886005\n",
      "====================================================================================================\n",
      "Iteration:  754\n",
      "Previous theta :  [ 6.41413880e-03 -7.60684959e-02  1.07850923e-01  1.43411969e-02\n",
      "  9.95761304e-02 -2.25681874e-01  2.76177062e-01  4.34120061e-04\n",
      " -3.14301530e-01  3.09466250e-01 -2.11121228e-01 -2.13049587e-01\n",
      "  9.27217922e-02 -4.42994616e-01]\n",
      "New theta_0 : [ 0.00641361 -0.07609451  0.10787529  0.01436907  0.09956975 -0.2257339\n",
      "  0.2761541   0.0004457  -0.31434625  0.30959034 -0.21123399 -0.21306507\n",
      "  0.09271565 -0.44300067]\n",
      "Training Error:  10.548746190830771\n",
      "====================================================================================================\n",
      "Iteration:  755\n",
      "Previous theta :  [ 0.00641361 -0.07609451  0.10787529  0.01436907  0.09956975 -0.2257339\n",
      "  0.2761541   0.0004457  -0.31434625  0.30959034 -0.21123399 -0.21306507\n",
      "  0.09271565 -0.44300067]\n",
      "New theta_0 : [ 0.00641308 -0.07612038  0.10789952  0.01439692  0.0995634  -0.22578558\n",
      "  0.27613127  0.00045723 -0.31439063  0.30971406 -0.2113465  -0.21308047\n",
      "  0.09270955 -0.4430067 ]\n",
      "Training Error:  10.548713106689052\n",
      "====================================================================================================\n",
      "Iteration:  756\n",
      "Previous theta :  [ 0.00641308 -0.07612038  0.10789952  0.01439692  0.0995634  -0.22578558\n",
      "  0.27613127  0.00045723 -0.31439063  0.30971406 -0.2113465  -0.21308047\n",
      "  0.09270955 -0.4430067 ]\n",
      "New theta_0 : [ 0.00641255 -0.07614611  0.10792362  0.01442473  0.09955706 -0.22583692\n",
      "  0.27610856  0.00046872 -0.31443467  0.30983739 -0.21145877 -0.21309578\n",
      "  0.0927035  -0.44301272]\n",
      "Training Error:  10.548680244567835\n",
      "====================================================================================================\n",
      "Iteration:  757\n",
      "Previous theta :  [ 0.00641255 -0.07614611  0.10792362  0.01442473  0.09955706 -0.22583692\n",
      "  0.27610856  0.00046872 -0.31443467  0.30983739 -0.21145877 -0.21309578\n",
      "  0.0927035  -0.44301272]\n",
      "New theta_0 : [ 0.00641203 -0.0761717   0.10794759  0.0144525   0.09955073 -0.22588792\n",
      "  0.27608597  0.00048015 -0.31447838  0.30996035 -0.21157079 -0.21311101\n",
      "  0.09269748 -0.44301873]\n",
      "Training Error:  10.548647602619667\n",
      "====================================================================================================\n",
      "Iteration:  758\n",
      "Previous theta :  [ 0.00641203 -0.0761717   0.10794759  0.0144525   0.09955073 -0.22588792\n",
      "  0.27608597  0.00048015 -0.31447838  0.30996035 -0.21157079 -0.21311101\n",
      "  0.09269748 -0.44301873]\n",
      "New theta_0 : [ 0.00641151 -0.07619715  0.10797144  0.01448025  0.09954443 -0.22593858\n",
      "  0.2760635   0.00049155 -0.31452176  0.31008294 -0.21168257 -0.21312615\n",
      "  0.09269151 -0.44302473]\n",
      "Training Error:  10.548615179016444\n",
      "====================================================================================================\n",
      "Iteration:  759\n",
      "Previous theta :  [ 0.00641151 -0.07619715  0.10797144  0.01448025  0.09954443 -0.22593858\n",
      "  0.2760635   0.00049155 -0.31452176  0.31008294 -0.21168257 -0.21312615\n",
      "  0.09269151 -0.44302473]\n",
      "New theta_0 : [ 0.00641099 -0.07622247  0.10799515  0.01450796  0.09953814 -0.22598891\n",
      "  0.27604115  0.0005029  -0.3145648   0.31020515 -0.2117941  -0.21314121\n",
      "  0.09268557 -0.44303072]\n",
      "Training Error:  10.54858297194918\n",
      "====================================================================================================\n",
      "Iteration:  760\n",
      "Previous theta :  [ 0.00641099 -0.07622247  0.10799515  0.01450796  0.09953814 -0.22598891\n",
      "  0.27604115  0.0005029  -0.3145648   0.31020515 -0.2117941  -0.21314121\n",
      "  0.09268557 -0.44303072]\n",
      "New theta_0 : [ 0.00641048 -0.07624765  0.10801874  0.01453563  0.09953187 -0.2260389\n",
      "  0.27601892  0.0005142  -0.31460752  0.31032699 -0.21190538 -0.21315618\n",
      "  0.09267968 -0.44303669]\n",
      "Training Error:  10.54855097962777\n",
      "====================================================================================================\n",
      "Iteration:  761\n",
      "Previous theta :  [ 0.00641048 -0.07624765  0.10801874  0.01453563  0.09953187 -0.2260389\n",
      "  0.27601892  0.0005142  -0.31460752  0.31032699 -0.21190538 -0.21315618\n",
      "  0.09267968 -0.44303669]\n",
      "New theta_0 : [ 0.00640997 -0.07627269  0.1080422   0.01456327  0.09952562 -0.22608856\n",
      "  0.27599681  0.00052546 -0.31464991  0.31044846 -0.21201642 -0.21317107\n",
      "  0.09267383 -0.44304265]\n",
      "Training Error:  10.548519200280754\n",
      "====================================================================================================\n",
      "Iteration:  762\n",
      "Previous theta :  [ 0.00640997 -0.07627269  0.1080422   0.01456327  0.09952562 -0.22608856\n",
      "  0.27599681  0.00052546 -0.31464991  0.31044846 -0.21201642 -0.21317107\n",
      "  0.09267383 -0.44304265]\n",
      "New theta_0 : [ 0.00640946 -0.0762976   0.10806554  0.01459087  0.09951938 -0.22613789\n",
      "  0.27597481  0.00053667 -0.31469198  0.31056956 -0.21212722 -0.21318588\n",
      "  0.09266802 -0.44304859]\n",
      "Training Error:  10.548487632155092\n",
      "====================================================================================================\n",
      "Iteration:  763\n",
      "Previous theta :  [ 0.00640946 -0.0762976   0.10806554  0.01459087  0.09951938 -0.22613789\n",
      "  0.27597481  0.00053667 -0.31469198  0.31056956 -0.21212722 -0.21318588\n",
      "  0.09266802 -0.44304859]\n",
      "New theta_0 : [ 0.00640895 -0.07632237  0.10808875  0.01461844  0.09951316 -0.22618689\n",
      "  0.27595294  0.00054784 -0.31473373  0.31069029 -0.21223777 -0.2132006\n",
      "  0.09266225 -0.44305453]\n",
      "Training Error:  10.548456273515937\n",
      "====================================================================================================\n",
      "Iteration:  764\n",
      "Previous theta :  [ 0.00640895 -0.07632237  0.10808875  0.01461844  0.09951316 -0.22618689\n",
      "  0.27595294  0.00054784 -0.31473373  0.31069029 -0.21223777 -0.2132006\n",
      "  0.09266225 -0.44305453]\n",
      "New theta_0 : [ 0.00640845 -0.07634701  0.10811184  0.01464597  0.09950696 -0.22623557\n",
      "  0.27593118  0.00055897 -0.31477517  0.31081066 -0.21234808 -0.21321524\n",
      "  0.09265652 -0.44306045]\n",
      "Training Error:  10.548425122646409\n",
      "====================================================================================================\n",
      "Iteration:  765\n",
      "Previous theta :  [ 0.00640845 -0.07634701  0.10811184  0.01464597  0.09950696 -0.22623557\n",
      "  0.27593118  0.00055897 -0.31477517  0.31081066 -0.21234808 -0.21321524\n",
      "  0.09265652 -0.44306045]\n",
      "New theta_0 : [ 0.00640795 -0.07637151  0.1081348   0.01467347  0.09950078 -0.22628393\n",
      "  0.27590953  0.00057005 -0.31481628  0.31093066 -0.21245815 -0.2132298\n",
      "  0.09265083 -0.44306636]\n",
      "Training Error:  10.548394177847372\n",
      "====================================================================================================\n",
      "Iteration:  766\n",
      "Previous theta :  [ 0.00640795 -0.07637151  0.1081348   0.01467347  0.09950078 -0.22628393\n",
      "  0.27590953  0.00057005 -0.31481628  0.31093066 -0.21245815 -0.2132298\n",
      "  0.09265083 -0.44306636]\n",
      "New theta_0 : [ 0.00640745 -0.07639589  0.10815765  0.01470093  0.09949461 -0.22633196\n",
      "  0.275888    0.00058108 -0.31485709  0.3110503  -0.21256797 -0.21324428\n",
      "  0.09264517 -0.44307226]\n",
      "Training Error:  10.548363437437226\n",
      "====================================================================================================\n",
      "Iteration:  767\n",
      "Previous theta :  [ 0.00640745 -0.07639589  0.10815765  0.01470093  0.09949461 -0.22633196\n",
      "  0.275888    0.00058108 -0.31485709  0.3110503  -0.21256797 -0.21324428\n",
      "  0.09264517 -0.44307226]\n",
      "New theta_0 : [ 0.00640695 -0.07642013  0.10818037  0.01472836  0.09948846 -0.22637968\n",
      "  0.27586659  0.00059208 -0.31489758  0.31116958 -0.21267755 -0.21325867\n",
      "  0.09263956 -0.44307814]\n",
      "Training Error:  10.54833289975169\n",
      "====================================================================================================\n",
      "Iteration:  768\n",
      "Previous theta :  [ 0.00640695 -0.07642013  0.10818037  0.01472836  0.09948846 -0.22637968\n",
      "  0.27586659  0.00059208 -0.31489758  0.31116958 -0.21267755 -0.21325867\n",
      "  0.09263956 -0.44307814]\n",
      "New theta_0 : [ 0.00640646 -0.07644425  0.10820297  0.01475574  0.09948232 -0.22642708\n",
      "  0.27584528  0.00060303 -0.31493776  0.31128849 -0.21278689 -0.21327299\n",
      "  0.09263398 -0.44308401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.548302563143578\n",
      "====================================================================================================\n",
      "Iteration:  769\n",
      "Previous theta :  [ 0.00640646 -0.07644425  0.10820297  0.01475574  0.09948232 -0.22642708\n",
      "  0.27584528  0.00060303 -0.31493776  0.31128849 -0.21278689 -0.21327299\n",
      "  0.09263398 -0.44308401]\n",
      "New theta_0 : [ 0.00640597 -0.07646823  0.10822545  0.01478309  0.09947621 -0.22647417\n",
      "  0.27582409  0.00061394 -0.31497764  0.31140705 -0.21289599 -0.21328723\n",
      "  0.09262845 -0.44308987]\n",
      "Training Error:  10.548272425982606\n",
      "====================================================================================================\n",
      "Iteration:  770\n",
      "Previous theta :  [ 0.00640597 -0.07646823  0.10822545  0.01478309  0.09947621 -0.22647417\n",
      "  0.27582409  0.00061394 -0.31497764  0.31140705 -0.21289599 -0.21328723\n",
      "  0.09262845 -0.44308987]\n",
      "New theta_0 : [ 0.00640548 -0.07649209  0.10824782  0.01481041  0.09947011 -0.22652094\n",
      "  0.27580302  0.0006248  -0.31501721  0.31152524 -0.21300484 -0.21330139\n",
      "  0.09262295 -0.44309572]\n",
      "Training Error:  10.548242486655182\n",
      "====================================================================================================\n",
      "Iteration:  771\n",
      "Previous theta :  [ 0.00640548 -0.07649209  0.10824782  0.01481041  0.09947011 -0.22652094\n",
      "  0.27580302  0.0006248  -0.31501721  0.31152524 -0.21300484 -0.21330139\n",
      "  0.09262295 -0.44309572]\n",
      "New theta_0 : [ 0.006405   -0.07651582  0.10827006  0.01483768  0.09946403 -0.22656741\n",
      "  0.27578205  0.00063562 -0.31505648  0.31164308 -0.21311345 -0.21331547\n",
      "  0.09261748 -0.44310156]\n",
      "Training Error:  10.548212743564196\n",
      "====================================================================================================\n",
      "Iteration:  772\n",
      "Previous theta :  [ 0.006405   -0.07651582  0.10827006  0.01483768  0.09946403 -0.22656741\n",
      "  0.27578205  0.00063562 -0.31505648  0.31164308 -0.21311345 -0.21331547\n",
      "  0.09261748 -0.44310156]\n",
      "New theta_0 : [ 0.00640451 -0.07653942  0.10829219  0.01486492  0.09945796 -0.22661356\n",
      "  0.27576119  0.0006464  -0.31509546  0.31176056 -0.21322182 -0.21332947\n",
      "  0.09261206 -0.44310738]\n",
      "Training Error:  10.548183195128827\n",
      "====================================================================================================\n",
      "Iteration:  773\n",
      "Previous theta :  [ 0.00640451 -0.07653942  0.10829219  0.01486492  0.09945796 -0.22661356\n",
      "  0.27576119  0.0006464  -0.31509546  0.31176056 -0.21322182 -0.21332947\n",
      "  0.09261206 -0.44310738]\n",
      "New theta_0 : [ 0.00640403 -0.0765629   0.1083142   0.01489212  0.09945191 -0.22665942\n",
      "  0.27574044  0.00065714 -0.31513413  0.31187769 -0.21332995 -0.21334339\n",
      "  0.09260667 -0.4431132 ]\n",
      "Training Error:  10.548153839784339\n",
      "====================================================================================================\n",
      "Iteration:  774\n",
      "Previous theta :  [ 0.00640403 -0.0765629   0.1083142   0.01489212  0.09945191 -0.22665942\n",
      "  0.27574044  0.00065714 -0.31513413  0.31187769 -0.21332995 -0.21334339\n",
      "  0.09260667 -0.4431132 ]\n",
      "New theta_0 : [ 0.00640356 -0.07658625  0.10833609  0.01491928  0.09944588 -0.22670496\n",
      "  0.27571981  0.00066783 -0.31517251  0.31199447 -0.21343784 -0.21335724\n",
      "  0.09260132 -0.443119  ]\n",
      "Training Error:  10.548124675981894\n",
      "====================================================================================================\n",
      "Iteration:  775\n",
      "Previous theta :  [ 0.00640356 -0.07658625  0.10833609  0.01491928  0.09944588 -0.22670496\n",
      "  0.27571981  0.00066783 -0.31517251  0.31199447 -0.21343784 -0.21335724\n",
      "  0.09260132 -0.443119  ]\n",
      "New theta_0 : [ 0.00640308 -0.07660948  0.10835787  0.0149464   0.09943986 -0.22675021\n",
      "  0.27569927  0.00067849 -0.3152106   0.31211089 -0.21354549 -0.213371\n",
      "  0.09259601 -0.44312479]\n",
      "Training Error:  10.548095702188348\n",
      "====================================================================================================\n",
      "Iteration:  776\n",
      "Previous theta :  [ 0.00640308 -0.07660948  0.10835787  0.0149464   0.09943986 -0.22675021\n",
      "  0.27569927  0.00067849 -0.3152106   0.31211089 -0.21354549 -0.213371\n",
      "  0.09259601 -0.44312479]\n",
      "New theta_0 : [ 0.00640261 -0.07663258  0.10837953  0.01497349  0.09943386 -0.22679516\n",
      "  0.27567885  0.0006891  -0.31524839  0.31222696 -0.2136529  -0.2133847\n",
      "  0.09259073 -0.44313057]\n",
      "Training Error:  10.548066916886077\n",
      "====================================================================================================\n",
      "Iteration:  777\n",
      "Previous theta :  [ 0.00640261 -0.07663258  0.10837953  0.01497349  0.09943386 -0.22679516\n",
      "  0.27567885  0.0006891  -0.31524839  0.31222696 -0.2136529  -0.2133847\n",
      "  0.09259073 -0.44313057]\n",
      "New theta_0 : [ 0.00640214 -0.07665556  0.10840108  0.01500053  0.09942788 -0.2268398\n",
      "  0.27565853  0.00069967 -0.3152859   0.31234268 -0.21376007 -0.21339831\n",
      "  0.09258549 -0.44313633]\n",
      "Training Error:  10.548038318572775\n",
      "====================================================================================================\n",
      "Iteration:  778\n",
      "Previous theta :  [ 0.00640214 -0.07665556  0.10840108  0.01500053  0.09942788 -0.2268398\n",
      "  0.27565853  0.00069967 -0.3152859   0.31234268 -0.21376007 -0.21339831\n",
      "  0.09258549 -0.44313633]\n",
      "New theta_0 : [ 0.00640167 -0.07667842  0.10842252  0.01502754  0.09942191 -0.22688416\n",
      "  0.27563832  0.0007102  -0.31532312  0.31245806 -0.21386701 -0.21341186\n",
      "  0.09258028 -0.44314209]\n",
      "Training Error:  10.548009905761273\n",
      "====================================================================================================\n",
      "Iteration:  779\n",
      "Previous theta :  [ 0.00640167 -0.07667842  0.10842252  0.01502754  0.09942191 -0.22688416\n",
      "  0.27563832  0.0007102  -0.31532312  0.31245806 -0.21386701 -0.21341186\n",
      "  0.09258028 -0.44314209]\n",
      "New theta_0 : [ 0.00640121 -0.07670116  0.10844385  0.01505451  0.09941596 -0.22692822\n",
      "  0.27561822  0.00072069 -0.31536006  0.31257308 -0.2139737  -0.21342532\n",
      "  0.09257511 -0.44314783]\n",
      "Training Error:  10.547981676979358\n",
      "====================================================================================================\n",
      "Iteration:  780\n",
      "Previous theta :  [ 0.00640121 -0.07670116  0.10844385  0.01505451  0.09941596 -0.22692822\n",
      "  0.27561822  0.00072069 -0.31536006  0.31257308 -0.2139737  -0.21342532\n",
      "  0.09257511 -0.44314783]\n",
      "New theta_0 : [ 0.00640074 -0.07672377  0.10846506  0.01508143  0.09941003 -0.22697198\n",
      "  0.27559822  0.00073114 -0.31539672  0.31268777 -0.21408015 -0.21343871\n",
      "  0.09256998 -0.44315356]\n",
      "Training Error:  10.547953630769598\n",
      "====================================================================================================\n",
      "Iteration:  781\n",
      "Previous theta :  [ 0.00640074 -0.07672377  0.10846506  0.01508143  0.09941003 -0.22697198\n",
      "  0.27559822  0.00073114 -0.31539672  0.31268777 -0.21408015 -0.21343871\n",
      "  0.09256998 -0.44315356]\n",
      "New theta_0 : [ 0.00640028 -0.07674627  0.10848616  0.01510832  0.09940411 -0.22701546\n",
      "  0.27557832  0.00074154 -0.31543309  0.3128021  -0.21418637 -0.21345203\n",
      "  0.09256488 -0.44315929]\n",
      "Training Error:  10.547925765689152\n",
      "====================================================================================================\n",
      "Iteration:  782\n",
      "Previous theta :  [ 0.00640028 -0.07674627  0.10848616  0.01510832  0.09940411 -0.22701546\n",
      "  0.27557832  0.00074154 -0.31543309  0.3128021  -0.21418637 -0.21345203\n",
      "  0.09256488 -0.44315929]\n",
      "New theta_0 : [ 0.00639983 -0.07676865  0.10850715  0.01513517  0.09939821 -0.22705865\n",
      "  0.27555852  0.00075191 -0.31546919  0.31291609 -0.21429235 -0.21346527\n",
      "  0.09255981 -0.443165  ]\n",
      "Training Error:  10.547898080309608\n",
      "====================================================================================================\n",
      "Iteration:  783\n",
      "Previous theta :  [ 0.00639983 -0.07676865  0.10850715  0.01513517  0.09939821 -0.22705865\n",
      "  0.27555852  0.00075191 -0.31546919  0.31291609 -0.21429235 -0.21346527\n",
      "  0.09255981 -0.443165  ]\n",
      "New theta_0 : [ 0.00639937 -0.07679091  0.10852804  0.01516198  0.09939232 -0.22710155\n",
      "  0.27553883  0.00076224 -0.31550501  0.31302975 -0.21439809 -0.21347845\n",
      "  0.09255478 -0.44317069]\n",
      "Training Error:  10.547870573216798\n",
      "====================================================================================================\n",
      "Iteration:  784\n",
      "Previous theta :  [ 0.00639937 -0.07679091  0.10852804  0.01516198  0.09939232 -0.22710155\n",
      "  0.27553883  0.00076224 -0.31550501  0.31302975 -0.21439809 -0.21347845\n",
      "  0.09255478 -0.44317069]\n",
      "New theta_0 : [ 0.00639892 -0.07681305  0.10854881  0.01518874  0.09938645 -0.22714417\n",
      "  0.27551924  0.00077253 -0.31554056  0.31314306 -0.21450359 -0.21349154\n",
      "  0.09254978 -0.44317638]\n",
      "Training Error:  10.54784324301064\n",
      "====================================================================================================\n",
      "Iteration:  785\n",
      "Previous theta :  [ 0.00639892 -0.07681305  0.10854881  0.01518874  0.09938645 -0.22714417\n",
      "  0.27551924  0.00077253 -0.31554056  0.31314306 -0.21450359 -0.21349154\n",
      "  0.09254978 -0.44317638]\n",
      "New theta_0 : [ 0.00639847 -0.07683508  0.10856948  0.01521547  0.0993806  -0.22718651\n",
      "  0.27549975  0.00078277 -0.31557583  0.31325603 -0.21460886 -0.21350457\n",
      "  0.09254482 -0.44318206]\n",
      "Training Error:  10.547816088304955\n",
      "====================================================================================================\n",
      "Iteration:  786\n",
      "Previous theta :  [ 0.00639847 -0.07683508  0.10856948  0.01521547  0.0993806  -0.22718651\n",
      "  0.27549975  0.00078277 -0.31557583  0.31325603 -0.21460886 -0.21350457\n",
      "  0.09254482 -0.44318206]\n",
      "New theta_0 : [ 0.00639802 -0.07685699  0.10859003  0.01524215  0.09937476 -0.22722857\n",
      "  0.27548036  0.00079298 -0.31561084  0.31336866 -0.21471389 -0.21351752\n",
      "  0.09253989 -0.44318772]\n",
      "Training Error:  10.547789107727315\n",
      "====================================================================================================\n",
      "Iteration:  787\n",
      "Previous theta :  [ 0.00639802 -0.07685699  0.10859003  0.01524215  0.09937476 -0.22722857\n",
      "  0.27548036  0.00079298 -0.31561084  0.31336866 -0.21471389 -0.21351752\n",
      "  0.09253989 -0.44318772]\n",
      "New theta_0 : [ 0.00639757 -0.07687878  0.10861049  0.0152688   0.09936894 -0.22727035\n",
      "  0.27546107  0.00080315 -0.31564558  0.31348095 -0.21481868 -0.21353041\n",
      "  0.092535   -0.44319338]\n",
      "Training Error:  10.54776229991887\n",
      "====================================================================================================\n",
      "Iteration:  788\n",
      "Previous theta :  [ 0.00639757 -0.07687878  0.10861049  0.0152688   0.09936894 -0.22727035\n",
      "  0.27546107  0.00080315 -0.31564558  0.31348095 -0.21481868 -0.21353041\n",
      "  0.092535   -0.44319338]\n",
      "New theta_0 : [ 0.00639713 -0.07690046  0.10863083  0.0152954   0.09936314 -0.22731185\n",
      "  0.27544188  0.00081328 -0.31568005  0.31359291 -0.21492324 -0.21354322\n",
      "  0.09253013 -0.44319902]\n",
      "Training Error:  10.547735663534187\n",
      "====================================================================================================\n",
      "Iteration:  789\n",
      "Previous theta :  [ 0.00639713 -0.07690046  0.10863083  0.0152954   0.09936314 -0.22731185\n",
      "  0.27544188  0.00081328 -0.31568005  0.31359291 -0.21492324 -0.21354322\n",
      "  0.09253013 -0.44319902]\n",
      "New theta_0 : [ 0.00639669 -0.07692203  0.10865107  0.01532196  0.09935735 -0.22735308\n",
      "  0.27542279  0.00082337 -0.31571426  0.31370453 -0.21502756 -0.21355596\n",
      "  0.0925253  -0.44320465]\n",
      "Training Error:  10.547709197241097\n",
      "====================================================================================================\n",
      "Iteration:  790\n",
      "Previous theta :  [ 0.00639669 -0.07692203  0.10865107  0.01532196  0.09935735 -0.22735308\n",
      "  0.27542279  0.00082337 -0.31571426  0.31370453 -0.21502756 -0.21355596\n",
      "  0.0925253  -0.44320465]\n",
      "New theta_0 : [ 0.00639625 -0.07694348  0.10867121  0.01534848  0.09935157 -0.22739403\n",
      "  0.2754038   0.00083343 -0.3157482   0.31381582 -0.21513165 -0.21356863\n",
      "  0.09252051 -0.44321028]\n",
      "Training Error:  10.547682899720527\n",
      "====================================================================================================\n",
      "Iteration:  791\n",
      "Previous theta :  [ 0.00639625 -0.07694348  0.10867121  0.01534848  0.09935157 -0.22739403\n",
      "  0.2754038   0.00083343 -0.3157482   0.31381582 -0.21513165 -0.21356863\n",
      "  0.09252051 -0.44321028]\n",
      "New theta_0 : [ 0.00639581 -0.07696482  0.10869124  0.01537496  0.09934582 -0.22743472\n",
      "  0.2753849   0.00084344 -0.31578189  0.31392678 -0.2152355  -0.21358123\n",
      "  0.09251574 -0.44321589]\n",
      "Training Error:  10.547656769666354\n",
      "====================================================================================================\n",
      "Iteration:  792\n",
      "Previous theta :  [ 0.00639581 -0.07696482  0.10869124  0.01537496  0.09934582 -0.22743472\n",
      "  0.2753849   0.00084344 -0.31578189  0.31392678 -0.2152355  -0.21358123\n",
      "  0.09251574 -0.44321589]\n",
      "New theta_0 : [ 0.00639538 -0.07698605  0.10871117  0.0154014   0.09934007 -0.22747513\n",
      "  0.2753661   0.00085342 -0.31581532  0.3140374  -0.21533912 -0.21359376\n",
      "  0.09251101 -0.44322149]\n",
      "Training Error:  10.547630805785246\n",
      "====================================================================================================\n",
      "Iteration:  793\n",
      "Previous theta :  [ 0.00639538 -0.07698605  0.10871117  0.0154014   0.09934007 -0.22747513\n",
      "  0.2753661   0.00085342 -0.31581532  0.3140374  -0.21533912 -0.21359376\n",
      "  0.09251101 -0.44322149]\n",
      "New theta_0 : [ 0.00639495 -0.07700717  0.10873099  0.01542779  0.09933435 -0.22751528\n",
      "  0.2753474   0.00086335 -0.31584849  0.3141477  -0.2154425  -0.21360622\n",
      "  0.09250631 -0.44322708]\n",
      "Training Error:  10.547605006796513\n",
      "====================================================================================================\n",
      "Iteration:  794\n",
      "Previous theta :  [ 0.00639495 -0.07700717  0.10873099  0.01542779  0.09933435 -0.22751528\n",
      "  0.2753474   0.00086335 -0.31584849  0.3141477  -0.2154425  -0.21360622\n",
      "  0.09250631 -0.44322708]\n",
      "New theta_0 : [ 0.00639452 -0.07702818  0.10875072  0.01545414  0.09932864 -0.22755516\n",
      "  0.27532879  0.00087325 -0.31588141  0.31425766 -0.21554566 -0.21361862\n",
      "  0.09250165 -0.44323265]\n",
      "Training Error:  10.547579371431958\n",
      "====================================================================================================\n",
      "Iteration:  795\n",
      "Previous theta :  [ 0.00639452 -0.07702818  0.10875072  0.01545414  0.09932864 -0.22755516\n",
      "  0.27532879  0.00087325 -0.31588141  0.31425766 -0.21554566 -0.21361862\n",
      "  0.09250165 -0.44323265]\n",
      "New theta_0 : [ 0.00639409 -0.07704908  0.10877034  0.01548045  0.09932294 -0.22759478\n",
      "  0.27531027  0.00088312 -0.31591407  0.3143673  -0.21564857 -0.21363095\n",
      "  0.09249701 -0.44323822]\n",
      "Training Error:  10.547553898435723\n",
      "====================================================================================================\n",
      "Iteration:  796\n",
      "Previous theta :  [ 0.00639409 -0.07704908  0.10877034  0.01548045  0.09932294 -0.22759478\n",
      "  0.27531027  0.00088312 -0.31591407  0.3143673  -0.21564857 -0.21363095\n",
      "  0.09249701 -0.44323822]\n",
      "New theta_0 : [ 0.00639367 -0.07706987  0.10878986  0.01550672  0.09931726 -0.22763414\n",
      "  0.27529185  0.00089294 -0.31594649  0.31447661 -0.21575126 -0.2136432\n",
      "  0.09249241 -0.44324378]\n",
      "Training Error:  10.547528586564157\n",
      "====================================================================================================\n",
      "Iteration:  797\n",
      "Previous theta :  [ 0.00639367 -0.07706987  0.10878986  0.01550672  0.09931726 -0.22763414\n",
      "  0.27529185  0.00089294 -0.31594649  0.31447661 -0.21575126 -0.2136432\n",
      "  0.09249241 -0.44324378]\n",
      "New theta_0 : [ 0.00639325 -0.07709055  0.10880928  0.01553294  0.0993116  -0.22767323\n",
      "  0.27527353  0.00090273 -0.31597866  0.3145856  -0.21585371 -0.2136554\n",
      "  0.09248783 -0.44324933]\n",
      "Training Error:  10.54750343458566\n",
      "====================================================================================================\n",
      "Iteration:  798\n",
      "Previous theta :  [ 0.00639325 -0.07709055  0.10880928  0.01553294  0.0993116  -0.22767323\n",
      "  0.27527353  0.00090273 -0.31597866  0.3145856  -0.21585371 -0.2136554\n",
      "  0.09248783 -0.44324933]\n",
      "New theta_0 : [ 0.00639282 -0.07711112  0.1088286   0.01555912  0.09930595 -0.22771207\n",
      "  0.27525529  0.00091248 -0.31601058  0.31469426 -0.21595593 -0.21366752\n",
      "  0.09248329 -0.44325486]\n",
      "Training Error:  10.547478441280546\n",
      "====================================================================================================\n",
      "Iteration:  799\n",
      "Previous theta :  [ 0.00639282 -0.07711112  0.1088286   0.01555912  0.09930595 -0.22771207\n",
      "  0.27525529  0.00091248 -0.31601058  0.31469426 -0.21595593 -0.21366752\n",
      "  0.09248329 -0.44325486]\n",
      "New theta_0 : [ 0.00639241 -0.07713159  0.10884782  0.01558526  0.09930032 -0.22775065\n",
      "  0.27523715  0.00092219 -0.31604225  0.3148026  -0.21605792 -0.21367958\n",
      "  0.09247878 -0.44326039]\n",
      "Training Error:  10.547453605440902\n",
      "====================================================================================================\n",
      "Iteration:  800\n",
      "Previous theta :  [ 0.00639241 -0.07713159  0.10884782  0.01558526  0.09930032 -0.22775065\n",
      "  0.27523715  0.00092219 -0.31604225  0.3148026  -0.21605792 -0.21367958\n",
      "  0.09247878 -0.44326039]\n",
      "New theta_0 : [ 0.00639199 -0.07715195  0.10886695  0.01561136  0.0992947  -0.22778897\n",
      "  0.2752191   0.00093187 -0.31607369  0.31491061 -0.21615967 -0.21369157\n",
      "  0.0924743  -0.44326591]\n",
      "Training Error:  10.547428925870452\n",
      "====================================================================================================\n",
      "Iteration:  801\n",
      "Previous theta :  [ 0.00639199 -0.07715195  0.10886695  0.01561136  0.0992947  -0.22778897\n",
      "  0.2752191   0.00093187 -0.31607369  0.31491061 -0.21615967 -0.21369157\n",
      "  0.0924743  -0.44326591]\n",
      "New theta_0 : [ 0.00639158 -0.07717221  0.10888597  0.01563741  0.0992891  -0.22782705\n",
      "  0.27520114  0.00094151 -0.31610488  0.31501831 -0.2162612  -0.2137035\n",
      "  0.09246985 -0.44327141]\n",
      "Training Error:  10.547404401384421\n",
      "====================================================================================================\n",
      "Iteration:  802\n",
      "Previous theta :  [ 0.00639158 -0.07717221  0.10888597  0.01563741  0.0992891  -0.22782705\n",
      "  0.27520114  0.00094151 -0.31610488  0.31501831 -0.2162612  -0.2137035\n",
      "  0.09246985 -0.44327141]\n",
      "New theta_0 : [ 0.00639117 -0.07719236  0.1089049   0.01566342  0.09928351 -0.22786487\n",
      "  0.27518327  0.00095112 -0.31613583  0.31512568 -0.21636249 -0.21371536\n",
      "  0.09246542 -0.44327691]\n",
      "Training Error:  10.547380030809398\n",
      "====================================================================================================\n",
      "Iteration:  803\n",
      "Previous theta :  [ 0.00639117 -0.07719236  0.1089049   0.01566342  0.09928351 -0.22786487\n",
      "  0.27518327  0.00095112 -0.31613583  0.31512568 -0.21636249 -0.21371536\n",
      "  0.09246542 -0.44327691]\n",
      "New theta_0 : [ 0.00639076 -0.07721241  0.10892374  0.01568938  0.09927794 -0.22790244\n",
      "  0.27516549  0.00096068 -0.31616655  0.31523274 -0.21646355 -0.21372716\n",
      "  0.09246103 -0.44328239]\n",
      "Training Error:  10.547355812983204\n",
      "====================================================================================================\n",
      "Iteration:  804\n",
      "Previous theta :  [ 0.00639076 -0.07721241  0.10892374  0.01568938  0.09927794 -0.22790244\n",
      "  0.27516549  0.00096068 -0.31616655  0.31523274 -0.21646355 -0.21372716\n",
      "  0.09246103 -0.44328239]\n",
      "New theta_0 : [ 0.00639035 -0.07723235  0.10894247  0.0157153   0.09927238 -0.22793976\n",
      "  0.2751478   0.00097022 -0.31619702  0.31533947 -0.21656439 -0.21373889\n",
      "  0.09245667 -0.44328787]\n",
      "Training Error:  10.547331746754763\n",
      "====================================================================================================\n",
      "Iteration:  805\n",
      "Previous theta :  [ 0.00639035 -0.07723235  0.10894247  0.0157153   0.09927238 -0.22793976\n",
      "  0.2751478   0.00097022 -0.31619702  0.31533947 -0.21656439 -0.21373889\n",
      "  0.09245667 -0.44328787]\n",
      "New theta_0 : [ 0.00638994 -0.07725219  0.10896112  0.01574118  0.09926684 -0.22797683\n",
      "  0.2751302   0.00097971 -0.31622727  0.3154459  -0.21666499 -0.21375056\n",
      "  0.09245234 -0.44329333]\n",
      "Training Error:  10.547307830983971\n",
      "====================================================================================================\n",
      "Iteration:  806\n",
      "Previous theta :  [ 0.00638994 -0.07725219  0.10896112  0.01574118  0.09926684 -0.22797683\n",
      "  0.2751302   0.00097971 -0.31622727  0.3154459  -0.21666499 -0.21375056\n",
      "  0.09245234 -0.44329333]\n",
      "New theta_0 : [ 0.00638954 -0.07727193  0.10897966  0.01576701  0.09926132 -0.22801366\n",
      "  0.27511269  0.00098917 -0.31625728  0.315552   -0.21676536 -0.21376216\n",
      "  0.09244804 -0.44329879]\n",
      "Training Error:  10.54728406454157\n",
      "====================================================================================================\n",
      "Iteration:  807\n",
      "Previous theta :  [ 0.00638954 -0.07727193  0.10897966  0.01576701  0.09926132 -0.22801366\n",
      "  0.27511269  0.00098917 -0.31625728  0.315552   -0.21676536 -0.21376216\n",
      "  0.09244804 -0.44329879]\n",
      "New theta_0 : [ 0.00638914 -0.07729156  0.10899812  0.0157928   0.0992558  -0.22805025\n",
      "  0.27509526  0.0009986  -0.31628706  0.31565779 -0.21686551 -0.21377371\n",
      "  0.09244376 -0.44330423]\n",
      "Training Error:  10.54726044630902\n",
      "====================================================================================================\n",
      "Iteration:  808\n",
      "Previous theta :  [ 0.00638914 -0.07729156  0.10899812  0.0157928   0.0992558  -0.22805025\n",
      "  0.27509526  0.0009986  -0.31628706  0.31565779 -0.21686551 -0.21377371\n",
      "  0.09244376 -0.44330423]\n",
      "New theta_0 : [ 0.00638874 -0.0773111   0.10901648  0.01581855  0.09925031 -0.2280866\n",
      "  0.27507793  0.00100799 -0.31631662  0.31576327 -0.21696542 -0.21378518\n",
      "  0.09243952 -0.44330966]\n",
      "Training Error:  10.547236975178377\n",
      "====================================================================================================\n",
      "Iteration:  809\n",
      "Previous theta :  [ 0.00638874 -0.0773111   0.10901648  0.01581855  0.09925031 -0.2280866\n",
      "  0.27507793  0.00100799 -0.31631662  0.31576327 -0.21696542 -0.21378518\n",
      "  0.09243952 -0.44330966]\n",
      "New theta_0 : [ 0.00638834 -0.07733053  0.10903475  0.01584425  0.09924483 -0.2281227\n",
      "  0.27506067  0.00101734 -0.31634594  0.31586844 -0.21706511 -0.2137966\n",
      "  0.0924353  -0.44331509]\n",
      "Training Error:  10.54721365005217\n",
      "====================================================================================================\n",
      "Iteration:  810\n",
      "Previous theta :  [ 0.00638834 -0.07733053  0.10903475  0.01584425  0.09924483 -0.2281227\n",
      "  0.27506067  0.00101734 -0.31634594  0.31586844 -0.21706511 -0.2137966\n",
      "  0.0924353  -0.44331509]\n",
      "New theta_0 : [ 0.00638795 -0.07734987  0.10905292  0.0158699   0.09923936 -0.22815857\n",
      "  0.27504351  0.00102666 -0.31637504  0.31597329 -0.21716457 -0.21380795\n",
      "  0.09243111 -0.4433205 ]\n",
      "Training Error:  10.547190469843278\n",
      "====================================================================================================\n",
      "Iteration:  811\n",
      "Previous theta :  [ 0.00638795 -0.07734987  0.10905292  0.0158699   0.09923936 -0.22815857\n",
      "  0.27504351  0.00102666 -0.31637504  0.31597329 -0.21716457 -0.21380795\n",
      "  0.09243111 -0.4433205 ]\n",
      "New theta_0 : [ 0.00638756 -0.0773691   0.109071    0.01589551  0.09923391 -0.2281942\n",
      "  0.27502643  0.00103595 -0.31640392  0.31607783 -0.2172638  -0.21381925\n",
      "  0.09242695 -0.44332591]\n",
      "Training Error:  10.547167433474813\n",
      "====================================================================================================\n",
      "Iteration:  812\n",
      "Previous theta :  [ 0.00638756 -0.0773691   0.109071    0.01589551  0.09923391 -0.2281942\n",
      "  0.27502643  0.00103595 -0.31640392  0.31607783 -0.2172638  -0.21381925\n",
      "  0.09242695 -0.44332591]\n",
      "New theta_0 : [ 0.00638717 -0.07738824  0.109089    0.01592108  0.09922847 -0.22822959\n",
      "  0.27500943  0.0010452  -0.31643257  0.31618207 -0.21736281 -0.21383048\n",
      "  0.09242282 -0.4433313 ]\n",
      "Training Error:  10.547144539880005\n",
      "====================================================================================================\n",
      "Iteration:  813\n",
      "Previous theta :  [ 0.00638717 -0.07738824  0.109089    0.01592108  0.09922847 -0.22822959\n",
      "  0.27500943  0.0010452  -0.31643257  0.31618207 -0.21736281 -0.21383048\n",
      "  0.09242282 -0.4433313 ]\n",
      "New theta_0 : [ 0.00638678 -0.07740728  0.1091069   0.0159466   0.09922305 -0.22826475\n",
      "  0.27499252  0.00105442 -0.31646101  0.316286   -0.21746158 -0.21384165\n",
      "  0.09241872 -0.44333669]\n",
      "Training Error:  10.547121788002073\n",
      "====================================================================================================\n",
      "Iteration:  814\n",
      "Previous theta :  [ 0.00638678 -0.07740728  0.1091069   0.0159466   0.09922305 -0.22826475\n",
      "  0.27499252  0.00105442 -0.31646101  0.316286   -0.21746158 -0.21384165\n",
      "  0.09241872 -0.44333669]\n",
      "New theta_0 : [ 0.00638639 -0.07742622  0.10912471  0.01597208  0.09921764 -0.22829968\n",
      "  0.27497569  0.0010636  -0.31648922  0.31638962 -0.21756013 -0.21385276\n",
      "  0.09241464 -0.44334206]\n",
      "Training Error:  10.547099176794127\n",
      "====================================================================================================\n",
      "Iteration:  815\n",
      "Previous theta :  [ 0.00638639 -0.07742622  0.10912471  0.01597208  0.09921764 -0.22829968\n",
      "  0.27497569  0.0010636  -0.31648922  0.31638962 -0.21756013 -0.21385276\n",
      "  0.09241464 -0.44334206]\n",
      "New theta_0 : [ 0.00638601 -0.07744507  0.10914243  0.01599751  0.09921225 -0.22833438\n",
      "  0.27495895  0.00107274 -0.31651722  0.31649293 -0.21765846 -0.21386381\n",
      "  0.09241059 -0.44334742]\n",
      "Training Error:  10.547076705219045\n",
      "====================================================================================================\n",
      "Iteration:  816\n",
      "Previous theta :  [ 0.00638601 -0.07744507  0.10914243  0.01599751  0.09921225 -0.22833438\n",
      "  0.27495895  0.00107274 -0.31651722  0.31649293 -0.21765846 -0.21386381\n",
      "  0.09241059 -0.44334742]\n",
      "New theta_0 : [ 0.00638563 -0.07746382  0.10916007  0.01602289  0.09920687 -0.22836885\n",
      "  0.27494228  0.00108186 -0.316545    0.31659594 -0.21775656 -0.2138748\n",
      "  0.09240657 -0.44335278]\n",
      "Training Error:  10.547054372249361\n",
      "====================================================================================================\n",
      "Iteration:  817\n",
      "Previous theta :  [ 0.00638563 -0.07746382  0.10916007  0.01602289  0.09920687 -0.22836885\n",
      "  0.27494228  0.00108186 -0.316545    0.31659594 -0.21775656 -0.2138748\n",
      "  0.09240657 -0.44335278]\n",
      "New theta_0 : [ 0.00638525 -0.07748247  0.10917761  0.01604823  0.09920151 -0.22840309\n",
      "  0.2749257   0.00109094 -0.31657257  0.31669865 -0.21785443 -0.21388573\n",
      "  0.09240257 -0.44335812]\n",
      "Training Error:  10.547032176867162\n",
      "====================================================================================================\n",
      "Iteration:  818\n",
      "Previous theta :  [ 0.00638525 -0.07748247  0.10917761  0.01604823  0.09920151 -0.22840309\n",
      "  0.2749257   0.00109094 -0.31657257  0.31669865 -0.21785443 -0.21388573\n",
      "  0.09240257 -0.44335812]\n",
      "New theta_0 : [ 0.00638487 -0.07750103  0.10919507  0.01607353  0.09919616 -0.2284371\n",
      "  0.27490921  0.00109999 -0.31659992  0.31680105 -0.21795208 -0.2138966\n",
      "  0.0923986  -0.44336346]\n",
      "Training Error:  10.547010118063966\n",
      "====================================================================================================\n",
      "Iteration:  819\n",
      "Previous theta :  [ 0.00638487 -0.07750103  0.10919507  0.01607353  0.09919616 -0.2284371\n",
      "  0.27490921  0.00109999 -0.31659992  0.31680105 -0.21795208 -0.2138966\n",
      "  0.0923986  -0.44336346]\n",
      "New theta_0 : [ 0.00638449 -0.07751949  0.10921244  0.01609878  0.09919083 -0.22847089\n",
      "  0.27489279  0.001109   -0.31662707  0.31690315 -0.2180495  -0.21390741\n",
      "  0.09239466 -0.44336878]\n",
      "Training Error:  10.546988194840628\n",
      "====================================================================================================\n",
      "Iteration:  820\n",
      "Previous theta :  [ 0.00638449 -0.07751949  0.10921244  0.01609878  0.09919083 -0.22847089\n",
      "  0.27489279  0.001109   -0.31662707  0.31690315 -0.2180495  -0.21390741\n",
      "  0.09239466 -0.44336878]\n",
      "New theta_0 : [ 0.00638412 -0.07753786  0.10922972  0.01612398  0.09918551 -0.22850446\n",
      "  0.27487645  0.00111798 -0.31665401  0.31700495 -0.2181467  -0.21391816\n",
      "  0.09239074 -0.4433741 ]\n",
      "Training Error:  10.546966406207227\n",
      "====================================================================================================\n",
      "Iteration:  821\n",
      "Previous theta :  [ 0.00638412 -0.07753786  0.10922972  0.01612398  0.09918551 -0.22850446\n",
      "  0.27487645  0.00111798 -0.31665401  0.31700495 -0.2181467  -0.21391816\n",
      "  0.09239074 -0.4433741 ]\n",
      "New theta_0 : [ 0.00638374 -0.07755614  0.10924692  0.01614914  0.0991802  -0.22853781\n",
      "  0.2748602   0.00112693 -0.31668073  0.31710645 -0.21824368 -0.21392886\n",
      "  0.09238686 -0.44337941]\n",
      "Training Error:  10.54694475118296\n",
      "====================================================================================================\n",
      "Iteration:  822\n",
      "Previous theta :  [ 0.00638374 -0.07755614  0.10924692  0.01614914  0.0991802  -0.22853781\n",
      "  0.2748602   0.00112693 -0.31668073  0.31710645 -0.21824368 -0.21392886\n",
      "  0.09238686 -0.44337941]\n",
      "New theta_0 : [ 0.00638337 -0.07757433  0.10926403  0.01617426  0.09917491 -0.22857093\n",
      "  0.27484402  0.00113584 -0.31670726  0.31720766 -0.21834043 -0.21393949\n",
      "  0.09238299 -0.4433847 ]\n",
      "Training Error:  10.546923228796041\n",
      "====================================================================================================\n",
      "Iteration:  823\n",
      "Previous theta :  [ 0.00638337 -0.07757433  0.10926403  0.01617426  0.09917491 -0.22857093\n",
      "  0.27484402  0.00113584 -0.31670726  0.31720766 -0.21834043 -0.21393949\n",
      "  0.09238299 -0.4433847 ]\n",
      "New theta_0 : [ 0.00638301 -0.07759242  0.10928106  0.01619932  0.09916963 -0.22860384\n",
      "  0.27482792  0.00114472 -0.31673357  0.31730856 -0.21843696 -0.21395007\n",
      "  0.09237915 -0.44338999]\n",
      "Training Error:  10.546901838083603\n",
      "====================================================================================================\n",
      "Iteration:  824\n",
      "Previous theta :  [ 0.00638301 -0.07759242  0.10928106  0.01619932  0.09916963 -0.22860384\n",
      "  0.27482792  0.00114472 -0.31673357  0.31730856 -0.21843696 -0.21395007\n",
      "  0.09237915 -0.44338999]\n",
      "New theta_0 : [ 0.00638264 -0.07761042  0.109298    0.01622434  0.09916437 -0.22863653\n",
      "  0.2748119   0.00115357 -0.31675969  0.31740917 -0.21853326 -0.2139606\n",
      "  0.09237534 -0.44339527]\n",
      "Training Error:  10.546880578091587\n",
      "====================================================================================================\n",
      "Iteration:  825\n",
      "Previous theta :  [ 0.00638264 -0.07761042  0.109298    0.01622434  0.09916437 -0.22863653\n",
      "  0.2748119   0.00115357 -0.31675969  0.31740917 -0.21853326 -0.2139606\n",
      "  0.09237534 -0.44339527]\n",
      "New theta_0 : [ 0.00638228 -0.07762833  0.10931486  0.01624932  0.09915912 -0.228669\n",
      "  0.27479596  0.00116239 -0.3167856   0.31750948 -0.21862935 -0.21397106\n",
      "  0.09237156 -0.44340053]\n",
      "Training Error:  10.54685944787465\n",
      "====================================================================================================\n",
      "Iteration:  826\n",
      "Previous theta :  [ 0.00638228 -0.07762833  0.10931486  0.01624932  0.09915912 -0.228669\n",
      "  0.27479596  0.00116239 -0.3167856   0.31750948 -0.21862935 -0.21397106\n",
      "  0.09237156 -0.44340053]\n",
      "New theta_0 : [ 0.00638191 -0.07764615  0.10933164  0.01627425  0.09915389 -0.22870126\n",
      "  0.27478009  0.00117117 -0.31681131  0.3176095  -0.21872521 -0.21398147\n",
      "  0.09236779 -0.44340579]\n",
      "Training Error:  10.546838446496071\n",
      "====================================================================================================\n",
      "Iteration:  827\n",
      "Previous theta :  [ 0.00638191 -0.07764615  0.10933164  0.01627425  0.09915389 -0.22870126\n",
      "  0.27478009  0.00117117 -0.31681131  0.3176095  -0.21872521 -0.21398147\n",
      "  0.09236779 -0.44340579]\n",
      "New theta_0 : [ 0.00638155 -0.07766388  0.10934833  0.01629913  0.09914867 -0.22873331\n",
      "  0.27476431  0.00117992 -0.31683683  0.31770923 -0.21882085 -0.21399183\n",
      "  0.09236406 -0.44341104]\n",
      "Training Error:  10.54681757302764\n",
      "====================================================================================================\n",
      "Iteration:  828\n",
      "Previous theta :  [ 0.00638155 -0.07766388  0.10934833  0.01629913  0.09914867 -0.22873331\n",
      "  0.27476431  0.00117992 -0.31683683  0.31770923 -0.21882085 -0.21399183\n",
      "  0.09236406 -0.44341104]\n",
      "New theta_0 : [ 0.00638119 -0.07768152  0.10936494  0.01632397  0.09914346 -0.22876515\n",
      "  0.2747486   0.00118864 -0.31686214  0.31780866 -0.21891627 -0.21400213\n",
      "  0.09236035 -0.44341628]\n",
      "Training Error:  10.546796826549574\n",
      "====================================================================================================\n",
      "Iteration:  829\n",
      "Previous theta :  [ 0.00638119 -0.07768152  0.10936494  0.01632397  0.09914346 -0.22876515\n",
      "  0.2747486   0.00118864 -0.31686214  0.31780866 -0.21891627 -0.21400213\n",
      "  0.09236035 -0.44341628]\n",
      "New theta_0 : [ 0.00638084 -0.07769908  0.10938146  0.01634876  0.09913827 -0.22879677\n",
      "  0.27473296  0.00119733 -0.31688726  0.3179078  -0.21901146 -0.21401237\n",
      "  0.09235666 -0.44342151]\n",
      "Training Error:  10.546776206150419\n",
      "====================================================================================================\n",
      "Iteration:  830\n",
      "Previous theta :  [ 0.00638084 -0.07769908  0.10938146  0.01634876  0.09913827 -0.22879677\n",
      "  0.27473296  0.00119733 -0.31688726  0.3179078  -0.21901146 -0.21401237\n",
      "  0.09235666 -0.44342151]\n",
      "New theta_0 : [ 0.00638048 -0.07771654  0.10939791  0.0163735   0.0991331  -0.22882819\n",
      "  0.2747174   0.00120599 -0.31691219  0.31800665 -0.21910644 -0.21402256\n",
      "  0.092353   -0.44342673]\n",
      "Training Error:  10.546755710926957\n",
      "====================================================================================================\n",
      "Iteration:  831\n",
      "Previous theta :  [ 0.00638048 -0.07771654  0.10939791  0.0163735   0.0991331  -0.22882819\n",
      "  0.2747174   0.00120599 -0.31691219  0.31800665 -0.21910644 -0.21402256\n",
      "  0.092353   -0.44342673]\n",
      "New theta_0 : [ 0.00638013 -0.07773392  0.10941428  0.0163982   0.09912793 -0.2288594\n",
      "  0.27470192  0.00121461 -0.31693692  0.31810521 -0.2192012  -0.21403269\n",
      "  0.09234936 -0.44343194]\n",
      "Training Error:  10.546735339984114\n",
      "====================================================================================================\n",
      "Iteration:  832\n",
      "Previous theta :  [ 0.00638013 -0.07773392  0.10941428  0.0163982   0.09912793 -0.2288594\n",
      "  0.27470192  0.00121461 -0.31693692  0.31810521 -0.2192012  -0.21403269\n",
      "  0.09234936 -0.44343194]\n",
      "New theta_0 : [ 0.00637978 -0.07775121  0.10943056  0.01642285  0.09912278 -0.22889041\n",
      "  0.27468651  0.0012232  -0.31696147  0.31820349 -0.21929573 -0.21404277\n",
      "  0.09234575 -0.44343714]\n",
      "Training Error:  10.546715092434864\n",
      "====================================================================================================\n",
      "Iteration:  833\n",
      "Previous theta :  [ 0.00637978 -0.07775121  0.10943056  0.01642285  0.09912278 -0.22889041\n",
      "  0.27468651  0.0012232  -0.31696147  0.31820349 -0.21929573 -0.21404277\n",
      "  0.09234575 -0.44343714]\n",
      "New theta_0 : [ 0.00637943 -0.07776841  0.10944676  0.01644745  0.09911765 -0.22892121\n",
      "  0.27467118  0.00123177 -0.31698582  0.31830147 -0.21939005 -0.21405279\n",
      "  0.09234216 -0.44344234]\n",
      "Training Error:  10.546694967400155\n",
      "====================================================================================================\n",
      "Iteration:  834\n",
      "Previous theta :  [ 0.00637943 -0.07776841  0.10944676  0.01644745  0.09911765 -0.22892121\n",
      "  0.27467118  0.00123177 -0.31698582  0.31830147 -0.21939005 -0.21405279\n",
      "  0.09234216 -0.44344234]\n",
      "New theta_0 : [ 0.00637908 -0.07778553  0.10946289  0.01647201  0.09911253 -0.2289518\n",
      "  0.27465592  0.0012403  -0.31700999  0.31839917 -0.21948415 -0.21406276\n",
      "  0.09233859 -0.44344752]\n",
      "Training Error:  10.546674964008796\n",
      "====================================================================================================\n",
      "Iteration:  835\n",
      "Previous theta :  [ 0.00637908 -0.07778553  0.10946289  0.01647201  0.09911253 -0.2289518\n",
      "  0.27465592  0.0012403  -0.31700999  0.31839917 -0.21948415 -0.21406276\n",
      "  0.09233859 -0.44344752]\n",
      "New theta_0 : [ 0.00637873 -0.07780256  0.10947894  0.01649652  0.09910742 -0.2289822\n",
      "  0.27464073  0.0012488  -0.31703396  0.31849658 -0.21957802 -0.21407268\n",
      "  0.09233505 -0.44345269]\n",
      "Training Error:  10.546655081397393\n",
      "====================================================================================================\n",
      "Iteration:  836\n",
      "Previous theta :  [ 0.00637873 -0.07780256  0.10947894  0.01649652  0.09910742 -0.2289822\n",
      "  0.27464073  0.0012488  -0.31703396  0.31849658 -0.21957802 -0.21407268\n",
      "  0.09233505 -0.44345269]\n",
      "New theta_0 : [ 0.00637839 -0.07781951  0.1094949   0.01652098  0.09910232 -0.2290124\n",
      "  0.27462561  0.00125727 -0.31705775  0.31859371 -0.21967168 -0.21408254\n",
      "  0.09233153 -0.44345786]\n",
      "Training Error:  10.546635318710248\n",
      "====================================================================================================\n",
      "Iteration:  837\n",
      "Previous theta :  [ 0.00637839 -0.07781951  0.1094949   0.01652098  0.09910232 -0.2290124\n",
      "  0.27462561  0.00125727 -0.31705775  0.31859371 -0.21967168 -0.21408254\n",
      "  0.09233153 -0.44345786]\n",
      "New theta_0 : [ 0.00637805 -0.07783637  0.10951079  0.0165454   0.09909724 -0.22904239\n",
      "  0.27461057  0.00126571 -0.31708136  0.31869056 -0.21976513 -0.21409236\n",
      "  0.09232804 -0.44346301]\n",
      "Training Error:  10.546615675099279\n",
      "====================================================================================================\n",
      "Iteration:  838\n",
      "Previous theta :  [ 0.00637805 -0.07783637  0.10951079  0.0165454   0.09909724 -0.22904239\n",
      "  0.27461057  0.00126571 -0.31708136  0.31869056 -0.21976513 -0.21409236\n",
      "  0.09232804 -0.44346301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00637771 -0.07785315  0.10952661  0.01656977  0.09909218 -0.22907219\n",
      "  0.2745956   0.00127411 -0.31710479  0.31878712 -0.21985835 -0.21410212\n",
      "  0.09232456 -0.44346816]\n",
      "Training Error:  10.546596149723939\n",
      "====================================================================================================\n",
      "Iteration:  839\n",
      "Previous theta :  [ 0.00637771 -0.07785315  0.10952661  0.01656977  0.09909218 -0.22907219\n",
      "  0.2745956   0.00127411 -0.31710479  0.31878712 -0.21985835 -0.21410212\n",
      "  0.09232456 -0.44346816]\n",
      "New theta_0 : [ 0.00637737 -0.07786984  0.10954234  0.01659409  0.09908712 -0.22910179\n",
      "  0.2745807   0.00128249 -0.31712803  0.3188834  -0.21995136 -0.21411182\n",
      "  0.09232112 -0.4434733 ]\n",
      "Training Error:  10.546576741751121\n",
      "====================================================================================================\n",
      "Iteration:  840\n",
      "Previous theta :  [ 0.00637737 -0.07786984  0.10954234  0.01659409  0.09908712 -0.22910179\n",
      "  0.2745807   0.00128249 -0.31712803  0.3188834  -0.21995136 -0.21411182\n",
      "  0.09232112 -0.4434733 ]\n",
      "New theta_0 : [ 0.00637703 -0.07788645  0.109558    0.01661837  0.09908209 -0.2291312\n",
      "  0.27456587  0.00129084 -0.31715109  0.3189794  -0.22004415 -0.21412148\n",
      "  0.09231769 -0.44347842]\n",
      "Training Error:  10.546557450355094\n",
      "====================================================================================================\n",
      "Iteration:  841\n",
      "Previous theta :  [ 0.00637703 -0.07788645  0.109558    0.01661837  0.09908209 -0.2291312\n",
      "  0.27456587  0.00129084 -0.31715109  0.3189794  -0.22004415 -0.21412148\n",
      "  0.09231769 -0.44347842]\n",
      "New theta_0 : [ 0.0063767  -0.07790298  0.10957358  0.0166426   0.09907706 -0.22916042\n",
      "  0.27455112  0.00129916 -0.31717398  0.31907512 -0.22013672 -0.21413108\n",
      "  0.09231429 -0.44348354]\n",
      "Training Error:  10.546538274717403\n",
      "====================================================================================================\n",
      "Iteration:  842\n",
      "Previous theta :  [ 0.0063767  -0.07790298  0.10957358  0.0166426   0.09907706 -0.22916042\n",
      "  0.27455112  0.00129916 -0.31717398  0.31907512 -0.22013672 -0.21413108\n",
      "  0.09231429 -0.44348354]\n",
      "New theta_0 : [ 0.00637636 -0.07791943  0.10958909  0.01666678  0.09907205 -0.22918944\n",
      "  0.27453643  0.00130745 -0.31719669  0.31917056 -0.22022908 -0.21414063\n",
      "  0.09231091 -0.44348865]\n",
      "Training Error:  10.546519214026802\n",
      "====================================================================================================\n",
      "Iteration:  843\n",
      "Previous theta :  [ 0.00637636 -0.07791943  0.10958909  0.01666678  0.09907205 -0.22918944\n",
      "  0.27453643  0.00130745 -0.31719669  0.31917056 -0.22022908 -0.21414063\n",
      "  0.09231091 -0.44348865]\n",
      "New theta_0 : [ 0.00637603 -0.0779358   0.10960452  0.01669092  0.09906705 -0.22921827\n",
      "  0.27452181  0.0013157  -0.31721922  0.31926572 -0.22032122 -0.21415014\n",
      "  0.09230755 -0.44349375]\n",
      "Training Error:  10.546500267479175\n",
      "====================================================================================================\n",
      "Iteration:  844\n",
      "Previous theta :  [ 0.00637603 -0.0779358   0.10960452  0.01669092  0.09906705 -0.22921827\n",
      "  0.27452181  0.0013157  -0.31721922  0.31926572 -0.22032122 -0.21415014\n",
      "  0.09230755 -0.44349375]\n",
      "New theta_0 : [ 0.0063757  -0.07795208  0.10961988  0.016715    0.09906206 -0.22924691\n",
      "  0.27450726  0.00132393 -0.31724157  0.3193606  -0.22041315 -0.21415959\n",
      "  0.09230421 -0.44349884]\n",
      "Training Error:  10.54648143427745\n",
      "====================================================================================================\n",
      "Iteration:  845\n",
      "Previous theta :  [ 0.0063757  -0.07795208  0.10961988  0.016715    0.09906206 -0.22924691\n",
      "  0.27450726  0.00132393 -0.31724157  0.3193606  -0.22041315 -0.21415959\n",
      "  0.09230421 -0.44349884]\n",
      "New theta_0 : [ 0.00637537 -0.07796829  0.10963516  0.01673904  0.09905709 -0.22927536\n",
      "  0.27449279  0.00133213 -0.31726375  0.31945521 -0.22050486 -0.21416899\n",
      "  0.0923009  -0.44350393]\n",
      "Training Error:  10.546462713631522\n",
      "====================================================================================================\n",
      "Iteration:  846\n",
      "Previous theta :  [ 0.00637537 -0.07796829  0.10963516  0.01673904  0.09905709 -0.22927536\n",
      "  0.27449279  0.00133213 -0.31726375  0.31945521 -0.22050486 -0.21416899\n",
      "  0.0923009  -0.44350393]\n",
      "New theta_0 : [ 0.00637504 -0.07798441  0.10965037  0.01676304  0.09905214 -0.22930363\n",
      "  0.27447837  0.0013403  -0.31728576  0.31954955 -0.22059636 -0.21417834\n",
      "  0.0922976  -0.443509  ]\n",
      "Training Error:  10.54644410475819\n",
      "====================================================================================================\n",
      "Iteration:  847\n",
      "Previous theta :  [ 0.00637504 -0.07798441  0.10965037  0.01676304  0.09905214 -0.22930363\n",
      "  0.27447837  0.0013403  -0.31728576  0.31954955 -0.22059636 -0.21417834\n",
      "  0.0922976  -0.443509  ]\n",
      "New theta_0 : [ 0.00637472 -0.07800046  0.1096655   0.01678698  0.09904719 -0.22933171\n",
      "  0.27446403  0.00134844 -0.3173076   0.31964361 -0.22068764 -0.21418764\n",
      "  0.09229433 -0.44351406]\n",
      "Training Error:  10.546425606881073\n",
      "====================================================================================================\n",
      "Iteration:  848\n",
      "Previous theta :  [ 0.00637472 -0.07800046  0.1096655   0.01678698  0.09904719 -0.22933171\n",
      "  0.27446403  0.00134844 -0.3173076   0.31964361 -0.22068764 -0.21418764\n",
      "  0.09229433 -0.44351406]\n",
      "New theta_0 : [ 0.0063744  -0.07801642  0.10968057  0.01681088  0.09904226 -0.2293596\n",
      "  0.27444976  0.00135655 -0.31732927  0.31973739 -0.22077871 -0.21419689\n",
      "  0.09229108 -0.44351912]\n",
      "Training Error:  10.546407219230526\n",
      "====================================================================================================\n",
      "Iteration:  849\n",
      "Previous theta :  [ 0.0063744  -0.07801642  0.10968057  0.01681088  0.09904226 -0.2293596\n",
      "  0.27444976  0.00135655 -0.31732927  0.31973739 -0.22077871 -0.21419689\n",
      "  0.09229108 -0.44351912]\n",
      "New theta_0 : [ 0.00637408 -0.07803231  0.10969556  0.01683473  0.09903734 -0.22938731\n",
      "  0.27443555  0.00136464 -0.31735077  0.3198309  -0.22086957 -0.21420609\n",
      "  0.09228786 -0.44352416]\n",
      "Training Error:  10.546388941043586\n",
      "====================================================================================================\n",
      "Iteration:  850\n",
      "Previous theta :  [ 0.00637408 -0.07803231  0.10969556  0.01683473  0.09903734 -0.22938731\n",
      "  0.27443555  0.00136464 -0.31735077  0.3198309  -0.22086957 -0.21420609\n",
      "  0.09228786 -0.44352416]\n",
      "New theta_0 : [ 0.00637376 -0.07804812  0.10971047  0.01685853  0.09903244 -0.22941484\n",
      "  0.27442141  0.00137269 -0.31737211  0.31992415 -0.22096021 -0.21421525\n",
      "  0.09228465 -0.4435292 ]\n",
      "Training Error:  10.546370771563888\n",
      "====================================================================================================\n",
      "Iteration:  851\n",
      "Previous theta :  [ 0.00637376 -0.07804812  0.10971047  0.01685853  0.09903244 -0.22941484\n",
      "  0.27442141  0.00137269 -0.31737211  0.31992415 -0.22096021 -0.21421525\n",
      "  0.09228465 -0.4435292 ]\n",
      "New theta_0 : [ 0.00637344 -0.07806385  0.10972532  0.01688229  0.09902755 -0.22944219\n",
      "  0.27440733  0.00138071 -0.31739328  0.32001712 -0.22105064 -0.21422435\n",
      "  0.09228147 -0.44353423]\n",
      "Training Error:  10.546352710041596\n",
      "====================================================================================================\n",
      "Iteration:  852\n",
      "Previous theta :  [ 0.00637344 -0.07806385  0.10972532  0.01688229  0.09902755 -0.22944219\n",
      "  0.27440733  0.00138071 -0.31739328  0.32001712 -0.22105064 -0.21422435\n",
      "  0.09228147 -0.44353423]\n",
      "New theta_0 : [ 0.00637312 -0.07807951  0.1097401   0.016906    0.09902267 -0.22946935\n",
      "  0.27439332  0.00138871 -0.31741428  0.32010982 -0.22114086 -0.21423341\n",
      "  0.0922783  -0.44353925]\n",
      "Training Error:  10.546334755733334\n",
      "====================================================================================================\n",
      "Iteration:  853\n",
      "Previous theta :  [ 0.00637312 -0.07807951  0.1097401   0.016906    0.09902267 -0.22946935\n",
      "  0.27439332  0.00138871 -0.31741428  0.32010982 -0.22114086 -0.21423341\n",
      "  0.0922783  -0.44353925]\n",
      "New theta_0 : [ 0.00637281 -0.07809509  0.1097548   0.01692966  0.0990178  -0.22949634\n",
      "  0.27437938  0.00139668 -0.31743512  0.32020225 -0.22123087 -0.21424242\n",
      "  0.09227516 -0.44354426]\n",
      "Training Error:  10.546316907902114\n",
      "====================================================================================================\n",
      "Iteration:  854\n",
      "Previous theta :  [ 0.00637281 -0.07809509  0.1097548   0.01692966  0.0990178  -0.22949634\n",
      "  0.27437938  0.00139668 -0.31743512  0.32020225 -0.22123087 -0.21424242\n",
      "  0.09227516 -0.44354426]\n",
      "New theta_0 : [ 0.00637249 -0.07811059  0.10976943  0.01695327  0.09901295 -0.22952316\n",
      "  0.2743655   0.00140462 -0.3174558   0.32029442 -0.22132066 -0.21425138\n",
      "  0.09227203 -0.44354926]\n",
      "Training Error:  10.54629916581727\n",
      "====================================================================================================\n",
      "Iteration:  855\n",
      "Previous theta :  [ 0.00637249 -0.07811059  0.10976943  0.01695327  0.09901295 -0.22952316\n",
      "  0.2743655   0.00140462 -0.3174558   0.32029442 -0.22132066 -0.21425138\n",
      "  0.09227203 -0.44354926]\n",
      "New theta_0 : [ 0.00637218 -0.07812602  0.109784    0.01697684  0.09900811 -0.22954979\n",
      "  0.27435169  0.00141253 -0.31747631  0.32038631 -0.22141024 -0.21426029\n",
      "  0.09226893 -0.44355425]\n",
      "Training Error:  10.546281528754388\n",
      "====================================================================================================\n",
      "Iteration:  856\n",
      "Previous theta :  [ 0.00637218 -0.07812602  0.109784    0.01697684  0.09900811 -0.22954979\n",
      "  0.27435169  0.00141253 -0.31747631  0.32038631 -0.22141024 -0.21426029\n",
      "  0.09226893 -0.44355425]\n",
      "New theta_0 : [ 0.00637187 -0.07814137  0.10979849  0.01700036  0.09900328 -0.22957625\n",
      "  0.27433794  0.00142041 -0.31749667  0.32047795 -0.22149962 -0.21426916\n",
      "  0.09226585 -0.44355923]\n",
      "Training Error:  10.546263995995242\n",
      "====================================================================================================\n",
      "Iteration:  857\n",
      "Previous theta :  [ 0.00637187 -0.07814137  0.10979849  0.01700036  0.09900328 -0.22957625\n",
      "  0.27433794  0.00142041 -0.31749667  0.32047795 -0.22149962 -0.21426916\n",
      "  0.09226585 -0.44355923]\n",
      "New theta_0 : [ 0.00637156 -0.07815664  0.10981292  0.01702383  0.09899847 -0.22960254\n",
      "  0.27432425  0.00142827 -0.31751687  0.32056931 -0.22158878 -0.21427798\n",
      "  0.09226279 -0.44356421]\n",
      "Training Error:  10.54624656682772\n",
      "====================================================================================================\n",
      "Iteration:  858\n",
      "Previous theta :  [ 0.00637156 -0.07815664  0.10981292  0.01702383  0.09899847 -0.22960254\n",
      "  0.27432425  0.00142827 -0.31751687  0.32056931 -0.22158878 -0.21427798\n",
      "  0.09226279 -0.44356421]\n",
      "New theta_0 : [ 0.00637126 -0.07817185  0.10982728  0.01704725  0.09899367 -0.22962865\n",
      "  0.27431063  0.0014361  -0.31753691  0.32066041 -0.22167773 -0.21428675\n",
      "  0.09225975 -0.44356917]\n",
      "Training Error:  10.546229240545772\n",
      "====================================================================================================\n",
      "Iteration:  859\n",
      "Previous theta :  [ 0.00637126 -0.07817185  0.10982728  0.01704725  0.09899367 -0.22962865\n",
      "  0.27431063  0.0014361  -0.31753691  0.32066041 -0.22167773 -0.21428675\n",
      "  0.09225975 -0.44356917]\n",
      "New theta_0 : [ 0.00637095 -0.07818697  0.10984156  0.01707062  0.09898888 -0.22965459\n",
      "  0.27429707  0.0014439  -0.31755679  0.32075125 -0.22176647 -0.21429548\n",
      "  0.09225673 -0.44357413]\n",
      "Training Error:  10.546212016449331\n",
      "====================================================================================================\n",
      "Iteration:  860\n",
      "Previous theta :  [ 0.00637095 -0.07818697  0.10984156  0.01707062  0.09898888 -0.22965459\n",
      "  0.27429707  0.0014439  -0.31755679  0.32075125 -0.22176647 -0.21429548\n",
      "  0.09225673 -0.44357413]\n",
      "New theta_0 : [ 0.00637065 -0.07820203  0.10985579  0.01709395  0.09898411 -0.22968036\n",
      "  0.27428358  0.00145167 -0.31757652  0.32084183 -0.22185501 -0.21430416\n",
      "  0.09225372 -0.44357908]\n",
      "Training Error:  10.546194893844262\n",
      "====================================================================================================\n",
      "Iteration:  861\n",
      "Previous theta :  [ 0.00637065 -0.07820203  0.10985579  0.01709395  0.09898411 -0.22968036\n",
      "  0.27428358  0.00145167 -0.31757652  0.32084183 -0.22185501 -0.21430416\n",
      "  0.09225372 -0.44357908]\n",
      "New theta_0 : [ 0.00637034 -0.07821701  0.10986994  0.01711723  0.09897935 -0.22970597\n",
      "  0.27427015  0.00145942 -0.3175961   0.32093214 -0.22194333 -0.2143128\n",
      "  0.09225074 -0.44358402]\n",
      "Training Error:  10.54617787204229\n",
      "====================================================================================================\n",
      "Iteration:  862\n",
      "Previous theta :  [ 0.00637034 -0.07821701  0.10986994  0.01711723  0.09897935 -0.22970597\n",
      "  0.27427015  0.00145942 -0.3175961   0.32093214 -0.22194333 -0.2143128\n",
      "  0.09225074 -0.44358402]\n",
      "New theta_0 : [ 0.00637004 -0.07823192  0.10988403  0.01714046  0.0989746  -0.2297314\n",
      "  0.27425678  0.00146713 -0.31761552  0.32102219 -0.22203145 -0.21432139\n",
      "  0.09224778 -0.44358895]\n",
      "Training Error:  10.546160950360942\n",
      "====================================================================================================\n",
      "Iteration:  863\n",
      "Previous theta :  [ 0.00637004 -0.07823192  0.10988403  0.01714046  0.0989746  -0.2297314\n",
      "  0.27425678  0.00146713 -0.31761552  0.32102219 -0.22203145 -0.21432139\n",
      "  0.09224778 -0.44358895]\n",
      "New theta_0 : [ 0.00636975 -0.07824676  0.10989804  0.01716365  0.09896986 -0.22975667\n",
      "  0.27424347  0.00147482 -0.31763479  0.32111199 -0.22211935 -0.21432993\n",
      "  0.09224484 -0.44359387]\n",
      "Training Error:  10.546144128123483\n",
      "====================================================================================================\n",
      "Iteration:  864\n",
      "Previous theta :  [ 0.00636975 -0.07824676  0.10989804  0.01716365  0.09896986 -0.22975667\n",
      "  0.27424347  0.00147482 -0.31763479  0.32111199 -0.22211935 -0.21432993\n",
      "  0.09224484 -0.44359387]\n",
      "New theta_0 : [ 0.00636945 -0.07826152  0.109912    0.01718678  0.09896514 -0.22978177\n",
      "  0.27423022  0.00148249 -0.31765391  0.32120152 -0.22220705 -0.21433843\n",
      "  0.09224191 -0.44359878]\n",
      "Training Error:  10.546127404658863\n",
      "====================================================================================================\n",
      "Iteration:  865\n",
      "Previous theta :  [ 0.00636945 -0.07826152  0.109912    0.01718678  0.09896514 -0.22978177\n",
      "  0.27423022  0.00148249 -0.31765391  0.32120152 -0.22220705 -0.21433843\n",
      "  0.09224191 -0.44359878]\n",
      "New theta_0 : [ 0.00636915 -0.07827622  0.10992589  0.01720987  0.09896043 -0.2298067\n",
      "  0.27421703  0.00149013 -0.31767288  0.32129079 -0.22229455 -0.21434689\n",
      "  0.09223901 -0.44360369]\n",
      "Training Error:  10.546110779301642\n",
      "====================================================================================================\n",
      "Iteration:  866\n",
      "Previous theta :  [ 0.00636915 -0.07827622  0.10992589  0.01720987  0.09896043 -0.2298067\n",
      "  0.27421703  0.00149013 -0.31767288  0.32129079 -0.22229455 -0.21434689\n",
      "  0.09223901 -0.44360369]\n",
      "New theta_0 : [ 0.00636886 -0.07829084  0.10993971  0.01723291  0.09895573 -0.22983148\n",
      "  0.2742039   0.00149774 -0.31769171  0.32137981 -0.22238183 -0.2143553\n",
      "  0.09223612 -0.44360859]\n",
      "Training Error:  10.54609425139195\n",
      "====================================================================================================\n",
      "Iteration:  867\n",
      "Previous theta :  [ 0.00636886 -0.07829084  0.10993971  0.01723291  0.09895573 -0.22983148\n",
      "  0.2742039   0.00149774 -0.31769171  0.32137981 -0.22238183 -0.2143553\n",
      "  0.09223612 -0.44360859]\n",
      "New theta_0 : [ 0.00636856 -0.07830539  0.10995347  0.0172559   0.09895105 -0.22985609\n",
      "  0.27419084  0.00150532 -0.31771038  0.32146857 -0.22246891 -0.21436367\n",
      "  0.09223325 -0.44361347]\n",
      "Training Error:  10.54607782027541\n",
      "====================================================================================================\n",
      "Iteration:  868\n",
      "Previous theta :  [ 0.00636856 -0.07830539  0.10995347  0.0172559   0.09895105 -0.22985609\n",
      "  0.27419084  0.00150532 -0.31771038  0.32146857 -0.22246891 -0.21436367\n",
      "  0.09223325 -0.44361347]\n",
      "New theta_0 : [ 0.00636827 -0.07831987  0.10996716  0.01727885  0.09894637 -0.22988054\n",
      "  0.27417783  0.00151288 -0.31772891  0.32155708 -0.22255578 -0.21437199\n",
      "  0.09223041 -0.44361835]\n",
      "Training Error:  10.546061485303099\n",
      "====================================================================================================\n",
      "Iteration:  869\n",
      "Previous theta :  [ 0.00636827 -0.07831987  0.10996716  0.01727885  0.09894637 -0.22988054\n",
      "  0.27417783  0.00151288 -0.31772891  0.32155708 -0.22255578 -0.21437199\n",
      "  0.09223041 -0.44361835]\n",
      "New theta_0 : [ 0.00636798 -0.07833429  0.10998079  0.01730175  0.09894171 -0.22990482\n",
      "  0.27416489  0.00152041 -0.3177473   0.32164533 -0.22264245 -0.21438027\n",
      "  0.09222758 -0.44362322]\n",
      "Training Error:  10.546045245831474\n",
      "====================================================================================================\n",
      "Iteration:  870\n",
      "Previous theta :  [ 0.00636798 -0.07833429  0.10998079  0.01730175  0.09894171 -0.22990482\n",
      "  0.27416489  0.00152041 -0.3177473   0.32164533 -0.22264245 -0.21438027\n",
      "  0.09222758 -0.44362322]\n",
      "New theta_0 : [ 0.0063677  -0.07834863  0.10999435  0.0173246   0.09893707 -0.22992895\n",
      "  0.274152    0.00152791 -0.31776554  0.32173332 -0.22272891 -0.21438851\n",
      "  0.09222477 -0.44362808]\n",
      "Training Error:  10.546029101222324\n",
      "====================================================================================================\n",
      "Iteration:  871\n",
      "Previous theta :  [ 0.0063677  -0.07834863  0.10999435  0.0173246   0.09893707 -0.22992895\n",
      "  0.274152    0.00152791 -0.31776554  0.32173332 -0.22272891 -0.21438851\n",
      "  0.09222477 -0.44362808]\n",
      "New theta_0 : [ 0.00636741 -0.07836291  0.11000785  0.0173474   0.09893243 -0.22995292\n",
      "  0.27413917  0.00153539 -0.31778364  0.32182106 -0.22281517 -0.2143967\n",
      "  0.09222197 -0.44363293]\n",
      "Training Error:  10.546013050842715\n",
      "====================================================================================================\n",
      "Iteration:  872\n",
      "Previous theta :  [ 0.00636741 -0.07836291  0.11000785  0.0173474   0.09893243 -0.22995292\n",
      "  0.27413917  0.00153539 -0.31778364  0.32182106 -0.22281517 -0.2143967\n",
      "  0.09222197 -0.44363293]\n",
      "New theta_0 : [ 0.00636712 -0.07837711  0.11002129  0.01737015  0.09892781 -0.22997674\n",
      "  0.2741264   0.00154284 -0.31780159  0.32190855 -0.22290122 -0.21440485\n",
      "  0.0922192  -0.44363778]\n",
      "Training Error:  10.545997094064932\n",
      "====================================================================================================\n",
      "Iteration:  873\n",
      "Previous theta :  [ 0.00636712 -0.07837711  0.11002129  0.01737015  0.09892781 -0.22997674\n",
      "  0.2741264   0.00154284 -0.31780159  0.32190855 -0.22290122 -0.21440485\n",
      "  0.0922192  -0.44363778]\n",
      "New theta_0 : [ 0.00636684 -0.07839125  0.11003467  0.01739286  0.0989232  -0.23000039\n",
      "  0.27411369  0.00155027 -0.31781941  0.32199579 -0.22298707 -0.21441296\n",
      "  0.09221644 -0.44364261]\n",
      "Training Error:  10.545981230266431\n",
      "====================================================================================================\n",
      "Iteration:  874\n",
      "Previous theta :  [ 0.00636684 -0.07839125  0.11003467  0.01739286  0.0989232  -0.23000039\n",
      "  0.27411369  0.00155027 -0.31781941  0.32199579 -0.22298707 -0.21441296\n",
      "  0.09221644 -0.44364261]\n",
      "New theta_0 : [ 0.00636656 -0.07840532  0.11004798  0.01741552  0.0989186  -0.23002389\n",
      "  0.27410103  0.00155767 -0.31783709  0.32208278 -0.22307271 -0.21442103\n",
      "  0.0922137  -0.44364744]\n",
      "Training Error:  10.545965458829775\n",
      "====================================================================================================\n",
      "Iteration:  875\n",
      "Previous theta :  [ 0.00636656 -0.07840532  0.11004798  0.01741552  0.0989186  -0.23002389\n",
      "  0.27410103  0.00155767 -0.31783709  0.32208278 -0.22307271 -0.21442103\n",
      "  0.0922137  -0.44364744]\n",
      "New theta_0 : [ 0.00636628 -0.07841933  0.11006123  0.01743813  0.09891402 -0.23004724\n",
      "  0.27408843  0.00156505 -0.31785462  0.32216952 -0.22315815 -0.21442905\n",
      "  0.09221098 -0.44365226]\n",
      "Training Error:  10.545949779142589\n",
      "====================================================================================================\n",
      "Iteration:  876\n",
      "Previous theta :  [ 0.00636628 -0.07841933  0.11006123  0.01743813  0.09891402 -0.23004724\n",
      "  0.27408843  0.00156505 -0.31785462  0.32216952 -0.22315815 -0.21442905\n",
      "  0.09221098 -0.44365226]\n",
      "New theta_0 : [ 0.006366   -0.07843326  0.11007442  0.01746069  0.09890944 -0.23007044\n",
      "  0.27407589  0.0015724  -0.31787202  0.32225601 -0.22324339 -0.21443703\n",
      "  0.09220828 -0.44365707]\n",
      "Training Error:  10.545934190597507\n",
      "====================================================================================================\n",
      "Iteration:  877\n",
      "Previous theta :  [ 0.006366   -0.07843326  0.11007442  0.01746069  0.09890944 -0.23007044\n",
      "  0.27407589  0.0015724  -0.31787202  0.32225601 -0.22324339 -0.21443703\n",
      "  0.09220828 -0.44365707]\n",
      "New theta_0 : [ 0.00636572 -0.07844713  0.11008755  0.0174832   0.09890488 -0.23009348\n",
      "  0.27406341  0.00157972 -0.31788929  0.32234225 -0.22332843 -0.21444497\n",
      "  0.09220559 -0.44366187]\n",
      "Training Error:  10.545918692592121\n",
      "====================================================================================================\n",
      "Iteration:  878\n",
      "Previous theta :  [ 0.00636572 -0.07844713  0.11008755  0.0174832   0.09890488 -0.23009348\n",
      "  0.27406341  0.00157972 -0.31788929  0.32234225 -0.22332843 -0.21444497\n",
      "  0.09220559 -0.44366187]\n",
      "New theta_0 : [ 0.00636544 -0.07846094  0.11010061  0.01750567  0.09890033 -0.23011637\n",
      "  0.27405098  0.00158702 -0.31790642  0.32242824 -0.22341326 -0.21445287\n",
      "  0.09220292 -0.44366666]\n",
      "Training Error:  10.545903284528922\n",
      "====================================================================================================\n",
      "Iteration:  879\n",
      "Previous theta :  [ 0.00636544 -0.07846094  0.11010061  0.01750567  0.09890033 -0.23011637\n",
      "  0.27405098  0.00158702 -0.31790642  0.32242824 -0.22341326 -0.21445287\n",
      "  0.09220292 -0.44366666]\n",
      "New theta_0 : [ 0.00636517 -0.07847468  0.11011362  0.01752809  0.0988958  -0.23013911\n",
      "  0.27403861  0.00159429 -0.31792341  0.32251398 -0.22349789 -0.21446073\n",
      "  0.09220027 -0.44367144]\n",
      "Training Error:  10.545887965815263\n",
      "====================================================================================================\n",
      "Iteration:  880\n",
      "Previous theta :  [ 0.00636517 -0.07847468  0.11011362  0.01752809  0.0988958  -0.23013911\n",
      "  0.27403861  0.00159429 -0.31792341  0.32251398 -0.22349789 -0.21446073\n",
      "  0.09220027 -0.44367144]\n",
      "New theta_0 : [ 0.00636489 -0.07848835  0.11012657  0.01755046  0.09889127 -0.23016171\n",
      "  0.2740263   0.00160154 -0.31794027  0.32259948 -0.22358232 -0.21446855\n",
      "  0.09219764 -0.44367622]\n",
      "Training Error:  10.545872735863297\n",
      "====================================================================================================\n",
      "Iteration:  881\n",
      "Previous theta :  [ 0.00636489 -0.07848835  0.11012657  0.01755046  0.09889127 -0.23016171\n",
      "  0.2740263   0.00160154 -0.31794027  0.32259948 -0.22358232 -0.21446855\n",
      "  0.09219764 -0.44367622]\n",
      "New theta_0 : [ 0.00636462 -0.07850196  0.11013945  0.01757279  0.09888676 -0.23018415\n",
      "  0.27401404  0.00160876 -0.317957    0.32268474 -0.22366655 -0.21447632\n",
      "  0.09219502 -0.44368098]\n",
      "Training Error:  10.545857594089934\n",
      "====================================================================================================\n",
      "Iteration:  882\n",
      "Previous theta :  [ 0.00636462 -0.07850196  0.11013945  0.01757279  0.09888676 -0.23018415\n",
      "  0.27401404  0.00160876 -0.317957    0.32268474 -0.22366655 -0.21447632\n",
      "  0.09219502 -0.44368098]\n",
      "New theta_0 : [ 0.00636435 -0.0785155   0.11015228  0.01759506  0.09888226 -0.23020645\n",
      "  0.27400183  0.00161596 -0.31797359  0.32276975 -0.22375057 -0.21448406\n",
      "  0.09219242 -0.44368574]\n",
      "Training Error:  10.545842539916794\n",
      "====================================================================================================\n",
      "Iteration:  883\n",
      "Previous theta :  [ 0.00636435 -0.0785155   0.11015228  0.01759506  0.09888226 -0.23020645\n",
      "  0.27400183  0.00161596 -0.31797359  0.32276975 -0.22375057 -0.21448406\n",
      "  0.09219242 -0.44368574]\n",
      "New theta_0 : [ 0.00636408 -0.07852899  0.11016505  0.01761729  0.09887777 -0.2302286\n",
      "  0.27398968  0.00162313 -0.31799006  0.32285451 -0.2238344  -0.21449176\n",
      "  0.09218984 -0.44369049]\n",
      "Training Error:  10.545827572770158\n",
      "====================================================================================================\n",
      "Iteration:  884\n",
      "Previous theta :  [ 0.00636408 -0.07852899  0.11016505  0.01761729  0.09887777 -0.2302286\n",
      "  0.27398968  0.00162313 -0.31799006  0.32285451 -0.2238344  -0.21449176\n",
      "  0.09218984 -0.44369049]\n",
      "New theta_0 : [ 0.00636381 -0.0785424   0.11017776  0.01763947  0.0988733  -0.23025061\n",
      "  0.27397759  0.00163028 -0.3180064   0.32293904 -0.22391803 -0.21449941\n",
      "  0.09218727 -0.44369523]\n",
      "Training Error:  10.545812692080911\n",
      "====================================================================================================\n",
      "Iteration:  885\n",
      "Previous theta :  [ 0.00636381 -0.0785424   0.11017776  0.01763947  0.0988733  -0.23025061\n",
      "  0.27397759  0.00163028 -0.3180064   0.32293904 -0.22391803 -0.21449941\n",
      "  0.09218727 -0.44369523]\n",
      "New theta_0 : [ 0.00636354 -0.07855576  0.11019041  0.0176616   0.09886883 -0.23027247\n",
      "  0.27396554  0.00163741 -0.3180226   0.32302332 -0.22400145 -0.21450703\n",
      "  0.09218472 -0.44369997]\n",
      "Training Error:  10.54579789728451\n",
      "====================================================================================================\n",
      "Iteration:  886\n",
      "Previous theta :  [ 0.00636354 -0.07855576  0.11019041  0.0176616   0.09886883 -0.23027247\n",
      "  0.27396554  0.00163741 -0.3180226   0.32302332 -0.22400145 -0.21450703\n",
      "  0.09218472 -0.44369997]\n",
      "New theta_0 : [ 0.00636328 -0.07856905  0.110203    0.01768369  0.09886438 -0.23029419\n",
      "  0.27395356  0.00164451 -0.31803868  0.32310736 -0.22408468 -0.21451461\n",
      "  0.09218219 -0.44370469]\n",
      "Training Error:  10.54578318782093\n",
      "====================================================================================================\n",
      "Iteration:  887\n",
      "Previous theta :  [ 0.00636328 -0.07856905  0.110203    0.01768369  0.09886438 -0.23029419\n",
      "  0.27395356  0.00164451 -0.31803868  0.32310736 -0.22408468 -0.21451461\n",
      "  0.09218219 -0.44370469]\n",
      "New theta_0 : [ 0.00636301 -0.07858227  0.11021553  0.01770572  0.09885994 -0.23031577\n",
      "  0.27394162  0.00165158 -0.31805464  0.32319116 -0.22416771 -0.21452214\n",
      "  0.09217967 -0.44370941]\n",
      "Training Error:  10.545768563134622\n",
      "====================================================================================================\n",
      "Iteration:  888\n",
      "Previous theta :  [ 0.00636301 -0.07858227  0.11021553  0.01770572  0.09885994 -0.23031577\n",
      "  0.27394162  0.00165158 -0.31805464  0.32319116 -0.22416771 -0.21452214\n",
      "  0.09217967 -0.44370941]\n",
      "New theta_0 : [ 0.00636275 -0.07859544  0.11022801  0.01772771  0.09885551 -0.2303372\n",
      "  0.27392974  0.00165863 -0.31807046  0.32327472 -0.22425054 -0.21452964\n",
      "  0.09217717 -0.44371411]\n",
      "Training Error:  10.545754022674464\n",
      "====================================================================================================\n",
      "Iteration:  889\n",
      "Previous theta :  [ 0.00636275 -0.07859544  0.11022801  0.01772771  0.09885551 -0.2303372\n",
      "  0.27392974  0.00165863 -0.31807046  0.32327472 -0.22425054 -0.21452964\n",
      "  0.09217717 -0.44371411]\n",
      "New theta_0 : [ 0.00636249 -0.07860854  0.11024043  0.01774966  0.09885109 -0.2303585\n",
      "  0.27391791  0.00166566 -0.31808617  0.32335804 -0.22433317 -0.2145371\n",
      "  0.09217469 -0.44371881]\n",
      "Training Error:  10.545739565893708\n",
      "====================================================================================================\n",
      "Iteration:  890\n",
      "Previous theta :  [ 0.00636249 -0.07860854  0.11024043  0.01774966  0.09885109 -0.2303585\n",
      "  0.27391791  0.00166566 -0.31808617  0.32335804 -0.22433317 -0.2145371\n",
      "  0.09217469 -0.44371881]\n",
      "New theta_0 : [ 0.00636223 -0.07862159  0.1102528   0.01777155  0.09884669 -0.23037966\n",
      "  0.27390614  0.00167266 -0.31810175  0.32344112 -0.22441561 -0.21454453\n",
      "  0.09217222 -0.4437235 ]\n",
      "Training Error:  10.545725192249963\n",
      "====================================================================================================\n",
      "Iteration:  891\n",
      "Previous theta :  [ 0.00636223 -0.07862159  0.1102528   0.01777155  0.09884669 -0.23037966\n",
      "  0.27390614  0.00167266 -0.31810175  0.32344112 -0.22441561 -0.21454453\n",
      "  0.09217222 -0.4437235 ]\n",
      "New theta_0 : [ 0.00636197 -0.07863457  0.1102651   0.0177934   0.0988423  -0.23040067\n",
      "  0.27389441  0.00167964 -0.3181172   0.32352397 -0.22449785 -0.21455191\n",
      "  0.09216977 -0.44372818]\n",
      "Training Error:  10.545710901205123\n",
      "====================================================================================================\n",
      "Iteration:  892\n",
      "Previous theta :  [ 0.00636197 -0.07863457  0.1102651   0.0177934   0.0988423  -0.23040067\n",
      "  0.27389441  0.00167964 -0.3181172   0.32352397 -0.22449785 -0.21455191\n",
      "  0.09216977 -0.44372818]\n",
      "New theta_0 : [ 0.00636171 -0.07864749  0.11027735  0.01781519  0.09883792 -0.23042155\n",
      "  0.27388274  0.0016866  -0.31813254  0.32360657 -0.22457989 -0.21455925\n",
      "  0.09216733 -0.44373286]\n",
      "Training Error:  10.54569669222534\n",
      "====================================================================================================\n",
      "Iteration:  893\n",
      "Previous theta :  [ 0.00636171 -0.07864749  0.11027735  0.01781519  0.09883792 -0.23042155\n",
      "  0.27388274  0.0016866  -0.31813254  0.32360657 -0.22457989 -0.21455925\n",
      "  0.09216733 -0.44373286]\n",
      "New theta_0 : [ 0.00636146 -0.07866035  0.11028955  0.01783695  0.09883355 -0.2304423\n",
      "  0.27387112  0.00169353 -0.31814775  0.32368895 -0.22466173 -0.21456656\n",
      "  0.09216491 -0.44373752]\n",
      "Training Error:  10.545682564780973\n",
      "====================================================================================================\n",
      "Iteration:  894\n",
      "Previous theta :  [ 0.00636146 -0.07866035  0.11028955  0.01783695  0.09883355 -0.2304423\n",
      "  0.27387112  0.00169353 -0.31814775  0.32368895 -0.22466173 -0.21456656\n",
      "  0.09216491 -0.44373752]\n",
      "New theta_0 : [ 0.0063612  -0.07867315  0.11030169  0.01785865  0.09882919 -0.23046291\n",
      "  0.27385955  0.00170044 -0.31816285  0.32377109 -0.22474338 -0.21457383\n",
      "  0.0921625  -0.44374218]\n",
      "Training Error:  10.545668518346552\n",
      "====================================================================================================\n",
      "Iteration:  895\n",
      "Previous theta :  [ 0.0063612  -0.07867315  0.11030169  0.01785865  0.09882919 -0.23046291\n",
      "  0.27385955  0.00170044 -0.31816285  0.32377109 -0.22474338 -0.21457383\n",
      "  0.0921625  -0.44374218]\n",
      "New theta_0 : [ 0.00636095 -0.07868589  0.11031377  0.01788031  0.09882484 -0.23048338\n",
      "  0.27384803  0.00170732 -0.31817782  0.32385299 -0.22482483 -0.21458107\n",
      "  0.09216011 -0.44374683]\n",
      "Training Error:  10.545654552400737\n",
      "====================================================================================================\n",
      "Iteration:  896\n",
      "Previous theta :  [ 0.00636095 -0.07868589  0.11031377  0.01788031  0.09882484 -0.23048338\n",
      "  0.27384803  0.00170732 -0.31817782  0.32385299 -0.22482483 -0.21458107\n",
      "  0.09216011 -0.44374683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.0063607  -0.07869857  0.1103258   0.01790192  0.09882051 -0.23050372\n",
      "  0.27383657  0.00171418 -0.31819268  0.32393466 -0.22490609 -0.21458826\n",
      "  0.09215774 -0.44375147]\n",
      "Training Error:  10.545640666426271\n",
      "====================================================================================================\n",
      "Iteration:  897\n",
      "Previous theta :  [ 0.0063607  -0.07869857  0.1103258   0.01790192  0.09882051 -0.23050372\n",
      "  0.27383657  0.00171418 -0.31819268  0.32393466 -0.22490609 -0.21458826\n",
      "  0.09215774 -0.44375147]\n",
      "New theta_0 : [ 0.00636045 -0.07871119  0.11033778  0.01792348  0.09881619 -0.23052393\n",
      "  0.27382515  0.00172102 -0.31820741  0.3240161  -0.22498715 -0.21459542\n",
      "  0.09215538 -0.4437561 ]\n",
      "Training Error:  10.545626859909943\n",
      "====================================================================================================\n",
      "Iteration:  898\n",
      "Previous theta :  [ 0.00636045 -0.07871119  0.11033778  0.01792348  0.09881619 -0.23052393\n",
      "  0.27382515  0.00172102 -0.31820741  0.3240161  -0.22498715 -0.21459542\n",
      "  0.09215538 -0.4437561 ]\n",
      "New theta_0 : [ 0.0063602  -0.07872375  0.1103497   0.01794499  0.09881187 -0.230544\n",
      "  0.27381378  0.00172784 -0.31822204  0.3240973  -0.22506802 -0.21460254\n",
      "  0.09215303 -0.44376072]\n",
      "Training Error:  10.54561313234255\n",
      "====================================================================================================\n",
      "Iteration:  899\n",
      "Previous theta :  [ 0.0063602  -0.07872375  0.1103497   0.01794499  0.09881187 -0.230544\n",
      "  0.27381378  0.00172784 -0.31822204  0.3240973  -0.22506802 -0.21460254\n",
      "  0.09215303 -0.44376072]\n",
      "New theta_0 : [ 0.00635995 -0.07873626  0.11036157  0.01796646  0.09880758 -0.23056395\n",
      "  0.27380247  0.00173463 -0.31823654  0.32417828 -0.22514869 -0.21460963\n",
      "  0.0921507  -0.44376534]\n",
      "Training Error:  10.545599483218856\n",
      "====================================================================================================\n",
      "Iteration:  900\n",
      "Previous theta :  [ 0.00635995 -0.07873626  0.11036157  0.01796646  0.09880758 -0.23056395\n",
      "  0.27380247  0.00173463 -0.31823654  0.32417828 -0.22514869 -0.21460963\n",
      "  0.0921507  -0.44376534]\n",
      "New theta_0 : [ 0.0063597  -0.07874871  0.11037338  0.01798788  0.09880329 -0.23058376\n",
      "  0.2737912   0.0017414  -0.31825093  0.32425902 -0.22522917 -0.21461668\n",
      "  0.09214839 -0.44376995]\n",
      "Training Error:  10.545585912037549\n",
      "====================================================================================================\n",
      "Iteration:  901\n",
      "Previous theta :  [ 0.0063597  -0.07874871  0.11037338  0.01798788  0.09880329 -0.23058376\n",
      "  0.2737912   0.0017414  -0.31825093  0.32425902 -0.22522917 -0.21461668\n",
      "  0.09214839 -0.44376995]\n",
      "New theta_0 : [ 0.00635945 -0.07876109  0.11038514  0.01800925  0.09879901 -0.23060345\n",
      "  0.27377998  0.00174814 -0.31826521  0.32433953 -0.22530945 -0.21462369\n",
      "  0.09214609 -0.44377455]\n",
      "Training Error:  10.545572418301207\n",
      "====================================================================================================\n",
      "Iteration:  902\n",
      "Previous theta :  [ 0.00635945 -0.07876109  0.11038514  0.01800925  0.09879901 -0.23060345\n",
      "  0.27377998  0.00174814 -0.31826521  0.32433953 -0.22530945 -0.21462369\n",
      "  0.09214609 -0.44377455]\n",
      "New theta_0 : [ 0.00635921 -0.07877343  0.11039685  0.01803057  0.09879474 -0.230623\n",
      "  0.27376881  0.00175486 -0.31827937  0.32441982 -0.22538954 -0.21463067\n",
      "  0.09214381 -0.44377914]\n",
      "Training Error:  10.545559001516263\n",
      "====================================================================================================\n",
      "Iteration:  903\n",
      "Previous theta :  [ 0.00635921 -0.07877343  0.11039685  0.01803057  0.09879474 -0.230623\n",
      "  0.27376881  0.00175486 -0.31827937  0.32441982 -0.22538954 -0.21463067\n",
      "  0.09214381 -0.44377914]\n",
      "New theta_0 : [ 0.00635897 -0.0787857   0.1104085   0.01805185  0.09879049 -0.23064243\n",
      "  0.27375769  0.00176156 -0.31829343  0.32449987 -0.22546944 -0.21463761\n",
      "  0.09214154 -0.44378372]\n",
      "Training Error:  10.54554566119296\n",
      "====================================================================================================\n",
      "Iteration:  904\n",
      "Previous theta :  [ 0.00635897 -0.0787857   0.1104085   0.01805185  0.09879049 -0.23064243\n",
      "  0.27375769  0.00176156 -0.31829343  0.32449987 -0.22546944 -0.21463761\n",
      "  0.09214154 -0.44378372]\n",
      "New theta_0 : [ 0.00635872 -0.07879792  0.11042011  0.01807308  0.09878625 -0.23066173\n",
      "  0.27374662  0.00176824 -0.31830737  0.3245797  -0.22554915 -0.21464452\n",
      "  0.09213928 -0.44378829]\n",
      "Training Error:  10.545532396845312\n",
      "====================================================================================================\n",
      "Iteration:  905\n",
      "Previous theta :  [ 0.00635872 -0.07879792  0.11042011  0.01807308  0.09878625 -0.23066173\n",
      "  0.27374662  0.00176824 -0.31830737  0.3245797  -0.22554915 -0.21464452\n",
      "  0.09213928 -0.44378829]\n",
      "New theta_0 : [ 0.00635848 -0.07881008  0.11043166  0.01809426  0.09878202 -0.23068091\n",
      "  0.2737356   0.0017749  -0.3183212   0.3246593  -0.22562867 -0.21465139\n",
      "  0.09213704 -0.44379286]\n",
      "Training Error:  10.545519207991081\n",
      "====================================================================================================\n",
      "Iteration:  906\n",
      "Previous theta :  [ 0.00635848 -0.07881008  0.11043166  0.01809426  0.09878202 -0.23068091\n",
      "  0.2737356   0.0017749  -0.3183212   0.3246593  -0.22562867 -0.21465139\n",
      "  0.09213704 -0.44379286]\n",
      "New theta_0 : [ 0.00635824 -0.07882219  0.11044316  0.0181154   0.0987778  -0.23069996\n",
      "  0.27372462  0.00178153 -0.31833492  0.32473868 -0.22570799 -0.21465823\n",
      "  0.09213481 -0.44379741]\n",
      "Training Error:  10.545506094151728\n",
      "====================================================================================================\n",
      "Iteration:  907\n",
      "Previous theta :  [ 0.00635824 -0.07882219  0.11044316  0.0181154   0.0987778  -0.23069996\n",
      "  0.27372462  0.00178153 -0.31833492  0.32473868 -0.22570799 -0.21465823\n",
      "  0.09213481 -0.44379741]\n",
      "New theta_0 : [ 0.006358   -0.07883424  0.1104546   0.01813648  0.09877359 -0.23071889\n",
      "  0.27371369  0.00178814 -0.31834853  0.32481783 -0.22578712 -0.21466503\n",
      "  0.0921326  -0.44380196]\n",
      "Training Error:  10.545493054852377\n",
      "====================================================================================================\n",
      "Iteration:  908\n",
      "Previous theta :  [ 0.006358   -0.07883424  0.1104546   0.01813648  0.09877359 -0.23071889\n",
      "  0.27371369  0.00178814 -0.31834853  0.32481783 -0.22578712 -0.21466503\n",
      "  0.0921326  -0.44380196]\n",
      "New theta_0 : [ 0.00635777 -0.07884623  0.110466    0.01815752  0.09876939 -0.23073769\n",
      "  0.27370281  0.00179473 -0.31836203  0.32489675 -0.22586607 -0.2146718\n",
      "  0.0921304  -0.4438065 ]\n",
      "Training Error:  10.545480089621787\n",
      "====================================================================================================\n",
      "Iteration:  909\n",
      "Previous theta :  [ 0.00635777 -0.07884623  0.110466    0.01815752  0.09876939 -0.23073769\n",
      "  0.27370281  0.00179473 -0.31836203  0.32489675 -0.22586607 -0.2146718\n",
      "  0.0921304  -0.4438065 ]\n",
      "New theta_0 : [ 0.00635753 -0.07885817  0.11047734  0.01817852  0.0987652  -0.23075637\n",
      "  0.27369198  0.00180129 -0.31837543  0.32497545 -0.22594482 -0.21467853\n",
      "  0.09212821 -0.44381104]\n",
      "Training Error:  10.545467197992313\n",
      "====================================================================================================\n",
      "Iteration:  910\n",
      "Previous theta :  [ 0.00635753 -0.07885817  0.11047734  0.01817852  0.0987652  -0.23075637\n",
      "  0.27369198  0.00180129 -0.31837543  0.32497545 -0.22594482 -0.21467853\n",
      "  0.09212821 -0.44381104]\n",
      "New theta_0 : [ 0.0063573  -0.07887006  0.11048864  0.01819946  0.09876103 -0.23077493\n",
      "  0.27368119  0.00180784 -0.31838872  0.32505393 -0.22602338 -0.21468523\n",
      "  0.09212604 -0.44381556]\n",
      "Training Error:  10.545454379499873\n",
      "====================================================================================================\n",
      "Iteration:  911\n",
      "Previous theta :  [ 0.0063573  -0.07887006  0.11048864  0.01819946  0.09876103 -0.23077493\n",
      "  0.27368119  0.00180784 -0.31838872  0.32505393 -0.22602338 -0.21468523\n",
      "  0.09212604 -0.44381556]\n",
      "New theta_0 : [ 0.00635706 -0.07888189  0.11049988  0.01822036  0.09875687 -0.23079337\n",
      "  0.27367045  0.00181436 -0.3184019   0.32513218 -0.22610175 -0.21469189\n",
      "  0.09212389 -0.44382008]\n",
      "Training Error:  10.545441633683906\n",
      "====================================================================================================\n",
      "Iteration:  912\n",
      "Previous theta :  [ 0.00635706 -0.07888189  0.11049988  0.01822036  0.09875687 -0.23079337\n",
      "  0.27367045  0.00181436 -0.3184019   0.32513218 -0.22610175 -0.21469189\n",
      "  0.09212389 -0.44382008]\n",
      "New theta_0 : [ 0.00635683 -0.07889366  0.11051108  0.01824122  0.09875271 -0.23081168\n",
      "  0.27365976  0.00182086 -0.31841498  0.32521022 -0.22617993 -0.21469852\n",
      "  0.09212174 -0.44382459]\n",
      "Training Error:  10.545428960087351\n",
      "====================================================================================================\n",
      "Iteration:  913\n",
      "Previous theta :  [ 0.00635683 -0.07889366  0.11051108  0.01824122  0.09875271 -0.23081168\n",
      "  0.27365976  0.00182086 -0.31841498  0.32521022 -0.22617993 -0.21469852\n",
      "  0.09212174 -0.44382459]\n",
      "New theta_0 : [ 0.0063566  -0.07890539  0.11052222  0.01826202  0.09874857 -0.23082988\n",
      "  0.27364911  0.00182734 -0.31842795  0.32528803 -0.22625793 -0.21470512\n",
      "  0.09211961 -0.44382909]\n",
      "Training Error:  10.545416358256606\n",
      "====================================================================================================\n",
      "Iteration:  914\n",
      "Previous theta :  [ 0.0063566  -0.07890539  0.11052222  0.01826202  0.09874857 -0.23082988\n",
      "  0.27364911  0.00182734 -0.31842795  0.32528803 -0.22625793 -0.21470512\n",
      "  0.09211961 -0.44382909]\n",
      "New theta_0 : [ 0.00635637 -0.07891705  0.11053332  0.01828278  0.09874444 -0.23084796\n",
      "  0.27363851  0.00183379 -0.31844082  0.32536562 -0.22633573 -0.21471168\n",
      "  0.0921175  -0.44383358]\n",
      "Training Error:  10.54540382774149\n",
      "====================================================================================================\n",
      "Iteration:  915\n",
      "Previous theta :  [ 0.00635637 -0.07891705  0.11053332  0.01828278  0.09874444 -0.23084796\n",
      "  0.27363851  0.00183379 -0.31844082  0.32536562 -0.22633573 -0.21471168\n",
      "  0.0921175  -0.44383358]\n",
      "New theta_0 : [ 0.00635614 -0.07892867  0.11054437  0.01830349  0.09874032 -0.23086592\n",
      "  0.27362795  0.00184023 -0.31845359  0.32544299 -0.22641335 -0.21471821\n",
      "  0.09211539 -0.44383806]\n",
      "Training Error:  10.545391368095222\n",
      "====================================================================================================\n",
      "Iteration:  916\n",
      "Previous theta :  [ 0.00635614 -0.07892867  0.11054437  0.01830349  0.09874032 -0.23086592\n",
      "  0.27362795  0.00184023 -0.31845359  0.32544299 -0.22641335 -0.21471821\n",
      "  0.09211539 -0.44383806]\n",
      "New theta_0 : [ 0.00635591 -0.07894023  0.11055536  0.01832416  0.09873621 -0.23088377\n",
      "  0.27361744  0.00184664 -0.31846626  0.32552014 -0.22649078 -0.21472471\n",
      "  0.0921133  -0.44384254]\n",
      "Training Error:  10.54537897887438\n",
      "====================================================================================================\n",
      "Iteration:  917\n",
      "Previous theta :  [ 0.00635591 -0.07894023  0.11055536  0.01832416  0.09873621 -0.23088377\n",
      "  0.27361744  0.00184664 -0.31846626  0.32552014 -0.22649078 -0.21472471\n",
      "  0.0921133  -0.44384254]\n",
      "New theta_0 : [ 0.00635568 -0.07895174  0.11056631  0.01834478  0.09873211 -0.2309015\n",
      "  0.27360697  0.00185303 -0.31847883  0.32559708 -0.22656802 -0.21473117\n",
      "  0.09211123 -0.443847  ]\n",
      "Training Error:  10.545366659638873\n",
      "====================================================================================================\n",
      "Iteration:  918\n",
      "Previous theta :  [ 0.00635568 -0.07895174  0.11056631  0.01834478  0.09873211 -0.2309015\n",
      "  0.27360697  0.00185303 -0.31847883  0.32559708 -0.22656802 -0.21473117\n",
      "  0.09211123 -0.443847  ]\n",
      "New theta_0 : [ 0.00635546 -0.0789632   0.11057721  0.01836535  0.09872803 -0.23091911\n",
      "  0.27359655  0.00185941 -0.31849129  0.32567379 -0.22664507 -0.21473761\n",
      "  0.09210917 -0.44385146]\n",
      "Training Error:  10.545354409951909\n",
      "====================================================================================================\n",
      "Iteration:  919\n",
      "Previous theta :  [ 0.00635546 -0.0789632   0.11057721  0.01836535  0.09872803 -0.23091911\n",
      "  0.27359655  0.00185941 -0.31849129  0.32567379 -0.22664507 -0.21473761\n",
      "  0.09210917 -0.44385146]\n",
      "New theta_0 : [ 0.00635523 -0.07897461  0.11058807  0.01838587  0.09872395 -0.23093661\n",
      "  0.27358617  0.00186576 -0.31850366  0.32575029 -0.22672194 -0.21474401\n",
      "  0.09210712 -0.44385591]\n",
      "Training Error:  10.545342229379957\n",
      "====================================================================================================\n",
      "Iteration:  920\n",
      "Previous theta :  [ 0.00635523 -0.07897461  0.11058807  0.01838587  0.09872395 -0.23093661\n",
      "  0.27358617  0.00186576 -0.31850366  0.32575029 -0.22672194 -0.21474401\n",
      "  0.09210712 -0.44385591]\n",
      "New theta_0 : [ 0.00635501 -0.07898596  0.11059887  0.01840635  0.09871989 -0.23095399\n",
      "  0.27357584  0.00187208 -0.31851593  0.32582658 -0.22679862 -0.21475037\n",
      "  0.09210508 -0.44386036]\n",
      "Training Error:  10.54533011749273\n",
      "====================================================================================================\n",
      "Iteration:  921\n",
      "Previous theta :  [ 0.00635501 -0.07898596  0.11059887  0.01840635  0.09871989 -0.23095399\n",
      "  0.27357584  0.00187208 -0.31851593  0.32582658 -0.22679862 -0.21475037\n",
      "  0.09210508 -0.44386036]\n",
      "New theta_0 : [ 0.00635479 -0.07899727  0.11060963  0.01842678  0.09871583 -0.23097126\n",
      "  0.27356555  0.00187839 -0.3185281   0.32590264 -0.22687512 -0.21475671\n",
      "  0.09210305 -0.44386479]\n",
      "Training Error:  10.545318073863141\n",
      "====================================================================================================\n",
      "Iteration:  922\n",
      "Previous theta :  [ 0.00635479 -0.07899727  0.11060963  0.01842678  0.09871583 -0.23097126\n",
      "  0.27356555  0.00187839 -0.3185281   0.32590264 -0.22687512 -0.21475671\n",
      "  0.09210305 -0.44386479]\n",
      "New theta_0 : [ 0.00635457 -0.07900852  0.11062034  0.01844717  0.09871179 -0.23098842\n",
      "  0.2735553   0.00188468 -0.31854017  0.32597849 -0.22695143 -0.21476301\n",
      "  0.09210104 -0.44386922]\n",
      "Training Error:  10.545306098067284\n",
      "====================================================================================================\n",
      "Iteration:  923\n",
      "Previous theta :  [ 0.00635457 -0.07900852  0.11062034  0.01844717  0.09871179 -0.23098842\n",
      "  0.2735553   0.00188468 -0.31854017  0.32597849 -0.22695143 -0.21476301\n",
      "  0.09210104 -0.44386922]\n",
      "New theta_0 : [ 0.00635435 -0.07901972  0.110631    0.0184675   0.09870776 -0.23100547\n",
      "  0.2735451   0.00189094 -0.31855214  0.32605413 -0.22702756 -0.21476928\n",
      "  0.09209904 -0.44387363]\n",
      "Training Error:  10.545294189684391\n",
      "====================================================================================================\n",
      "Iteration:  924\n",
      "Previous theta :  [ 0.00635435 -0.07901972  0.110631    0.0184675   0.09870776 -0.23100547\n",
      "  0.2735451   0.00189094 -0.31855214  0.32605413 -0.22702756 -0.21476928\n",
      "  0.09209904 -0.44387363]\n",
      "New theta_0 : [ 0.00635413 -0.07903087  0.11064162  0.0184878   0.09870374 -0.23102241\n",
      "  0.27353494  0.00189719 -0.31856402  0.32612956 -0.2271035  -0.21477552\n",
      "  0.09209706 -0.44387805]\n",
      "Training Error:  10.545282348296816\n",
      "====================================================================================================\n",
      "Iteration:  925\n",
      "Previous theta :  [ 0.00635413 -0.07903087  0.11064162  0.0184878   0.09870374 -0.23102241\n",
      "  0.27353494  0.00189719 -0.31856402  0.32612956 -0.2271035  -0.21477552\n",
      "  0.09209706 -0.44387805]\n",
      "New theta_0 : [ 0.00635391 -0.07904197  0.11065219  0.01850804  0.09869972 -0.23103923\n",
      "  0.27352483  0.00190341 -0.31857581  0.32620477 -0.22717926 -0.21478173\n",
      "  0.09209508 -0.44388245]\n",
      "Training Error:  10.545270573489997\n",
      "====================================================================================================\n",
      "Iteration:  926\n",
      "Previous theta :  [ 0.00635391 -0.07904197  0.11065219  0.01850804  0.09869972 -0.23103923\n",
      "  0.27352483  0.00190341 -0.31857581  0.32620477 -0.22717926 -0.21478173\n",
      "  0.09209508 -0.44388245]\n",
      "New theta_0 : [ 0.00635369 -0.07905302  0.11066271  0.01852824  0.09869572 -0.23105595\n",
      "  0.27351475  0.00190962 -0.3185875   0.32627976 -0.22725483 -0.21478791\n",
      "  0.09209312 -0.44388684]\n",
      "Training Error:  10.545258864852434\n",
      "====================================================================================================\n",
      "Iteration:  927\n",
      "Previous theta :  [ 0.00635369 -0.07905302  0.11066271  0.01852824  0.09869572 -0.23105595\n",
      "  0.27351475  0.00190962 -0.3185875   0.32627976 -0.22725483 -0.21478791\n",
      "  0.09209312 -0.44388684]\n",
      "New theta_0 : [ 0.00635348 -0.07906402  0.11067319  0.01854839  0.09869173 -0.23107256\n",
      "  0.27350472  0.0019158  -0.3185991   0.32635455 -0.22733022 -0.21479406\n",
      "  0.09209117 -0.44389123]\n",
      "Training Error:  10.54524722197565\n",
      "====================================================================================================\n",
      "Iteration:  928\n",
      "Previous theta :  [ 0.00635348 -0.07906402  0.11067319  0.01854839  0.09869173 -0.23107256\n",
      "  0.27350472  0.0019158  -0.3185991   0.32635455 -0.22733022 -0.21479406\n",
      "  0.09209117 -0.44389123]\n",
      "New theta_0 : [ 0.00635326 -0.07907497  0.11068363  0.0185685   0.09868775 -0.23108906\n",
      "  0.27349473  0.00192196 -0.3186106   0.32642913 -0.22740542 -0.21480017\n",
      "  0.09208924 -0.44389561]\n",
      "Training Error:  10.545235644454177\n",
      "====================================================================================================\n",
      "Iteration:  929\n",
      "Previous theta :  [ 0.00635326 -0.07907497  0.11068363  0.0185685   0.09868775 -0.23108906\n",
      "  0.27349473  0.00192196 -0.3186106   0.32642913 -0.22740542 -0.21480017\n",
      "  0.09208924 -0.44389561]\n",
      "New theta_0 : [ 0.00635305 -0.07908587  0.11069401  0.01858856  0.09868379 -0.23110545\n",
      "  0.27348479  0.0019281  -0.31862201  0.32650349 -0.22748045 -0.21480626\n",
      "  0.09208731 -0.44389998]\n",
      "Training Error:  10.545224131885515\n",
      "====================================================================================================\n",
      "Iteration:  930\n",
      "Previous theta :  [ 0.00635305 -0.07908587  0.11069401  0.01858856  0.09868379 -0.23110545\n",
      "  0.27348479  0.0019281  -0.31862201  0.32650349 -0.22748045 -0.21480626\n",
      "  0.09208731 -0.44389998]\n",
      "New theta_0 : [ 0.00635284 -0.07909673  0.11070435  0.01860857  0.09867983 -0.23112174\n",
      "  0.27347488  0.00193423 -0.31863333  0.32657765 -0.22755529 -0.21481231\n",
      "  0.0920854  -0.44390434]\n",
      "Training Error:  10.545212683870117\n",
      "====================================================================================================\n",
      "Iteration:  931\n",
      "Previous theta :  [ 0.00635284 -0.07909673  0.11070435  0.01860857  0.09867983 -0.23112174\n",
      "  0.27347488  0.00193423 -0.31863333  0.32657765 -0.22755529 -0.21481231\n",
      "  0.0920854  -0.44390434]\n",
      "New theta_0 : [ 0.00635263 -0.07910753  0.11071465  0.01862854  0.09867588 -0.23113792\n",
      "  0.27346502  0.00194033 -0.31864456  0.3266516  -0.22762995 -0.21481834\n",
      "  0.0920835  -0.44390869]\n",
      "Training Error:  10.545201300011346\n",
      "====================================================================================================\n",
      "Iteration:  932\n",
      "Previous theta :  [ 0.00635263 -0.07910753  0.11071465  0.01862854  0.09867588 -0.23113792\n",
      "  0.27346502  0.00194033 -0.31864456  0.3266516  -0.22762995 -0.21481834\n",
      "  0.0920835  -0.44390869]\n",
      "New theta_0 : [ 0.00635242 -0.07911829  0.1107249   0.01864846  0.09867194 -0.231154\n",
      "  0.2734552   0.00194641 -0.3186557   0.32672533 -0.22770442 -0.21482433\n",
      "  0.09208161 -0.44391304]\n",
      "Training Error:  10.545189979915465\n",
      "====================================================================================================\n",
      "Iteration:  933\n",
      "Previous theta :  [ 0.00635242 -0.07911829  0.1107249   0.01864846  0.09867194 -0.231154\n",
      "  0.2734552   0.00194641 -0.3186557   0.32672533 -0.22770442 -0.21482433\n",
      "  0.09208161 -0.44391304]\n",
      "New theta_0 : [ 0.00635221 -0.079129    0.11073511  0.01866834  0.09866802 -0.23116997\n",
      "  0.27344542  0.00195247 -0.31866675  0.32679887 -0.22777872 -0.21483029\n",
      "  0.09207974 -0.44391737]\n",
      "Training Error:  10.545178723191599\n",
      "====================================================================================================\n",
      "Iteration:  934\n",
      "Previous theta :  [ 0.00635221 -0.079129    0.11073511  0.01866834  0.09866802 -0.23116997\n",
      "  0.27344542  0.00195247 -0.31866675  0.32679887 -0.22777872 -0.21483029\n",
      "  0.09207974 -0.44391737]\n",
      "New theta_0 : [ 0.006352   -0.07913966  0.11074528  0.01868817  0.0986641  -0.23118584\n",
      "  0.27343568  0.00195851 -0.31867771  0.32687219 -0.22785283 -0.21483623\n",
      "  0.09207787 -0.4439217 ]\n",
      "Training Error:  10.545167529451716\n",
      "====================================================================================================\n",
      "Iteration:  935\n",
      "Previous theta :  [ 0.006352   -0.07913966  0.11074528  0.01868817  0.0986641  -0.23118584\n",
      "  0.27343568  0.00195851 -0.31867771  0.32687219 -0.22785283 -0.21483623\n",
      "  0.09207787 -0.4439217 ]\n",
      "New theta_0 : [ 0.00635179 -0.07915027  0.1107554   0.01870795  0.0986602  -0.2312016\n",
      "  0.27342598  0.00196454 -0.31868858  0.32694531 -0.22792677 -0.21484213\n",
      "  0.09207602 -0.44392603]\n",
      "Training Error:  10.545156398310587\n",
      "====================================================================================================\n",
      "Iteration:  936\n",
      "Previous theta :  [ 0.00635179 -0.07915027  0.1107554   0.01870795  0.0986602  -0.2312016\n",
      "  0.27342598  0.00196454 -0.31868858  0.32694531 -0.22792677 -0.21484213\n",
      "  0.09207602 -0.44392603]\n",
      "New theta_0 : [ 0.00635158 -0.07916084  0.11076547  0.01872769  0.0986563  -0.23121727\n",
      "  0.27341632  0.00197054 -0.31869937  0.32701822 -0.22800052 -0.21484801\n",
      "  0.09207418 -0.44393034]\n",
      "Training Error:  10.545145329385784\n",
      "====================================================================================================\n",
      "Iteration:  937\n",
      "Previous theta :  [ 0.00635158 -0.07916084  0.11076547  0.01872769  0.0986563  -0.23121727\n",
      "  0.27341632  0.00197054 -0.31869937  0.32701822 -0.22800052 -0.21484801\n",
      "  0.09207418 -0.44393034]\n",
      "New theta_0 : [ 0.00635138 -0.07917136  0.11077551  0.01874738  0.09865242 -0.23123283\n",
      "  0.2734067   0.00197652 -0.31871006  0.32709092 -0.2280741  -0.21485386\n",
      "  0.09207235 -0.44393464]\n",
      "Training Error:  10.545134322297635\n",
      "====================================================================================================\n",
      "Iteration:  938\n",
      "Previous theta :  [ 0.00635138 -0.07917136  0.11077551  0.01874738  0.09865242 -0.23123283\n",
      "  0.2734067   0.00197652 -0.31871006  0.32709092 -0.2280741  -0.21485386\n",
      "  0.09207235 -0.44393464]\n",
      "New theta_0 : [ 0.00635118 -0.07918183  0.1107855   0.01876703  0.09864854 -0.23124829\n",
      "  0.27339712  0.00198248 -0.31872067  0.32716343 -0.22814749 -0.21485968\n",
      "  0.09207053 -0.44393894]\n",
      "Training Error:  10.545123376669205\n",
      "====================================================================================================\n",
      "Iteration:  939\n",
      "Previous theta :  [ 0.00635118 -0.07918183  0.1107855   0.01876703  0.09864854 -0.23124829\n",
      "  0.27339712  0.00198248 -0.31872067  0.32716343 -0.22814749 -0.21485968\n",
      "  0.09207053 -0.44393894]\n",
      "New theta_0 : [ 0.00635097 -0.07919225  0.11079545  0.01878663  0.09864468 -0.23126365\n",
      "  0.27338758  0.00198843 -0.3187312   0.32723572 -0.22822071 -0.21486546\n",
      "  0.09206872 -0.44394323]\n",
      "Training Error:  10.545112492126272\n",
      "====================================================================================================\n",
      "Iteration:  940\n",
      "Previous theta :  [ 0.00635097 -0.07919225  0.11079545  0.01878663  0.09864468 -0.23126365\n",
      "  0.27338758  0.00198843 -0.3187312   0.32723572 -0.22822071 -0.21486546\n",
      "  0.09206872 -0.44394323]\n",
      "New theta_0 : [ 0.00635077 -0.07920263  0.11080535  0.01880619  0.09864082 -0.23127891\n",
      "  0.27337808  0.00199435 -0.31874164  0.32730782 -0.22829375 -0.21487122\n",
      "  0.09206693 -0.44394751]\n",
      "Training Error:  10.545101668297301\n",
      "====================================================================================================\n",
      "Iteration:  941\n",
      "Previous theta :  [ 0.00635077 -0.07920263  0.11080535  0.01880619  0.09864082 -0.23127891\n",
      "  0.27337808  0.00199435 -0.31874164  0.32730782 -0.22829375 -0.21487122\n",
      "  0.09206693 -0.44394751]\n",
      "New theta_0 : [ 0.00635057 -0.07921297  0.11081521  0.0188257   0.09863698 -0.23129407\n",
      "  0.27336862  0.00200026 -0.318752    0.32737971 -0.22836661 -0.21487696\n",
      "  0.09206514 -0.44395179]\n",
      "Training Error:  10.545090904813422\n",
      "====================================================================================================\n",
      "Iteration:  942\n",
      "Previous theta :  [ 0.00635057 -0.07921297  0.11081521  0.0188257   0.09863698 -0.23129407\n",
      "  0.27336862  0.00200026 -0.318752    0.32737971 -0.22836661 -0.21487696\n",
      "  0.09206514 -0.44395179]\n",
      "New theta_0 : [ 0.00635037 -0.07922326  0.11082503  0.01884516  0.09863315 -0.23130914\n",
      "  0.2733592   0.00200614 -0.31876227  0.3274514  -0.22843929 -0.21488266\n",
      "  0.09206337 -0.44395605]\n",
      "Training Error:  10.545080201308405\n",
      "====================================================================================================\n",
      "Iteration:  943\n",
      "Previous theta :  [ 0.00635037 -0.07922326  0.11082503  0.01884516  0.09863315 -0.23130914\n",
      "  0.2733592   0.00200614 -0.31876227  0.3274514  -0.22843929 -0.21488266\n",
      "  0.09206337 -0.44395605]\n",
      "New theta_0 : [ 0.00635017 -0.0792335   0.11083481  0.01886458  0.09862932 -0.2313241\n",
      "  0.27334982  0.00201201 -0.31877246  0.32752289 -0.22851179 -0.21488833\n",
      "  0.09206161 -0.44396031]\n",
      "Training Error:  10.545069557418635\n",
      "====================================================================================================\n",
      "Iteration:  944\n",
      "Previous theta :  [ 0.00635017 -0.0792335   0.11083481  0.01886458  0.09862932 -0.2313241\n",
      "  0.27334982  0.00201201 -0.31877246  0.32752289 -0.22851179 -0.21488833\n",
      "  0.09206161 -0.44396031]\n",
      "New theta_0 : [ 0.00634997 -0.0792437   0.11084455  0.01888395  0.09862551 -0.23133897\n",
      "  0.27334048  0.00201785 -0.31878257  0.32759418 -0.22858412 -0.21489398\n",
      "  0.09205986 -0.44396456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.545058972783087\n",
      "====================================================================================================\n",
      "Iteration:  945\n",
      "Previous theta :  [ 0.00634997 -0.0792437   0.11084455  0.01888395  0.09862551 -0.23133897\n",
      "  0.27334048  0.00201785 -0.31878257  0.32759418 -0.22858412 -0.21489398\n",
      "  0.09205986 -0.44396456]\n",
      "New theta_0 : [ 0.00634978 -0.07925385  0.11085424  0.01890328  0.09862171 -0.23135374\n",
      "  0.27333117  0.00202368 -0.3187926   0.32766527 -0.22865627 -0.2148996\n",
      "  0.09205811 -0.4439688 ]\n",
      "Training Error:  10.545048447043307\n",
      "====================================================================================================\n",
      "Iteration:  946\n",
      "Previous theta :  [ 0.00634978 -0.07925385  0.11085424  0.01890328  0.09862171 -0.23135374\n",
      "  0.27333117  0.00202368 -0.3187926   0.32766527 -0.22865627 -0.2148996\n",
      "  0.09205811 -0.4439688 ]\n",
      "New theta_0 : [ 0.00634958 -0.07926396  0.1108639   0.01892256  0.09861791 -0.23136842\n",
      "  0.27332191  0.00202949 -0.31880254  0.32773616 -0.22872824 -0.21490519\n",
      "  0.09205638 -0.44397304]\n",
      "Training Error:  10.545037979843388\n",
      "====================================================================================================\n",
      "Iteration:  947\n",
      "Previous theta :  [ 0.00634958 -0.07926396  0.1108639   0.01892256  0.09861791 -0.23136842\n",
      "  0.27332191  0.00202949 -0.31880254  0.32773616 -0.22872824 -0.21490519\n",
      "  0.09205638 -0.44397304]\n",
      "New theta_0 : [ 0.00634938 -0.07927402  0.11087351  0.0189418   0.09861413 -0.231383\n",
      "  0.27331268  0.00203528 -0.31881241  0.32780685 -0.22880004 -0.21491075\n",
      "  0.09205467 -0.44397726]\n",
      "Training Error:  10.545027570829943\n",
      "====================================================================================================\n",
      "Iteration:  948\n",
      "Previous theta :  [ 0.00634938 -0.07927402  0.11087351  0.0189418   0.09861413 -0.231383\n",
      "  0.27331268  0.00203528 -0.31881241  0.32780685 -0.22880004 -0.21491075\n",
      "  0.09205467 -0.44397726]\n",
      "New theta_0 : [ 0.00634919 -0.07928404  0.11088308  0.01896099  0.09861036 -0.23139749\n",
      "  0.27330349  0.00204105 -0.31882219  0.32787734 -0.22887166 -0.21491629\n",
      "  0.09205296 -0.44398148]\n",
      "Training Error:  10.545017219652092\n",
      "====================================================================================================\n",
      "Iteration:  949\n",
      "Previous theta :  [ 0.00634919 -0.07928404  0.11088308  0.01896099  0.09861036 -0.23139749\n",
      "  0.27330349  0.00204105 -0.31882219  0.32787734 -0.22887166 -0.21491629\n",
      "  0.09205296 -0.44398148]\n",
      "New theta_0 : [ 0.006349   -0.07929402  0.11089261  0.01898014  0.0986066  -0.23141189\n",
      "  0.27329433  0.00204681 -0.3188319   0.32794763 -0.22894311 -0.2149218\n",
      "  0.09205126 -0.44398569]\n",
      "Training Error:  10.545006925961431\n",
      "====================================================================================================\n",
      "Iteration:  950\n",
      "Previous theta :  [ 0.006349   -0.07929402  0.11089261  0.01898014  0.0986066  -0.23141189\n",
      "  0.27329433  0.00204681 -0.3188319   0.32794763 -0.22894311 -0.2149218\n",
      "  0.09205126 -0.44398569]\n",
      "New theta_0 : [ 0.0063488  -0.07930395  0.1109021   0.01899924  0.09860284 -0.23142619\n",
      "  0.27328522  0.00205254 -0.31884152  0.32801773 -0.22901438 -0.21492728\n",
      "  0.09204957 -0.44398989]\n",
      "Training Error:  10.544996689412008\n",
      "====================================================================================================\n",
      "Iteration:  951\n",
      "Previous theta :  [ 0.0063488  -0.07930395  0.1109021   0.01899924  0.09860284 -0.23142619\n",
      "  0.27328522  0.00205254 -0.31884152  0.32801773 -0.22901438 -0.21492728\n",
      "  0.09204957 -0.44398989]\n",
      "New theta_0 : [ 0.00634861 -0.07931384  0.11091155  0.0190183   0.0985991  -0.23144039\n",
      "  0.27327614  0.00205825 -0.31885107  0.32808763 -0.22908547 -0.21493274\n",
      "  0.0920479  -0.44399409]\n",
      "Training Error:  10.544986509660312\n",
      "====================================================================================================\n",
      "Iteration:  952\n",
      "Previous theta :  [ 0.00634861 -0.07931384  0.11091155  0.0190183   0.0985991  -0.23144039\n",
      "  0.27327614  0.00205825 -0.31885107  0.32808763 -0.22908547 -0.21493274\n",
      "  0.0920479  -0.44399409]\n",
      "New theta_0 : [ 0.00634842 -0.07932369  0.11092096  0.01903731  0.09859537 -0.23145451\n",
      "  0.2732671   0.00206395 -0.31886054  0.32815733 -0.2291564  -0.21493816\n",
      "  0.09204623 -0.44399827]\n",
      "Training Error:  10.544976386365244\n",
      "====================================================================================================\n",
      "Iteration:  953\n",
      "Previous theta :  [ 0.00634842 -0.07932369  0.11092096  0.01903731  0.09859537 -0.23145451\n",
      "  0.2732671   0.00206395 -0.31886054  0.32815733 -0.2291564  -0.21493816\n",
      "  0.09204623 -0.44399827]\n",
      "New theta_0 : [ 0.00634823 -0.07933349  0.11093033  0.01905628  0.09859165 -0.23146854\n",
      "  0.27325809  0.00206963 -0.31886994  0.32822684 -0.22922714 -0.21494357\n",
      "  0.09204457 -0.44400245]\n",
      "Training Error:  10.544966319188097\n",
      "====================================================================================================\n",
      "Iteration:  954\n",
      "Previous theta :  [ 0.00634823 -0.07933349  0.11093033  0.01905628  0.09859165 -0.23146854\n",
      "  0.27325809  0.00206963 -0.31886994  0.32822684 -0.22922714 -0.21494357\n",
      "  0.09204457 -0.44400245]\n",
      "New theta_0 : [ 0.00634804 -0.07934325  0.11093967  0.0190752   0.09858793 -0.23148247\n",
      "  0.27324913  0.00207529 -0.31887926  0.32829616 -0.22929772 -0.21494894\n",
      "  0.09204293 -0.44400662]\n",
      "Training Error:  10.544956307792535\n",
      "====================================================================================================\n",
      "Iteration:  955\n",
      "Previous theta :  [ 0.00634804 -0.07934325  0.11093967  0.0190752   0.09858793 -0.23148247\n",
      "  0.27324913  0.00207529 -0.31887926  0.32829616 -0.22929772 -0.21494894\n",
      "  0.09204293 -0.44400662]\n",
      "New theta_0 : [ 0.00634786 -0.07935297  0.11094896  0.01909408  0.09858423 -0.23149632\n",
      "  0.27324019  0.00208093 -0.3188885   0.32836528 -0.22936812 -0.21495429\n",
      "  0.09204129 -0.44401079]\n",
      "Training Error:  10.544946351844574\n",
      "====================================================================================================\n",
      "Iteration:  956\n",
      "Previous theta :  [ 0.00634786 -0.07935297  0.11094896  0.01909408  0.09858423 -0.23149632\n",
      "  0.27324019  0.00208093 -0.3188885   0.32836528 -0.22936812 -0.21495429\n",
      "  0.09204129 -0.44401079]\n",
      "New theta_0 : [ 0.00634767 -0.07936264  0.11095821  0.01911291  0.09858054 -0.23151007\n",
      "  0.2732313   0.00208655 -0.31889766  0.32843421 -0.22943835 -0.21495961\n",
      "  0.09203967 -0.44401494]\n",
      "Training Error:  10.544936451012557\n",
      "====================================================================================================\n",
      "Iteration:  957\n",
      "Previous theta :  [ 0.00634767 -0.07936264  0.11095821  0.01911291  0.09858054 -0.23151007\n",
      "  0.2732313   0.00208655 -0.31889766  0.32843421 -0.22943835 -0.21495961\n",
      "  0.09203967 -0.44401494]\n",
      "New theta_0 : [ 0.00634748 -0.07937227  0.11096742  0.0191317   0.09857685 -0.23152374\n",
      "  0.27322244  0.00209216 -0.31890676  0.32850294 -0.22950841 -0.21496491\n",
      "  0.09203805 -0.44401909]\n",
      "Training Error:  10.54492660496714\n",
      "====================================================================================================\n",
      "Iteration:  958\n",
      "Previous theta :  [ 0.00634748 -0.07937227  0.11096742  0.0191317   0.09857685 -0.23152374\n",
      "  0.27322244  0.00209216 -0.31890676  0.32850294 -0.22950841 -0.21496491\n",
      "  0.09203805 -0.44401909]\n",
      "New theta_0 : [ 0.0063473  -0.07938187  0.1109766   0.01915044  0.09857318 -0.23153732\n",
      "  0.27321362  0.00209775 -0.31891578  0.32857149 -0.22957829 -0.21497018\n",
      "  0.09203645 -0.44402323]\n",
      "Training Error:  10.544916813381267\n",
      "====================================================================================================\n",
      "Iteration:  959\n",
      "Previous theta :  [ 0.0063473  -0.07938187  0.1109766   0.01915044  0.09857318 -0.23153732\n",
      "  0.27321362  0.00209775 -0.31891578  0.32857149 -0.22957829 -0.21497018\n",
      "  0.09203645 -0.44402323]\n",
      "New theta_0 : [ 0.00634712 -0.07939142  0.11098574  0.01916914  0.09856952 -0.23155081\n",
      "  0.27320483  0.00210332 -0.31892472  0.32863984 -0.22964801 -0.21497542\n",
      "  0.09203485 -0.44402736]\n",
      "Training Error:  10.544907075930153\n",
      "====================================================================================================\n",
      "Iteration:  960\n",
      "Previous theta :  [ 0.00634712 -0.07939142  0.11098574  0.01916914  0.09856952 -0.23155081\n",
      "  0.27320483  0.00210332 -0.31892472  0.32863984 -0.22964801 -0.21497542\n",
      "  0.09203485 -0.44402736]\n",
      "New theta_0 : [ 0.00634693 -0.07940092  0.11099484  0.01918779  0.09856586 -0.23156421\n",
      "  0.27319608  0.00210887 -0.31893359  0.328708   -0.22971755 -0.21498064\n",
      "  0.09203327 -0.44403148]\n",
      "Training Error:  10.544897392291258\n",
      "====================================================================================================\n",
      "Iteration:  961\n",
      "Previous theta :  [ 0.00634693 -0.07940092  0.11099484  0.01918779  0.09856586 -0.23156421\n",
      "  0.27319608  0.00210887 -0.31893359  0.328708   -0.22971755 -0.21498064\n",
      "  0.09203327 -0.44403148]\n",
      "New theta_0 : [ 0.00634675 -0.07941039  0.1110039   0.0192064   0.09856222 -0.23157753\n",
      "  0.27318736  0.0021144  -0.31894239  0.32877597 -0.22978692 -0.21498584\n",
      "  0.09203169 -0.4440356 ]\n",
      "Training Error:  10.54488776214428\n",
      "====================================================================================================\n",
      "Iteration:  962\n",
      "Previous theta :  [ 0.00634675 -0.07941039  0.1110039   0.0192064   0.09856222 -0.23157753\n",
      "  0.27318736  0.0021144  -0.31894239  0.32877597 -0.22978692 -0.21498584\n",
      "  0.09203169 -0.4440356 ]\n",
      "New theta_0 : [ 0.00634657 -0.07941982  0.11101292  0.01922497  0.09855858 -0.23159076\n",
      "  0.27317868  0.00211992 -0.31895112  0.32884375 -0.22985612 -0.214991\n",
      "  0.09203012 -0.44403971]\n",
      "Training Error:  10.544878185171124\n",
      "====================================================================================================\n",
      "Iteration:  963\n",
      "Previous theta :  [ 0.00634657 -0.07941982  0.11101292  0.01922497  0.09855858 -0.23159076\n",
      "  0.27317868  0.00211992 -0.31895112  0.32884375 -0.22985612 -0.214991\n",
      "  0.09203012 -0.44403971]\n",
      "New theta_0 : [ 0.00634639 -0.07942921  0.11102191  0.01924349  0.09855496 -0.23160391\n",
      "  0.27317003  0.00212542 -0.31895977  0.32891134 -0.22992515 -0.21499615\n",
      "  0.09202857 -0.44404381]\n",
      "Training Error:  10.544868661055885\n",
      "====================================================================================================\n",
      "Iteration:  964\n",
      "Previous theta :  [ 0.00634639 -0.07942921  0.11102191  0.01924349  0.09855496 -0.23160391\n",
      "  0.27317003  0.00212542 -0.31895977  0.32891134 -0.22992515 -0.21499615\n",
      "  0.09202857 -0.44404381]\n",
      "New theta_0 : [ 0.00634621 -0.07943855  0.11103085  0.01926197  0.09855134 -0.23161697\n",
      "  0.27316142  0.0021309  -0.31896836  0.32897874 -0.22999402 -0.21500127\n",
      "  0.09202702 -0.4440479 ]\n",
      "Training Error:  10.544859189484837\n",
      "====================================================================================================\n",
      "Iteration:  965\n",
      "Previous theta :  [ 0.00634621 -0.07943855  0.11103085  0.01926197  0.09855134 -0.23161697\n",
      "  0.27316142  0.0021309  -0.31896836  0.32897874 -0.22999402 -0.21500127\n",
      "  0.09202702 -0.4440479 ]\n",
      "New theta_0 : [ 0.00634603 -0.07944786  0.11103977  0.0192804   0.09854774 -0.23162995\n",
      "  0.27315284  0.00213636 -0.31897687  0.32904595 -0.23006271 -0.21500636\n",
      "  0.09202548 -0.44405198]\n",
      "Training Error:  10.544849770146405\n",
      "====================================================================================================\n",
      "Iteration:  966\n",
      "Previous theta :  [ 0.00634603 -0.07944786  0.11103977  0.0192804   0.09854774 -0.23162995\n",
      "  0.27315284  0.00213636 -0.31897687  0.32904595 -0.23006271 -0.21500636\n",
      "  0.09202548 -0.44405198]\n",
      "New theta_0 : [ 0.00634585 -0.07945712  0.11104864  0.01929879  0.09854414 -0.23164284\n",
      "  0.2731443   0.0021418  -0.31898532  0.32911298 -0.23013123 -0.21501143\n",
      "  0.09202395 -0.44405606]\n",
      "Training Error:  10.54484040273115\n",
      "====================================================================================================\n",
      "Iteration:  967\n",
      "Previous theta :  [ 0.00634585 -0.07945712  0.11104864  0.01929879  0.09854414 -0.23164284\n",
      "  0.2731443   0.0021418  -0.31898532  0.32911298 -0.23013123 -0.21501143\n",
      "  0.09202395 -0.44405606]\n",
      "New theta_0 : [ 0.00634568 -0.07946635  0.11105748  0.01931714  0.09854055 -0.23165565\n",
      "  0.27313579  0.00214723 -0.3189937   0.32917982 -0.23019958 -0.21501647\n",
      "  0.09202244 -0.44406013]\n",
      "Training Error:  10.544831086931755\n",
      "====================================================================================================\n",
      "Iteration:  968\n",
      "Previous theta :  [ 0.00634568 -0.07946635  0.11105748  0.01931714  0.09854055 -0.23165565\n",
      "  0.27313579  0.00214723 -0.3189937   0.32917982 -0.23019958 -0.21501647\n",
      "  0.09202244 -0.44406013]\n",
      "New theta_0 : [ 0.0063455  -0.07947553  0.11106628  0.01933544  0.09853697 -0.23166838\n",
      "  0.27312732  0.00215264 -0.319002    0.32924647 -0.23026777 -0.21502149\n",
      "  0.09202093 -0.44406419]\n",
      "Training Error:  10.544821822442998\n",
      "====================================================================================================\n",
      "Iteration:  969\n",
      "Previous theta :  [ 0.0063455  -0.07947553  0.11106628  0.01933544  0.09853697 -0.23166838\n",
      "  0.27312732  0.00215264 -0.319002    0.32924647 -0.23026777 -0.21502149\n",
      "  0.09202093 -0.44406419]\n",
      "New theta_0 : [ 0.00634533 -0.07948468  0.11107504  0.0193537   0.09853341 -0.23168102\n",
      "  0.27311888  0.00215804 -0.31901024  0.32931294 -0.23033579 -0.21502649\n",
      "  0.09201943 -0.44406825]\n",
      "Training Error:  10.54481260896174\n",
      "====================================================================================================\n",
      "Iteration:  970\n",
      "Previous theta :  [ 0.00634533 -0.07948468  0.11107504  0.0193537   0.09853341 -0.23168102\n",
      "  0.27311888  0.00215804 -0.31901024  0.32931294 -0.23033579 -0.21502649\n",
      "  0.09201943 -0.44406825]\n",
      "New theta_0 : [ 0.00634515 -0.07949379  0.11108377  0.01937191  0.09852985 -0.23169359\n",
      "  0.27311047  0.00216341 -0.31901841  0.32937922 -0.23040364 -0.21503146\n",
      "  0.09201793 -0.44407229]\n",
      "Training Error:  10.544803446186911\n",
      "====================================================================================================\n",
      "Iteration:  971\n",
      "Previous theta :  [ 0.00634515 -0.07949379  0.11108377  0.01937191  0.09852985 -0.23169359\n",
      "  0.27311047  0.00216341 -0.31901841  0.32937922 -0.23040364 -0.21503146\n",
      "  0.09201793 -0.44407229]\n",
      "New theta_0 : [ 0.00634498 -0.07950286  0.11109246  0.01939008  0.0985263  -0.23170607\n",
      "  0.2731021   0.00216877 -0.31902652  0.32944532 -0.23047132 -0.21503641\n",
      "  0.09201645 -0.44407633]\n",
      "Training Error:  10.544794333819482\n",
      "====================================================================================================\n",
      "Iteration:  972\n",
      "Previous theta :  [ 0.00634498 -0.07950286  0.11109246  0.01939008  0.0985263  -0.23170607\n",
      "  0.2731021   0.00216877 -0.31902652  0.32944532 -0.23047132 -0.21503641\n",
      "  0.09201645 -0.44407633]\n",
      "New theta_0 : [ 0.00634481 -0.07951189  0.11110112  0.01940821  0.09852276 -0.23171847\n",
      "  0.27309375  0.00217411 -0.31903456  0.32951123 -0.23053884 -0.21504133\n",
      "  0.09201498 -0.44408036]\n",
      "Training Error:  10.544785271562457\n",
      "====================================================================================================\n",
      "Iteration:  973\n",
      "Previous theta :  [ 0.00634481 -0.07951189  0.11110112  0.01940821  0.09852276 -0.23171847\n",
      "  0.27309375  0.00217411 -0.31903456  0.32951123 -0.23053884 -0.21504133\n",
      "  0.09201498 -0.44408036]\n",
      "New theta_0 : [ 0.00634463 -0.07952088  0.11110974  0.01942629  0.09851923 -0.2317308\n",
      "  0.27308545  0.00217944 -0.31904253  0.32957696 -0.23060619 -0.21504623\n",
      "  0.09201352 -0.44408438]\n",
      "Training Error:  10.544776259120855\n",
      "====================================================================================================\n",
      "Iteration:  974\n",
      "Previous theta :  [ 0.00634463 -0.07952088  0.11110974  0.01942629  0.09851923 -0.2317308\n",
      "  0.27308545  0.00217944 -0.31904253  0.32957696 -0.23060619 -0.21504623\n",
      "  0.09201352 -0.44408438]\n",
      "New theta_0 : [ 0.00634446 -0.07952983  0.11111832  0.01944433  0.09851571 -0.23174304\n",
      "  0.27307717  0.00218474 -0.31905043  0.32964251 -0.23067337 -0.21505111\n",
      "  0.09201206 -0.4440884 ]\n",
      "Training Error:  10.544767296201682\n",
      "====================================================================================================\n",
      "Iteration:  975\n",
      "Previous theta :  [ 0.00634446 -0.07952983  0.11111832  0.01944433  0.09851571 -0.23174304\n",
      "  0.27307717  0.00218474 -0.31905043  0.32964251 -0.23067337 -0.21505111\n",
      "  0.09201206 -0.4440884 ]\n",
      "New theta_0 : [ 0.00634429 -0.07953875  0.11112687  0.01946233  0.0985122  -0.23175521\n",
      "  0.27306893  0.00219003 -0.31905828  0.32970787 -0.23074039 -0.21505596\n",
      "  0.09201061 -0.4440924 ]\n",
      "Training Error:  10.544758382513933\n",
      "====================================================================================================\n",
      "Iteration:  976\n",
      "Previous theta :  [ 0.00634429 -0.07953875  0.11112687  0.01946233  0.0985122  -0.23175521\n",
      "  0.27306893  0.00219003 -0.31905828  0.32970787 -0.23074039 -0.21505596\n",
      "  0.09201061 -0.4440924 ]\n",
      "New theta_0 : [ 0.00634412 -0.07954763  0.11113539  0.01948028  0.0985087  -0.2317673\n",
      "  0.27306072  0.00219531 -0.31906605  0.32977305 -0.23080724 -0.21506079\n",
      "  0.09200918 -0.4440964 ]\n",
      "Training Error:  10.544749517768558\n",
      "====================================================================================================\n",
      "Iteration:  977\n",
      "Previous theta :  [ 0.00634412 -0.07954763  0.11113539  0.01948028  0.0985087  -0.2317673\n",
      "  0.27306072  0.00219531 -0.31906605  0.32977305 -0.23080724 -0.21506079\n",
      "  0.09200918 -0.4440964 ]\n",
      "New theta_0 : [ 0.00634395 -0.07955647  0.11114387  0.01949819  0.0985052  -0.23177931\n",
      "  0.27305255  0.00220057 -0.31907377  0.32983805 -0.23087393 -0.21506559\n",
      "  0.09200775 -0.44410039]\n",
      "Training Error:  10.54474070167846\n",
      "====================================================================================================\n",
      "Iteration:  978\n",
      "Previous theta :  [ 0.00634395 -0.07955647  0.11114387  0.01949819  0.0985052  -0.23177931\n",
      "  0.27305255  0.00220057 -0.31907377  0.32983805 -0.23087393 -0.21506559\n",
      "  0.09200775 -0.44410039]\n",
      "New theta_0 : [ 0.00634379 -0.07956527  0.11115231  0.01951606  0.09850172 -0.23179124\n",
      "  0.2730444   0.00220581 -0.31908141  0.32990287 -0.23094045 -0.21507038\n",
      "  0.09200633 -0.44410438]\n",
      "Training Error:  10.544731933958463\n",
      "====================================================================================================\n",
      "Iteration:  979\n",
      "Previous theta :  [ 0.00634379 -0.07956527  0.11115231  0.01951606  0.09850172 -0.23179124\n",
      "  0.2730444   0.00220581 -0.31908141  0.32990287 -0.23094045 -0.21507038\n",
      "  0.09200633 -0.44410438]\n",
      "New theta_0 : [ 0.00634362 -0.07957404  0.11116072  0.01953388  0.09849825 -0.23180309\n",
      "  0.27303629  0.00221103 -0.319089    0.32996751 -0.23100681 -0.21507514\n",
      "  0.09200492 -0.44410835]\n",
      "Training Error:  10.54472321432531\n",
      "====================================================================================================\n",
      "Iteration:  980\n",
      "Previous theta :  [ 0.00634362 -0.07957404  0.11116072  0.01953388  0.09849825 -0.23180309\n",
      "  0.27303629  0.00221103 -0.319089    0.32996751 -0.23100681 -0.21507514\n",
      "  0.09200492 -0.44410835]\n",
      "New theta_0 : [ 0.00634345 -0.07958276  0.1111691   0.01955166  0.09849478 -0.23181487\n",
      "  0.27302821  0.00221624 -0.31909652  0.33003197 -0.231073   -0.21507987\n",
      "  0.09200352 -0.44411232]\n",
      "Training Error:  10.544714542497642\n",
      "====================================================================================================\n",
      "Iteration:  981\n",
      "Previous theta :  [ 0.00634345 -0.07958276  0.1111691   0.01955166  0.09849478 -0.23181487\n",
      "  0.27302821  0.00221624 -0.31909652  0.33003197 -0.231073   -0.21507987\n",
      "  0.09200352 -0.44411232]\n",
      "New theta_0 : [ 0.00634329 -0.07959146  0.11117744  0.0195694   0.09849132 -0.23182658\n",
      "  0.27302016  0.00222143 -0.31910398  0.33009625 -0.23113903 -0.21508459\n",
      "  0.09200212 -0.44411628]\n",
      "Training Error:  10.544705918195982\n",
      "====================================================================================================\n",
      "Iteration:  982\n",
      "Previous theta :  [ 0.00634329 -0.07959146  0.11117744  0.0195694   0.09849132 -0.23182658\n",
      "  0.27302016  0.00222143 -0.31910398  0.33009625 -0.23113903 -0.21508459\n",
      "  0.09200212 -0.44411628]\n",
      "New theta_0 : [ 0.00634312 -0.07960011  0.11118575  0.01958709  0.09848788 -0.23183821\n",
      "  0.27301214  0.0022266  -0.31911138  0.33016035 -0.2312049  -0.21508928\n",
      "  0.09200074 -0.44412024]\n",
      "Training Error:  10.544697341142715\n",
      "====================================================================================================\n",
      "Iteration:  983\n",
      "Previous theta :  [ 0.00634312 -0.07960011  0.11118575  0.01958709  0.09848788 -0.23183821\n",
      "  0.27301214  0.0022266  -0.31911138  0.33016035 -0.2312049  -0.21508928\n",
      "  0.09200074 -0.44412024]\n",
      "New theta_0 : [ 0.00634296 -0.07960873  0.11119402  0.01960474  0.09848444 -0.23184976\n",
      "  0.27300416  0.00223176 -0.31911872  0.33022428 -0.23127061 -0.21509395\n",
      "  0.09199936 -0.44412418]\n",
      "Training Error:  10.544688811062084\n",
      "====================================================================================================\n",
      "Iteration:  984\n",
      "Previous theta :  [ 0.00634296 -0.07960873  0.11119402  0.01960474  0.09848444 -0.23184976\n",
      "  0.27300416  0.00223176 -0.31911872  0.33022428 -0.23127061 -0.21509395\n",
      "  0.09199936 -0.44412418]\n",
      "New theta_0 : [ 0.0063428  -0.07961731  0.11120226  0.01962235  0.09848101 -0.23186124\n",
      "  0.2729962   0.0022369  -0.319126    0.33028803 -0.23133615 -0.2150986\n",
      "  0.09199799 -0.44412812]\n",
      "Training Error:  10.544680327680162\n",
      "====================================================================================================\n",
      "Iteration:  985\n",
      "Previous theta :  [ 0.0063428  -0.07961731  0.11120226  0.01962235  0.09848101 -0.23186124\n",
      "  0.2729962   0.0022369  -0.319126    0.33028803 -0.23133615 -0.2150986\n",
      "  0.09199799 -0.44412812]\n",
      "New theta_0 : [ 0.00634264 -0.07962586  0.11121047  0.01963992  0.09847759 -0.23187265\n",
      "  0.27298828  0.00224203 -0.31913321  0.3303516  -0.23140153 -0.21510322\n",
      "  0.09199663 -0.44413205]\n",
      "Training Error:  10.544671890724844\n",
      "====================================================================================================\n",
      "Iteration:  986\n",
      "Previous theta :  [ 0.00634264 -0.07962586  0.11121047  0.01963992  0.09847759 -0.23187265\n",
      "  0.27298828  0.00224203 -0.31913321  0.3303516  -0.23140153 -0.21510322\n",
      "  0.09199663 -0.44413205]\n",
      "New theta_0 : [ 0.00634248 -0.07963437  0.11121865  0.01965744  0.09847418 -0.23188398\n",
      "  0.27298039  0.00224714 -0.31914037  0.33041499 -0.23146675 -0.21510782\n",
      "  0.09199528 -0.44413597]\n",
      "Training Error:  10.544663499925834\n",
      "====================================================================================================\n",
      "Iteration:  987\n",
      "Previous theta :  [ 0.00634248 -0.07963437  0.11121865  0.01965744  0.09847418 -0.23188398\n",
      "  0.27298039  0.00224714 -0.31914037  0.33041499 -0.23146675 -0.21510782\n",
      "  0.09199528 -0.44413597]\n",
      "New theta_0 : [ 0.00634231 -0.07964284  0.11122679  0.01967492  0.09847078 -0.23189524\n",
      "  0.27297252  0.00225223 -0.31914747  0.33047821 -0.2315318  -0.2151124\n",
      "  0.09199393 -0.44413989]\n",
      "Training Error:  10.544655155014622\n",
      "====================================================================================================\n",
      "Iteration:  988\n",
      "Previous theta :  [ 0.00634231 -0.07964284  0.11122679  0.01967492  0.09847078 -0.23189524\n",
      "  0.27297252  0.00225223 -0.31914747  0.33047821 -0.2315318  -0.2151124\n",
      "  0.09199393 -0.44413989]\n",
      "New theta_0 : [ 0.00634216 -0.07965128  0.1112349   0.01969236  0.09846739 -0.23190643\n",
      "  0.27296469  0.00225731 -0.31915451  0.33054125 -0.2315967  -0.21511696\n",
      "  0.0919926  -0.44414379]\n",
      "Training Error:  10.54464685572448\n",
      "====================================================================================================\n",
      "Iteration:  989\n",
      "Previous theta :  [ 0.00634216 -0.07965128  0.1112349   0.01969236  0.09846739 -0.23190643\n",
      "  0.27296469  0.00225731 -0.31915451  0.33054125 -0.2315967  -0.21511696\n",
      "  0.0919926  -0.44414379]\n",
      "New theta_0 : [ 0.006342   -0.07965969  0.11124297  0.01970976  0.09846401 -0.23191755\n",
      "  0.27295689  0.00226237 -0.31916149  0.33060411 -0.23166143 -0.2151215\n",
      "  0.09199127 -0.44414769]\n",
      "Training Error:  10.544638601790439\n",
      "====================================================================================================\n",
      "Iteration:  990\n",
      "Previous theta :  [ 0.006342   -0.07965969  0.11124297  0.01970976  0.09846401 -0.23191755\n",
      "  0.27295689  0.00226237 -0.31916149  0.33060411 -0.23166143 -0.2151215\n",
      "  0.09199127 -0.44414769]\n",
      "New theta_0 : [ 0.00634184 -0.07966805  0.11125101  0.01972711  0.09846063 -0.23192859\n",
      "  0.27294912  0.00226741 -0.31916841  0.33066681 -0.23172601 -0.21512602\n",
      "  0.09198995 -0.44415159]\n",
      "Training Error:  10.544630392949276\n",
      "====================================================================================================\n",
      "Iteration:  991\n",
      "Previous theta :  [ 0.00634184 -0.07966805  0.11125101  0.01972711  0.09846063 -0.23192859\n",
      "  0.27294912  0.00226741 -0.31916841  0.33066681 -0.23172601 -0.21512602\n",
      "  0.09198995 -0.44415159]\n",
      "New theta_0 : [ 0.00634168 -0.07967639  0.11125902  0.01974442  0.09845727 -0.23193957\n",
      "  0.27294138  0.00227244 -0.31917527  0.33072933 -0.23179042 -0.21513051\n",
      "  0.09198864 -0.44415547]\n",
      "Training Error:  10.544622228939504\n",
      "====================================================================================================\n",
      "Iteration:  992\n",
      "Previous theta :  [ 0.00634168 -0.07967639  0.11125902  0.01974442  0.09845727 -0.23193957\n",
      "  0.27294138  0.00227244 -0.31917527  0.33072933 -0.23179042 -0.21513051\n",
      "  0.09198864 -0.44415547]\n",
      "New theta_0 : [ 0.00634152 -0.07968469  0.111267    0.01976169  0.09845391 -0.23195047\n",
      "  0.27293367  0.00227745 -0.31918208  0.33079167 -0.23185468 -0.21513498\n",
      "  0.09198733 -0.44415935]\n",
      "Training Error:  10.544614109501353\n",
      "====================================================================================================\n",
      "Iteration:  993\n",
      "Previous theta :  [ 0.00634152 -0.07968469  0.111267    0.01976169  0.09845391 -0.23195047\n",
      "  0.27293367  0.00227745 -0.31918208  0.33079167 -0.23185468 -0.21513498\n",
      "  0.09198733 -0.44415935]\n",
      "New theta_0 : [ 0.00634137 -0.07969295  0.11127495  0.01977892  0.09845056 -0.23196131\n",
      "  0.27292599  0.00228245 -0.31918883  0.33085384 -0.23191877 -0.21513944\n",
      "  0.09198603 -0.44416322]\n",
      "Training Error:  10.544606034376764\n",
      "====================================================================================================\n",
      "Iteration:  994\n",
      "Previous theta :  [ 0.00634137 -0.07969295  0.11127495  0.01977892  0.09845056 -0.23196131\n",
      "  0.27292599  0.00228245 -0.31918883  0.33085384 -0.23191877 -0.21513944\n",
      "  0.09198603 -0.44416322]\n",
      "New theta_0 : [ 0.00634121 -0.07970118  0.11128286  0.0197961   0.09844722 -0.23197207\n",
      "  0.27291834  0.00228743 -0.31919553  0.33091584 -0.23198271 -0.21514387\n",
      "  0.09198475 -0.44416708]\n",
      "Training Error:  10.544598003309362\n",
      "====================================================================================================\n",
      "Iteration:  995\n",
      "Previous theta :  [ 0.00634121 -0.07970118  0.11128286  0.0197961   0.09844722 -0.23197207\n",
      "  0.27291834  0.00228743 -0.31919553  0.33091584 -0.23198271 -0.21514387\n",
      "  0.09198475 -0.44416708]\n",
      "New theta_0 : [ 0.00634106 -0.07970938  0.11129075  0.01981325  0.09844389 -0.23198277\n",
      "  0.27291072  0.0022924  -0.31920216  0.33097767 -0.23204649 -0.21514828\n",
      "  0.09198346 -0.44417093]\n",
      "Training Error:  10.544590016044454\n",
      "====================================================================================================\n",
      "Iteration:  996\n",
      "Previous theta :  [ 0.00634106 -0.07970938  0.11129075  0.01981325  0.09844389 -0.23198277\n",
      "  0.27291072  0.0022924  -0.31920216  0.33097767 -0.23204649 -0.21514828\n",
      "  0.09198346 -0.44417093]\n",
      "New theta_0 : [ 0.00634091 -0.07971754  0.1112986   0.01983035  0.09844057 -0.2319934\n",
      "  0.27290313  0.00229735 -0.31920875  0.33103933 -0.23211011 -0.21515266\n",
      "  0.09198219 -0.44417478]\n",
      "Training Error:  10.544582072329016\n",
      "====================================================================================================\n",
      "Iteration:  997\n",
      "Previous theta :  [ 0.00634091 -0.07971754  0.1112986   0.01983035  0.09844057 -0.2319934\n",
      "  0.27290313  0.00229735 -0.31920875  0.33103933 -0.23211011 -0.21515266\n",
      "  0.09198219 -0.44417478]\n",
      "New theta_0 : [ 0.00634075 -0.07972567  0.11130642  0.01984741  0.09843726 -0.23200396\n",
      "  0.27289557  0.00230228 -0.31921527  0.33110082 -0.23217357 -0.21515703\n",
      "  0.09198093 -0.44417862]\n",
      "Training Error:  10.544574171911668\n",
      "====================================================================================================\n",
      "Iteration:  998\n",
      "Previous theta :  [ 0.00634075 -0.07972567  0.11130642  0.01984741  0.09843726 -0.23200396\n",
      "  0.27289557  0.00230228 -0.31921527  0.33110082 -0.23217357 -0.21515703\n",
      "  0.09198093 -0.44417862]\n",
      "New theta_0 : [ 0.0063406  -0.07973376  0.11131421  0.01986443  0.09843396 -0.23201445\n",
      "  0.27288803  0.0023072  -0.31922175  0.33116214 -0.23223687 -0.21516138\n",
      "  0.09197967 -0.44418245]\n",
      "Training Error:  10.54456631454267\n",
      "====================================================================================================\n",
      "Iteration:  999\n",
      "Previous theta :  [ 0.0063406  -0.07973376  0.11131421  0.01986443  0.09843396 -0.23201445\n",
      "  0.27288803  0.0023072  -0.31922175  0.33116214 -0.23223687 -0.21516138\n",
      "  0.09197967 -0.44418245]\n",
      "New theta_0 : [ 0.00634045 -0.07974182  0.11132196  0.0198814   0.09843066 -0.23202488\n",
      "  0.27288053  0.00231211 -0.31922817  0.33122328 -0.23230002 -0.21516571\n",
      "  0.09197842 -0.44418627]\n",
      "Training Error:  10.544558499973911\n",
      "====================================================================================================\n",
      "Iteration:  1000\n",
      "Previous theta :  [ 0.00634045 -0.07974182  0.11132196  0.0198814   0.09843066 -0.23202488\n",
      "  0.27288053  0.00231211 -0.31922817  0.33122328 -0.23230002 -0.21516571\n",
      "  0.09197842 -0.44418627]\n",
      "New theta_0 : [ 0.0063403  -0.07974985  0.11132969  0.01989834  0.09842738 -0.23203524\n",
      "  0.27287306  0.002317   -0.31923453  0.33128426 -0.23236301 -0.21517001\n",
      "  0.09197717 -0.44419009]\n",
      "Training Error:  10.544550727958887\n",
      "====================================================================================================\n",
      "Iteration:  1001\n",
      "Previous theta :  [ 0.0063403  -0.07974985  0.11132969  0.01989834  0.09842738 -0.23203524\n",
      "  0.27287306  0.002317   -0.31923453  0.33128426 -0.23236301 -0.21517001\n",
      "  0.09197717 -0.44419009]\n",
      "New theta_0 : [ 0.00634015 -0.07975785  0.11133739  0.01991523  0.0984241  -0.23204553\n",
      "  0.27286561  0.00232187 -0.31924084  0.33134507 -0.23242584 -0.2151743\n",
      "  0.09197594 -0.4441939 ]\n",
      "Training Error:  10.5445429982527\n",
      "====================================================================================================\n",
      "Iteration:  1002\n",
      "Previous theta :  [ 0.00634015 -0.07975785  0.11133739  0.01991523  0.0984241  -0.23204553\n",
      "  0.27286561  0.00232187 -0.31924084  0.33134507 -0.23242584 -0.2151743\n",
      "  0.09197594 -0.4441939 ]\n",
      "New theta_0 : [ 0.00634    -0.07976581  0.11134505  0.01993208  0.09842083 -0.23205576\n",
      "  0.27285819  0.00232673 -0.3192471   0.33140571 -0.23248852 -0.21517857\n",
      "  0.09197471 -0.4441977 ]\n",
      "Training Error:  10.54453531061203\n",
      "====================================================================================================\n",
      "Iteration:  1003\n",
      "Previous theta :  [ 0.00634    -0.07976581  0.11134505  0.01993208  0.09842083 -0.23205576\n",
      "  0.27285819  0.00232673 -0.3192471   0.33140571 -0.23248852 -0.21517857\n",
      "  0.09197471 -0.4441977 ]\n",
      "New theta_0 : [ 0.00633985 -0.07977374  0.11135269  0.01994889  0.09841757 -0.23206592\n",
      "  0.2728508   0.00233157 -0.31925331  0.33146618 -0.23255104 -0.21518281\n",
      "  0.09197349 -0.44420149]\n",
      "Training Error:  10.544527664795138\n",
      "====================================================================================================\n",
      "Iteration:  1004\n",
      "Previous theta :  [ 0.00633985 -0.07977374  0.11135269  0.01994889  0.09841757 -0.23206592\n",
      "  0.2728508   0.00233157 -0.31925331  0.33146618 -0.23255104 -0.21518281\n",
      "  0.09197349 -0.44420149]\n",
      "New theta_0 : [ 0.0063397  -0.07978163  0.11136029  0.01996566  0.09841432 -0.23207602\n",
      "  0.27284344  0.0023364  -0.31925946  0.33152649 -0.23261341 -0.21518704\n",
      "  0.09197228 -0.44420528]\n",
      "Training Error:  10.544520060561844\n",
      "====================================================================================================\n",
      "Iteration:  1005\n",
      "Previous theta :  [ 0.0063397  -0.07978163  0.11136029  0.01996566  0.09841432 -0.23207602\n",
      "  0.27284344  0.0023364  -0.31925946  0.33152649 -0.23261341 -0.21518704\n",
      "  0.09197228 -0.44420528]\n",
      "New theta_0 : [ 0.00633956 -0.0797895   0.11136786  0.01998239  0.09841108 -0.23208605\n",
      "  0.27283611  0.00234121 -0.31926556  0.33158663 -0.23267562 -0.21519125\n",
      "  0.09197107 -0.44420906]\n",
      "Training Error:  10.54451249767352\n",
      "====================================================================================================\n",
      "Iteration:  1006\n",
      "Previous theta :  [ 0.00633956 -0.0797895   0.11136786  0.01998239  0.09841108 -0.23208605\n",
      "  0.27283611  0.00234121 -0.31926556  0.33158663 -0.23267562 -0.21519125\n",
      "  0.09197107 -0.44420906]\n",
      "New theta_0 : [ 0.00633941 -0.07979733  0.11137541  0.01999907  0.09840784 -0.23209602\n",
      "  0.2728288   0.00234601 -0.31927161  0.3316466  -0.23273767 -0.21519543\n",
      "  0.09196987 -0.44421283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.54450497589307\n",
      "====================================================================================================\n",
      "Iteration:  1007\n",
      "Previous theta :  [ 0.00633941 -0.07979733  0.11137541  0.01999907  0.09840784 -0.23209602\n",
      "  0.2728288   0.00234601 -0.31927161  0.3316466  -0.23273767 -0.21519543\n",
      "  0.09196987 -0.44421283]\n",
      "New theta_0 : [ 0.00633926 -0.07980513  0.11138292  0.02001572  0.09840462 -0.23210593\n",
      "  0.27282152  0.00235079 -0.31927761  0.33170641 -0.23279957 -0.2151996\n",
      "  0.09196868 -0.44421659]\n",
      "Training Error:  10.544497494984926\n",
      "====================================================================================================\n",
      "Iteration:  1008\n",
      "Previous theta :  [ 0.00633926 -0.07980513  0.11138292  0.02001572  0.09840462 -0.23210593\n",
      "  0.27282152  0.00235079 -0.31927761  0.33170641 -0.23279957 -0.2151996\n",
      "  0.09196868 -0.44421659]\n",
      "New theta_0 : [ 0.00633912 -0.0798129   0.11139041  0.02003232  0.0984014  -0.23211577\n",
      "  0.27281427  0.00235556 -0.31928356  0.33176605 -0.23286132 -0.21520375\n",
      "  0.09196749 -0.44422035]\n",
      "Training Error:  10.544490054715036\n",
      "====================================================================================================\n",
      "Iteration:  1009\n",
      "Previous theta :  [ 0.00633912 -0.0798129   0.11139041  0.02003232  0.0984014  -0.23211577\n",
      "  0.27281427  0.00235556 -0.31928356  0.33176605 -0.23286132 -0.21520375\n",
      "  0.09196749 -0.44422035]\n",
      "New theta_0 : [ 0.00633897 -0.07982063  0.11139786  0.02004889  0.09839819 -0.23212555\n",
      "  0.27280705  0.00236032 -0.31928946  0.33182553 -0.23292292 -0.21520788\n",
      "  0.09196632 -0.44422409]\n",
      "Training Error:  10.544482654850846\n",
      "====================================================================================================\n",
      "Iteration:  1010\n",
      "Previous theta :  [ 0.00633897 -0.07982063  0.11139786  0.02004889  0.09839819 -0.23212555\n",
      "  0.27280705  0.00236032 -0.31928946  0.33182553 -0.23292292 -0.21520788\n",
      "  0.09196632 -0.44422409]\n",
      "New theta_0 : [ 0.00633883 -0.07982834  0.11140529  0.02006541  0.09839499 -0.23213527\n",
      "  0.27279985  0.00236505 -0.31929531  0.33188485 -0.23298436 -0.21521198\n",
      "  0.09196515 -0.44422784]\n",
      "Training Error:  10.544475295161293\n",
      "====================================================================================================\n",
      "Iteration:  1011\n",
      "Previous theta :  [ 0.00633883 -0.07982834  0.11140529  0.02006541  0.09839499 -0.23213527\n",
      "  0.27279985  0.00236505 -0.31929531  0.33188485 -0.23298436 -0.21521198\n",
      "  0.09196515 -0.44422784]\n",
      "New theta_0 : [ 0.00633869 -0.07983601  0.11141269  0.02008189  0.0983918  -0.23214492\n",
      "  0.27279269  0.00236978 -0.31930111  0.331944   -0.23304564 -0.21521607\n",
      "  0.09196398 -0.44423157]\n",
      "Training Error:  10.544467975416792\n",
      "====================================================================================================\n",
      "Iteration:  1012\n",
      "Previous theta :  [ 0.00633869 -0.07983601  0.11141269  0.02008189  0.0983918  -0.23214492\n",
      "  0.27279269  0.00236978 -0.31930111  0.331944   -0.23304564 -0.21521607\n",
      "  0.09196398 -0.44423157]\n",
      "New theta_0 : [ 0.00633854 -0.07984365  0.11142005  0.02009833  0.09838862 -0.23215452\n",
      "  0.27278555  0.00237449 -0.31930686  0.33200298 -0.23310678 -0.21522014\n",
      "  0.09196282 -0.44423529]\n",
      "Training Error:  10.544460695389223\n",
      "====================================================================================================\n",
      "Iteration:  1013\n",
      "Previous theta :  [ 0.00633854 -0.07984365  0.11142005  0.02009833  0.09838862 -0.23215452\n",
      "  0.27278555  0.00237449 -0.31930686  0.33200298 -0.23310678 -0.21522014\n",
      "  0.09196282 -0.44423529]\n",
      "New theta_0 : [ 0.0063384  -0.07985126  0.11142739  0.02011473  0.09838544 -0.23216405\n",
      "  0.27277843  0.00237918 -0.31931256  0.33206181 -0.23316776 -0.2152242\n",
      "  0.09196167 -0.44423901]\n",
      "Training Error:  10.544453454851924\n",
      "====================================================================================================\n",
      "Iteration:  1014\n",
      "Previous theta :  [ 0.0063384  -0.07985126  0.11142739  0.02011473  0.09838544 -0.23216405\n",
      "  0.27277843  0.00237918 -0.31931256  0.33206181 -0.23316776 -0.2152242\n",
      "  0.09196167 -0.44423901]\n",
      "New theta_0 : [ 0.00633826 -0.07985884  0.1114347   0.02013109  0.09838227 -0.23217352\n",
      "  0.27277134  0.00238386 -0.31931822  0.33212047 -0.23322859 -0.21522823\n",
      "  0.09196053 -0.44424272]\n",
      "Training Error:  10.544446253579675\n",
      "====================================================================================================\n",
      "Iteration:  1015\n",
      "Previous theta :  [ 0.00633826 -0.07985884  0.1114347   0.02013109  0.09838227 -0.23217352\n",
      "  0.27277134  0.00238386 -0.31931822  0.33212047 -0.23322859 -0.21522823\n",
      "  0.09196053 -0.44424272]\n",
      "New theta_0 : [ 0.00633812 -0.07986639  0.11144199  0.02014741  0.09837912 -0.23218293\n",
      "  0.27276428  0.00238853 -0.31932382  0.33217897 -0.23328927 -0.21523224\n",
      "  0.09195939 -0.44424643]\n",
      "Training Error:  10.544439091348691\n",
      "====================================================================================================\n",
      "Iteration:  1016\n",
      "Previous theta :  [ 0.00633812 -0.07986639  0.11144199  0.02014741  0.09837912 -0.23218293\n",
      "  0.27276428  0.00238853 -0.31932382  0.33217897 -0.23328927 -0.21523224\n",
      "  0.09195939 -0.44424643]\n",
      "New theta_0 : [ 0.00633798 -0.07987391  0.11144924  0.02016369  0.09837597 -0.23219229\n",
      "  0.27275725  0.00239318 -0.31932938  0.33223731 -0.2333498  -0.21523624\n",
      "  0.09195826 -0.44425012]\n",
      "Training Error:  10.544431967936607\n",
      "====================================================================================================\n",
      "Iteration:  1017\n",
      "Previous theta :  [ 0.00633798 -0.07987391  0.11144924  0.02016369  0.09837597 -0.23219229\n",
      "  0.27275725  0.00239318 -0.31932938  0.33223731 -0.2333498  -0.21523624\n",
      "  0.09195826 -0.44425012]\n",
      "New theta_0 : [ 0.00633784 -0.0798814   0.11145646  0.02017993  0.09837283 -0.23220158\n",
      "  0.27275024  0.00239781 -0.31933489  0.33229549 -0.23341017 -0.21524022\n",
      "  0.09195714 -0.44425381]\n",
      "Training Error:  10.544424883122469\n",
      "====================================================================================================\n",
      "Iteration:  1018\n",
      "Previous theta :  [ 0.00633784 -0.0798814   0.11145646  0.02017993  0.09837283 -0.23220158\n",
      "  0.27275024  0.00239781 -0.31933489  0.33229549 -0.23341017 -0.21524022\n",
      "  0.09195714 -0.44425381]\n",
      "New theta_0 : [ 0.00633771 -0.07988886  0.11146366  0.02019613  0.09836969 -0.23221081\n",
      "  0.27274326  0.00240244 -0.31934036  0.3323535  -0.2334704  -0.21524417\n",
      "  0.09195602 -0.4442575 ]\n",
      "Training Error:  10.544417836686723\n",
      "====================================================================================================\n",
      "Iteration:  1019\n",
      "Previous theta :  [ 0.00633771 -0.07988886  0.11146366  0.02019613  0.09836969 -0.23221081\n",
      "  0.27274326  0.00240244 -0.31934036  0.3323535  -0.2334704  -0.21524417\n",
      "  0.09195602 -0.4442575 ]\n",
      "New theta_0 : [ 0.00633757 -0.07989628  0.11147083  0.02021229  0.09836657 -0.23221999\n",
      "  0.27273631  0.00240704 -0.31934577  0.33241136 -0.23353047 -0.21524811\n",
      "  0.09195491 -0.44426117]\n",
      "Training Error:  10.544410828411207\n",
      "====================================================================================================\n",
      "Iteration:  1020\n",
      "Previous theta :  [ 0.00633757 -0.07989628  0.11147083  0.02021229  0.09836657 -0.23221999\n",
      "  0.27273631  0.00240704 -0.31934577  0.33241136 -0.23353047 -0.21524811\n",
      "  0.09195491 -0.44426117]\n",
      "New theta_0 : [ 0.00633743 -0.07990368  0.11147797  0.02022841  0.09836345 -0.23222911\n",
      "  0.27272938  0.00241164 -0.31935114  0.33246906 -0.2335904  -0.21525204\n",
      "  0.09195381 -0.44426484]\n",
      "Training Error:  10.544403858079136\n",
      "====================================================================================================\n",
      "Iteration:  1021\n",
      "Previous theta :  [ 0.00633743 -0.07990368  0.11147797  0.02022841  0.09836345 -0.23222911\n",
      "  0.27272938  0.00241164 -0.31935114  0.33246906 -0.2335904  -0.21525204\n",
      "  0.09195381 -0.44426484]\n",
      "New theta_0 : [ 0.00633729 -0.07991105  0.11148508  0.02024449  0.09836034 -0.23223816\n",
      "  0.27272248  0.00241622 -0.31935647  0.3325266  -0.23365018 -0.21525594\n",
      "  0.09195271 -0.4442685 ]\n",
      "Training Error:  10.544396925475091\n",
      "====================================================================================================\n",
      "Iteration:  1022\n",
      "Previous theta :  [ 0.00633729 -0.07991105  0.11148508  0.02024449  0.09836034 -0.23223816\n",
      "  0.27272248  0.00241622 -0.31935647  0.3325266  -0.23365018 -0.21525594\n",
      "  0.09195271 -0.4442685 ]\n",
      "New theta_0 : [ 0.00633716 -0.07991839  0.11149217  0.02026053  0.09835724 -0.23224717\n",
      "  0.2727156   0.00242078 -0.31936175  0.33258398 -0.2337098  -0.21525983\n",
      "  0.09195162 -0.44427215]\n",
      "Training Error:  10.544390030385015\n",
      "====================================================================================================\n",
      "Iteration:  1023\n",
      "Previous theta :  [ 0.00633716 -0.07991839  0.11149217  0.02026053  0.09835724 -0.23224717\n",
      "  0.2727156   0.00242078 -0.31936175  0.33258398 -0.2337098  -0.21525983\n",
      "  0.09195162 -0.44427215]\n",
      "New theta_0 : [ 0.00633702 -0.0799257   0.11149923  0.02027653  0.09835415 -0.23225611\n",
      "  0.27270875  0.00242533 -0.31936699  0.33264121 -0.23376928 -0.21526369\n",
      "  0.09195054 -0.44427579]\n",
      "Training Error:  10.544383172596197\n",
      "====================================================================================================\n",
      "Iteration:  1024\n",
      "Previous theta :  [ 0.00633702 -0.0799257   0.11149923  0.02027653  0.09835415 -0.23225611\n",
      "  0.27270875  0.00242533 -0.31936699  0.33264121 -0.23376928 -0.21526369\n",
      "  0.09195054 -0.44427579]\n",
      "New theta_0 : [ 0.00633689 -0.07993298  0.11150626  0.02029248  0.09835107 -0.232265\n",
      "  0.27270192  0.00242987 -0.31937218  0.33269827 -0.23382861 -0.21526754\n",
      "  0.09194946 -0.44427943]\n",
      "Training Error:  10.544376351897261\n",
      "====================================================================================================\n",
      "Iteration:  1025\n",
      "Previous theta :  [ 0.00633689 -0.07993298  0.11150626  0.02029248  0.09835107 -0.232265\n",
      "  0.27270192  0.00242987 -0.31937218  0.33269827 -0.23382861 -0.21526754\n",
      "  0.09194946 -0.44427943]\n",
      "New theta_0 : [ 0.00633675 -0.07994023  0.11151326  0.0203084   0.09834799 -0.23227383\n",
      "  0.27269512  0.00243439 -0.31937732  0.33275518 -0.23388779 -0.21527138\n",
      "  0.09194839 -0.44428306]\n",
      "Training Error:  10.544369568078162\n",
      "====================================================================================================\n",
      "Iteration:  1026\n",
      "Previous theta :  [ 0.00633675 -0.07994023  0.11151326  0.0203084   0.09834799 -0.23227383\n",
      "  0.27269512  0.00243439 -0.31937732  0.33275518 -0.23388779 -0.21527138\n",
      "  0.09194839 -0.44428306]\n",
      "New theta_0 : [ 0.00633662 -0.07994745  0.11152024  0.02032428  0.09834492 -0.2322826\n",
      "  0.27268835  0.0024389  -0.31938242  0.33281193 -0.23394682 -0.21527519\n",
      "  0.09194732 -0.44428668]\n",
      "Training Error:  10.544362820930168\n",
      "====================================================================================================\n",
      "Iteration:  1027\n",
      "Previous theta :  [ 0.00633662 -0.07994745  0.11152024  0.02032428  0.09834492 -0.2322826\n",
      "  0.27268835  0.0024389  -0.31938242  0.33281193 -0.23394682 -0.21527519\n",
      "  0.09194732 -0.44428668]\n",
      "New theta_0 : [ 0.00633649 -0.07995464  0.11152719  0.02034012  0.09834187 -0.23229132\n",
      "  0.2726816   0.0024434  -0.31938748  0.33286853 -0.23400571 -0.21527899\n",
      "  0.09194627 -0.4442903 ]\n",
      "Training Error:  10.54435611024586\n",
      "====================================================================================================\n",
      "Iteration:  1028\n",
      "Previous theta :  [ 0.00633649 -0.07995464  0.11152719  0.02034012  0.09834187 -0.23229132\n",
      "  0.2726816   0.0024434  -0.31938748  0.33286853 -0.23400571 -0.21527899\n",
      "  0.09194627 -0.4442903 ]\n",
      "New theta_0 : [ 0.00633636 -0.0799618   0.11153411  0.02035593  0.09833881 -0.23229999\n",
      "  0.27267487  0.00244788 -0.3193925   0.33292497 -0.23406444 -0.21528277\n",
      "  0.09194521 -0.4442939 ]\n",
      "Training Error:  10.544349435819111\n",
      "====================================================================================================\n",
      "Iteration:  1029\n",
      "Previous theta :  [ 0.00633636 -0.0799618   0.11153411  0.02035593  0.09833881 -0.23229999\n",
      "  0.27267487  0.00244788 -0.3193925   0.33292497 -0.23406444 -0.21528277\n",
      "  0.09194521 -0.4442939 ]\n",
      "New theta_0 : [ 0.00633623 -0.07996894  0.11154101  0.02037169  0.09833577 -0.2323086\n",
      "  0.27266817  0.00245235 -0.31939747  0.33298126 -0.23412304 -0.21528653\n",
      "  0.09194417 -0.4442975 ]\n",
      "Training Error:  10.544342797445086\n",
      "====================================================================================================\n",
      "Iteration:  1030\n",
      "Previous theta :  [ 0.00633623 -0.07996894  0.11154101  0.02037169  0.09833577 -0.2323086\n",
      "  0.27266817  0.00245235 -0.31939747  0.33298126 -0.23412304 -0.21528653\n",
      "  0.09194417 -0.4442975 ]\n",
      "New theta_0 : [ 0.0063361  -0.07997604  0.11154788  0.02038741  0.09833274 -0.23231715\n",
      "  0.2726615   0.0024568  -0.3194024   0.33303739 -0.23418148 -0.21529028\n",
      "  0.09194313 -0.4443011 ]\n",
      "Training Error:  10.544336194920225\n",
      "====================================================================================================\n",
      "Iteration:  1031\n",
      "Previous theta :  [ 0.0063361  -0.07997604  0.11154788  0.02038741  0.09833274 -0.23231715\n",
      "  0.2726615   0.0024568  -0.3194024   0.33303739 -0.23418148 -0.21529028\n",
      "  0.09194313 -0.4443011 ]\n",
      "New theta_0 : [ 0.00633597 -0.07998312  0.11155472  0.02040309  0.09832971 -0.23232565\n",
      "  0.27265485  0.00246124 -0.31940728  0.33309336 -0.23423978 -0.215294\n",
      "  0.09194209 -0.44430468]\n",
      "Training Error:  10.54432962804224\n",
      "====================================================================================================\n",
      "Iteration:  1032\n",
      "Previous theta :  [ 0.00633597 -0.07998312  0.11155472  0.02040309  0.09832971 -0.23232565\n",
      "  0.27265485  0.00246124 -0.31940728  0.33309336 -0.23423978 -0.215294\n",
      "  0.09194209 -0.44430468]\n",
      "New theta_0 : [ 0.00633584 -0.07999017  0.11156154  0.02041874  0.09832669 -0.2323341\n",
      "  0.27264822  0.00246567 -0.31941213  0.33314919 -0.23429793 -0.21529771\n",
      "  0.09194106 -0.44430826]\n",
      "Training Error:  10.544323096610096\n",
      "====================================================================================================\n",
      "Iteration:  1033\n",
      "Previous theta :  [ 0.00633584 -0.07999017  0.11156154  0.02041874  0.09832669 -0.2323341\n",
      "  0.27264822  0.00246567 -0.31941213  0.33314919 -0.23429793 -0.21529771\n",
      "  0.09194106 -0.44430826]\n",
      "New theta_0 : [ 0.00633571 -0.07999719  0.11156833  0.02043434  0.09832368 -0.2323425\n",
      "  0.27264162  0.00247008 -0.31941693  0.33320486 -0.23435594 -0.21530141\n",
      "  0.09194004 -0.44431183]\n",
      "Training Error:  10.544316600424015\n",
      "====================================================================================================\n",
      "Iteration:  1034\n",
      "Previous theta :  [ 0.00633571 -0.07999719  0.11156833  0.02043434  0.09832368 -0.2323425\n",
      "  0.27264162  0.00247008 -0.31941693  0.33320486 -0.23435594 -0.21530141\n",
      "  0.09194004 -0.44431183]\n",
      "New theta_0 : [ 0.00633558 -0.08000419  0.11157509  0.02044991  0.09832068 -0.23235084\n",
      "  0.27263504  0.00247448 -0.31942169  0.33326037 -0.2344138  -0.21530509\n",
      "  0.09193902 -0.4443154 ]\n",
      "Training Error:  10.544310139285455\n",
      "====================================================================================================\n",
      "Iteration:  1035\n",
      "Previous theta :  [ 0.00633558 -0.08000419  0.11157509  0.02044991  0.09832068 -0.23235084\n",
      "  0.27263504  0.00247448 -0.31942169  0.33326037 -0.2344138  -0.21530509\n",
      "  0.09193902 -0.4443154 ]\n",
      "New theta_0 : [ 0.00633545 -0.08001115  0.11158183  0.02046543  0.09831768 -0.23235912\n",
      "  0.27262849  0.00247887 -0.31942641  0.33331574 -0.23447151 -0.21530875\n",
      "  0.09193801 -0.44431895]\n",
      "Training Error:  10.544303712997106\n",
      "====================================================================================================\n",
      "Iteration:  1036\n",
      "Previous theta :  [ 0.00633545 -0.08001115  0.11158183  0.02046543  0.09831768 -0.23235912\n",
      "  0.27262849  0.00247887 -0.31942641  0.33331574 -0.23447151 -0.21530875\n",
      "  0.09193801 -0.44431895]\n",
      "New theta_0 : [ 0.00633532 -0.08001809  0.11158854  0.02048092  0.09831469 -0.23236736\n",
      "  0.27262196  0.00248324 -0.31943109  0.33337095 -0.23452909 -0.21531239\n",
      "  0.09193701 -0.4443225 ]\n",
      "Training Error:  10.544297321362881\n",
      "====================================================================================================\n",
      "Iteration:  1037\n",
      "Previous theta :  [ 0.00633532 -0.08001809  0.11158854  0.02048092  0.09831469 -0.23236736\n",
      "  0.27262196  0.00248324 -0.31943109  0.33337095 -0.23452909 -0.21531239\n",
      "  0.09193701 -0.4443225 ]\n",
      "New theta_0 : [ 0.0063352  -0.080025    0.11159523  0.02049637  0.09831171 -0.23237554\n",
      "  0.27261546  0.0024876  -0.31943573  0.33342601 -0.23458651 -0.21531602\n",
      "  0.09193601 -0.44432605]\n",
      "Training Error:  10.544290964187907\n",
      "====================================================================================================\n",
      "Iteration:  1038\n",
      "Previous theta :  [ 0.0063352  -0.080025    0.11159523  0.02049637  0.09831171 -0.23237554\n",
      "  0.27261546  0.0024876  -0.31943573  0.33342601 -0.23458651 -0.21531602\n",
      "  0.09193601 -0.44432605]\n",
      "New theta_0 : [ 0.00633507 -0.08003188  0.11160189  0.02051178  0.09830874 -0.23238368\n",
      "  0.27260898  0.00249195 -0.31944033  0.33348092 -0.2346438  -0.21531963\n",
      "  0.09193502 -0.44432958]\n",
      "Training Error:  10.544284641278512\n",
      "====================================================================================================\n",
      "Iteration:  1039\n",
      "Previous theta :  [ 0.00633507 -0.08003188  0.11160189  0.02051178  0.09830874 -0.23238368\n",
      "  0.27260898  0.00249195 -0.31944033  0.33348092 -0.2346438  -0.21531963\n",
      "  0.09193502 -0.44432958]\n",
      "New theta_0 : [ 0.00633495 -0.08003874  0.11160853  0.02052716  0.09830578 -0.23239176\n",
      "  0.27260252  0.00249628 -0.31944488  0.33353568 -0.23470094 -0.21532322\n",
      "  0.09193403 -0.44433311]\n",
      "Training Error:  10.544278352442221\n",
      "====================================================================================================\n",
      "Iteration:  1040\n",
      "Previous theta :  [ 0.00633495 -0.08003874  0.11160853  0.02052716  0.09830578 -0.23239176\n",
      "  0.27260252  0.00249628 -0.31944488  0.33353568 -0.23470094 -0.21532322\n",
      "  0.09193403 -0.44433311]\n",
      "New theta_0 : [ 0.00633482 -0.08004557  0.11161514  0.02054249  0.09830282 -0.23239979\n",
      "  0.27259609  0.0025006  -0.3194494   0.33359029 -0.23475793 -0.2153268\n",
      "  0.09193305 -0.44433663]\n",
      "Training Error:  10.544272097487749\n",
      "====================================================================================================\n",
      "Iteration:  1041\n",
      "Previous theta :  [ 0.00633482 -0.08004557  0.11161514  0.02054249  0.09830282 -0.23239979\n",
      "  0.27259609  0.0025006  -0.3194494   0.33359029 -0.23475793 -0.2153268\n",
      "  0.09193305 -0.44433663]\n",
      "New theta_0 : [ 0.0063347  -0.08005237  0.11162173  0.02055779  0.09829988 -0.23240777\n",
      "  0.27258968  0.00250491 -0.31945388  0.33364475 -0.23481479 -0.21533036\n",
      "  0.09193207 -0.44434014]\n",
      "Training Error:  10.544265876224983\n",
      "====================================================================================================\n",
      "Iteration:  1042\n",
      "Previous theta :  [ 0.0063347  -0.08005237  0.11162173  0.02055779  0.09829988 -0.23240777\n",
      "  0.27258968  0.00250491 -0.31945388  0.33364475 -0.23481479 -0.21533036\n",
      "  0.09193207 -0.44434014]\n",
      "New theta_0 : [ 0.00633457 -0.08005915  0.11162829  0.02057304  0.09829694 -0.23241569\n",
      "  0.27258329  0.0025092  -0.31945832  0.33369906 -0.2348715  -0.21533391\n",
      "  0.0919311  -0.44434365]\n",
      "Training Error:  10.544259688464983\n",
      "====================================================================================================\n",
      "Iteration:  1043\n",
      "Previous theta :  [ 0.00633457 -0.08005915  0.11162829  0.02057304  0.09829694 -0.23241569\n",
      "  0.27258329  0.0025092  -0.31945832  0.33369906 -0.2348715  -0.21533391\n",
      "  0.0919311  -0.44434365]\n",
      "New theta_0 : [ 0.00633445 -0.0800659   0.11163483  0.02058826  0.098294   -0.23242357\n",
      "  0.27257693  0.00251348 -0.31946273  0.33375322 -0.23492807 -0.21533744\n",
      "  0.09193014 -0.44434715]\n",
      "Training Error:  10.544253534019969\n",
      "====================================================================================================\n",
      "Iteration:  1044\n",
      "Previous theta :  [ 0.00633445 -0.0800659   0.11163483  0.02058826  0.098294   -0.23242357\n",
      "  0.27257693  0.00251348 -0.31946273  0.33375322 -0.23492807 -0.21533744\n",
      "  0.09193014 -0.44434715]\n",
      "New theta_0 : [ 0.00633433 -0.08007262  0.11164134  0.02060344  0.09829108 -0.2324314\n",
      "  0.27257059  0.00251775 -0.31946709  0.33380723 -0.23498449 -0.21534095\n",
      "  0.09192918 -0.44435064]\n",
      "Training Error:  10.544247412703312\n",
      "====================================================================================================\n",
      "Iteration:  1045\n",
      "Previous theta :  [ 0.00633433 -0.08007262  0.11164134  0.02060344  0.09829108 -0.2324314\n",
      "  0.27257059  0.00251775 -0.31946709  0.33380723 -0.23498449 -0.21534095\n",
      "  0.09192918 -0.44435064]\n",
      "New theta_0 : [ 0.00633421 -0.08007932  0.11164783  0.02061859  0.09828816 -0.23243918\n",
      "  0.27256427  0.002522   -0.31947142  0.3338611  -0.23504078 -0.21534445\n",
      "  0.09192823 -0.44435412]\n",
      "Training Error:  10.544241324329528\n",
      "====================================================================================================\n",
      "Iteration:  1046\n",
      "Previous theta :  [ 0.00633421 -0.08007932  0.11164783  0.02061859  0.09828816 -0.23243918\n",
      "  0.27256427  0.002522   -0.31947142  0.3338611  -0.23504078 -0.21534445\n",
      "  0.09192823 -0.44435412]\n",
      "New theta_0 : [ 0.00633408 -0.08008599  0.11165429  0.02063369  0.09828525 -0.23244691\n",
      "  0.27255798  0.00252624 -0.3194757   0.33391481 -0.23509692 -0.21534793\n",
      "  0.09192728 -0.4443576 ]\n",
      "Training Error:  10.544235268714269\n",
      "====================================================================================================\n",
      "Iteration:  1047\n",
      "Previous theta :  [ 0.00633408 -0.08008599  0.11165429  0.02063369  0.09828525 -0.23244691\n",
      "  0.27255798  0.00252624 -0.3194757   0.33391481 -0.23509692 -0.21534793\n",
      "  0.09192728 -0.4443576 ]\n",
      "New theta_0 : [ 0.00633396 -0.08009263  0.11166073  0.02064876  0.09828235 -0.23245459\n",
      "  0.27255171  0.00253047 -0.31947996  0.33396838 -0.23515293 -0.21535139\n",
      "  0.09192633 -0.44436107]\n",
      "Training Error:  10.544229245674316\n",
      "====================================================================================================\n",
      "Iteration:  1048\n",
      "Previous theta :  [ 0.00633396 -0.08009263  0.11166073  0.02064876  0.09828235 -0.23245459\n",
      "  0.27255171  0.00253047 -0.31947996  0.33396838 -0.23515293 -0.21535139\n",
      "  0.09192633 -0.44436107]\n",
      "New theta_0 : [ 0.00633384 -0.08009925  0.11166714  0.02066379  0.09827946 -0.23246223\n",
      "  0.27254546  0.00253468 -0.31948417  0.33402181 -0.23520879 -0.21535484\n",
      "  0.0919254  -0.44436453]\n",
      "Training Error:  10.544223255027562\n",
      "====================================================================================================\n",
      "Iteration:  1049\n",
      "Previous theta :  [ 0.00633384 -0.08009925  0.11166714  0.02066379  0.09827946 -0.23246223\n",
      "  0.27254546  0.00253468 -0.31948417  0.33402181 -0.23520879 -0.21535484\n",
      "  0.0919254  -0.44436453]\n",
      "New theta_0 : [ 0.00633372 -0.08010584  0.11167353  0.02067878  0.09827657 -0.23246981\n",
      "  0.27253923  0.00253889 -0.31948834  0.33407508 -0.23526451 -0.21535828\n",
      "  0.09192447 -0.44436799]\n",
      "Training Error:  10.544217296593022\n",
      "====================================================================================================\n",
      "Iteration:  1050\n",
      "Previous theta :  [ 0.00633372 -0.08010584  0.11167353  0.02067878  0.09827657 -0.23246981\n",
      "  0.27253923  0.00253889 -0.31948834  0.33407508 -0.23526451 -0.21535828\n",
      "  0.09192447 -0.44436799]\n",
      "New theta_0 : [ 0.0063336  -0.08011241  0.1116799   0.02069373  0.09827369 -0.23247735\n",
      "  0.27253303  0.00254308 -0.31949248  0.33412821 -0.23532009 -0.2153617\n",
      "  0.09192354 -0.44437143]\n",
      "Training Error:  10.544211370190803\n",
      "====================================================================================================\n",
      "Iteration:  1051\n",
      "Previous theta :  [ 0.0063336  -0.08011241  0.1116799   0.02069373  0.09827369 -0.23247735\n",
      "  0.27253303  0.00254308 -0.31949248  0.33412821 -0.23532009 -0.2153617\n",
      "  0.09192354 -0.44437143]\n",
      "New theta_0 : [ 0.00633349 -0.08011895  0.11168624  0.02070865  0.09827082 -0.23248484\n",
      "  0.27252685  0.00254725 -0.31949659  0.3341812  -0.23537553 -0.2153651\n",
      "  0.09192262 -0.44437488]\n",
      "Training Error:  10.544205475642116\n",
      "====================================================================================================\n",
      "Iteration:  1052\n",
      "Previous theta :  [ 0.00633349 -0.08011895  0.11168624  0.02070865  0.09827082 -0.23248484\n",
      "  0.27252685  0.00254725 -0.31949659  0.3341812  -0.23537553 -0.2153651\n",
      "  0.09192262 -0.44437488]\n",
      "New theta_0 : [ 0.00633337 -0.08012546  0.11169256  0.02072352  0.09826796 -0.23249229\n",
      "  0.27252069  0.00255142 -0.31950066  0.33423404 -0.23543084 -0.21536849\n",
      "  0.0919217  -0.44437831]\n",
      "Training Error:  10.544199612769255\n",
      "====================================================================================================\n",
      "Iteration:  1053\n",
      "Previous theta :  [ 0.00633337 -0.08012546  0.11169256  0.02072352  0.09826796 -0.23249229\n",
      "  0.27252069  0.00255142 -0.31950066  0.33423404 -0.23543084 -0.21536849\n",
      "  0.0919217  -0.44437831]\n",
      "New theta_0 : [ 0.00633325 -0.08013195  0.11169885  0.02073837  0.0982651  -0.23249968\n",
      "  0.27251456  0.00255557 -0.31950469  0.33428674 -0.235486   -0.21537186\n",
      "  0.09192079 -0.44438174]\n",
      "Training Error:  10.544193781395595\n",
      "====================================================================================================\n",
      "Iteration:  1054\n",
      "Previous theta :  [ 0.00633325 -0.08013195  0.11169885  0.02073837  0.0982651  -0.23249968\n",
      "  0.27251456  0.00255557 -0.31950469  0.33428674 -0.235486   -0.21537186\n",
      "  0.09192079 -0.44438174]\n",
      "New theta_0 : [ 0.00633313 -0.08013842  0.11170512  0.02075317  0.09826225 -0.23250703\n",
      "  0.27250844  0.00255971 -0.31950868  0.33433929 -0.23554103 -0.21537522\n",
      "  0.09191989 -0.44438516]\n",
      "Training Error:  10.54418798134558\n",
      "====================================================================================================\n",
      "Iteration:  1055\n",
      "Previous theta :  [ 0.00633313 -0.08013842  0.11170512  0.02075317  0.09826225 -0.23250703\n",
      "  0.27250844  0.00255971 -0.31950868  0.33433929 -0.23554103 -0.21537522\n",
      "  0.09191989 -0.44438516]\n",
      "New theta_0 : [ 0.00633302 -0.08014485  0.11171137  0.02076793  0.09825941 -0.23251434\n",
      "  0.27250235  0.00256384 -0.31951264  0.33439169 -0.23559591 -0.21537857\n",
      "  0.09191899 -0.44438857]\n",
      "Training Error:  10.544182212444724\n",
      "====================================================================================================\n",
      "Iteration:  1056\n",
      "Previous theta :  [ 0.00633302 -0.08014485  0.11171137  0.02076793  0.09825941 -0.23251434\n",
      "  0.27250235  0.00256384 -0.31951264  0.33439169 -0.23559591 -0.21537857\n",
      "  0.09191899 -0.44438857]\n",
      "New theta_0 : [ 0.0063329  -0.08015127  0.1117176   0.02078266  0.09825658 -0.2325216\n",
      "  0.27249628  0.00256795 -0.31951657  0.33444396 -0.23565066 -0.21538189\n",
      "  0.09191809 -0.44439198]\n",
      "Training Error:  10.544176474519594\n",
      "====================================================================================================\n",
      "Iteration:  1057\n",
      "Previous theta :  [ 0.0063329  -0.08015127  0.1117176   0.02078266  0.09825658 -0.2325216\n",
      "  0.27249628  0.00256795 -0.31951657  0.33444396 -0.23565066 -0.21538189\n",
      "  0.09191809 -0.44439198]\n",
      "New theta_0 : [ 0.00633279 -0.08015766  0.1117238   0.02079736  0.09825375 -0.23252881\n",
      "  0.27249023  0.00257205 -0.31952046  0.33449608 -0.23570527 -0.21538521\n",
      "  0.0919172  -0.44439537]\n",
      "Training Error:  10.544170767397802\n",
      "====================================================================================================\n",
      "Iteration:  1058\n",
      "Previous theta :  [ 0.00633279 -0.08015766  0.1117238   0.02079736  0.09825375 -0.23252881\n",
      "  0.27249023  0.00257205 -0.31952046  0.33449608 -0.23570527 -0.21538521\n",
      "  0.0919172  -0.44439537]\n",
      "New theta_0 : [ 0.00633267 -0.08016402  0.11172997  0.02081201  0.09825093 -0.23253598\n",
      "  0.27248421  0.00257614 -0.31952432  0.33454806 -0.23575975 -0.21538851\n",
      "  0.09191632 -0.44439876]\n",
      "Training Error:  10.54416509090801\n",
      "====================================================================================================\n",
      "Iteration:  1059\n",
      "Previous theta :  [ 0.00633267 -0.08016402  0.11172997  0.02081201  0.09825093 -0.23253598\n",
      "  0.27248421  0.00257614 -0.31952432  0.33454806 -0.23575975 -0.21538851\n",
      "  0.09191632 -0.44439876]\n",
      "New theta_0 : [ 0.00633256 -0.08017036  0.11173613  0.02082663  0.09824812 -0.2325431\n",
      "  0.2724782   0.00258022 -0.31952814  0.3345999  -0.23581408 -0.21539179\n",
      "  0.09191544 -0.44440215]\n",
      "Training Error:  10.544159444879908\n",
      "====================================================================================================\n",
      "Iteration:  1060\n",
      "Previous theta :  [ 0.00633256 -0.08017036  0.11173613  0.02082663  0.09824812 -0.2325431\n",
      "  0.2724782   0.00258022 -0.31952814  0.3345999  -0.23581408 -0.21539179\n",
      "  0.09191544 -0.44440215]\n",
      "New theta_0 : [ 0.00633244 -0.08017668  0.11174226  0.02084121  0.09824532 -0.23255018\n",
      "  0.27247222  0.00258428 -0.31953193  0.33465159 -0.23586828 -0.21539506\n",
      "  0.09191456 -0.44440553]\n",
      "Training Error:  10.544153829144214\n",
      "====================================================================================================\n",
      "Iteration:  1061\n",
      "Previous theta :  [ 0.00633244 -0.08017668  0.11174226  0.02084121  0.09824532 -0.23255018\n",
      "  0.27247222  0.00258428 -0.31953193  0.33465159 -0.23586828 -0.21539506\n",
      "  0.09191456 -0.44440553]\n",
      "New theta_0 : [ 0.00633233 -0.08018297  0.11174837  0.02085575  0.09824252 -0.23255721\n",
      "  0.27246626  0.00258834 -0.31953568  0.33470315 -0.23592235 -0.21539831\n",
      "  0.09191369 -0.4444089 ]\n",
      "Training Error:  10.54414824353267\n",
      "====================================================================================================\n",
      "Iteration:  1062\n",
      "Previous theta :  [ 0.00633233 -0.08018297  0.11174837  0.02085575  0.09824252 -0.23255721\n",
      "  0.27246626  0.00258834 -0.31953568  0.33470315 -0.23592235 -0.21539831\n",
      "  0.09191369 -0.4444089 ]\n",
      "New theta_0 : [ 0.00633222 -0.08018924  0.11175446  0.02087026  0.09823974 -0.2325642\n",
      "  0.27246031  0.00259238 -0.31953941  0.33475456 -0.23597627 -0.21540155\n",
      "  0.09191283 -0.44441226]\n",
      "Training Error:  10.544142687878026\n",
      "====================================================================================================\n",
      "Iteration:  1063\n",
      "Previous theta :  [ 0.00633222 -0.08018924  0.11175446  0.02087026  0.09823974 -0.2325642\n",
      "  0.27246031  0.00259238 -0.31953941  0.33475456 -0.23597627 -0.21540155\n",
      "  0.09191283 -0.44441226]\n",
      "New theta_0 : [ 0.00633211 -0.08019548  0.11176052  0.02088473  0.09823695 -0.23257115\n",
      "  0.2724544   0.0025964  -0.3195431   0.33480583 -0.23603006 -0.21540478\n",
      "  0.09191197 -0.44441562]\n",
      "Training Error:  10.544137162014039\n",
      "====================================================================================================\n",
      "Iteration:  1064\n",
      "Previous theta :  [ 0.00633211 -0.08019548  0.11176052  0.02088473  0.09823695 -0.23257115\n",
      "  0.2724544   0.0025964  -0.3195431   0.33480583 -0.23603006 -0.21540478\n",
      "  0.09191197 -0.44441562]\n",
      "New theta_0 : [ 0.00633199 -0.0802017   0.11176656  0.02089916  0.09823418 -0.23257805\n",
      "  0.2724485   0.00260042 -0.31954675  0.33485697 -0.23608372 -0.21540799\n",
      "  0.09191111 -0.44441896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.544131665775462\n",
      "====================================================================================================\n",
      "Iteration:  1065\n",
      "Previous theta :  [ 0.00633199 -0.0802017   0.11176656  0.02089916  0.09823418 -0.23257805\n",
      "  0.2724485   0.00260042 -0.31954675  0.33485697 -0.23608372 -0.21540799\n",
      "  0.09191111 -0.44441896]\n",
      "New theta_0 : [ 0.00633188 -0.0802079   0.11177258  0.02091356  0.09823141 -0.23258491\n",
      "  0.27244262  0.00260442 -0.31955037  0.33490796 -0.23613724 -0.21541119\n",
      "  0.09191026 -0.44442231]\n",
      "Training Error:  10.544126198998043\n",
      "====================================================================================================\n",
      "Iteration:  1066\n",
      "Previous theta :  [ 0.00633188 -0.0802079   0.11177258  0.02091356  0.09823141 -0.23258491\n",
      "  0.27244262  0.00260442 -0.31955037  0.33490796 -0.23613724 -0.21541119\n",
      "  0.09191026 -0.44442231]\n",
      "New theta_0 : [ 0.00633177 -0.08021407  0.11177858  0.02092792  0.09822865 -0.23259173\n",
      "  0.27243676  0.00260841 -0.31955397  0.33495881 -0.23619063 -0.21541437\n",
      "  0.09190942 -0.44442564]\n",
      "Training Error:  10.544120761518514\n",
      "====================================================================================================\n",
      "Iteration:  1067\n",
      "Previous theta :  [ 0.00633177 -0.08021407  0.11177858  0.02092792  0.09822865 -0.23259173\n",
      "  0.27243676  0.00260841 -0.31955397  0.33495881 -0.23619063 -0.21541437\n",
      "  0.09190942 -0.44442564]\n",
      "New theta_0 : [ 0.00633166 -0.08022022  0.11178456  0.02094225  0.0982259  -0.2325985\n",
      "  0.27243093  0.00261239 -0.31955752  0.33500953 -0.23624388 -0.21541754\n",
      "  0.09190858 -0.44442897]\n",
      "Training Error:  10.54411535317458\n",
      "====================================================================================================\n",
      "Iteration:  1068\n",
      "Previous theta :  [ 0.00633166 -0.08022022  0.11178456  0.02094225  0.0982259  -0.2325985\n",
      "  0.27243093  0.00261239 -0.31955752  0.33500953 -0.23624388 -0.21541754\n",
      "  0.09190858 -0.44442897]\n",
      "New theta_0 : [ 0.00633155 -0.08022634  0.11179051  0.02095654  0.09822316 -0.23260523\n",
      "  0.27242511  0.00261636 -0.31956105  0.33506011 -0.23629699 -0.2154207\n",
      "  0.09190774 -0.44443229]\n",
      "Training Error:  10.544109973804924\n",
      "====================================================================================================\n",
      "Iteration:  1069\n",
      "Previous theta :  [ 0.00633155 -0.08022634  0.11179051  0.02095654  0.09822316 -0.23260523\n",
      "  0.27242511  0.00261636 -0.31956105  0.33506011 -0.23629699 -0.2154207\n",
      "  0.09190774 -0.44443229]\n",
      "New theta_0 : [ 0.00633144 -0.08023244  0.11179644  0.02097079  0.09822042 -0.23261192\n",
      "  0.27241932  0.00262032 -0.31956455  0.33511055 -0.23634998 -0.21542384\n",
      "  0.09190691 -0.4444356 ]\n",
      "Training Error:  10.544104623249188\n",
      "====================================================================================================\n",
      "Iteration:  1070\n",
      "Previous theta :  [ 0.00633144 -0.08023244  0.11179644  0.02097079  0.09822042 -0.23261192\n",
      "  0.27241932  0.00262032 -0.31956455  0.33511055 -0.23634998 -0.21542384\n",
      "  0.09190691 -0.4444356 ]\n",
      "New theta_0 : [ 0.00633133 -0.08023852  0.11180235  0.020985    0.09821769 -0.23261857\n",
      "  0.27241355  0.00262426 -0.31956801  0.33516085 -0.23640282 -0.21542697\n",
      "  0.09190608 -0.44443891]\n",
      "Training Error:  10.544099301347968\n",
      "====================================================================================================\n",
      "Iteration:  1071\n",
      "Previous theta :  [ 0.00633133 -0.08023852  0.11180235  0.020985    0.09821769 -0.23261857\n",
      "  0.27241355  0.00262426 -0.31956801  0.33516085 -0.23640282 -0.21542697\n",
      "  0.09190608 -0.44443891]\n",
      "New theta_0 : [ 0.00633123 -0.08024457  0.11180824  0.02099918  0.09821497 -0.23262517\n",
      "  0.27240779  0.00262819 -0.31957144  0.33521101 -0.23645554 -0.21543008\n",
      "  0.09190526 -0.44444221]\n",
      "Training Error:  10.544094007942821\n",
      "====================================================================================================\n",
      "Iteration:  1072\n",
      "Previous theta :  [ 0.00633123 -0.08024457  0.11180824  0.02099918  0.09821497 -0.23262517\n",
      "  0.27240779  0.00262819 -0.31957144  0.33521101 -0.23645554 -0.21543008\n",
      "  0.09190526 -0.44444221]\n",
      "New theta_0 : [ 0.00633112 -0.08025061  0.1118141   0.02101333  0.09821225 -0.23263174\n",
      "  0.27240206  0.00263211 -0.31957485  0.33526104 -0.23650812 -0.21543318\n",
      "  0.09190444 -0.4444455 ]\n",
      "Training Error:  10.54408874287624\n",
      "====================================================================================================\n",
      "Iteration:  1073\n",
      "Previous theta :  [ 0.00633112 -0.08025061  0.1118141   0.02101333  0.09821225 -0.23263174\n",
      "  0.27240206  0.00263211 -0.31957485  0.33526104 -0.23650812 -0.21543318\n",
      "  0.09190444 -0.4444455 ]\n",
      "New theta_0 : [ 0.00633101 -0.08025661  0.11181995  0.02102744  0.09820954 -0.23263826\n",
      "  0.27239635  0.00263602 -0.31957822  0.33531093 -0.23656057 -0.21543626\n",
      "  0.09190363 -0.44444879]\n",
      "Training Error:  10.544083505991654\n",
      "====================================================================================================\n",
      "Iteration:  1074\n",
      "Previous theta :  [ 0.00633101 -0.08025661  0.11181995  0.02102744  0.09820954 -0.23263826\n",
      "  0.27239635  0.00263602 -0.31957822  0.33531093 -0.23656057 -0.21543626\n",
      "  0.09190363 -0.44444879]\n",
      "New theta_0 : [ 0.0063309  -0.0802626   0.11182577  0.02104151  0.09820684 -0.23264475\n",
      "  0.27239065  0.00263992 -0.31958156  0.33536069 -0.23661289 -0.21543934\n",
      "  0.09190282 -0.44445207]\n",
      "Training Error:  10.544078297133431\n",
      "====================================================================================================\n",
      "Iteration:  1075\n",
      "Previous theta :  [ 0.0063309  -0.0802626   0.11182577  0.02104151  0.09820684 -0.23264475\n",
      "  0.27239065  0.00263992 -0.31958156  0.33536069 -0.23661289 -0.21543934\n",
      "  0.09190282 -0.44445207]\n",
      "New theta_0 : [ 0.0063308  -0.08026856  0.11183157  0.02105555  0.09820414 -0.23265119\n",
      "  0.27238498  0.0026438  -0.31958487  0.33541031 -0.23666508 -0.2154424\n",
      "  0.09190202 -0.44445534]\n",
      "Training Error:  10.544073116146858\n",
      "====================================================================================================\n",
      "Iteration:  1076\n",
      "Previous theta :  [ 0.0063308  -0.08026856  0.11183157  0.02105555  0.09820414 -0.23265119\n",
      "  0.27238498  0.0026438  -0.31958487  0.33541031 -0.23666508 -0.2154424\n",
      "  0.09190202 -0.44445534]\n",
      "New theta_0 : [ 0.00633069 -0.0802745   0.11183735  0.02106955  0.09820146 -0.23265759\n",
      "  0.27237933  0.00264768 -0.31958815  0.33545979 -0.23671713 -0.21544544\n",
      "  0.09190122 -0.44445861]\n",
      "Training Error:  10.54406796287814\n",
      "====================================================================================================\n",
      "Iteration:  1077\n",
      "Previous theta :  [ 0.00633069 -0.0802745   0.11183735  0.02106955  0.09820146 -0.23265759\n",
      "  0.27237933  0.00264768 -0.31958815  0.33545979 -0.23671713 -0.21544544\n",
      "  0.09190122 -0.44445861]\n",
      "New theta_0 : [ 0.00633059 -0.08028042  0.11184311  0.02108351  0.09819878 -0.23266396\n",
      "  0.2723737   0.00265154 -0.3195914   0.33550914 -0.23676905 -0.21544847\n",
      "  0.09190043 -0.44446186]\n",
      "Training Error:  10.544062837174396\n",
      "====================================================================================================\n",
      "Iteration:  1078\n",
      "Previous theta :  [ 0.00633059 -0.08028042  0.11184311  0.02108351  0.09819878 -0.23266396\n",
      "  0.2723737   0.00265154 -0.3195914   0.33550914 -0.23676905 -0.21544847\n",
      "  0.09190043 -0.44446186]\n",
      "New theta_0 : [ 0.00633048 -0.08028632  0.11184885  0.02109744  0.0981961  -0.23267028\n",
      "  0.27236808  0.00265539 -0.31959462  0.33555835 -0.23682084 -0.21545149\n",
      "  0.09189964 -0.44446512]\n",
      "Training Error:  10.544057738883652\n",
      "====================================================================================================\n",
      "Iteration:  1079\n",
      "Previous theta :  [ 0.00633048 -0.08028632  0.11184885  0.02109744  0.0981961  -0.23267028\n",
      "  0.27236808  0.00265539 -0.31959462  0.33555835 -0.23682084 -0.21545149\n",
      "  0.09189964 -0.44446512]\n",
      "New theta_0 : [ 0.00633038 -0.08029219  0.11185457  0.02111134  0.09819344 -0.23267656\n",
      "  0.27236249  0.00265923 -0.31959781  0.33560743 -0.23687251 -0.2154545\n",
      "  0.09189885 -0.44446836]\n",
      "Training Error:  10.54405266785483\n",
      "====================================================================================================\n",
      "Iteration:  1080\n",
      "Previous theta :  [ 0.00633038 -0.08029219  0.11185457  0.02111134  0.09819344 -0.23267656\n",
      "  0.27236249  0.00265923 -0.31959781  0.33560743 -0.23687251 -0.2154545\n",
      "  0.09189885 -0.44446836]\n",
      "New theta_0 : [ 0.00633027 -0.08029804  0.11186027  0.0211252   0.09819078 -0.23268281\n",
      "  0.27235692  0.00266305 -0.31960098  0.33565638 -0.23692403 -0.21545749\n",
      "  0.09189807 -0.4444716 ]\n",
      "Training Error:  10.544047623937747\n",
      "====================================================================================================\n",
      "Iteration:  1081\n",
      "Previous theta :  [ 0.00633027 -0.08029804  0.11186027  0.0211252   0.09819078 -0.23268281\n",
      "  0.27235692  0.00266305 -0.31960098  0.33565638 -0.23692403 -0.21545749\n",
      "  0.09189807 -0.4444716 ]\n",
      "New theta_0 : [ 0.00633017 -0.08030387  0.11186594  0.02113902  0.09818812 -0.23268901\n",
      "  0.27235136  0.00266687 -0.31960411  0.3357052  -0.23697543 -0.21546047\n",
      "  0.09189729 -0.44447483]\n",
      "Training Error:  10.544042606983108\n",
      "====================================================================================================\n",
      "Iteration:  1082\n",
      "Previous theta :  [ 0.00633017 -0.08030387  0.11186594  0.02113902  0.09818812 -0.23268901\n",
      "  0.27235136  0.00266687 -0.31960411  0.3357052  -0.23697543 -0.21546047\n",
      "  0.09189729 -0.44447483]\n",
      "New theta_0 : [ 0.00633007 -0.08030967  0.1118716   0.02115281  0.09818548 -0.23269518\n",
      "  0.27234583  0.00267067 -0.31960722  0.33575388 -0.2370267  -0.21546344\n",
      "  0.09189652 -0.44447805]\n",
      "Training Error:  10.544037616842497\n",
      "====================================================================================================\n",
      "Iteration:  1083\n",
      "Previous theta :  [ 0.00633007 -0.08030967  0.1118716   0.02115281  0.09818548 -0.23269518\n",
      "  0.27234583  0.00267067 -0.31960722  0.33575388 -0.2370267  -0.21546344\n",
      "  0.09189652 -0.44447805]\n",
      "New theta_0 : [ 0.00632996 -0.08031546  0.11187724  0.02116656  0.09818284 -0.23270131\n",
      "  0.27234031  0.00267447 -0.3196103   0.33580243 -0.23707784 -0.21546639\n",
      "  0.09189575 -0.44448127]\n",
      "Training Error:  10.544032653368378\n",
      "====================================================================================================\n",
      "Iteration:  1084\n",
      "Previous theta :  [ 0.00632996 -0.08031546  0.11187724  0.02116656  0.09818284 -0.23270131\n",
      "  0.27234031  0.00267447 -0.3196103   0.33580243 -0.23707784 -0.21546639\n",
      "  0.09189575 -0.44448127]\n",
      "New theta_0 : [ 0.00632986 -0.08032122  0.11188285  0.02118028  0.09818021 -0.2327074\n",
      "  0.27233482  0.00267825 -0.31961335  0.33585084 -0.23712886 -0.21546933\n",
      "  0.09189499 -0.44448448]\n",
      "Training Error:  10.54402771641408\n",
      "====================================================================================================\n",
      "Iteration:  1085\n",
      "Previous theta :  [ 0.00632986 -0.08032122  0.11188285  0.02118028  0.09818021 -0.2327074\n",
      "  0.27233482  0.00267825 -0.31961335  0.33585084 -0.23712886 -0.21546933\n",
      "  0.09189499 -0.44448448]\n",
      "New theta_0 : [ 0.00632976 -0.08032696  0.11188844  0.02119397  0.09817759 -0.23271346\n",
      "  0.27232934  0.00268202 -0.31961637  0.33589913 -0.23717974 -0.21547226\n",
      "  0.09189423 -0.44448768]\n",
      "Training Error:  10.544022805833794\n",
      "====================================================================================================\n",
      "Iteration:  1086\n",
      "Previous theta :  [ 0.00632976 -0.08032696  0.11188844  0.02119397  0.09817759 -0.23271346\n",
      "  0.27232934  0.00268202 -0.31961637  0.33589913 -0.23717974 -0.21547226\n",
      "  0.09189423 -0.44448768]\n",
      "New theta_0 : [ 0.00632966 -0.08033268  0.11189402  0.02120762  0.09817497 -0.23271947\n",
      "  0.27232388  0.00268578 -0.31961936  0.33594728 -0.23723049 -0.21547517\n",
      "  0.09189347 -0.44449088]\n",
      "Training Error:  10.544017921482576\n",
      "====================================================================================================\n",
      "Iteration:  1087\n",
      "Previous theta :  [ 0.00632966 -0.08033268  0.11189402  0.02120762  0.09817497 -0.23271947\n",
      "  0.27232388  0.00268578 -0.31961936  0.33594728 -0.23723049 -0.21547517\n",
      "  0.09189347 -0.44449088]\n",
      "New theta_0 : [ 0.00632956 -0.08033838  0.11189957  0.02122123  0.09817236 -0.23272545\n",
      "  0.27231845  0.00268953 -0.31962233  0.3359953  -0.23728112 -0.21547808\n",
      "  0.09189272 -0.44449407]\n",
      "Training Error:  10.544013063216326\n",
      "====================================================================================================\n",
      "Iteration:  1088\n",
      "Previous theta :  [ 0.00632956 -0.08033838  0.11189957  0.02122123  0.09817236 -0.23272545\n",
      "  0.27231845  0.00268953 -0.31962233  0.3359953  -0.23728112 -0.21547808\n",
      "  0.09189272 -0.44449407]\n",
      "New theta_0 : [ 0.00632946 -0.08034406  0.11190511  0.02123481  0.09816975 -0.23273139\n",
      "  0.27231303  0.00269326 -0.31962527  0.33604319 -0.23733161 -0.21548097\n",
      "  0.09189198 -0.44449725]\n",
      "Training Error:  10.544008230891793\n",
      "====================================================================================================\n",
      "Iteration:  1089\n",
      "Previous theta :  [ 0.00632946 -0.08034406  0.11190511  0.02123481  0.09816975 -0.23273139\n",
      "  0.27231303  0.00269326 -0.31962527  0.33604319 -0.23733161 -0.21548097\n",
      "  0.09189198 -0.44449725]\n",
      "New theta_0 : [ 0.00632936 -0.08034972  0.11191062  0.02124835  0.09816716 -0.2327373\n",
      "  0.27230763  0.00269699 -0.31962818  0.33609096 -0.23738198 -0.21548384\n",
      "  0.09189123 -0.44450043]\n",
      "Training Error:  10.544003424366569\n",
      "====================================================================================================\n",
      "Iteration:  1090\n",
      "Previous theta :  [ 0.00632936 -0.08034972  0.11191062  0.02124835  0.09816716 -0.2327373\n",
      "  0.27230763  0.00269699 -0.31962818  0.33609096 -0.23738198 -0.21548384\n",
      "  0.09189123 -0.44450043]\n",
      "New theta_0 : [ 0.00632926 -0.08035535  0.11191612  0.02126186  0.09816457 -0.23274316\n",
      "  0.27230224  0.0027007  -0.31963107  0.33613859 -0.23743222 -0.21548671\n",
      "  0.09189049 -0.44450359]\n",
      "Training Error:  10.543998643499075\n",
      "====================================================================================================\n",
      "Iteration:  1091\n",
      "Previous theta :  [ 0.00632926 -0.08035535  0.11191612  0.02126186  0.09816457 -0.23274316\n",
      "  0.27230224  0.0027007  -0.31963107  0.33613859 -0.23743222 -0.21548671\n",
      "  0.09189049 -0.44450359]\n",
      "New theta_0 : [ 0.00632916 -0.08036096  0.11192159  0.02127534  0.09816198 -0.232749\n",
      "  0.27229688  0.00270441 -0.31963393  0.33618609 -0.23748234 -0.21548956\n",
      "  0.09188976 -0.44450676]\n",
      "Training Error:  10.543993888148568\n",
      "====================================================================================================\n",
      "Iteration:  1092\n",
      "Previous theta :  [ 0.00632916 -0.08036096  0.11192159  0.02127534  0.09816198 -0.232749\n",
      "  0.27229688  0.00270441 -0.31963393  0.33618609 -0.23748234 -0.21548956\n",
      "  0.09188976 -0.44450676]\n",
      "New theta_0 : [ 0.00632906 -0.08036656  0.11192704  0.02128878  0.09815941 -0.23275479\n",
      "  0.27229154  0.0027081  -0.31963676  0.33623346 -0.23753232 -0.2154924\n",
      "  0.09188903 -0.44450991]\n",
      "Training Error:  10.543989158175124\n",
      "====================================================================================================\n",
      "Iteration:  1093\n",
      "Previous theta :  [ 0.00632906 -0.08036656  0.11192704  0.02128878  0.09815941 -0.23275479\n",
      "  0.27229154  0.0027081  -0.31963676  0.33623346 -0.23753232 -0.2154924\n",
      "  0.09188903 -0.44450991]\n",
      "New theta_0 : [ 0.00632896 -0.08037213  0.11193248  0.02130219  0.09815684 -0.23276055\n",
      "  0.27228621  0.00271178 -0.31963957  0.33628071 -0.23758218 -0.21549523\n",
      "  0.0918883  -0.44451306]\n",
      "Training Error:  10.543984453439638\n",
      "====================================================================================================\n",
      "Iteration:  1094\n",
      "Previous theta :  [ 0.00632896 -0.08037213  0.11193248  0.02130219  0.09815684 -0.23276055\n",
      "  0.27228621  0.00271178 -0.31963957  0.33628071 -0.23758218 -0.21549523\n",
      "  0.0918883  -0.44451306]\n",
      "New theta_0 : [ 0.00632887 -0.08037768  0.1119379   0.02131556  0.09815428 -0.23276628\n",
      "  0.2722809   0.00271545 -0.31964235  0.33632782 -0.23763192 -0.21549805\n",
      "  0.09188758 -0.4445162 ]\n",
      "Training Error:  10.543979773803814\n",
      "====================================================================================================\n",
      "Iteration:  1095\n",
      "Previous theta :  [ 0.00632887 -0.08037768  0.1119379   0.02131556  0.09815428 -0.23276628\n",
      "  0.2722809   0.00271545 -0.31964235  0.33632782 -0.23763192 -0.21549805\n",
      "  0.09188758 -0.4445162 ]\n",
      "New theta_0 : [ 0.00632877 -0.08038321  0.11194329  0.0213289   0.09815172 -0.23277196\n",
      "  0.27227561  0.00271911 -0.3196451   0.33637481 -0.23768153 -0.21550085\n",
      "  0.09188686 -0.44451934]\n",
      "Training Error:  10.543975119130174\n",
      "====================================================================================================\n",
      "Iteration:  1096\n",
      "Previous theta :  [ 0.00632877 -0.08038321  0.11194329  0.0213289   0.09815172 -0.23277196\n",
      "  0.27227561  0.00271911 -0.3196451   0.33637481 -0.23768153 -0.21550085\n",
      "  0.09188686 -0.44451934]\n",
      "New theta_0 : [ 0.00632867 -0.08038872  0.11194867  0.02134221  0.09814917 -0.23277762\n",
      "  0.27227034  0.00272276 -0.31964783  0.33642167 -0.23773101 -0.21550364\n",
      "  0.09188615 -0.44452247]\n",
      "Training Error:  10.543970489282028\n",
      "====================================================================================================\n",
      "Iteration:  1097\n",
      "Previous theta :  [ 0.00632867 -0.08038872  0.11194867  0.02134221  0.09814917 -0.23277762\n",
      "  0.27227034  0.00272276 -0.31964783  0.33642167 -0.23773101 -0.21550364\n",
      "  0.09188615 -0.44452247]\n",
      "New theta_0 : [ 0.00632858 -0.08039421  0.11195403  0.02135548  0.09814663 -0.23278324\n",
      "  0.27226509  0.0027264  -0.31965053  0.3364684  -0.23778037 -0.21550642\n",
      "  0.09188544 -0.44452559]\n",
      "Training Error:  10.543965884123494\n",
      "====================================================================================================\n",
      "Iteration:  1098\n",
      "Previous theta :  [ 0.00632858 -0.08039421  0.11195403  0.02135548  0.09814663 -0.23278324\n",
      "  0.27226509  0.0027264  -0.31965053  0.3364684  -0.23778037 -0.21550642\n",
      "  0.09188544 -0.44452559]\n",
      "New theta_0 : [ 0.00632848 -0.08039968  0.11195937  0.02136871  0.09814409 -0.23278882\n",
      "  0.27225985  0.00273003 -0.31965321  0.33651501 -0.2378296  -0.21550919\n",
      "  0.09188473 -0.4445287 ]\n",
      "Training Error:  10.543961303519476\n",
      "====================================================================================================\n",
      "Iteration:  1099\n",
      "Previous theta :  [ 0.00632848 -0.08039968  0.11195937  0.02136871  0.09814409 -0.23278882\n",
      "  0.27225985  0.00273003 -0.31965321  0.33651501 -0.2378296  -0.21550919\n",
      "  0.09188473 -0.4445287 ]\n",
      "New theta_0 : [ 0.00632839 -0.08040513  0.11196469  0.02138192  0.09814156 -0.23279437\n",
      "  0.27225464  0.00273364 -0.31965587  0.33656149 -0.23787871 -0.21551194\n",
      "  0.09188403 -0.44453181]\n",
      "Training Error:  10.543956747335661\n",
      "====================================================================================================\n",
      "Iteration:  1100\n",
      "Previous theta :  [ 0.00632839 -0.08040513  0.11196469  0.02138192  0.09814156 -0.23279437\n",
      "  0.27225464  0.00273364 -0.31965587  0.33656149 -0.23787871 -0.21551194\n",
      "  0.09188403 -0.44453181]\n",
      "New theta_0 : [ 0.00632829 -0.08041056  0.11196999  0.02139508  0.09813904 -0.23279989\n",
      "  0.27224944  0.00273725 -0.31965849  0.33660784 -0.23792769 -0.21551469\n",
      "  0.09188333 -0.44453491]\n",
      "Training Error:  10.543952215438525\n",
      "====================================================================================================\n",
      "Iteration:  1101\n",
      "Previous theta :  [ 0.00632829 -0.08041056  0.11196999  0.02139508  0.09813904 -0.23279989\n",
      "  0.27224944  0.00273725 -0.31965849  0.33660784 -0.23792769 -0.21551469\n",
      "  0.09188333 -0.44453491]\n",
      "New theta_0 : [ 0.0063282  -0.08041597  0.11197527  0.02140822  0.09813652 -0.23280537\n",
      "  0.27224425  0.00274084 -0.3196611   0.33665407 -0.23797655 -0.21551742\n",
      "  0.09188263 -0.44453801]\n",
      "Training Error:  10.543947707695311\n",
      "====================================================================================================\n",
      "Iteration:  1102\n",
      "Previous theta :  [ 0.0063282  -0.08041597  0.11197527  0.02140822  0.09813652 -0.23280537\n",
      "  0.27224425  0.00274084 -0.3196611   0.33665407 -0.23797655 -0.21551742\n",
      "  0.09188263 -0.44453801]\n",
      "New theta_0 : [ 0.0063281  -0.08042136  0.11198053  0.02142132  0.09813401 -0.23281081\n",
      "  0.27223909  0.00274443 -0.31966368  0.33670017 -0.23802529 -0.21552014\n",
      "  0.09188194 -0.44454109]\n",
      "Training Error:  10.54394322397404\n",
      "====================================================================================================\n",
      "Iteration:  1103\n",
      "Previous theta :  [ 0.0063281  -0.08042136  0.11198053  0.02142132  0.09813401 -0.23281081\n",
      "  0.27223909  0.00274443 -0.31966368  0.33670017 -0.23802529 -0.21552014\n",
      "  0.09188194 -0.44454109]\n",
      "New theta_0 : [ 0.00632801 -0.08042672  0.11198578  0.02143439  0.09813151 -0.23281623\n",
      "  0.27223395  0.002748   -0.31966623  0.33674615 -0.2380739  -0.21552285\n",
      "  0.09188125 -0.44454417]\n",
      "Training Error:  10.54393876414349\n",
      "====================================================================================================\n",
      "Iteration:  1104\n",
      "Previous theta :  [ 0.00632801 -0.08042672  0.11198578  0.02143439  0.09813151 -0.23281623\n",
      "  0.27223395  0.002748   -0.31966623  0.33674615 -0.2380739  -0.21552285\n",
      "  0.09188125 -0.44454417]\n",
      "New theta_0 : [ 0.00632791 -0.08043207  0.111991    0.02144743  0.09812902 -0.23282161\n",
      "  0.27222882  0.00275156 -0.31966876  0.336792   -0.23812239 -0.21552555\n",
      "  0.09188057 -0.44454725]\n",
      "Training Error:  10.543934328073208\n",
      "====================================================================================================\n",
      "Iteration:  1105\n",
      "Previous theta :  [ 0.00632791 -0.08043207  0.111991    0.02144743  0.09812902 -0.23282161\n",
      "  0.27222882  0.00275156 -0.31966876  0.336792   -0.23812239 -0.21552555\n",
      "  0.09188057 -0.44454725]\n",
      "New theta_0 : [ 0.00632782 -0.0804374   0.11199621  0.02146043  0.09812653 -0.23282696\n",
      "  0.27222371  0.00275512 -0.31967127  0.33683773 -0.23817075 -0.21552823\n",
      "  0.09187989 -0.44455032]\n",
      "Training Error:  10.543929915633491\n",
      "====================================================================================================\n",
      "Iteration:  1106\n",
      "Previous theta :  [ 0.00632782 -0.0804374   0.11199621  0.02146043  0.09812653 -0.23282696\n",
      "  0.27222371  0.00275512 -0.31967127  0.33683773 -0.23817075 -0.21552823\n",
      "  0.09187989 -0.44455032]\n",
      "New theta_0 : [ 0.00632773 -0.08044271  0.1120014   0.0214734   0.09812404 -0.23283227\n",
      "  0.27221861  0.00275866 -0.31967376  0.33688333 -0.23821899 -0.21553091\n",
      "  0.09187921 -0.44455338]\n",
      "Training Error:  10.543925526695391\n",
      "====================================================================================================\n",
      "Iteration:  1107\n",
      "Previous theta :  [ 0.00632773 -0.08044271  0.1120014   0.0214734   0.09812404 -0.23283227\n",
      "  0.27221861  0.00275866 -0.31967376  0.33688333 -0.23821899 -0.21553091\n",
      "  0.09187921 -0.44455338]\n",
      "New theta_0 : [ 0.00632764 -0.080448    0.11200657  0.02148633  0.09812157 -0.23283755\n",
      "  0.27221354  0.00276219 -0.31967622  0.33692881 -0.23826711 -0.21553357\n",
      "  0.09187854 -0.44455643]\n",
      "Training Error:  10.543921161130697\n",
      "====================================================================================================\n",
      "Iteration:  1108\n",
      "Previous theta :  [ 0.00632764 -0.080448    0.11200657  0.02148633  0.09812157 -0.23283755\n",
      "  0.27221354  0.00276219 -0.31967622  0.33692881 -0.23826711 -0.21553357\n",
      "  0.09187854 -0.44455643]\n",
      "New theta_0 : [ 0.00632755 -0.08045327  0.11201172  0.02149923  0.0981191  -0.2328428\n",
      "  0.27220848  0.00276571 -0.31967865  0.33697417 -0.23831511 -0.21553622\n",
      "  0.09187787 -0.44455948]\n",
      "Training Error:  10.543916818811953\n",
      "====================================================================================================\n",
      "Iteration:  1109\n",
      "Previous theta :  [ 0.00632755 -0.08045327  0.11201172  0.02149923  0.0981191  -0.2328428\n",
      "  0.27220848  0.00276571 -0.31967865  0.33697417 -0.23831511 -0.21553622\n",
      "  0.09187787 -0.44455948]\n",
      "New theta_0 : [ 0.00632745 -0.08045853  0.11201686  0.0215121   0.09811663 -0.23284802\n",
      "  0.27220344  0.00276922 -0.31968107  0.3370194  -0.23836299 -0.21553886\n",
      "  0.09187721 -0.44456252]\n",
      "Training Error:  10.543912499612421\n",
      "====================================================================================================\n",
      "Iteration:  1110\n",
      "Previous theta :  [ 0.00632745 -0.08045853  0.11201686  0.0215121   0.09811663 -0.23284802\n",
      "  0.27220344  0.00276922 -0.31968107  0.3370194  -0.23836299 -0.21553886\n",
      "  0.09187721 -0.44456252]\n",
      "New theta_0 : [ 0.00632736 -0.08046376  0.11202197  0.02152494  0.09811418 -0.2328532\n",
      "  0.27219841  0.00277272 -0.31968346  0.33706452 -0.23841074 -0.21554149\n",
      "  0.09187654 -0.44456556]\n",
      "Training Error:  10.543908203406108\n",
      "====================================================================================================\n",
      "Iteration:  1111\n",
      "Previous theta :  [ 0.00632736 -0.08046376  0.11202197  0.02152494  0.09811418 -0.2328532\n",
      "  0.27219841  0.00277272 -0.31968346  0.33706452 -0.23841074 -0.21554149\n",
      "  0.09187654 -0.44456556]\n",
      "New theta_0 : [ 0.00632727 -0.08046897  0.11202707  0.02153774  0.09811173 -0.23285836\n",
      "  0.27219341  0.00277621 -0.31968583  0.3371095  -0.23845837 -0.21554411\n",
      "  0.09187589 -0.44456858]\n",
      "Training Error:  10.543903930067742\n",
      "====================================================================================================\n",
      "Iteration:  1112\n",
      "Previous theta :  [ 0.00632727 -0.08046897  0.11202707  0.02153774  0.09811173 -0.23285836\n",
      "  0.27219341  0.00277621 -0.31968583  0.3371095  -0.23845837 -0.21554411\n",
      "  0.09187589 -0.44456858]\n",
      "New theta_0 : [ 0.00632718 -0.08047417  0.11203215  0.02155051  0.09810928 -0.23286348\n",
      "  0.27218842  0.00277969 -0.31968817  0.33715437 -0.23850589 -0.21554671\n",
      "  0.09187523 -0.44457161]\n",
      "Training Error:  10.543899679472775\n",
      "====================================================================================================\n",
      "Iteration:  1113\n",
      "Previous theta :  [ 0.00632718 -0.08047417  0.11203215  0.02155051  0.09810928 -0.23286348\n",
      "  0.27218842  0.00277969 -0.31968817  0.33715437 -0.23850589 -0.21554671\n",
      "  0.09187523 -0.44457161]\n",
      "New theta_0 : [ 0.00632709 -0.08047934  0.11203721  0.02156325  0.09810685 -0.23286857\n",
      "  0.27218344  0.00278316 -0.3196905   0.33719912 -0.23855328 -0.21554931\n",
      "  0.09187458 -0.44457462]\n",
      "Training Error:  10.54389545149737\n",
      "====================================================================================================\n",
      "Iteration:  1114\n",
      "Previous theta :  [ 0.00632709 -0.08047934  0.11203721  0.02156325  0.09810685 -0.23286857\n",
      "  0.27218344  0.00278316 -0.3196905   0.33719912 -0.23855328 -0.21554931\n",
      "  0.09187458 -0.44457462]\n",
      "New theta_0 : [ 0.006327   -0.0804845   0.11204226  0.02157595  0.09810441 -0.23287363\n",
      "  0.27217849  0.00278662 -0.3196928   0.33724374 -0.23860055 -0.21555189\n",
      "  0.09187393 -0.44457763]\n",
      "Training Error:  10.543891246018411\n",
      "====================================================================================================\n",
      "Iteration:  1115\n",
      "Previous theta :  [ 0.006327   -0.0804845   0.11204226  0.02157595  0.09810441 -0.23287363\n",
      "  0.27217849  0.00278662 -0.3196928   0.33724374 -0.23860055 -0.21555189\n",
      "  0.09187393 -0.44457763]\n",
      "New theta_0 : [ 0.00632691 -0.08048964  0.11204728  0.02158862  0.09810199 -0.23287866\n",
      "  0.27217355  0.00279007 -0.31969508  0.33728825 -0.2386477  -0.21555447\n",
      "  0.09187329 -0.44458063]\n",
      "Training Error:  10.543887062913479\n",
      "====================================================================================================\n",
      "Iteration:  1116\n",
      "Previous theta :  [ 0.00632691 -0.08048964  0.11204728  0.02158862  0.09810199 -0.23287866\n",
      "  0.27217355  0.00279007 -0.31969508  0.33728825 -0.2386477  -0.21555447\n",
      "  0.09187329 -0.44458063]\n",
      "New theta_0 : [ 0.00632683 -0.08049475  0.11205229  0.02160126  0.09809957 -0.23288365\n",
      "  0.27216863  0.00279351 -0.31969734  0.33733263 -0.23869473 -0.21555703\n",
      "  0.09187265 -0.44458362]\n",
      "Training Error:  10.54388290206087\n",
      "====================================================================================================\n",
      "Iteration:  1117\n",
      "Previous theta :  [ 0.00632683 -0.08049475  0.11205229  0.02160126  0.09809957 -0.23288365\n",
      "  0.27216863  0.00279351 -0.31969734  0.33733263 -0.23869473 -0.21555703\n",
      "  0.09187265 -0.44458362]\n",
      "New theta_0 : [ 0.00632674 -0.08049985  0.11205729  0.02161387  0.09809716 -0.23288862\n",
      "  0.27216372  0.00279694 -0.31969957  0.33737689 -0.23874164 -0.21555958\n",
      "  0.09187201 -0.44458661]\n",
      "Training Error:  10.54387876333957\n",
      "====================================================================================================\n",
      "Iteration:  1118\n",
      "Previous theta :  [ 0.00632674 -0.08049985  0.11205729  0.02161387  0.09809716 -0.23288862\n",
      "  0.27216372  0.00279694 -0.31969957  0.33737689 -0.23874164 -0.21555958\n",
      "  0.09187201 -0.44458661]\n",
      "New theta_0 : [ 0.00632665 -0.08050494  0.11206226  0.02162644  0.09809475 -0.23289356\n",
      "  0.27215883  0.00280036 -0.31970179  0.33742103 -0.23878843 -0.21556212\n",
      "  0.09187138 -0.44458959]\n",
      "Training Error:  10.543874646629261\n",
      "====================================================================================================\n",
      "Iteration:  1119\n",
      "Previous theta :  [ 0.00632665 -0.08050494  0.11206226  0.02162644  0.09809475 -0.23289356\n",
      "  0.27215883  0.00280036 -0.31970179  0.33742103 -0.23878843 -0.21556212\n",
      "  0.09187138 -0.44458959]\n",
      "New theta_0 : [ 0.00632656 -0.08051     0.11206722  0.02163899  0.09809236 -0.23289846\n",
      "  0.27215396  0.00280377 -0.31970398  0.33746506 -0.23883511 -0.21556466\n",
      "  0.09187075 -0.44459257]\n",
      "Training Error:  10.543870551810315\n",
      "====================================================================================================\n",
      "Iteration:  1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous theta :  [ 0.00632656 -0.08051     0.11206722  0.02163899  0.09809236 -0.23289846\n",
      "  0.27215396  0.00280377 -0.31970398  0.33746506 -0.23883511 -0.21556466\n",
      "  0.09187075 -0.44459257]\n",
      "New theta_0 : [ 0.00632648 -0.08051504  0.11207216  0.0216515   0.09808996 -0.23290334\n",
      "  0.2721491   0.00280717 -0.31970615  0.33750896 -0.23888166 -0.21556718\n",
      "  0.09187012 -0.44459554]\n",
      "Training Error:  10.54386647876379\n",
      "====================================================================================================\n",
      "Iteration:  1121\n",
      "Previous theta :  [ 0.00632648 -0.08051504  0.11207216  0.0216515   0.09808996 -0.23290334\n",
      "  0.2721491   0.00280717 -0.31970615  0.33750896 -0.23888166 -0.21556718\n",
      "  0.09187012 -0.44459554]\n",
      "New theta_0 : [ 0.00632639 -0.08052007  0.11207708  0.02166397  0.09808758 -0.23290818\n",
      "  0.27214426  0.00281055 -0.3197083   0.33755275 -0.2389281  -0.21556968\n",
      "  0.0918695  -0.4445985 ]\n",
      "Training Error:  10.543862427371426\n",
      "====================================================================================================\n",
      "Iteration:  1122\n",
      "Previous theta :  [ 0.00632639 -0.08052007  0.11207708  0.02166397  0.09808758 -0.23290818\n",
      "  0.27214426  0.00281055 -0.3197083   0.33755275 -0.2389281  -0.21556968\n",
      "  0.0918695  -0.4445985 ]\n",
      "New theta_0 : [ 0.0063263  -0.08052508  0.11208198  0.02167642  0.0980852  -0.232913\n",
      "  0.27213944  0.00281393 -0.31971043  0.33759641 -0.23897442 -0.21557218\n",
      "  0.09186888 -0.44460146]\n",
      "Training Error:  10.543858397515637\n",
      "====================================================================================================\n",
      "Iteration:  1123\n",
      "Previous theta :  [ 0.0063263  -0.08052508  0.11208198  0.02167642  0.0980852  -0.232913\n",
      "  0.27213944  0.00281393 -0.31971043  0.33759641 -0.23897442 -0.21557218\n",
      "  0.09186888 -0.44460146]\n",
      "New theta_0 : [ 0.00632622 -0.08053007  0.11208687  0.02168883  0.09808282 -0.23291779\n",
      "  0.27213463  0.0028173  -0.31971254  0.33763996 -0.23902062 -0.21557467\n",
      "  0.09186826 -0.44460441]\n",
      "Training Error:  10.543854389079508\n",
      "====================================================================================================\n",
      "Iteration:  1124\n",
      "Previous theta :  [ 0.00632622 -0.08053007  0.11208687  0.02168883  0.09808282 -0.23291779\n",
      "  0.27213463  0.0028173  -0.31971254  0.33763996 -0.23902062 -0.21557467\n",
      "  0.09186826 -0.44460441]\n",
      "New theta_0 : [ 0.00632613 -0.08053504  0.11209174  0.02170121  0.09808045 -0.23292255\n",
      "  0.27212984  0.00282066 -0.31971463  0.33768339 -0.2390667  -0.21557715\n",
      "  0.09186765 -0.44460735]\n",
      "Training Error:  10.543850401946793\n",
      "====================================================================================================\n",
      "Iteration:  1125\n",
      "Previous theta :  [ 0.00632613 -0.08053504  0.11209174  0.02170121  0.09808045 -0.23292255\n",
      "  0.27212984  0.00282066 -0.31971463  0.33768339 -0.2390667  -0.21557715\n",
      "  0.09186765 -0.44460735]\n",
      "New theta_0 : [ 0.00632605 -0.08054     0.1120966   0.02171356  0.09807809 -0.23292728\n",
      "  0.27212506  0.00282401 -0.3197167   0.33772671 -0.23911267 -0.21557962\n",
      "  0.09186704 -0.44461028]\n",
      "Training Error:  10.54384643600191\n",
      "====================================================================================================\n",
      "Iteration:  1126\n",
      "Previous theta :  [ 0.00632605 -0.08054     0.1120966   0.02171356  0.09807809 -0.23292728\n",
      "  0.27212506  0.00282401 -0.3197167   0.33772671 -0.23911267 -0.21557962\n",
      "  0.09186704 -0.44461028]\n",
      "New theta_0 : [ 0.00632596 -0.08054493  0.11210143  0.02172588  0.09807574 -0.23293198\n",
      "  0.2721203   0.00282735 -0.31971875  0.3377699  -0.23915851 -0.21558207\n",
      "  0.09186643 -0.44461321]\n",
      "Training Error:  10.543842491129938\n",
      "====================================================================================================\n",
      "Iteration:  1127\n",
      "Previous theta :  [ 0.00632596 -0.08054493  0.11210143  0.02172588  0.09807574 -0.23293198\n",
      "  0.2721203   0.00282735 -0.31971875  0.3377699  -0.23915851 -0.21558207\n",
      "  0.09186643 -0.44461321]\n",
      "New theta_0 : [ 0.00632588 -0.08054985  0.11210625  0.02173817  0.09807339 -0.23293665\n",
      "  0.27211556  0.00283068 -0.31972077  0.33781298 -0.23920425 -0.21558452\n",
      "  0.09186583 -0.44461614]\n",
      "Training Error:  10.543838567216609\n",
      "====================================================================================================\n",
      "Iteration:  1128\n",
      "Previous theta :  [ 0.00632588 -0.08054985  0.11210625  0.02173817  0.09807339 -0.23293665\n",
      "  0.27211556  0.00283068 -0.31972077  0.33781298 -0.23920425 -0.21558452\n",
      "  0.09186583 -0.44461614]\n",
      "New theta_0 : [ 0.00632579 -0.08055475  0.11211106  0.02175042  0.09807105 -0.23294129\n",
      "  0.27211083  0.002834   -0.31972278  0.33785594 -0.23924986 -0.21558696\n",
      "  0.09186523 -0.44461905]\n",
      "Training Error:  10.543834664148307\n",
      "====================================================================================================\n",
      "Iteration:  1129\n",
      "Previous theta :  [ 0.00632579 -0.08055475  0.11211106  0.02175042  0.09807105 -0.23294129\n",
      "  0.27211083  0.002834   -0.31972278  0.33785594 -0.23924986 -0.21558696\n",
      "  0.09186523 -0.44461905]\n",
      "New theta_0 : [ 0.00632571 -0.08055964  0.11211585  0.02176265  0.09806871 -0.2329459\n",
      "  0.27210612  0.00283731 -0.31972477  0.33789879 -0.23929536 -0.21558939\n",
      "  0.09186463 -0.44462197]\n",
      "Training Error:  10.543830781812058\n",
      "====================================================================================================\n",
      "Iteration:  1130\n",
      "Previous theta :  [ 0.00632571 -0.08055964  0.11211585  0.02176265  0.09806871 -0.2329459\n",
      "  0.27210612  0.00283731 -0.31972477  0.33789879 -0.23929536 -0.21558939\n",
      "  0.09186463 -0.44462197]\n",
      "New theta_0 : [ 0.00632563 -0.0805645   0.11212062  0.02177484  0.09806638 -0.23295049\n",
      "  0.27210142  0.00284061 -0.31972674  0.33794152 -0.23934074 -0.2155918\n",
      "  0.09186404 -0.44462487]\n",
      "Training Error:  10.543826920095539\n",
      "====================================================================================================\n",
      "Iteration:  1131\n",
      "Previous theta :  [ 0.00632563 -0.0805645   0.11212062  0.02177484  0.09806638 -0.23295049\n",
      "  0.27210142  0.00284061 -0.31972674  0.33794152 -0.23934074 -0.2155918\n",
      "  0.09186404 -0.44462487]\n",
      "New theta_0 : [ 0.00632554 -0.08056935  0.11212537  0.021787    0.09806405 -0.23295505\n",
      "  0.27209674  0.0028439  -0.31972869  0.33798414 -0.23938601 -0.21559421\n",
      "  0.09186345 -0.44462777]\n",
      "Training Error:  10.543823078887058\n",
      "====================================================================================================\n",
      "Iteration:  1132\n",
      "Previous theta :  [ 0.00632554 -0.08056935  0.11212537  0.021787    0.09806405 -0.23295505\n",
      "  0.27209674  0.0028439  -0.31972869  0.33798414 -0.23938601 -0.21559421\n",
      "  0.09186345 -0.44462777]\n",
      "New theta_0 : [ 0.00632546 -0.08057418  0.11213011  0.02179913  0.09806174 -0.23295958\n",
      "  0.27209208  0.00284718 -0.31973062  0.33802664 -0.23943117 -0.21559661\n",
      "  0.09186286 -0.44463066]\n",
      "Training Error:  10.543819258075565\n",
      "====================================================================================================\n",
      "Iteration:  1133\n",
      "Previous theta :  [ 0.00632546 -0.08057418  0.11213011  0.02179913  0.09806174 -0.23295958\n",
      "  0.27209208  0.00284718 -0.31973062  0.33802664 -0.23943117 -0.21559661\n",
      "  0.09186286 -0.44463066]\n",
      "New theta_0 : [ 0.00632538 -0.080579    0.11213483  0.02181122  0.09805942 -0.23296408\n",
      "  0.27208743  0.00285045 -0.31973253  0.33806902 -0.2394762  -0.21559899\n",
      "  0.09186227 -0.44463354]\n",
      "Training Error:  10.543815457550636\n",
      "====================================================================================================\n",
      "Iteration:  1134\n",
      "Previous theta :  [ 0.00632538 -0.080579    0.11213483  0.02181122  0.09805942 -0.23296408\n",
      "  0.27208743  0.00285045 -0.31973253  0.33806902 -0.2394762  -0.21559899\n",
      "  0.09186227 -0.44463354]\n",
      "New theta_0 : [ 0.0063253  -0.08058379  0.11213953  0.02182329  0.09805712 -0.23296856\n",
      "  0.2720828   0.00285372 -0.31973442  0.33811129 -0.23952113 -0.21560137\n",
      "  0.09186169 -0.44463642]\n",
      "Training Error:  10.54381167720247\n",
      "====================================================================================================\n",
      "Iteration:  1135\n",
      "Previous theta :  [ 0.0063253  -0.08058379  0.11213953  0.02182329  0.09805712 -0.23296856\n",
      "  0.2720828   0.00285372 -0.31973442  0.33811129 -0.23952113 -0.21560137\n",
      "  0.09186169 -0.44463642]\n",
      "New theta_0 : [ 0.00632521 -0.08058857  0.11214422  0.02183533  0.09805482 -0.23297301\n",
      "  0.27207818  0.00285697 -0.3197363   0.33815345 -0.23956593 -0.21560374\n",
      "  0.09186111 -0.44463929]\n",
      "Training Error:  10.543807916921896\n",
      "====================================================================================================\n",
      "Iteration:  1136\n",
      "Previous theta :  [ 0.00632521 -0.08058857  0.11214422  0.02183533  0.09805482 -0.23297301\n",
      "  0.27207818  0.00285697 -0.3197363   0.33815345 -0.23956593 -0.21560374\n",
      "  0.09186111 -0.44463929]\n",
      "New theta_0 : [ 0.00632513 -0.08059334  0.1121489   0.02184733  0.09805252 -0.23297743\n",
      "  0.27207358  0.00286021 -0.31973815  0.33819549 -0.23961063 -0.21560609\n",
      "  0.09186054 -0.44464216]\n",
      "Training Error:  10.54380417660036\n",
      "====================================================================================================\n",
      "Iteration:  1137\n",
      "Previous theta :  [ 0.00632513 -0.08059334  0.1121489   0.02184733  0.09805252 -0.23297743\n",
      "  0.27207358  0.00286021 -0.31973815  0.33819549 -0.23961063 -0.21560609\n",
      "  0.09186054 -0.44464216]\n",
      "New theta_0 : [ 0.00632505 -0.08059808  0.11215355  0.0218593   0.09805024 -0.23298183\n",
      "  0.27206899  0.00286345 -0.31973999  0.33823742 -0.23965521 -0.21560844\n",
      "  0.09185997 -0.44464502]\n",
      "Training Error:  10.543800456129919\n",
      "====================================================================================================\n",
      "Iteration:  1138\n",
      "Previous theta :  [ 0.00632505 -0.08059808  0.11215355  0.0218593   0.09805024 -0.23298183\n",
      "  0.27206899  0.00286345 -0.31973999  0.33823742 -0.23965521 -0.21560844\n",
      "  0.09185997 -0.44464502]\n",
      "New theta_0 : [ 0.00632497 -0.08060281  0.11215819  0.02187125  0.09804795 -0.23298619\n",
      "  0.27206442  0.00286667 -0.31974181  0.33827924 -0.23969967 -0.21561078\n",
      "  0.0918594  -0.44464787]\n",
      "Training Error:  10.543796755403244\n",
      "====================================================================================================\n",
      "Iteration:  1139\n",
      "Previous theta :  [ 0.00632497 -0.08060281  0.11215819  0.02187125  0.09804795 -0.23298619\n",
      "  0.27206442  0.00286667 -0.31974181  0.33827924 -0.23969967 -0.21561078\n",
      "  0.0918594  -0.44464787]\n",
      "New theta_0 : [ 0.00632489 -0.08060752  0.11216282  0.02188316  0.09804568 -0.23299054\n",
      "  0.27205986  0.00286989 -0.31974361  0.33832094 -0.23974403 -0.2156131\n",
      "  0.09185883 -0.44465072]\n",
      "Training Error:  10.543793074313616\n",
      "====================================================================================================\n",
      "Iteration:  1140\n",
      "Previous theta :  [ 0.00632489 -0.08060752  0.11216282  0.02188316  0.09804568 -0.23299054\n",
      "  0.27205986  0.00286989 -0.31974361  0.33832094 -0.23974403 -0.2156131\n",
      "  0.09185883 -0.44465072]\n",
      "New theta_0 : [ 0.00632481 -0.08061222  0.11216743  0.02189504  0.09804341 -0.23299485\n",
      "  0.27205532  0.00287309 -0.31974539  0.33836253 -0.23978827 -0.21561542\n",
      "  0.09185827 -0.44465356]\n",
      "Training Error:  10.543789412754913\n",
      "====================================================================================================\n",
      "Iteration:  1141\n",
      "Previous theta :  [ 0.00632481 -0.08061222  0.11216743  0.02189504  0.09804341 -0.23299485\n",
      "  0.27205532  0.00287309 -0.31974539  0.33836253 -0.23978827 -0.21561542\n",
      "  0.09185827 -0.44465356]\n",
      "New theta_0 : [ 0.00632473 -0.0806169   0.11217202  0.02190689  0.09804114 -0.23299914\n",
      "  0.27205079  0.00287629 -0.31974715  0.33840401 -0.2398324  -0.21561773\n",
      "  0.09185771 -0.44465639]\n",
      "Training Error:  10.543785770621616\n",
      "====================================================================================================\n",
      "Iteration:  1142\n",
      "Previous theta :  [ 0.00632473 -0.0806169   0.11217202  0.02190689  0.09804114 -0.23299914\n",
      "  0.27205079  0.00287629 -0.31974715  0.33840401 -0.2398324  -0.21561773\n",
      "  0.09185771 -0.44465639]\n",
      "New theta_0 : [ 0.00632465 -0.08062156  0.1121766   0.02191871  0.09803889 -0.2330034\n",
      "  0.27204628  0.00287947 -0.3197489   0.33844538 -0.23987641 -0.21562003\n",
      "  0.09185715 -0.44465922]\n",
      "Training Error:  10.543782147808804\n",
      "====================================================================================================\n",
      "Iteration:  1143\n",
      "Previous theta :  [ 0.00632465 -0.08062156  0.1121766   0.02191871  0.09803889 -0.2330034\n",
      "  0.27204628  0.00287947 -0.3197489   0.33844538 -0.23987641 -0.21562003\n",
      "  0.09185715 -0.44465922]\n",
      "New theta_0 : [ 0.00632457 -0.0806262   0.11218116  0.0219305   0.09803663 -0.23300764\n",
      "  0.27204178  0.00288265 -0.31975063  0.33848663 -0.23992031 -0.21562232\n",
      "  0.0918566  -0.44466204]\n",
      "Training Error:  10.543778544212142\n",
      "====================================================================================================\n",
      "Iteration:  1144\n",
      "Previous theta :  [ 0.00632457 -0.0806262   0.11218116  0.0219305   0.09803663 -0.23300764\n",
      "  0.27204178  0.00288265 -0.31975063  0.33848663 -0.23992031 -0.21562232\n",
      "  0.0918566  -0.44466204]\n",
      "New theta_0 : [ 0.0063245  -0.08063083  0.11218571  0.02194226  0.09803439 -0.23301185\n",
      "  0.2720373   0.00288582 -0.31975234  0.33852778 -0.2399641  -0.2156246\n",
      "  0.09185604 -0.44466485]\n",
      "Training Error:  10.54377495972789\n",
      "====================================================================================================\n",
      "Iteration:  1145\n",
      "Previous theta :  [ 0.0063245  -0.08063083  0.11218571  0.02194226  0.09803439 -0.23301185\n",
      "  0.2720373   0.00288582 -0.31975234  0.33852778 -0.2399641  -0.2156246\n",
      "  0.09185604 -0.44466485]\n",
      "New theta_0 : [ 0.00632442 -0.08063544  0.11219024  0.02195398  0.09803215 -0.23301604\n",
      "  0.27203283  0.00288898 -0.31975403  0.33856881 -0.24000778 -0.21562687\n",
      "  0.0918555  -0.44466766]\n",
      "Training Error:  10.543771394252891\n",
      "====================================================================================================\n",
      "Iteration:  1146\n",
      "Previous theta :  [ 0.00632442 -0.08063544  0.11219024  0.02195398  0.09803215 -0.23301604\n",
      "  0.27203283  0.00288898 -0.31975403  0.33856881 -0.24000778 -0.21562687\n",
      "  0.0918555  -0.44466766]\n",
      "New theta_0 : [ 0.00632434 -0.08064004  0.11219475  0.02196568  0.09802991 -0.2330202\n",
      "  0.27202838  0.00289213 -0.31975571  0.33860973 -0.24005135 -0.21562913\n",
      "  0.09185495 -0.44467046]\n",
      "Training Error:  10.543767847684569\n",
      "====================================================================================================\n",
      "Iteration:  1147\n",
      "Previous theta :  [ 0.00632434 -0.08064004  0.11219475  0.02196568  0.09802991 -0.2330202\n",
      "  0.27202838  0.00289213 -0.31975571  0.33860973 -0.24005135 -0.21562913\n",
      "  0.09185495 -0.44467046]\n",
      "New theta_0 : [ 0.00632426 -0.08064462  0.11219925  0.02197735  0.09802768 -0.23302434\n",
      "  0.27202394  0.00289527 -0.31975737  0.33865054 -0.24009481 -0.21563139\n",
      "  0.09185441 -0.44467326]\n",
      "Training Error:  10.543764319920921\n",
      "====================================================================================================\n",
      "Iteration:  1148\n",
      "Previous theta :  [ 0.00632426 -0.08064462  0.11219925  0.02197735  0.09802768 -0.23302434\n",
      "  0.27202394  0.00289527 -0.31975737  0.33865054 -0.24009481 -0.21563139\n",
      "  0.09185441 -0.44467326]\n",
      "New theta_0 : [ 0.00632419 -0.08064918  0.11220374  0.02198899  0.09802546 -0.23302845\n",
      "  0.27201952  0.0028984  -0.31975901  0.33869124 -0.24013815 -0.21563363\n",
      "  0.09185387 -0.44467605]\n",
      "Training Error:  10.543760810860526\n",
      "====================================================================================================\n",
      "Iteration:  1149\n",
      "Previous theta :  [ 0.00632419 -0.08064918  0.11220374  0.02198899  0.09802546 -0.23302845\n",
      "  0.27201952  0.0028984  -0.31975901  0.33869124 -0.24013815 -0.21563363\n",
      "  0.09185387 -0.44467605]\n",
      "New theta_0 : [ 0.00632411 -0.08065373  0.11220821  0.02200059  0.09802325 -0.23303253\n",
      "  0.27201511  0.00290152 -0.31976064  0.33873183 -0.24018139 -0.21563586\n",
      "  0.09185333 -0.44467883]\n",
      "Training Error:  10.543757320402529\n",
      "====================================================================================================\n",
      "Iteration:  1150\n",
      "Previous theta :  [ 0.00632411 -0.08065373  0.11220821  0.02200059  0.09802325 -0.23303253\n",
      "  0.27201511  0.00290152 -0.31976064  0.33873183 -0.24018139 -0.21563586\n",
      "  0.09185333 -0.44467883]\n",
      "New theta_0 : [ 0.00632403 -0.08065826  0.11221266  0.02201217  0.09802103 -0.2330366\n",
      "  0.27201071  0.00290464 -0.31976225  0.33877232 -0.24022451 -0.21563809\n",
      "  0.0918528  -0.44468161]\n",
      "Training Error:  10.543753848446642\n",
      "====================================================================================================\n",
      "Iteration:  1151\n",
      "Previous theta :  [ 0.00632403 -0.08065826  0.11221266  0.02201217  0.09802103 -0.2330366\n",
      "  0.27201071  0.00290464 -0.31976225  0.33877232 -0.24022451 -0.21563809\n",
      "  0.0918528  -0.44468161]\n",
      "New theta_0 : [ 0.00632396 -0.08066278  0.1122171   0.02202372  0.09801883 -0.23304063\n",
      "  0.27200633  0.00290774 -0.31976384  0.33881269 -0.24026752 -0.2156403\n",
      "  0.09185226 -0.44468438]\n",
      "Training Error:  10.543750394893138\n",
      "====================================================================================================\n",
      "Iteration:  1152\n",
      "Previous theta :  [ 0.00632396 -0.08066278  0.1122171   0.02202372  0.09801883 -0.23304063\n",
      "  0.27200633  0.00290774 -0.31976384  0.33881269 -0.24026752 -0.2156403\n",
      "  0.09185226 -0.44468438]\n",
      "New theta_0 : [ 0.00632388 -0.08066728  0.11222153  0.02203524  0.09801663 -0.23304465\n",
      "  0.27200197  0.00291084 -0.31976541  0.33885295 -0.24031043 -0.21564251\n",
      "  0.09185174 -0.44468715]\n",
      "Training Error:  10.54374695964286\n",
      "====================================================================================================\n",
      "Iteration:  1153\n",
      "Previous theta :  [ 0.00632388 -0.08066728  0.11222153  0.02203524  0.09801663 -0.23304465\n",
      "  0.27200197  0.00291084 -0.31976541  0.33885295 -0.24031043 -0.21564251\n",
      "  0.09185174 -0.44468715]\n",
      "New theta_0 : [ 0.0063238  -0.08067176  0.11222594  0.02204672  0.09801444 -0.23304864\n",
      "  0.27199761  0.00291392 -0.31976697  0.33889311 -0.24035322 -0.21564471\n",
      "  0.09185121 -0.4446899 ]\n",
      "Training Error:  10.543743542597193\n",
      "====================================================================================================\n",
      "Iteration:  1154\n",
      "Previous theta :  [ 0.0063238  -0.08067176  0.11222594  0.02204672  0.09801444 -0.23304864\n",
      "  0.27199761  0.00291392 -0.31976697  0.33889311 -0.24035322 -0.21564471\n",
      "  0.09185121 -0.4446899 ]\n",
      "New theta_0 : [ 0.00632373 -0.08067623  0.11223033  0.02205818  0.09801225 -0.2330526\n",
      "  0.27199328  0.002917   -0.31976852  0.33893316 -0.24039591 -0.2156469\n",
      "  0.09185069 -0.44469266]\n",
      "Training Error:  10.543740143658088\n",
      "====================================================================================================\n",
      "Iteration:  1155\n",
      "Previous theta :  [ 0.00632373 -0.08067623  0.11223033  0.02205818  0.09801225 -0.2330526\n",
      "  0.27199328  0.002917   -0.31976852  0.33893316 -0.24039591 -0.2156469\n",
      "  0.09185069 -0.44469266]\n",
      "New theta_0 : [ 0.00632365 -0.08068068  0.11223471  0.02206961  0.09801007 -0.23305654\n",
      "  0.27198895  0.00292007 -0.31977005  0.3389731  -0.24043849 -0.21564908\n",
      "  0.09185017 -0.4446954 ]\n",
      "Training Error:  10.543736762728036\n",
      "====================================================================================================\n",
      "Iteration:  1156\n",
      "Previous theta :  [ 0.00632365 -0.08068068  0.11223471  0.02206961  0.09801007 -0.23305654\n",
      "  0.27198895  0.00292007 -0.31977005  0.3389731  -0.24043849 -0.21564908\n",
      "  0.09185017 -0.4446954 ]\n",
      "New theta_0 : [ 0.00632358 -0.08068512  0.11223907  0.02208101  0.09800789 -0.23306046\n",
      "  0.27198464  0.00292313 -0.31977156  0.33901293 -0.24048095 -0.21565125\n",
      "  0.09184965 -0.44469814]\n",
      "Training Error:  10.543733399710083\n",
      "====================================================================================================\n",
      "Iteration:  1157\n",
      "Previous theta :  [ 0.00632358 -0.08068512  0.11223907  0.02208101  0.09800789 -0.23306046\n",
      "  0.27198464  0.00292313 -0.31977156  0.33901293 -0.24048095 -0.21565125\n",
      "  0.09184965 -0.44469814]\n",
      "New theta_0 : [ 0.00632351 -0.08068954  0.11224342  0.02209238  0.09800572 -0.23306435\n",
      "  0.27198035  0.00292618 -0.31977305  0.33905265 -0.24052331 -0.21565341\n",
      "  0.09184913 -0.44470088]\n",
      "Training Error:  10.54373005450781\n",
      "====================================================================================================\n",
      "Iteration:  1158\n",
      "Previous theta :  [ 0.00632351 -0.08068954  0.11224342  0.02209238  0.09800572 -0.23306435\n",
      "  0.27198035  0.00292618 -0.31977305  0.33905265 -0.24052331 -0.21565341\n",
      "  0.09184913 -0.44470088]\n",
      "New theta_0 : [ 0.00632343 -0.08069395  0.11224776  0.02210372  0.09800356 -0.23306822\n",
      "  0.27197607  0.00292922 -0.31977453  0.33909227 -0.24056556 -0.21565556\n",
      "  0.09184862 -0.4447036 ]\n",
      "Training Error:  10.543726727025344\n",
      "====================================================================================================\n",
      "Iteration:  1159\n",
      "Previous theta :  [ 0.00632343 -0.08069395  0.11224776  0.02210372  0.09800356 -0.23306822\n",
      "  0.27197607  0.00292922 -0.31977453  0.33909227 -0.24056556 -0.21565556\n",
      "  0.09184862 -0.4447036 ]\n",
      "New theta_0 : [ 0.00632336 -0.08069834  0.11225208  0.02211503  0.0980014  -0.23307207\n",
      "  0.2719718   0.00293225 -0.319776    0.33913178 -0.24060771 -0.21565771\n",
      "  0.09184811 -0.44470633]\n",
      "Training Error:  10.543723417167342\n",
      "====================================================================================================\n",
      "Iteration:  1160\n",
      "Previous theta :  [ 0.00632336 -0.08069834  0.11225208  0.02211503  0.0980014  -0.23307207\n",
      "  0.2719718   0.00293225 -0.319776    0.33913178 -0.24060771 -0.21565771\n",
      "  0.09184811 -0.44470633]\n",
      "New theta_0 : [ 0.00632328 -0.08070272  0.11225639  0.02212631  0.09799924 -0.23307589\n",
      "  0.27196755  0.00293528 -0.31977745  0.33917118 -0.24064974 -0.21565985\n",
      "  0.0918476  -0.44470904]\n",
      "Training Error:  10.543720124839002\n",
      "====================================================================================================\n",
      "Iteration:  1161\n",
      "Previous theta :  [ 0.00632328 -0.08070272  0.11225639  0.02212631  0.09799924 -0.23307589\n",
      "  0.27196755  0.00293528 -0.31977745  0.33917118 -0.24064974 -0.21565985\n",
      "  0.0918476  -0.44470904]\n",
      "New theta_0 : [ 0.00632321 -0.08070708  0.11226068  0.02213756  0.0979971  -0.2330797\n",
      "  0.27196331  0.00293829 -0.31977888  0.33921048 -0.24069167 -0.21566197\n",
      "  0.0918471  -0.44471175]\n",
      "Training Error:  10.543716849946046\n",
      "====================================================================================================\n",
      "Iteration:  1162\n",
      "Previous theta :  [ 0.00632321 -0.08070708  0.11226068  0.02213756  0.0979971  -0.2330797\n",
      "  0.27196331  0.00293829 -0.31977888  0.33921048 -0.24069167 -0.21566197\n",
      "  0.0918471  -0.44471175]\n",
      "New theta_0 : [ 0.00632314 -0.08071142  0.11226496  0.02214878  0.09799495 -0.23308347\n",
      "  0.27195908  0.0029413  -0.3197803   0.33924967 -0.24073349 -0.21566409\n",
      "  0.0918466  -0.44471445]\n",
      "Training Error:  10.543713592394722\n",
      "====================================================================================================\n",
      "Iteration:  1163\n",
      "Previous theta :  [ 0.00632314 -0.08071142  0.11226496  0.02214878  0.09799495 -0.23308347\n",
      "  0.27195908  0.0029413  -0.3197803   0.33924967 -0.24073349 -0.21566409\n",
      "  0.0918466  -0.44471445]\n",
      "New theta_0 : [ 0.00632307 -0.08071575  0.11226922  0.02215998  0.09799282 -0.23308723\n",
      "  0.27195487  0.0029443  -0.31978171  0.33928876 -0.2407752  -0.2156662\n",
      "  0.0918461  -0.44471715]\n",
      "Training Error:  10.543710352091805\n",
      "====================================================================================================\n",
      "Iteration:  1164\n",
      "Previous theta :  [ 0.00632307 -0.08071575  0.11226922  0.02215998  0.09799282 -0.23308723\n",
      "  0.27195487  0.0029443  -0.31978171  0.33928876 -0.2407752  -0.2156662\n",
      "  0.0918461  -0.44471715]\n",
      "New theta_0 : [ 0.00632299 -0.08072007  0.11227347  0.02217114  0.09799069 -0.23309096\n",
      "  0.27195067  0.00294729 -0.3197831   0.33932774 -0.24081681 -0.2156683\n",
      "  0.0918456  -0.44471984]\n",
      "Training Error:  10.54370712894459\n",
      "====================================================================================================\n",
      "Iteration:  1165\n",
      "Previous theta :  [ 0.00632299 -0.08072007  0.11227347  0.02217114  0.09799069 -0.23309096\n",
      "  0.27195067  0.00294729 -0.3197831   0.33932774 -0.24081681 -0.2156683\n",
      "  0.0918456  -0.44471984]\n",
      "New theta_0 : [ 0.00632292 -0.08072437  0.1122777   0.02218228  0.09798856 -0.23309467\n",
      "  0.27194649  0.00295027 -0.31978447  0.33936662 -0.24085831 -0.2156704\n",
      "  0.09184511 -0.44472253]\n",
      "Training Error:  10.543703922860885\n",
      "====================================================================================================\n",
      "Iteration:  1166\n",
      "Previous theta :  [ 0.00632292 -0.08072437  0.1122777   0.02218228  0.09798856 -0.23309467\n",
      "  0.27194649  0.00295027 -0.31978447  0.33936662 -0.24085831 -0.2156704\n",
      "  0.09184511 -0.44472253]\n",
      "New theta_0 : [ 0.00632285 -0.08072865  0.11228192  0.02219339  0.09798644 -0.23309836\n",
      "  0.27194232  0.00295324 -0.31978583  0.33940539 -0.2408997  -0.21567248\n",
      "  0.09184462 -0.4447252 ]\n",
      "Training Error:  10.543700733749018\n",
      "====================================================================================================\n",
      "Iteration:  1167\n",
      "Previous theta :  [ 0.00632285 -0.08072865  0.11228192  0.02219339  0.09798644 -0.23309836\n",
      "  0.27194232  0.00295324 -0.31978583  0.33940539 -0.2408997  -0.21567248\n",
      "  0.09184462 -0.4447252 ]\n",
      "New theta_0 : [ 0.00632278 -0.08073292  0.11228613  0.02220446  0.09798433 -0.23310203\n",
      "  0.27193816  0.00295621 -0.31978718  0.33944406 -0.24094099 -0.21567456\n",
      "  0.09184413 -0.44472788]\n",
      "Training Error:  10.543697561517822\n",
      "====================================================================================================\n",
      "Iteration:  1168\n",
      "Previous theta :  [ 0.00632278 -0.08073292  0.11228613  0.02220446  0.09798433 -0.23310203\n",
      "  0.27193816  0.00295621 -0.31978718  0.33944406 -0.24094099 -0.21567456\n",
      "  0.09184413 -0.44472788]\n",
      "New theta_0 : [ 0.00632271 -0.08073718  0.11229032  0.02221551  0.09798222 -0.23310567\n",
      "  0.27193402  0.00295916 -0.31978851  0.33948262 -0.24098217 -0.21567663\n",
      "  0.09184364 -0.44473054]\n",
      "Training Error:  10.543694406076643\n",
      "====================================================================================================\n",
      "Iteration:  1169\n",
      "Previous theta :  [ 0.00632271 -0.08073718  0.11229032  0.02221551  0.09798222 -0.23310567\n",
      "  0.27193402  0.00295916 -0.31978851  0.33948262 -0.24098217 -0.21567663\n",
      "  0.09184364 -0.44473054]\n",
      "New theta_0 : [ 0.00632264 -0.08074142  0.1122945   0.02222653  0.09798012 -0.2331093\n",
      "  0.27192989  0.00296211 -0.31978982  0.33952108 -0.24102325 -0.21567869\n",
      "  0.09184316 -0.4447332 ]\n",
      "Training Error:  10.543691267335324\n",
      "====================================================================================================\n",
      "Iteration:  1170\n",
      "Previous theta :  [ 0.00632264 -0.08074142  0.1122945   0.02222653  0.09798012 -0.2331093\n",
      "  0.27192989  0.00296211 -0.31978982  0.33952108 -0.24102325 -0.21567869\n",
      "  0.09184316 -0.4447332 ]\n",
      "New theta_0 : [ 0.00632257 -0.08074564  0.11229866  0.02223753  0.09797802 -0.2331129\n",
      "  0.27192577  0.00296505 -0.31979113  0.33955944 -0.24106422 -0.21568074\n",
      "  0.09184267 -0.44473586]\n",
      "Training Error:  10.54368814520422\n",
      "====================================================================================================\n",
      "Iteration:  1171\n",
      "Previous theta :  [ 0.00632257 -0.08074564  0.11229866  0.02223753  0.09797802 -0.2331129\n",
      "  0.27192577  0.00296505 -0.31979113  0.33955944 -0.24106422 -0.21568074\n",
      "  0.09184267 -0.44473586]\n",
      "New theta_0 : [ 0.0063225  -0.08074985  0.11230281  0.02224849  0.09797593 -0.23311648\n",
      "  0.27192166  0.00296798 -0.31979242  0.33959769 -0.24110509 -0.21568278\n",
      "  0.0918422  -0.44473851]\n",
      "Training Error:  10.543685039594173\n",
      "====================================================================================================\n",
      "Iteration:  1172\n",
      "Previous theta :  [ 0.0063225  -0.08074985  0.11230281  0.02224849  0.09797593 -0.23311648\n",
      "  0.27192166  0.00296798 -0.31979242  0.33959769 -0.24110509 -0.21568278\n",
      "  0.0918422  -0.44473851]\n",
      "New theta_0 : [ 0.00632243 -0.08075405  0.11230695  0.02225942  0.09797384 -0.23312004\n",
      "  0.27191757  0.0029709  -0.31979369  0.33963584 -0.24114585 -0.21568482\n",
      "  0.09184172 -0.44474115]\n",
      "Training Error:  10.543681950416532\n",
      "====================================================================================================\n",
      "Iteration:  1173\n",
      "Previous theta :  [ 0.00632243 -0.08075405  0.11230695  0.02225942  0.09797384 -0.23312004\n",
      "  0.27191757  0.0029709  -0.31979369  0.33963584 -0.24114585 -0.21568482\n",
      "  0.09184172 -0.44474115]\n",
      "New theta_0 : [ 0.00632236 -0.08075823  0.11231107  0.02227033  0.09797176 -0.23312357\n",
      "  0.2719135   0.00297381 -0.31979495  0.33967389 -0.24118651 -0.21568685\n",
      "  0.09184124 -0.44474379]\n",
      "Training Error:  10.543678877583131\n",
      "====================================================================================================\n",
      "Iteration:  1174\n",
      "Previous theta :  [ 0.00632236 -0.08075823  0.11231107  0.02227033  0.09797176 -0.23312357\n",
      "  0.2719135   0.00297381 -0.31979495  0.33967389 -0.24118651 -0.21568685\n",
      "  0.09184124 -0.44474379]\n",
      "New theta_0 : [ 0.00632229 -0.0807624   0.11231518  0.02228121  0.09796969 -0.23312709\n",
      "  0.27190943  0.00297671 -0.3197962   0.33971184 -0.24122707 -0.21568886\n",
      "  0.09184077 -0.44474642]\n",
      "Training Error:  10.543675821006294\n",
      "====================================================================================================\n",
      "Iteration:  1175\n",
      "Previous theta :  [ 0.00632229 -0.0807624   0.11231518  0.02228121  0.09796969 -0.23312709\n",
      "  0.27190943  0.00297671 -0.3197962   0.33971184 -0.24122707 -0.21568886\n",
      "  0.09184077 -0.44474642]\n",
      "New theta_0 : [ 0.00632222 -0.08076655  0.11231928  0.02229206  0.09796762 -0.23313059\n",
      "  0.27190538  0.00297961 -0.31979743  0.33974968 -0.24126752 -0.21569088\n",
      "  0.0918403  -0.44474904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.543672780598834\n",
      "====================================================================================================\n",
      "Iteration:  1176\n",
      "Previous theta :  [ 0.00632222 -0.08076655  0.11231928  0.02229206  0.09796762 -0.23313059\n",
      "  0.27190538  0.00297961 -0.31979743  0.33974968 -0.24126752 -0.21569088\n",
      "  0.0918403  -0.44474904]\n",
      "New theta_0 : [ 0.00632215 -0.08077069  0.11232336  0.02230288  0.09796555 -0.23313406\n",
      "  0.27190134  0.0029825  -0.31979865  0.33978742 -0.24130786 -0.21569288\n",
      "  0.09183984 -0.44475166]\n",
      "Training Error:  10.543669756274051\n",
      "====================================================================================================\n",
      "Iteration:  1177\n",
      "Previous theta :  [ 0.00632215 -0.08077069  0.11232336  0.02230288  0.09796555 -0.23313406\n",
      "  0.27190134  0.0029825  -0.31979865  0.33978742 -0.24130786 -0.21569288\n",
      "  0.09183984 -0.44475166]\n",
      "New theta_0 : [ 0.00632208 -0.08077482  0.11232743  0.02231368  0.09796349 -0.23313751\n",
      "  0.27189732  0.00298538 -0.31979986  0.33982506 -0.24134811 -0.21569487\n",
      "  0.09183937 -0.44475427]\n",
      "Training Error:  10.543666747945718\n",
      "====================================================================================================\n",
      "Iteration:  1178\n",
      "Previous theta :  [ 0.00632208 -0.08077482  0.11232743  0.02231368  0.09796349 -0.23313751\n",
      "  0.27189732  0.00298538 -0.31979986  0.33982506 -0.24134811 -0.21569487\n",
      "  0.09183937 -0.44475427]\n",
      "New theta_0 : [ 0.00632202 -0.08077893  0.11233148  0.02232444  0.09796144 -0.23314095\n",
      "  0.2718933   0.00298825 -0.31980105  0.3398626  -0.24138825 -0.21569686\n",
      "  0.09183891 -0.44475688]\n",
      "Training Error:  10.543663755528089\n",
      "====================================================================================================\n",
      "Iteration:  1179\n",
      "Previous theta :  [ 0.00632202 -0.08077893  0.11233148  0.02232444  0.09796144 -0.23314095\n",
      "  0.2718933   0.00298825 -0.31980105  0.3398626  -0.24138825 -0.21569686\n",
      "  0.09183891 -0.44475688]\n",
      "New theta_0 : [ 0.00632195 -0.08078303  0.11233553  0.02233518  0.09795939 -0.23314436\n",
      "  0.27188931  0.00299111 -0.31980223  0.33990004 -0.24142829 -0.21569884\n",
      "  0.09183845 -0.44475948]\n",
      "Training Error:  10.543660778935896\n",
      "====================================================================================================\n",
      "Iteration:  1180\n",
      "Previous theta :  [ 0.00632195 -0.08078303  0.11233553  0.02233518  0.09795939 -0.23314436\n",
      "  0.27188931  0.00299111 -0.31980223  0.33990004 -0.24142829 -0.21569884\n",
      "  0.09183845 -0.44475948]\n",
      "New theta_0 : [ 0.00632188 -0.08078711  0.11233955  0.02234589  0.09795735 -0.23314775\n",
      "  0.27188532  0.00299397 -0.3198034   0.33993738 -0.24146822 -0.21570081\n",
      "  0.09183799 -0.44476207]\n",
      "Training Error:  10.543657818084341\n",
      "====================================================================================================\n",
      "Iteration:  1181\n",
      "Previous theta :  [ 0.00632188 -0.08078711  0.11233955  0.02234589  0.09795735 -0.23314775\n",
      "  0.27188532  0.00299397 -0.3198034   0.33993738 -0.24146822 -0.21570081\n",
      "  0.09183799 -0.44476207]\n",
      "New theta_0 : [ 0.00632181 -0.08079118  0.11234357  0.02235657  0.09795531 -0.23315113\n",
      "  0.27188134  0.00299681 -0.31980455  0.33997461 -0.24150805 -0.21570278\n",
      "  0.09183754 -0.44476466]\n",
      "Training Error:  10.543654872889094\n",
      "====================================================================================================\n",
      "Iteration:  1182\n",
      "Previous theta :  [ 0.00632181 -0.08079118  0.11234357  0.02235657  0.09795531 -0.23315113\n",
      "  0.27188134  0.00299681 -0.31980455  0.33997461 -0.24150805 -0.21570278\n",
      "  0.09183754 -0.44476466]\n",
      "New theta_0 : [ 0.00632175 -0.08079523  0.11234757  0.02236723  0.09795328 -0.23315448\n",
      "  0.27187738  0.00299965 -0.31980569  0.34001175 -0.24154778 -0.21570473\n",
      "  0.09183708 -0.44476724]\n",
      "Training Error:  10.543651943266296\n",
      "====================================================================================================\n",
      "Iteration:  1183\n",
      "Previous theta :  [ 0.00632175 -0.08079523  0.11234757  0.02236723  0.09795328 -0.23315448\n",
      "  0.27187738  0.00299965 -0.31980569  0.34001175 -0.24154778 -0.21570473\n",
      "  0.09183708 -0.44476724]\n",
      "New theta_0 : [ 0.00632168 -0.08079927  0.11235156  0.02237785  0.09795125 -0.23315781\n",
      "  0.27187343  0.00300248 -0.31980682  0.34004879 -0.24158741 -0.21570668\n",
      "  0.09183663 -0.44476982]\n",
      "Training Error:  10.543649029132547\n",
      "====================================================================================================\n",
      "Iteration:  1184\n",
      "Previous theta :  [ 0.00632168 -0.08079927  0.11235156  0.02237785  0.09795125 -0.23315781\n",
      "  0.27187343  0.00300248 -0.31980682  0.34004879 -0.24158741 -0.21570668\n",
      "  0.09183663 -0.44476982]\n",
      "New theta_0 : [ 0.00632161 -0.0808033   0.11235554  0.02238845  0.09794923 -0.23316112\n",
      "  0.2718695   0.0030053  -0.31980794  0.34008573 -0.24162694 -0.21570862\n",
      "  0.09183619 -0.44477239]\n",
      "Training Error:  10.543646130404912\n",
      "====================================================================================================\n",
      "Iteration:  1185\n",
      "Previous theta :  [ 0.00632161 -0.0808033   0.11235554  0.02238845  0.09794923 -0.23316112\n",
      "  0.2718695   0.0030053  -0.31980794  0.34008573 -0.24162694 -0.21570862\n",
      "  0.09183619 -0.44477239]\n",
      "New theta_0 : [ 0.00632155 -0.08080732  0.1123595   0.02239902  0.09794721 -0.23316442\n",
      "  0.27186558  0.00300812 -0.31980904  0.34012256 -0.24166637 -0.21571055\n",
      "  0.09183574 -0.44477496]\n",
      "Training Error:  10.543643247000908\n",
      "====================================================================================================\n",
      "Iteration:  1186\n",
      "Previous theta :  [ 0.00632155 -0.08080732  0.1123595   0.02239902  0.09794721 -0.23316442\n",
      "  0.27186558  0.00300812 -0.31980904  0.34012256 -0.24166637 -0.21571055\n",
      "  0.09183574 -0.44477496]\n",
      "New theta_0 : [ 0.00632148 -0.08081132  0.11236345  0.02240957  0.0979452  -0.23316769\n",
      "  0.27186166  0.00301092 -0.31981013  0.3401593  -0.24170569 -0.21571248\n",
      "  0.0918353  -0.44477751]\n",
      "Training Error:  10.543640378838518\n",
      "====================================================================================================\n",
      "Iteration:  1187\n",
      "Previous theta :  [ 0.00632148 -0.08081132  0.11236345  0.02240957  0.0979452  -0.23316769\n",
      "  0.27186166  0.00301092 -0.31981013  0.3401593  -0.24170569 -0.21571248\n",
      "  0.0918353  -0.44477751]\n",
      "New theta_0 : [ 0.00632142 -0.0808153   0.11236738  0.02242008  0.0979432  -0.23317095\n",
      "  0.27185777  0.00301372 -0.31981121  0.34019595 -0.24174492 -0.2157144\n",
      "  0.09183485 -0.44478007]\n",
      "Training Error:  10.543637525836168\n",
      "====================================================================================================\n",
      "Iteration:  1188\n",
      "Previous theta :  [ 0.00632142 -0.0808153   0.11236738  0.02242008  0.0979432  -0.23317095\n",
      "  0.27185777  0.00301372 -0.31981121  0.34019595 -0.24174492 -0.2157144\n",
      "  0.09183485 -0.44478007]\n",
      "New theta_0 : [ 0.00632135 -0.08081928  0.11237131  0.02243057  0.0979412  -0.23317418\n",
      "  0.27185388  0.00301651 -0.31981228  0.34023249 -0.24178404 -0.21571631\n",
      "  0.09183441 -0.44478262]\n",
      "Training Error:  10.543634687912737\n",
      "====================================================================================================\n",
      "Iteration:  1189\n",
      "Previous theta :  [ 0.00632135 -0.08081928  0.11237131  0.02243057  0.0979412  -0.23317418\n",
      "  0.27185388  0.00301651 -0.31981228  0.34023249 -0.24178404 -0.21571631\n",
      "  0.09183441 -0.44478262]\n",
      "New theta_0 : [ 0.00632129 -0.08082323  0.11237522  0.02244103  0.0979392  -0.2331774\n",
      "  0.27185001  0.00301929 -0.31981333  0.34026893 -0.24182306 -0.21571821\n",
      "  0.09183398 -0.44478516]\n",
      "Training Error:  10.543631864987557\n",
      "====================================================================================================\n",
      "Iteration:  1190\n",
      "Previous theta :  [ 0.00632129 -0.08082323  0.11237522  0.02244103  0.0979392  -0.2331774\n",
      "  0.27185001  0.00301929 -0.31981333  0.34026893 -0.24182306 -0.21571821\n",
      "  0.09183398 -0.44478516]\n",
      "New theta_0 : [ 0.00632122 -0.08082718  0.11237911  0.02245147  0.09793721 -0.2331806\n",
      "  0.27184614  0.00302207 -0.31981437  0.34030528 -0.24186198 -0.2157201\n",
      "  0.09183354 -0.44478769]\n",
      "Training Error:  10.5436290569804\n",
      "====================================================================================================\n",
      "Iteration:  1191\n",
      "Previous theta :  [ 0.00632122 -0.08082718  0.11237911  0.02245147  0.09793721 -0.2331806\n",
      "  0.27184614  0.00302207 -0.31981437  0.34030528 -0.24186198 -0.2157201\n",
      "  0.09183354 -0.44478769]\n",
      "New theta_0 : [ 0.00632116 -0.08083111  0.112383    0.02246188  0.09793523 -0.23318377\n",
      "  0.2718423   0.00302483 -0.3198154   0.34034153 -0.24190081 -0.21572199\n",
      "  0.09183311 -0.44479022]\n",
      "Training Error:  10.543626263811475\n",
      "====================================================================================================\n",
      "Iteration:  1192\n",
      "Previous theta :  [ 0.00632116 -0.08083111  0.112383    0.02246188  0.09793523 -0.23318377\n",
      "  0.2718423   0.00302483 -0.3198154   0.34034153 -0.24190081 -0.21572199\n",
      "  0.09183311 -0.44479022]\n",
      "New theta_0 : [ 0.00632109 -0.08083503  0.11238687  0.02247226  0.09793325 -0.23318693\n",
      "  0.27183846  0.00302759 -0.31981642  0.34037768 -0.24193953 -0.21572387\n",
      "  0.09183268 -0.44479275]\n",
      "Training Error:  10.543623485401444\n",
      "====================================================================================================\n",
      "Iteration:  1193\n",
      "Previous theta :  [ 0.00632109 -0.08083503  0.11238687  0.02247226  0.09793325 -0.23318693\n",
      "  0.27183846  0.00302759 -0.31981642  0.34037768 -0.24193953 -0.21572387\n",
      "  0.09183268 -0.44479275]\n",
      "New theta_0 : [ 0.00632103 -0.08083894  0.11239073  0.02248261  0.09793127 -0.23319008\n",
      "  0.27183463  0.00303034 -0.31981743  0.34041374 -0.24197816 -0.21572574\n",
      "  0.09183225 -0.44479526]\n",
      "Training Error:  10.543620721671394\n",
      "====================================================================================================\n",
      "Iteration:  1194\n",
      "Previous theta :  [ 0.00632103 -0.08083894  0.11239073  0.02248261  0.09793127 -0.23319008\n",
      "  0.27183463  0.00303034 -0.31981743  0.34041374 -0.24197816 -0.21572574\n",
      "  0.09183225 -0.44479526]\n",
      "New theta_0 : [ 0.00632096 -0.08084283  0.11239458  0.02249294  0.09792931 -0.2331932\n",
      "  0.27183082  0.00303309 -0.31981842  0.34044969 -0.24201668 -0.21572761\n",
      "  0.09183182 -0.44479778]\n",
      "Training Error:  10.543617972542851\n",
      "====================================================================================================\n",
      "Iteration:  1195\n",
      "Previous theta :  [ 0.00632096 -0.08084283  0.11239458  0.02249294  0.09792931 -0.2331932\n",
      "  0.27183082  0.00303309 -0.31981842  0.34044969 -0.24201668 -0.21572761\n",
      "  0.09183182 -0.44479778]\n",
      "New theta_0 : [ 0.0063209  -0.08084671  0.11239841  0.02250324  0.09792734 -0.2331963\n",
      "  0.27182702  0.00303582 -0.31981941  0.34048556 -0.24205511 -0.21572947\n",
      "  0.0918314  -0.44480028]\n",
      "Training Error:  10.543615237937775\n",
      "====================================================================================================\n",
      "Iteration:  1196\n",
      "Previous theta :  [ 0.0063209  -0.08084671  0.11239841  0.02250324  0.09792734 -0.2331963\n",
      "  0.27182702  0.00303582 -0.31981941  0.34048556 -0.24205511 -0.21572947\n",
      "  0.0918314  -0.44480028]\n",
      "New theta_0 : [ 0.00632084 -0.08085058  0.11240223  0.02251351  0.09792538 -0.23319939\n",
      "  0.27182323  0.00303855 -0.31982038  0.34052132 -0.24209344 -0.21573132\n",
      "  0.09183098 -0.44480278]\n",
      "Training Error:  10.54361251777855\n",
      "====================================================================================================\n",
      "Iteration:  1197\n",
      "Previous theta :  [ 0.00632084 -0.08085058  0.11240223  0.02251351  0.09792538 -0.23319939\n",
      "  0.27182323  0.00303855 -0.31982038  0.34052132 -0.24209344 -0.21573132\n",
      "  0.09183098 -0.44480278]\n",
      "New theta_0 : [ 0.00632077 -0.08085443  0.11240604  0.02252375  0.09792343 -0.23320246\n",
      "  0.27181946  0.00304127 -0.31982134  0.34055699 -0.24213166 -0.21573316\n",
      "  0.09183056 -0.44480528]\n",
      "Training Error:  10.543609811987995\n",
      "====================================================================================================\n",
      "Iteration:  1198\n",
      "Previous theta :  [ 0.00632077 -0.08085443  0.11240604  0.02252375  0.09792343 -0.23320246\n",
      "  0.27181946  0.00304127 -0.31982134  0.34055699 -0.24213166 -0.21573316\n",
      "  0.09183056 -0.44480528]\n",
      "New theta_0 : [ 0.00632071 -0.08085827  0.11240984  0.02253397  0.09792148 -0.23320551\n",
      "  0.27181569  0.00304398 -0.31982229  0.34059256 -0.2421698  -0.215735\n",
      "  0.09183014 -0.44480777]\n",
      "Training Error:  10.543607120489343\n",
      "====================================================================================================\n",
      "Iteration:  1199\n",
      "Previous theta :  [ 0.00632071 -0.08085827  0.11240984  0.02253397  0.09792148 -0.23320551\n",
      "  0.27181569  0.00304398 -0.31982229  0.34059256 -0.2421698  -0.215735\n",
      "  0.09183014 -0.44480777]\n",
      "New theta_0 : [ 0.00632065 -0.0808621   0.11241363  0.02254417  0.09791954 -0.23320854\n",
      "  0.27181194  0.00304668 -0.31982322  0.34062804 -0.24220783 -0.21573683\n",
      "  0.09182972 -0.44481025]\n",
      "Training Error:  10.543604443206258\n",
      "====================================================================================================\n",
      "Iteration:  1200\n",
      "Previous theta :  [ 0.00632065 -0.0808621   0.11241363  0.02254417  0.09791954 -0.23320854\n",
      "  0.27181194  0.00304668 -0.31982322  0.34062804 -0.24220783 -0.21573683\n",
      "  0.09182972 -0.44481025]\n",
      "New theta_0 : [ 0.00632059 -0.08086591  0.1124174   0.02255433  0.0979176  -0.23321155\n",
      "  0.2718082   0.00304938 -0.31982415  0.34066343 -0.24224576 -0.21573865\n",
      "  0.09182931 -0.44481273]\n",
      "Training Error:  10.543601780062817\n",
      "====================================================================================================\n",
      "Iteration:  1201\n",
      "Previous theta :  [ 0.00632059 -0.08086591  0.1124174   0.02255433  0.0979176  -0.23321155\n",
      "  0.2718082   0.00304938 -0.31982415  0.34066343 -0.24224576 -0.21573865\n",
      "  0.09182931 -0.44481273]\n",
      "New theta_0 : [ 0.00632053 -0.08086971  0.11242116  0.02256447  0.09791567 -0.23321455\n",
      "  0.27180447  0.00305206 -0.31982507  0.34069871 -0.2422836  -0.21574046\n",
      "  0.0918289  -0.4448152 ]\n",
      "Training Error:  10.543599130983518\n",
      "====================================================================================================\n",
      "Iteration:  1202\n",
      "Previous theta :  [ 0.00632053 -0.08086971  0.11242116  0.02256447  0.09791567 -0.23321455\n",
      "  0.27180447  0.00305206 -0.31982507  0.34069871 -0.2422836  -0.21574046\n",
      "  0.0918289  -0.4448152 ]\n",
      "New theta_0 : [ 0.00632046 -0.0808735   0.11242491  0.02257459  0.09791374 -0.23321753\n",
      "  0.27180075  0.00305474 -0.31982597  0.34073391 -0.24232134 -0.21574227\n",
      "  0.09182849 -0.44481767]\n",
      "Training Error:  10.543596495893269\n",
      "====================================================================================================\n",
      "Iteration:  1203\n",
      "Previous theta :  [ 0.00632046 -0.0808735   0.11242491  0.02257459  0.09791374 -0.23321753\n",
      "  0.27180075  0.00305474 -0.31982597  0.34073391 -0.24232134 -0.21574227\n",
      "  0.09182849 -0.44481767]\n",
      "New theta_0 : [ 0.0063204  -0.08087728  0.11242864  0.02258467  0.09791182 -0.23322049\n",
      "  0.27179705  0.00305742 -0.31982687  0.34076901 -0.24235899 -0.21574407\n",
      "  0.09182808 -0.44482013]\n",
      "Training Error:  10.543593874717397\n",
      "====================================================================================================\n",
      "Iteration:  1204\n",
      "Previous theta :  [ 0.0063204  -0.08087728  0.11242864  0.02258467  0.09791182 -0.23322049\n",
      "  0.27179705  0.00305742 -0.31982687  0.34076901 -0.24235899 -0.21574407\n",
      "  0.09182808 -0.44482013]\n",
      "New theta_0 : [ 0.00632034 -0.08088104  0.11243237  0.02259473  0.0979099  -0.23322343\n",
      "  0.27179335  0.00306008 -0.31982775  0.34080401 -0.24239654 -0.21574587\n",
      "  0.09182767 -0.44482258]\n",
      "Training Error:  10.54359126738163\n",
      "====================================================================================================\n",
      "Iteration:  1205\n",
      "Previous theta :  [ 0.00632034 -0.08088104  0.11243237  0.02259473  0.0979099  -0.23322343\n",
      "  0.27179335  0.00306008 -0.31982775  0.34080401 -0.24239654 -0.21574587\n",
      "  0.09182767 -0.44482258]\n",
      "New theta_0 : [ 0.00632028 -0.08088479  0.11243608  0.02260477  0.09790799 -0.23322636\n",
      "  0.27178967  0.00306274 -0.31982862  0.34083892 -0.24243399 -0.21574766\n",
      "  0.09182727 -0.44482503]\n",
      "Training Error:  10.54358867381211\n",
      "====================================================================================================\n",
      "Iteration:  1206\n",
      "Previous theta :  [ 0.00632028 -0.08088479  0.11243608  0.02260477  0.09790799 -0.23322636\n",
      "  0.27178967  0.00306274 -0.31982862  0.34083892 -0.24243399 -0.21574766\n",
      "  0.09182727 -0.44482503]\n",
      "New theta_0 : [ 0.00632022 -0.08088853  0.11243978  0.02261478  0.09790608 -0.23322927\n",
      "  0.271786    0.00306539 -0.31982949  0.34087374 -0.24247134 -0.21574944\n",
      "  0.09182687 -0.44482748]\n",
      "Training Error:  10.543586093935382\n",
      "====================================================================================================\n",
      "Iteration:  1207\n",
      "Previous theta :  [ 0.00632022 -0.08088853  0.11243978  0.02261478  0.09790608 -0.23322927\n",
      "  0.271786    0.00306539 -0.31982949  0.34087374 -0.24247134 -0.21574944\n",
      "  0.09182687 -0.44482748]\n",
      "New theta_0 : [ 0.00632016 -0.08089226  0.11244346  0.02262476  0.09790418 -0.23323216\n",
      "  0.27178234  0.00306803 -0.31983034  0.34090847 -0.2425086  -0.21575121\n",
      "  0.09182647 -0.44482991]\n",
      "Training Error:  10.54358352767839\n",
      "====================================================================================================\n",
      "Iteration:  1208\n",
      "Previous theta :  [ 0.00632016 -0.08089226  0.11244346  0.02262476  0.09790418 -0.23323216\n",
      "  0.27178234  0.00306803 -0.31983034  0.34090847 -0.2425086  -0.21575121\n",
      "  0.09182647 -0.44482991]\n",
      "New theta_0 : [ 0.0063201  -0.08089597  0.11244714  0.02263471  0.09790228 -0.23323504\n",
      "  0.27177869  0.00307067 -0.31983118  0.3409431  -0.24254576 -0.21575298\n",
      "  0.09182607 -0.44483235]\n",
      "Training Error:  10.543580974968485\n",
      "====================================================================================================\n",
      "Iteration:  1209\n",
      "Previous theta :  [ 0.0063201  -0.08089597  0.11244714  0.02263471  0.09790228 -0.23323504\n",
      "  0.27177869  0.00307067 -0.31983118  0.3409431  -0.24254576 -0.21575298\n",
      "  0.09182607 -0.44483235]\n",
      "New theta_0 : [ 0.00632004 -0.08089967  0.1124508   0.02264465  0.09790039 -0.2332379\n",
      "  0.27177506  0.00307329 -0.31983201  0.34097764 -0.24258283 -0.21575474\n",
      "  0.09182568 -0.44483477]\n",
      "Training Error:  10.543578435733409\n",
      "====================================================================================================\n",
      "Iteration:  1210\n",
      "Previous theta :  [ 0.00632004 -0.08089967  0.1124508   0.02264465  0.09790039 -0.2332379\n",
      "  0.27177506  0.00307329 -0.31983201  0.34097764 -0.24258283 -0.21575474\n",
      "  0.09182568 -0.44483477]\n",
      "New theta_0 : [ 0.00631998 -0.08090336  0.11245446  0.02265455  0.0978985  -0.23324074\n",
      "  0.27177143  0.00307591 -0.31983283  0.34101208 -0.2426198  -0.21575649\n",
      "  0.09182528 -0.44483719]\n",
      "Training Error:  10.543575909901302\n",
      "====================================================================================================\n",
      "Iteration:  1211\n",
      "Previous theta :  [ 0.00631998 -0.08090336  0.11245446  0.02265455  0.0978985  -0.23324074\n",
      "  0.27177143  0.00307591 -0.31983283  0.34101208 -0.2426198  -0.21575649\n",
      "  0.09182528 -0.44483719]\n",
      "New theta_0 : [ 0.00631992 -0.08090704  0.1124581   0.02266443  0.09789662 -0.23324357\n",
      "  0.27176782  0.00307853 -0.31983364  0.34104644 -0.24265668 -0.21575823\n",
      "  0.09182489 -0.44483961]\n",
      "Training Error:  10.5435733974007\n",
      "====================================================================================================\n",
      "Iteration:  1212\n",
      "Previous theta :  [ 0.00631992 -0.08090704  0.1124581   0.02266443  0.09789662 -0.23324357\n",
      "  0.27176782  0.00307853 -0.31983364  0.34104644 -0.24265668 -0.21575823\n",
      "  0.09182489 -0.44483961]\n",
      "New theta_0 : [ 0.00631986 -0.0809107   0.11246173  0.02267428  0.09789474 -0.23324638\n",
      "  0.27176422  0.00308113 -0.31983444  0.3410807  -0.24269346 -0.21575997\n",
      "  0.0918245  -0.44484202]\n",
      "Training Error:  10.543570898160523\n",
      "====================================================================================================\n",
      "Iteration:  1213\n",
      "Previous theta :  [ 0.00631986 -0.0809107   0.11246173  0.02267428  0.09789474 -0.23324638\n",
      "  0.27176422  0.00308113 -0.31983444  0.3410807  -0.24269346 -0.21575997\n",
      "  0.0918245  -0.44484202]\n",
      "New theta_0 : [ 0.0063198  -0.08091435  0.11246534  0.02268411  0.09789287 -0.23324917\n",
      "  0.27176063  0.00308373 -0.31983524  0.34111487 -0.24273015 -0.21576171\n",
      "  0.09182411 -0.44484442]\n",
      "Training Error:  10.543568412110085\n",
      "====================================================================================================\n",
      "Iteration:  1214\n",
      "Previous theta :  [ 0.0063198  -0.08091435  0.11246534  0.02268411  0.09789287 -0.23324917\n",
      "  0.27176063  0.00308373 -0.31983524  0.34111487 -0.24273015 -0.21576171\n",
      "  0.09182411 -0.44484442]\n",
      "New theta_0 : [ 0.00631974 -0.08091799  0.11246895  0.02269391  0.097891   -0.23325195\n",
      "  0.27175705  0.00308632 -0.31983602  0.34114895 -0.24276675 -0.21576343\n",
      "  0.09182373 -0.44484682]\n",
      "Training Error:  10.54356593917909\n",
      "====================================================================================================\n",
      "Iteration:  1215\n",
      "Previous theta :  [ 0.00631974 -0.08091799  0.11246895  0.02269391  0.097891   -0.23325195\n",
      "  0.27175705  0.00308632 -0.31983602  0.34114895 -0.24276675 -0.21576343\n",
      "  0.09182373 -0.44484682]\n",
      "New theta_0 : [ 0.00631968 -0.08092162  0.11247254  0.02270368  0.09788914 -0.23325471\n",
      "  0.27175348  0.0030889  -0.31983679  0.34118293 -0.24280324 -0.21576515\n",
      "  0.09182334 -0.44484921]\n",
      "Training Error:  10.543563479297614\n",
      "====================================================================================================\n",
      "Iteration:  1216\n",
      "Previous theta :  [ 0.00631968 -0.08092162  0.11247254  0.02270368  0.09788914 -0.23325471\n",
      "  0.27175348  0.0030889  -0.31983679  0.34118293 -0.24280324 -0.21576515\n",
      "  0.09182334 -0.44484921]\n",
      "New theta_0 : [ 0.00631963 -0.08092524  0.11247612  0.02271344  0.09788728 -0.23325745\n",
      "  0.27174992  0.00309148 -0.31983755  0.34121683 -0.24283965 -0.21576686\n",
      "  0.09182296 -0.4448516 ]\n",
      "Training Error:  10.543561032396127\n",
      "====================================================================================================\n",
      "Iteration:  1217\n",
      "Previous theta :  [ 0.00631963 -0.08092524  0.11247612  0.02271344  0.09788728 -0.23325745\n",
      "  0.27174992  0.00309148 -0.31983755  0.34121683 -0.24283965 -0.21576686\n",
      "  0.09182296 -0.4448516 ]\n",
      "New theta_0 : [ 0.00631957 -0.08092884  0.11247969  0.02272316  0.09788542 -0.23326018\n",
      "  0.27174637  0.00309405 -0.3198383   0.34125064 -0.24287596 -0.21576857\n",
      "  0.09182258 -0.44485398]\n",
      "Training Error:  10.543558598405474\n",
      "====================================================================================================\n",
      "Iteration:  1218\n",
      "Previous theta :  [ 0.00631957 -0.08092884  0.11247969  0.02272316  0.09788542 -0.23326018\n",
      "  0.27174637  0.00309405 -0.3198383   0.34125064 -0.24287596 -0.21576857\n",
      "  0.09182258 -0.44485398]\n",
      "New theta_0 : [ 0.00631951 -0.08093243  0.11248325  0.02273286  0.09788358 -0.23326289\n",
      "  0.27174284  0.00309661 -0.31983904  0.34128435 -0.24291218 -0.21577027\n",
      "  0.0918222  -0.44485636]\n",
      "Training Error:  10.543556177256873\n",
      "====================================================================================================\n",
      "Iteration:  1219\n",
      "Previous theta :  [ 0.00631951 -0.08093243  0.11248325  0.02273286  0.09788358 -0.23326289\n",
      "  0.27174284  0.00309661 -0.31983904  0.34128435 -0.24291218 -0.21577027\n",
      "  0.0918222  -0.44485636]\n",
      "New theta_0 : [ 0.00631945 -0.08093601  0.1124868   0.02274253  0.09788173 -0.23326559\n",
      "  0.27173931  0.00309916 -0.31983978  0.34131798 -0.24294831 -0.21577196\n",
      "  0.09182182 -0.44485873]\n",
      "Training Error:  10.543553768881925\n",
      "====================================================================================================\n",
      "Iteration:  1220\n",
      "Previous theta :  [ 0.00631945 -0.08093601  0.1124868   0.02274253  0.09788173 -0.23326559\n",
      "  0.27173931  0.00309916 -0.31983978  0.34131798 -0.24294831 -0.21577196\n",
      "  0.09182182 -0.44485873]\n",
      "New theta_0 : [ 0.00631939 -0.08093958  0.11249034  0.02275218  0.09787989 -0.23326827\n",
      "  0.2717358   0.00310171 -0.3198405   0.34135151 -0.24298434 -0.21577365\n",
      "  0.09182145 -0.44486109]\n",
      "Training Error:  10.543551373212601\n",
      "====================================================================================================\n",
      "Iteration:  1221\n",
      "Previous theta :  [ 0.00631939 -0.08093958  0.11249034  0.02275218  0.09787989 -0.23326827\n",
      "  0.2717358   0.00310171 -0.3198405   0.34135151 -0.24298434 -0.21577365\n",
      "  0.09182145 -0.44486109]\n",
      "New theta_0 : [ 0.00631934 -0.08094314  0.11249386  0.02276181  0.09787806 -0.23327094\n",
      "  0.2717323   0.00310425 -0.31984121  0.34138496 -0.24302028 -0.21577533\n",
      "  0.09182108 -0.44486345]\n",
      "Training Error:  10.54354899018124\n",
      "====================================================================================================\n",
      "Iteration:  1222\n",
      "Previous theta :  [ 0.00631934 -0.08094314  0.11249386  0.02276181  0.09787806 -0.23327094\n",
      "  0.2717323   0.00310425 -0.31984121  0.34138496 -0.24302028 -0.21577533\n",
      "  0.09182108 -0.44486345]\n",
      "New theta_0 : [ 0.00631928 -0.08094668  0.11249738  0.0227714   0.09787623 -0.23327359\n",
      "  0.27172881  0.00310678 -0.31984192  0.34141831 -0.24305613 -0.21577701\n",
      "  0.0918207  -0.44486581]\n",
      "Training Error:  10.543546619720555\n",
      "====================================================================================================\n",
      "Iteration:  1223\n",
      "Previous theta :  [ 0.00631928 -0.08094668  0.11249738  0.0227714   0.09787623 -0.23327359\n",
      "  0.27172881  0.00310678 -0.31984192  0.34141831 -0.24305613 -0.21577701\n",
      "  0.0918207  -0.44486581]\n",
      "New theta_0 : [ 0.00631922 -0.08095021  0.11250088  0.02278098  0.09787441 -0.23327622\n",
      "  0.27172533  0.0031093  -0.31984262  0.34145158 -0.24309188 -0.21577867\n",
      "  0.09182033 -0.44486816]\n",
      "Training Error:  10.543544261763623\n",
      "====================================================================================================\n",
      "Iteration:  1224\n",
      "Previous theta :  [ 0.00631922 -0.08095021  0.11250088  0.02278098  0.09787441 -0.23327622\n",
      "  0.27172533  0.0031093  -0.31984262  0.34145158 -0.24309188 -0.21577867\n",
      "  0.09182033 -0.44486816]\n",
      "New theta_0 : [ 0.00631917 -0.08095373  0.11250437  0.02279053  0.09787259 -0.23327884\n",
      "  0.27172186  0.00311182 -0.3198433   0.34148475 -0.24312755 -0.21578033\n",
      "  0.09181997 -0.4448705 ]\n",
      "Training Error:  10.543541916243884\n",
      "====================================================================================================\n",
      "Iteration:  1225\n",
      "Previous theta :  [ 0.00631917 -0.08095373  0.11250437  0.02279053  0.09787259 -0.23327884\n",
      "  0.27172186  0.00311182 -0.3198433   0.34148475 -0.24312755 -0.21578033\n",
      "  0.09181997 -0.4448705 ]\n",
      "New theta_0 : [ 0.00631911 -0.08095724  0.11250785  0.02280005  0.09787077 -0.23328145\n",
      "  0.2717184   0.00311433 -0.31984398  0.34151784 -0.24316312 -0.21578199\n",
      "  0.0918196  -0.44487284]\n",
      "Training Error:  10.543539583095145\n",
      "====================================================================================================\n",
      "Iteration:  1226\n",
      "Previous theta :  [ 0.00631911 -0.08095724  0.11250785  0.02280005  0.09787077 -0.23328145\n",
      "  0.2717184   0.00311433 -0.31984398  0.34151784 -0.24316312 -0.21578199\n",
      "  0.0918196  -0.44487284]\n",
      "New theta_0 : [ 0.00631905 -0.08096074  0.11251132  0.02280955  0.09786896 -0.23328404\n",
      "  0.27171495  0.00311683 -0.31984465  0.34155084 -0.2431986  -0.21578364\n",
      "  0.09181924 -0.44487517]\n",
      "Training Error:  10.543537262251567\n",
      "====================================================================================================\n",
      "Iteration:  1227\n",
      "Previous theta :  [ 0.00631905 -0.08096074  0.11251132  0.02280955  0.09786896 -0.23328404\n",
      "  0.27171495  0.00311683 -0.31984465  0.34155084 -0.2431986  -0.21578364\n",
      "  0.09181924 -0.44487517]\n",
      "New theta_0 : [ 0.006319   -0.08096423  0.11251478  0.02281902  0.09786716 -0.23328661\n",
      "  0.27171151  0.00311933 -0.31984531  0.34158375 -0.24323399 -0.21578528\n",
      "  0.09181887 -0.44487749]\n",
      "Training Error:  10.543534953647676\n",
      "====================================================================================================\n",
      "Iteration:  1228\n",
      "Previous theta :  [ 0.006319   -0.08096423  0.11251478  0.02281902  0.09786716 -0.23328661\n",
      "  0.27171151  0.00311933 -0.31984531  0.34158375 -0.24323399 -0.21578528\n",
      "  0.09181887 -0.44487749]\n",
      "New theta_0 : [ 0.00631894 -0.0809677   0.11251823  0.02282847  0.09786536 -0.23328917\n",
      "  0.27170809  0.00312182 -0.31984596  0.34161658 -0.24326928 -0.21578692\n",
      "  0.09181851 -0.44487982]\n",
      "Training Error:  10.543532657218348\n",
      "====================================================================================================\n",
      "Iteration:  1229\n",
      "Previous theta :  [ 0.00631894 -0.0809677   0.11251823  0.02282847  0.09786536 -0.23328917\n",
      "  0.27170809  0.00312182 -0.31984596  0.34161658 -0.24326928 -0.21578692\n",
      "  0.09181851 -0.44487982]\n",
      "New theta_0 : [ 0.00631889 -0.08097117  0.11252166  0.0228379   0.09786356 -0.23329172\n",
      "  0.27170467  0.0031243  -0.3198466   0.34164931 -0.24330449 -0.21578855\n",
      "  0.09181815 -0.44488213]\n",
      "Training Error:  10.54353037289882\n",
      "====================================================================================================\n",
      "Iteration:  1230\n",
      "Previous theta :  [ 0.00631889 -0.08097117  0.11252166  0.0228379   0.09786356 -0.23329172\n",
      "  0.27170467  0.0031243  -0.3198466   0.34164931 -0.24330449 -0.21578855\n",
      "  0.09181815 -0.44488213]\n",
      "New theta_0 : [ 0.00631883 -0.08097462  0.11252509  0.0228473   0.09786177 -0.23329425\n",
      "  0.27170126  0.00312678 -0.31984724  0.34168196 -0.24333961 -0.21579017\n",
      "  0.0918178  -0.44488444]\n",
      "Training Error:  10.543528100624677\n",
      "====================================================================================================\n",
      "Iteration:  1231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous theta :  [ 0.00631883 -0.08097462  0.11252509  0.0228473   0.09786177 -0.23329425\n",
      "  0.27170126  0.00312678 -0.31984724  0.34168196 -0.24333961 -0.21579017\n",
      "  0.0918178  -0.44488444]\n",
      "New theta_0 : [ 0.00631878 -0.08097806  0.1125285   0.02285667  0.09785999 -0.23329676\n",
      "  0.27169787  0.00312924 -0.31984786  0.34171452 -0.24337463 -0.21579179\n",
      "  0.09181744 -0.44488675]\n",
      "Training Error:  10.543525840331853\n",
      "====================================================================================================\n",
      "Iteration:  1232\n",
      "Previous theta :  [ 0.00631878 -0.08097806  0.1125285   0.02285667  0.09785999 -0.23329676\n",
      "  0.27169787  0.00312924 -0.31984786  0.34171452 -0.24337463 -0.21579179\n",
      "  0.09181744 -0.44488675]\n",
      "New theta_0 : [ 0.00631872 -0.08098149  0.11253191  0.02286602  0.09785821 -0.23329926\n",
      "  0.27169448  0.00313171 -0.31984848  0.341747   -0.24340957 -0.2157934\n",
      "  0.09181709 -0.44488905]\n",
      "Training Error:  10.543523591956632\n",
      "====================================================================================================\n",
      "Iteration:  1233\n",
      "Previous theta :  [ 0.00631872 -0.08098149  0.11253191  0.02286602  0.09785821 -0.23329926\n",
      "  0.27169448  0.00313171 -0.31984848  0.341747   -0.24340957 -0.2157934\n",
      "  0.09181709 -0.44488905]\n",
      "New theta_0 : [ 0.00631867 -0.08098491  0.1125353   0.02287535  0.09785643 -0.23330175\n",
      "  0.27169111  0.00313416 -0.31984909  0.34177938 -0.24344441 -0.21579501\n",
      "  0.09181674 -0.44489134]\n",
      "Training Error:  10.543521355435647\n",
      "====================================================================================================\n",
      "Iteration:  1234\n",
      "Previous theta :  [ 0.00631867 -0.08098491  0.1125353   0.02287535  0.09785643 -0.23330175\n",
      "  0.27169111  0.00313416 -0.31984909  0.34177938 -0.24344441 -0.21579501\n",
      "  0.09181674 -0.44489134]\n",
      "New theta_0 : [ 0.00631861 -0.08098831  0.11253868  0.02288465  0.09785466 -0.23330422\n",
      "  0.27168774  0.00313661 -0.31984969  0.34181168 -0.24347917 -0.2157966\n",
      "  0.09181639 -0.44489363]\n",
      "Training Error:  10.543519130705869\n",
      "====================================================================================================\n",
      "Iteration:  1235\n",
      "Previous theta :  [ 0.00631861 -0.08098831  0.11253868  0.02288465  0.09785466 -0.23330422\n",
      "  0.27168774  0.00313661 -0.31984969  0.34181168 -0.24347917 -0.2157966\n",
      "  0.09181639 -0.44489363]\n",
      "New theta_0 : [ 0.00631856 -0.08099171  0.11254205  0.02289393  0.09785289 -0.23330668\n",
      "  0.27168439  0.00313905 -0.31985028  0.3418439  -0.24351384 -0.2157982\n",
      "  0.09181604 -0.44489591]\n",
      "Training Error:  10.543516917704617\n",
      "====================================================================================================\n",
      "Iteration:  1236\n",
      "Previous theta :  [ 0.00631856 -0.08099171  0.11254205  0.02289393  0.09785289 -0.23330668\n",
      "  0.27168439  0.00313905 -0.31985028  0.3418439  -0.24351384 -0.2157982\n",
      "  0.09181604 -0.44489591]\n",
      "New theta_0 : [ 0.00631851 -0.08099509  0.11254541  0.02290318  0.09785113 -0.23330913\n",
      "  0.27168105  0.00314148 -0.31985087  0.34187603 -0.24354841 -0.21579979\n",
      "  0.09181569 -0.44489819]\n",
      "Training Error:  10.543514716369545\n",
      "====================================================================================================\n",
      "Iteration:  1237\n",
      "Previous theta :  [ 0.00631851 -0.08099509  0.11254541  0.02290318  0.09785113 -0.23330913\n",
      "  0.27168105  0.00314148 -0.31985087  0.34187603 -0.24354841 -0.21579979\n",
      "  0.09181569 -0.44489819]\n",
      "New theta_0 : [ 0.00631845 -0.08099847  0.11254876  0.02291241  0.09784937 -0.23331156\n",
      "  0.27167772  0.00314391 -0.31985144  0.34190807 -0.2435829  -0.21580137\n",
      "  0.09181534 -0.44490046]\n",
      "Training Error:  10.543512526638652\n",
      "====================================================================================================\n",
      "Iteration:  1238\n",
      "Previous theta :  [ 0.00631845 -0.08099847  0.11254876  0.02291241  0.09784937 -0.23331156\n",
      "  0.27167772  0.00314391 -0.31985144  0.34190807 -0.2435829  -0.21580137\n",
      "  0.09181534 -0.44490046]\n",
      "New theta_0 : [ 0.0063184  -0.08100183  0.1125521   0.02292162  0.09784762 -0.23331398\n",
      "  0.27167439  0.00314633 -0.31985201  0.34194002 -0.2436173  -0.21580294\n",
      "  0.091815   -0.44490273]\n",
      "Training Error:  10.543510348450267\n",
      "====================================================================================================\n",
      "Iteration:  1239\n",
      "Previous theta :  [ 0.0063184  -0.08100183  0.1125521   0.02292162  0.09784762 -0.23331398\n",
      "  0.27167439  0.00314633 -0.31985201  0.34194002 -0.2436173  -0.21580294\n",
      "  0.091815   -0.44490273]\n",
      "New theta_0 : [ 0.00631835 -0.08100518  0.11255543  0.0229308   0.09784587 -0.23331638\n",
      "  0.27167108  0.00314874 -0.31985257  0.3419719  -0.24365161 -0.21580451\n",
      "  0.09181466 -0.44490499]\n",
      "Training Error:  10.543508181743057\n",
      "====================================================================================================\n",
      "Iteration:  1240\n",
      "Previous theta :  [ 0.00631835 -0.08100518  0.11255543  0.0229308   0.09784587 -0.23331638\n",
      "  0.27167108  0.00314874 -0.31985257  0.3419719  -0.24365161 -0.21580451\n",
      "  0.09181466 -0.44490499]\n",
      "New theta_0 : [ 0.00631829 -0.08100852  0.11255875  0.02293996  0.09784412 -0.23331877\n",
      "  0.27166778  0.00315115 -0.31985312  0.34200368 -0.24368583 -0.21580608\n",
      "  0.09181432 -0.44490725]\n",
      "Training Error:  10.54350602645602\n",
      "====================================================================================================\n",
      "Iteration:  1241\n",
      "Previous theta :  [ 0.00631829 -0.08100852  0.11255875  0.02293996  0.09784412 -0.23331877\n",
      "  0.27166778  0.00315115 -0.31985312  0.34200368 -0.24368583 -0.21580608\n",
      "  0.09181432 -0.44490725]\n",
      "New theta_0 : [ 0.00631824 -0.08101185  0.11256206  0.02294909  0.09784238 -0.23332114\n",
      "  0.27166449  0.00315355 -0.31985366  0.34203538 -0.24371997 -0.21580763\n",
      "  0.09181398 -0.4449095 ]\n",
      "Training Error:  10.543503882528487\n",
      "====================================================================================================\n",
      "Iteration:  1242\n",
      "Previous theta :  [ 0.00631824 -0.08101185  0.11256206  0.02294909  0.09784238 -0.23332114\n",
      "  0.27166449  0.00315355 -0.31985366  0.34203538 -0.24371997 -0.21580763\n",
      "  0.09181398 -0.4449095 ]\n",
      "New theta_0 : [ 0.00631819 -0.08101517  0.11256536  0.0229582   0.09784065 -0.2333235\n",
      "  0.2716612   0.00315594 -0.3198542   0.342067   -0.24375401 -0.21580919\n",
      "  0.09181364 -0.44491174]\n",
      "Training Error:  10.543501749900111\n",
      "====================================================================================================\n",
      "Iteration:  1243\n",
      "Previous theta :  [ 0.00631819 -0.08101517  0.11256536  0.0229582   0.09784065 -0.2333235\n",
      "  0.2716612   0.00315594 -0.3198542   0.342067   -0.24375401 -0.21580919\n",
      "  0.09181364 -0.44491174]\n",
      "New theta_0 : [ 0.00631814 -0.08101848  0.11256864  0.02296728  0.09783892 -0.23332585\n",
      "  0.27165793  0.00315832 -0.31985473  0.34209853 -0.24378797 -0.21581073\n",
      "  0.09181331 -0.44491398]\n",
      "Training Error:  10.543499628510883\n",
      "====================================================================================================\n",
      "Iteration:  1244\n",
      "Previous theta :  [ 0.00631814 -0.08101848  0.11256864  0.02296728  0.09783892 -0.23332585\n",
      "  0.27165793  0.00315832 -0.31985473  0.34209853 -0.24378797 -0.21581073\n",
      "  0.09181331 -0.44491398]\n",
      "New theta_0 : [ 0.00631808 -0.08102178  0.11257192  0.02297634  0.09783719 -0.23332819\n",
      "  0.27165467  0.0031607  -0.31985525  0.34212998 -0.24382184 -0.21581227\n",
      "  0.09181297 -0.44491622]\n",
      "Training Error:  10.54349751830111\n",
      "====================================================================================================\n",
      "Iteration:  1245\n",
      "Previous theta :  [ 0.00631808 -0.08102178  0.11257192  0.02297634  0.09783719 -0.23332819\n",
      "  0.27165467  0.0031607  -0.31985525  0.34212998 -0.24382184 -0.21581227\n",
      "  0.09181297 -0.44491622]\n",
      "New theta_0 : [ 0.00631803 -0.08102507  0.11257519  0.02298538  0.09783547 -0.23333051\n",
      "  0.27165142  0.00316308 -0.31985576  0.34216134 -0.24385562 -0.21581381\n",
      "  0.09181264 -0.44491845]\n",
      "Training Error:  10.543495419211427\n",
      "====================================================================================================\n",
      "Iteration:  1246\n",
      "Previous theta :  [ 0.00631803 -0.08102507  0.11257519  0.02298538  0.09783547 -0.23333051\n",
      "  0.27165142  0.00316308 -0.31985576  0.34216134 -0.24385562 -0.21581381\n",
      "  0.09181264 -0.44491845]\n",
      "New theta_0 : [ 0.00631798 -0.08102834  0.11257844  0.0229944   0.09783375 -0.23333282\n",
      "  0.27164818  0.00316544 -0.31985627  0.34219262 -0.24388932 -0.21581534\n",
      "  0.09181231 -0.44492067]\n",
      "Training Error:  10.543493331182788\n",
      "====================================================================================================\n",
      "Iteration:  1247\n",
      "Previous theta :  [ 0.00631798 -0.08102834  0.11257844  0.0229944   0.09783375 -0.23333282\n",
      "  0.27164818  0.00316544 -0.31985627  0.34219262 -0.24388932 -0.21581534\n",
      "  0.09181231 -0.44492067]\n",
      "New theta_0 : [ 0.00631793 -0.08103161  0.11258169  0.02300339  0.09783204 -0.23333511\n",
      "  0.27164494  0.0031678  -0.31985677  0.34222382 -0.24392293 -0.21581686\n",
      "  0.09181198 -0.44492289]\n",
      "Training Error:  10.543491254156466\n",
      "====================================================================================================\n",
      "Iteration:  1248\n",
      "Previous theta :  [ 0.00631793 -0.08103161  0.11258169  0.02300339  0.09783204 -0.23333511\n",
      "  0.27164494  0.0031678  -0.31985677  0.34222382 -0.24392293 -0.21581686\n",
      "  0.09181198 -0.44492289]\n",
      "New theta_0 : [ 0.00631788 -0.08103486  0.11258492  0.02301235  0.09783033 -0.23333739\n",
      "  0.27164172  0.00317015 -0.31985726  0.34225493 -0.24395645 -0.21581838\n",
      "  0.09181165 -0.44492511]\n",
      "Training Error:  10.543489188074053\n",
      "====================================================================================================\n",
      "Iteration:  1249\n",
      "Previous theta :  [ 0.00631788 -0.08103486  0.11258492  0.02301235  0.09783033 -0.23333739\n",
      "  0.27164172  0.00317015 -0.31985726  0.34225493 -0.24395645 -0.21581838\n",
      "  0.09181165 -0.44492511]\n",
      "New theta_0 : [ 0.00631782 -0.08103811  0.11258815  0.0230213   0.09782863 -0.23333966\n",
      "  0.27163851  0.0031725  -0.31985774  0.34228596 -0.24398989 -0.21581989\n",
      "  0.09181132 -0.44492731]\n",
      "Training Error:  10.543487132877459\n",
      "====================================================================================================\n",
      "Iteration:  1250\n",
      "Previous theta :  [ 0.00631782 -0.08103811  0.11258815  0.0230213   0.09782863 -0.23333966\n",
      "  0.27163851  0.0031725  -0.31985774  0.34228596 -0.24398989 -0.21581989\n",
      "  0.09181132 -0.44492731]\n",
      "New theta_0 : [ 0.00631777 -0.08104134  0.11259137  0.02303022  0.09782693 -0.23334192\n",
      "  0.27163531  0.00317484 -0.31985822  0.34231691 -0.24402324 -0.2158214\n",
      "  0.091811   -0.44492952]\n",
      "Training Error:  10.543485088508904\n",
      "====================================================================================================\n",
      "Iteration:  1251\n",
      "Previous theta :  [ 0.00631777 -0.08104134  0.11259137  0.02303022  0.09782693 -0.23334192\n",
      "  0.27163531  0.00317484 -0.31985822  0.34231691 -0.24402324 -0.2158214\n",
      "  0.091811   -0.44492952]\n",
      "New theta_0 : [ 0.00631772 -0.08104456  0.11259457  0.02303912  0.09782524 -0.23334416\n",
      "  0.27163211  0.00317717 -0.31985869  0.34234777 -0.2440565  -0.2158229\n",
      "  0.09181068 -0.44493172]\n",
      "Training Error:  10.543483054910924\n",
      "====================================================================================================\n",
      "Iteration:  1252\n",
      "Previous theta :  [ 0.00631772 -0.08104456  0.11259457  0.02303912  0.09782524 -0.23334416\n",
      "  0.27163211  0.00317717 -0.31985869  0.34234777 -0.2440565  -0.2158229\n",
      "  0.09181068 -0.44493172]\n",
      "New theta_0 : [ 0.00631767 -0.08104778  0.11259777  0.02304799  0.09782355 -0.23334639\n",
      "  0.27162893  0.0031795  -0.31985915  0.34237855 -0.24408968 -0.21582439\n",
      "  0.09181035 -0.44493391]\n",
      "Training Error:  10.543481032026365\n",
      "====================================================================================================\n",
      "Iteration:  1253\n",
      "Previous theta :  [ 0.00631767 -0.08104778  0.11259777  0.02304799  0.09782355 -0.23334639\n",
      "  0.27162893  0.0031795  -0.31985915  0.34237855 -0.24408968 -0.21582439\n",
      "  0.09181035 -0.44493391]\n",
      "New theta_0 : [ 0.00631762 -0.08105098  0.11260095  0.02305684  0.09782186 -0.23334861\n",
      "  0.27162576  0.00318182 -0.3198596   0.34240925 -0.24412277 -0.21582588\n",
      "  0.09181003 -0.4449361 ]\n",
      "Training Error:  10.54347901979838\n",
      "====================================================================================================\n",
      "Iteration:  1254\n",
      "Previous theta :  [ 0.00631762 -0.08105098  0.11260095  0.02305684  0.09782186 -0.23334861\n",
      "  0.27162576  0.00318182 -0.3198596   0.34240925 -0.24412277 -0.21582588\n",
      "  0.09181003 -0.4449361 ]\n",
      "New theta_0 : [ 0.00631757 -0.08105417  0.11260413  0.02306567  0.09782018 -0.23335082\n",
      "  0.27162259  0.00318413 -0.31986005  0.34243987 -0.24415578 -0.21582737\n",
      "  0.09180972 -0.44493828]\n",
      "Training Error:  10.543477018170428\n",
      "====================================================================================================\n",
      "Iteration:  1255\n",
      "Previous theta :  [ 0.00631757 -0.08105417  0.11260413  0.02306567  0.09782018 -0.23335082\n",
      "  0.27162259  0.00318413 -0.31986005  0.34243987 -0.24415578 -0.21582737\n",
      "  0.09180972 -0.44493828]\n",
      "New theta_0 : [ 0.00631752 -0.08105735  0.11260729  0.02307447  0.0978185  -0.23335301\n",
      "  0.27161944  0.00318644 -0.31986049  0.3424704  -0.2441887  -0.21582885\n",
      "  0.0918094  -0.44494046]\n",
      "Training Error:  10.543475027086277\n",
      "====================================================================================================\n",
      "Iteration:  1256\n",
      "Previous theta :  [ 0.00631752 -0.08105735  0.11260729  0.02307447  0.0978185  -0.23335301\n",
      "  0.27161944  0.00318644 -0.31986049  0.3424704  -0.2441887  -0.21582885\n",
      "  0.0918094  -0.44494046]\n",
      "New theta_0 : [ 0.00631747 -0.08106053  0.11261045  0.02308325  0.09781683 -0.23335519\n",
      "  0.27161629  0.00318874 -0.31986092  0.34250086 -0.24422154 -0.21583032\n",
      "  0.09180908 -0.44494263]\n",
      "Training Error:  10.543473046489998\n",
      "====================================================================================================\n",
      "Iteration:  1257\n",
      "Previous theta :  [ 0.00631747 -0.08106053  0.11261045  0.02308325  0.09781683 -0.23335519\n",
      "  0.27161629  0.00318874 -0.31986092  0.34250086 -0.24422154 -0.21583032\n",
      "  0.09180908 -0.44494263]\n",
      "New theta_0 : [ 0.00631742 -0.08106369  0.1126136   0.02309201  0.09781516 -0.23335736\n",
      "  0.27161316  0.00319103 -0.31986135  0.34253123 -0.24425429 -0.21583179\n",
      "  0.09180877 -0.4449448 ]\n",
      "Training Error:  10.543471076325963\n",
      "====================================================================================================\n",
      "Iteration:  1258\n",
      "Previous theta :  [ 0.00631742 -0.08106369  0.1126136   0.02309201  0.09781516 -0.23335736\n",
      "  0.27161316  0.00319103 -0.31986135  0.34253123 -0.24425429 -0.21583179\n",
      "  0.09180877 -0.4449448 ]\n",
      "New theta_0 : [ 0.00631737 -0.08106684  0.11261673  0.02310075  0.0978135  -0.23335952\n",
      "  0.27161003  0.00319332 -0.31986177  0.34256152 -0.24428696 -0.21583325\n",
      "  0.09180846 -0.44494696]\n",
      "Training Error:  10.543469116538843\n",
      "====================================================================================================\n",
      "Iteration:  1259\n",
      "Previous theta :  [ 0.00631737 -0.08106684  0.11261673  0.02310075  0.0978135  -0.23335952\n",
      "  0.27161003  0.00319332 -0.31986177  0.34256152 -0.24428696 -0.21583325\n",
      "  0.09180846 -0.44494696]\n",
      "New theta_0 : [ 0.00631732 -0.08106998  0.11261986  0.02310946  0.09781184 -0.23336166\n",
      "  0.27160692  0.0031956  -0.31986219  0.34259174 -0.24431954 -0.21583471\n",
      "  0.09180814 -0.44494912]\n",
      "Training Error:  10.54346716707361\n",
      "====================================================================================================\n",
      "Iteration:  1260\n",
      "Previous theta :  [ 0.00631732 -0.08106998  0.11261986  0.02310946  0.09781184 -0.23336166\n",
      "  0.27160692  0.0031956  -0.31986219  0.34259174 -0.24431954 -0.21583471\n",
      "  0.09180814 -0.44494912]\n",
      "New theta_0 : [ 0.00631727 -0.08107311  0.11262298  0.02311815  0.09781018 -0.23336379\n",
      "  0.27160381  0.00319787 -0.31986259  0.34262187 -0.24435204 -0.21583616\n",
      "  0.09180783 -0.44495127]\n",
      "Training Error:  10.543465227875533\n",
      "====================================================================================================\n",
      "Iteration:  1261\n",
      "Previous theta :  [ 0.00631727 -0.08107311  0.11262298  0.02311815  0.09781018 -0.23336379\n",
      "  0.27160381  0.00319787 -0.31986259  0.34262187 -0.24435204 -0.21583616\n",
      "  0.09180783 -0.44495127]\n",
      "New theta_0 : [ 0.00631723 -0.08107623  0.11262608  0.02312681  0.09780853 -0.23336591\n",
      "  0.27160071  0.00320014 -0.31986299  0.34265192 -0.24438446 -0.2158376\n",
      "  0.09180753 -0.44495342]\n",
      "Training Error:  10.543463298890172\n",
      "====================================================================================================\n",
      "Iteration:  1262\n",
      "Previous theta :  [ 0.00631723 -0.08107623  0.11262608  0.02312681  0.09780853 -0.23336591\n",
      "  0.27160071  0.00320014 -0.31986299  0.34265192 -0.24438446 -0.2158376\n",
      "  0.09180753 -0.44495342]\n",
      "New theta_0 : [ 0.00631718 -0.08107935  0.11262918  0.02313546  0.09780689 -0.23336802\n",
      "  0.27159763  0.0032024  -0.31986339  0.34268189 -0.24441679 -0.21583905\n",
      "  0.09180722 -0.44495556]\n",
      "Training Error:  10.543461380063384\n",
      "====================================================================================================\n",
      "Iteration:  1263\n",
      "Previous theta :  [ 0.00631718 -0.08107935  0.11262918  0.02313546  0.09780689 -0.23336802\n",
      "  0.27159763  0.0032024  -0.31986339  0.34268189 -0.24441679 -0.21583905\n",
      "  0.09180722 -0.44495556]\n",
      "New theta_0 : [ 0.00631713 -0.08108245  0.11263227  0.02314408  0.09780525 -0.23337011\n",
      "  0.27159455  0.00320466 -0.31986377  0.34271178 -0.24444904 -0.21584048\n",
      "  0.09180691 -0.44495769]\n",
      "Training Error:  10.54345947134132\n",
      "====================================================================================================\n",
      "Iteration:  1264\n",
      "Previous theta :  [ 0.00631713 -0.08108245  0.11263227  0.02314408  0.09780525 -0.23337011\n",
      "  0.27159455  0.00320466 -0.31986377  0.34271178 -0.24444904 -0.21584048\n",
      "  0.09180691 -0.44495769]\n",
      "New theta_0 : [ 0.00631708 -0.08108554  0.11263535  0.02315268  0.09780361 -0.2333722\n",
      "  0.27159148  0.0032069  -0.31986415  0.34274159 -0.2444812  -0.21584191\n",
      "  0.09180661 -0.44495982]\n",
      "Training Error:  10.543457572670416\n",
      "====================================================================================================\n",
      "Iteration:  1265\n",
      "Previous theta :  [ 0.00631708 -0.08108554  0.11263535  0.02315268  0.09780361 -0.2333722\n",
      "  0.27159148  0.0032069  -0.31986415  0.34274159 -0.2444812  -0.21584191\n",
      "  0.09180661 -0.44495982]\n",
      "New theta_0 : [ 0.00631703 -0.08108862  0.11263841  0.02316126  0.09780198 -0.23337427\n",
      "  0.27158842  0.00320915 -0.31986453  0.34277132 -0.24451328 -0.21584334\n",
      "  0.09180631 -0.44496195]\n",
      "Training Error:  10.5434556839974\n",
      "====================================================================================================\n",
      "Iteration:  1266\n",
      "Previous theta :  [ 0.00631703 -0.08108862  0.11263841  0.02316126  0.09780198 -0.23337427\n",
      "  0.27158842  0.00320915 -0.31986453  0.34277132 -0.24451328 -0.21584334\n",
      "  0.09180631 -0.44496195]\n",
      "New theta_0 : [ 0.00631698 -0.08109169  0.11264147  0.02316981  0.09780035 -0.23337633\n",
      "  0.27158537  0.00321138 -0.3198649   0.34280097 -0.24454528 -0.21584476\n",
      "  0.091806   -0.44496407]\n",
      "Training Error:  10.54345380526929\n",
      "====================================================================================================\n",
      "Iteration:  1267\n",
      "Previous theta :  [ 0.00631698 -0.08109169  0.11264147  0.02316981  0.09780035 -0.23337633\n",
      "  0.27158537  0.00321138 -0.3198649   0.34280097 -0.24454528 -0.21584476\n",
      "  0.091806   -0.44496407]\n",
      "New theta_0 : [ 0.00631694 -0.08109475  0.11264452  0.02317834  0.09779872 -0.23337838\n",
      "  0.27158233  0.00321361 -0.31986526  0.34283054 -0.2445772  -0.21584617\n",
      "  0.0918057  -0.44496619]\n",
      "Training Error:  10.54345193643338\n",
      "====================================================================================================\n",
      "Iteration:  1268\n",
      "Previous theta :  [ 0.00631694 -0.08109475  0.11264452  0.02317834  0.09779872 -0.23337838\n",
      "  0.27158233  0.00321361 -0.31986526  0.34283054 -0.2445772  -0.21584617\n",
      "  0.0918057  -0.44496619]\n",
      "New theta_0 : [ 0.00631689 -0.08109781  0.11264756  0.02318685  0.0977971  -0.23338042\n",
      "  0.2715793   0.00321584 -0.31986561  0.34286004 -0.24460903 -0.21584758\n",
      "  0.09180541 -0.4449683 ]\n",
      "Training Error:  10.543450077437257\n",
      "====================================================================================================\n",
      "Iteration:  1269\n",
      "Previous theta :  [ 0.00631689 -0.08109781  0.11264756  0.02318685  0.0977971  -0.23338042\n",
      "  0.2715793   0.00321584 -0.31986561  0.34286004 -0.24460903 -0.21584758\n",
      "  0.09180541 -0.4449683 ]\n",
      "New theta_0 : [ 0.00631684 -0.08110085  0.11265059  0.02319534  0.09779549 -0.23338244\n",
      "  0.27157627  0.00321805 -0.31986596  0.34288945 -0.24464079 -0.21584899\n",
      "  0.09180511 -0.4449704 ]\n",
      "Training Error:  10.543448228228785\n",
      "====================================================================================================\n",
      "Iteration:  1270\n",
      "Previous theta :  [ 0.00631684 -0.08110085  0.11265059  0.02319534  0.09779549 -0.23338244\n",
      "  0.27157627  0.00321805 -0.31986596  0.34288945 -0.24464079 -0.21584899\n",
      "  0.09180511 -0.4449704 ]\n",
      "New theta_0 : [ 0.00631679 -0.08110388  0.11265362  0.0232038   0.09779387 -0.23338446\n",
      "  0.27157326  0.00322027 -0.31986631  0.34291879 -0.24467246 -0.21585039\n",
      "  0.09180481 -0.44497251]\n",
      "Training Error:  10.543446388756111\n",
      "====================================================================================================\n",
      "Iteration:  1271\n",
      "Previous theta :  [ 0.00631679 -0.08110388  0.11265362  0.0232038   0.09779387 -0.23338446\n",
      "  0.27157326  0.00322027 -0.31986631  0.34291879 -0.24467246 -0.21585039\n",
      "  0.09180481 -0.44497251]\n",
      "New theta_0 : [ 0.00631675 -0.0811069   0.11265663  0.02321224  0.09779227 -0.23338646\n",
      "  0.27157025  0.00322247 -0.31986664  0.34294805 -0.24470405 -0.21585178\n",
      "  0.09180452 -0.4449746 ]\n",
      "Training Error:  10.54344455896766\n",
      "====================================================================================================\n",
      "Iteration:  1272\n",
      "Previous theta :  [ 0.00631675 -0.0811069   0.11265663  0.02321224  0.09779227 -0.23338646\n",
      "  0.27157025  0.00322247 -0.31986664  0.34294805 -0.24470405 -0.21585178\n",
      "  0.09180452 -0.4449746 ]\n",
      "New theta_0 : [ 0.0063167  -0.08110992  0.11265963  0.02322066  0.09779066 -0.23338845\n",
      "  0.27156726  0.00322467 -0.31986698  0.34297723 -0.24473555 -0.21585317\n",
      "  0.09180423 -0.44497669]\n",
      "Training Error:  10.543442738812136\n",
      "====================================================================================================\n",
      "Iteration:  1273\n",
      "Previous theta :  [ 0.0063167  -0.08110992  0.11265963  0.02322066  0.09779066 -0.23338845\n",
      "  0.27156726  0.00322467 -0.31986698  0.34297723 -0.24473555 -0.21585317\n",
      "  0.09180423 -0.44497669]\n",
      "New theta_0 : [ 0.00631665 -0.08111292  0.11266262  0.02322906  0.09778906 -0.23339044\n",
      "  0.27156427  0.00322686 -0.3198673   0.34300633 -0.24476698 -0.21585455\n",
      "  0.09180393 -0.44497878]\n",
      "Training Error:  10.543440928238518\n",
      "====================================================================================================\n",
      "Iteration:  1274\n",
      "Previous theta :  [ 0.00631665 -0.08111292  0.11266262  0.02322906  0.09778906 -0.23339044\n",
      "  0.27156427  0.00322686 -0.3198673   0.34300633 -0.24476698 -0.21585455\n",
      "  0.09180393 -0.44497878]\n",
      "New theta_0 : [ 0.00631661 -0.08111592  0.11266561  0.02323744  0.09778747 -0.23339241\n",
      "  0.27156129  0.00322905 -0.31986762  0.34303535 -0.24479832 -0.21585593\n",
      "  0.09180364 -0.44498086]\n",
      "Training Error:  10.543439127196056\n",
      "====================================================================================================\n",
      "Iteration:  1275\n",
      "Previous theta :  [ 0.00631661 -0.08111592  0.11266561  0.02323744  0.09778747 -0.23339241\n",
      "  0.27156129  0.00322905 -0.31986762  0.34303535 -0.24479832 -0.21585593\n",
      "  0.09180364 -0.44498086]\n",
      "New theta_0 : [ 0.00631656 -0.0811189   0.11266858  0.02324579  0.09778588 -0.23339436\n",
      "  0.27155833  0.00323123 -0.31986793  0.3430643  -0.24482958 -0.21585731\n",
      "  0.09180335 -0.44498294]\n",
      "Training Error:  10.54343733563428\n",
      "====================================================================================================\n",
      "Iteration:  1276\n",
      "Previous theta :  [ 0.00631656 -0.0811189   0.11266858  0.02324579  0.09778588 -0.23339436\n",
      "  0.27155833  0.00323123 -0.31986793  0.3430643  -0.24482958 -0.21585731\n",
      "  0.09180335 -0.44498294]\n",
      "New theta_0 : [ 0.00631651 -0.08112188  0.11267155  0.02325413  0.09778429 -0.23339631\n",
      "  0.27155537  0.0032334  -0.31986824  0.34309317 -0.24486077 -0.21585868\n",
      "  0.09180307 -0.44498501]\n",
      "Training Error:  10.543435553502986\n",
      "====================================================================================================\n",
      "Iteration:  1277\n",
      "Previous theta :  [ 0.00631651 -0.08112188  0.11267155  0.02325413  0.09778429 -0.23339631\n",
      "  0.27155537  0.0032334  -0.31986824  0.34309317 -0.24486077 -0.21585868\n",
      "  0.09180307 -0.44498501]\n",
      "New theta_0 : [ 0.00631647 -0.08112484  0.11267451  0.02326244  0.09778271 -0.23339825\n",
      "  0.27155242  0.00323557 -0.31986854  0.34312197 -0.24489187 -0.21586004\n",
      "  0.09180278 -0.44498707]\n",
      "Training Error:  10.543433780752242\n",
      "====================================================================================================\n",
      "Iteration:  1278\n",
      "Previous theta :  [ 0.00631647 -0.08112484  0.11267451  0.02326244  0.09778271 -0.23339825\n",
      "  0.27155242  0.00323557 -0.31986854  0.34312197 -0.24489187 -0.21586004\n",
      "  0.09180278 -0.44498707]\n",
      "New theta_0 : [ 0.00631642 -0.0811278   0.11267746  0.02327073  0.09778113 -0.23340018\n",
      "  0.27154947  0.00323774 -0.31986884  0.34315068 -0.24492289 -0.2158614\n",
      "  0.09180249 -0.44498913]\n",
      "Training Error:  10.54343201733238\n",
      "====================================================================================================\n",
      "Iteration:  1279\n",
      "Previous theta :  [ 0.00631642 -0.0811278   0.11267746  0.02327073  0.09778113 -0.23340018\n",
      "  0.27154947  0.00323774 -0.31986884  0.34315068 -0.24492289 -0.2158614\n",
      "  0.09180249 -0.44498913]\n",
      "New theta_0 : [ 0.00631638 -0.08113075  0.11268039  0.02327899  0.09777956 -0.23340209\n",
      "  0.27154654  0.00323989 -0.31986913  0.34317932 -0.24495383 -0.21586275\n",
      "  0.09180221 -0.44499119]\n",
      "Training Error:  10.543430263194008\n",
      "====================================================================================================\n",
      "Iteration:  1280\n",
      "Previous theta :  [ 0.00631638 -0.08113075  0.11268039  0.02327899  0.09777956 -0.23340209\n",
      "  0.27154654  0.00323989 -0.31986913  0.34317932 -0.24495383 -0.21586275\n",
      "  0.09180221 -0.44499119]\n",
      "New theta_0 : [ 0.00631633 -0.08113368  0.11268332  0.02328724  0.09777799 -0.233404\n",
      "  0.27154362  0.00324204 -0.31986942  0.34320789 -0.24498469 -0.2158641\n",
      "  0.09180193 -0.44499324]\n",
      "Training Error:  10.54342851828799\n",
      "====================================================================================================\n",
      "Iteration:  1281\n",
      "Previous theta :  [ 0.00631633 -0.08113368  0.11268332  0.02328724  0.09777799 -0.233404\n",
      "  0.27154362  0.00324204 -0.31986942  0.34320789 -0.24498469 -0.2158641\n",
      "  0.09180193 -0.44499324]\n",
      "New theta_0 : [ 0.00631629 -0.08113661  0.11268624  0.02329546  0.09777642 -0.23340589\n",
      "  0.2715407   0.00324419 -0.31986969  0.34323637 -0.24501547 -0.21586545\n",
      "  0.09180165 -0.44499529]\n",
      "Training Error:  10.54342678256546\n",
      "====================================================================================================\n",
      "Iteration:  1282\n",
      "Previous theta :  [ 0.00631629 -0.08113661  0.11268624  0.02329546  0.09777642 -0.23340589\n",
      "  0.2715407   0.00324419 -0.31986969  0.34323637 -0.24501547 -0.21586545\n",
      "  0.09180165 -0.44499529]\n",
      "New theta_0 : [ 0.00631624 -0.08113953  0.11268916  0.02330366  0.09777486 -0.23340778\n",
      "  0.27153779  0.00324632 -0.31986997  0.34326479 -0.24504618 -0.21586679\n",
      "  0.09180137 -0.44499733]\n",
      "Training Error:  10.54342505597781\n",
      "====================================================================================================\n",
      "Iteration:  1283\n",
      "Previous theta :  [ 0.00631624 -0.08113953  0.11268916  0.02330366  0.09777486 -0.23340778\n",
      "  0.27153779  0.00324632 -0.31986997  0.34326479 -0.24504618 -0.21586679\n",
      "  0.09180137 -0.44499733]\n",
      "New theta_0 : [ 0.0063162  -0.08114244  0.11269206  0.02331184  0.0977733  -0.23340965\n",
      "  0.27153489  0.00324846 -0.31987024  0.34329312 -0.2450768  -0.21586812\n",
      "  0.09180109 -0.44499936]\n",
      "Training Error:  10.543423338476696\n",
      "====================================================================================================\n",
      "Iteration:  1284\n",
      "Previous theta :  [ 0.0063162  -0.08114244  0.11269206  0.02331184  0.0977733  -0.23340965\n",
      "  0.27153489  0.00324846 -0.31987024  0.34329312 -0.2450768  -0.21586812\n",
      "  0.09180109 -0.44499936]\n",
      "New theta_0 : [ 0.00631615 -0.08114534  0.11269495  0.02332     0.09777175 -0.23341151\n",
      "  0.27153201  0.00325058 -0.3198705   0.34332138 -0.24510734 -0.21586945\n",
      "  0.09180081 -0.4450014 ]\n",
      "Training Error:  10.543421630014034\n",
      "====================================================================================================\n",
      "Iteration:  1285\n",
      "Previous theta :  [ 0.00631615 -0.08114534  0.11269495  0.02332     0.09777175 -0.23341151\n",
      "  0.27153201  0.00325058 -0.3198705   0.34332138 -0.24510734 -0.21586945\n",
      "  0.09180081 -0.4450014 ]\n",
      "New theta_0 : [ 0.00631611 -0.08114823  0.11269784  0.02332814  0.0977702  -0.23341336\n",
      "  0.27152912  0.0032527  -0.31987076  0.34334957 -0.24513781 -0.21587078\n",
      "  0.09180053 -0.44500342]\n",
      "Training Error:  10.543419930541992\n",
      "====================================================================================================\n",
      "Iteration:  1286\n",
      "Previous theta :  [ 0.00631611 -0.08114823  0.11269784  0.02332814  0.0977702  -0.23341336\n",
      "  0.27152912  0.0032527  -0.31987076  0.34334957 -0.24513781 -0.21587078\n",
      "  0.09180053 -0.44500342]\n",
      "New theta_0 : [ 0.00631606 -0.08115112  0.11270071  0.02333626  0.09776865 -0.23341521\n",
      "  0.27152625  0.00325482 -0.31987101  0.34337768 -0.24516819 -0.2158721\n",
      "  0.09180026 -0.44500544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.543418240013006\n",
      "====================================================================================================\n",
      "Iteration:  1287\n",
      "Previous theta :  [ 0.00631606 -0.08115112  0.11270071  0.02333626  0.09776865 -0.23341521\n",
      "  0.27152625  0.00325482 -0.31987101  0.34337768 -0.24516819 -0.2158721\n",
      "  0.09180026 -0.44500544]\n",
      "New theta_0 : [ 0.00631602 -0.08115399  0.11270358  0.02334435  0.09776711 -0.23341704\n",
      "  0.27152339  0.00325693 -0.31987126  0.34340571 -0.2451985  -0.21587342\n",
      "  0.09179998 -0.44500746]\n",
      "Training Error:  10.543416558379754\n",
      "====================================================================================================\n",
      "Iteration:  1288\n",
      "Previous theta :  [ 0.00631602 -0.08115399  0.11270358  0.02334435  0.09776711 -0.23341704\n",
      "  0.27152339  0.00325693 -0.31987126  0.34340571 -0.2451985  -0.21587342\n",
      "  0.09179998 -0.44500746]\n",
      "New theta_0 : [ 0.00631597 -0.08115685  0.11270644  0.02335243  0.09776558 -0.23341886\n",
      "  0.27152053  0.00325903 -0.3198715   0.34343368 -0.24522873 -0.21587473\n",
      "  0.09179971 -0.44500947]\n",
      "Training Error:  10.543414885595176\n",
      "====================================================================================================\n",
      "Iteration:  1289\n",
      "Previous theta :  [ 0.00631597 -0.08115685  0.11270644  0.02335243  0.09776558 -0.23341886\n",
      "  0.27152053  0.00325903 -0.3198715   0.34343368 -0.24522873 -0.21587473\n",
      "  0.09179971 -0.44500947]\n",
      "New theta_0 : [ 0.00631593 -0.08115971  0.11270929  0.02336048  0.09776404 -0.23342067\n",
      "  0.27151769  0.00326113 -0.31987174  0.34346156 -0.24525888 -0.21587603\n",
      "  0.09179944 -0.44501148]\n",
      "Training Error:  10.543413221612465\n",
      "====================================================================================================\n",
      "Iteration:  1290\n",
      "Previous theta :  [ 0.00631593 -0.08115971  0.11270929  0.02336048  0.09776404 -0.23342067\n",
      "  0.27151769  0.00326113 -0.31987174  0.34346156 -0.24525888 -0.21587603\n",
      "  0.09179944 -0.44501148]\n",
      "New theta_0 : [ 0.00631588 -0.08116256  0.11271213  0.02336851  0.09776251 -0.23342248\n",
      "  0.27151485  0.00326322 -0.31987197  0.34348937 -0.24528895 -0.21587733\n",
      "  0.09179917 -0.44501348]\n",
      "Training Error:  10.54341156638506\n",
      "====================================================================================================\n",
      "Iteration:  1291\n",
      "Previous theta :  [ 0.00631588 -0.08116256  0.11271213  0.02336851  0.09776251 -0.23342248\n",
      "  0.27151485  0.00326322 -0.31987197  0.34348937 -0.24528895 -0.21587733\n",
      "  0.09179917 -0.44501348]\n",
      "New theta_0 : [ 0.00631584 -0.08116539  0.11271496  0.02337652  0.09776099 -0.23342427\n",
      "  0.27151202  0.0032653  -0.3198722   0.34351711 -0.24531895 -0.21587863\n",
      "  0.0917989  -0.44501548]\n",
      "Training Error:  10.543409919866653\n",
      "====================================================================================================\n",
      "Iteration:  1292\n",
      "Previous theta :  [ 0.00631584 -0.08116539  0.11271496  0.02337652  0.09776099 -0.23342427\n",
      "  0.27151202  0.0032653  -0.3198722   0.34351711 -0.24531895 -0.21587863\n",
      "  0.0917989  -0.44501548]\n",
      "New theta_0 : [ 0.0063158  -0.08116822  0.11271779  0.02338451  0.09775947 -0.23342605\n",
      "  0.2715092   0.00326738 -0.31987242  0.34354478 -0.24534886 -0.21587992\n",
      "  0.09179863 -0.44501747]\n",
      "Training Error:  10.543408282011184\n",
      "====================================================================================================\n",
      "Iteration:  1293\n",
      "Previous theta :  [ 0.0063158  -0.08116822  0.11271779  0.02338451  0.09775947 -0.23342605\n",
      "  0.2715092   0.00326738 -0.31987242  0.34354478 -0.24534886 -0.21587992\n",
      "  0.09179863 -0.44501747]\n",
      "New theta_0 : [ 0.00631575 -0.08117104  0.1127206   0.02339248  0.09775795 -0.23342782\n",
      "  0.27150639  0.00326946 -0.31987264  0.34357237 -0.2453787  -0.21588121\n",
      "  0.09179837 -0.44501946]\n",
      "Training Error:  10.543406652772836\n",
      "====================================================================================================\n",
      "Iteration:  1294\n",
      "Previous theta :  [ 0.00631575 -0.08117104  0.1127206   0.02339248  0.09775795 -0.23342782\n",
      "  0.27150639  0.00326946 -0.31987264  0.34357237 -0.2453787  -0.21588121\n",
      "  0.09179837 -0.44501946]\n",
      "New theta_0 : [ 0.00631571 -0.08117385  0.11272341  0.02340043  0.09775644 -0.23342959\n",
      "  0.27150358  0.00327152 -0.31987285  0.34359988 -0.24540847 -0.2158825\n",
      "  0.0917981  -0.44502144]\n",
      "Training Error:  10.543405032106042\n",
      "====================================================================================================\n",
      "Iteration:  1295\n",
      "Previous theta :  [ 0.00631571 -0.08117385  0.11272341  0.02340043  0.09775644 -0.23342959\n",
      "  0.27150358  0.00327152 -0.31987285  0.34359988 -0.24540847 -0.2158825\n",
      "  0.0917981  -0.44502144]\n",
      "New theta_0 : [ 0.00631567 -0.08117666  0.11272621  0.02340836  0.09775493 -0.23343134\n",
      "  0.27150078  0.00327358 -0.31987305  0.34362733 -0.24543815 -0.21588377\n",
      "  0.09179784 -0.44502342]\n",
      "Training Error:  10.543403419965482\n",
      "====================================================================================================\n",
      "Iteration:  1296\n",
      "Previous theta :  [ 0.00631567 -0.08117666  0.11272621  0.02340836  0.09775493 -0.23343134\n",
      "  0.27150078  0.00327358 -0.31987305  0.34362733 -0.24543815 -0.21588377\n",
      "  0.09179784 -0.44502342]\n",
      "New theta_0 : [ 0.00631563 -0.08117945  0.112729    0.02341626  0.09775342 -0.23343308\n",
      "  0.271498    0.00327564 -0.31987326  0.3436547  -0.24546776 -0.21588505\n",
      "  0.09179758 -0.4450254 ]\n",
      "Training Error:  10.543401816306067\n",
      "====================================================================================================\n",
      "Iteration:  1297\n",
      "Previous theta :  [ 0.00631563 -0.08117945  0.112729    0.02341626  0.09775342 -0.23343308\n",
      "  0.271498    0.00327564 -0.31987326  0.3436547  -0.24546776 -0.21588505\n",
      "  0.09179758 -0.4450254 ]\n",
      "New theta_0 : [ 0.00631558 -0.08118223  0.11273178  0.02342415  0.09775192 -0.23343482\n",
      "  0.27149522  0.00327769 -0.31987345  0.343682   -0.24549729 -0.21588632\n",
      "  0.09179731 -0.44502737]\n",
      "Training Error:  10.543400221082964\n",
      "====================================================================================================\n",
      "Iteration:  1298\n",
      "Previous theta :  [ 0.00631558 -0.08118223  0.11273178  0.02342415  0.09775192 -0.23343482\n",
      "  0.27149522  0.00327769 -0.31987345  0.343682   -0.24549729 -0.21588632\n",
      "  0.09179731 -0.44502737]\n",
      "New theta_0 : [ 0.00631554 -0.08118501  0.11273455  0.02343201  0.09775042 -0.23343654\n",
      "  0.27149245  0.00327974 -0.31987365  0.34370922 -0.24552675 -0.21588758\n",
      "  0.09179705 -0.44502933]\n",
      "Training Error:  10.543398634251567\n",
      "====================================================================================================\n",
      "Iteration:  1299\n",
      "Previous theta :  [ 0.00631554 -0.08118501  0.11273455  0.02343201  0.09775042 -0.23343654\n",
      "  0.27149245  0.00327974 -0.31987365  0.34370922 -0.24552675 -0.21588758\n",
      "  0.09179705 -0.44502933]\n",
      "New theta_0 : [ 0.0063155  -0.08118778  0.11273732  0.02343986  0.09774893 -0.23343825\n",
      "  0.27148968  0.00328178 -0.31987383  0.34373638 -0.24555613 -0.21588884\n",
      "  0.09179679 -0.44503129]\n",
      "Training Error:  10.543397055767516\n",
      "====================================================================================================\n",
      "Iteration:  1300\n",
      "Previous theta :  [ 0.0063155  -0.08118778  0.11273732  0.02343986  0.09774893 -0.23343825\n",
      "  0.27148968  0.00328178 -0.31987383  0.34373638 -0.24555613 -0.21588884\n",
      "  0.09179679 -0.44503129]\n",
      "New theta_0 : [ 0.00631546 -0.08119053  0.11274007  0.02344768  0.09774744 -0.23343996\n",
      "  0.27148693  0.00328381 -0.31987402  0.34376346 -0.24558543 -0.2158901\n",
      "  0.09179654 -0.44503324]\n",
      "Training Error:  10.54339548558669\n",
      "====================================================================================================\n",
      "Iteration:  1301\n",
      "Previous theta :  [ 0.00631546 -0.08119053  0.11274007  0.02344768  0.09774744 -0.23343996\n",
      "  0.27148693  0.00328381 -0.31987402  0.34376346 -0.24558543 -0.2158901\n",
      "  0.09179654 -0.44503324]\n",
      "New theta_0 : [ 0.00631541 -0.08119328  0.11274282  0.02345548  0.09774596 -0.23344166\n",
      "  0.27148418  0.00328584 -0.3198742   0.34379047 -0.24561466 -0.21589135\n",
      "  0.09179628 -0.44503519]\n",
      "Training Error:  10.543393923665198\n",
      "====================================================================================================\n",
      "Iteration:  1302\n",
      "Previous theta :  [ 0.00631541 -0.08119328  0.11274282  0.02345548  0.09774596 -0.23344166\n",
      "  0.27148418  0.00328584 -0.3198742   0.34379047 -0.24561466 -0.21589135\n",
      "  0.09179628 -0.44503519]\n",
      "New theta_0 : [ 0.00631537 -0.08119603  0.11274556  0.02346326  0.09774447 -0.23344334\n",
      "  0.27148144  0.00328786 -0.31987437  0.3438174  -0.24564381 -0.2158926\n",
      "  0.09179602 -0.44503714]\n",
      "Training Error:  10.543392369959387\n",
      "====================================================================================================\n",
      "Iteration:  1303\n",
      "Previous theta :  [ 0.00631537 -0.08119603  0.11274556  0.02346326  0.09774447 -0.23344334\n",
      "  0.27148144  0.00328786 -0.31987437  0.3438174  -0.24564381 -0.2158926\n",
      "  0.09179602 -0.44503714]\n",
      "New theta_0 : [ 0.00631533 -0.08119876  0.11274829  0.02347103  0.097743   -0.23344502\n",
      "  0.27147871  0.00328988 -0.31987454  0.34384427 -0.24567289 -0.21589384\n",
      "  0.09179577 -0.44503908]\n",
      "Training Error:  10.543390824425838\n",
      "====================================================================================================\n",
      "Iteration:  1304\n",
      "Previous theta :  [ 0.00631533 -0.08119876  0.11274829  0.02347103  0.097743   -0.23344502\n",
      "  0.27147871  0.00328988 -0.31987454  0.34384427 -0.24567289 -0.21589384\n",
      "  0.09179577 -0.44503908]\n",
      "New theta_0 : [ 0.00631529 -0.08120148  0.11275101  0.02347877  0.09774152 -0.23344669\n",
      "  0.27147599  0.00329189 -0.3198747   0.34387106 -0.24570189 -0.21589508\n",
      "  0.09179551 -0.44504101]\n",
      "Training Error:  10.543389287021364\n",
      "====================================================================================================\n",
      "Iteration:  1305\n",
      "Previous theta :  [ 0.00631529 -0.08120148  0.11275101  0.02347877  0.09774152 -0.23344669\n",
      "  0.27147599  0.00329189 -0.3198747   0.34387106 -0.24570189 -0.21589508\n",
      "  0.09179551 -0.44504101]\n",
      "New theta_0 : [ 0.00631525 -0.0812042   0.11275373  0.02348649  0.09774005 -0.23344835\n",
      "  0.27147328  0.00329389 -0.31987486  0.34389778 -0.24573081 -0.21589631\n",
      "  0.09179526 -0.44504295]\n",
      "Training Error:  10.54338775770301\n",
      "====================================================================================================\n",
      "Iteration:  1306\n",
      "Previous theta :  [ 0.00631525 -0.0812042   0.11275373  0.02348649  0.09774005 -0.23344835\n",
      "  0.27147328  0.00329389 -0.31987486  0.34389778 -0.24573081 -0.21589631\n",
      "  0.09179526 -0.44504295]\n",
      "New theta_0 : [ 0.00631521 -0.08120691  0.11275643  0.02349419  0.09773859 -0.23345\n",
      "  0.27147057  0.00329589 -0.31987502  0.34392443 -0.24575967 -0.21589754\n",
      "  0.09179501 -0.44504487]\n",
      "Training Error:  10.543386236428047\n",
      "====================================================================================================\n",
      "Iteration:  1307\n",
      "Previous theta :  [ 0.00631521 -0.08120691  0.11275643  0.02349419  0.09773859 -0.23345\n",
      "  0.27147057  0.00329589 -0.31987502  0.34392443 -0.24575967 -0.21589754\n",
      "  0.09179501 -0.44504487]\n",
      "New theta_0 : [ 0.00631516 -0.08120961  0.11275913  0.02350187  0.09773712 -0.23345164\n",
      "  0.27146787  0.00329789 -0.31987517  0.34395101 -0.24578844 -0.21589877\n",
      "  0.09179476 -0.44504679]\n",
      "Training Error:  10.543384723153977\n",
      "====================================================================================================\n",
      "Iteration:  1308\n",
      "Previous theta :  [ 0.00631516 -0.08120961  0.11275913  0.02350187  0.09773712 -0.23345164\n",
      "  0.27146787  0.00329789 -0.31987517  0.34395101 -0.24578844 -0.21589877\n",
      "  0.09179476 -0.44504679]\n",
      "New theta_0 : [ 0.00631512 -0.0812123   0.11276182  0.02350953  0.09773567 -0.23345327\n",
      "  0.27146518  0.00329988 -0.31987532  0.34397752 -0.24581715 -0.21589999\n",
      "  0.09179451 -0.44504871]\n",
      "Training Error:  10.543383217838532\n",
      "====================================================================================================\n",
      "Iteration:  1309\n",
      "Previous theta :  [ 0.00631512 -0.0812123   0.11276182  0.02350953  0.09773567 -0.23345327\n",
      "  0.27146518  0.00329988 -0.31987532  0.34397752 -0.24581715 -0.21589999\n",
      "  0.09179451 -0.44504871]\n",
      "New theta_0 : [ 0.00631508 -0.08121498  0.1127645   0.02351717  0.09773421 -0.23345489\n",
      "  0.2714625   0.00330186 -0.31987546  0.34400396 -0.24584577 -0.21590121\n",
      "  0.09179426 -0.44505062]\n",
      "Training Error:  10.543381720439662\n",
      "====================================================================================================\n",
      "Iteration:  1310\n",
      "Previous theta :  [ 0.00631508 -0.08121498  0.1127645   0.02351717  0.09773421 -0.23345489\n",
      "  0.2714625   0.00330186 -0.31987546  0.34400396 -0.24584577 -0.21590121\n",
      "  0.09179426 -0.44505062]\n",
      "New theta_0 : [ 0.00631504 -0.08121765  0.11276718  0.02352479  0.09773276 -0.23345651\n",
      "  0.27145983  0.00330384 -0.3198756   0.34403033 -0.24587433 -0.21590242\n",
      "  0.09179402 -0.44505253]\n",
      "Training Error:  10.543380230915549\n",
      "====================================================================================================\n",
      "Iteration:  1311\n",
      "Previous theta :  [ 0.00631504 -0.08121765  0.11276718  0.02352479  0.09773276 -0.23345651\n",
      "  0.27145983  0.00330384 -0.3198756   0.34403033 -0.24587433 -0.21590242\n",
      "  0.09179402 -0.44505253]\n",
      "New theta_0 : [ 0.006315   -0.08122032  0.11276984  0.02353239  0.09773131 -0.23345811\n",
      "  0.27145716  0.00330581 -0.31987574  0.34405663 -0.24590281 -0.21590363\n",
      "  0.09179377 -0.44505443]\n",
      "Training Error:  10.543378749224596\n",
      "====================================================================================================\n",
      "Iteration:  1312\n",
      "Previous theta :  [ 0.006315   -0.08122032  0.11276984  0.02353239  0.09773131 -0.23345811\n",
      "  0.27145716  0.00330581 -0.31987574  0.34405663 -0.24590281 -0.21590363\n",
      "  0.09179377 -0.44505443]\n",
      "New theta_0 : [ 0.00631496 -0.08122298  0.1127725   0.02353997  0.09772987 -0.23345971\n",
      "  0.2714545   0.00330778 -0.31987587  0.34408286 -0.24593121 -0.21590483\n",
      "  0.09179352 -0.44505633]\n",
      "Training Error:  10.543377275325428\n",
      "====================================================================================================\n",
      "Iteration:  1313\n",
      "Previous theta :  [ 0.00631496 -0.08122298  0.1127725   0.02353997  0.09772987 -0.23345971\n",
      "  0.2714545   0.00330778 -0.31987587  0.34408286 -0.24593121 -0.21590483\n",
      "  0.09179352 -0.44505633]\n",
      "New theta_0 : [ 0.00631492 -0.08122563  0.11277515  0.02354753  0.09772843 -0.2334613\n",
      "  0.27145185  0.00330974 -0.31987599  0.34410902 -0.24595954 -0.21590603\n",
      "  0.09179328 -0.44505823]\n",
      "Training Error:  10.54337580917689\n",
      "====================================================================================================\n",
      "Iteration:  1314\n",
      "Previous theta :  [ 0.00631492 -0.08122563  0.11277515  0.02354753  0.09772843 -0.2334613\n",
      "  0.27145185  0.00330974 -0.31987599  0.34410902 -0.24595954 -0.21590603\n",
      "  0.09179328 -0.44505823]\n",
      "New theta_0 : [ 0.00631488 -0.08122827  0.11277779  0.02355508  0.09772699 -0.23346288\n",
      "  0.27144921  0.00331169 -0.31987612  0.34413511 -0.2459878  -0.21590723\n",
      "  0.09179304 -0.44506011]\n",
      "Training Error:  10.543374350738048\n",
      "====================================================================================================\n",
      "Iteration:  1315\n",
      "Previous theta :  [ 0.00631488 -0.08122827  0.11277779  0.02355508  0.09772699 -0.23346288\n",
      "  0.27144921  0.00331169 -0.31987612  0.34413511 -0.2459878  -0.21590723\n",
      "  0.09179304 -0.44506011]\n",
      "New theta_0 : [ 0.00631484 -0.0812309   0.11278043  0.0235626   0.09772556 -0.23346445\n",
      "  0.27144657  0.00331364 -0.31987623  0.34416113 -0.24601599 -0.21590842\n",
      "  0.0917928  -0.445062  ]\n",
      "Training Error:  10.543372899968189\n",
      "====================================================================================================\n",
      "Iteration:  1316\n",
      "Previous theta :  [ 0.00631484 -0.0812309   0.11278043  0.0235626   0.09772556 -0.23346445\n",
      "  0.27144657  0.00331364 -0.31987623  0.34416113 -0.24601599 -0.21590842\n",
      "  0.0917928  -0.445062  ]\n",
      "New theta_0 : [ 0.0063148  -0.08123352  0.11278305  0.0235701   0.09772414 -0.23346601\n",
      "  0.27144394  0.00331559 -0.31987635  0.34418708 -0.2460441  -0.2159096\n",
      "  0.09179256 -0.44506388]\n",
      "Training Error:  10.543371456826813\n",
      "====================================================================================================\n",
      "Iteration:  1317\n",
      "Previous theta :  [ 0.0063148  -0.08123352  0.11278305  0.0235701   0.09772414 -0.23346601\n",
      "  0.27144394  0.00331559 -0.31987635  0.34418708 -0.2460441  -0.2159096\n",
      "  0.09179256 -0.44506388]\n",
      "New theta_0 : [ 0.00631476 -0.08123614  0.11278567  0.02357758  0.09772271 -0.23346757\n",
      "  0.27144133  0.00331753 -0.31987646  0.34421296 -0.24607214 -0.21591079\n",
      "  0.09179232 -0.44506576]\n",
      "Training Error:  10.543370021273637\n",
      "====================================================================================================\n",
      "Iteration:  1318\n",
      "Previous theta :  [ 0.00631476 -0.08123614  0.11278567  0.02357758  0.09772271 -0.23346757\n",
      "  0.27144133  0.00331753 -0.31987646  0.34421296 -0.24607214 -0.21591079\n",
      "  0.09179232 -0.44506576]\n",
      "New theta_0 : [ 0.00631472 -0.08123875  0.11278828  0.02358504  0.09772129 -0.23346911\n",
      "  0.27143871  0.00331946 -0.31987656  0.34423877 -0.24610011 -0.21591197\n",
      "  0.09179208 -0.44506763]\n",
      "Training Error:  10.543368593268593\n",
      "====================================================================================================\n",
      "Iteration:  1319\n",
      "Previous theta :  [ 0.00631472 -0.08123875  0.11278828  0.02358504  0.09772129 -0.23346911\n",
      "  0.27143871  0.00331946 -0.31987656  0.34423877 -0.24610011 -0.21591197\n",
      "  0.09179208 -0.44506763]\n",
      "New theta_0 : [ 0.00631468 -0.08124135  0.11279088  0.02359248  0.09771987 -0.23347065\n",
      "  0.27143611  0.00332139 -0.31987667  0.34426452 -0.246128   -0.21591314\n",
      "  0.09179184 -0.44506949]\n",
      "Training Error:  10.54336717277183\n",
      "====================================================================================================\n",
      "Iteration:  1320\n",
      "Previous theta :  [ 0.00631468 -0.08124135  0.11279088  0.02359248  0.09771987 -0.23347065\n",
      "  0.27143611  0.00332139 -0.31987667  0.34426452 -0.246128   -0.21591314\n",
      "  0.09179184 -0.44506949]\n",
      "New theta_0 : [ 0.00631464 -0.08124394  0.11279348  0.02359991  0.09771846 -0.23347218\n",
      "  0.27143351  0.00332331 -0.31987676  0.3442902  -0.24615583 -0.21591431\n",
      "  0.0917916  -0.44507135]\n",
      "Training Error:  10.543365759743708\n",
      "====================================================================================================\n",
      "Iteration:  1321\n",
      "Previous theta :  [ 0.00631464 -0.08124394  0.11279348  0.02359991  0.09771846 -0.23347218\n",
      "  0.27143351  0.00332331 -0.31987676  0.3442902  -0.24615583 -0.21591431\n",
      "  0.0917916  -0.44507135]\n",
      "New theta_0 : [ 0.0063146  -0.08124653  0.11279606  0.02360731  0.09771705 -0.2334737\n",
      "  0.27143092  0.00332523 -0.31987686  0.3443158  -0.24618358 -0.21591548\n",
      "  0.09179137 -0.44507321]\n",
      "Training Error:  10.543364354144797\n",
      "====================================================================================================\n",
      "Iteration:  1322\n",
      "Previous theta :  [ 0.0063146  -0.08124653  0.11279606  0.02360731  0.09771705 -0.2334737\n",
      "  0.27143092  0.00332523 -0.31987686  0.3443158  -0.24618358 -0.21591548\n",
      "  0.09179137 -0.44507321]\n",
      "New theta_0 : [ 0.00631456 -0.0812491   0.11279864  0.02361469  0.09771565 -0.23347521\n",
      "  0.27142834  0.00332715 -0.31987695  0.34434134 -0.24621126 -0.21591664\n",
      "  0.09179113 -0.44507506]\n",
      "Training Error:  10.543362955935876\n",
      "====================================================================================================\n",
      "Iteration:  1323\n",
      "Previous theta :  [ 0.00631456 -0.0812491   0.11279864  0.02361469  0.09771565 -0.23347521\n",
      "  0.27142834  0.00332715 -0.31987695  0.34434134 -0.24621126 -0.21591664\n",
      "  0.09179113 -0.44507506]\n",
      "New theta_0 : [ 0.00631453 -0.08125167  0.11280122  0.02362206  0.09771424 -0.23347672\n",
      "  0.27142577  0.00332905 -0.31987704  0.34436682 -0.24623886 -0.2159178\n",
      "  0.0917909  -0.44507691]\n",
      "Training Error:  10.543361565077939\n",
      "====================================================================================================\n",
      "Iteration:  1324\n",
      "Previous theta :  [ 0.00631453 -0.08125167  0.11280122  0.02362206  0.09771424 -0.23347672\n",
      "  0.27142577  0.00332905 -0.31987704  0.34436682 -0.24623886 -0.2159178\n",
      "  0.0917909  -0.44507691]\n",
      "New theta_0 : [ 0.00631449 -0.08125423  0.11280378  0.0236294   0.09771284 -0.23347821\n",
      "  0.2714232   0.00333096 -0.31987712  0.34439222 -0.2462664  -0.21591895\n",
      "  0.09179067 -0.44507876]\n",
      "Training Error:  10.543360181532181\n",
      "====================================================================================================\n",
      "Iteration:  1325\n",
      "Previous theta :  [ 0.00631449 -0.08125423  0.11280378  0.0236294   0.09771284 -0.23347821\n",
      "  0.2714232   0.00333096 -0.31987712  0.34439222 -0.2462664  -0.21591895\n",
      "  0.09179067 -0.44507876]\n",
      "New theta_0 : [ 0.00631445 -0.08125678  0.11280633  0.02363673  0.09771145 -0.2334797\n",
      "  0.27142064  0.00333285 -0.3198772   0.34441756 -0.24629386 -0.2159201\n",
      "  0.09179044 -0.4450806 ]\n",
      "Training Error:  10.543358805260011\n",
      "====================================================================================================\n",
      "Iteration:  1326\n",
      "Previous theta :  [ 0.00631445 -0.08125678  0.11280633  0.02363673  0.09771145 -0.2334797\n",
      "  0.27142064  0.00333285 -0.3198772   0.34441756 -0.24629386 -0.2159201\n",
      "  0.09179044 -0.4450806 ]\n",
      "New theta_0 : [ 0.00631441 -0.08125933  0.11280888  0.02364404  0.09771006 -0.23348118\n",
      "  0.27141809  0.00333474 -0.31987727  0.34444283 -0.24632126 -0.21592125\n",
      "  0.09179021 -0.44508243]\n",
      "Training Error:  10.543357436223035\n",
      "====================================================================================================\n",
      "Iteration:  1327\n",
      "Previous theta :  [ 0.00631441 -0.08125933  0.11280888  0.02364404  0.09771006 -0.23348118\n",
      "  0.27141809  0.00333474 -0.31987727  0.34444283 -0.24632126 -0.21592125\n",
      "  0.09179021 -0.44508243]\n",
      "New theta_0 : [ 0.00631437 -0.08126187  0.11281142  0.02365132  0.09770867 -0.23348266\n",
      "  0.27141555  0.00333663 -0.31987735  0.34446803 -0.24634858 -0.21592239\n",
      "  0.09178998 -0.44508426]\n",
      "Training Error:  10.543356074383071\n",
      "====================================================================================================\n",
      "Iteration:  1328\n",
      "Previous theta :  [ 0.00631437 -0.08126187  0.11281142  0.02365132  0.09770867 -0.23348266\n",
      "  0.27141555  0.00333663 -0.31987735  0.34446803 -0.24634858 -0.21592239\n",
      "  0.09178998 -0.44508426]\n",
      "New theta_0 : [ 0.00631433 -0.0812644   0.11281396  0.02365859  0.09770729 -0.23348412\n",
      "  0.27141301  0.00333851 -0.31987741  0.34449316 -0.24637583 -0.21592353\n",
      "  0.09178975 -0.44508609]\n",
      "Training Error:  10.54335471970214\n",
      "====================================================================================================\n",
      "Iteration:  1329\n",
      "Previous theta :  [ 0.00631433 -0.0812644   0.11281396  0.02365859  0.09770729 -0.23348412\n",
      "  0.27141301  0.00333851 -0.31987741  0.34449316 -0.24637583 -0.21592353\n",
      "  0.09178975 -0.44508609]\n",
      "New theta_0 : [ 0.0063143  -0.08126692  0.11281648  0.02366584  0.09770591 -0.23348558\n",
      "  0.27141048  0.00334039 -0.31987748  0.34451823 -0.24640301 -0.21592467\n",
      "  0.09178952 -0.44508791]\n",
      "Training Error:  10.543353372142464\n",
      "====================================================================================================\n",
      "Iteration:  1330\n",
      "Previous theta :  [ 0.0063143  -0.08126692  0.11281648  0.02366584  0.09770591 -0.23348558\n",
      "  0.27141048  0.00334039 -0.31987748  0.34451823 -0.24640301 -0.21592467\n",
      "  0.09178952 -0.44508791]\n",
      "New theta_0 : [ 0.00631426 -0.08126943  0.112819    0.02367307  0.09770453 -0.23348703\n",
      "  0.27140796  0.00334226 -0.31987754  0.34454323 -0.24643012 -0.2159258\n",
      "  0.09178929 -0.44508972]\n",
      "Training Error:  10.54335203166646\n",
      "====================================================================================================\n",
      "Iteration:  1331\n",
      "Previous theta :  [ 0.00631426 -0.08126943  0.112819    0.02367307  0.09770453 -0.23348703\n",
      "  0.27140796  0.00334226 -0.31987754  0.34454323 -0.24643012 -0.2159258\n",
      "  0.09178929 -0.44508972]\n",
      "New theta_0 : [ 0.00631422 -0.08127194  0.11282151  0.02368028  0.09770316 -0.23348847\n",
      "  0.27140545  0.00334413 -0.3198776   0.34456817 -0.24645716 -0.21592692\n",
      "  0.09178907 -0.44509154]\n",
      "Training Error:  10.543350698236758\n",
      "====================================================================================================\n",
      "Iteration:  1332\n",
      "Previous theta :  [ 0.00631422 -0.08127194  0.11282151  0.02368028  0.09770316 -0.23348847\n",
      "  0.27140545  0.00334413 -0.3198776   0.34456817 -0.24645716 -0.21592692\n",
      "  0.09178907 -0.44509154]\n",
      "New theta_0 : [ 0.00631418 -0.08127444  0.11282401  0.02368747  0.09770179 -0.2334899\n",
      "  0.27140294  0.00334599 -0.31987765  0.34459304 -0.24648413 -0.21592805\n",
      "  0.09178884 -0.44509335]\n",
      "Training Error:  10.543349371816173\n",
      "====================================================================================================\n",
      "Iteration:  1333\n",
      "Previous theta :  [ 0.00631418 -0.08127444  0.11282401  0.02368747  0.09770179 -0.2334899\n",
      "  0.27140294  0.00334599 -0.31987765  0.34459304 -0.24648413 -0.21592805\n",
      "  0.09178884 -0.44509335]\n",
      "New theta_0 : [ 0.00631415 -0.08127693  0.11282651  0.02369465  0.09770042 -0.23349133\n",
      "  0.27140044  0.00334784 -0.3198777   0.34461784 -0.24651103 -0.21592917\n",
      "  0.09178862 -0.44509515]\n",
      "Training Error:  10.543348052367731\n",
      "====================================================================================================\n",
      "Iteration:  1334\n",
      "Previous theta :  [ 0.00631415 -0.08127693  0.11282651  0.02369465  0.09770042 -0.23349133\n",
      "  0.27140044  0.00334784 -0.3198777   0.34461784 -0.24651103 -0.21592917\n",
      "  0.09178862 -0.44509515]\n",
      "New theta_0 : [ 0.00631411 -0.08127941  0.112829    0.0237018   0.09769906 -0.23349275\n",
      "  0.27139795  0.00334969 -0.31987775  0.34464258 -0.24653786 -0.21593028\n",
      "  0.0917884  -0.44509695]\n",
      "Training Error:  10.543346739854647\n",
      "====================================================================================================\n",
      "Iteration:  1335\n",
      "Previous theta :  [ 0.00631411 -0.08127941  0.112829    0.0237018   0.09769906 -0.23349275\n",
      "  0.27139795  0.00334969 -0.31987775  0.34464258 -0.24653786 -0.21593028\n",
      "  0.0917884  -0.44509695]\n",
      "New theta_0 : [ 0.00631407 -0.08128189  0.11283148  0.02370894  0.0976977  -0.23349416\n",
      "  0.27139547  0.00335154 -0.3198778   0.34466725 -0.24656462 -0.21593139\n",
      "  0.09178818 -0.44509874]\n",
      "Training Error:  10.543345434240333\n",
      "====================================================================================================\n",
      "Iteration:  1336\n",
      "Previous theta :  [ 0.00631407 -0.08128189  0.11283148  0.02370894  0.0976977  -0.23349416\n",
      "  0.27139547  0.00335154 -0.3198778   0.34466725 -0.24656462 -0.21593139\n",
      "  0.09178818 -0.44509874]\n",
      "New theta_0 : [ 0.00631403 -0.08128435  0.11283395  0.02371605  0.09769635 -0.23349556\n",
      "  0.27139299  0.00335338 -0.31987784  0.34469186 -0.24659131 -0.2159325\n",
      "  0.09178796 -0.44510053]\n",
      "Training Error:  10.543344135488399\n",
      "====================================================================================================\n",
      "Iteration:  1337\n",
      "Previous theta :  [ 0.00631403 -0.08128435  0.11283395  0.02371605  0.09769635 -0.23349556\n",
      "  0.27139299  0.00335338 -0.31987784  0.34469186 -0.24659131 -0.2159325\n",
      "  0.09178796 -0.44510053]\n",
      "New theta_0 : [ 0.006314   -0.08128681  0.11283642  0.02372315  0.097695   -0.23349695\n",
      "  0.27139052  0.00335521 -0.31987788  0.3447164  -0.24661793 -0.2159336\n",
      "  0.09178774 -0.44510232]\n",
      "Training Error:  10.543342843562645\n",
      "====================================================================================================\n",
      "Iteration:  1338\n",
      "Previous theta :  [ 0.006314   -0.08128681  0.11283642  0.02372315  0.097695   -0.23349695\n",
      "  0.27139052  0.00335521 -0.31987788  0.3447164  -0.24661793 -0.2159336\n",
      "  0.09178774 -0.44510232]\n",
      "New theta_0 : [ 0.00631396 -0.08128927  0.11283887  0.02373023  0.09769365 -0.23349834\n",
      "  0.27138805  0.00335704 -0.31987791  0.34474087 -0.24664448 -0.2159347\n",
      "  0.09178752 -0.4451041 ]\n",
      "Training Error:  10.543341558427064\n",
      "====================================================================================================\n",
      "Iteration:  1339\n",
      "Previous theta :  [ 0.00631396 -0.08128927  0.11283887  0.02373023  0.09769365 -0.23349834\n",
      "  0.27138805  0.00335704 -0.31987791  0.34474087 -0.24664448 -0.2159347\n",
      "  0.09178752 -0.4451041 ]\n",
      "New theta_0 : [ 0.00631392 -0.08129171  0.11284133  0.02373729  0.09769231 -0.23349972\n",
      "  0.2713856   0.00335887 -0.31987794  0.34476528 -0.24667097 -0.2159358\n",
      "  0.0917873  -0.44510588]\n",
      "Training Error:  10.543340280045843\n",
      "====================================================================================================\n",
      "Iteration:  1340\n",
      "Previous theta :  [ 0.00631392 -0.08129171  0.11284133  0.02373729  0.09769231 -0.23349972\n",
      "  0.2713856   0.00335887 -0.31987794  0.34476528 -0.24667097 -0.2159358\n",
      "  0.0917873  -0.44510588]\n",
      "New theta_0 : [ 0.00631389 -0.08129415  0.11284377  0.02374434  0.09769097 -0.2335011\n",
      "  0.27138315  0.00336069 -0.31987797  0.34478963 -0.24669738 -0.21593689\n",
      "  0.09178708 -0.44510765]\n",
      "Training Error:  10.54333900838336\n",
      "====================================================================================================\n",
      "Iteration:  1341\n",
      "Previous theta :  [ 0.00631389 -0.08129415  0.11284377  0.02374434  0.09769097 -0.2335011\n",
      "  0.27138315  0.00336069 -0.31987797  0.34478963 -0.24669738 -0.21593689\n",
      "  0.09178708 -0.44510765]\n",
      "New theta_0 : [ 0.00631385 -0.08129658  0.11284621  0.02375136  0.09768963 -0.23350246\n",
      "  0.27138071  0.0033625  -0.31987799  0.34481391 -0.24672373 -0.21593798\n",
      "  0.09178687 -0.44510942]\n",
      "Training Error:  10.543337743404175\n",
      "====================================================================================================\n",
      "Iteration:  1342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous theta :  [ 0.00631385 -0.08129658  0.11284621  0.02375136  0.09768963 -0.23350246\n",
      "  0.27138071  0.0033625  -0.31987799  0.34481391 -0.24672373 -0.21593798\n",
      "  0.09178687 -0.44510942]\n",
      "New theta_0 : [ 0.00631381 -0.08129901  0.11284864  0.02375837  0.09768829 -0.23350382\n",
      "  0.27137827  0.00336431 -0.31987801  0.34483813 -0.24675    -0.21593906\n",
      "  0.09178665 -0.44511118]\n",
      "Training Error:  10.54333648507305\n",
      "====================================================================================================\n",
      "Iteration:  1343\n",
      "Previous theta :  [ 0.00631381 -0.08129901  0.11284864  0.02375837  0.09768829 -0.23350382\n",
      "  0.27137827  0.00336431 -0.31987801  0.34483813 -0.24675    -0.21593906\n",
      "  0.09178665 -0.44511118]\n",
      "New theta_0 : [ 0.00631378 -0.08130142  0.11285106  0.02376535  0.09768696 -0.23350517\n",
      "  0.27137585  0.00336612 -0.31987803  0.34486228 -0.24677621 -0.21594014\n",
      "  0.09178644 -0.44511294]\n",
      "Training Error:  10.543335233354922\n",
      "====================================================================================================\n",
      "Iteration:  1344\n",
      "Previous theta :  [ 0.00631378 -0.08130142  0.11285106  0.02376535  0.09768696 -0.23350517\n",
      "  0.27137585  0.00336612 -0.31987803  0.34486228 -0.24677621 -0.21594014\n",
      "  0.09178644 -0.44511294]\n",
      "New theta_0 : [ 0.00631374 -0.08130383  0.11285347  0.02377232  0.09768564 -0.23350652\n",
      "  0.27137343  0.00336792 -0.31987805  0.34488637 -0.24680236 -0.21594122\n",
      "  0.09178622 -0.4451147 ]\n",
      "Training Error:  10.54333398821492\n",
      "====================================================================================================\n",
      "Iteration:  1345\n",
      "Previous theta :  [ 0.00631374 -0.08130383  0.11285347  0.02377232  0.09768564 -0.23350652\n",
      "  0.27137343  0.00336792 -0.31987805  0.34488637 -0.24680236 -0.21594122\n",
      "  0.09178622 -0.4451147 ]\n",
      "New theta_0 : [ 0.00631371 -0.08130623  0.11285588  0.02377927  0.09768431 -0.23350786\n",
      "  0.27137101  0.00336971 -0.31987806  0.34491039 -0.24682843 -0.2159423\n",
      "  0.09178601 -0.44511645]\n",
      "Training Error:  10.54333274961836\n",
      "====================================================================================================\n",
      "Iteration:  1346\n",
      "Previous theta :  [ 0.00631371 -0.08130623  0.11285588  0.02377927  0.09768431 -0.23350786\n",
      "  0.27137101  0.00336971 -0.31987806  0.34491039 -0.24682843 -0.2159423\n",
      "  0.09178601 -0.44511645]\n",
      "New theta_0 : [ 0.00631367 -0.08130863  0.11285828  0.0237862   0.09768299 -0.23350919\n",
      "  0.27136861  0.0033715  -0.31987807  0.34493435 -0.24685444 -0.21594337\n",
      "  0.0917858  -0.4451182 ]\n",
      "Training Error:  10.543331517530738\n",
      "====================================================================================================\n",
      "Iteration:  1347\n",
      "Previous theta :  [ 0.00631367 -0.08130863  0.11285828  0.0237862   0.09768299 -0.23350919\n",
      "  0.27136861  0.0033715  -0.31987807  0.34493435 -0.24685444 -0.21594337\n",
      "  0.0917858  -0.4451182 ]\n",
      "New theta_0 : [ 0.00631364 -0.08131101  0.11286068  0.02379312  0.09768168 -0.23351051\n",
      "  0.27136621  0.00337329 -0.31987808  0.34495825 -0.24688038 -0.21594443\n",
      "  0.09178559 -0.44511994]\n",
      "Training Error:  10.543330291917737\n",
      "====================================================================================================\n",
      "Iteration:  1348\n",
      "Previous theta :  [ 0.00631364 -0.08131101  0.11286068  0.02379312  0.09768168 -0.23351051\n",
      "  0.27136621  0.00337329 -0.31987808  0.34495825 -0.24688038 -0.21594443\n",
      "  0.09178559 -0.44511994]\n",
      "New theta_0 : [ 0.0063136  -0.08131339  0.11286306  0.02380001  0.09768037 -0.23351183\n",
      "  0.27136381  0.00337507 -0.31987808  0.34498208 -0.24690625 -0.2159455\n",
      "  0.09178538 -0.44512168]\n",
      "Training Error:  10.54332907274522\n",
      "====================================================================================================\n",
      "Iteration:  1349\n",
      "Previous theta :  [ 0.0063136  -0.08131339  0.11286306  0.02380001  0.09768037 -0.23351183\n",
      "  0.27136381  0.00337507 -0.31987808  0.34498208 -0.24690625 -0.2159455\n",
      "  0.09178538 -0.44512168]\n",
      "New theta_0 : [ 0.00631356 -0.08131576  0.11286544  0.02380689  0.09767906 -0.23351314\n",
      "  0.27136143  0.00337684 -0.31987808  0.34500586 -0.24693205 -0.21594655\n",
      "  0.09178517 -0.44512341]\n",
      "Training Error:  10.543327859979232\n",
      "====================================================================================================\n",
      "Iteration:  1350\n",
      "Previous theta :  [ 0.00631356 -0.08131576  0.11286544  0.02380689  0.09767906 -0.23351314\n",
      "  0.27136143  0.00337684 -0.31987808  0.34500586 -0.24693205 -0.21594655\n",
      "  0.09178517 -0.44512341]\n",
      "New theta_0 : [ 0.00631353 -0.08131813  0.11286782  0.02381375  0.09767775 -0.23351444\n",
      "  0.27135905  0.00337861 -0.31987808  0.34502956 -0.24695779 -0.21594761\n",
      "  0.09178496 -0.44512514]\n",
      "Training Error:  10.543326653586004\n",
      "====================================================================================================\n",
      "Iteration:  1351\n",
      "Previous theta :  [ 0.00631353 -0.08131813  0.11286782  0.02381375  0.09767775 -0.23351444\n",
      "  0.27135905  0.00337861 -0.31987808  0.34502956 -0.24695779 -0.21594761\n",
      "  0.09178496 -0.44512514]\n",
      "New theta_0 : [ 0.00631349 -0.08132049  0.11287018  0.02382059  0.09767645 -0.23351574\n",
      "  0.27135668  0.00338038 -0.31987807  0.34505321 -0.24698346 -0.21594866\n",
      "  0.09178476 -0.44512687]\n",
      "Training Error:  10.543325453531935\n",
      "====================================================================================================\n",
      "Iteration:  1352\n",
      "Previous theta :  [ 0.00631349 -0.08132049  0.11287018  0.02382059  0.09767645 -0.23351574\n",
      "  0.27135668  0.00338038 -0.31987807  0.34505321 -0.24698346 -0.21594866\n",
      "  0.09178476 -0.44512687]\n",
      "New theta_0 : [ 0.00631346 -0.08132284  0.11287254  0.02382742  0.09767515 -0.23351702\n",
      "  0.27135431  0.00338214 -0.31987806  0.34507679 -0.24700906 -0.21594971\n",
      "  0.09178455 -0.44512859]\n",
      "Training Error:  10.543324259783613\n",
      "====================================================================================================\n",
      "Iteration:  1353\n",
      "Previous theta :  [ 0.00631346 -0.08132284  0.11287254  0.02382742  0.09767515 -0.23351702\n",
      "  0.27135431  0.00338214 -0.31987806  0.34507679 -0.24700906 -0.21594971\n",
      "  0.09178455 -0.44512859]\n",
      "New theta_0 : [ 0.00631342 -0.08132518  0.11287489  0.02383422  0.09767385 -0.23351831\n",
      "  0.27135195  0.0033839  -0.31987805  0.34510031 -0.2470346  -0.21595075\n",
      "  0.09178434 -0.44513031]\n",
      "Training Error:  10.5433230723078\n",
      "====================================================================================================\n",
      "Iteration:  1354\n",
      "Previous theta :  [ 0.00631342 -0.08132518  0.11287489  0.02383422  0.09767385 -0.23351831\n",
      "  0.27135195  0.0033839  -0.31987805  0.34510031 -0.2470346  -0.21595075\n",
      "  0.09178434 -0.44513031]\n",
      "New theta_0 : [ 0.00631339 -0.08132752  0.11287724  0.02384101  0.09767256 -0.23351958\n",
      "  0.2713496   0.00338565 -0.31987804  0.34512376 -0.24706007 -0.2159518\n",
      "  0.09178414 -0.44513202]\n",
      "Training Error:  10.543321891071432\n",
      "====================================================================================================\n",
      "Iteration:  1355\n",
      "Previous theta :  [ 0.00631339 -0.08132752  0.11287724  0.02384101  0.09767256 -0.23351958\n",
      "  0.2713496   0.00338565 -0.31987804  0.34512376 -0.24706007 -0.2159518\n",
      "  0.09178414 -0.44513202]\n",
      "New theta_0 : [ 0.00631335 -0.08132985  0.11287957  0.02384778  0.09767127 -0.23352085\n",
      "  0.27134726  0.00338739 -0.31987802  0.34514716 -0.24708548 -0.21595283\n",
      "  0.09178394 -0.44513373]\n",
      "Training Error:  10.543320716041624\n",
      "====================================================================================================\n",
      "Iteration:  1356\n",
      "Previous theta :  [ 0.00631335 -0.08132985  0.11287957  0.02384778  0.09767127 -0.23352085\n",
      "  0.27134726  0.00338739 -0.31987802  0.34514716 -0.24708548 -0.21595283\n",
      "  0.09178394 -0.44513373]\n",
      "New theta_0 : [ 0.00631332 -0.08133217  0.1128819   0.02385453  0.09766999 -0.23352211\n",
      "  0.27134492  0.00338913 -0.319878    0.34517049 -0.24711082 -0.21595387\n",
      "  0.09178373 -0.44513543]\n",
      "Training Error:  10.543319547185664\n",
      "====================================================================================================\n",
      "Iteration:  1357\n",
      "Previous theta :  [ 0.00631332 -0.08133217  0.1128819   0.02385453  0.09766999 -0.23352211\n",
      "  0.27134492  0.00338913 -0.319878    0.34517049 -0.24711082 -0.21595387\n",
      "  0.09178373 -0.44513543]\n",
      "New theta_0 : [ 0.00631329 -0.08133449  0.11288423  0.02386126  0.09766871 -0.23352337\n",
      "  0.27134259  0.00339087 -0.31987798  0.34519376 -0.24713609 -0.2159549\n",
      "  0.09178353 -0.44513713]\n",
      "Training Error:  10.543318384471018\n",
      "====================================================================================================\n",
      "Iteration:  1358\n",
      "Previous theta :  [ 0.00631329 -0.08133449  0.11288423  0.02386126  0.09766871 -0.23352337\n",
      "  0.27134259  0.00339087 -0.31987798  0.34519376 -0.24713609 -0.2159549\n",
      "  0.09178353 -0.44513713]\n",
      "New theta_0 : [ 0.00631325 -0.08133679  0.11288655  0.02386798  0.09766743 -0.23352462\n",
      "  0.27134027  0.0033926  -0.31987796  0.34521697 -0.2471613  -0.21595593\n",
      "  0.09178333 -0.44513883]\n",
      "Training Error:  10.543317227865316\n",
      "====================================================================================================\n",
      "Iteration:  1359\n",
      "Previous theta :  [ 0.00631325 -0.08133679  0.11288655  0.02386798  0.09766743 -0.23352462\n",
      "  0.27134027  0.0033926  -0.31987796  0.34521697 -0.2471613  -0.21595593\n",
      "  0.09178333 -0.44513883]\n",
      "New theta_0 : [ 0.00631322 -0.0813391   0.11288886  0.02387468  0.09766615 -0.23352586\n",
      "  0.27133795  0.00339433 -0.31987793  0.34524012 -0.24718644 -0.21595695\n",
      "  0.09178313 -0.44514052]\n",
      "Training Error:  10.543316077336367\n",
      "====================================================================================================\n",
      "Iteration:  1360\n",
      "Previous theta :  [ 0.00631322 -0.0813391   0.11288886  0.02387468  0.09766615 -0.23352586\n",
      "  0.27133795  0.00339433 -0.31987793  0.34524012 -0.24718644 -0.21595695\n",
      "  0.09178313 -0.44514052]\n",
      "New theta_0 : [ 0.00631318 -0.08134139  0.11289116  0.02388136  0.09766488 -0.2335271\n",
      "  0.27133564  0.00339605 -0.3198779   0.3452632  -0.24721152 -0.21595797\n",
      "  0.09178293 -0.44514221]\n",
      "Training Error:  10.54331493285215\n",
      "====================================================================================================\n",
      "Iteration:  1361\n",
      "Previous theta :  [ 0.00631318 -0.08134139  0.11289116  0.02388136  0.09766488 -0.2335271\n",
      "  0.27133564  0.00339605 -0.3198779   0.3452632  -0.24721152 -0.21595797\n",
      "  0.09178293 -0.44514221]\n",
      "New theta_0 : [ 0.00631315 -0.08134368  0.11289346  0.02388803  0.09766361 -0.23352833\n",
      "  0.27133334  0.00339777 -0.31987787  0.34528623 -0.24723653 -0.21595899\n",
      "  0.09178273 -0.44514389]\n",
      "Training Error:  10.543313794380811\n",
      "====================================================================================================\n",
      "Iteration:  1362\n",
      "Previous theta :  [ 0.00631315 -0.08134368  0.11289346  0.02388803  0.09766361 -0.23352833\n",
      "  0.27133334  0.00339777 -0.31987787  0.34528623 -0.24723653 -0.21595899\n",
      "  0.09178273 -0.44514389]\n",
      "New theta_0 : [ 0.00631312 -0.08134596  0.11289575  0.02389467  0.09766235 -0.23352955\n",
      "  0.27133104  0.00339948 -0.31987783  0.34530919 -0.24726148 -0.21596\n",
      "  0.09178253 -0.44514557]\n",
      "Training Error:  10.54331266189067\n",
      "====================================================================================================\n",
      "Iteration:  1363\n",
      "Previous theta :  [ 0.00631312 -0.08134596  0.11289575  0.02389467  0.09766235 -0.23352955\n",
      "  0.27133104  0.00339948 -0.31987783  0.34530919 -0.24726148 -0.21596\n",
      "  0.09178253 -0.44514557]\n",
      "New theta_0 : [ 0.00631308 -0.08134823  0.11289803  0.0239013   0.09766108 -0.23353077\n",
      "  0.27132875  0.00340119 -0.31987779  0.34533209 -0.24728636 -0.21596101\n",
      "  0.09178234 -0.44514725]\n",
      "Training Error:  10.54331153535021\n",
      "====================================================================================================\n",
      "Iteration:  1364\n",
      "Previous theta :  [ 0.00631308 -0.08134823  0.11289803  0.0239013   0.09766108 -0.23353077\n",
      "  0.27132875  0.00340119 -0.31987779  0.34533209 -0.24728636 -0.21596101\n",
      "  0.09178234 -0.44514725]\n",
      "New theta_0 : [ 0.00631305 -0.0813505   0.11290031  0.02390791  0.09765982 -0.23353198\n",
      "  0.27132646  0.00340289 -0.31987775  0.34535494 -0.24731118 -0.21596202\n",
      "  0.09178214 -0.44514892]\n",
      "Training Error:  10.543310414728085\n",
      "====================================================================================================\n",
      "Iteration:  1365\n",
      "Previous theta :  [ 0.00631305 -0.0813505   0.11290031  0.02390791  0.09765982 -0.23353198\n",
      "  0.27132646  0.00340289 -0.31987775  0.34535494 -0.24731118 -0.21596202\n",
      "  0.09178214 -0.44514892]\n",
      "New theta_0 : [ 0.00631301 -0.08135276  0.11290258  0.02391451  0.09765857 -0.23353318\n",
      "  0.27132419  0.00340459 -0.31987771  0.34537772 -0.24733593 -0.21596302\n",
      "  0.09178195 -0.44515059]\n",
      "Training Error:  10.543309299993112\n",
      "====================================================================================================\n",
      "Iteration:  1366\n",
      "Previous theta :  [ 0.00631301 -0.08135276  0.11290258  0.02391451  0.09765857 -0.23353318\n",
      "  0.27132419  0.00340459 -0.31987771  0.34537772 -0.24733593 -0.21596302\n",
      "  0.09178195 -0.44515059]\n",
      "New theta_0 : [ 0.00631298 -0.08135501  0.11290484  0.02392108  0.09765732 -0.23353438\n",
      "  0.27132191  0.00340629 -0.31987766  0.34540044 -0.24736062 -0.21596402\n",
      "  0.09178175 -0.44515225]\n",
      "Training Error:  10.543308191114274\n",
      "====================================================================================================\n",
      "Iteration:  1367\n",
      "Previous theta :  [ 0.00631298 -0.08135501  0.11290484  0.02392108  0.09765732 -0.23353438\n",
      "  0.27132191  0.00340629 -0.31987766  0.34540044 -0.24736062 -0.21596402\n",
      "  0.09178175 -0.44515225]\n",
      "New theta_0 : [ 0.00631295 -0.08135726  0.1129071   0.02392764  0.09765607 -0.23353557\n",
      "  0.27131965  0.00340798 -0.31987762  0.3454231  -0.24738524 -0.21596502\n",
      "  0.09178156 -0.44515391]\n",
      "Training Error:  10.543307088060725\n",
      "====================================================================================================\n",
      "Iteration:  1368\n",
      "Previous theta :  [ 0.00631295 -0.08135726  0.1129071   0.02392764  0.09765607 -0.23353557\n",
      "  0.27131965  0.00340798 -0.31987762  0.3454231  -0.24738524 -0.21596502\n",
      "  0.09178156 -0.44515391]\n",
      "New theta_0 : [ 0.00631292 -0.0813595   0.11290935  0.02393418  0.09765482 -0.23353676\n",
      "  0.27131739  0.00340966 -0.31987757  0.3454457  -0.2474098  -0.21596601\n",
      "  0.09178136 -0.44515556]\n",
      "Training Error:  10.543305990801773\n",
      "====================================================================================================\n",
      "Iteration:  1369\n",
      "Previous theta :  [ 0.00631292 -0.0813595   0.11290935  0.02393418  0.09765482 -0.23353676\n",
      "  0.27131739  0.00340966 -0.31987757  0.3454457  -0.2474098  -0.21596601\n",
      "  0.09178136 -0.44515556]\n",
      "New theta_0 : [ 0.00631288 -0.08136173  0.11291159  0.02394071  0.09765358 -0.23353794\n",
      "  0.27131514  0.00341134 -0.31987751  0.34546824 -0.2474343  -0.215967\n",
      "  0.09178117 -0.44515721]\n",
      "Training Error:  10.543304899306897\n",
      "====================================================================================================\n",
      "Iteration:  1370\n",
      "Previous theta :  [ 0.00631288 -0.08136173  0.11291159  0.02394071  0.09765358 -0.23353794\n",
      "  0.27131514  0.00341134 -0.31987751  0.34546824 -0.2474343  -0.215967\n",
      "  0.09178117 -0.44515721]\n",
      "New theta_0 : [ 0.00631285 -0.08136396  0.11291383  0.02394722  0.09765234 -0.23353911\n",
      "  0.2713129   0.00341302 -0.31987746  0.34549072 -0.24745874 -0.21596799\n",
      "  0.09178098 -0.44515886]\n",
      "Training Error:  10.543303813545732\n",
      "====================================================================================================\n",
      "Iteration:  1371\n",
      "Previous theta :  [ 0.00631285 -0.08136396  0.11291383  0.02394722  0.09765234 -0.23353911\n",
      "  0.2713129   0.00341302 -0.31987746  0.34549072 -0.24745874 -0.21596799\n",
      "  0.09178098 -0.44515886]\n",
      "New theta_0 : [ 0.00631282 -0.08136618  0.11291606  0.02395371  0.09765111 -0.23354028\n",
      "  0.27131066  0.00341469 -0.3198774   0.34551314 -0.24748311 -0.21596897\n",
      "  0.09178079 -0.4451605 ]\n",
      "Training Error:  10.543302733488074\n",
      "====================================================================================================\n",
      "Iteration:  1372\n",
      "Previous theta :  [ 0.00631282 -0.08136618  0.11291606  0.02395371  0.09765111 -0.23354028\n",
      "  0.27131066  0.00341469 -0.3198774   0.34551314 -0.24748311 -0.21596897\n",
      "  0.09178079 -0.4451605 ]\n",
      "New theta_0 : [ 0.00631278 -0.08136839  0.11291828  0.02396018  0.09764987 -0.23354144\n",
      "  0.27130843  0.00341635 -0.31987734  0.3455355  -0.24750741 -0.21596995\n",
      "  0.0917806  -0.44516214]\n",
      "Training Error:  10.543301659103886\n",
      "====================================================================================================\n",
      "Iteration:  1373\n",
      "Previous theta :  [ 0.00631278 -0.08136839  0.11291828  0.02396018  0.09764987 -0.23354144\n",
      "  0.27130843  0.00341635 -0.31987734  0.3455355  -0.24750741 -0.21596995\n",
      "  0.0917806  -0.44516214]\n",
      "New theta_0 : [ 0.00631275 -0.0813706   0.1129205   0.02396664  0.09764864 -0.23354259\n",
      "  0.2713062   0.00341802 -0.31987728  0.34555781 -0.24753166 -0.21597092\n",
      "  0.09178041 -0.44516377]\n",
      "Training Error:  10.543300590363284\n",
      "====================================================================================================\n",
      "Iteration:  1374\n",
      "Previous theta :  [ 0.00631275 -0.0813706   0.1129205   0.02396664  0.09764864 -0.23354259\n",
      "  0.2713062   0.00341802 -0.31987728  0.34555781 -0.24753166 -0.21597092\n",
      "  0.09178041 -0.44516377]\n",
      "New theta_0 : [ 0.00631272 -0.0813728   0.11292271  0.02397308  0.09764742 -0.23354374\n",
      "  0.27130398  0.00341967 -0.31987722  0.34558005 -0.24755584 -0.2159719\n",
      "  0.09178022 -0.4451654 ]\n",
      "Training Error:  10.543299527236545\n",
      "====================================================================================================\n",
      "Iteration:  1375\n",
      "Previous theta :  [ 0.00631272 -0.0813728   0.11292271  0.02397308  0.09764742 -0.23354374\n",
      "  0.27130398  0.00341967 -0.31987722  0.34558005 -0.24755584 -0.2159719\n",
      "  0.09178022 -0.4451654 ]\n",
      "New theta_0 : [ 0.00631269 -0.08137499  0.11292492  0.0239795   0.0976462  -0.23354488\n",
      "  0.27130177  0.00342133 -0.31987715  0.34560223 -0.24757995 -0.21597287\n",
      "  0.09178004 -0.44516703]\n",
      "Training Error:  10.5432984696941\n",
      "====================================================================================================\n",
      "Iteration:  1376\n",
      "Previous theta :  [ 0.00631269 -0.08137499  0.11292492  0.0239795   0.0976462  -0.23354488\n",
      "  0.27130177  0.00342133 -0.31987715  0.34560223 -0.24757995 -0.21597287\n",
      "  0.09178004 -0.44516703]\n",
      "New theta_0 : [ 0.00631265 -0.08137718  0.11292711  0.0239859   0.09764498 -0.23354602\n",
      "  0.27129956  0.00342297 -0.31987708  0.34562436 -0.24760401 -0.21597384\n",
      "  0.09177985 -0.44516865]\n",
      "Training Error:  10.543297417706544\n",
      "====================================================================================================\n",
      "Iteration:  1377\n",
      "Previous theta :  [ 0.00631265 -0.08137718  0.11292711  0.0239859   0.09764498 -0.23354602\n",
      "  0.27129956  0.00342297 -0.31987708  0.34562436 -0.24760401 -0.21597384\n",
      "  0.09177985 -0.44516865]\n",
      "New theta_0 : [ 0.00631262 -0.08137936  0.1129293   0.02399229  0.09764376 -0.23354715\n",
      "  0.27129736  0.00342462 -0.31987701  0.34564643 -0.247628   -0.2159748\n",
      "  0.09177966 -0.44517027]\n",
      "Training Error:  10.543296371244619\n",
      "====================================================================================================\n",
      "Iteration:  1378\n",
      "Previous theta :  [ 0.00631262 -0.08137936  0.1129293   0.02399229  0.09764376 -0.23354715\n",
      "  0.27129736  0.00342462 -0.31987701  0.34564643 -0.247628   -0.2159748\n",
      "  0.09177966 -0.44517027]\n",
      "New theta_0 : [ 0.00631259 -0.08138154  0.11293149  0.02399867  0.09764255 -0.23354828\n",
      "  0.27129517  0.00342626 -0.31987694  0.34566844 -0.24765193 -0.21597576\n",
      "  0.09177948 -0.44517189]\n",
      "Training Error:  10.54329533027923\n",
      "====================================================================================================\n",
      "Iteration:  1379\n",
      "Previous theta :  [ 0.00631259 -0.08138154  0.11293149  0.02399867  0.09764255 -0.23354828\n",
      "  0.27129517  0.00342626 -0.31987694  0.34566844 -0.24765193 -0.21597576\n",
      "  0.09177948 -0.44517189]\n",
      "New theta_0 : [ 0.00631256 -0.0813837   0.11293367  0.02400502  0.09764134 -0.2335494\n",
      "  0.27129298  0.00342789 -0.31987686  0.34569039 -0.2476758  -0.21597672\n",
      "  0.09177929 -0.4451735 ]\n",
      "Training Error:  10.543294294781433\n",
      "====================================================================================================\n",
      "Iteration:  1380\n",
      "Previous theta :  [ 0.00631256 -0.0813837   0.11293367  0.02400502  0.09764134 -0.2335494\n",
      "  0.27129298  0.00342789 -0.31987686  0.34569039 -0.2476758  -0.21597672\n",
      "  0.09177929 -0.4451735 ]\n",
      "New theta_0 : [ 0.00631253 -0.08138586  0.11293584  0.02401136  0.09764013 -0.23355051\n",
      "  0.2712908   0.00342952 -0.31987678  0.34571228 -0.2476996  -0.21597767\n",
      "  0.09177911 -0.4451751 ]\n",
      "Training Error:  10.543293264722434\n",
      "====================================================================================================\n",
      "Iteration:  1381\n",
      "Previous theta :  [ 0.00631253 -0.08138586  0.11293584  0.02401136  0.09764013 -0.23355051\n",
      "  0.2712908   0.00342952 -0.31987678  0.34571228 -0.2476996  -0.21597767\n",
      "  0.09177911 -0.4451751 ]\n",
      "New theta_0 : [ 0.0063125  -0.08138802  0.11293801  0.02401768  0.09763893 -0.23355162\n",
      "  0.27128862  0.00343115 -0.3198767   0.34573411 -0.24772335 -0.21597862\n",
      "  0.09177893 -0.4451767 ]\n",
      "Training Error:  10.543292240073598\n",
      "====================================================================================================\n",
      "Iteration:  1382\n",
      "Previous theta :  [ 0.0063125  -0.08138802  0.11293801  0.02401768  0.09763893 -0.23355162\n",
      "  0.27128862  0.00343115 -0.3198767   0.34573411 -0.24772335 -0.21597862\n",
      "  0.09177893 -0.4451767 ]\n",
      "New theta_0 : [ 0.00631246 -0.08139017  0.11294017  0.02402399  0.09763773 -0.23355273\n",
      "  0.27128645  0.00343277 -0.31987662  0.34575589 -0.24774703 -0.21597957\n",
      "  0.09177874 -0.4451783 ]\n",
      "Training Error:  10.543291220806434\n",
      "====================================================================================================\n",
      "Iteration:  1383\n",
      "Previous theta :  [ 0.00631246 -0.08139017  0.11294017  0.02402399  0.09763773 -0.23355273\n",
      "  0.27128645  0.00343277 -0.31987662  0.34575589 -0.24774703 -0.21597957\n",
      "  0.09177874 -0.4451783 ]\n",
      "New theta_0 : [ 0.00631243 -0.08139231  0.11294232  0.02403028  0.09763653 -0.23355382\n",
      "  0.27128429  0.00343439 -0.31987654  0.34577761 -0.24777065 -0.21598051\n",
      "  0.09177856 -0.4451799 ]\n",
      "Training Error:  10.543290206892612\n",
      "====================================================================================================\n",
      "Iteration:  1384\n",
      "Previous theta :  [ 0.00631243 -0.08139231  0.11294232  0.02403028  0.09763653 -0.23355382\n",
      "  0.27128429  0.00343439 -0.31987654  0.34577761 -0.24777065 -0.21598051\n",
      "  0.09177856 -0.4451799 ]\n",
      "New theta_0 : [ 0.0063124  -0.08139444  0.11294447  0.02403655  0.09763533 -0.23355491\n",
      "  0.27128214  0.003436   -0.31987645  0.34579927 -0.24779421 -0.21598145\n",
      "  0.09177838 -0.44518149]\n",
      "Training Error:  10.543289198303944\n",
      "====================================================================================================\n",
      "Iteration:  1385\n",
      "Previous theta :  [ 0.0063124  -0.08139444  0.11294447  0.02403655  0.09763533 -0.23355491\n",
      "  0.27128214  0.003436   -0.31987645  0.34579927 -0.24779421 -0.21598145\n",
      "  0.09177838 -0.44518149]\n",
      "New theta_0 : [ 0.00631237 -0.08139657  0.11294661  0.0240428   0.09763414 -0.233556\n",
      "  0.27127998  0.00343761 -0.31987636  0.34582087 -0.24781771 -0.21598239\n",
      "  0.0917782  -0.44518307]\n",
      "Training Error:  10.543288195012392\n",
      "====================================================================================================\n",
      "Iteration:  1386\n",
      "Previous theta :  [ 0.00631237 -0.08139657  0.11294661  0.0240428   0.09763414 -0.233556\n",
      "  0.27127998  0.00343761 -0.31987636  0.34582087 -0.24781771 -0.21598239\n",
      "  0.0917782  -0.44518307]\n",
      "New theta_0 : [ 0.00631234 -0.0813987   0.11294874  0.02404904  0.09763296 -0.23355708\n",
      "  0.27127784  0.00343921 -0.31987627  0.34584242 -0.24784115 -0.21598333\n",
      "  0.09177802 -0.44518466]\n",
      "Training Error:  10.543287196990073\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = test_train_split(X, y, validation_sample1)\n",
    "learning_rate = 0.01\n",
    "train_error1, valid_error1, theta1 = linear_regression(X_train, y_train, X_test, y_test, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'First Sample')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(train_error1))], train_error1, label='Training error')\n",
    "plt.plot([i for i in range(len(valid_error1))], valid_error1, label='Validation error')\n",
    "plt.gca().legend(('Training error','Validation error'))\n",
    "plt.title('First Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  0\n",
      "Previous theta :  [1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5]\n",
      "New theta_0 : [1.43732465 1.30300788 1.59247561 1.28083021 1.44384227 1.29563189\n",
      " 1.57255528 1.3208338  1.63181516 1.27051513 1.27276569 1.35689007\n",
      " 1.5642803  1.33347688]\n",
      "Training Error:  126.79057310145393\n",
      "====================================================================================================\n",
      "Iteration:  1\n",
      "Previous theta :  [1.43732465 1.30300788 1.59247561 1.28083021 1.44384227 1.29563189\n",
      " 1.57255528 1.3208338  1.63181516 1.27051513 1.27276569 1.35689007\n",
      " 1.5642803  1.33347688]\n",
      "New theta_0 : [1.37607905 1.1454082  1.64675195 1.11239955 1.39125286 1.14010834\n",
      " 1.62153271 1.18381476 1.72232813 1.08519171 1.08983254 1.24105258\n",
      " 1.60464112 1.2040822 ]\n",
      "Training Error:  108.86001182138074\n",
      "====================================================================================================\n",
      "Iteration:  2\n",
      "Previous theta :  [1.37607905 1.1454082  1.64675195 1.11239955 1.39125286 1.14010834\n",
      " 1.62153271 1.18381476 1.72232813 1.08519171 1.08983254 1.24105258\n",
      " 1.60464112 1.2040822 ]\n",
      "New theta_0 : [1.3165207  1.01827519 1.67254601 0.98268186 1.34168611 1.02176108\n",
      " 1.65274297 1.07878941 1.78165978 0.93411769 0.94117541 1.14625984\n",
      " 1.62685957 1.10299214]\n",
      "Training Error:  96.07645233068519\n",
      "====================================================================================================\n",
      "Iteration:  3\n",
      "Previous theta :  [1.3165207  1.01827519 1.67254601 0.98268186 1.34168611 1.02176108\n",
      " 1.65274297 1.07878941 1.78165978 0.93411769 0.94117541 1.14625984\n",
      " 1.62685957 1.10299214]\n",
      "New theta_0 : [1.25881957 0.91477309 1.67724307 0.88249999 1.29471906 0.93169047\n",
      " 1.67060988 0.99802069 1.81751912 0.80969958 0.81911912 1.06774849\n",
      " 1.63535017 1.02347559]\n",
      "Training Error:  86.93084903002021\n",
      "====================================================================================================\n",
      "Iteration:  4\n",
      "Previous theta :  [1.25881957 0.91477309 1.67724307 0.88249999 1.29471906 0.93169047\n",
      " 1.67060988 0.99802069 1.81751912 0.80969958 0.81911912 1.06774849\n",
      " 1.63535017 1.02347559]\n",
      "New theta_0 : [1.2030801  0.82966274 1.66645013 0.80485128 1.25002231 0.86310976\n",
      " 1.67849927 0.93561522 1.83577495 0.70611504 0.71778342 1.00187336\n",
      " 1.63348669 0.9603986 ]\n",
      "Training Error:  80.27890603870577\n",
      "====================================================================================================\n",
      "Iteration:  5\n",
      "Previous theta :  [1.2030801  0.82966274 1.66645013 0.80485128 1.25002231 0.86310976\n",
      " 1.67849927 0.93561522 1.83577495 0.70611504 0.71778342 1.00187336\n",
      " 1.63348669 0.9603986 ]\n",
      "New theta_0 : [1.14935776 0.75892494 1.64441844 0.74439269 1.20733785 0.81084466\n",
      " 1.67896996 0.88708613 1.84089232 0.61889512 0.6326593  0.9458433\n",
      " 1.62384795 0.9098461 ]\n",
      "Training Error:  75.29421333806931\n",
      "====================================================================================================\n",
      "Iteration:  6\n",
      "Previous theta :  [1.14935776 0.75892494 1.64441844 0.74439269 1.20733785 0.81084466\n",
      " 1.67896996 0.88708613 1.84089232 0.61889512 0.6326593  0.9458433\n",
      " 1.62384795 0.9098461 ]\n",
      "New theta_0 : [1.09767179 0.6994728  1.61436583 0.69704781 1.16646211 0.77095126\n",
      " 1.67396536 0.84901951 1.83626552 0.54460514 0.56028547 0.89751943\n",
      " 1.60840541 0.86883315]\n",
      "Training Error:  71.4076225383484\n",
      "====================================================================================================\n",
      "Iteration:  7\n",
      "Previous theta :  [1.09767179 0.6994728  1.61436583 0.69704781 1.16646211 0.77095126\n",
      " 1.67396536 0.84901951 1.83626552 0.54460514 0.56028547 0.89751943\n",
      " 1.60840541 0.86883315]\n",
      "New theta_0 : [1.0480148  0.64893221 1.57872272 0.65970693 1.12723311 0.74042454\n",
      " 1.66495962 0.8188197  1.82447226 0.48060117 0.49800144 0.85526121\n",
      " 1.58866645 0.83508461]\n",
      "Training Error:  68.24223253044329\n",
      "====================================================================================================\n",
      "Iteration:  8\n",
      "Previous theta :  [1.0480148  0.64893221 1.57872272 0.65970693 1.12723311 0.74042454\n",
      " 1.66495962 0.8188197  1.82447226 0.48060117 0.49800144 0.85526121\n",
      " 1.58866645 0.83508461]\n",
      "New theta_0 : [1.00036005 0.6054741  1.53931976 0.62999807 1.08952057 0.71697575\n",
      " 1.65306923 0.79451508 1.80746765 0.42484403 0.44375887 0.81780884\n",
      " 1.56578376 0.80686692]\n",
      "Training Error:  65.55548471495351\n",
      "====================================================================================================\n",
      "Iteration:  9\n",
      "Previous theta :  [1.00036005 0.6054741  1.53931976 0.62999807 1.08952057 0.71697575\n",
      " 1.65306923 0.79451508 1.80746765 0.42484403 0.44375887 0.81780884\n",
      " 1.56578376 0.80686692]\n",
      "New theta_0 : [0.95466698 0.56768644 1.49753111 0.60611224 1.05321848 0.69886264\n",
      " 1.63913811 0.7746097  1.78673222 0.3757572  0.39597763 0.78419351\n",
      " 1.54063886 0.78285972]\n",
      "Training Error:  63.194117053368416\n",
      "====================================================================================================\n",
      "Iteration:  10\n",
      "Previous theta :  [0.95466698 0.56768644 1.49753111 0.60611224 1.05321848 0.69886264\n",
      " 1.63913811 0.7746097  1.78673222 0.3757572  0.39597763 0.78419351\n",
      " 1.54063886 0.78285972]\n",
      "New theta_0 : [0.9108854  0.5344764  1.45438361 0.58667003 1.01823936 0.68475977\n",
      " 1.62380263 0.75797018 1.76338487 0.33211839 0.3534358  0.7536689\n",
      " 1.5139059  0.76205786]\n",
      "Training Error:  61.062191078152914\n",
      "====================================================================================================\n",
      "Iteration:  11\n",
      "Previous theta :  [0.9108854  0.5344764  1.45438361 0.58667003 1.01823936 0.68475977\n",
      " 1.62380263 0.75797018 1.76338487 0.33211839 0.3534358  0.7536689\n",
      " 1.5139059  0.76205786]\n",
      "New theta_0 : [0.86895862 0.50499571 1.4106401  0.57061987 0.98450993 0.67365963\n",
      " 1.60754108 0.74373935 1.73826906 0.29297667 0.31518575 0.72565879\n",
      " 1.48610039 0.74369661]\n",
      "Training Error:  59.09972522298722\n",
      "====================================================================================================\n",
      "Iteration:  12\n",
      "Previous theta :  [0.86895862 0.50499571 1.4106401  0.57061987 0.98450993 0.67365963\n",
      " 1.60754108 0.74373935 1.73826906 0.29297667 0.31518575 0.72565879\n",
      " 1.48610039 0.74369661]\n",
      "New theta_0 : [0.8288258  0.47858351 1.36686299 0.55716027 0.95196781 0.66479711\n",
      " 1.59071155 0.73127038 1.71201852 0.25758916 0.28048991 0.69971717\n",
      " 1.45761645 0.72719463]\n",
      "Training Error:  57.26896206226401\n",
      "====================================================================================================\n",
      "Iteration:  13\n",
      "Previous theta :  [0.8288258  0.47858351 1.36686299 0.55716027 0.95196781 0.66479711\n",
      " 1.59071155 0.73127038 1.71201852 0.25758916 0.28048991 0.69971717\n",
      " 1.45761645 0.72719463]\n",
      "New theta_0 : [0.79042374 0.45472281 1.3234627  0.54568053 0.92055902 0.6575919\n",
      " 1.57358072 0.72007655 1.68510746 0.22537267 0.24877183 0.67549766\n",
      " 1.42875518 0.71211037]\n",
      "Training Error:  55.54576016179998\n",
      "====================================================================================================\n",
      "Iteration:  14\n",
      "Previous theta :  [0.79042374 0.45472281 1.3234627  0.54568053 0.92055902 0.6575919\n",
      " 1.57358072 0.72007655 1.68510746 0.22537267 0.24877183 0.67549766\n",
      " 1.42875518 0.71211037]\n",
      "New theta_0 : [0.75368817 0.43300711 1.28073455 0.53571551 0.89023605 0.65160453\n",
      " 1.55634587 0.70979287 1.6578888  0.19586674 0.21957871 0.65273024\n",
      " 1.39974648 0.69810885]\n",
      "Training Error:  53.91428409637714\n",
      "====================================================================================================\n",
      "Iteration:  15\n",
      "Previous theta :  [0.75368817 0.43300711 1.28073455 0.53571551 0.89023605 0.65160453\n",
      " 1.55634587 0.70979287 1.6578888  0.19586674 0.21957871 0.65273024\n",
      " 1.39974648 0.69810885]\n",
      "New theta_0 : [0.71855473 0.41311496 1.23888692 0.52691109 0.86095641 0.64650282\n",
      " 1.53915165 0.70014691 1.63062335 0.16870535 0.19255278 0.63120341\n",
      " 1.37076561 0.68493631]\n",
      "Training Error:  52.36376261837216\n",
      "====================================================================================================\n",
      "Iteration:  16\n",
      "Previous theta :  [0.71855473 0.41311496 1.23888692 0.52691109 0.86095641 0.64650282\n",
      " 1.53915165 0.70014691 1.63062335 0.16870535 0.19255278 0.63120341\n",
      " 1.37076561 0.68493631]\n",
      "New theta_0 : [0.68495968 0.39479043 1.19806266 0.51899777 0.83268158 0.64203629\n",
      " 1.52210283 0.69093646 1.60350204 0.14359538 0.16740942 0.61075061\n",
      " 1.34194589 0.67240082]\n",
      "Training Error:  50.8865226483148\n",
      "====================================================================================================\n",
      "Iteration:  17\n",
      "Previous theta :  [0.68495968 0.39479043 1.19806266 0.51899777 0.83268158 0.64203629\n",
      " 1.52210283 0.69093646 1.60350204 0.14359538 0.16740942 0.61075061\n",
      " 1.34194589 0.67240082]\n",
      "New theta_0 : [0.65284037 0.37782825 1.15835544 0.5117706  0.80537611 0.63801662\n",
      " 1.50527407 0.68201257 1.57666289 0.12029996 0.14392046 0.59123981\n",
      " 1.31338845 0.66035756]\n",
      "Training Error:  49.47680208785151\n",
      "====================================================================================================\n",
      "Iteration:  18\n",
      "Previous theta :  [0.65284037 0.37782825 1.15835544 0.5117706  0.80537611 0.63801662\n",
      " 1.50527407 0.68201257 1.57666289 0.12029996 0.14392046 0.59123981\n",
      " 1.31338845 0.66035756]\n",
      "New theta_0 : [0.62213566 0.36206233 1.11982208 0.50507381 0.77900701 0.6343028\n",
      " 1.48871732 0.67326659 1.55020394 0.09862591 0.1219013  0.57256554\n",
      " 1.28516965 0.64869754]\n",
      "Training Error:  48.13003476600621\n",
      "====================================================================================================\n",
      "Iteration:  19\n",
      "Previous theta :  [0.62213566 0.36206233 1.11982208 0.50507381 0.77900701 0.6343028\n",
      " 1.48871732 0.67326659 1.55020394 0.09862591 0.1219013  0.57256554\n",
      " 1.28516965 0.64869754]\n",
      "New theta_0 : [0.59278611 0.34735705 1.08249206 0.49878913 0.75354331 0.63078975\n",
      " 1.47246747 0.66462031 1.52419305 0.078414   0.10120121 0.55464285\n",
      " 1.25734675 0.63733898]\n",
      "Training Error:  46.84242021813328\n",
      "====================================================================================================\n",
      "Iteration:  20\n",
      "Previous theta :  [0.59278611 0.34735705 1.08249206 0.49878913 0.75354331 0.63078975\n",
      " 1.47246747 0.66462031 1.52419305 0.078414   0.10120121 0.55464285\n",
      " 1.25734675 0.63733898]\n",
      "New theta_0 : [0.56473418 0.33360054 1.04637465 0.49282679 0.72895566 0.62739965\n",
      " 1.45654664 0.65601844 1.49867544 0.05953148 0.08169571 0.53740262\n",
      " 1.22996232 0.62622082]\n",
      "Training Error:  45.61066468622496\n",
      "====================================================================================================\n",
      "Iteration:  21\n",
      "Previous theta :  [0.56473418 0.33360054 1.04637465 0.49282679 0.72895566 0.62739965\n",
      " 1.45654664 0.65601844 1.49867544 0.05953148 0.08169571 0.53740262\n",
      " 1.22996232 0.62622082]\n",
      "New theta_0 : [0.53792429 0.32069957 1.01146432 0.48711881 0.70521604 0.62407536\n",
      " 1.44096744 0.64742292 1.47367932 0.04186646 0.06328092 0.52078803\n",
      " 1.20304754 0.61529767]\n",
      "Training Error:  44.4318247522236\n",
      "====================================================================================================\n",
      "Iteration:  22\n",
      "Previous theta :  [0.53792429 0.32069957 1.01146432 0.48711881 0.70521604 0.62407536\n",
      " 1.44096744 0.64742292 1.47367932 0.04186646 0.06328092 0.52078803\n",
      " 1.20304754 0.61529767]\n",
      "New theta_0 : [0.5123029  0.30857551 0.97774487 0.48161369 0.68229762 0.62077536\n",
      " 1.42573547 0.63880856 1.44922031 0.02532341 0.04586905 0.50475181\n",
      " 1.17662481 0.60453604]\n",
      "Training Error:  43.30321234364669\n",
      "====================================================================================================\n",
      "Iteration:  23\n",
      "Previous theta :  [0.5123029  0.30857551 0.97774487 0.48161369 0.68229762 0.62077536\n",
      " 1.42573547 0.63880856 1.44922031 0.02532341 0.04586905 0.50475181\n",
      " 1.17662481 0.60453604]\n",
      "New theta_0 : [0.48781852 0.29716137 0.94519254 0.47627253 0.66017454 0.61746999\n",
      " 1.41085117 0.63015973 1.42530465 0.00981988 0.02938506 0.48925415\n",
      " 1.15070969 0.59391141]\n",
      "Training Error:  42.222336363326\n",
      "====================================================================================================\n",
      "Iteration:  24\n",
      "Previous theta :  [0.48781852 0.29716137 0.94519254 0.47627253 0.66017454 0.61746999\n",
      " 1.41085117 0.63015973 1.42530465 0.00981988 0.02938506 0.48925415\n",
      " 1.15070969 0.59391141]\n",
      "New theta_0 : [ 0.46442167  0.28639939  0.91377833  0.47106598  0.63882182  0.61413844\n",
      "  1.39631125  0.62146788  1.40193174 -0.00471616  0.01376401  0.47426113\n",
      "  1.12531242  0.58340604]\n",
      "Training Error:  41.186866139410256\n",
      "====================================================================================================\n",
      "Iteration:  25\n",
      "Previous theta :  [ 0.46442167  0.28639939  0.91377833  0.47106598  0.63882182  0.61413844\n",
      "  1.39631125  0.62146788  1.40193174 -0.00471616  0.01376401  0.47426113\n",
      "  1.12531242  0.58340604]\n",
      "New theta_0 : [ 4.42064884e-01  2.76239278e-01  8.83469794e-01  4.65971924e-01\n",
      "  6.18215282e-01  6.10766597e-01  1.38210980e+00  6.12729628e-01\n",
      "  1.37909600e+00 -1.83483057e-02 -1.05091161e-03  4.59743423e-01\n",
      "  1.10043911e+00  5.73007284e-01]\n",
      "Training Error:  40.194607864303414\n",
      "====================================================================================================\n",
      "Iteration:  26\n",
      "Previous theta :  [ 4.42064884e-01  2.76239278e-01  8.83469794e-01  4.65971924e-01\n",
      "  6.18215282e-01  6.10766597e-01  1.38210980e+00  6.12729628e-01\n",
      "  1.37909600e+00 -1.83483057e-02 -1.05091161e-03  4.59743423e-01\n",
      "  1.10043911e+00  5.73007284e-01]\n",
      "New theta_0 : [ 0.42070266  0.26663675  0.85423231  0.46097375  0.59833146  0.60734535\n",
      "  1.36823905  0.60394531  1.35678832 -0.0311333  -0.01511001  0.4456754\n",
      "  1.07609263  0.56270632]\n",
      "Training Error:  39.2434887693706\n",
      "====================================================================================================\n",
      "Iteration:  27\n",
      "Previous theta :  [ 0.42070266  0.26663675  0.85423231  0.46097375  0.59833146  0.60734535\n",
      "  1.36823905  0.60394531  1.35678832 -0.0311333  -0.01511001  0.4456754\n",
      "  1.07609263  0.56270632]\n",
      "New theta_0 : [ 0.40029141  0.25755246  0.82603007  0.45605898  0.57914756  0.60386927\n",
      "  1.35468998  0.59511794  1.33499713 -0.04312225 -0.02845824  0.43203439\n",
      "  1.05227332  0.55249716]\n",
      "Training Error:  38.33154592055503\n",
      "====================================================================================================\n",
      "Iteration:  28\n",
      "Previous theta :  [ 0.40029141  0.25755246  0.82603007  0.45605898  0.57914756  0.60386927\n",
      "  1.35468998  0.59511794  1.33499713 -0.04312225 -0.02845824  0.43203439\n",
      "  1.05227332  0.55249716]\n",
      "New theta_0 : [ 0.38078936  0.24895115  0.79882684  0.45121831  0.56064143  0.60033569\n",
      "  1.34145283  0.58625235  1.31370921 -0.05436152 -0.04113617  0.41880008\n",
      "  1.02897953  0.54237591]\n",
      "Training Error:  37.456917794413265\n",
      "====================================================================================================\n",
      "Iteration:  29\n",
      "Previous theta :  [ 0.38078936  0.24895115  0.79882684  0.45121831  0.56064143  0.60033569\n",
      "  1.34145283  0.58625235  1.31370921 -0.05436152 -0.04113617  0.41880008\n",
      "  1.02897953  0.54237591]\n",
      "New theta_0 : [ 0.36215656  0.24080099  0.77258644  0.44644478  0.54279151  0.59674393\n",
      "  1.32851738  0.5773546   1.29291027 -0.06489357 -0.05318071  0.40595412\n",
      "  1.00620801  0.53234025]\n",
      "Training Error:  36.61783755117667\n",
      "====================================================================================================\n",
      "Iteration:  30\n",
      "Previous theta :  [ 0.36215656  0.24080099  0.77258644  0.44644478  0.54279151  0.59674393\n",
      "  1.32851738  0.5773546   1.29291027 -0.06489357 -0.05318071  0.40595412\n",
      "  1.00620801  0.53234025]\n",
      "New theta_0 : [ 0.34435476  0.23307301  0.74727314  0.4417332   0.52557684  0.59309476\n",
      "  1.31587323  0.56843153  1.27258545 -0.07475745 -0.0646257   0.39347977\n",
      "  0.98395432  0.52238895]\n",
      "Training Error:  35.812627369575864\n",
      "====================================================================================================\n",
      "Iteration:  31\n",
      "Previous theta :  [ 0.34435476  0.23307301  0.74727314  0.4417332   0.52557684  0.59309476\n",
      "  1.31587323  0.56843153  1.27258545 -0.07475745 -0.0646257   0.39347977\n",
      "  0.98395432  0.52238895]\n",
      "New theta_0 : [ 0.32734737  0.22574072  0.72285195  0.43707973  0.50897699  0.58938997\n",
      "  1.30350996  0.55949041  1.25271959 -0.08398933 -0.07550233  0.38136161\n",
      "  0.96221298  0.51252161]\n",
      "Training Error:  35.03969347223274\n",
      "====================================================================================================\n",
      "Iteration:  32\n",
      "Previous theta :  [ 0.32734737  0.22574072  0.72285195  0.43707973  0.50897699  0.58938997\n",
      "  1.30350996  0.55949041  1.25271959 -0.08398933 -0.07550233  0.38136161\n",
      "  0.96221298  0.51252161]\n",
      "New theta_0 : [ 0.31109941  0.21877976  0.69928878  0.4324815   0.4929721   0.58563207\n",
      "  1.2914173   0.5505387   1.23329754 -0.09262284 -0.08583955  0.36958536\n",
      "  0.94097779  0.50273838]\n",
      "Training Error:  34.297521625192964\n",
      "====================================================================================================\n",
      "Iteration:  33\n",
      "Previous theta :  [ 0.31109941  0.21877976  0.69928878  0.4324815   0.4929721   0.58563207\n",
      "  1.2914173   0.5505387   1.23329754 -0.09262284 -0.08583955  0.36958536\n",
      "  0.94097779  0.50273838]\n",
      "New theta_0 : [ 0.2955774   0.21216762  0.67655057  0.42793639  0.47754284  0.58182401\n",
      "  1.27958517  0.54158384  1.21430429 -0.10068938 -0.09566432  0.35813772\n",
      "  0.9202419   0.49303978]\n",
      "Training Error:  33.584672985282694\n",
      "====================================================================================================\n",
      "Iteration:  34\n",
      "Previous theta :  [ 0.2955774   0.21216762  0.67655057  0.42793639  0.47754284  0.58182401\n",
      "  1.27958517  0.54158384  1.21430429 -0.10068938 -0.09566432  0.35813772\n",
      "  0.9202419   0.49303978]\n",
      "New theta_0 : [ 0.28074934  0.20588344  0.65460539  0.42344282  0.46267038  0.57796907\n",
      "  1.26800379  0.53263317  1.19572512 -0.10821837 -0.10500186  0.34700621\n",
      "  0.89999799  0.48342659]\n",
      "Training Error:  32.89978022102206\n",
      "====================================================================================================\n",
      "Iteration:  35\n",
      "Previous theta :  [ 0.28074934  0.20588344  0.65460539  0.42344282  0.46267038  0.57796907\n",
      "  1.26800379  0.53263317  1.19572512 -0.10821837 -0.10500186  0.34700621\n",
      "  0.89999799  0.48342659]\n",
      "New theta_0 : [ 0.26658464  0.19990783  0.63342246  0.41899959  0.44833644  0.57407067\n",
      "  1.2566637   0.5236938   1.17754565 -0.11523743 -0.11387584  0.33617909\n",
      "  0.88023836  0.47389972]\n",
      "Training Error:  32.241543862601134\n",
      "====================================================================================================\n",
      "Iteration:  36\n",
      "Previous theta :  [ 0.26658464  0.19990783  0.63342246  0.41899959  0.44833644  0.57407067\n",
      "  1.2566637   0.5236938   1.17754565 -0.11523743 -0.11387584  0.33617909\n",
      "  0.88023836  0.47389972]\n",
      "New theta_0 : [ 0.25305403  0.1942227   0.61297219  0.41460582  0.43452321  0.57013231\n",
      "  1.24555581  0.51477256  1.15975197 -0.12177259 -0.12230853  0.32564526\n",
      "  0.860955    0.46446018]\n",
      "Training Error:  31.60872885326291\n",
      "====================================================================================================\n",
      "Iteration:  37\n",
      "Previous theta :  [ 0.25305403  0.1942227   0.61297219  0.41460582  0.43452321  0.57013231\n",
      "  1.24555581  0.51477256  1.15975197 -0.12177259 -0.12230853  0.32564526\n",
      "  0.860955    0.46446018]\n",
      "New theta_0 : [ 0.24012956  0.18881115  0.59322613  0.41026078  0.42121338  0.56615748\n",
      "  1.23467136  0.50587595  1.1423306  -0.12784839 -0.13032095  0.31539422\n",
      "  0.84213968  0.45510896]\n",
      "Training Error:  31.00016128383746\n",
      "====================================================================================================\n",
      "Iteration:  38\n",
      "Previous theta :  [ 0.24012956  0.18881115  0.59322613  0.41026078  0.42121338  0.56615748\n",
      "  1.23467136  0.50587595  1.1423306  -0.12784839 -0.13032095  0.31539422\n",
      "  0.84213968  0.45510896]\n",
      "New theta_0 : [ 0.22778447  0.18365737  0.57415701  0.40596392  0.40839013  0.56214962\n",
      "  1.224002    0.49701014  1.12526857 -0.13348801 -0.13793292  0.30541598\n",
      "  0.82378401  0.44584706]\n",
      "Training Error:  30.414725297348816\n",
      "====================================================================================================\n",
      "Iteration:  39\n",
      "Previous theta :  [ 0.22778447  0.18365737  0.57415701  0.40596392  0.40839013  0.56214962\n",
      "  1.224002    0.49701014  1.12526857 -0.13348801 -0.13793292  0.30541598\n",
      "  0.82378401  0.44584706]\n",
      "New theta_0 : [ 0.21599322  0.17874652  0.5557387   0.40171476  0.39603712  0.55811208\n",
      "  1.21353974  0.48818094  1.10855337 -0.13871339 -0.14516325  0.29570103\n",
      "  0.80587945  0.4366754 ]\n",
      "Training Error:  29.851360153436914\n",
      "====================================================================================================\n",
      "Iteration:  40\n",
      "Previous theta :  [ 0.21599322  0.17874652  0.5557387   0.40171476  0.39603712  0.55811208\n",
      "  1.21353974  0.48818094  1.10855337 -0.13871339 -0.14516325  0.29570103\n",
      "  0.80587945  0.4366754 ]\n",
      "New theta_0 : [ 0.20473136  0.1740647   0.53794615  0.39751291  0.38413847  0.55404809\n",
      "  1.20327695  0.47939377  1.09217303 -0.1435453  -0.15202973  0.28624031\n",
      "  0.7884174   0.42759486]\n",
      "Training Error:  29.30905744387296\n",
      "====================================================================================================\n",
      "Iteration:  41\n",
      "Previous theta :  [ 0.20473136  0.1740647   0.53794615  0.39751291  0.38413847  0.55404809\n",
      "  1.20327695  0.47939377  1.09217303 -0.1435453  -0.15202973  0.28624031\n",
      "  0.7884174   0.42759486]\n",
      "New theta_0 : [ 0.19397554  0.16959884  0.5207554   0.39335798  0.37267876  0.54996077\n",
      "  1.19320637  0.47065373  1.07611605 -0.14800343 -0.15854925  0.27702515\n",
      "  0.77138917  0.41860622]\n",
      "Training Error:  28.78685845130467\n",
      "====================================================================================================\n",
      "Iteration:  42\n",
      "Previous theta :  [ 0.19397554  0.16959884  0.5207554   0.39335798  0.37267876  0.54996077\n",
      "  1.19320637  0.47065373  1.07611605 -0.14800343 -0.15854925  0.27702515\n",
      "  0.77138917  0.41860622]\n",
      "New theta_0 : [ 0.18370343  0.16533664  0.5041435   0.38924963  0.36164302  0.54585307\n",
      "  1.18332107  0.46196553  1.06037138 -0.15210647 -0.16473784  0.26804727\n",
      "  0.75478607  0.40971017]\n",
      "Training Error:  28.28385164388567\n",
      "====================================================================================================\n",
      "Iteration:  43\n",
      "Previous theta :  [ 0.18370343  0.16533664  0.5041435   0.38924963  0.36164302  0.54585307\n",
      "  1.18332107  0.46196553  1.06037138 -0.15210647 -0.16473784  0.26804727\n",
      "  0.75478607  0.40971017]\n",
      "New theta_0 : [ 0.17389368  0.16126655  0.4880885   0.3851875   0.35101672  0.54172784\n",
      "  1.17361447  0.45333356  1.04492849 -0.15587213 -0.17061074  0.25929874\n",
      "  0.7385994   0.40090732]\n",
      "Training Error:  27.79917029880176\n",
      "====================================================================================================\n",
      "Iteration:  44\n",
      "Previous theta :  [ 0.17389368  0.16126655  0.4880885   0.3851875   0.35101672  0.54172784\n",
      "  1.17361447  0.45333356  1.04492849 -0.15587213 -0.17061074  0.25929874\n",
      "  0.7385994   0.40090732]\n",
      "New theta_0 : [ 0.16452589  0.15737768  0.47256938  0.38117123  0.34078578  0.53758774\n",
      "  1.1640803   0.44476187  1.02977727 -0.15931726 -0.17618243  0.25077198\n",
      "  0.72282047  0.39219818]\n",
      "Training Error:  27.33199024800108\n",
      "====================================================================================================\n",
      "Iteration:  45\n",
      "Previous theta :  [ 0.16452589  0.15737768  0.47256938  0.38117123  0.34078578  0.53758774\n",
      "  1.1640803   0.44476187  1.02977727 -0.15931726 -0.17618243  0.25077198\n",
      "  0.72282047  0.39219818]\n",
      "New theta_0 : [ 0.15558054  0.1536598   0.45756606  0.37720047  0.33093653  0.53343532\n",
      "  1.15471262  0.43625419  1.01490806 -0.16245784 -0.18146669  0.24245968\n",
      "  0.70744062  0.38358316]\n",
      "Training Error:  26.881527739710894\n",
      "====================================================================================================\n",
      "Iteration:  46\n",
      "Previous theta :  [ 0.15558054  0.1536598   0.45756606  0.37720047  0.33093653  0.53343532\n",
      "  1.15471262  0.43625419  1.01490806 -0.16245784 -0.18146669  0.24245968\n",
      "  0.70744062  0.38358316]\n",
      "New theta_0 : [ 0.14703899  0.15010324  0.44305928  0.37327485  0.32145571  0.52927296\n",
      "  1.14550576  0.42781395  1.00031159 -0.16530908 -0.18647665  0.23435486\n",
      "  0.69245126  0.37506259]\n",
      "Training Error:  26.447037409599066\n",
      "====================================================================================================\n",
      "Iteration:  47\n",
      "Previous theta :  [ 0.14703899  0.15010324  0.44305928  0.37327485  0.32145571  0.52927296\n",
      "  1.14550576  0.42781395  1.00031159 -0.16530908 -0.18647665  0.23435486\n",
      "  0.69245126  0.37506259]\n",
      "New theta_0 : [ 0.13888341  0.14669892  0.42903066  0.36939396  0.31233048  0.52510294\n",
      "  1.13645433  0.41944429  0.98597903 -0.16788543 -0.19122479  0.22645081\n",
      "  0.67784383  0.36663669]\n",
      "Training Error:  26.027810355720344\n",
      "====================================================================================================\n",
      "Iteration:  48\n",
      "Previous theta :  [ 0.13888341  0.14669892  0.42903066  0.36939396  0.31233048  0.52510294\n",
      "  1.13645433  0.41944429  0.98597903 -0.16788543 -0.19122479  0.22645081\n",
      "  0.67784383  0.36663669]\n",
      "New theta_0 : [ 0.13109677  0.14343827  0.41546258  0.36555741  0.30354838  0.52092737\n",
      "  1.12755323  0.41114808  0.97190191 -0.17020063 -0.19572301  0.21874109\n",
      "  0.66360986  0.35830561]\n",
      "Training Error:  25.6231723116746\n",
      "====================================================================================================\n",
      "Iteration:  49\n",
      "Previous theta :  [ 0.13109677  0.14343827  0.41546258  0.36555741  0.30354838  0.52092737\n",
      "  1.12755323  0.41114808  0.97190191 -0.17020063 -0.19572301  0.21874109\n",
      "  0.66360986  0.35830561]\n",
      "New theta_0 : [ 0.12366276  0.14031319  0.40233817  0.36176477  0.29509737  0.51674826\n",
      "  1.11879758  0.40292793  0.95807213 -0.17226776 -0.19998264  0.21121949\n",
      "  0.64974096  0.35006941]\n",
      "Training Error:  25.232481912693192\n",
      "====================================================================================================\n",
      "Iteration:  50\n",
      "Previous theta :  [ 0.12366276  0.14031319  0.40233817  0.36176477  0.29509737  0.51674826\n",
      "  1.11879758  0.40292793  0.95807213 -0.17226776 -0.19998264  0.21121949\n",
      "  0.64974096  0.35006941]\n",
      "New theta_0 : [ 0.11656582  0.13731608  0.3896413   0.3580156   0.28696575  0.51256747\n",
      "  1.11018277  0.39478619  0.94448194 -0.17409924 -0.20401448  0.20388007\n",
      "  0.63622882  0.34192808]\n",
      "Training Error:  24.85512904965667\n",
      "====================================================================================================\n",
      "Iteration:  51\n",
      "Previous theta :  [ 0.11656582  0.13731608  0.3896413   0.3580156   0.28696575  0.51256747\n",
      "  1.11018277  0.39478619  0.94448194 -0.17409924 -0.20401448  0.20388007\n",
      "  0.63622882  0.34192808]\n",
      "New theta_0 : [ 0.10979105  0.13443976  0.37735651  0.35430946  0.27914223  0.50838677\n",
      "  1.10170439  0.386725    0.93112393 -0.17570692 -0.20782884  0.1967171\n",
      "  0.62306524  0.33388154]\n",
      "Training Error:  24.49053330632808\n",
      "====================================================================================================\n",
      "Iteration:  52\n",
      "Previous theta :  [ 0.10979105  0.13443976  0.37735651  0.35430946  0.27914223  0.50838677\n",
      "  1.10170439  0.386725    0.93112393 -0.17570692 -0.20782884  0.1967171\n",
      "  0.62306524  0.33388154]\n",
      "New theta_0 : [ 0.10332422  0.13167745  0.36546901  0.35064586  0.27161584  0.50420782\n",
      "  1.09335827  0.37874628  0.917991   -0.17710206 -0.21143554  0.18972507\n",
      "  0.61024213  0.32592961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  24.138142475358663\n",
      "====================================================================================================\n",
      "Iteration:  53\n",
      "Previous theta :  [ 0.10332422  0.13167745  0.36546901  0.35064586  0.27161584  0.50420782\n",
      "  1.09335827  0.37874628  0.917991   -0.17710206 -0.21143554  0.18972507\n",
      "  0.61024213  0.32592961]\n",
      "New theta_0 : [ 0.09715172  0.12902277  0.35396461  0.34702434  0.26437599  0.50003215\n",
      "  1.08514042  0.37085173  0.90507636 -0.17829537 -0.21484393  0.18289867\n",
      "  0.59775149  0.31807207]\n",
      "Training Error:  23.797431148883298\n",
      "====================================================================================================\n",
      "Iteration:  54\n",
      "Previous theta :  [ 0.09715172  0.12902277  0.35396461  0.34702434  0.26437599  0.50003215\n",
      "  1.08514042  0.37085173  0.90507636 -0.17829537 -0.21484393  0.18289867\n",
      "  0.59775149  0.31807207]\n",
      "New theta_0 : [ 0.09126053  0.12646969  0.34282973  0.3434444   0.25741244  0.4958612\n",
      "  1.07704706  0.36304288  0.89237349 -0.17929707 -0.21806296  0.17623281\n",
      "  0.58558544  0.31030864]\n",
      "Training Error:  23.467899379772206\n",
      "====================================================================================================\n",
      "Iteration:  55\n",
      "Previous theta :  [ 0.09126053  0.12646969  0.34282973  0.3434444   0.25741244  0.4958612\n",
      "  1.07704706  0.36304288  0.89237349 -0.17929707 -0.21806296  0.17623281\n",
      "  0.58558544  0.31030864]\n",
      "New theta_0 : [ 0.08563823  0.12401253  0.33205136  0.33990554  0.25071525  0.49169634\n",
      "  1.06907458  0.35532105  0.87987618 -0.18011688 -0.22110115  0.16972257\n",
      "  0.57373622  0.30263897]\n",
      "Training Error:  23.149071409839383\n",
      "====================================================================================================\n",
      "Iteration:  56\n",
      "Previous theta :  [ 0.08563823  0.12401253  0.33205136  0.33990554  0.25071525  0.49169634\n",
      "  1.06907458  0.35532105  0.87987618 -0.18011688 -0.22110115  0.16972257\n",
      "  0.57373622  0.30263897]\n",
      "New theta_0 : [ 0.08027291  0.12164593  0.321617    0.33640725  0.24427484  0.48753882\n",
      "  1.06121956  0.34768743  0.86757844 -0.18076403 -0.22396663  0.16336323\n",
      "  0.56219621  0.29506266]\n",
      "Training Error:  22.840494461529698\n",
      "====================================================================================================\n",
      "Iteration:  57\n",
      "Previous theta :  [ 0.08027291  0.12164593  0.321617    0.33640725  0.24427484  0.48753882\n",
      "  1.06121956  0.34768743  0.86757844 -0.18076403 -0.22396663  0.16336323\n",
      "  0.56219621  0.29506266]\n",
      "New theta_0 : [ 0.07515321  0.11936485  0.3115147   0.33294901  0.23808193  0.48338983\n",
      "  1.05347872  0.34014301  0.85547456 -0.18124736 -0.22666716  0.15715021\n",
      "  0.55095789  0.28757927]\n",
      "Training Error:  22.54173758981275\n",
      "====================================================================================================\n",
      "Iteration:  58\n",
      "Previous theta :  [ 0.07515321  0.11936485  0.3115147   0.33294901  0.23808193  0.48338983\n",
      "  1.05347872  0.34014301  0.85547456 -0.18124736 -0.22666716  0.15715021\n",
      "  0.55095789  0.28757927]\n",
      "New theta_0 : [ 0.07026826  0.11716451  0.30173297  0.3295303   0.23212754  0.47925045\n",
      "  1.04584895  0.33268866  0.84355906 -0.18157525 -0.22921016  0.15107914\n",
      "  0.54001388  0.28018831]\n",
      "Training Error:  22.252390591205003\n",
      "====================================================================================================\n",
      "Iteration:  59\n",
      "Previous theta :  [ 0.07026826  0.11716451  0.30173297  0.3295303   0.23212754  0.47925045\n",
      "  1.04584895  0.33268866  0.84355906 -0.18157525 -0.22921016  0.15107914\n",
      "  0.54001388  0.28018831]\n",
      "New theta_0 : [ 0.06560767  0.11504042  0.29226081  0.3261506   0.22640301  0.47512173\n",
      "  1.03832729  0.3253251   0.83182666 -0.1817557  -0.2316027   0.14514577\n",
      "  0.52935692  0.27288922]\n",
      "Training Error:  21.972062967021163\n",
      "====================================================================================================\n",
      "Iteration:  60\n",
      "Previous theta :  [ 0.06560767  0.11504042  0.29226081  0.3261506   0.22640301  0.47512173\n",
      "  1.03832729  0.3253251   0.83182666 -0.1817557  -0.2316027   0.14514577\n",
      "  0.52935692  0.27288922]\n",
      "New theta_0 : [ 0.06116149  0.11298833  0.28308766  0.32280937  0.22089995  0.4710046\n",
      "  1.0309109   0.31805293  0.82027233 -0.18179632 -0.23385154  0.13934603\n",
      "  0.51897989  0.26568145]\n",
      "Training Error:  21.700382938123088\n",
      "====================================================================================================\n",
      "Iteration:  61\n",
      "Previous theta :  [ 0.06116149  0.11298833  0.28308766  0.32280937  0.22089995  0.4710046\n",
      "  1.0309109   0.31805293  0.82027233 -0.18179632 -0.23385154  0.13934603\n",
      "  0.51897989  0.26568145]\n",
      "New theta_0 : [ 0.05692024  0.11100426  0.27420336  0.31950609  0.21561028  0.46689996\n",
      "  1.02359708  0.31087261  0.80889122 -0.18170438 -0.23596312  0.13367599\n",
      "  0.50887581  0.25856437]\n",
      "Training Error:  21.43699650858987\n",
      "====================================================================================================\n",
      "Iteration:  62\n",
      "Previous theta :  [ 0.05692024  0.11100426  0.27420336  0.31950609  0.21561028  0.46689996\n",
      "  1.02359708  0.31087261  0.80889122 -0.18170438 -0.23596312  0.13367599\n",
      "  0.50887581  0.25856437]\n",
      "New theta_0 : [ 0.05287481  0.10908443  0.26559818  0.31624022  0.21052616  0.46280863\n",
      "  1.01638326  0.30378449  0.79767868 -0.18148677 -0.23794361  0.12813184\n",
      "  0.49903781  0.25153733]\n",
      "Training Error:  21.18156657587689\n",
      "====================================================================================================\n",
      "Iteration:  63\n",
      "Previous theta :  [ 0.05287481  0.10908443  0.26559818  0.31624022  0.21052616  0.46280863\n",
      "  1.01638326  0.30378449  0.79767868 -0.18148677 -0.23794361  0.12813184\n",
      "  0.49903781  0.25153733]\n",
      "New theta_0 : [ 0.04901655  0.10722528  0.25726278  0.31301122  0.20564004  0.45873139\n",
      "  1.00926697  0.29678884  0.78663026 -0.1811501  -0.2397989   0.12270994\n",
      "  0.48945918  0.24459967]\n",
      "Training Error:  20.933772085165696\n",
      "====================================================================================================\n",
      "Iteration:  64\n",
      "Previous theta :  [ 0.04901655  0.10722528  0.25726278  0.31301122  0.20564004  0.45873139\n",
      "  1.00926697  0.29678884  0.78663026 -0.1811501  -0.2397989   0.12270994\n",
      "  0.48945918  0.24459967]\n",
      "New theta_0 : [ 0.04533713  0.10542345  0.24918817  0.30981857  0.20094462  0.45466893\n",
      "  1.00224586  0.28988579  0.77574167 -0.18070064 -0.24153461  0.11740675\n",
      "  0.48013331  0.23775068]\n",
      "Training Error:  20.693307225731136\n",
      "====================================================================================================\n",
      "Iteration:  65\n",
      "Previous theta :  [ 0.04533713  0.10542345  0.24918817  0.30981857  0.20094462  0.45466893\n",
      "  1.00224586  0.28988579  0.77574167 -0.18070064 -0.24153461  0.11740675\n",
      "  0.48013331  0.23775068]\n",
      "New theta_0 : [ 0.04182862  0.10367578  0.24136572  0.30666173  0.19643286  0.45062192\n",
      "  0.99531768  0.28307542  0.76500879 -0.18014437 -0.24315612  0.11221886\n",
      "  0.47105377  0.23098962]\n",
      "Training Error:  20.459880667267914\n",
      "====================================================================================================\n",
      "Iteration:  66\n",
      "Previous theta :  [ 0.04182862  0.10367578  0.24136572  0.30666173  0.19643286  0.45062192\n",
      "  0.99531768  0.28307542  0.76500879 -0.18014437 -0.24315612  0.11221886\n",
      "  0.47105377  0.23098962]\n",
      "New theta_0 : [ 0.03848343  0.10197929  0.23378713  0.30354018  0.19209795  0.44659097\n",
      "  0.98848028  0.27635769  0.75442766 -0.179487   -0.24466856  0.10714299\n",
      "  0.46221422  0.22431575]\n",
      "Training Error:  20.233214834226484\n",
      "====================================================================================================\n",
      "Iteration:  67\n",
      "Previous theta :  [ 0.03848343  0.10197929  0.23378713  0.30354018  0.19209795  0.44659097\n",
      "  0.98848028  0.27635769  0.75442766 -0.179487   -0.24466856  0.10714299\n",
      "  0.46221422  0.22431575]\n",
      "New theta_0 : [ 0.03529431  0.10033117  0.22644444  0.30045339  0.18793333  0.44257665\n",
      "  0.98173161  0.2697325   0.74399448 -0.17873395 -0.24607683  0.10217597\n",
      "  0.45360848  0.21772828]\n",
      "Training Error:  20.01304521630898\n",
      "====================================================================================================\n",
      "Iteration:  68\n",
      "Previous theta :  [ 0.03529431  0.10033117  0.22644444  0.30045339  0.18793333  0.44257665\n",
      "  0.98173161  0.2697325   0.74399448 -0.17873395 -0.24607683  0.10217597\n",
      "  0.45360848  0.21772828]\n",
      "New theta_0 : [ 0.03225431  0.09872875  0.21932997  0.29740084  0.18393265  0.43857946\n",
      "  0.9750697   0.26319967  0.73370559 -0.17789041 -0.24738564  0.09731472\n",
      "  0.44523049  0.21122642]\n",
      "Training Error:  19.799119713369567\n",
      "====================================================================================================\n",
      "Iteration:  69\n",
      "Previous theta :  [ 0.03225431  0.09872875  0.21932997  0.29740084  0.18393265  0.43857946\n",
      "  0.9750697   0.26319967  0.73370559 -0.17789041 -0.24738564  0.09731472\n",
      "  0.44523049  0.21122642]\n",
      "New theta_0 : [ 0.0293568   0.09716954  0.21243635  0.29438201  0.1800898   0.43459989\n",
      "  0.96849266  0.25675895  0.72355746 -0.17696131 -0.24859946  0.09255629\n",
      "  0.43707433  0.20480937]\n",
      "Training Error:  19.59119801305142\n",
      "====================================================================================================\n",
      "Iteration:  70\n",
      "Previous theta :  [ 0.0293568   0.09716954  0.21243635  0.29438201  0.1800898   0.43459989\n",
      "  0.96849266  0.25675895  0.72355746 -0.17696131 -0.24859946  0.09255629\n",
      "  0.43707433  0.20480937]\n",
      "New theta_0 : [ 0.02659545  0.09565118  0.20575648  0.29139639  0.17639888  0.43063839\n",
      "  0.96199867  0.25041002  0.7135467  -0.17595138 -0.24972259  0.08789782\n",
      "  0.4291342   0.1984763 ]\n",
      "Training Error:  19.389050999575037\n",
      "====================================================================================================\n",
      "Iteration:  71\n",
      "Previous theta :  [ 0.02659545  0.09565118  0.20575648  0.29139639  0.17639888  0.43063839\n",
      "  0.96199867  0.25041002  0.7135467  -0.17595138 -0.24972259  0.08789782\n",
      "  0.4291342   0.1984763 ]\n",
      "New theta_0 : [ 0.02396417  0.09417144  0.19928353  0.28844348  0.17285418  0.42669534\n",
      "  0.95558602  0.24415251  0.70367006 -0.17486508 -0.25075913  0.08333656\n",
      "  0.42140443  0.19222636]\n",
      "Training Error:  19.192460192169563\n",
      "====================================================================================================\n",
      "Iteration:  72\n",
      "Previous theta :  [ 0.02396417  0.09417144  0.19928353  0.28844348  0.17285418  0.42669534\n",
      "  0.95558602  0.24415251  0.70367006 -0.17486508 -0.25075913  0.08333656\n",
      "  0.42140443  0.19222636]\n",
      "New theta_0 : [ 0.02145719  0.09272823  0.19301093  0.28552276  0.16945022  0.42277114\n",
      "  0.94925303  0.237986    0.6939244  -0.1737067  -0.251713    0.07886982\n",
      "  0.4138795   0.18605871]\n",
      "Training Error:  19.00121721171186\n",
      "====================================================================================================\n",
      "Iteration:  73\n",
      "Previous theta :  [ 0.02145719  0.09272823  0.19301093  0.28552276  0.16945022  0.42277114\n",
      "  0.94925303  0.237986    0.6939244  -0.1737067  -0.251713    0.07886982\n",
      "  0.4138795   0.18605871]\n",
      "New theta_0 : [ 0.01906894  0.09131956  0.18693235  0.28263375  0.16618169  0.4188661\n",
      "  0.9429981   0.23191     0.68430667 -0.17248032 -0.25258794  0.07449504\n",
      "  0.40655398  0.17997248]\n",
      "Training Error:  18.815123274206243\n",
      "====================================================================================================\n",
      "Iteration:  74\n",
      "Previous theta :  [ 0.01906894  0.09131956  0.18693235  0.28263375  0.16618169  0.4188661\n",
      "  0.9429981   0.23191     0.68430667 -0.17248032 -0.25258794  0.07449504\n",
      "  0.40655398  0.17997248]\n",
      "New theta_0 : [ 0.01679414  0.08994357  0.18104169  0.27977595  0.16304349  0.41498054\n",
      "  0.9368197   0.225924    0.67481397 -0.17118982 -0.25338755  0.07020973\n",
      "  0.3994226   0.17396681]\n",
      "Training Error:  18.633988709802736\n",
      "====================================================================================================\n",
      "Iteration:  75\n",
      "Previous theta :  [ 0.01679414  0.08994357  0.18104169  0.27977595  0.16304349  0.41498054\n",
      "  0.9368197   0.225924    0.67481397 -0.17118982 -0.25338755  0.07020973\n",
      "  0.3994226   0.17396681]\n",
      "New theta_0 : [ 0.01462771  0.08859851  0.17533308  0.27694889  0.16003069  0.41111474\n",
      "  0.93071636  0.22002741  0.66544348 -0.16983892 -0.25411527  0.06601147\n",
      "  0.39248019  0.16804081]\n",
      "Training Error:  18.457632506112734\n",
      "====================================================================================================\n",
      "Iteration:  76\n",
      "Previous theta :  [ 0.01462771  0.08859851  0.17533308  0.27694889  0.16003069  0.41111474\n",
      "  0.93071636  0.22002741  0.66544348 -0.16983892 -0.25411527  0.06601147\n",
      "  0.39248019  0.16804081]\n",
      "New theta_0 : [ 0.01256481  0.08728272  0.16980086  0.27415209  0.15713853  0.40726895\n",
      "  0.92468665  0.21421965  0.65619249 -0.16843116 -0.25477437  0.06189793\n",
      "  0.38572171  0.16219361]\n",
      "Training Error:  18.28588187463907\n",
      "====================================================================================================\n",
      "Iteration:  77\n",
      "Previous theta :  [ 0.01256481  0.08728272  0.16980086  0.27415209  0.15713853  0.40726895\n",
      "  0.92468665  0.21421965  0.65619249 -0.16843116 -0.25477437  0.06189793\n",
      "  0.38572171  0.16219361]\n",
      "New theta_0 : [ 0.0106008   0.08599463  0.16443957  0.27138507  0.15436243  0.40344341\n",
      "  0.9187292   0.20850005  0.64705838 -0.16696989 -0.255368    0.05786687\n",
      "  0.37914225  0.15642432]\n",
      "Training Error:  18.11857183919243\n",
      "====================================================================================================\n",
      "Iteration:  78\n",
      "Previous theta :  [ 0.0106008   0.08599463  0.16443957  0.27138507  0.15436243  0.40344341\n",
      "  0.9187292   0.20850005  0.64705838 -0.16696989 -0.255368    0.05786687\n",
      "  0.37914225  0.15642432]\n",
      "New theta_0 : [ 0.00873126  0.08473278  0.15924395  0.26864739  0.15169797  0.3996383\n",
      "  0.9128427   0.20286795  0.63803862 -0.16545835 -0.25589916  0.0539161\n",
      "  0.372737    0.15073204]\n",
      "Training Error:  17.95554484521841\n",
      "====================================================================================================\n",
      "Iteration:  79\n",
      "Previous theta :  [ 0.00873126  0.08473278  0.15924395  0.26864739  0.15169797  0.3996383\n",
      "  0.9128427   0.20286795  0.63803862 -0.16545835 -0.25589916  0.0539161\n",
      "  0.372737    0.15073204]\n",
      "New theta_0 : [ 0.00695195  0.08349577  0.15420894  0.26593857  0.14914091  0.39585382\n",
      "  0.90702589  0.19732263  0.62913077 -0.16389958 -0.25637074  0.05004352\n",
      "  0.36650128  0.14511588]\n",
      "Training Error:  17.796650389009205\n",
      "====================================================================================================\n",
      "Iteration:  80\n",
      "Previous theta :  [ 0.00695195  0.08349577  0.15420894  0.26593857  0.14914091  0.39585382\n",
      "  0.90702589  0.19732263  0.62913077 -0.16389958 -0.25637074  0.05004352\n",
      "  0.36650128  0.14511588]\n",
      "New theta_0 : [ 0.00525882  0.08228231  0.14932965  0.26325818  0.14668713  0.39209012\n",
      "  0.90127752  0.19186336  0.62033248 -0.16229652 -0.25678549  0.04624709\n",
      "  0.36043052  0.13957493]\n",
      "Training Error:  17.641744665821452\n",
      "====================================================================================================\n",
      "Iteration:  81\n",
      "Previous theta :  [ 0.00525882  0.08228231  0.14932965  0.26325818  0.14668713  0.39209012\n",
      "  0.90127752  0.19186336  0.62033248 -0.16229652 -0.25678549  0.04624709\n",
      "  0.36043052  0.13957493]\n",
      "New theta_0 : [ 0.003648    0.08109116  0.14460134  0.26060578  0.14433269  0.38834736\n",
      "  0.89559643  0.18648938  0.61164148 -0.16065196 -0.25714604  0.04252483\n",
      "  0.35452026  0.13410831]\n",
      "Training Error:  17.490690235966856\n",
      "====================================================================================================\n",
      "Iteration:  82\n",
      "Previous theta :  [ 0.003648    0.08109116  0.14460134  0.26060578  0.14433269  0.38834736\n",
      "  0.89559643  0.18648938  0.61164148 -0.16065196 -0.25714604  0.04252483\n",
      "  0.35452026  0.13410831]\n",
      "New theta_0 : [ 0.00211579  0.07992115  0.14001948  0.25798093  0.14207377  0.38462564\n",
      "  0.88998147  0.1811999   0.60305556 -0.15896855 -0.25745492  0.03887484\n",
      "  0.34876616  0.12871512]\n",
      "Training Error:  17.34335570798548\n",
      "====================================================================================================\n",
      "Iteration:  83\n",
      "Previous theta :  [ 0.00211579  0.07992115  0.14001948  0.25798093  0.14207377  0.38462564\n",
      "  0.88998147  0.1811999   0.60305556 -0.15896855 -0.25745492  0.03887484\n",
      "  0.34876616  0.12871512]\n",
      "New theta_0 : [ 6.58658507e-04  7.87712053e-02  1.35579651e-01  2.55383207e-01\n",
      "  1.39906701e-01  3.80925090e-01  8.84431536e-01  1.75994123e-01\n",
      "  5.94572587e-01 -1.57248821e-01 -2.57714549e-01  3.52952649e-02\n",
      "  3.43163973e-01  1.23394444e-01]\n",
      "Training Error:  17.199615438052774\n",
      "====================================================================================================\n",
      "Iteration:  84\n",
      "Previous theta :  [ 6.58658507e-04  7.87712053e-02  1.35579651e-01  2.55383207e-01\n",
      "  1.39906701e-01  3.80925090e-01  8.84431536e-01  1.75994123e-01\n",
      "  5.94572587e-01 -1.57248821e-01 -2.57714549e-01  3.52952649e-02\n",
      "  3.43163973e-01  1.23394444e-01]\n",
      "New theta_0 : [-7.26789412e-04  7.76402839e-02  1.31277622e-01  2.52812201e-01\n",
      "  1.37827948e-01  3.77245785e-01  8.78945563e-01  1.70871222e-01\n",
      "  5.86190516e-01 -1.55495198e-01 -2.57927238e-01  3.17843158e-02\n",
      "  3.37709573e-01  1.18145403e-01]\n",
      "Training Error:  17.059349244810875\n",
      "====================================================================================================\n",
      "Iteration:  85\n",
      "Previous theta :  [-7.26789412e-04  7.76402839e-02  1.31277622e-01  2.52812201e-01\n",
      "  1.37827948e-01  3.77245785e-01  8.78945563e-01  1.70871222e-01\n",
      "  5.86190516e-01 -1.55495198e-01 -2.57927238e-01  3.17843158e-02\n",
      "  3.37709573e-01  1.18145403e-01]\n",
      "New theta_0 : [-0.00204378  0.07652742  0.12710929  0.2502675   0.13583411  0.3735878\n",
      "  0.87352252  0.16583036  0.57790735 -0.15370998 -0.2580952   0.02834026\n",
      "  0.33239893  0.1129671 ]\n",
      "Training Error:  16.922442138852393\n",
      "====================================================================================================\n",
      "Iteration:  86\n",
      "Previous theta :  [-0.00204378  0.07652742  0.12710929  0.2502675   0.13583411  0.3735878\n",
      "  0.87352252  0.16583036  0.57790735 -0.15370998 -0.2580952   0.02834026\n",
      "  0.33239893  0.1129671 ]\n",
      "New theta_0 : [-0.00329541  0.0754317   0.1230707   0.2477487   0.13392189  0.36995121\n",
      "  0.8681614   0.16087067  0.56972117 -0.15189537 -0.25822057  0.02496142\n",
      "  0.32722813  0.10785863]\n",
      "Training Error:  16.788784066120947\n",
      "====================================================================================================\n",
      "Iteration:  87\n",
      "Previous theta :  [-0.00329541  0.0754317   0.1230707   0.2477487   0.13392189  0.36995121\n",
      "  0.8681614   0.16087067  0.56972117 -0.15189537 -0.25822057  0.02496142\n",
      "  0.32722813  0.10785863]\n",
      "New theta_0 : [-0.00448464  0.07435226  0.11915802  0.24525542  0.13208814  0.36633605\n",
      "  0.86286124  0.1559913   0.56163011 -0.15005346 -0.25830536  0.02164617\n",
      "  0.32219334  0.10281912]\n",
      "Training Error:  16.658269664527303\n",
      "====================================================================================================\n",
      "Iteration:  88\n",
      "Previous theta :  [-0.00448464  0.07435226  0.11915802  0.24525542  0.13208814  0.36633605\n",
      "  0.86286124  0.1559913   0.56163011 -0.15005346 -0.25830536  0.02164617\n",
      "  0.32219334  0.10281912]\n",
      "New theta_0 : [-0.00561428  0.0732883   0.11536755  0.24278725  0.13032982  0.36274236\n",
      "  0.85762109  0.15119137  0.55363236 -0.14818625 -0.25835153  0.01839293\n",
      "  0.31729084  0.09784769]\n",
      "Training Error:  16.530798033112976\n",
      "====================================================================================================\n",
      "Iteration:  89\n",
      "Previous theta :  [-0.00561428  0.0732883   0.11536755  0.24278725  0.13032982  0.36274236\n",
      "  0.85762109  0.15119137  0.55363236 -0.14818625 -0.25835153  0.01839293\n",
      "  0.31729084  0.09784769]\n",
      "New theta_0 : [-0.00668705  0.07223905  0.11169573  0.24034384  0.128644    0.35917016\n",
      "  0.85244005  0.14646998  0.54572617 -0.14629563 -0.25836095  0.01520018\n",
      "  0.31251699  0.09294344]\n",
      "Training Error:  16.406272513124744\n",
      "====================================================================================================\n",
      "Iteration:  90\n",
      "Previous theta :  [-0.00668705  0.07223905  0.11169573  0.24034384  0.128644    0.35917016\n",
      "  0.85244005  0.14646998  0.54572617 -0.14629563 -0.25836095  0.01520018\n",
      "  0.31251699  0.09294344]\n",
      "New theta_0 : [-0.00770552  0.07120379  0.10813909  0.2379248   0.12702784  0.35561947\n",
      "  0.84731723  0.14182624  0.53790985 -0.14438344 -0.25833538  0.01206643\n",
      "  0.30786828  0.0881055 ]\n",
      "Training Error:  16.28460048039389\n",
      "====================================================================================================\n",
      "Iteration:  91\n",
      "Previous theta :  [-0.00770552  0.07120379  0.10813909  0.2379248   0.12702784  0.35561947\n",
      "  0.84731723  0.14182624  0.53790985 -0.14438344 -0.25833538  0.01206643\n",
      "  0.30786828  0.0881055 ]\n",
      "New theta_0 : [-0.00867216  0.07018185  0.10469429  0.23552977  0.12547864  0.35209029\n",
      "  0.84225177  0.13725925  0.53018175 -0.14245139 -0.25827656  0.00899026\n",
      "  0.30334125  0.08333301]\n",
      "Training Error:  16.16569314844294\n",
      "====================================================================================================\n",
      "Iteration:  92\n",
      "Previous theta :  [-0.00867216  0.07018185  0.10469429  0.23552977  0.12547864  0.35209029\n",
      "  0.84225177  0.13725925  0.53018175 -0.14245139 -0.25827656  0.00899026\n",
      "  0.30334125  0.08333301]\n",
      "New theta_0 : [-0.00958934  0.06917259  0.10135811  0.23315839  0.12399378  0.34858261\n",
      "  0.83724283  0.13276809  0.52254028 -0.14050114 -0.2581861   0.00597027\n",
      "  0.29893255  0.0786251 ]\n",
      "Training Error:  16.04946538177036\n",
      "====================================================================================================\n",
      "Iteration:  93\n",
      "Previous theta :  [-0.00958934  0.06917259  0.10135811  0.23315839  0.12399378  0.34858261\n",
      "  0.83724283  0.13276809  0.52254028 -0.14050114 -0.2581861   0.00597027\n",
      "  0.29893255  0.0786251 ]\n",
      "New theta_0 : [-0.0104593   0.06817542  0.09812742  0.23081033  0.12257074  0.34509642\n",
      "  0.8322896   0.12835185  0.5149839  -0.13853426 -0.25806559  0.00300512\n",
      "  0.29463893  0.07398091]\n",
      "Training Error:  15.93583551879032\n",
      "====================================================================================================\n",
      "Iteration:  94\n",
      "Previous theta :  [-0.0104593   0.06817542  0.09812742  0.23081033  0.12257074  0.34509642\n",
      "  0.8322896   0.12835185  0.5149839  -0.13853426 -0.25806559  0.00300512\n",
      "  0.29463893  0.07398091]\n",
      "New theta_0 : [-1.12842077e-02  6.71897773e-02  9.49991907e-02  2.28485226e-01\n",
      "  1.21207106e-01  3.41631688e-01  8.27391281e-01  1.24009613e-01\n",
      "  5.07511094e-01 -1.36552252e-01 -2.57916533e-01  9.35001722e-05\n",
      "  2.90457199e-01  6.93995880e-02]\n",
      "Training Error:  15.824725203929997\n",
      "====================================================================================================\n",
      "Iteration:  95\n",
      "Previous theta :  [-1.12842077e-02  6.71897773e-02  9.49991907e-02  2.28485226e-01\n",
      "  1.21207106e-01  3.41631688e-01  8.27391281e-01  1.24009613e-01\n",
      "  5.07511094e-01 -1.36552252e-01 -2.57916533e-01  9.35001722e-05\n",
      "  2.90457199e-01  6.93995880e-02]\n",
      "New theta_0 : [-0.01206612  0.06621512  0.09197049  0.22618276  0.11990053  0.33818839\n",
      "  0.82254711  0.11974046  0.50012042 -0.13455654 -0.25774036 -0.00276586\n",
      "  0.28638428  0.06488029]\n",
      "Training Error:  15.716059228411108\n",
      "====================================================================================================\n",
      "Iteration:  96\n",
      "Previous theta :  [-0.01206612  0.06621512  0.09197049  0.22618276  0.11990053  0.33818839\n",
      "  0.82254711  0.11974046  0.50012042 -0.13455654 -0.25774036 -0.00276586\n",
      "  0.28638428  0.06488029]\n",
      "New theta_0 : [-0.01280702  0.06525097  0.0890385   0.22390259  0.11864878  0.33476649\n",
      "  0.81775632  0.11554346  0.49281046 -0.13254848 -0.25753846 -0.00557419\n",
      "  0.28241715  0.06042217]\n",
      "Training Error:  15.609765379265752\n",
      "====================================================================================================\n",
      "Iteration:  97\n",
      "Previous theta :  [-0.01280702  0.06525097  0.0890385   0.22390259  0.11864878  0.33476649\n",
      "  0.81775632  0.11554346  0.49281046 -0.13254848 -0.25753846 -0.00557419\n",
      "  0.28241715  0.06042217]\n",
      "New theta_0 : [-0.01350877  0.06429684  0.08620045  0.22164441  0.11744969  0.33136594\n",
      "  0.81301819  0.11141769  0.48557983 -0.13052938 -0.25731214 -0.00833269\n",
      "  0.27855289  0.0560244 ]\n",
      "Training Error:  15.505774296158728\n",
      "====================================================================================================\n",
      "Iteration:  98\n",
      "Previous theta :  [-0.01350877  0.06429684  0.08620045  0.22164441  0.11744969  0.33136594\n",
      "  0.81301819  0.11141769  0.48557983 -0.13052938 -0.25731214 -0.00833269\n",
      "  0.27855289  0.0560244 ]\n",
      "New theta_0 : [-0.01417318  0.0633523   0.08345371  0.2194079   0.11630118  0.32798668\n",
      "  0.80833201  0.10736224  0.47842721 -0.12850047 -0.25706269 -0.0110425\n",
      "  0.27478865  0.05168615]\n",
      "Training Error:  15.404019335609775\n",
      "====================================================================================================\n",
      "Iteration:  99\n",
      "Previous theta :  [-0.01417318  0.0633523   0.08345371  0.2194079   0.11630118  0.32798668\n",
      "  0.80833201  0.10736224  0.47842721 -0.12850047 -0.25706269 -0.0110425\n",
      "  0.27478865  0.05168615]\n",
      "New theta_0 : [-0.01480198  0.06241694  0.08079568  0.21719275  0.11520125  0.32462866\n",
      "  0.80369706  0.10337617  0.4713513  -0.12646292 -0.25679131 -0.01370476\n",
      "  0.27112166  0.04740662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  15.304436442229438\n",
      "====================================================================================================\n",
      "Iteration:  100\n",
      "Previous theta :  [-0.01480198  0.06241694  0.08079568  0.21719275  0.11520125  0.32462866\n",
      "  0.80369706  0.10337617  0.4713513  -0.12646292 -0.25679131 -0.01370476\n",
      "  0.27112166  0.04740662]\n",
      "New theta_0 : [-0.0153968   0.06149037  0.07822389  0.21499866  0.11414798  0.32129182\n",
      "  0.79911268  0.09945857  0.46435083 -0.12441786 -0.25649917 -0.01632055\n",
      "  0.26754921  0.04318499]\n",
      "Training Error:  15.206964026601637\n",
      "====================================================================================================\n",
      "Iteration:  101\n",
      "Previous theta :  [-0.0153968   0.06149037  0.07822389  0.21499866  0.11414798  0.32129182\n",
      "  0.79911268  0.09945857  0.46435083 -0.12441786 -0.25649917 -0.01632055\n",
      "  0.26754921  0.04318499]\n",
      "New theta_0 : [-0.01595922  0.06057222  0.07573591  0.21282534  0.11313951  0.31797609\n",
      "  0.79457818  0.09560852  0.45742459 -0.12236635 -0.25618738 -0.01889093\n",
      "  0.26406869  0.03902045]\n",
      "Training Error:  15.111542849464497\n",
      "====================================================================================================\n",
      "Iteration:  102\n",
      "Previous theta :  [-0.01595922  0.06057222  0.07573591  0.21282534  0.11313951  0.31797609\n",
      "  0.79457818  0.09560852  0.45742459 -0.12236635 -0.25618738 -0.01889093\n",
      "  0.26406869  0.03902045]\n",
      "New theta_0 : [-0.01649074  0.05966215  0.0733294   0.2106725   0.11217407  0.31468139\n",
      "  0.79009292  0.09182511  0.45057136 -0.1203094  -0.25585701 -0.02141694\n",
      "  0.26067755  0.03491221]\n",
      "Training Error:  15.018115911858619\n",
      "====================================================================================================\n",
      "Iteration:  103\n",
      "Previous theta :  [-0.01649074  0.05966215  0.0733294   0.2106725   0.11217407  0.31468139\n",
      "  0.79009292  0.09182511  0.45057136 -0.1203094  -0.25585701 -0.02141694\n",
      "  0.26067755  0.03491221]\n",
      "New theta_0 : [-0.01699279  0.05875984  0.07100208  0.20853986  0.11124994  0.31140764\n",
      "  0.78565626  0.08810741  0.44379    -0.118248   -0.25550908 -0.02389956\n",
      "  0.25737329  0.0308595 ]\n",
      "Training Error:  14.926628350928791\n",
      "====================================================================================================\n",
      "Iteration:  104\n",
      "Previous theta :  [-0.01699279  0.05875984  0.07100208  0.20853986  0.11124994  0.31140764\n",
      "  0.78565626  0.08810741  0.44379    -0.118248   -0.25550908 -0.02389956\n",
      "  0.25737329  0.0308595 ]\n",
      "New theta_0 : [-0.01746675  0.05786498  0.06875177  0.20642715  0.11036547  0.30815478\n",
      "  0.78126758  0.08445453  0.43707938 -0.11618305 -0.25514458 -0.02633978\n",
      "  0.25415351  0.02686153]\n",
      "Training Error:  14.83702734108122\n",
      "====================================================================================================\n",
      "Iteration:  105\n",
      "Previous theta :  [-0.01746675  0.05786498  0.06875177  0.20642715  0.11036547  0.30815478\n",
      "  0.78126758  0.08445453  0.43707938 -0.11618305 -0.25514458 -0.02633978\n",
      "  0.25415351  0.02686153]\n",
      "New theta_0 : [-0.01791393  0.0569773   0.06657632  0.20433409  0.10951907  0.30492271\n",
      "  0.77692626  0.08086556  0.43043838 -0.11411542 -0.25476444 -0.02873853\n",
      "  0.25101586  0.02291753]\n",
      "Training Error:  14.749262000213548\n",
      "====================================================================================================\n",
      "Iteration:  106\n",
      "Previous theta :  [-0.01791393  0.0569773   0.06657632  0.20433409  0.10951907  0.30492271\n",
      "  0.77692626  0.08086556  0.43043838 -0.11411542 -0.25476444 -0.02873853\n",
      "  0.25101586  0.02291753]\n",
      "New theta_0 : [-0.01833559  0.05609653  0.06447367  0.20226042  0.10870923  0.30171134\n",
      "  0.7726317   0.0773396   0.42386595 -0.11204597 -0.25436957 -0.03109673\n",
      "  0.24795804  0.01902675]\n",
      "Training Error:  14.663283300749615\n",
      "====================================================================================================\n",
      "Iteration:  107\n",
      "Previous theta :  [-0.01833559  0.05609653  0.06447367  0.20226042  0.10870923  0.30171134\n",
      "  0.7726317   0.0773396   0.42386595 -0.11204597 -0.25436957 -0.03109673\n",
      "  0.24795804  0.01902675]\n",
      "New theta_0 : [-0.01873291  0.05522241  0.0624418   0.20020589  0.10793448  0.29852058\n",
      "  0.76838332  0.07387575  0.41736103 -0.10997546 -0.25396084 -0.03341527\n",
      "  0.24497786  0.01518843]\n",
      "Training Error:  14.57904398522466\n",
      "====================================================================================================\n",
      "Iteration:  108\n",
      "Previous theta :  [-0.01873291  0.05522241  0.0624418   0.20020589  0.10793448  0.29852058\n",
      "  0.76838332  0.07387575  0.41736103 -0.10997546 -0.25396084 -0.03341527\n",
      "  0.24497786  0.01518843]\n",
      "New theta_0 : [-0.01910704  0.05435472  0.06047877  0.19817024  0.10719341  0.29535034\n",
      "  0.76418053  0.07047314  0.4109226  -0.10790467 -0.25353905 -0.03569501\n",
      "  0.24207313  0.01140182]\n",
      "Training Error:  14.496498486179942\n",
      "====================================================================================================\n",
      "Iteration:  109\n",
      "Previous theta :  [-0.01910704  0.05435472  0.06047877  0.19817024  0.10719341  0.29535034\n",
      "  0.76418053  0.07047314  0.4109226  -0.10790467 -0.25353905 -0.03569501\n",
      "  0.24207313  0.01140182]\n",
      "New theta_0 : [-0.01945908  0.05349324  0.05858269  0.19615322  0.10648465  0.29220053\n",
      "  0.76002278  0.06713087  0.40454968 -0.10583429 -0.25310502 -0.03793679\n",
      "  0.23924176  0.00766621]\n",
      "Training Error:  14.415602850138294\n",
      "====================================================================================================\n",
      "Iteration:  110\n",
      "Previous theta :  [-0.01945908  0.05349324  0.05858269  0.19615322  0.10648465  0.29220053\n",
      "  0.76002278  0.06713087  0.40454968 -0.10583429 -0.25310502 -0.03793679\n",
      "  0.23924176  0.00766621]\n",
      "New theta_0 : [-0.01979006  0.05263775  0.05675172  0.19415459  0.10580692  0.28907103\n",
      "  0.7559095   0.06384807  0.3982413  -0.10376502 -0.2526595  -0.04014143\n",
      "  0.23648172  0.00398085]\n",
      "Training Error:  14.336314665444082\n",
      "====================================================================================================\n",
      "Iteration:  111\n",
      "Previous theta :  [-0.01979006  0.05263775  0.05675172  0.19415459  0.10580692  0.28907103\n",
      "  0.7559095   0.06384807  0.3982413  -0.10376502 -0.2526595  -0.04014143\n",
      "  0.23648172  0.00398085]\n",
      "New theta_0 : [-2.01009963e-02  5.17880736e-02  5.49840885e-02  1.92174128e-01\n",
      "  1.05158952e-01  2.85961762e-01  7.51840158e-01  6.06238824e-02\n",
      "  3.91996507e-01 -1.01697502e-01 -2.52203208e-01 -4.23097265e-02\n",
      "  2.33791018e-01  3.45033843e-04]\n",
      "Training Error:  14.2585929937623\n",
      "====================================================================================================\n",
      "Iteration:  112\n",
      "Previous theta :  [-2.01009963e-02  5.17880736e-02  5.49840885e-02  1.92174128e-01\n",
      "  1.05158952e-01  2.85961762e-01  7.51840158e-01  6.06238824e-02\n",
      "  3.91996507e-01 -1.01697502e-01 -2.52203208e-01 -4.23097265e-02\n",
      "  2.33791018e-01  3.45033843e-04]\n",
      "New theta_0 : [-0.02039283  0.05094402  0.05327806  0.19021159  0.10453954  0.28287261\n",
      "  0.74781421  0.05745743  0.38581438 -0.09963234 -0.25173685 -0.04444245\n",
      "  0.23116772 -0.00324195]\n",
      "Training Error:  14.182398305042618\n",
      "====================================================================================================\n",
      "Iteration:  113\n",
      "Previous theta :  [-0.02039283  0.05094402  0.05327806  0.19021159  0.10453954  0.28287261\n",
      "  0.74781421  0.05745743  0.38581438 -0.09963234 -0.25173685 -0.04444245\n",
      "  0.23116772 -0.00324195]\n",
      "New theta_0 : [-0.02066648  0.05010543  0.05163196  0.18826675  0.10394754  0.27980346\n",
      "  0.74383114  0.05434788  0.37969403 -0.09757013 -0.2512611  -0.04654036\n",
      "  0.22860996 -0.00678079]\n",
      "Training Error:  14.10769241576404\n",
      "====================================================================================================\n",
      "Iteration:  114\n",
      "Previous theta :  [-0.02066648  0.05010543  0.05163196  0.18826675  0.10394754  0.27980346\n",
      "  0.74383114  0.05434788  0.37969403 -0.09757013 -0.2512611  -0.04654036\n",
      "  0.22860996 -0.00678079]\n",
      "New theta_0 : [-0.0209228   0.04927214  0.05004415  0.18633939  0.10338183  0.27675422\n",
      "  0.73989041  0.05129436  0.37363457 -0.09551141 -0.25077659 -0.04860417\n",
      "  0.22611591 -0.01027219]\n",
      "Training Error:  14.03443843028596\n",
      "====================================================================================================\n",
      "Iteration:  115\n",
      "Previous theta :  [-0.0209228   0.04927214  0.05004415  0.18633939  0.10338183  0.27675422\n",
      "  0.73989041  0.05129436  0.37363457 -0.09551141 -0.25077659 -0.04860417\n",
      "  0.22611591 -0.01027219]\n",
      "New theta_0 : [-0.02116264  0.048444    0.04851306  0.18442929  0.10284133  0.27372478\n",
      "  0.73599154  0.04829605  0.36763514 -0.09345672 -0.25028393 -0.05063461\n",
      "  0.22368379 -0.01371682]\n",
      "Training Error:  13.96260068514045\n",
      "====================================================================================================\n",
      "Iteration:  116\n",
      "Previous theta :  [-0.02116264  0.048444    0.04851306  0.18442929  0.10284133  0.27372478\n",
      "  0.73599154  0.04829605  0.36763514 -0.09345672 -0.25028393 -0.05063461\n",
      "  0.22368379 -0.01371682]\n",
      "New theta_0 : [-0.02138679  0.04762088  0.04703715  0.18253624  0.10232503  0.27071503\n",
      "  0.73213401  0.04535211  0.36169491 -0.09140654 -0.24978371 -0.05263237\n",
      "  0.22131189 -0.01711537]\n",
      "Training Error:  13.89214469610946\n",
      "====================================================================================================\n",
      "Iteration:  117\n",
      "Previous theta :  [-0.02138679  0.04762088  0.04703715  0.18253624  0.10232503  0.27071503\n",
      "  0.73213401  0.04535211  0.36169491 -0.09140654 -0.24978371 -0.05263237\n",
      "  0.22131189 -0.01711537]\n",
      "New theta_0 : [-0.02159599  0.04680264  0.04561491  0.18066004  0.10183193  0.26772485\n",
      "  0.72831734  0.04246172  0.35581305 -0.08936136 -0.2492765  -0.05459811\n",
      "  0.21899854 -0.02046849]\n",
      "Training Error:  13.82303710793894\n",
      "====================================================================================================\n",
      "Iteration:  118\n",
      "Previous theta :  [-0.02159599  0.04680264  0.04561491  0.18066004  0.10183193  0.26772485\n",
      "  0.72831734  0.04246172  0.35581305 -0.08936136 -0.2492765  -0.05459811\n",
      "  0.21899854 -0.02046849]\n",
      "New theta_0 : [-0.02179099  0.04598917  0.04424491  0.17880048  0.10136109  0.26475413\n",
      "  0.72454103  0.03962406  0.34998878 -0.0873216  -0.24876282 -0.0565325\n",
      "  0.2167421  -0.02377683]\n",
      "Training Error:  13.755245646549856\n",
      "====================================================================================================\n",
      "Iteration:  119\n",
      "Previous theta :  [-0.02179099  0.04598917  0.04424491  0.17880048  0.10136109  0.26475413\n",
      "  0.72454103  0.03962406  0.34998878 -0.0873216  -0.24876282 -0.0565325\n",
      "  0.2167421  -0.02377683]\n",
      "New theta_0 : [-0.02197247  0.04518035  0.04292574  0.17695736  0.10091159  0.26180276\n",
      "  0.72080462  0.03683833  0.3442213  -0.08528771 -0.24824321 -0.05843617\n",
      "  0.214541   -0.02704106]\n",
      "Training Error:  13.68873907361347\n",
      "====================================================================================================\n",
      "Iteration:  120\n",
      "Previous theta :  [-0.02197247  0.04518035  0.04292574  0.17695736  0.10091159  0.26180276\n",
      "  0.72080462  0.03683833  0.3442213  -0.08528771 -0.24824321 -0.05843617\n",
      "  0.214541   -0.02704106]\n",
      "New theta_0 : [-0.02214108  0.04437607  0.04165601  0.17513049  0.10048255  0.25887063\n",
      "  0.71710764  0.03410374  0.33850986 -0.08326006 -0.24771814 -0.06030975\n",
      "  0.21239369 -0.0302618 ]\n",
      "Training Error:  13.623487143365493\n",
      "====================================================================================================\n",
      "Iteration:  121\n",
      "Previous theta :  [-0.02214108  0.04437607  0.04165601  0.17513049  0.10048255  0.25887063\n",
      "  0.71710764  0.03410374  0.33850986 -0.08326006 -0.24771814 -0.06030975\n",
      "  0.21239369 -0.0302618 ]\n",
      "New theta_0 : [-0.02229747  0.04357625  0.0404344   0.17331968  0.10007313  0.25595763\n",
      "  0.71344962  0.03141949  0.3328537  -0.08123906 -0.24718809 -0.06215384\n",
      "  0.2102987  -0.03343968]\n",
      "Training Error:  13.55946056154041\n",
      "====================================================================================================\n",
      "Iteration:  122\n",
      "Previous theta :  [-0.02229747  0.04357625  0.0404344   0.17331968  0.10007313  0.25595763\n",
      "  0.71344962  0.03141949  0.3328537  -0.08123906 -0.24718809 -0.06215384\n",
      "  0.2102987  -0.03343968]\n",
      "New theta_0 : [-0.02244222  0.04278079  0.03925961  0.17152475  0.09968253  0.25306363\n",
      "  0.70983011  0.02878479  0.32725209 -0.07922504 -0.24665352 -0.06396904\n",
      "  0.20825456 -0.03657533]\n",
      "Training Error:  13.496630946313601\n",
      "====================================================================================================\n",
      "Iteration:  123\n",
      "Previous theta :  [-0.02244222  0.04278079  0.03925961  0.17152475  0.09968253  0.25306363\n",
      "  0.70983011  0.02878479  0.32725209 -0.07922504 -0.24665352 -0.06396904\n",
      "  0.20825456 -0.03657533]\n",
      "New theta_0 : [-0.02257593  0.04198959  0.03813039  0.1697455   0.09930996  0.25018852\n",
      "  0.70624866  0.02619889  0.32170432 -0.07721835 -0.24611486 -0.06575591\n",
      "  0.20625987 -0.03966935]\n",
      "Training Error:  13.43497079114514\n",
      "====================================================================================================\n",
      "Iteration:  124\n",
      "Previous theta :  [-0.02257593  0.04198959  0.03813039  0.1697455   0.09930996  0.25018852\n",
      "  0.70624866  0.02619889  0.32170432 -0.07721835 -0.24611486 -0.06575591\n",
      "  0.20625987 -0.03966935]\n",
      "New theta_0 : [-0.02269913  0.0412026   0.03704551  0.16798176  0.09895468  0.24733218\n",
      "  0.70270483  0.02366102  0.31620969 -0.0752193  -0.24557252 -0.06751502\n",
      "  0.20431325 -0.04272236]\n",
      "Training Error:  13.374453429424623\n",
      "====================================================================================================\n",
      "Iteration:  125\n",
      "Previous theta :  [-0.02269913  0.0412026   0.03704551  0.16798176  0.09895468  0.24733218\n",
      "  0.70270483  0.02366102  0.31620969 -0.0752193  -0.24557252 -0.06751502\n",
      "  0.20431325 -0.04272236]\n",
      "New theta_0 : [-0.02281235  0.04041972  0.03600378  0.16623336  0.09861597  0.24449451\n",
      "  0.69919818  0.02117042  0.31076751 -0.0732282  -0.24502689 -0.06924691\n",
      "  0.20241338 -0.04573495]\n",
      "Training Error:  13.315053000822072\n",
      "====================================================================================================\n",
      "Iteration:  126\n",
      "Previous theta :  [-0.02281235  0.04041972  0.03600378  0.16623336  0.09861597  0.24449451\n",
      "  0.69919818  0.02117042  0.31076751 -0.0732282  -0.24502689 -0.06924691\n",
      "  0.20241338 -0.04573495]\n",
      "New theta_0 : [-0.0229161   0.03964089  0.03500404  0.16450013  0.09829314  0.24167538\n",
      "  0.69572829  0.01872634  0.3053771  -0.07124533 -0.24447836 -0.07095212\n",
      "  0.20055897 -0.0487077 ]\n",
      "Training Error:  13.256744419254934\n",
      "====================================================================================================\n",
      "Iteration:  127\n",
      "Previous theta :  [-0.0229161   0.03964089  0.03500404  0.16450013  0.09829314  0.24167538\n",
      "  0.69572829  0.01872634  0.3053771  -0.07124533 -0.24447836 -0.07095212\n",
      "  0.20055897 -0.0487077 ]\n",
      "New theta_0 : [-0.02301084  0.03886605  0.03404516  0.16278189  0.09798553  0.23887468\n",
      "  0.69229472  0.01632806  0.30003782 -0.06927094 -0.2439273  -0.07263116\n",
      "  0.19874875 -0.0516412 ]\n",
      "Training Error:  13.199503342386134\n",
      "====================================================================================================\n",
      "Iteration:  128\n",
      "Previous theta :  [-0.02301084  0.03886605  0.03404516  0.16278189  0.09798553  0.23887468\n",
      "  0.69229472  0.01632806  0.30003782 -0.06927094 -0.2439273  -0.07263116\n",
      "  0.19874875 -0.0516412 ]\n",
      "New theta_0 : [-0.02309704  0.03809514  0.03312605  0.16107849  0.0976925   0.23609228\n",
      "  0.68889708  0.01397484  0.29474902 -0.0673053  -0.24337404 -0.07428455\n",
      "  0.19698151 -0.05453602]\n",
      "Training Error:  13.143306142572786\n",
      "====================================================================================================\n",
      "Iteration:  129\n",
      "Previous theta :  [-0.02309704  0.03809514  0.03312605  0.16107849  0.0976925   0.23609228\n",
      "  0.68889708  0.01397484  0.29474902 -0.0673053  -0.24337404 -0.07428455\n",
      "  0.19698151 -0.05453602]\n",
      "New theta_0 : [-0.02317512  0.0373281   0.03224565  0.15938976  0.09741344  0.23332808\n",
      "  0.68553493  0.01166597  0.28951006 -0.06534863 -0.24281892 -0.07591277\n",
      "  0.19525607 -0.05739271]\n",
      "Training Error:  13.088129879189424\n",
      "====================================================================================================\n",
      "Iteration:  130\n",
      "Previous theta :  [-0.02317512  0.0373281   0.03224565  0.15938976  0.09741344  0.23332808\n",
      "  0.68553493  0.01166597  0.28951006 -0.06534863 -0.24281892 -0.07591277\n",
      "  0.19525607 -0.05739271]\n",
      "New theta_0 : [-0.02324551  0.03656489  0.03140291  0.15771554  0.09714777  0.23058196\n",
      "  0.68220788  0.00940073  0.28432033 -0.06340116 -0.24226225 -0.0775163\n",
      "  0.19357126 -0.06021185]\n",
      "Training Error:  13.033952272253895\n",
      "====================================================================================================\n",
      "Iteration:  131\n",
      "Previous theta :  [-0.02324551  0.03656489  0.03140291  0.15771554  0.09714777  0.23058196\n",
      "  0.68220788  0.00940073  0.28432033 -0.06340116 -0.24226225 -0.0775163\n",
      "  0.19357126 -0.06021185]\n",
      "New theta_0 : [-0.0233086   0.03580544  0.03059683  0.15605568  0.09689492  0.22785379\n",
      "  0.67891553  0.00717843  0.27917921 -0.06146308 -0.24170434 -0.07909562\n",
      "  0.19192597 -0.06299396]\n",
      "Training Error:  12.980751677287849\n",
      "====================================================================================================\n",
      "Iteration:  132\n",
      "Previous theta :  [-0.0233086   0.03580544  0.03059683  0.15605568  0.09689492  0.22785379\n",
      "  0.67891553  0.00717843  0.27917921 -0.06146308 -0.24170434 -0.07909562\n",
      "  0.19192597 -0.06299396]\n",
      "New theta_0 : [-0.02336477  0.03504973  0.02982643  0.15441004  0.09665436  0.22514347\n",
      "  0.67565747  0.00499837  0.27408612 -0.0595346  -0.24114548 -0.08065118\n",
      "  0.19031912 -0.0657396 ]\n",
      "Training Error:  12.928507061347489\n",
      "====================================================================================================\n",
      "Iteration:  133\n",
      "Previous theta :  [-0.02336477  0.03504973  0.02982643  0.15441004  0.09665436  0.22514347\n",
      "  0.67565747  0.00499837  0.27408612 -0.0595346  -0.24114548 -0.08065118\n",
      "  0.19031912 -0.0657396 ]\n",
      "New theta_0 : [-0.02341438  0.03429771  0.02909074  0.15277845  0.09642555  0.22245088\n",
      "  0.67243333  0.00285988  0.26904048 -0.0576159  -0.24058595 -0.08218343\n",
      "  0.18874964 -0.06844929]\n",
      "Training Error:  12.877197980163773\n",
      "====================================================================================================\n",
      "Iteration:  134\n",
      "Previous theta :  [-0.02341438  0.03429771  0.02909074  0.15277845  0.09642555  0.22245088\n",
      "  0.67243333  0.00285988  0.26904048 -0.0576159  -0.24058595 -0.08218343\n",
      "  0.18874964 -0.06844929]\n",
      "New theta_0 : [-0.02345777  0.03354934  0.02838884  0.15116077  0.09620801  0.2197759\n",
      "  0.66924271  0.00076228  0.2640417  -0.05570713 -0.240026   -0.08369281\n",
      "  0.18721652 -0.07112356]\n",
      "Training Error:  12.826804556334508\n",
      "====================================================================================================\n",
      "Iteration:  135\n",
      "Previous theta :  [-0.02345777  0.03354934  0.02838884  0.15116077  0.09620801  0.2197759\n",
      "  0.66924271  0.00076228  0.2640417  -0.05570713 -0.240026   -0.08369281\n",
      "  0.18721652 -0.07112356]\n",
      "New theta_0 : [-0.02349527  0.03280459  0.02771983  0.14955686  0.09600125  0.21711841\n",
      "  0.66608523 -0.0012951   0.25908923 -0.05380846 -0.2394659  -0.08517973\n",
      "  0.18571875 -0.07376292]\n",
      "Training Error:  12.77730745851402\n",
      "====================================================================================================\n",
      "Iteration:  136\n",
      "Previous theta :  [-0.02349527  0.03280459  0.02771983  0.14955686  0.09600125  0.21711841\n",
      "  0.66608523 -0.0012951   0.25908923 -0.05380846 -0.2394659  -0.08517973\n",
      "  0.18571875 -0.07376292]\n",
      "New theta_0 : [-0.0235272   0.03206342  0.02708281  0.14796659  0.09580482  0.21447831\n",
      "  0.66296052 -0.00331292  0.25418251 -0.05192004 -0.23890587 -0.08664462\n",
      "  0.18425537 -0.07636788]\n",
      "Training Error:  12.72868788154882\n",
      "====================================================================================================\n",
      "Iteration:  137\n",
      "Previous theta :  [-0.0235272   0.03206342  0.02708281  0.14796659  0.09580482  0.21447831\n",
      "  0.66296052 -0.00331292  0.25418251 -0.05192004 -0.23890587 -0.08664462\n",
      "  0.18425537 -0.07636788]\n",
      "New theta_0 : [-0.02355385  0.03132581  0.02647693  0.1463898   0.09561828  0.21185547\n",
      "  0.65986821 -0.00529181  0.24932101 -0.05004198 -0.23834616 -0.08808789\n",
      "  0.18282543 -0.07893895]\n",
      "Training Error:  12.680927527510768\n",
      "====================================================================================================\n",
      "Iteration:  138\n",
      "Previous theta :  [-0.02355385  0.03132581  0.02647693  0.1463898   0.09561828  0.21185547\n",
      "  0.65986821 -0.00529181  0.24932101 -0.05004198 -0.23834616 -0.08808789\n",
      "  0.18282543 -0.07893895]\n",
      "New theta_0 : [-0.02357551  0.03059173  0.02590136  0.14482637  0.09544119  0.20924978\n",
      "  0.65680793 -0.00723241  0.2445042  -0.04817443 -0.23778698 -0.08950992\n",
      "  0.18142803 -0.08147661]\n",
      "Training Error:  12.634008587581645\n",
      "====================================================================================================\n",
      "Iteration:  139\n",
      "Previous theta :  [-0.02357551  0.03059173  0.02590136  0.14482637  0.09544119  0.20924978\n",
      "  0.65680793 -0.00723241  0.2445042  -0.04817443 -0.23778698 -0.08950992\n",
      "  0.18142803 -0.08147661]\n",
      "New theta_0 : [-0.02359245  0.02986115  0.02535529  0.14327617  0.09527316  0.20666113\n",
      "  0.65377933 -0.00913536  0.23973154 -0.04631749 -0.23722854 -0.09091111\n",
      "  0.18006227 -0.08398137]\n",
      "Training Error:  12.587913724745638\n",
      "====================================================================================================\n",
      "Iteration:  140\n",
      "Previous theta :  [-0.02359245  0.02986115  0.02535529  0.14327617  0.09527316  0.20666113\n",
      "  0.65377933 -0.00913536  0.23973154 -0.04631749 -0.23722854 -0.09091111\n",
      "  0.18006227 -0.08398137]\n",
      "New theta_0 : [-0.02360493  0.02913405  0.02483791  0.14173906  0.0951138   0.20408941\n",
      "  0.65078203 -0.01100128  0.23500254 -0.04447127 -0.23667103 -0.09229182\n",
      "  0.17872729 -0.08645368]\n",
      "Training Error:  12.5426260572486\n",
      "====================================================================================================\n",
      "Iteration:  141\n",
      "Previous theta :  [-0.02360493  0.02913405  0.02483791  0.14173906  0.0951138   0.20408941\n",
      "  0.65078203 -0.01100128  0.23500254 -0.04447127 -0.23667103 -0.09229182\n",
      "  0.17872729 -0.08645368]\n",
      "New theta_0 : [-0.02361319  0.02841041  0.02434845  0.14021492  0.09496273  0.2015345\n",
      "  0.6478157  -0.01283078  0.23031669 -0.04263586 -0.23611466 -0.09365245\n",
      "  0.17742226 -0.08889403]\n",
      "Training Error:  12.498129142785206\n",
      "====================================================================================================\n",
      "Iteration:  142\n",
      "Previous theta :  [-0.02361319  0.02841041  0.02434845  0.14021492  0.09496273  0.2015345\n",
      "  0.6478157  -0.01283078  0.23031669 -0.04263586 -0.23611466 -0.09365245\n",
      "  0.17742226 -0.08889403]\n",
      "New theta_0 : [-0.02361747  0.02769021  0.02388617  0.13870362  0.09481959  0.19899628\n",
      "  0.64487998 -0.01462446  0.22567349 -0.04081136 -0.23555959 -0.09499333\n",
      "  0.17614636 -0.09130288]\n",
      "Training Error:  12.4544069633771\n",
      "====================================================================================================\n",
      "Iteration:  143\n",
      "Previous theta :  [-0.02361747  0.02769021  0.02388617  0.13870362  0.09481959  0.19899628\n",
      "  0.64487998 -0.01462446  0.22567349 -0.04081136 -0.23555959 -0.09499333\n",
      "  0.17614636 -0.09130288]\n",
      "New theta_0 : [-0.023618    0.02697343  0.02345033  0.13720503  0.09468404  0.19647466\n",
      "  0.64197453 -0.01638291  0.22107246 -0.03899784 -0.235006   -0.09631483\n",
      "  0.1748988  -0.09368069]\n",
      "Training Error:  12.411443910907323\n",
      "====================================================================================================\n",
      "Iteration:  144\n",
      "Previous theta :  [-0.023618    0.02697343  0.02345033  0.13720503  0.09468404  0.19647466\n",
      "  0.64197453 -0.01638291  0.22107246 -0.03899784 -0.235006   -0.09631483\n",
      "  0.1748988  -0.09368069]\n",
      "New theta_0 : [-0.02361498  0.02626005  0.02304022  0.13571904  0.09455575  0.19396951\n",
      "  0.639099   -0.01810673  0.21651312 -0.03719537 -0.23445406 -0.09761729\n",
      "  0.17367882 -0.09602792]\n",
      "Training Error:  12.369224773278033\n",
      "====================================================================================================\n",
      "Iteration:  145\n",
      "Previous theta :  [-0.02361498  0.02626005  0.02304022  0.13571904  0.09455575  0.19396951\n",
      "  0.639099   -0.01810673  0.21651312 -0.03719537 -0.23445406 -0.09761729\n",
      "  0.17367882 -0.09602792]\n",
      "New theta_0 : [-0.02360863  0.02555007  0.02265514  0.13424553  0.09443439  0.19148072\n",
      "  0.63625307 -0.01979649  0.211995   -0.03540402 -0.23390392 -0.09890104\n",
      "  0.17248566 -0.098345  ]\n",
      "Training Error:  12.32773472116034\n",
      "====================================================================================================\n",
      "Iteration:  146\n",
      "Previous theta :  [-0.02360863  0.02555007  0.02265514  0.13424553  0.09443439  0.19148072\n",
      "  0.63625307 -0.01979649  0.211995   -0.03540402 -0.23390392 -0.09890104\n",
      "  0.17248566 -0.098345  ]\n",
      "New theta_0 : [-0.02359913  0.02484346  0.02229441  0.13278438  0.09431967  0.18900819\n",
      "  0.6334364  -0.02145276  0.20751764 -0.03362385 -0.23335573 -0.10016642\n",
      "  0.17131861 -0.10063237]\n",
      "Training Error:  12.286959295306833\n",
      "====================================================================================================\n",
      "Iteration:  147\n",
      "Previous theta :  [-0.02359913  0.02484346  0.02229441  0.13278438  0.09431967  0.18900819\n",
      "  0.6334364  -0.02145276  0.20751764 -0.03362385 -0.23335573 -0.10016642\n",
      "  0.17131861 -0.10063237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.02358668  0.02414021  0.02195738  0.13133547  0.0942113   0.18655181\n",
      "  0.63064867 -0.0230761   0.20308059 -0.0318549  -0.23280962 -0.10141375\n",
      "  0.17017695 -0.10289047]\n",
      "Training Error:  12.246884394398858\n",
      "====================================================================================================\n",
      "Iteration:  148\n",
      "Previous theta :  [-0.02358668  0.02414021  0.02195738  0.13133547  0.0942113   0.18655181\n",
      "  0.63064867 -0.0230761   0.20308059 -0.0318549  -0.23280962 -0.10141375\n",
      "  0.17017695 -0.10289047]\n",
      "New theta_0 : [-0.02357144  0.02344031  0.0216434   0.1298987   0.09410899  0.18411146\n",
      "  0.62788954 -0.02466707  0.1986834  -0.03009722 -0.23226574 -0.10264333\n",
      "  0.16906002 -0.10511972]\n",
      "Training Error:  12.207496263402184\n",
      "====================================================================================================\n",
      "Iteration:  149\n",
      "Previous theta :  [-0.02357144  0.02344031  0.0216434   0.1298987   0.09410899  0.18411146\n",
      "  0.62788954 -0.02466707  0.1986834  -0.03009722 -0.23226574 -0.10264333\n",
      "  0.16906002 -0.10511972]\n",
      "New theta_0 : [-0.02355358  0.02274376  0.02135184  0.12847394  0.09401248  0.18168705\n",
      "  0.6251587  -0.02622621  0.19432563 -0.02835086 -0.23172421 -0.10385549\n",
      "  0.16796714 -0.10732054]\n",
      "Training Error:  12.168781482406036\n",
      "====================================================================================================\n",
      "Iteration:  150\n",
      "Previous theta :  [-0.02355358  0.02274376  0.02135184  0.12847394  0.09401248  0.18168705\n",
      "  0.6251587  -0.02622621  0.19432563 -0.02835086 -0.23172421 -0.10385549\n",
      "  0.16796714 -0.10732054]\n",
      "New theta_0 : [-0.02353327  0.02205053  0.0210821   0.1270611   0.0939215   0.17927845\n",
      "  0.62245584 -0.02775406  0.19000686 -0.02661583 -0.23118515 -0.10505052\n",
      "  0.16689766 -0.10949334]\n",
      "Training Error:  12.13072695592195\n",
      "====================================================================================================\n",
      "Iteration:  151\n",
      "Previous theta :  [-0.02353327  0.02205053  0.0210821   0.1270611   0.0939215   0.17927845\n",
      "  0.62245584 -0.02775406  0.19000686 -0.02661583 -0.23118515 -0.10505052\n",
      "  0.16689766 -0.10949334]\n",
      "New theta_0 : [-0.02351065  0.02136063  0.02083357  0.12566006  0.09383582  0.17688557\n",
      "  0.61978063 -0.02925114  0.18572665 -0.02489217 -0.23064867 -0.10622872\n",
      "  0.16585097 -0.11163853]\n",
      "Training Error:  12.093319902619912\n",
      "====================================================================================================\n",
      "Iteration:  152\n",
      "Previous theta :  [-0.02351065  0.02136063  0.02083357  0.12566006  0.09383582  0.17688557\n",
      "  0.61978063 -0.02925114  0.18572665 -0.02489217 -0.23064867 -0.10622872\n",
      "  0.16585097 -0.11163853]\n",
      "New theta_0 : [-0.02348587  0.02067404  0.02060568  0.12427072  0.09375519  0.1745083\n",
      "  0.61713278 -0.03071798  0.18148459 -0.0231799  -0.23011488 -0.10739037\n",
      "  0.16482645 -0.11375651]\n",
      "Training Error:  12.056547845480805\n",
      "====================================================================================================\n",
      "Iteration:  153\n",
      "Previous theta :  [-0.02348587  0.02067404  0.02060568  0.12427072  0.09375519  0.1745083\n",
      "  0.61713278 -0.03071798  0.18148459 -0.0231799  -0.23011488 -0.10739037\n",
      "  0.16482645 -0.11375651]\n",
      "New theta_0 : [-0.02345907  0.01999076  0.02039787  0.12289297  0.09367938  0.17214653\n",
      "  0.61451197 -0.0321551   0.17728027 -0.02147904 -0.22958389 -0.10853576\n",
      "  0.16382352 -0.11584767]\n",
      "Training Error:  12.020398602344889\n",
      "====================================================================================================\n",
      "Iteration:  154\n",
      "Previous theta :  [-0.02345907  0.01999076  0.02039787  0.12289297  0.09367938  0.17214653\n",
      "  0.61451197 -0.0321551   0.17728027 -0.02147904 -0.22958389 -0.10853576\n",
      "  0.16382352 -0.11584767]\n",
      "New theta_0 : [-0.02343038  0.01931078  0.02020957  0.12152671  0.09360819  0.16980016\n",
      "  0.61191791 -0.03356299  0.17311328 -0.01978959 -0.22905578 -0.10966516\n",
      "  0.16284159 -0.1179124 ]\n",
      "Training Error:  11.984860276837514\n",
      "====================================================================================================\n",
      "Iteration:  155\n",
      "Previous theta :  [-0.02343038  0.01931078  0.02020957  0.12152671  0.09360819  0.16980016\n",
      "  0.61191791 -0.03356299  0.17311328 -0.01978959 -0.22905578 -0.10966516\n",
      "  0.16284159 -0.1179124 ]\n",
      "New theta_0 : [-0.02339992  0.01863409  0.02004026  0.12017185  0.0935414   0.16746909\n",
      "  0.60935029 -0.03494216  0.16898323 -0.01811157 -0.22853066 -0.11077884\n",
      "  0.16188012 -0.11995107]\n",
      "Training Error:  11.949921249653913\n",
      "====================================================================================================\n",
      "Iteration:  156\n",
      "Previous theta :  [-0.02339992  0.01863409  0.02004026  0.12017185  0.0935414   0.16746909\n",
      "  0.60935029 -0.03494216  0.16898323 -0.01811157 -0.22853066 -0.11077884\n",
      "  0.16188012 -0.11995107]\n",
      "New theta_0 : [-0.02336781  0.01796069  0.0198894   0.11882827  0.0934788   0.1651532\n",
      "  0.60680882 -0.0362931   0.16488972 -0.01644497 -0.2280086  -0.11187707\n",
      "  0.16093855 -0.12196408]\n",
      "Training Error:  11.915570170186218\n",
      "====================================================================================================\n",
      "Iteration:  157\n",
      "Previous theta :  [-0.02336781  0.01796069  0.0198894   0.11882827  0.0934788   0.1651532\n",
      "  0.60680882 -0.0362931   0.16488972 -0.01644497 -0.2280086  -0.11187707\n",
      "  0.16093855 -0.12196408]\n",
      "New theta_0 : [-0.02333417  0.01729058  0.0197565   0.11749588  0.09342022  0.16285241\n",
      "  0.60429322 -0.03761629  0.16083237 -0.0147898  -0.22748969 -0.1129601\n",
      "  0.16001637 -0.12395178]\n",
      "Training Error:  11.881795948476345\n",
      "====================================================================================================\n",
      "Iteration:  158\n",
      "Previous theta :  [-0.02333417  0.01729058  0.0197565   0.11749588  0.09342022  0.16285241\n",
      "  0.60429322 -0.03761629  0.16083237 -0.0147898  -0.22748969 -0.1129601\n",
      "  0.16001637 -0.12395178]\n",
      "New theta_0 : [-0.02329909  0.01662374  0.01964104  0.1161746   0.09336546  0.1605666\n",
      "  0.60180318 -0.03891221  0.15681079 -0.01314604 -0.22697401 -0.1140282\n",
      "  0.15911306 -0.12591454]\n",
      "Training Error:  11.848587747479687\n",
      "====================================================================================================\n",
      "Iteration:  159\n",
      "Previous theta :  [-0.02329909  0.01662374  0.01964104  0.1161746   0.09336546  0.1605666\n",
      "  0.60180318 -0.03891221  0.15681079 -0.01314604 -0.22697401 -0.1140282\n",
      "  0.15911306 -0.12591454]\n",
      "New theta_0 : [-0.02326269  0.01596018  0.01954255  0.11486431  0.09331435  0.15829568\n",
      "  0.59933844 -0.04018132  0.15282461 -0.0115137  -0.22646162 -0.1150816\n",
      "  0.15822812 -0.12785273]\n",
      "Training Error:  11.815934975624932\n",
      "====================================================================================================\n",
      "Iteration:  160\n",
      "Previous theta :  [-0.02326269  0.01596018  0.01954255  0.11486431  0.09331435  0.15829568\n",
      "  0.59933844 -0.04018132  0.15282461 -0.0115137  -0.22646162 -0.1150816\n",
      "  0.15822812 -0.12785273]\n",
      "New theta_0 : [-0.02322506  0.01529988  0.01946055  0.11356493  0.09326672  0.15603955\n",
      "  0.5968987  -0.04142408  0.14887346 -0.00989275 -0.22595259 -0.11612055\n",
      "  0.15736108 -0.12976669]\n",
      "Training Error:  11.783827279656407\n",
      "====================================================================================================\n",
      "Iteration:  161\n",
      "Previous theta :  [-0.02322506  0.01529988  0.01946055  0.11356493  0.09326672  0.15603955\n",
      "  0.5968987  -0.04142408  0.14887346 -0.00989275 -0.22595259 -0.11612055\n",
      "  0.15736108 -0.12976669]\n",
      "New theta_0 : [-0.0231863   0.01464285  0.01939457  0.11227636  0.09322241  0.1537981\n",
      "  0.59448369 -0.04264096  0.14495699 -0.00828318 -0.22544698 -0.1171453\n",
      "  0.15651146 -0.13165677]\n",
      "Training Error:  11.752254537745825\n",
      "====================================================================================================\n",
      "Iteration:  162\n",
      "Previous theta :  [-0.0231863   0.01464285  0.01939457  0.11227636  0.09322241  0.1537981\n",
      "  0.59448369 -0.04264096  0.14495699 -0.00828318 -0.22544698 -0.1171453\n",
      "  0.15651146 -0.13165677]\n",
      "New theta_0 : [-0.02314648  0.01398909  0.01934418  0.11099852  0.09318126  0.15157123\n",
      "  0.59209313 -0.0438324   0.14107482 -0.00668498 -0.22494487 -0.11815607\n",
      "  0.15567881 -0.13352332]\n",
      "Training Error:  11.721206852861208\n",
      "====================================================================================================\n",
      "Iteration:  163\n",
      "Previous theta :  [-0.02314648  0.01398909  0.01934418  0.11099852  0.09318126  0.15157123\n",
      "  0.59209313 -0.0438324   0.14107482 -0.00668498 -0.22494487 -0.11815607\n",
      "  0.15567881 -0.13352332]\n",
      "New theta_0 : [-0.02310569  0.01333858  0.01930893  0.10973131  0.09314313  0.14935886\n",
      "  0.58972675 -0.04499883  0.13722661 -0.00509811 -0.22444629 -0.11915309\n",
      "  0.15486268 -0.13536667]\n",
      "Training Error:  11.690674546381157\n",
      "====================================================================================================\n",
      "Iteration:  164\n",
      "Previous theta :  [-0.02310569  0.01333858  0.01930893  0.10973131  0.09314313  0.14935886\n",
      "  0.58972675 -0.04499883  0.13722661 -0.00509811 -0.22444629 -0.11915309\n",
      "  0.15486268 -0.13536667]\n",
      "New theta_0 : [-0.02306401  0.01269133  0.01928839  0.10847464  0.09310787  0.14716088\n",
      "  0.58738429 -0.0461407   0.133412   -0.00352255 -0.2239513  -0.12013659\n",
      "  0.15406266 -0.13718715]\n",
      "Training Error:  11.660648151943478\n",
      "====================================================================================================\n",
      "Iteration:  165\n",
      "Previous theta :  [-0.02306401  0.01269133  0.01928839  0.10847464  0.09310787  0.14716088\n",
      "  0.58738429 -0.0461407   0.133412   -0.00352255 -0.2239513  -0.12013659\n",
      "  0.15406266 -0.13718715]\n",
      "New theta_0 : [-0.02302151  0.01204734  0.01928215  0.10722844  0.09307534  0.14497719\n",
      "  0.58506548 -0.04725843  0.12963067 -0.00195827 -0.22345995 -0.12110678\n",
      "  0.15327831 -0.1389851 ]\n",
      "Training Error:  11.631118409517565\n",
      "====================================================================================================\n",
      "Iteration:  166\n",
      "Previous theta :  [-0.02302151  0.01204734  0.01928215  0.10722844  0.09307534  0.14497719\n",
      "  0.58506548 -0.04725843  0.12963067 -0.00195827 -0.22345995 -0.12110678\n",
      "  0.15327831 -0.1389851 ]\n",
      "New theta_0 : [-2.29782773e-02  1.14065900e-02  1.92897927e-02  1.05992604e-01\n",
      "  9.30454162e-02  1.42807707e-01  5.82770049e-01 -4.83524343e-02\n",
      "  1.25882253e-01 -4.05244922e-04 -2.22972291e-01 -1.22063891e-01\n",
      "  1.52509236e-01 -1.40760832e-01]\n",
      "Training Error:  11.602076259690584\n",
      "====================================================================================================\n",
      "Iteration:  167\n",
      "Previous theta :  [-2.29782773e-02  1.14065900e-02  1.92897927e-02  1.05992604e-01\n",
      "  9.30454162e-02  1.42807707e-01  5.82770049e-01 -4.83524343e-02\n",
      "  1.25882253e-01 -4.05244922e-04 -2.22972291e-01 -1.22063891e-01\n",
      "  1.52509236e-01 -1.40760832e-01]\n",
      "New theta_0 : [-0.02293436  0.01076909  0.01931093  0.10476706  0.09301797  0.14065232\n",
      "  0.58049775 -0.04942313  0.12216643  0.00113656 -0.22248835 -0.12300812\n",
      "  0.15175504 -0.14251467]\n",
      "Training Error:  11.573512838157923\n",
      "====================================================================================================\n",
      "Iteration:  168\n",
      "Previous theta :  [-0.02293436  0.01076909  0.01931093  0.10476706  0.09301797  0.14065232\n",
      "  0.58049775 -0.04942313  0.12216643  0.00113656 -0.22248835 -0.12300812\n",
      "  0.15175504 -0.14251467]\n",
      "New theta_0 : [-0.02288983  0.01013484  0.01934517  0.10355171  0.09299289  0.13851095\n",
      "  0.57824831 -0.05047093  0.11848288  0.00266719 -0.22200818 -0.12393968\n",
      "  0.15101535 -0.14424692]\n",
      "Training Error:  11.545419470409014\n",
      "====================================================================================================\n",
      "Iteration:  169\n",
      "Previous theta :  [-0.02288983  0.01013484  0.01934517  0.10355171  0.09299289  0.13851095\n",
      "  0.57824831 -0.05047093  0.11848288  0.00266719 -0.22200818 -0.12393968\n",
      "  0.15101535 -0.14424692]\n",
      "New theta_0 : [-0.02284475  0.00950382  0.01939213  0.10234648  0.09297006  0.13638349\n",
      "  0.5760215  -0.05149623  0.11483126  0.00418667 -0.2215318  -0.12485877\n",
      "  0.15028978 -0.14595789]\n",
      "Training Error:  11.517787666599844\n",
      "====================================================================================================\n",
      "Iteration:  170\n",
      "Previous theta :  [-0.02284475  0.00950382  0.01939213  0.10234648  0.09297006  0.13638349\n",
      "  0.5760215  -0.05149623  0.11483126  0.00418667 -0.2215318  -0.12485877\n",
      "  0.15028978 -0.14595789]\n",
      "New theta_0 : [-0.02279918  0.00887605  0.01945145  0.1011513   0.09294935  0.13426985\n",
      "  0.57381705 -0.05249942  0.11121127  0.00569505 -0.22105925 -0.1257656\n",
      "  0.14957797 -0.14764788]\n",
      "Training Error:  11.490609116604158\n",
      "====================================================================================================\n",
      "Iteration:  171\n",
      "Previous theta :  [-0.02279918  0.00887605  0.01945145  0.1011513   0.09294935  0.13426985\n",
      "  0.57381705 -0.05249942  0.11121127  0.00569505 -0.22105925 -0.1257656\n",
      "  0.14957797 -0.14764788]\n",
      "New theta_0 : [-0.02275316  0.00825152  0.01952277  0.09996606  0.09293068  0.13216994\n",
      "  0.57163472 -0.0534809   0.10762258  0.00719237 -0.22059056 -0.12666035\n",
      "  0.14887958 -0.1493172 ]\n",
      "Training Error:  11.463875685235571\n",
      "====================================================================================================\n",
      "Iteration:  172\n",
      "Previous theta :  [-0.02275316  0.00825152  0.01952277  0.09996606  0.09293068  0.13216994\n",
      "  0.57163472 -0.0534809   0.10762258  0.00719237 -0.22059056 -0.12666035\n",
      "  0.14887958 -0.1493172 ]\n",
      "New theta_0 : [-0.02270675  0.00763021  0.01960574  0.09879071  0.09291394  0.13008367\n",
      "  0.56947426 -0.05444104  0.10406488  0.00867868 -0.22012575 -0.12754322\n",
      "  0.14819426 -0.15096614]\n",
      "Training Error:  11.437579407633296\n",
      "====================================================================================================\n",
      "Iteration:  173\n",
      "Previous theta :  [-0.02270675  0.00763021  0.01960574  0.09879071  0.09291394  0.13008367\n",
      "  0.56947426 -0.05444104  0.10406488  0.00867868 -0.22012575 -0.12754322\n",
      "  0.14819426 -0.15096614]\n",
      "New theta_0 : [-0.02266     0.00701214  0.01970002  0.09762515  0.09289904  0.12801095\n",
      "  0.56733543 -0.05538022  0.10053786  0.01015401 -0.21966486 -0.1284144\n",
      "  0.14752168 -0.15259498]\n",
      "Training Error:  11.411712484804537\n",
      "====================================================================================================\n",
      "Iteration:  174\n",
      "Previous theta :  [-0.02266     0.00701214  0.01970002  0.09762515  0.09289904  0.12801095\n",
      "  0.56733543 -0.05538022  0.10053786  0.01015401 -0.21966486 -0.1284144\n",
      "  0.14752168 -0.15259498]\n",
      "New theta_0 : [-0.02261296  0.0063973   0.01980526  0.09646931  0.09288587  0.12595169\n",
      "  0.565218   -0.05629881  0.09704123  0.01161843 -0.21920789 -0.12927407\n",
      "  0.14686152 -0.15420402]\n",
      "Training Error:  11.386267279316884\n",
      "====================================================================================================\n",
      "Iteration:  175\n",
      "Previous theta :  [-0.02261296  0.0063973   0.01980526  0.09646931  0.09288587  0.12595169\n",
      "  0.565218   -0.05629881  0.09704123  0.01161843 -0.21920789 -0.12927407\n",
      "  0.14686152 -0.15420402]\n",
      "New theta_0 : [-0.02256566  0.00578569  0.01992116  0.09532312  0.09287436  0.12390579\n",
      "  0.56312172 -0.05719717  0.09357468  0.01307197 -0.21875488 -0.13012241\n",
      "  0.14621346 -0.15579352]\n",
      "Training Error:  11.36123631113449\n",
      "====================================================================================================\n",
      "Iteration:  176\n",
      "Previous theta :  [-0.02256566  0.00578569  0.01992116  0.09532312  0.09287436  0.12390579\n",
      "  0.56312172 -0.05719717  0.09357468  0.01307197 -0.21875488 -0.13012241\n",
      "  0.14621346 -0.15579352]\n",
      "New theta_0 : [-0.02251815  0.0051773   0.02004738  0.09418649  0.09286441  0.12187317\n",
      "  0.56104637 -0.05807566  0.09013792  0.01451469 -0.21830583 -0.1309596\n",
      "  0.1455772  -0.15736377]\n",
      "Training Error:  11.336612253591994\n",
      "====================================================================================================\n",
      "Iteration:  177\n",
      "Previous theta :  [-0.02251815  0.0051773   0.02004738  0.09418649  0.09286441  0.12187317\n",
      "  0.56104637 -0.05807566  0.09013792  0.01451469 -0.21830583 -0.1309596\n",
      "  0.1455772  -0.15736377]\n",
      "New theta_0 : [-0.02247047  0.00457213  0.02018362  0.09305936  0.09285595  0.11985374\n",
      "  0.55899171 -0.05893464  0.08673066  0.01594664 -0.21786077 -0.13178581\n",
      "  0.14495246 -0.15891504]\n",
      "Training Error:  11.312387929500517\n",
      "====================================================================================================\n",
      "Iteration:  178\n",
      "Previous theta :  [-0.02247047  0.00457213  0.02018362  0.09305936  0.09285595  0.11985374\n",
      "  0.55899171 -0.05893464  0.08673066  0.01594664 -0.21786077 -0.13178581\n",
      "  0.14495246 -0.15891504]\n",
      "New theta_0 : [-0.02242266  0.00397017  0.02032959  0.09194164  0.09284891  0.11784741\n",
      "  0.55695751 -0.05977445  0.08335261  0.01736788 -0.2174197  -0.13260122\n",
      "  0.14433893 -0.1604476 ]\n",
      "Training Error:  11.288556307380308\n",
      "====================================================================================================\n",
      "Iteration:  179\n",
      "Previous theta :  [-0.02242266  0.00397017  0.02032959  0.09194164  0.09284891  0.11784741\n",
      "  0.55695751 -0.05977445  0.08335261  0.01736788 -0.2174197  -0.13260122\n",
      "  0.14433893 -0.1604476 ]\n",
      "New theta_0 : [-0.02237474  0.00337143  0.02048497  0.09083326  0.0928432   0.11585409\n",
      "  0.55494355 -0.06059543  0.08000348  0.01877846 -0.21698263 -0.13340598\n",
      "  0.14373634 -0.1619617 ]\n",
      "Training Error:  11.26511049781492\n",
      "====================================================================================================\n",
      "Iteration:  180\n",
      "Previous theta :  [-0.02237474  0.00337143  0.02048497  0.09083326  0.0928432   0.11585409\n",
      "  0.55494355 -0.06059543  0.08000348  0.01877846 -0.21698263 -0.13340598\n",
      "  0.14373634 -0.1619617 ]\n",
      "New theta_0 : [-0.02232676  0.00277591  0.0206495   0.08973416  0.09283875  0.11387371\n",
      "  0.5529496  -0.06139791  0.07668299  0.02017844 -0.21654958 -0.13420028\n",
      "  0.14314442 -0.16345762]\n",
      "Training Error:  11.242043749921956\n",
      "====================================================================================================\n",
      "Iteration:  181\n",
      "Previous theta :  [-0.02232676  0.00277591  0.0206495   0.08973416  0.09283875  0.11387371\n",
      "  0.5529496  -0.06139791  0.07668299  0.02017844 -0.21654958 -0.13420028\n",
      "  0.14314442 -0.16345762]\n",
      "New theta_0 : [-0.02227874  0.00218359  0.02082288  0.08864425  0.0928355   0.11190617\n",
      "  0.55097545 -0.06218223  0.07339088  0.02156787 -0.21612056 -0.13498426\n",
      "  0.1425629  -0.16493559]\n",
      "Training Error:  11.219349447935759\n",
      "====================================================================================================\n",
      "Iteration:  182\n",
      "Previous theta :  [-0.02227874  0.00218359  0.02082288  0.08864425  0.0928355   0.11190617\n",
      "  0.55097545 -0.06218223  0.07339088  0.02156787 -0.21612056 -0.13498426\n",
      "  0.1425629  -0.16493559]\n",
      "New theta_0 : [-0.02223071  0.00159447  0.02100484  0.08756348  0.09283339  0.10995139\n",
      "  0.54902087 -0.06294871  0.07012686  0.02294681 -0.21569555 -0.13575808\n",
      "  0.14199153 -0.16639589]\n",
      "Training Error:  11.197021107897573\n",
      "====================================================================================================\n",
      "Iteration:  183\n",
      "Previous theta :  [-0.02223071  0.00159447  0.02100484  0.08756348  0.09283339  0.10995139\n",
      "  0.54902087 -0.06294871  0.07012686  0.02294681 -0.21569555 -0.13575808\n",
      "  0.14199153 -0.16639589]\n",
      "New theta_0 : [-0.0221827   0.00100855  0.02119512  0.08649175  0.09283235  0.10800928\n",
      "  0.54708566 -0.06369767  0.06689067  0.02431533 -0.21527458 -0.13652191\n",
      "  0.14143007 -0.16783874]\n",
      "Training Error:  11.175052374448958\n",
      "====================================================================================================\n",
      "Iteration:  184\n",
      "Previous theta :  [-0.0221827   0.00100855  0.02119512  0.08649175  0.09283235  0.10800928\n",
      "  0.54708566 -0.06369767  0.06689067  0.02431533 -0.21527458 -0.13652191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.14143007 -0.16783874]\n",
      "New theta_0 : [-2.21347300e-02  4.25836261e-04  2.13934504e-02  8.54290208e-02\n",
      "  9.28323188e-02  1.06079769e-01  5.45169588e-01 -6.44294303e-02\n",
      "  6.36820325e-02  2.56734750e-02 -2.14857644e-01 -1.37275895e-01\n",
      "  1.40878261e-01 -1.69264408e-01]\n",
      "Training Error:  11.153437017724352\n",
      "====================================================================================================\n",
      "Iteration:  185\n",
      "Previous theta :  [-2.21347300e-02  4.25836261e-04  2.13934504e-02  8.54290208e-02\n",
      "  9.28323188e-02  1.06079769e-01  5.45169588e-01 -6.44294303e-02\n",
      "  6.36820325e-02  2.56734750e-02 -2.14857644e-01 -1.37275895e-01\n",
      "  1.40878261e-01 -1.69264408e-01]\n",
      "New theta_0 : [-2.20868320e-02 -1.53689417e-04  2.15995861e-02  8.43752053e-02\n",
      "  9.28332452e-02  1.04162762e-01  5.43272458e-01 -6.51442888e-02\n",
      "  6.05006943e-02  2.70213162e-02 -2.14444738e-01 -1.38020184e-01\n",
      "  1.40335876e-01 -1.70673119e-01]\n",
      "Training Error:  11.132168930339033\n",
      "====================================================================================================\n",
      "Iteration:  186\n",
      "Previous theta :  [-2.20868320e-02 -1.53689417e-04  2.15995861e-02  8.43752053e-02\n",
      "  9.28332452e-02  1.04162762e-01  5.43272458e-01 -6.51442888e-02\n",
      "  6.05006943e-02  2.70213162e-02 -2.14444738e-01 -1.38020184e-01\n",
      "  1.40335876e-01 -1.70673119e-01]\n",
      "New theta_0 : [-0.02203903 -0.00073003  0.02181328  0.08333024  0.09283507  0.10225818\n",
      "  0.54139406 -0.06584255  0.05734639  0.02835891 -0.21403586 -0.13875492\n",
      "  0.13980269 -0.17206511]\n",
      "Training Error:  11.111242124468717\n",
      "====================================================================================================\n",
      "Iteration:  187\n",
      "Previous theta :  [-0.02203903 -0.00073003  0.02181328  0.08333024  0.09283507  0.10225818\n",
      "  0.54139406 -0.06584255  0.05734639  0.02835891 -0.21403586 -0.13875492\n",
      "  0.13980269 -0.17206511]\n",
      "New theta_0 : [-0.02199133 -0.00130318  0.02203428  0.08229406  0.09283775  0.10036594\n",
      "  0.53953418 -0.06652453  0.05421887  0.02968633 -0.21363102 -0.13948026\n",
      "  0.13927847 -0.17344062]\n",
      "Training Error:  11.090650729017318\n",
      "====================================================================================================\n",
      "Iteration:  188\n",
      "Previous theta :  [-0.02199133 -0.00130318  0.02203428  0.08229406  0.09283775  0.10036594\n",
      "  0.53953418 -0.06652453  0.05421887  0.02968633 -0.21363102 -0.13948026\n",
      "  0.13927847 -0.17344062]\n",
      "New theta_0 : [-0.02194377 -0.00187315  0.02226236  0.08126659  0.09284123  0.09848597\n",
      "  0.53769262 -0.0671905   0.05111787  0.03100362 -0.2132302  -0.14019634\n",
      "  0.13876301 -0.17479988]\n",
      "Training Error:  11.07038898686953\n",
      "====================================================================================================\n",
      "Iteration:  189\n",
      "Previous theta :  [-0.02194377 -0.00187315  0.02226236  0.08126659  0.09284123  0.09848597\n",
      "  0.53769262 -0.0671905   0.05111787  0.03100362 -0.2132302  -0.14019634\n",
      "  0.13876301 -0.17479988]\n",
      "New theta_0 : [-0.02189636 -0.00243995  0.02249728  0.08024777  0.09284547  0.09661818\n",
      "  0.53586919 -0.06784076  0.04804315  0.03231086 -0.2128334  -0.1409033\n",
      "  0.13825609 -0.17614311]\n",
      "Training Error:  11.050451252225058\n",
      "====================================================================================================\n",
      "Iteration:  190\n",
      "Previous theta :  [-0.02189636 -0.00243995  0.02249728  0.08024777  0.09284547  0.09661818\n",
      "  0.53586919 -0.06784076  0.04804315  0.03231086 -0.2128334  -0.1409033\n",
      "  0.13825609 -0.17614311]\n",
      "New theta_0 : [-0.02184912 -0.00300357  0.02273883  0.07923753  0.09285041  0.09476249\n",
      "  0.53406367 -0.06847559  0.04499446  0.03360811 -0.21244062 -0.14160127\n",
      "  0.13775752 -0.17747053]\n",
      "Training Error:  11.030831988011393\n",
      "====================================================================================================\n",
      "Iteration:  191\n",
      "Previous theta :  [-0.02184912 -0.00300357  0.02273883  0.07923753  0.09285041  0.09476249\n",
      "  0.53406367 -0.06847559  0.04499446  0.03360811 -0.21244062 -0.14160127\n",
      "  0.13775752 -0.17747053]\n",
      "New theta_0 : [-0.02180206 -0.00356403  0.02298678  0.07823581  0.09285602  0.09291883\n",
      "  0.53227588 -0.06909528  0.04197155  0.03489543 -0.21205185 -0.14229039\n",
      "  0.13726709 -0.17878236]\n",
      "Training Error:  11.01152576337227\n",
      "====================================================================================================\n",
      "Iteration:  192\n",
      "Previous theta :  [-0.02180206 -0.00356403  0.02298678  0.07823581  0.09285602  0.09291883\n",
      "  0.53227588 -0.06909528  0.04197155  0.03489543 -0.21205185 -0.14229039\n",
      "  0.13726709 -0.17878236]\n",
      "New theta_0 : [-0.02175521 -0.00412133  0.02324092  0.07724255  0.09286225  0.09108711\n",
      "  0.53050562 -0.06970009  0.03897418  0.03617289 -0.21166707 -0.1429708\n",
      "  0.13678462 -0.18007882]\n",
      "Training Error:  10.992527251229008\n",
      "====================================================================================================\n",
      "Iteration:  193\n",
      "Previous theta :  [-0.02175521 -0.00412133  0.02324092  0.07724255  0.09286225  0.09108711\n",
      "  0.53050562 -0.06970009  0.03897418  0.03617289 -0.21166707 -0.1429708\n",
      "  0.13678462 -0.18007882]\n",
      "New theta_0 : [-0.02170857 -0.00467548  0.02350105  0.07625768  0.09286908  0.08926725\n",
      "  0.5287527  -0.0702903   0.03600212  0.03744056 -0.21128628 -0.14364263\n",
      "  0.13630991 -0.18136011]\n",
      "Training Error:  10.973831225912116\n",
      "====================================================================================================\n",
      "Iteration:  194\n",
      "Previous theta :  [-0.02170857 -0.00467548  0.02350105  0.07625768  0.09286908  0.08926725\n",
      "  0.5287527  -0.0702903   0.03600212  0.03744056 -0.21128628 -0.14364263\n",
      "  0.13630991 -0.18136011]\n",
      "New theta_0 : [-0.02166215 -0.00522647  0.02376695  0.07528113  0.09287644  0.08745919\n",
      "  0.52701693 -0.07086618  0.03305512  0.03869849 -0.21090948 -0.14430599\n",
      "  0.13584277 -0.18262646]\n",
      "Training Error:  10.955432560860515\n",
      "====================================================================================================\n",
      "Iteration:  195\n",
      "Previous theta :  [-0.02166215 -0.00522647  0.02376695  0.07528113  0.09287644  0.08745919\n",
      "  0.52701693 -0.07086618  0.03305512  0.03869849 -0.21090948 -0.14430599\n",
      "  0.13584277 -0.18262646]\n",
      "New theta_0 : [-0.02161598 -0.00577432  0.02403843  0.07431284  0.09288433  0.08566284\n",
      "  0.52529812 -0.07142798  0.03013295  0.03994676 -0.21053664 -0.14496102\n",
      "  0.13538305 -0.18387806]\n",
      "Training Error:  10.937326226386089\n",
      "====================================================================================================\n",
      "Iteration:  196\n",
      "Previous theta :  [-0.02161598 -0.00577432  0.02403843  0.07431284  0.09288433  0.08566284\n",
      "  0.52529812 -0.07142798  0.03013295  0.03994676 -0.21053664 -0.14496102\n",
      "  0.13538305 -0.18387806]\n",
      "New theta_0 : [-0.02157006 -0.00631903  0.02431529  0.07335276  0.09289269  0.08387813\n",
      "  0.52359608 -0.07197597  0.02723539  0.04118544 -0.21016776 -0.14560785\n",
      "  0.13493055 -0.18511512]\n",
      "Training Error:  10.919507287501142\n",
      "====================================================================================================\n",
      "Iteration:  197\n",
      "Previous theta :  [-0.02157006 -0.00631903  0.02431529  0.07335276  0.09289269  0.08387813\n",
      "  0.52359608 -0.07197597  0.02723539  0.04118544 -0.21016776 -0.14560785\n",
      "  0.13493055 -0.18511512]\n",
      "New theta_0 : [-0.0215244  -0.00686061  0.02459736  0.07240082  0.0929015   0.08210498\n",
      "  0.52191065 -0.0725104   0.0243622   0.04241459 -0.20980282 -0.14624659\n",
      "  0.13448512 -0.18633783]\n",
      "Training Error:  10.901970901806575\n",
      "====================================================================================================\n",
      "Iteration:  198\n",
      "Previous theta :  [-0.0215244  -0.00686061  0.02459736  0.07240082  0.0929015   0.08210498\n",
      "  0.52191065 -0.0725104   0.0243622   0.04241459 -0.20980282 -0.14624659\n",
      "  0.13448512 -0.18633783]\n",
      "New theta_0 : [-0.02147901 -0.00739906  0.02488444  0.07145695  0.09291072  0.08034331\n",
      "  0.52024162 -0.0730315   0.02151317  0.04363427 -0.20944181 -0.14687736\n",
      "  0.13404659 -0.18754639]\n",
      "Training Error:  10.88471231743864\n",
      "====================================================================================================\n",
      "Iteration:  199\n",
      "Previous theta :  [-0.02147901 -0.00739906  0.02488444  0.07145695  0.09291072  0.08034331\n",
      "  0.52024162 -0.0730315   0.02151317  0.04363427 -0.20944181 -0.14687736\n",
      "  0.13404659 -0.18754639]\n",
      "New theta_0 : [-0.02143391 -0.00793439  0.02517635  0.07052111  0.09292033  0.07859306\n",
      "  0.51858883 -0.07353954  0.01868806  0.04484456 -0.20908471 -0.14750028\n",
      "  0.13361481 -0.18874101]\n",
      "Training Error:  10.867726871072254\n",
      "====================================================================================================\n",
      "Iteration:  200\n",
      "Previous theta :  [-0.02143391 -0.00793439  0.02517635  0.07052111  0.09292033  0.07859306\n",
      "  0.51858883 -0.07353954  0.01868806  0.04484456 -0.20908471 -0.14750028\n",
      "  0.13361481 -0.18874101]\n",
      "New theta_0 : [-0.02138909 -0.0084666   0.02547292  0.06959322  0.0929303   0.07685414\n",
      "  0.51695209 -0.07403475  0.01588665  0.04604552 -0.20873151 -0.14811547\n",
      "  0.13318961 -0.18992185]\n",
      "Training Error:  10.85100998597891\n",
      "====================================================================================================\n",
      "Iteration:  201\n",
      "Previous theta :  [-0.02138909 -0.0084666   0.02547292  0.06959322  0.0929303   0.07685414\n",
      "  0.51695209 -0.07403475  0.01588665  0.04604552 -0.20873151 -0.14811547\n",
      "  0.13318961 -0.18992185]\n",
      "New theta_0 : [-0.02134457 -0.00899571  0.02577398  0.06867323  0.09294061  0.07512649\n",
      "  0.51533124 -0.07451737  0.01310874  0.04723722 -0.20838219 -0.14872303\n",
      "  0.13277085 -0.19108912]\n",
      "Training Error:  10.83455717013731\n",
      "====================================================================================================\n",
      "Iteration:  202\n",
      "Previous theta :  [-0.02134457 -0.00899571  0.02577398  0.06867323  0.09294061  0.07512649\n",
      "  0.51533124 -0.07451737  0.01310874  0.04723722 -0.20838219 -0.14872303\n",
      "  0.13277085 -0.19108912]\n",
      "New theta_0 : [-0.02130036 -0.00952173  0.02607936  0.06776108  0.09295121  0.07341002\n",
      "  0.5137261  -0.07498762  0.0103541   0.04841973 -0.20803674 -0.14932309\n",
      "  0.13235839 -0.192243  ]\n",
      "Training Error:  10.818364014394938\n",
      "====================================================================================================\n",
      "Iteration:  203\n",
      "Previous theta :  [-0.02130036 -0.00952173  0.02607936  0.06776108  0.09295121  0.07341002\n",
      "  0.5137261  -0.07498762  0.0103541   0.04841973 -0.20803674 -0.14932309\n",
      "  0.13235839 -0.192243  ]\n",
      "New theta_0 : [-0.02125645 -0.01004464  0.0263889   0.06685671  0.0929621   0.07170468\n",
      "  0.5121365  -0.07544575  0.00762252  0.04959311 -0.20769513 -0.14991575\n",
      "  0.13195207 -0.19338367]\n",
      "Training Error:  10.802426190678853\n",
      "====================================================================================================\n",
      "Iteration:  204\n",
      "Previous theta :  [-0.02125645 -0.01004464  0.0263889   0.06685671  0.0929621   0.07170468\n",
      "  0.5121365  -0.07544575  0.00762252  0.04959311 -0.20769513 -0.14991575\n",
      "  0.13195207 -0.19338367]\n",
      "New theta_0 : [-0.02121286 -0.01056447  0.02670244  0.06596007  0.09297325  0.07001038\n",
      "  0.51056227 -0.07589196  0.00491379  0.05075743 -0.20735736 -0.15050111\n",
      "  0.13155177 -0.19451131]\n",
      "Training Error:  10.786739450254066\n",
      "====================================================================================================\n",
      "Iteration:  205\n",
      "Previous theta :  [-0.02121286 -0.01056447  0.02670244  0.06596007  0.09297325  0.07001038\n",
      "  0.51056227 -0.07589196  0.00491379  0.05075743 -0.20735736 -0.15050111\n",
      "  0.13155177 -0.19451131]\n",
      "New theta_0 : [-0.0211696  -0.01108123  0.02701983  0.06507109  0.09298463  0.06832706\n",
      "  0.50900324 -0.0763265   0.00222771  0.05191277 -0.2070234  -0.15107929\n",
      "  0.13115735 -0.19562609]\n",
      "Training Error:  10.771299622027895\n",
      "====================================================================================================\n",
      "Iteration:  206\n",
      "Previous theta :  [-0.0211696  -0.01108123  0.02701983  0.06507109  0.09298463  0.06832706\n",
      "  0.50900324 -0.0763265   0.00222771  0.05191277 -0.2070234  -0.15107929\n",
      "  0.13115735 -0.19562609]\n",
      "New theta_0 : [-2.11266557e-02 -1.15949107e-02  2.73409091e-02  6.41897205e-02\n",
      "  9.29962345e-02  6.66546430e-02  5.07459254e-01 -7.67495564e-02\n",
      " -4.35941726e-04  5.30591771e-02 -2.06693224e-01 -1.51650392e-01\n",
      "  1.30768681e-01 -1.96728195e-01]\n",
      "Training Error:  10.756102610898802\n",
      "====================================================================================================\n",
      "Iteration:  207\n",
      "Previous theta :  [-2.11266557e-02 -1.15949107e-02  2.73409091e-02  6.41897205e-02\n",
      "  9.29962345e-02  6.66546430e-02  5.07459254e-01 -7.67495564e-02\n",
      " -4.35941726e-04  5.30591771e-02 -2.06693224e-01 -1.51650392e-01\n",
      "  1.30768681e-01 -1.96728195e-01]\n",
      "New theta_0 : [-0.02108405 -0.01210553  0.02766554  0.0633159   0.09300803  0.06499306\n",
      "  0.50593014 -0.07716136 -0.00307736  0.05419673 -0.20636683 -0.15221451\n",
      "  0.13038563 -0.19781779]\n",
      "Training Error:  10.741144396148284\n",
      "====================================================================================================\n",
      "Iteration:  208\n",
      "Previous theta :  [-0.02108405 -0.01210553  0.02766554  0.0633159   0.09300803  0.06499306\n",
      "  0.50593014 -0.07716136 -0.00307736  0.05419673 -0.20636683 -0.15221451\n",
      "  0.13038563 -0.19781779]\n",
      "New theta_0 : [-0.02104177 -0.01261309  0.02799357  0.06244958  0.09302     0.06334224\n",
      "  0.50441575 -0.07756212 -0.00569674  0.0553255  -0.20604418 -0.15277176\n",
      "  0.13000808 -0.19889504]\n",
      "Training Error:  10.726421029874347\n",
      "====================================================================================================\n",
      "Iteration:  209\n",
      "Previous theta :  [-0.02104177 -0.01261309  0.02799357  0.06244958  0.09302     0.06334224\n",
      "  0.50441575 -0.07756212 -0.00569674  0.0553255  -0.20604418 -0.15277176\n",
      "  0.13000808 -0.19889504]\n",
      "New theta_0 : [-0.02099983 -0.01311761  0.02832486  0.06159069  0.09303213  0.06170212\n",
      "  0.50291591 -0.07795205 -0.00829429  0.05644555 -0.20572526 -0.15332222\n",
      "  0.1296359  -0.19996012]\n",
      "Training Error:  10.711928635465302\n",
      "====================================================================================================\n",
      "Iteration:  210\n",
      "Previous theta :  [-0.02099983 -0.01311761  0.02832486  0.06159069  0.09303213  0.06170212\n",
      "  0.50291591 -0.07795205 -0.00829429  0.05644555 -0.20572526 -0.15332222\n",
      "  0.1296359  -0.19996012]\n",
      "New theta_0 : [-0.02095824 -0.01361909  0.02865929  0.06073919  0.09304441  0.06007263\n",
      "  0.50143048 -0.07833133 -0.01087021  0.05755695 -0.20541006 -0.153866\n",
      "  0.12926899 -0.20101319]\n",
      "Training Error:  10.697663406112557\n",
      "====================================================================================================\n",
      "Iteration:  211\n",
      "Previous theta :  [-0.02095824 -0.01361909  0.02865929  0.06073919  0.09304441  0.06007263\n",
      "  0.50143048 -0.07833133 -0.01087021  0.05755695 -0.20541006 -0.153866\n",
      "  0.12926899 -0.20101319]\n",
      "New theta_0 : [-0.02091698 -0.01411754  0.0289967   0.05989502  0.09305681  0.05845369\n",
      "  0.49995928 -0.07870018 -0.01342468  0.05865976 -0.20509854 -0.1544032\n",
      "  0.12890723 -0.20205441]\n",
      "Training Error:  10.683621603361155\n",
      "====================================================================================================\n",
      "Iteration:  212\n",
      "Previous theta :  [-0.02091698 -0.01411754  0.0289967   0.05989502  0.09305681  0.05845369\n",
      "  0.49995928 -0.07870018 -0.01342468  0.05865976 -0.20509854 -0.1544032\n",
      "  0.12890723 -0.20205441]\n",
      "New theta_0 : [-0.02087607 -0.01461297  0.02933699  0.05905813  0.09306931  0.05684524\n",
      "  0.49850218 -0.07905879 -0.01595791  0.05975405 -0.20479069 -0.15493391\n",
      "  0.1285505  -0.20308393]\n",
      "Training Error:  10.669799555696901\n",
      "====================================================================================================\n",
      "Iteration:  213\n",
      "Previous theta :  [-0.02087607 -0.01461297  0.02933699  0.05905813  0.09306931  0.05684524\n",
      "  0.49850218 -0.07905879 -0.01595791  0.05975405 -0.20479069 -0.15493391\n",
      "  0.1285505  -0.20308393]\n",
      "New theta_0 : [-0.02083551 -0.01510538  0.02968001  0.05822845  0.09308192  0.05524722\n",
      "  0.49705902 -0.07940735 -0.01847008  0.06083989 -0.20448649 -0.15545823\n",
      "  0.1281987  -0.20410192]\n",
      "Training Error:  10.656193657168922\n",
      "====================================================================================================\n",
      "Iteration:  214\n",
      "Previous theta :  [-0.02083551 -0.01510538  0.02968001  0.05822845  0.09308192  0.05524722\n",
      "  0.49705902 -0.07940735 -0.01847008  0.06083989 -0.20448649 -0.15545823\n",
      "  0.1281987  -0.20410192]\n",
      "New theta_0 : [-0.0207953  -0.01559479  0.03002564  0.05740595  0.0930946   0.05365955\n",
      "  0.49562964 -0.07974606 -0.02096138  0.06191734 -0.20418591 -0.15597623\n",
      "  0.12785172 -0.20510853]\n",
      "Training Error:  10.642800366046536\n",
      "====================================================================================================\n",
      "Iteration:  215\n",
      "Previous theta :  [-0.0207953  -0.01559479  0.03002564  0.05740595  0.0930946   0.05365955\n",
      "  0.49562964 -0.07974606 -0.02096138  0.06191734 -0.20418591 -0.15597623\n",
      "  0.12785172 -0.20510853]\n",
      "New theta_0 : [-0.02075544 -0.0160812   0.03037377  0.05659055  0.09310736  0.05208218\n",
      "  0.49421391 -0.08007509 -0.023432    0.06298648 -0.20388893 -0.15648803\n",
      "  0.12750947 -0.2061039 ]\n",
      "Training Error:  10.629616203509404\n",
      "====================================================================================================\n",
      "Iteration:  216\n",
      "Previous theta :  [-0.02075544 -0.0160812   0.03037377  0.05659055  0.09310736  0.05208218\n",
      "  0.49421391 -0.08007509 -0.023432    0.06298648 -0.20388893 -0.15648803\n",
      "  0.12750947 -0.2061039 ]\n",
      "New theta_0 : [-0.02071593 -0.01656463  0.03072428  0.05578222  0.09312016  0.05051503\n",
      "  0.49281167 -0.08039464 -0.02588212  0.06404736 -0.20359552 -0.15699369\n",
      "  0.12717184 -0.2070882 ]\n",
      "Training Error:  10.616637752369934\n",
      "====================================================================================================\n",
      "Iteration:  217\n",
      "Previous theta :  [-0.02071593 -0.01656463  0.03072428  0.05578222  0.09312016  0.05051503\n",
      "  0.49281167 -0.08039464 -0.02588212  0.06404736 -0.20359552 -0.15699369\n",
      "  0.12717184 -0.2070882 ]\n",
      "New theta_0 : [-0.02067676 -0.01704508  0.03107704  0.05498089  0.09313302  0.04895804\n",
      "  0.49142278 -0.08070487 -0.02831193  0.06510006 -0.20330567 -0.15749332\n",
      "  0.12683874 -0.20806156]\n",
      "Training Error:  10.603861655826964\n",
      "====================================================================================================\n",
      "Iteration:  218\n",
      "Previous theta :  [-0.02067676 -0.01704508  0.03107704  0.05498089  0.09313302  0.04895804\n",
      "  0.49142278 -0.08070487 -0.02831193  0.06510006 -0.20330567 -0.15749332\n",
      "  0.12683874 -0.20806156]\n",
      "New theta_0 : [-0.02063795 -0.01752256  0.03143196  0.05418652  0.0931459   0.04741114\n",
      "  0.4900471  -0.08100598 -0.0307216   0.06614464 -0.20301935 -0.15798699\n",
      "  0.12651007 -0.20902413]\n",
      "Training Error:  10.591284616249746\n",
      "====================================================================================================\n",
      "Iteration:  219\n",
      "Previous theta :  [-0.02063795 -0.01752256  0.03143196  0.05418652  0.0931459   0.04741114\n",
      "  0.4900471  -0.08100598 -0.0307216   0.06614464 -0.20301935 -0.15798699\n",
      "  0.12651007 -0.20902413]\n",
      "New theta_0 : [-0.0205995  -0.01799709  0.03178892  0.05339906  0.09315881  0.04587427\n",
      "  0.48868448 -0.08129813 -0.03311132  0.06718116 -0.20273654 -0.15847479\n",
      "  0.12618574 -0.20997606]\n",
      "Training Error:  10.57890339399138\n",
      "====================================================================================================\n",
      "Iteration:  220\n",
      "Previous theta :  [-0.0205995  -0.01799709  0.03178892  0.05339906  0.09315881  0.04587427\n",
      "  0.48868448 -0.08129813 -0.03311132  0.06718116 -0.20273654 -0.15847479\n",
      "  0.12618574 -0.20997606]\n",
      "New theta_0 : [-0.02056139 -0.01846867  0.03214782  0.05261844  0.09317172  0.04434737\n",
      "  0.48733479 -0.08158149 -0.03548126  0.06820969 -0.20245721 -0.15895681\n",
      "  0.12586566 -0.21091747]\n",
      "Training Error:  10.566714806230765\n",
      "====================================================================================================\n",
      "Iteration:  221\n",
      "Previous theta :  [-0.02056139 -0.01846867  0.03214782  0.05261844  0.09317172  0.04434737\n",
      "  0.48733479 -0.08158149 -0.03548126  0.06820969 -0.20245721 -0.15895681\n",
      "  0.12586566 -0.21091747]\n",
      "New theta_0 : [-0.02052363 -0.01893731  0.03250855  0.05184463  0.09318464  0.04283037\n",
      "  0.48599789 -0.08185623 -0.03783159  0.0692303  -0.20218134 -0.15943312\n",
      "  0.12554974 -0.21184853]\n",
      "Training Error:  10.554715725842268\n",
      "====================================================================================================\n",
      "Iteration:  222\n",
      "Previous theta :  [-0.02052363 -0.01893731  0.03250855  0.05184463  0.09318464  0.04283037\n",
      "  0.48599789 -0.08185623 -0.03783159  0.0692303  -0.20218134 -0.15943312\n",
      "  0.12554974 -0.21184853]\n",
      "New theta_0 : [-0.02048623 -0.01940302  0.03287101  0.05107757  0.09319755  0.04132321\n",
      "  0.48467363 -0.08212252 -0.0401625   0.07024304 -0.2019089  -0.15990381\n",
      "  0.12523791 -0.21276934]\n",
      "Training Error:  10.542903080292257\n",
      "====================================================================================================\n",
      "Iteration:  223\n",
      "Previous theta :  [-0.02048623 -0.01940302  0.03287101  0.05107757  0.09319755  0.04132321\n",
      "  0.48467363 -0.08212252 -0.0401625   0.07024304 -0.2019089  -0.15990381\n",
      "  0.12523791 -0.21276934]\n",
      "New theta_0 : [-0.02044917 -0.01986581  0.0332351   0.05031721  0.09321045  0.03982583\n",
      "  0.48336189 -0.08238052 -0.04247415  0.07124799 -0.20163987 -0.16036895\n",
      "  0.12493007 -0.21368007]\n",
      "Training Error:  10.531273850561744\n",
      "====================================================================================================\n",
      "Iteration:  224\n",
      "Previous theta :  [-0.02044917 -0.01986581  0.0332351   0.05031721  0.09321045  0.03982583\n",
      "  0.48336189 -0.08238052 -0.04247415  0.07124799 -0.20163987 -0.16036895\n",
      "  0.12493007 -0.21368007]\n",
      "New theta_0 : [-0.02041247 -0.02032569  0.03360073  0.04956351  0.09322332  0.03833816\n",
      "  0.48206254 -0.08263039 -0.04476672  0.07224521 -0.20137423 -0.16082862\n",
      "  0.12462615 -0.21458082]\n",
      "Training Error:  10.519825070094381\n",
      "====================================================================================================\n",
      "Iteration:  225\n",
      "Previous theta :  [-0.02041247 -0.02032569  0.03360073  0.04956351  0.09322332  0.03833816\n",
      "  0.48206254 -0.08263039 -0.04476672  0.07224521 -0.20137423 -0.16082862\n",
      "  0.12462615 -0.21458082]\n",
      "New theta_0 : [-0.02037611 -0.02078268  0.03396781  0.0488164   0.09323617  0.03686014\n",
      "  0.48077543 -0.08287228 -0.04704036  0.07323476 -0.20111195 -0.16128291\n",
      "  0.12432607 -0.21547174]\n",
      "Training Error:  10.50855382376905\n",
      "====================================================================================================\n",
      "Iteration:  226\n",
      "Previous theta :  [-0.02037611 -0.02078268  0.03396781  0.0488164   0.09323617  0.03686014\n",
      "  0.48077543 -0.08287228 -0.04704036  0.07323476 -0.20111195 -0.16128291\n",
      "  0.12432607 -0.21547174]\n",
      "New theta_0 : [-0.0203401  -0.02123678  0.03433624  0.04807584  0.09324897  0.03539171\n",
      "  0.47950045 -0.08310635 -0.04929525  0.0742167  -0.200853   -0.16173188\n",
      "  0.12402975 -0.21635296]\n",
      "Training Error:  10.497457246896365\n",
      "====================================================================================================\n",
      "Iteration:  227\n",
      "Previous theta :  [-0.0203401  -0.02123678  0.03433624  0.04807584  0.09324897  0.03539171\n",
      "  0.47950045 -0.08310635 -0.04929525  0.0742167  -0.200853   -0.16173188\n",
      "  0.12402975 -0.21635296]\n",
      "New theta_0 : [-0.02030443 -0.02168801  0.03470593  0.04734179  0.09326173  0.03393282\n",
      "  0.47823745 -0.08333275 -0.05153155  0.0751911  -0.20059736 -0.16217561\n",
      "  0.12373713 -0.21722459]\n",
      "Training Error:  10.486532524238418\n",
      "====================================================================================================\n",
      "Iteration:  228\n",
      "Previous theta :  [-0.02030443 -0.02168801  0.03470593  0.04734179  0.09326173  0.03393282\n",
      "  0.47823745 -0.08333275 -0.05153155  0.0751911  -0.20059736 -0.16217561\n",
      "  0.12373713 -0.21722459]\n",
      "New theta_0 : [-0.0202691  -0.02213636  0.03507681  0.04661419  0.09327443  0.03248339\n",
      "  0.47698632 -0.08355164 -0.05374943  0.07615802 -0.20034501 -0.16261417\n",
      "  0.12344812 -0.21808677]\n",
      "Training Error:  10.475776889051076\n",
      "====================================================================================================\n",
      "Iteration:  229\n",
      "Previous theta :  [-0.0202691  -0.02213636  0.03507681  0.04661419  0.09327443  0.03248339\n",
      "  0.47698632 -0.08355164 -0.05374943  0.07615802 -0.20034501 -0.16261417\n",
      "  0.12344812 -0.21808677]\n",
      "New theta_0 : [-0.02023412 -0.02258187  0.03544878  0.045893    0.09328708  0.03104337\n",
      "  0.47574693 -0.08376314 -0.05594904  0.07711753 -0.20009592 -0.16304763\n",
      "  0.12316265 -0.21893962]\n",
      "Training Error:  10.465187622148225\n",
      "====================================================================================================\n",
      "Iteration:  230\n",
      "Previous theta :  [-0.02023412 -0.02258187  0.03544878  0.045893    0.09328708  0.03104337\n",
      "  0.47574693 -0.08376314 -0.05594904  0.07711753 -0.20009592 -0.16304763\n",
      "  0.12316265 -0.21893962]\n",
      "New theta_0 : [-0.02019948 -0.02302452  0.03582176  0.04517816  0.09329967  0.0296127\n",
      "  0.47451915 -0.08396742 -0.05813055  0.07806968 -0.19985007 -0.16347608\n",
      "  0.12288067 -0.21978325]\n",
      "Training Error:  10.454762050987355\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  231\n",
      "Previous theta :  [-0.02019948 -0.02302452  0.03582176  0.04517816  0.09329967  0.0296127\n",
      "  0.47451915 -0.08396742 -0.05813055  0.07806968 -0.19985007 -0.16347608\n",
      "  0.12288067 -0.21978325]\n",
      "New theta_0 : [-0.02016518 -0.02346435  0.03619567  0.04446964  0.09331219  0.02819132\n",
      "  0.47330287 -0.08416461 -0.06029412  0.07901454 -0.19960742 -0.16389956\n",
      "  0.1226021  -0.22061779]\n",
      "Training Error:  10.444497548775853\n",
      "====================================================================================================\n",
      "Iteration:  232\n",
      "Previous theta :  [-0.02016518 -0.02346435  0.03619567  0.04446964  0.09331219  0.02819132\n",
      "  0.47330287 -0.08416461 -0.06029412  0.07901454 -0.19960742 -0.16389956\n",
      "  0.1226021  -0.22061779]\n",
      "New theta_0 : [-0.02013121 -0.02390135  0.03657044  0.04376738  0.09332463  0.02677917\n",
      "  0.47209795 -0.08435485 -0.06243989  0.07995216 -0.19936797 -0.16431816\n",
      "  0.12232687 -0.22144336]\n",
      "Training Error:  10.434391533597472\n",
      "====================================================================================================\n",
      "Iteration:  233\n",
      "Previous theta :  [-0.02013121 -0.02390135  0.03657044  0.04376738  0.09332463  0.02677917\n",
      "  0.47209795 -0.08435485 -0.06243989  0.07995216 -0.19936797 -0.16431816\n",
      "  0.12232687 -0.22144336]\n",
      "New theta_0 : [-0.02009757 -0.02433555  0.03694599  0.04307133  0.09333699  0.0253762\n",
      "  0.47090429 -0.08453828 -0.06456803  0.08088262 -0.19913167 -0.16473195\n",
      "  0.12205493 -0.22226007]\n",
      "Training Error:  10.424441467558417\n",
      "====================================================================================================\n",
      "Iteration:  234\n",
      "Previous theta :  [-0.02009757 -0.02433555  0.03694599  0.04307133  0.09333699  0.0253762\n",
      "  0.47090429 -0.08453828 -0.06456803  0.08088262 -0.19913167 -0.16473195\n",
      "  0.12205493 -0.22226007]\n",
      "New theta_0 : [-0.02006427 -0.02476694  0.03732224  0.04238145  0.09334928  0.02398234\n",
      "  0.46972175 -0.08471502 -0.06667869  0.08180596 -0.1988985  -0.16514098\n",
      "  0.12178621 -0.22306803]\n",
      "Training Error:  10.414644855952503\n",
      "====================================================================================================\n",
      "Iteration:  235\n",
      "Previous theta :  [-0.02006427 -0.02476694  0.03732224  0.04238145  0.09334928  0.02398234\n",
      "  0.46972175 -0.08471502 -0.06667869  0.08180596 -0.1988985  -0.16514098\n",
      "  0.12178621 -0.22306803]\n",
      "New theta_0 : [-0.0200313  -0.02519554  0.03769913  0.0416977   0.09336147  0.02259753\n",
      "  0.46855023 -0.08488522 -0.06877201  0.08272225 -0.19866845 -0.16554533\n",
      "  0.12152065 -0.22386736]\n",
      "Training Error:  10.404999246444863\n",
      "====================================================================================================\n",
      "Iteration:  236\n",
      "Previous theta :  [-0.0200313  -0.02519554  0.03769913  0.0416977   0.09336147  0.02259753\n",
      "  0.46855023 -0.08488522 -0.06877201  0.08272225 -0.19866845 -0.16554533\n",
      "  0.12152065 -0.22386736]\n",
      "New theta_0 : [-0.01999865 -0.02562137  0.03807658  0.04102002  0.09337358  0.02122173\n",
      "  0.4673896  -0.085049   -0.07084817  0.08363156 -0.19844148 -0.16594505\n",
      "  0.1212582  -0.22465816]\n",
      "Training Error:  10.395502228273717\n",
      "====================================================================================================\n",
      "Iteration:  237\n",
      "Previous theta :  [-0.01999865 -0.02562137  0.03807658  0.04102002  0.09337358  0.02122173\n",
      "  0.4673896  -0.085049   -0.07084817  0.08363156 -0.19844148 -0.16594505\n",
      "  0.1212582  -0.22465816]\n",
      "New theta_0 : [-0.01996633 -0.02604443  0.03845453  0.04034837  0.09338559  0.01985487\n",
      "  0.46623976 -0.08520648 -0.07290729  0.08453393 -0.19821757 -0.16634022\n",
      "  0.12099879 -0.22544055]\n",
      "Training Error:  10.386151431469756\n",
      "====================================================================================================\n",
      "Iteration:  238\n",
      "Previous theta :  [-0.01996633 -0.02604443  0.03845453  0.04034837  0.09338559  0.01985487\n",
      "  0.46623976 -0.08520648 -0.07290729  0.08453393 -0.19821757 -0.16634022\n",
      "  0.12099879 -0.22544055]\n",
      "New theta_0 : [-0.01993433 -0.02646474  0.03883291  0.03968271  0.09339751  0.01849689\n",
      "  0.46510059 -0.0853578  -0.07494953  0.08542943 -0.19799669 -0.16673089\n",
      "  0.12074237 -0.22621464]\n",
      "Training Error:  10.376944526092569\n",
      "====================================================================================================\n",
      "Iteration:  239\n",
      "Previous theta :  [-0.01993433 -0.02646474  0.03883291  0.03968271  0.09339751  0.01849689\n",
      "  0.46510059 -0.0853578  -0.07494953  0.08542943 -0.19799669 -0.16673089\n",
      "  0.12074237 -0.22621464]\n",
      "New theta_0 : [-0.01990265 -0.02688231  0.03921165  0.03902299  0.09340932  0.01714774\n",
      "  0.46397198 -0.08550308 -0.07697503  0.08631811 -0.19777882 -0.16711713\n",
      "  0.12048889 -0.22698052]\n",
      "Training Error:  10.367879221483784\n",
      "====================================================================================================\n",
      "Iteration:  240\n",
      "Previous theta :  [-0.01990265 -0.02688231  0.03921165  0.03902299  0.09340932  0.01714774\n",
      "  0.46397198 -0.08550308 -0.07697503  0.08631811 -0.19777882 -0.16711713\n",
      "  0.12048889 -0.22698052]\n",
      "New theta_0 : [-0.01987129 -0.02729715  0.03959069  0.03836916  0.09342104  0.01580737\n",
      "  0.46285382 -0.08564243 -0.07898394  0.08720004 -0.19756394 -0.16749899\n",
      "  0.12023829 -0.22773831]\n",
      "Training Error:  10.358953265536398\n",
      "====================================================================================================\n",
      "Iteration:  241\n",
      "Previous theta :  [-0.01987129 -0.02729715  0.03959069  0.03836916  0.09342104  0.01580737\n",
      "  0.46285382 -0.08564243 -0.07898394  0.08720004 -0.19756394 -0.16749899\n",
      "  0.12023829 -0.22773831]\n",
      "New theta_0 : [-0.01984024 -0.02770926  0.03996998  0.03772119  0.09343264  0.01447571\n",
      "  0.46174599 -0.08577598 -0.0809764   0.08807527 -0.19735201 -0.16787654\n",
      "  0.11999052 -0.2284881 ]\n",
      "Training Error:  10.350164443979915\n",
      "====================================================================================================\n",
      "Iteration:  242\n",
      "Previous theta :  [-0.01984024 -0.02770926  0.03996998  0.03772119  0.09343264  0.01447571\n",
      "  0.46174599 -0.08577598 -0.0809764   0.08807527 -0.19735201 -0.16787654\n",
      "  0.11999052 -0.2284881 ]\n",
      "New theta_0 : [-0.01980951 -0.02811868  0.04034944  0.03707902  0.09344414  0.01315272\n",
      "  0.4606484  -0.08590384 -0.08295256  0.08894386 -0.19714302 -0.16824984\n",
      "  0.11974554 -0.22923   ]\n",
      "Training Error:  10.341510579680854\n",
      "====================================================================================================\n",
      "Iteration:  243\n",
      "Previous theta :  [-0.01980951 -0.02811868  0.04034944  0.03707902  0.09344414  0.01315272\n",
      "  0.4606484  -0.08590384 -0.08295256  0.08894386 -0.19714302 -0.16824984\n",
      "  0.11974554 -0.22923   ]\n",
      "New theta_0 : [-0.01977908 -0.02852539  0.04072903  0.03644262  0.09345553  0.01183834\n",
      "  0.45956093 -0.08602613 -0.08491255  0.08980587 -0.19693693 -0.16861895\n",
      "  0.11950328 -0.22996411]\n",
      "Training Error:  10.33298953195825\n",
      "====================================================================================================\n",
      "Iteration:  244\n",
      "Previous theta :  [-0.01977908 -0.02852539  0.04072903  0.03644262  0.09345553  0.01183834\n",
      "  0.45956093 -0.08602613 -0.08491255  0.08980587 -0.19693693 -0.16861895\n",
      "  0.11950328 -0.22996411]\n",
      "New theta_0 : [-0.01974896 -0.02892943  0.04110869  0.03581193  0.09346681  0.0105325\n",
      "  0.45848348 -0.08614295 -0.08685652  0.09066135 -0.19673373 -0.16898391\n",
      "  0.11926371 -0.23069052]\n",
      "Training Error:  10.32459919591376\n",
      "====================================================================================================\n",
      "Iteration:  245\n",
      "Previous theta :  [-0.01974896 -0.02892943  0.04110869  0.03581193  0.09346681  0.0105325\n",
      "  0.45848348 -0.08614295 -0.08685652  0.09066135 -0.19673373 -0.16898391\n",
      "  0.11926371 -0.23069052]\n",
      "New theta_0 : [-0.01971914 -0.0293308   0.04148836  0.03518692  0.09347797  0.00923517\n",
      "  0.45741594 -0.08625443 -0.08878459  0.09151036 -0.19653339 -0.16934479\n",
      "  0.11902678 -0.23140933]\n",
      "Training Error:  10.316337501775998\n",
      "====================================================================================================\n",
      "Iteration:  246\n",
      "Previous theta :  [-0.01971914 -0.0293308   0.04148836  0.03518692  0.09347797  0.00923517\n",
      "  0.45741594 -0.08625443 -0.08878459  0.09151036 -0.19653339 -0.16934479\n",
      "  0.11902678 -0.23140933]\n",
      "New theta_0 : [-0.01968963 -0.0297295   0.04186799  0.03456754  0.09348901  0.00794629\n",
      "  0.45635821 -0.08636066 -0.09069692  0.09235295 -0.19633588 -0.16970165\n",
      "  0.11879244 -0.23212065]\n",
      "Training Error:  10.308202414258693\n",
      "====================================================================================================\n",
      "Iteration:  247\n",
      "Previous theta :  [-0.01968963 -0.0297295   0.04186799  0.03456754  0.09348901  0.00794629\n",
      "  0.45635821 -0.08636066 -0.09069692  0.09235295 -0.19633588 -0.16970165\n",
      "  0.11879244 -0.23212065]\n",
      "New theta_0 : [-0.01966041 -0.03012557  0.04224752  0.03395375  0.09349994  0.00666579\n",
      "  0.45531019 -0.08646175 -0.09259362  0.09318919 -0.19614117 -0.17005453\n",
      "  0.11856065 -0.23282455]\n",
      "Training Error:  10.30019193193243\n",
      "====================================================================================================\n",
      "Iteration:  248\n",
      "Previous theta :  [-0.01966041 -0.03012557  0.04224752  0.03395375  0.09349994  0.00666579\n",
      "  0.45531019 -0.08646175 -0.09259362  0.09318919 -0.19614117 -0.17005453\n",
      "  0.11856065 -0.23282455]\n",
      "New theta_0 : [-0.01963149 -0.03051899  0.04262691  0.0333455   0.09351075  0.00539364\n",
      "  0.45427178 -0.08655782 -0.09447485  0.09401911 -0.19594926 -0.17040349\n",
      "  0.11833136 -0.23352114]\n",
      "Training Error:  10.292304086609493\n",
      "====================================================================================================\n",
      "Iteration:  249\n",
      "Previous theta :  [-0.01963149 -0.03051899  0.04262691  0.0333455   0.09351075  0.00539364\n",
      "  0.45427178 -0.08655782 -0.09447485  0.09401911 -0.19594926 -0.17040349\n",
      "  0.11833136 -0.23352114]\n",
      "New theta_0 : [-0.01960286 -0.0309098   0.04300611  0.03274276  0.09352144  0.00412977\n",
      "  0.45324287 -0.08664895 -0.09634072  0.09484279 -0.1957601  -0.17074859\n",
      "  0.11810453 -0.23421051]\n",
      "Training Error:  10.284536942741617\n",
      "====================================================================================================\n",
      "Iteration:  250\n",
      "Previous theta :  [-0.01960286 -0.0309098   0.04300611  0.03274276  0.09352144  0.00412977\n",
      "  0.45324287 -0.08664895 -0.09634072  0.09484279 -0.1957601  -0.17074859\n",
      "  0.11810453 -0.23421051]\n",
      "New theta_0 : [-0.01957452 -0.031298    0.04338506  0.03214548  0.09353201  0.00287414\n",
      "  0.45222338 -0.08673526 -0.09819137  0.09566027 -0.19557368 -0.17108987\n",
      "  0.11788013 -0.23489274]\n",
      "Training Error:  10.276888596830187\n",
      "====================================================================================================\n",
      "Iteration:  251\n",
      "Previous theta :  [-0.01957452 -0.031298    0.04338506  0.03214548  0.09353201  0.00287414\n",
      "  0.45222338 -0.08673526 -0.09819137  0.09566027 -0.19557368 -0.17108987\n",
      "  0.11788013 -0.23489274]\n",
      "New theta_0 : [-0.01954646 -0.0316836   0.04376373  0.03155363  0.09354245  0.00162668\n",
      "  0.4512132  -0.08681685 -0.10002693  0.09647161 -0.19538997 -0.17142739\n",
      "  0.1176581  -0.23556793]\n",
      "Training Error:  10.26935717684872\n",
      "====================================================================================================\n",
      "Iteration:  252\n",
      "Previous theta :  [-0.01954646 -0.0316836   0.04376373  0.03155363  0.09354245  0.00162668\n",
      "  0.4512132  -0.08681685 -0.10002693  0.09647161 -0.19538997 -0.17142739\n",
      "  0.1176581  -0.23556793]\n",
      "New theta_0 : [-1.95186920e-02 -3.20666202e-02  4.41420729e-02  3.09671498e-02\n",
      "  9.35527756e-02  3.87363853e-04  4.50212233e-01 -8.68937986e-02\n",
      " -1.01847535e-01  9.72768575e-02 -1.95208947e-01 -1.71761204e-01\n",
      "  1.17438418e-01 -2.36236156e-01]\n",
      "Training Error:  10.261940841677214\n",
      "====================================================================================================\n",
      "Iteration:  253\n",
      "Previous theta :  [-1.95186920e-02 -3.20666202e-02  4.41420729e-02  3.09671498e-02\n",
      "  9.35527756e-02  3.87363853e-04  4.50212233e-01 -8.68937986e-02\n",
      " -1.01847535e-01  9.72768575e-02 -1.95208947e-01 -1.71761204e-01\n",
      "  1.17438418e-01 -2.36236156e-01]\n",
      "New theta_0 : [-0.0194912  -0.03244707  0.04452004  0.03038601  0.09356297 -0.00084388\n",
      "  0.44922039 -0.08696622 -0.1036533   0.09807607 -0.19503059 -0.17209135\n",
      "  0.11722104 -0.23689751]\n",
      "Training Error:  10.254637780548123\n",
      "====================================================================================================\n",
      "Iteration:  254\n",
      "Previous theta :  [-0.0194912  -0.03244707  0.04452004  0.03038601  0.09356297 -0.00084388\n",
      "  0.44922039 -0.08696622 -0.1036533   0.09807607 -0.19503059 -0.17209135\n",
      "  0.11722104 -0.23689751]\n",
      "New theta_0 : [-0.01946399 -0.03282496  0.04489758  0.02981017  0.09357305 -0.00206709\n",
      "  0.44823757 -0.08703419 -0.10544436  0.09886929 -0.19485486 -0.17241789\n",
      "  0.11700592 -0.23755209]\n",
      "Training Error:  10.247446212503679\n",
      "====================================================================================================\n",
      "Iteration:  255\n",
      "Previous theta :  [-0.01946399 -0.03282496  0.04489758  0.02981017  0.09357305 -0.00206709\n",
      "  0.44823757 -0.08703419 -0.10544436  0.09886929 -0.19485486 -0.17241789\n",
      "  0.11700592 -0.23755209]\n",
      "New theta_0 : [-0.01943706 -0.0332003   0.04527466  0.02923958  0.093583   -0.00328233\n",
      "  0.44726369 -0.08709782 -0.10722084  0.09965659 -0.19468176 -0.17274086\n",
      "  0.11679303 -0.23819995]\n",
      "Training Error:  10.240364385864254\n",
      "====================================================================================================\n",
      "Iteration:  256\n",
      "Previous theta :  [-0.01943706 -0.0332003   0.04527466  0.02923958  0.093583   -0.00328233\n",
      "  0.44726369 -0.08709782 -0.10722084  0.09965659 -0.19468176 -0.17274086\n",
      "  0.11679303 -0.23819995]\n",
      "New theta_0 : [-0.01941039 -0.03357311  0.04565125  0.02867421  0.09359282 -0.00448964\n",
      "  0.44629865 -0.0871572  -0.10898287  0.100438   -0.19451124 -0.17306031\n",
      "  0.11658233 -0.2388412 ]\n",
      "Training Error:  10.233390577707524\n",
      "====================================================================================================\n",
      "Iteration:  257\n",
      "Previous theta :  [-0.01941039 -0.03357311  0.04565125  0.02867421  0.09359282 -0.00448964\n",
      "  0.44629865 -0.0871572  -0.10898287  0.100438   -0.19451124 -0.17306031\n",
      "  0.11658233 -0.2388412 ]\n",
      "New theta_0 : [-0.019384   -0.03394339  0.0460273   0.02811401  0.09360252 -0.00568907\n",
      "  0.44534237 -0.0872124  -0.11073055  0.10121358 -0.19434329 -0.1733763\n",
      "  0.1163738  -0.23947591]\n",
      "Training Error:  10.226523093358157\n",
      "====================================================================================================\n",
      "Iteration:  258\n",
      "Previous theta :  [-0.019384   -0.03394339  0.0460273   0.02811401  0.09360252 -0.00568907\n",
      "  0.44534237 -0.0872124  -0.11073055  0.10121358 -0.19434329 -0.1733763\n",
      "  0.1163738  -0.23947591]\n",
      "New theta_0 : [-0.01935787 -0.03431117  0.04640277  0.02755895  0.09361209 -0.00688067\n",
      "  0.44439474 -0.08726353 -0.11246403  0.10198338 -0.19417788 -0.17368886\n",
      "  0.11616738 -0.24010417]\n",
      "Training Error:  10.219760265887796\n",
      "====================================================================================================\n",
      "Iteration:  259\n",
      "Previous theta :  [-0.01935787 -0.03431117  0.04640277  0.02755895  0.09361209 -0.00688067\n",
      "  0.44439474 -0.08726353 -0.11246403  0.10198338 -0.19417788 -0.17368886\n",
      "  0.11616738 -0.24010417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01933201 -0.03467646  0.04677762  0.02700898  0.09362154 -0.0080645\n",
      "  0.44345569 -0.08731066 -0.11418341  0.10274746 -0.194015   -0.17399804\n",
      "  0.11596306 -0.24072604]\n",
      "Training Error:  10.21310045562505\n",
      "====================================================================================================\n",
      "Iteration:  260\n",
      "Previous theta :  [-0.01933201 -0.03467646  0.04677762  0.02700898  0.09362154 -0.0080645\n",
      "  0.44345569 -0.08731066 -0.11418341  0.10274746 -0.194015   -0.17399804\n",
      "  0.11596306 -0.24072604]\n",
      "New theta_0 : [-0.01930641 -0.03503926  0.04715183  0.02646407  0.09363086 -0.0092406\n",
      "  0.44252513 -0.08735388 -0.11588882  0.10350585 -0.19385461 -0.17430389\n",
      "  0.11576079 -0.24134161]\n",
      "Training Error:  10.206542049675297\n",
      "====================================================================================================\n",
      "Iteration:  261\n",
      "Previous theta :  [-0.01930641 -0.03503926  0.04715183  0.02646407  0.09363086 -0.0092406\n",
      "  0.44252513 -0.08735388 -0.11588882  0.10350585 -0.19385461 -0.17430389\n",
      "  0.11576079 -0.24134161]\n",
      "New theta_0 : [-0.01928106 -0.03539959  0.04752535  0.02592418  0.09364005 -0.01040902\n",
      "  0.44160296 -0.08739327 -0.11758037  0.10425862 -0.1936967  -0.17460645\n",
      "  0.11556055 -0.24195096]\n",
      "Training Error:  10.200083461450047\n",
      "====================================================================================================\n",
      "Iteration:  262\n",
      "Previous theta :  [-0.01928106 -0.03539959  0.04752535  0.02592418  0.09364005 -0.01040902\n",
      "  0.44160296 -0.08739327 -0.11758037  0.10425862 -0.1936967  -0.17460645\n",
      "  0.11556055 -0.24195096]\n",
      "New theta_0 : [-0.01925597 -0.03575746  0.04789816  0.02538926  0.09364911 -0.01156981\n",
      "  0.44068911 -0.08742892 -0.11925818  0.1050058  -0.19354123 -0.17490577\n",
      "  0.11536231 -0.24255415]\n",
      "Training Error:  10.193723130205653\n",
      "====================================================================================================\n",
      "Iteration:  263\n",
      "Previous theta :  [-0.01925597 -0.03575746  0.04789816  0.02538926  0.09364911 -0.01156981\n",
      "  0.44068911 -0.08742892 -0.11925818  0.1050058  -0.19354123 -0.17490577\n",
      "  0.11536231 -0.24255415]\n",
      "New theta_0 : [-0.01923114 -0.03611289  0.04827021  0.02485929  0.09365805 -0.01272301\n",
      "  0.43978349 -0.08746091 -0.12092238  0.10574745 -0.1933882  -0.17520188\n",
      "  0.11516603 -0.24315128]\n",
      "Training Error:  10.187459520591124\n",
      "====================================================================================================\n",
      "Iteration:  264\n",
      "Previous theta :  [-0.01923114 -0.03611289  0.04827021  0.02485929  0.09365805 -0.01272301\n",
      "  0.43978349 -0.08746091 -0.12092238  0.10574745 -0.1933882  -0.17520188\n",
      "  0.11516603 -0.24315128]\n",
      "New theta_0 : [-0.01920655 -0.03646589  0.04864148  0.02433421  0.09366687 -0.01386868\n",
      "  0.43888601 -0.08748931 -0.12257306  0.10648362 -0.19323756 -0.17549483\n",
      "  0.11497169 -0.2437424 ]\n",
      "Training Error:  10.181291122204863\n",
      "====================================================================================================\n",
      "Iteration:  265\n",
      "Previous theta :  [-0.01920655 -0.03646589  0.04864148  0.02433421  0.09366687 -0.01386868\n",
      "  0.43888601 -0.08748931 -0.12257306  0.10648362 -0.19323756 -0.17549483\n",
      "  0.11497169 -0.2437424 ]\n",
      "New theta_0 : [-0.01918221 -0.03681647  0.04901194  0.023814    0.09367555 -0.01500686\n",
      "  0.43799659 -0.0875142  -0.12421036  0.10721435 -0.19308932 -0.17578467\n",
      "  0.11477925 -0.2443276 ]\n",
      "Training Error:  10.175216449160095\n",
      "====================================================================================================\n",
      "Iteration:  266\n",
      "Previous theta :  [-0.01918221 -0.03681647  0.04901194  0.023814    0.09367555 -0.01500686\n",
      "  0.43799659 -0.0875142  -0.12421036  0.10721435 -0.19308932 -0.17578467\n",
      "  0.11477925 -0.2443276 ]\n",
      "New theta_0 : [-0.01915812 -0.03716464  0.04938156  0.02329862  0.09368412 -0.0161376\n",
      "  0.43711515 -0.08753566 -0.12583437  0.10793969 -0.19294343 -0.17607142\n",
      "  0.11458869 -0.24490694]\n",
      "Training Error:  10.169234039658807\n",
      "====================================================================================================\n",
      "Iteration:  267\n",
      "Previous theta :  [-0.01915812 -0.03716464  0.04938156  0.02329862  0.09368412 -0.0161376\n",
      "  0.43711515 -0.08753566 -0.12583437  0.10793969 -0.19294343 -0.17607142\n",
      "  0.11458869 -0.24490694]\n",
      "New theta_0 : [-0.01913426 -0.03751043  0.04975031  0.02278802  0.09369255 -0.01726095\n",
      "  0.43624162 -0.08755376 -0.12744522  0.10865969 -0.19279988 -0.17635514\n",
      "  0.11439998 -0.24548049]\n",
      "Training Error:  10.163342455573988\n",
      "====================================================================================================\n",
      "Iteration:  268\n",
      "Previous theta :  [-0.01913426 -0.03751043  0.04975031  0.02278802  0.09369255 -0.01726095\n",
      "  0.43624162 -0.08755376 -0.12744522  0.10865969 -0.19279988 -0.17635514\n",
      "  0.11439998 -0.24548049]\n",
      "New theta_0 : [-0.01911065 -0.03785383  0.05011816  0.02228217  0.09370087 -0.01837695\n",
      "  0.4353759  -0.08756857 -0.12904301  0.1093744  -0.19265864 -0.17663586\n",
      "  0.11421309 -0.24604833]\n",
      "Training Error:  10.157540282039992\n",
      "====================================================================================================\n",
      "Iteration:  269\n",
      "Previous theta :  [-0.01911065 -0.03785383  0.05011816  0.02228217  0.09370087 -0.01837695\n",
      "  0.4353759  -0.08756857 -0.12904301  0.1093744  -0.19265864 -0.17663586\n",
      "  0.11421309 -0.24604833]\n",
      "New theta_0 : [-0.01908727 -0.03819486  0.05048508  0.02178103  0.09370905 -0.01948565\n",
      "  0.43451792 -0.08758018 -0.13062785  0.11008386 -0.1925197  -0.17691363\n",
      "  0.114028   -0.24661052]\n",
      "Training Error:  10.151826127050795\n",
      "====================================================================================================\n",
      "Iteration:  270\n",
      "Previous theta :  [-0.01908727 -0.03819486  0.05048508  0.02178103  0.09370905 -0.01948565\n",
      "  0.43451792 -0.08758018 -0.13062785  0.11008386 -0.1925197  -0.17691363\n",
      "  0.114028   -0.24661052]\n",
      "New theta_0 : [-0.01906412 -0.03853354  0.05085105  0.02128457  0.09371712 -0.0205871\n",
      "  0.43366761 -0.08758864 -0.13219986  0.11078811 -0.19238303 -0.17718848\n",
      "  0.11384468 -0.24716713]\n",
      "Training Error:  10.146198621066079\n",
      "====================================================================================================\n",
      "Iteration:  271\n",
      "Previous theta :  [-0.01906412 -0.03853354  0.05085105  0.02128457  0.09371712 -0.0205871\n",
      "  0.43366761 -0.08758864 -0.13219986  0.11078811 -0.19238303 -0.17718848\n",
      "  0.11384468 -0.24716713]\n",
      "New theta_0 : [-0.01904121 -0.03886987  0.05121604  0.02079275  0.09372506 -0.02168134\n",
      "  0.43282488 -0.08759402 -0.13375914  0.11148721 -0.19224861 -0.17746044\n",
      "  0.11366311 -0.24771823]\n",
      "Training Error:  10.140656416624804\n",
      "====================================================================================================\n",
      "Iteration:  272\n",
      "Previous theta :  [-0.01904121 -0.03886987  0.05121604  0.02079275  0.09372506 -0.02168134\n",
      "  0.43282488 -0.08759402 -0.13375914  0.11148721 -0.19224861 -0.17746044\n",
      "  0.11366311 -0.24771823]\n",
      "New theta_0 : [-0.01901852 -0.03920388  0.05158003  0.02030553  0.09373287 -0.02276842\n",
      "  0.43198966 -0.0875964  -0.13530579  0.11218119 -0.19211641 -0.17772956\n",
      "  0.11348326 -0.24826388]\n",
      "Training Error:  10.135198187966258\n",
      "====================================================================================================\n",
      "Iteration:  273\n",
      "Previous theta :  [-0.01901852 -0.03920388  0.05158003  0.02030553  0.09373287 -0.02276842\n",
      "  0.43198966 -0.0875964  -0.13530579  0.11218119 -0.19211641 -0.17772956\n",
      "  0.11348326 -0.24826388]\n",
      "New theta_0 : [-0.01899606 -0.03953557  0.051943    0.01982287  0.09374057 -0.02384838\n",
      "  0.43116187 -0.08759584 -0.13683992  0.11287011 -0.19198643 -0.17799588\n",
      "  0.1133051  -0.24880415]\n",
      "Training Error:  10.1298226306583\n",
      "====================================================================================================\n",
      "Iteration:  274\n",
      "Previous theta :  [-0.01899606 -0.03953557  0.051943    0.01982287  0.09374057 -0.02384838\n",
      "  0.43116187 -0.08759584 -0.13683992  0.11287011 -0.19198643 -0.17799588\n",
      "  0.1133051  -0.24880415]\n",
      "New theta_0 : [-0.01897382 -0.03986496  0.05230491  0.01934475  0.09374814 -0.02492127\n",
      "  0.43034144 -0.08759241 -0.13836164  0.113554   -0.19185863 -0.17825942\n",
      "  0.11312861 -0.2493391 ]\n",
      "Training Error:  10.124528461232707\n",
      "====================================================================================================\n",
      "Iteration:  275\n",
      "Previous theta :  [-0.01897382 -0.03986496  0.05230491  0.01934475  0.09374814 -0.02492127\n",
      "  0.43034144 -0.08759241 -0.13836164  0.113554   -0.19185863 -0.17825942\n",
      "  0.11312861 -0.2493391 ]\n",
      "New theta_0 : [-0.01895181 -0.04019206  0.05266576  0.01887112  0.09375559 -0.02598713\n",
      "  0.4295283  -0.08758618 -0.13987106  0.11423291 -0.19173299 -0.17852023\n",
      "  0.11295378 -0.24986879]\n",
      "Training Error:  10.119314416827434\n",
      "====================================================================================================\n",
      "Iteration:  276\n",
      "Previous theta :  [-0.01895181 -0.04019206  0.05266576  0.01887112  0.09375559 -0.02598713\n",
      "  0.4295283  -0.08758618 -0.13987106  0.11423291 -0.19173299 -0.17852023\n",
      "  0.11295378 -0.24986879]\n",
      "New theta_0 : [-0.01893001 -0.04051688  0.05302551  0.01840195  0.09376292 -0.02704601\n",
      "  0.42872237 -0.08757719 -0.14136826  0.11490689 -0.1916095  -0.17877834\n",
      "  0.11278057 -0.25039329]\n",
      "Training Error:  10.11417925483565\n",
      "====================================================================================================\n",
      "Iteration:  277\n",
      "Previous theta :  [-0.01893001 -0.04051688  0.05302551  0.01840195  0.09376292 -0.02704601\n",
      "  0.42872237 -0.08757719 -0.14136826  0.11490689 -0.1916095  -0.17877834\n",
      "  0.11278057 -0.25039329]\n",
      "New theta_0 : [-0.01890842 -0.04083944  0.05338415  0.0179372   0.09377013 -0.02809795\n",
      "  0.42792357 -0.08756553 -0.14285337  0.11557597 -0.19148813 -0.17903379\n",
      "  0.11260897 -0.25091266]\n",
      "Training Error:  10.109121752561377\n",
      "====================================================================================================\n",
      "Iteration:  278\n",
      "Previous theta :  [-0.01890842 -0.04083944  0.05338415  0.0179372   0.09377013 -0.02809795\n",
      "  0.42792357 -0.08756553 -0.14285337  0.11557597 -0.19148813 -0.17903379\n",
      "  0.11260897 -0.25091266]\n",
      "New theta_0 : [-0.01888705 -0.04115974  0.05374166  0.01747684  0.09377723 -0.02914299\n",
      "  0.42713185 -0.08755124 -0.14432647  0.1162402  -0.19136886 -0.17928661\n",
      "  0.11243895 -0.25142696]\n",
      "Training Error:  10.10414070688163\n",
      "====================================================================================================\n",
      "Iteration:  279\n",
      "Previous theta :  [-0.01888705 -0.04115974  0.05374166  0.01747684  0.09377723 -0.02914299\n",
      "  0.42713185 -0.08755124 -0.14432647  0.1162402  -0.19136886 -0.17928661\n",
      "  0.11243895 -0.25142696]\n",
      "New theta_0 : [-0.01886589 -0.04147781  0.05409801  0.01702083  0.0937842  -0.03018119\n",
      "  0.42634712 -0.08753439 -0.14578767  0.11689963 -0.19125167 -0.17953683\n",
      "  0.11227049 -0.25193624]\n",
      "Training Error:  10.099234933914865\n",
      "====================================================================================================\n",
      "Iteration:  280\n",
      "Previous theta :  [-0.01886589 -0.04147781  0.05409801  0.01702083  0.0937842  -0.03018119\n",
      "  0.42634712 -0.08753439 -0.14578767  0.11689963 -0.19125167 -0.17953683\n",
      "  0.11227049 -0.25193624]\n",
      "New theta_0 : [-0.01884494 -0.04179365  0.05445319  0.01656915  0.09379106 -0.03121258\n",
      "  0.42556932 -0.08751504 -0.14723707  0.11755428 -0.19113654 -0.17978449\n",
      "  0.11210357 -0.25244057]\n",
      "Training Error:  10.094403268695647\n",
      "====================================================================================================\n",
      "Iteration:  281\n",
      "Previous theta :  [-0.01884494 -0.04179365  0.05445319  0.01656915  0.09379106 -0.03121258\n",
      "  0.42556932 -0.08751504 -0.14723707  0.11755428 -0.19113654 -0.17978449\n",
      "  0.11210357 -0.25244057]\n",
      "New theta_0 : [-0.01882419 -0.04210728  0.05480718  0.01612174  0.0937978  -0.0322372\n",
      "  0.42479838 -0.08749324 -0.14867476  0.11820421 -0.19102346 -0.18002962\n",
      "  0.11193818 -0.25294001]\n",
      "Training Error:  10.089644564855364\n",
      "====================================================================================================\n",
      "Iteration:  282\n",
      "Previous theta :  [-0.01882419 -0.04210728  0.05480718  0.01612174  0.0937978  -0.0322372\n",
      "  0.42479838 -0.08749324 -0.14867476  0.11820421 -0.19102346 -0.18002962\n",
      "  0.11193818 -0.25294001]\n",
      "New theta_0 : [-0.01880365 -0.04241871  0.05515997  0.01567859  0.09380442 -0.0332551\n",
      "  0.42403423 -0.08746905 -0.15010085  0.11884946 -0.19091239 -0.18027225\n",
      "  0.11177428 -0.25343461]\n",
      "Training Error:  10.084957694308882\n",
      "====================================================================================================\n",
      "Iteration:  283\n",
      "Previous theta :  [-0.01880365 -0.04241871  0.05515997  0.01567859  0.09380442 -0.0332551\n",
      "  0.42403423 -0.08746905 -0.15010085  0.11884946 -0.19091239 -0.18027225\n",
      "  0.11177428 -0.25343461]\n",
      "New theta_0 : [-0.01878331 -0.04272795  0.05551153  0.01523966  0.09381093 -0.03426632\n",
      "  0.4232768  -0.08744253 -0.15151542  0.11949007 -0.19080333 -0.18051242\n",
      "  0.11161186 -0.25392442]\n",
      "Training Error:  10.08034154694699\n",
      "====================================================================================================\n",
      "Iteration:  284\n",
      "Previous theta :  [-0.01878331 -0.04272795  0.05551153  0.01523966  0.09381093 -0.03426632\n",
      "  0.4232768  -0.08744253 -0.15151542  0.11949007 -0.19080333 -0.18051242\n",
      "  0.11161186 -0.25392442]\n",
      "New theta_0 : [-0.01876316 -0.04303502  0.05586186  0.0148049   0.09381732 -0.0352709\n",
      "  0.42252603 -0.08741374 -0.15291859  0.12012607 -0.19069625 -0.18075016\n",
      "  0.11145091 -0.25440951]\n",
      "Training Error:  10.075795030334552\n",
      "====================================================================================================\n",
      "Iteration:  285\n",
      "Previous theta :  [-0.01876316 -0.04303502  0.05586186  0.0148049   0.09381732 -0.0352709\n",
      "  0.42252603 -0.08741374 -0.15291859  0.12012607 -0.19069625 -0.18075016\n",
      "  0.11145091 -0.25440951]\n",
      "New theta_0 : [-0.01874321 -0.04333992  0.05621093  0.0143743   0.09382361 -0.03626889\n",
      "  0.42178185 -0.08738271 -0.15431043  0.12075751 -0.19059112 -0.18098549\n",
      "  0.11129139 -0.25488993]\n",
      "Training Error:  10.071317069414194\n",
      "====================================================================================================\n",
      "Iteration:  286\n",
      "Previous theta :  [-0.01874321 -0.04333992  0.05621093  0.0143743   0.09382361 -0.03626889\n",
      "  0.42178185 -0.08738271 -0.15431043  0.12075751 -0.19059112 -0.18098549\n",
      "  0.11129139 -0.25488993]\n",
      "New theta_0 : [-0.01872346 -0.04364267  0.05655873  0.01394781  0.09382977 -0.03726033\n",
      "  0.42104419 -0.08734952 -0.15569105  0.12138443 -0.19048794 -0.18121845\n",
      "  0.11113331 -0.25536573]\n",
      "Training Error:  10.066906606215445\n",
      "====================================================================================================\n",
      "Iteration:  287\n",
      "Previous theta :  [-0.01872346 -0.04364267  0.05655873  0.01394781  0.09382977 -0.03726033\n",
      "  0.42104419 -0.08734952 -0.15569105  0.12138443 -0.19048794 -0.18121845\n",
      "  0.11113331 -0.25536573]\n",
      "New theta_0 : [-0.0187039  -0.04394329  0.05690524  0.0135254   0.09383583 -0.03824526\n",
      "  0.420313   -0.08731421 -0.15706053  0.12200687 -0.19038669 -0.18144907\n",
      "  0.11097662 -0.25583697]\n",
      "Training Error:  10.062562599569205\n",
      "====================================================================================================\n",
      "Iteration:  288\n",
      "Previous theta :  [-0.0187039  -0.04394329  0.05690524  0.0135254   0.09383583 -0.03824526\n",
      "  0.420313   -0.08731421 -0.15706053  0.12200687 -0.19038669 -0.18144907\n",
      "  0.11097662 -0.25583697]\n",
      "New theta_0 : [-0.01868453 -0.04424179  0.05725046  0.01310705  0.09384178 -0.03922371\n",
      "  0.4195882  -0.08727682 -0.15841898  0.12262486 -0.19028733 -0.18167738\n",
      "  0.11082133 -0.2563037 ]\n",
      "Training Error:  10.058284024827415\n",
      "====================================================================================================\n",
      "Iteration:  289\n",
      "Previous theta :  [-0.01868453 -0.04424179  0.05725046  0.01310705  0.09384178 -0.03922371\n",
      "  0.4195882  -0.08727682 -0.15841898  0.12262486 -0.19028733 -0.18167738\n",
      "  0.11082133 -0.2563037 ]\n",
      "New theta_0 : [-0.01866534 -0.04453817  0.05759436  0.01269271  0.09384762 -0.04019574\n",
      "  0.41886974 -0.08723742 -0.15976648  0.12323844 -0.19018986 -0.1819034\n",
      "  0.11066741 -0.25676597]\n",
      "Training Error:  10.054069873587858\n",
      "====================================================================================================\n",
      "Iteration:  290\n",
      "Previous theta :  [-0.01866534 -0.04453817  0.05759436  0.01269271  0.09384762 -0.04019574\n",
      "  0.41886974 -0.08723742 -0.15976648  0.12323844 -0.19018986 -0.1819034\n",
      "  0.11066741 -0.25676597]\n",
      "New theta_0 : [-0.01864634 -0.04483246  0.05793695  0.01228236  0.09385334 -0.04116138\n",
      "  0.41815754 -0.08719605 -0.16110313  0.12384766 -0.19009426 -0.18212718\n",
      "  0.11051484 -0.25722383]\n",
      "Training Error:  10.049919153423934\n",
      "====================================================================================================\n",
      "Iteration:  291\n",
      "Previous theta :  [-0.01864634 -0.04483246  0.05793695  0.01228236  0.09385334 -0.04116138\n",
      "  0.41815754 -0.08719605 -0.16110313  0.12384766 -0.19009426 -0.18212718\n",
      "  0.11051484 -0.25722383]\n",
      "New theta_0 : [-0.01862752 -0.04512465  0.05827819  0.01187595  0.09385896 -0.04212067\n",
      "  0.41745156 -0.08715275 -0.162429    0.12445255 -0.19000051 -0.18234872\n",
      "  0.11036361 -0.25767733]\n",
      "Training Error:  10.045830887619346\n",
      "====================================================================================================\n",
      "Iteration:  292\n",
      "Previous theta :  [-0.01862752 -0.04512465  0.05827819  0.01187595  0.09385896 -0.04212067\n",
      "  0.41745156 -0.08715275 -0.162429    0.12445255 -0.19000051 -0.18234872\n",
      "  0.11036361 -0.25767733]\n",
      "New theta_0 : [-0.01860889 -0.04541478  0.05861809  0.01147347  0.09386448 -0.04307366\n",
      "  0.41675173 -0.08710758 -0.1637442   0.12505314 -0.18990858 -0.18256807\n",
      "  0.1102137  -0.25812653]\n",
      "Training Error:  10.041804114907567\n",
      "====================================================================================================\n",
      "Iteration:  293\n",
      "Previous theta :  [-0.01860889 -0.04541478  0.05861809  0.01147347  0.09386448 -0.04307366\n",
      "  0.41675173 -0.08710758 -0.1637442   0.12505314 -0.18990858 -0.18256807\n",
      "  0.1102137  -0.25812653]\n",
      "New theta_0 : [-0.01859043 -0.04570285  0.05895663  0.01107488  0.09386988 -0.04402037\n",
      "  0.41605799 -0.08706058 -0.16504881  0.12564948 -0.18981846 -0.18278525\n",
      "  0.1100651  -0.25857146]\n",
      "Training Error:  10.037837889216021\n",
      "====================================================================================================\n",
      "Iteration:  294\n",
      "Previous theta :  [-0.01859043 -0.04570285  0.05895663  0.01107488  0.09386988 -0.04402037\n",
      "  0.41605799 -0.08706058 -0.16504881  0.12564948 -0.18981846 -0.18278525\n",
      "  0.1100651  -0.25857146]\n",
      "New theta_0 : [-0.01857215 -0.04598886  0.0592938   0.01068015  0.09387518 -0.04496086\n",
      "  0.41537027 -0.08701179 -0.16634292  0.12624161 -0.18973014 -0.18300028\n",
      "  0.10991778 -0.25901219]\n",
      "Training Error:  10.033931279414839\n",
      "====================================================================================================\n",
      "Iteration:  295\n",
      "Previous theta :  [-0.01857215 -0.04598886  0.0592938   0.01068015  0.09387518 -0.04496086\n",
      "  0.41537027 -0.08701179 -0.16634292  0.12624161 -0.18973014 -0.18300028\n",
      "  0.10991778 -0.25901219]\n",
      "New theta_0 : [-0.01855404 -0.04627284  0.05962959  0.01028924  0.09388038 -0.04589517\n",
      "  0.41468853 -0.08696127 -0.16762662  0.12682955 -0.18964359 -0.18321321\n",
      "  0.10977174 -0.25944876]\n",
      "Training Error:  10.030083369070145\n",
      "====================================================================================================\n",
      "Iteration:  296\n",
      "Previous theta :  [-0.01855404 -0.04627284  0.05962959  0.01028924  0.09388038 -0.04589517\n",
      "  0.41468853 -0.08696127 -0.16762662  0.12682955 -0.18964359 -0.18321321\n",
      "  0.10977174 -0.25944876]\n",
      "New theta_0 : [-0.01853611 -0.0465548   0.05996399  0.00990213  0.09388547 -0.04682332\n",
      "  0.4140127  -0.08690905 -0.16889999  0.12741335 -0.18955879 -0.18342404\n",
      "  0.10962696 -0.25988121]\n",
      "Training Error:  10.026293256201726\n",
      "====================================================================================================\n",
      "Iteration:  297\n",
      "Previous theta :  [-0.01853611 -0.0465548   0.05996399  0.00990213  0.09388547 -0.04682332\n",
      "  0.4140127  -0.08690905 -0.16889999  0.12741335 -0.18955879 -0.18342404\n",
      "  0.10962696 -0.25988121]\n",
      "New theta_0 : [-0.01851834 -0.04683475  0.06029699  0.00951878  0.09389047 -0.04774537\n",
      "  0.41334272 -0.08685517 -0.17016311  0.12799304 -0.18947574 -0.1836328\n",
      "  0.10948342 -0.26030959]\n",
      "Training Error:  10.02256005304506\n",
      "====================================================================================================\n",
      "Iteration:  298\n",
      "Previous theta :  [-0.01851834 -0.04683475  0.06029699  0.00951878  0.09389047 -0.04774537\n",
      "  0.41334272 -0.08685517 -0.17016311  0.12799304 -0.18947574 -0.1836328\n",
      "  0.10948342 -0.26030959]\n",
      "New theta_0 : [-0.01850075 -0.0471127   0.06062858  0.00913916  0.09389536 -0.04866134\n",
      "  0.41267854 -0.08679969 -0.17141608  0.12856865 -0.1893944  -0.18383954\n",
      "  0.10934112 -0.26073395]\n",
      "Training Error:  10.018882885817531\n",
      "====================================================================================================\n",
      "Iteration:  299\n",
      "Previous theta :  [-0.01850075 -0.0471127   0.06062858  0.00913916  0.09389536 -0.04866134\n",
      "  0.41267854 -0.08679969 -0.17141608  0.12856865 -0.1893944  -0.18383954\n",
      "  0.10934112 -0.26073395]\n",
      "New theta_0 : [-0.01848332 -0.04738866  0.06095876  0.00876325  0.09390015 -0.04957128\n",
      "  0.4120201  -0.08674264 -0.17265897  0.12914023 -0.18931477 -0.18404425\n",
      "  0.10920002 -0.26115434]\n",
      "Training Error:  10.015260894488863\n",
      "====================================================================================================\n",
      "Iteration:  300\n",
      "Previous theta :  [-0.01848332 -0.04738866  0.06095876  0.00876325  0.09390015 -0.04957128\n",
      "  0.4120201  -0.08674264 -0.17265897  0.12914023 -0.18931477 -0.18404425\n",
      "  0.10920002 -0.26115434]\n",
      "New theta_0 : [-0.01846606 -0.04766265  0.06128751  0.00839101  0.09390484 -0.05047524\n",
      "  0.41136735 -0.08668406 -0.17389187  0.1297078  -0.18923683 -0.18424699\n",
      "  0.10906013 -0.26157079]\n",
      "Training Error:  10.01169323255553\n",
      "====================================================================================================\n",
      "Iteration:  301\n",
      "Previous theta :  [-0.01846606 -0.04766265  0.06128751  0.00839101  0.09390484 -0.05047524\n",
      "  0.41136735 -0.08668406 -0.17389187  0.1297078  -0.18923683 -0.18424699\n",
      "  0.10906013 -0.26157079]\n",
      "New theta_0 : [-0.01844896 -0.04793468  0.06161484  0.00802241  0.09390943 -0.05137323\n",
      "  0.41072022 -0.08662399 -0.17511486  0.13027141 -0.18916055 -0.18444775\n",
      "  0.10892143 -0.26198335]\n",
      "Training Error:  10.008179066819247\n",
      "====================================================================================================\n",
      "Iteration:  302\n",
      "Previous theta :  [-0.01844896 -0.04793468  0.06161484  0.00802241  0.09390943 -0.05137323\n",
      "  0.41072022 -0.08662399 -0.17511486  0.13027141 -0.18916055 -0.18444775\n",
      "  0.10892143 -0.26198335]\n",
      "New theta_0 : [-0.01843202 -0.04820476  0.06194072  0.00765743  0.09391392 -0.05226531\n",
      "  0.41007868 -0.08656247 -0.17632802  0.13083108 -0.18908593 -0.18464659\n",
      "  0.1087839  -0.26239207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.004717577169295\n",
      "====================================================================================================\n",
      "Iteration:  303\n",
      "Previous theta :  [-0.01843202 -0.04820476  0.06194072  0.00765743  0.09391392 -0.05226531\n",
      "  0.41007868 -0.08656247 -0.17632802  0.13083108 -0.18908593 -0.18464659\n",
      "  0.1087839  -0.26239207]\n",
      "New theta_0 : [-0.01841524 -0.04847291  0.06226516  0.00729602  0.09391832 -0.05315151\n",
      "  0.40944265 -0.08649953 -0.17753144  0.13138685 -0.18901294 -0.1848435\n",
      "  0.10864752 -0.26279699]\n",
      "Training Error:  10.001307956368704\n",
      "====================================================================================================\n",
      "Iteration:  304\n",
      "Previous theta :  [-0.01841524 -0.04847291  0.06226516  0.00729602  0.09391832 -0.05315151\n",
      "  0.40944265 -0.08649953 -0.17753144  0.13138685 -0.18901294 -0.1848435\n",
      "  0.10864752 -0.26279699]\n",
      "New theta_0 : [-0.01839861 -0.04873913  0.06258814  0.00693818  0.09392262 -0.05403186\n",
      "  0.40881209 -0.08643523 -0.17872519  0.13193875 -0.18894157 -0.18503853\n",
      "  0.1085123  -0.26319815]\n",
      "Training Error:  9.997949409844189\n",
      "====================================================================================================\n",
      "Iteration:  305\n",
      "Previous theta :  [-0.01839861 -0.04873913  0.06258814  0.00693818  0.09392262 -0.05403186\n",
      "  0.40881209 -0.08643523 -0.17872519  0.13193875 -0.18894157 -0.18503853\n",
      "  0.1085123  -0.26319815]\n",
      "New theta_0 : [-0.01838215 -0.04900343  0.06290967  0.00658385  0.09392682 -0.05490642\n",
      "  0.40818695 -0.08636959 -0.17990936  0.13248682 -0.1888718  -0.18523169\n",
      "  0.10837821 -0.26359559]\n",
      "Training Error:  9.994641155479753\n",
      "====================================================================================================\n",
      "Iteration:  306\n",
      "Previous theta :  [-0.01838215 -0.04900343  0.06290967  0.00658385  0.09392682 -0.05490642\n",
      "  0.40818695 -0.08636959 -0.17990936  0.13248682 -0.1888718  -0.18523169\n",
      "  0.10837821 -0.26359559]\n",
      "New theta_0 : [-0.01836583 -0.04926584  0.06322973  0.00623302  0.09393094 -0.0557752\n",
      "  0.40756717 -0.08630264 -0.18108402  0.13303109 -0.18880362 -0.185423\n",
      "  0.10824525 -0.26398936]\n",
      "Training Error:  9.991382423413903\n",
      "====================================================================================================\n",
      "Iteration:  307\n",
      "Previous theta :  [-0.01836583 -0.04926584  0.06322973  0.00623302  0.09393094 -0.0557752\n",
      "  0.40756717 -0.08630264 -0.18108402  0.13303109 -0.18880362 -0.185423\n",
      "  0.10824525 -0.26398936]\n",
      "New theta_0 : [-0.01834967 -0.04952636  0.06354832  0.00588566  0.09393495 -0.05663825\n",
      "  0.4069527  -0.08623443 -0.18224924  0.13357159 -0.188737   -0.18561249\n",
      "  0.10811339 -0.26437949]\n",
      "Training Error:  9.988172455840395\n",
      "====================================================================================================\n",
      "Iteration:  308\n",
      "Previous theta :  [-0.01834967 -0.04952636  0.06354832  0.00588566  0.09393495 -0.05663825\n",
      "  0.4069527  -0.08623443 -0.18224924  0.13357159 -0.188737   -0.18561249\n",
      "  0.10811339 -0.26437949]\n",
      "New theta_0 : [-0.01833366 -0.049785    0.06386544  0.00554173  0.09393888 -0.05749561\n",
      "  0.40634349 -0.08616499 -0.18340512  0.13410836 -0.18867194 -0.18580018\n",
      "  0.10798263 -0.26476603]\n",
      "Training Error:  9.985010506812456\n",
      "====================================================================================================\n",
      "Iteration:  309\n",
      "Previous theta :  [-0.01833366 -0.049785    0.06386544  0.00554173  0.09393888 -0.05749561\n",
      "  0.40634349 -0.08616499 -0.18340512  0.13410836 -0.18867194 -0.18580018\n",
      "  0.10798263 -0.26476603]\n",
      "New theta_0 : [-0.0183178  -0.05004178  0.06418108  0.00520122  0.09394272 -0.05834732\n",
      "  0.4057395  -0.08609436 -0.18455172  0.13464142 -0.18860842 -0.1859861\n",
      "  0.10785295 -0.26514901]\n",
      "Training Error:  9.981895842050397\n",
      "====================================================================================================\n",
      "Iteration:  310\n",
      "Previous theta :  [-0.0183178  -0.05004178  0.06418108  0.00520122  0.09394272 -0.05834732\n",
      "  0.4057395  -0.08609436 -0.18455172  0.13464142 -0.18860842 -0.1859861\n",
      "  0.10785295 -0.26514901]\n",
      "New theta_0 : [-0.01830208 -0.0502967   0.06449523  0.00486408  0.09394646 -0.0591934\n",
      "  0.40514066 -0.08602256 -0.18568913  0.13517081 -0.18854642 -0.18617026\n",
      "  0.10772435 -0.26552847]\n",
      "Training Error:  9.978827738752546\n",
      "====================================================================================================\n",
      "Iteration:  311\n",
      "Previous theta :  [-0.01830208 -0.0502967   0.06449523  0.00486408  0.09394646 -0.0591934\n",
      "  0.40514066 -0.08602256 -0.18568913  0.13517081 -0.18854642 -0.18617026\n",
      "  0.10772435 -0.26552847]\n",
      "New theta_0 : [-0.01828651 -0.05054979  0.0648079   0.0045303   0.09395012 -0.06003389\n",
      "  0.40454693 -0.08594963 -0.18681741  0.13569656 -0.18848593 -0.18635268\n",
      "  0.10759682 -0.26590446]\n",
      "Training Error:  9.97580548540947\n",
      "====================================================================================================\n",
      "Iteration:  312\n",
      "Previous theta :  [-0.01828651 -0.05054979  0.0648079   0.0045303   0.09395012 -0.06003389\n",
      "  0.40454693 -0.08594963 -0.18681741  0.13569656 -0.18848593 -0.18635268\n",
      "  0.10759682 -0.26590446]\n",
      "New theta_0 : [-0.01827108 -0.05080105  0.06511908  0.00419984  0.09395369 -0.06086884\n",
      "  0.40395827 -0.08587561 -0.18793664  0.1362187  -0.18842692 -0.18653339\n",
      "  0.10747033 -0.26627701]\n",
      "Training Error:  9.972828381621397\n",
      "====================================================================================================\n",
      "Iteration:  313\n",
      "Previous theta :  [-0.01827108 -0.05080105  0.06511908  0.00419984  0.09395369 -0.06086884\n",
      "  0.40395827 -0.08587561 -0.18793664  0.1362187  -0.18842692 -0.18653339\n",
      "  0.10747033 -0.26627701]\n",
      "New theta_0 : [-0.0182558  -0.05105049  0.06542876  0.00387268  0.09395717 -0.06169826\n",
      "  0.40337462 -0.08580052 -0.18904689  0.13673726 -0.18836939 -0.18671241\n",
      "  0.10734488 -0.26664616]\n",
      "Training Error:  9.969895737918762\n",
      "====================================================================================================\n",
      "Iteration:  314\n",
      "Previous theta :  [-0.0182558  -0.05105049  0.06542876  0.00387268  0.09395717 -0.06169826\n",
      "  0.40337462 -0.08580052 -0.18904689  0.13673726 -0.18836939 -0.18671241\n",
      "  0.10734488 -0.26664616]\n",
      "New theta_0 : [-0.01824065 -0.05129813  0.06573695  0.00354879  0.09396056 -0.06252222\n",
      "  0.40279594 -0.08572439 -0.19014825  0.13725227 -0.18831333 -0.18688975\n",
      "  0.10722046 -0.26701194]\n",
      "Training Error:  9.967006875585867\n",
      "====================================================================================================\n",
      "Iteration:  315\n",
      "Previous theta :  [-0.01824065 -0.05129813  0.06573695  0.00354879  0.09396056 -0.06252222\n",
      "  0.40279594 -0.08572439 -0.19014825  0.13725227 -0.18831333 -0.18688975\n",
      "  0.10722046 -0.26701194]\n",
      "New theta_0 : [-0.01822565 -0.05154397  0.06604363  0.00322814  0.09396387 -0.06334072\n",
      "  0.40222217 -0.08564726 -0.19124078  0.13776377 -0.1882587  -0.18706544\n",
      "  0.10709706 -0.2673744 ]\n",
      "Training Error:  9.964161126487532\n",
      "====================================================================================================\n",
      "Iteration:  316\n",
      "Previous theta :  [-0.01822565 -0.05154397  0.06604363  0.00322814  0.09396387 -0.06334072\n",
      "  0.40222217 -0.08564726 -0.19124078  0.13776377 -0.1882587  -0.18706544\n",
      "  0.10709706 -0.2673744 ]\n",
      "New theta_0 : [-0.01821078 -0.05178803  0.06634881  0.0029107   0.09396709 -0.06415382\n",
      "  0.40165327 -0.08556916 -0.19232455  0.13827178 -0.18820551 -0.1872395\n",
      "  0.10697466 -0.26773356]\n",
      "Training Error:  9.961357832898743\n",
      "====================================================================================================\n",
      "Iteration:  317\n",
      "Previous theta :  [-0.01821078 -0.05178803  0.06634881  0.0029107   0.09396709 -0.06415382\n",
      "  0.40165327 -0.08556916 -0.19232455  0.13827178 -0.18820551 -0.1872395\n",
      "  0.10697466 -0.26773356]\n",
      "New theta_0 : [-0.01819604 -0.05203033  0.06665249  0.00259646  0.09397023 -0.06496154\n",
      "  0.40108921 -0.08549011 -0.19339964  0.13877634 -0.18815373 -0.18741195\n",
      "  0.10685327 -0.26808947]\n",
      "Training Error:  9.95859634733719\n",
      "====================================================================================================\n",
      "Iteration:  318\n",
      "Previous theta :  [-0.01819604 -0.05203033  0.06665249  0.00259646  0.09397023 -0.06496154\n",
      "  0.40108921 -0.08549011 -0.19339964  0.13877634 -0.18815373 -0.18741195\n",
      "  0.10685327 -0.26808947]\n",
      "New theta_0 : [-0.01818144 -0.05227086  0.06695466  0.00228538  0.09397328 -0.06576392\n",
      "  0.40052992 -0.08541014 -0.19446611  0.13927746 -0.18810335 -0.1875828\n",
      "  0.10673286 -0.26844215]\n",
      "Training Error:  9.95587603239866\n",
      "====================================================================================================\n",
      "Iteration:  319\n",
      "Previous theta :  [-0.01818144 -0.05227086  0.06695466  0.00228538  0.09397328 -0.06576392\n",
      "  0.40052992 -0.08541014 -0.19446611  0.13927746 -0.18810335 -0.1875828\n",
      "  0.10673286 -0.26844215]\n",
      "New theta_0 : [-0.01816698 -0.05250965  0.06725532  0.00197743  0.09397626 -0.066561\n",
      "  0.39997536 -0.08532929 -0.19552405  0.13977519 -0.18805435 -0.18775208\n",
      "  0.10661342 -0.26879166]\n",
      "Training Error:  9.953196260595249\n",
      "====================================================================================================\n",
      "Iteration:  320\n",
      "Previous theta :  [-0.01816698 -0.05250965  0.06725532  0.00197743  0.09397626 -0.066561\n",
      "  0.39997536 -0.08532929 -0.19552405  0.13977519 -0.18805435 -0.18775208\n",
      "  0.10661342 -0.26879166]\n",
      "New theta_0 : [-0.01815264 -0.0527467   0.06755447  0.00167259  0.09397915 -0.0673528\n",
      "  0.39942549 -0.08524757 -0.19657351  0.14026955 -0.18800673 -0.1879198\n",
      "  0.10649495 -0.26913801]\n",
      "Training Error:  9.950556414196297\n",
      "====================================================================================================\n",
      "Iteration:  321\n",
      "Previous theta :  [-0.01815264 -0.0527467   0.06755447  0.00167259  0.09397915 -0.0673528\n",
      "  0.39942549 -0.08524757 -0.19657351  0.14026955 -0.18800673 -0.1879198\n",
      "  0.10649495 -0.26913801]\n",
      "New theta_0 : [-0.01813844 -0.05298203  0.06785211  0.00137083  0.09398196 -0.06813937\n",
      "  0.39888027 -0.08516502 -0.19761457  0.14076056 -0.18796047 -0.18808598\n",
      "  0.10637744 -0.26948124]\n",
      "Training Error:  9.947955885072048\n",
      "====================================================================================================\n",
      "Iteration:  322\n",
      "Previous theta :  [-0.01813844 -0.05298203  0.06785211  0.00137083  0.09398196 -0.06813937\n",
      "  0.39888027 -0.08516502 -0.19761457  0.14076056 -0.18796047 -0.18808598\n",
      "  0.10637744 -0.26948124]\n",
      "New theta_0 : [-0.01812436 -0.05321565  0.06814823  0.00107213  0.09398469 -0.06892073\n",
      "  0.39833965 -0.08508167 -0.19864729  0.14124826 -0.18791554 -0.18825065\n",
      "  0.10626088 -0.26982139]\n",
      "Training Error:  9.945394074539925\n",
      "====================================================================================================\n",
      "Iteration:  323\n",
      "Previous theta :  [-0.01812436 -0.05321565  0.06814823  0.00107213  0.09398469 -0.06892073\n",
      "  0.39833965 -0.08508167 -0.19864729  0.14124826 -0.18791554 -0.18825065\n",
      "  0.10626088 -0.26982139]\n",
      "New theta_0 : [-0.01811041 -0.05344757  0.06844284  0.00077646  0.09398735 -0.06969692\n",
      "  0.39780359 -0.08499753 -0.19967175  0.14173268 -0.18787195 -0.18841381\n",
      "  0.10614525 -0.27015849]\n",
      "Training Error:  9.942870393213434\n",
      "====================================================================================================\n",
      "Iteration:  324\n",
      "Previous theta :  [-0.01811041 -0.05344757  0.06844284  0.00077646  0.09398735 -0.06969692\n",
      "  0.39780359 -0.08499753 -0.19967175  0.14173268 -0.18787195 -0.18841381\n",
      "  0.10614525 -0.27015849]\n",
      "New theta_0 : [-0.01809658 -0.0536778   0.06873594  0.0004838   0.09398992 -0.07046797\n",
      "  0.39727205 -0.08491264 -0.20068801  0.14221384 -0.18782967 -0.18857549\n",
      "  0.10603055 -0.27049257]\n",
      "Training Error:  9.940384260853593\n",
      "====================================================================================================\n",
      "Iteration:  325\n",
      "Previous theta :  [-0.01809658 -0.0536778   0.06873594  0.0004838   0.09398992 -0.07046797\n",
      "  0.39727205 -0.08491264 -0.20068801  0.14221384 -0.18782967 -0.18857549\n",
      "  0.10603055 -0.27049257]\n",
      "New theta_0 : [-1.80828835e-02 -5.39063499e-02  6.90275194e-02  1.94115033e-04\n",
      "  9.39924191e-02 -7.12339168e-02  3.96744973e-01 -8.48270189e-02\n",
      " -2.01696131e-01  1.42691775e-01 -1.87788694e-01 -1.88735710e-01\n",
      "  1.05916769e-01 -2.70823660e-01]\n",
      "Training Error:  9.937935106222874\n",
      "====================================================================================================\n",
      "Iteration:  326\n",
      "Previous theta :  [-1.80828835e-02 -5.39063499e-02  6.90275194e-02  1.94115033e-04\n",
      "  9.39924191e-02 -7.12339168e-02  3.96744973e-01 -8.48270189e-02\n",
      " -2.01696131e-01  1.42691775e-01 -1.87788694e-01 -1.88735710e-01\n",
      "  1.05916769e-01 -2.70823660e-01]\n",
      "New theta_0 : [-1.80693057e-02 -5.41332340e-02  6.93175871e-02 -9.26141850e-05\n",
      "  9.39948409e-02 -7.19947912e-02  3.96222330e-01 -8.47406923e-02\n",
      " -2.02696191e-01  1.43166505e-01 -1.87749004e-01 -1.88894476e-01\n",
      "  1.05803898e-01 -2.71151799e-01]\n",
      "Training Error:  9.935522366941598\n",
      "====================================================================================================\n",
      "Iteration:  327\n",
      "Previous theta :  [-1.80693057e-02 -5.41332340e-02  6.93175871e-02 -9.26141850e-05\n",
      "  9.39948409e-02 -7.19947912e-02  3.96222330e-01 -8.47406923e-02\n",
      " -2.02696191e-01  1.43166505e-01 -1.87749004e-01 -1.88894476e-01\n",
      "  1.05803898e-01 -2.71151799e-01]\n",
      "New theta_0 : [-1.80558493e-02 -5.43584626e-02  6.96061403e-02 -3.76413812e-04\n",
      "  9.39971873e-02 -7.27506260e-02  3.95704076e-01 -8.46536841e-02\n",
      " -2.03688251e-01  1.43638060e-01 -1.87710589e-01 -1.89051812e-01\n",
      "  1.05691928e-01 -2.71477016e-01]\n",
      "Training Error:  9.933145489346739\n",
      "====================================================================================================\n",
      "Iteration:  328\n",
      "Previous theta :  [-1.80558493e-02 -5.43584626e-02  6.96061403e-02 -3.76413812e-04\n",
      "  9.39971873e-02 -7.27506260e-02  3.95704076e-01 -8.46536841e-02\n",
      " -2.03688251e-01  1.43638060e-01 -1.87710589e-01 -1.89051812e-01\n",
      "  1.05691928e-01 -2.71477016e-01]\n",
      "New theta_0 : [-0.01804251 -0.05458205  0.06989318 -0.00065731  0.09399946 -0.07350145\n",
      "  0.39519017 -0.08456602 -0.20467238  0.14410647 -0.18767343 -0.18920773\n",
      "  0.10558085 -0.27179934]\n",
      "Training Error:  9.930803928353097\n",
      "====================================================================================================\n",
      "Iteration:  329\n",
      "Previous theta :  [-0.01804251 -0.05458205  0.06989318 -0.00065731  0.09399946 -0.07350145\n",
      "  0.39519017 -0.08456602 -0.20467238  0.14410647 -0.18767343 -0.18920773\n",
      "  0.10558085 -0.27179934]\n",
      "New theta_0 : [-0.0180293  -0.054804    0.07017871 -0.00093532  0.09400166 -0.07424731\n",
      "  0.39468057 -0.08447772 -0.20564863  0.14457175 -0.18763753 -0.18936225\n",
      "  0.10547066 -0.27211881]\n",
      "Training Error:  9.928497147316785\n",
      "====================================================================================================\n",
      "Iteration:  330\n",
      "Previous theta :  [-0.0180293  -0.054804    0.07017871 -0.00093532  0.09400166 -0.07424731\n",
      "  0.39468057 -0.08447772 -0.20564863  0.14457175 -0.18763753 -0.18936225\n",
      "  0.10547066 -0.27211881]\n",
      "New theta_0 : [-0.0180162  -0.05502433  0.07046272 -0.00121048  0.09400378 -0.07498822\n",
      "  0.39417524 -0.0843888  -0.20661708  0.14503394 -0.18760285 -0.18951539\n",
      "  0.10536134 -0.27243544]\n",
      "Training Error:  9.926224617901012\n",
      "====================================================================================================\n",
      "Iteration:  331\n",
      "Previous theta :  [-0.0180162  -0.05502433  0.07046272 -0.00121048  0.09400378 -0.07498822\n",
      "  0.39417524 -0.0843888  -0.20661708  0.14503394 -0.18760285 -0.18951539\n",
      "  0.10536134 -0.27243544]\n",
      "New theta_0 : [-0.01800321 -0.05524304  0.07074522 -0.00148281  0.09400583 -0.07572421\n",
      "  0.39367413 -0.0842993  -0.20757779  0.14549307 -0.1875694  -0.18966717\n",
      "  0.10525288 -0.27274927]\n",
      "Training Error:  9.92398581994409\n",
      "====================================================================================================\n",
      "Iteration:  332\n",
      "Previous theta :  [-0.01800321 -0.05524304  0.07074522 -0.00148281  0.09400583 -0.07572421\n",
      "  0.39367413 -0.0842993  -0.20757779  0.14549307 -0.1875694  -0.18966717\n",
      "  0.10525288 -0.27274927]\n",
      "New theta_0 : [-0.01799034 -0.05546016  0.07102621 -0.00175233  0.09400782 -0.07645533\n",
      "  0.39317722 -0.08420923 -0.20853081  0.14594914 -0.18753716 -0.18981759\n",
      "  0.10514529 -0.27306033]\n",
      "Training Error:  9.921780241329639\n",
      "====================================================================================================\n",
      "Iteration:  333\n",
      "Previous theta :  [-0.01799034 -0.05546016  0.07102621 -0.00175233  0.09400782 -0.07645533\n",
      "  0.39317722 -0.08420923 -0.20853081  0.14594914 -0.18753716 -0.18981759\n",
      "  0.10514529 -0.27306033]\n",
      "New theta_0 : [-0.01797759 -0.05567569  0.07130569 -0.00201907  0.09400973 -0.0771816\n",
      "  0.39268445 -0.08411862 -0.20947622  0.1464022  -0.18750611 -0.18996668\n",
      "  0.10503854 -0.27336865]\n",
      "Training Error:  9.919607377858965\n",
      "====================================================================================================\n",
      "Iteration:  334\n",
      "Previous theta :  [-0.01797759 -0.05567569  0.07130569 -0.00201907  0.09400973 -0.0771816\n",
      "  0.39268445 -0.08411862 -0.20947622  0.1464022  -0.18750611 -0.18996668\n",
      "  0.10503854 -0.27336865]\n",
      "New theta_0 : [-0.01796495 -0.05588964  0.07158366 -0.00228305  0.09401157 -0.07790306\n",
      "  0.39219579 -0.08402747 -0.21041408  0.14685227 -0.18747625 -0.19011445\n",
      "  0.10493264 -0.27367425]\n",
      "Training Error:  9.917466733125538\n",
      "====================================================================================================\n",
      "Iteration:  335\n",
      "Previous theta :  [-0.01796495 -0.05588964  0.07158366 -0.00228305  0.09401157 -0.07790306\n",
      "  0.39219579 -0.08402747 -0.21041408  0.14685227 -0.18747625 -0.19011445\n",
      "  0.10493264 -0.27367425]\n",
      "New theta_0 : [-0.01795242 -0.05610202  0.07186013 -0.00254429  0.09401334 -0.07861973\n",
      "  0.3917112  -0.08393583 -0.21134444  0.14729937 -0.18744755 -0.19026092\n",
      "  0.10482757 -0.27397717]\n",
      "Training Error:  9.915357818391564\n",
      "====================================================================================================\n",
      "Iteration:  336\n",
      "Previous theta :  [-0.01795242 -0.05610202  0.07186013 -0.00254429  0.09401334 -0.07861973\n",
      "  0.3917112  -0.08393583 -0.21134444  0.14729937 -0.18744755 -0.19026092\n",
      "  0.10482757 -0.27397717]\n",
      "New theta_0 : [-0.01793999 -0.05631284  0.07213509 -0.00280282  0.09401504 -0.07933164\n",
      "  0.39123065 -0.08384369 -0.21226737  0.14774353 -0.18742002 -0.1904061\n",
      "  0.10472333 -0.27427743]\n",
      "Training Error:  9.913280152466593\n",
      "====================================================================================================\n",
      "Iteration:  337\n",
      "Previous theta :  [-0.01793999 -0.05631284  0.07213509 -0.00280282  0.09401504 -0.07933164\n",
      "  0.39123065 -0.08384369 -0.21226737  0.14774353 -0.18742002 -0.1904061\n",
      "  0.10472333 -0.27427743]\n",
      "New theta_0 : [-0.01792768 -0.05652212  0.07240854 -0.00305867  0.09401668 -0.08003883\n",
      "  0.39075409 -0.0837511  -0.21318292  0.14818477 -0.18739363 -0.19055\n",
      "  0.1046199  -0.27457506]\n",
      "Training Error:  9.911233261588137\n",
      "====================================================================================================\n",
      "Iteration:  338\n",
      "Previous theta :  [-0.01792768 -0.05652212  0.07240854 -0.00305867  0.09401668 -0.08003883\n",
      "  0.39075409 -0.0837511  -0.21318292  0.14818477 -0.18739363 -0.19055\n",
      "  0.1046199  -0.27457506]\n",
      "New theta_0 : [-0.01791548 -0.05672986  0.0726805  -0.00331184  0.09401825 -0.08074132\n",
      "  0.3902815  -0.08365805 -0.21409116  0.14862312 -0.18736837 -0.19069265\n",
      "  0.10451729 -0.27487009]\n",
      "Training Error:  9.909216679304265\n",
      "====================================================================================================\n",
      "Iteration:  339\n",
      "Previous theta :  [-0.01791548 -0.05672986  0.0726805  -0.00331184  0.09401825 -0.08074132\n",
      "  0.3902815  -0.08365805 -0.21409116  0.14862312 -0.18736837 -0.19069265\n",
      "  0.10451729 -0.27487009]\n",
      "New theta_0 : [-0.01790338 -0.05693607  0.07295096 -0.00356238  0.09401975 -0.08143915\n",
      "  0.38981283 -0.08356458 -0.21499215  0.1490586  -0.18734424 -0.19083405\n",
      "  0.10441548 -0.27516255]\n",
      "Training Error:  9.907229946358113\n",
      "====================================================================================================\n",
      "Iteration:  340\n",
      "Previous theta :  [-0.01790338 -0.05693607  0.07295096 -0.00356238  0.09401975 -0.08143915\n",
      "  0.38981283 -0.08356458 -0.21499215  0.1490586  -0.18734424 -0.19083405\n",
      "  0.10441548 -0.27516255]\n",
      "New theta_0 : [-0.01789139 -0.05714077  0.07321992 -0.00381029  0.09402118 -0.08213235\n",
      "  0.38934804 -0.08347071 -0.21588595  0.14949123 -0.18732121 -0.19097422\n",
      "  0.10431446 -0.27545245]\n",
      "Training Error:  9.905272610574322\n",
      "====================================================================================================\n",
      "Iteration:  341\n",
      "Previous theta :  [-0.01789139 -0.05714077  0.07321992 -0.00381029  0.09402118 -0.08213235\n",
      "  0.38934804 -0.08347071 -0.21588595  0.14949123 -0.18732121 -0.19097422\n",
      "  0.10431446 -0.27545245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.0178795  -0.05734397  0.07348739 -0.00405561  0.09402256 -0.08282094\n",
      "  0.38888711 -0.08337644 -0.21677261  0.14992104 -0.18729929 -0.19111317\n",
      "  0.10421424 -0.27573983]\n",
      "Training Error:  9.903344226747324\n",
      "====================================================================================================\n",
      "Iteration:  342\n",
      "Previous theta :  [-0.0178795  -0.05734397  0.07348739 -0.00405561  0.09402256 -0.08282094\n",
      "  0.38888711 -0.08337644 -0.21677261  0.14992104 -0.18729929 -0.19111317\n",
      "  0.10421424 -0.27573983]\n",
      "New theta_0 : [-0.01786772 -0.05754567  0.07375337 -0.00429835  0.09402387 -0.08350497\n",
      "  0.38842999 -0.0832818  -0.21765219  0.15034806 -0.18727845 -0.19125092\n",
      "  0.10411479 -0.27602472]\n",
      "Training Error:  9.901444356531462\n",
      "====================================================================================================\n",
      "Iteration:  343\n",
      "Previous theta :  [-0.01786772 -0.05754567  0.07375337 -0.00429835  0.09402387 -0.08350497\n",
      "  0.38842999 -0.0832818  -0.21765219  0.15034806 -0.18727845 -0.19125092\n",
      "  0.10411479 -0.27602472]\n",
      "New theta_0 : [-0.01785604 -0.05774589  0.07401786 -0.00453854  0.09402511 -0.08418444\n",
      "  0.38797665 -0.0831868  -0.21852475  0.15077229 -0.18725868 -0.19138748\n",
      "  0.10401612 -0.27630713]\n",
      "Training Error:  9.899572568332943\n",
      "====================================================================================================\n",
      "Iteration:  344\n",
      "Previous theta :  [-0.01785604 -0.05774589  0.07401786 -0.00453854  0.09402511 -0.08418444\n",
      "  0.38797665 -0.0831868  -0.21852475  0.15077229 -0.18725868 -0.19138748\n",
      "  0.10401612 -0.27630713]\n",
      "New theta_0 : [-0.01784446 -0.05794463  0.07428086 -0.0047762   0.09402629 -0.0848594\n",
      "  0.38752706 -0.08309147 -0.21939035  0.15119378 -0.18723998 -0.19152287\n",
      "  0.10391822 -0.2765871 ]\n",
      "Training Error:  9.897728437203495\n",
      "====================================================================================================\n",
      "Iteration:  345\n",
      "Previous theta :  [-0.01784446 -0.05794463  0.07428086 -0.0047762   0.09402629 -0.0848594\n",
      "  0.38752706 -0.08309147 -0.21939035  0.15119378 -0.18723998 -0.19152287\n",
      "  0.10391822 -0.2765871 ]\n",
      "New theta_0 : [-0.01783298 -0.05814191  0.07454238 -0.00501135  0.09402741 -0.08552988\n",
      "  0.38708118 -0.08299581 -0.22024904  0.15161254 -0.18722233 -0.19165709\n",
      "  0.10382107 -0.27686465]\n",
      "Training Error:  9.895911544735855\n",
      "====================================================================================================\n",
      "Iteration:  346\n",
      "Previous theta :  [-0.01783298 -0.05814191  0.07454238 -0.00501135  0.09402741 -0.08552988\n",
      "  0.38708118 -0.08299581 -0.22024904  0.15161254 -0.18722233 -0.19165709\n",
      "  0.10382107 -0.27686465]\n",
      "New theta_0 : [-0.0178216  -0.05833774  0.07480242 -0.00524401  0.09402847 -0.0861959\n",
      "  0.38663897 -0.08289985 -0.22110088  0.15202859 -0.18720572 -0.19179016\n",
      "  0.10372468 -0.27713981]\n",
      "Training Error:  9.894121478960864\n",
      "====================================================================================================\n",
      "Iteration:  347\n",
      "Previous theta :  [-0.0178216  -0.05833774  0.07480242 -0.00524401  0.09402847 -0.0861959\n",
      "  0.38663897 -0.08289985 -0.22110088  0.15202859 -0.18720572 -0.19179016\n",
      "  0.10372468 -0.27713981]\n",
      "New theta_0 : [-0.01781032 -0.05853213  0.07506099 -0.00547421  0.09402947 -0.08685749\n",
      "  0.38620042 -0.0828036  -0.22194592  0.15244196 -0.18719014 -0.1919221\n",
      "  0.10362904 -0.27741259]\n",
      "Training Error:  9.892357834246326\n",
      "====================================================================================================\n",
      "Iteration:  348\n",
      "Previous theta :  [-0.01781032 -0.05853213  0.07506099 -0.00547421  0.09402947 -0.08685749\n",
      "  0.38620042 -0.0828036  -0.22194592  0.15244196 -0.18719014 -0.1919221\n",
      "  0.10362904 -0.27741259]\n",
      "New theta_0 : [-0.01779913 -0.05872508  0.07531809 -0.00570197  0.09403041 -0.08751468\n",
      "  0.38576547 -0.08270708 -0.22278422  0.15285266 -0.18717558 -0.19205291\n",
      "  0.10353413 -0.27768303]\n",
      "Training Error:  9.89062021119747\n",
      "====================================================================================================\n",
      "Iteration:  349\n",
      "Previous theta :  [-0.01779913 -0.05872508  0.07531809 -0.00570197  0.09403041 -0.08751468\n",
      "  0.38576547 -0.08270708 -0.22278422  0.15285266 -0.18717558 -0.19205291\n",
      "  0.10353413 -0.27768303]\n",
      "New theta_0 : [-0.01778804 -0.05891661  0.07557371 -0.0059273   0.09403129 -0.0881675\n",
      "  0.3853341  -0.0826103  -0.22361584  0.15326073 -0.18716202 -0.19218261\n",
      "  0.10343996 -0.27795114]\n",
      "Training Error:  9.888908216559035\n",
      "====================================================================================================\n",
      "Iteration:  350\n",
      "Previous theta :  [-0.01778804 -0.05891661  0.07557371 -0.0059273   0.09403129 -0.0881675\n",
      "  0.3853341  -0.0826103  -0.22361584  0.15326073 -0.18716202 -0.19218261\n",
      "  0.10343996 -0.27795114]\n",
      "New theta_0 : [-0.01777705 -0.05910673  0.07582787 -0.00615023  0.09403211 -0.08881598\n",
      "  0.38490627 -0.08251328 -0.22444082  0.15366618 -0.18714947 -0.19231121\n",
      "  0.10334652 -0.27821695]\n",
      "Training Error:  9.887221463118973\n",
      "====================================================================================================\n",
      "Iteration:  351\n",
      "Previous theta :  [-0.01777705 -0.05910673  0.07582787 -0.00615023  0.09403211 -0.08881598\n",
      "  0.38490627 -0.08251328 -0.22444082  0.15366618 -0.18714947 -0.19231121\n",
      "  0.10334652 -0.27821695]\n",
      "New theta_0 : [-0.01776615 -0.05929544  0.07608057 -0.00637078  0.09403288 -0.08946015\n",
      "  0.38448196 -0.08241604 -0.22525923  0.15406903 -0.1871379  -0.19243872\n",
      "  0.1032538  -0.27848049]\n",
      "Training Error:  9.885559569613681\n",
      "====================================================================================================\n",
      "Iteration:  352\n",
      "Previous theta :  [-0.01776615 -0.05929544  0.07608057 -0.00637078  0.09403288 -0.08946015\n",
      "  0.38448196 -0.08241604 -0.22525923  0.15406903 -0.1871379  -0.19243872\n",
      "  0.1032538  -0.27848049]\n",
      "New theta_0 : [-0.01775534 -0.05948276  0.07633181 -0.00658897  0.09403358 -0.09010003\n",
      "  0.38406113 -0.08231857 -0.22607111  0.15446931 -0.1871273  -0.19256516\n",
      "  0.10316179 -0.27874178]\n",
      "Training Error:  9.883922160634796\n",
      "====================================================================================================\n",
      "Iteration:  353\n",
      "Previous theta :  [-0.01775534 -0.05948276  0.07633181 -0.00658897  0.09403358 -0.09010003\n",
      "  0.38406113 -0.08231857 -0.22607111  0.15446931 -0.1871273  -0.19256516\n",
      "  0.10316179 -0.27874178]\n",
      "New theta_0 : [-0.01774463 -0.0596687   0.0765816  -0.00680482  0.09403424 -0.09073565\n",
      "  0.38364374 -0.08222091 -0.22687651  0.15486703 -0.18711767 -0.19269054\n",
      "  0.10307048 -0.27900083]\n",
      "Training Error:  9.882308866537496\n",
      "====================================================================================================\n",
      "Iteration:  354\n",
      "Previous theta :  [-0.01774463 -0.0596687   0.0765816  -0.00680482  0.09403424 -0.09073565\n",
      "  0.38364374 -0.08222091 -0.22687651  0.15486703 -0.18711767 -0.19269054\n",
      "  0.10307048 -0.27900083]\n",
      "New theta_0 : [-0.017734   -0.05985326  0.07682994 -0.00701836  0.09403483 -0.09136704\n",
      "  0.38322978 -0.08212307 -0.2276755   0.15526222 -0.18710899 -0.19281487\n",
      "  0.10297988 -0.27925767]\n",
      "Training Error:  9.88071932335028\n",
      "====================================================================================================\n",
      "Iteration:  355\n",
      "Previous theta :  [-0.017734   -0.05985326  0.07682994 -0.00701836  0.09403483 -0.09136704\n",
      "  0.38322978 -0.08212307 -0.2276755   0.15526222 -0.18710899 -0.19281487\n",
      "  0.10297988 -0.27925767]\n",
      "New theta_0 : [-0.01772347 -0.06003646  0.07707684 -0.00722959  0.09403537 -0.09199423\n",
      "  0.3828192  -0.08202505 -0.22846812  0.1556549  -0.18710126 -0.19293815\n",
      "  0.10288998 -0.27951233]\n",
      "Training Error:  9.879153172686198\n",
      "====================================================================================================\n",
      "Iteration:  356\n",
      "Previous theta :  [-0.01772347 -0.06003646  0.07707684 -0.00722959  0.09403537 -0.09199423\n",
      "  0.3828192  -0.08202505 -0.22846812  0.1556549  -0.18710126 -0.19293815\n",
      "  0.10288998 -0.27951233]\n",
      "New theta_0 : [-0.01771303 -0.06021831  0.07732229 -0.00743855  0.09403585 -0.09261724\n",
      "  0.38241198 -0.08192688 -0.22925442  0.15604509 -0.18709446 -0.19306041\n",
      "  0.10280077 -0.27976483]\n",
      "Training Error:  9.877610061655556\n",
      "====================================================================================================\n",
      "Iteration:  357\n",
      "Previous theta :  [-0.01771303 -0.06021831  0.07732229 -0.00743855  0.09403585 -0.09261724\n",
      "  0.38241198 -0.08192688 -0.22925442  0.15604509 -0.18709446 -0.19306041\n",
      "  0.10280077 -0.27976483]\n",
      "New theta_0 : [-0.01770268 -0.06039881  0.07756631 -0.00764525  0.09403628 -0.0932361\n",
      "  0.38200808 -0.08182855 -0.23003445  0.1564328  -0.18708859 -0.19318165\n",
      "  0.10271223 -0.28001518]\n",
      "Training Error:  9.876089642779966\n",
      "====================================================================================================\n",
      "Iteration:  358\n",
      "Previous theta :  [-0.01770268 -0.06039881  0.07756631 -0.00764525  0.09403628 -0.0932361\n",
      "  0.38200808 -0.08182855 -0.23003445  0.1564328  -0.18708859 -0.19318165\n",
      "  0.10271223 -0.28001518]\n",
      "New theta_0 : [-0.01769241 -0.06057798  0.07780889 -0.00784972  0.09403666 -0.09385084\n",
      "  0.38160748 -0.0817301  -0.23080827  0.15681807 -0.18708362 -0.19330188\n",
      "  0.10262438 -0.28026341]\n",
      "Training Error:  9.87459157390784\n",
      "====================================================================================================\n",
      "Iteration:  359\n",
      "Previous theta :  [-0.01769241 -0.06057798  0.07780889 -0.00784972  0.09403666 -0.09385084\n",
      "  0.38160748 -0.0817301  -0.23080827  0.15681807 -0.18708362 -0.19330188\n",
      "  0.10262438 -0.28026341]\n",
      "New theta_0 : [-0.01768223 -0.06075582  0.07805005 -0.00805196  0.09403699 -0.09446149\n",
      "  0.38121015 -0.08163153 -0.23157593  0.1572009  -0.18707957 -0.19342112\n",
      "  0.1025372  -0.28050954]\n",
      "Training Error:  9.873115518131208\n",
      "====================================================================================================\n",
      "Iteration:  360\n",
      "Previous theta :  [-0.01768223 -0.06075582  0.07805005 -0.00805196  0.09403699 -0.09446149\n",
      "  0.38121015 -0.08163153 -0.23157593  0.1572009  -0.18707957 -0.19342112\n",
      "  0.1025372  -0.28050954]\n",
      "New theta_0 : [-0.01767214 -0.06093235  0.07828978 -0.00825201  0.09403726 -0.09506807\n",
      "  0.38081605 -0.08153285 -0.23233746  0.15758132 -0.1870764  -0.19353938\n",
      "  0.10245068 -0.28075359]\n",
      "Training Error:  9.871661143703902\n",
      "====================================================================================================\n",
      "Iteration:  361\n",
      "Previous theta :  [-0.01767214 -0.06093235  0.07828978 -0.00825201  0.09403726 -0.09506807\n",
      "  0.38081605 -0.08153285 -0.23233746  0.15758132 -0.1870764  -0.19353938\n",
      "  0.10245068 -0.28075359]\n",
      "New theta_0 : [-0.01766213 -0.06110756  0.07852809 -0.00844987  0.09403748 -0.0956706\n",
      "  0.38042516 -0.08143407 -0.23309294  0.15795936 -0.18707413 -0.19365666\n",
      "  0.10236483 -0.28099559]\n",
      "Training Error:  9.87022812396103\n",
      "====================================================================================================\n",
      "Iteration:  362\n",
      "Previous theta :  [-0.01766213 -0.06110756  0.07852809 -0.00844987  0.09403748 -0.0956706\n",
      "  0.38042516 -0.08143407 -0.23309294  0.15795936 -0.18707413 -0.19365666\n",
      "  0.10236483 -0.28099559]\n",
      "New theta_0 : [-0.01765221 -0.06128148  0.07876499 -0.00864558  0.09403765 -0.09626912\n",
      "  0.38003745 -0.08133521 -0.23384239  0.15833501 -0.18707272 -0.19377298\n",
      "  0.10227962 -0.28123554]\n",
      "Training Error:  9.868816137239763\n",
      "====================================================================================================\n",
      "Iteration:  363\n",
      "Previous theta :  [-0.01765221 -0.06128148  0.07876499 -0.00864558  0.09403765 -0.09626912\n",
      "  0.38003745 -0.08133521 -0.23384239  0.15833501 -0.18707272 -0.19377298\n",
      "  0.10227962 -0.28123554]\n",
      "New theta_0 : [-0.01764237 -0.06145412  0.07900048 -0.00883915  0.09403777 -0.09686365\n",
      "  0.37965289 -0.08123627 -0.23458588  0.15870832 -0.18707218 -0.19388834\n",
      "  0.10219507 -0.28147348]\n",
      "Training Error:  9.867424866801372\n",
      "====================================================================================================\n",
      "Iteration:  364\n",
      "Previous theta :  [-0.01764237 -0.06145412  0.07900048 -0.00883915  0.09403777 -0.09686365\n",
      "  0.37965289 -0.08123627 -0.23458588  0.15870832 -0.18707218 -0.19388834\n",
      "  0.10219507 -0.28147348]\n",
      "New theta_0 : [-0.01763261 -0.06162547  0.07923457 -0.00903059  0.09403784 -0.09745422\n",
      "  0.37927145 -0.08113728 -0.23532344  0.1590793  -0.1870725  -0.19400277\n",
      "  0.10211116 -0.28170942]\n",
      "Training Error:  9.866054000754543\n",
      "====================================================================================================\n",
      "Iteration:  365\n",
      "Previous theta :  [-0.01763261 -0.06162547  0.07923457 -0.00903059  0.09403784 -0.09745422\n",
      "  0.37927145 -0.08113728 -0.23532344  0.1590793  -0.1870725  -0.19400277\n",
      "  0.10211116 -0.28170942]\n",
      "New theta_0 : [-0.01762293 -0.06179556  0.07946726 -0.00921994  0.09403786 -0.09804085\n",
      "  0.37889311 -0.08103823 -0.23605514  0.15944795 -0.18707366 -0.19411626\n",
      "  0.10202789 -0.28194338]\n",
      "Training Error:  9.864703231979906\n",
      "====================================================================================================\n",
      "Iteration:  366\n",
      "Previous theta :  [-0.01762293 -0.06179556  0.07946726 -0.00921994  0.09403786 -0.09804085\n",
      "  0.37889311 -0.08103823 -0.23605514  0.15944795 -0.18707366 -0.19411626\n",
      "  0.10202789 -0.28194338]\n",
      "New theta_0 : [-0.01761334 -0.06196438  0.07969855 -0.0094072   0.09403783 -0.09862357\n",
      "  0.37851783 -0.08093914 -0.236781    0.15981432 -0.18707566 -0.19422882\n",
      "  0.10194526 -0.28217539]\n",
      "Training Error:  9.863372258055756\n",
      "====================================================================================================\n",
      "Iteration:  367\n",
      "Previous theta :  [-0.01761334 -0.06196438  0.07969855 -0.0094072   0.09403783 -0.09862357\n",
      "  0.37851783 -0.08093914 -0.236781    0.15981432 -0.18707566 -0.19422882\n",
      "  0.10194526 -0.28217539]\n",
      "New theta_0 : [-0.01760383 -0.06213195  0.07992845 -0.00959239  0.09403775 -0.0992024\n",
      "  0.37814559 -0.08084003 -0.23750109  0.1601784  -0.18707849 -0.19434048\n",
      "  0.10186325 -0.28240545]\n",
      "Training Error:  9.86206078118499\n",
      "====================================================================================================\n",
      "Iteration:  368\n",
      "Previous theta :  [-0.01760383 -0.06213195  0.07992845 -0.00959239  0.09403775 -0.0992024\n",
      "  0.37814559 -0.08084003 -0.23750109  0.1601784  -0.18707849 -0.19434048\n",
      "  0.10186325 -0.28240545]\n",
      "New theta_0 : [-0.01759439 -0.06229828  0.08015697 -0.00977554  0.09403763 -0.09977737\n",
      "  0.37777636 -0.08074089 -0.23821545  0.16054023 -0.18708214 -0.19445123\n",
      "  0.10178186 -0.28263359]\n",
      "Training Error:  9.86076850812319\n",
      "====================================================================================================\n",
      "Iteration:  369\n",
      "Previous theta :  [-0.01759439 -0.06229828  0.08015697 -0.00977554  0.09403763 -0.09977737\n",
      "  0.37777636 -0.08074089 -0.23821545  0.16054023 -0.18708214 -0.19445123\n",
      "  0.10178186 -0.28263359]\n",
      "New theta_0 : [-0.01758504 -0.06246338  0.08038411 -0.00995665  0.09403745 -0.1003485\n",
      "  0.37741012 -0.08064175 -0.23892412  0.16089982 -0.18708659 -0.19456109\n",
      "  0.10170109 -0.28285983]\n",
      "Training Error:  9.85949515010787\n",
      "====================================================================================================\n",
      "Iteration:  370\n",
      "Previous theta :  [-0.01758504 -0.06246338  0.08038411 -0.00995665  0.09403745 -0.1003485\n",
      "  0.37741012 -0.08064175 -0.23892412  0.16089982 -0.18708659 -0.19456109\n",
      "  0.10170109 -0.28285983]\n",
      "New theta_0 : [-0.01757576 -0.06262725  0.08060988 -0.01013576  0.09403724 -0.10091582\n",
      "  0.37704683 -0.0805426  -0.23962715  0.16125718 -0.18709185 -0.19467007\n",
      "  0.10162093 -0.28308419]\n",
      "Training Error:  9.858240422788846\n",
      "====================================================================================================\n",
      "Iteration:  371\n",
      "Previous theta :  [-0.01757576 -0.06262725  0.08060988 -0.01013576  0.09403724 -0.10091582\n",
      "  0.37704683 -0.0805426  -0.23962715  0.16125718 -0.18709185 -0.19467007\n",
      "  0.10162093 -0.28308419]\n",
      "New theta_0 : [-0.01756656 -0.0627899   0.08083428 -0.01031287  0.09403697 -0.10147936\n",
      "  0.37668648 -0.08044347 -0.24032458  0.16161234 -0.1870979  -0.19477817\n",
      "  0.10154138 -0.28330668]\n",
      "Training Error:  9.857004046159702\n",
      "====================================================================================================\n",
      "Iteration:  372\n",
      "Previous theta :  [-0.01756656 -0.0627899   0.08083428 -0.01031287  0.09403697 -0.10147936\n",
      "  0.37668648 -0.08044347 -0.24032458  0.16161234 -0.1870979  -0.19477817\n",
      "  0.10154138 -0.28330668]\n",
      "New theta_0 : [-0.01755743 -0.06295135  0.08105731 -0.01048801  0.09403666 -0.10203913\n",
      "  0.37632903 -0.08034435 -0.24101646  0.16196531 -0.18710474 -0.19488541\n",
      "  0.10146243 -0.28352733]\n",
      "Training Error:  9.855785744490362\n",
      "====================================================================================================\n",
      "Iteration:  373\n",
      "Previous theta :  [-0.01755743 -0.06295135  0.08105731 -0.01048801  0.09403666 -0.10203913\n",
      "  0.37632903 -0.08034435 -0.24101646  0.16196531 -0.18710474 -0.19488541\n",
      "  0.10146243 -0.28352733]\n",
      "New theta_0 : [-0.01754839 -0.0631116   0.08127899 -0.01066119  0.09403631 -0.10259517\n",
      "  0.37597446 -0.08024526 -0.24170284  0.16231611 -0.18711234 -0.19499179\n",
      "  0.10138408 -0.28374614]\n",
      "Training Error:  9.854585246260744\n",
      "====================================================================================================\n",
      "Iteration:  374\n",
      "Previous theta :  [-0.01754839 -0.0631116   0.08127899 -0.01066119  0.09403631 -0.10259517\n",
      "  0.37597446 -0.08024526 -0.24170284  0.16231611 -0.18711234 -0.19499179\n",
      "  0.10138408 -0.28374614]\n",
      "New theta_0 : [-0.01753941 -0.06327066  0.08149931 -0.01083244  0.09403591 -0.1031475\n",
      "  0.37562275 -0.08014621 -0.24238376  0.16266476 -0.18712072 -0.19509732\n",
      "  0.10130632 -0.28396315]\n",
      "Training Error:  9.853402284095445\n",
      "====================================================================================================\n",
      "Iteration:  375\n",
      "Previous theta :  [-0.01753941 -0.06327066  0.08149931 -0.01083244  0.09403591 -0.1031475\n",
      "  0.37562275 -0.08014621 -0.24238376  0.16266476 -0.18712072 -0.19509732\n",
      "  0.10130632 -0.28396315]\n",
      "New theta_0 : [-0.01753052 -0.06342853  0.08171829 -0.01100176  0.09403547 -0.10369613\n",
      "  0.37527386 -0.08004721 -0.24305926  0.16301128 -0.18712985 -0.19520201\n",
      "  0.10122914 -0.28417836]\n",
      "Training Error:  9.852236594699482\n",
      "====================================================================================================\n",
      "Iteration:  376\n",
      "Previous theta :  [-0.01753052 -0.06342853  0.08171829 -0.01100176  0.09403547 -0.10369613\n",
      "  0.37527386 -0.08004721 -0.24305926  0.16301128 -0.18712985 -0.19520201\n",
      "  0.10122914 -0.28417836]\n",
      "New theta_0 : [-0.01752169 -0.06358524  0.08193592 -0.01116917  0.09403498 -0.10424111\n",
      "  0.37492779 -0.07994826 -0.24372939  0.16335568 -0.18713973 -0.19530588\n",
      "  0.10115255 -0.28439179]\n",
      "Training Error:  9.851087918795038\n",
      "====================================================================================================\n",
      "Iteration:  377\n",
      "Previous theta :  [-0.01752169 -0.06358524  0.08193592 -0.01116917  0.09403498 -0.10424111\n",
      "  0.37492779 -0.07994826 -0.24372939  0.16335568 -0.18713973 -0.19530588\n",
      "  0.10115255 -0.28439179]\n",
      "New theta_0 : [-0.01751294 -0.06374078  0.08215222 -0.0113347   0.09403445 -0.10478244\n",
      "  0.37458448 -0.07984937 -0.24439418  0.16369797 -0.18715035 -0.19540892\n",
      "  0.10107654 -0.28460347]\n",
      "Training Error:  9.849956001059235\n",
      "====================================================================================================\n",
      "Iteration:  378\n",
      "Previous theta :  [-0.01751294 -0.06374078  0.08215222 -0.0113347   0.09403445 -0.10478244\n",
      "  0.37458448 -0.07984937 -0.24439418  0.16369797 -0.18715035 -0.19540892\n",
      "  0.10107654 -0.28460347]\n",
      "New theta_0 : [-0.01750426 -0.06389516  0.08236719 -0.01149835  0.09403388 -0.10532016\n",
      "  0.37424394 -0.07975055 -0.24505369  0.16403818 -0.18716171 -0.19551115\n",
      "  0.1010011  -0.2848134 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.848840590062869\n",
      "====================================================================================================\n",
      "Iteration:  379\n",
      "Previous theta :  [-0.01750426 -0.06389516  0.08236719 -0.01149835  0.09403388 -0.10532016\n",
      "  0.37424394 -0.07975055 -0.24505369  0.16403818 -0.18716171 -0.19551115\n",
      "  0.1010011  -0.2848134 ]\n",
      "New theta_0 : [-0.01749565 -0.0640484   0.08258084 -0.01166016  0.09403326 -0.10585428\n",
      "  0.37390612 -0.07965181 -0.24570796  0.16437633 -0.18717379 -0.19561258\n",
      "  0.10092623 -0.2850216 ]\n",
      "Training Error:  9.847741438210129\n",
      "====================================================================================================\n",
      "Iteration:  380\n",
      "Previous theta :  [-0.01749565 -0.0640484   0.08258084 -0.01166016  0.09403326 -0.10585428\n",
      "  0.37390612 -0.07965181 -0.24570796  0.16437633 -0.18717379 -0.19561258\n",
      "  0.10092623 -0.2850216 ]\n",
      "New theta_0 : [-0.01748712 -0.0642005   0.08279316 -0.01182012  0.09403261 -0.10638484\n",
      "  0.37357102 -0.07955316 -0.24635702  0.16471242 -0.18718658 -0.19571321\n",
      "  0.10085192 -0.2852281 ]\n",
      "Training Error:  9.846658301679266\n",
      "====================================================================================================\n",
      "Iteration:  381\n",
      "Previous theta :  [-0.01748712 -0.0642005   0.08279316 -0.01182012  0.09403261 -0.10638484\n",
      "  0.37357102 -0.07955316 -0.24635702  0.16471242 -0.18718658 -0.19571321\n",
      "  0.10085192 -0.2852281 ]\n",
      "New theta_0 : [-0.01747865 -0.06435147  0.08300417 -0.01197827  0.09403191 -0.10691185\n",
      "  0.37323859 -0.0794546  -0.24700092  0.16504648 -0.18720009 -0.19581305\n",
      "  0.10077817 -0.2854329 ]\n",
      "Training Error:  9.845590940364204\n",
      "====================================================================================================\n",
      "Iteration:  382\n",
      "Previous theta :  [-0.01747865 -0.06435147  0.08300417 -0.01197827  0.09403191 -0.10691185\n",
      "  0.37323859 -0.0794546  -0.24700092  0.16504648 -0.18720009 -0.19581305\n",
      "  0.10077817 -0.2854329 ]\n",
      "New theta_0 : [-0.01747026 -0.06450132  0.08321388 -0.01213461  0.09403118 -0.10743534\n",
      "  0.37290882 -0.07935615 -0.24763969  0.16537852 -0.18721429 -0.19591211\n",
      "  0.10070497 -0.28563603]\n",
      "Training Error:  9.844539117817066\n",
      "====================================================================================================\n",
      "Iteration:  383\n",
      "Previous theta :  [-0.01747026 -0.06450132  0.08321388 -0.01213461  0.09403118 -0.10743534\n",
      "  0.37290882 -0.07935615 -0.24763969  0.16537852 -0.18721429 -0.19591211\n",
      "  0.10070497 -0.28563603]\n",
      "New theta_0 : [-0.01746193 -0.06465005  0.08342228 -0.01228916  0.0940304  -0.10795532\n",
      "  0.37258169 -0.0792578  -0.24827339  0.16570856 -0.18722919 -0.19601041\n",
      "  0.10063232 -0.2858375 ]\n",
      "Training Error:  9.843502601191632\n",
      "====================================================================================================\n",
      "Iteration:  384\n",
      "Previous theta :  [-0.01746193 -0.06465005  0.08342228 -0.01228916  0.0940304  -0.10795532\n",
      "  0.37258169 -0.0792578  -0.24827339  0.16570856 -0.18722919 -0.19601041\n",
      "  0.10063232 -0.2858375 ]\n",
      "New theta_0 : [-0.01745367 -0.06479767  0.08362939 -0.01244194  0.09402958 -0.10847184\n",
      "  0.37225717 -0.07915957 -0.24890206  0.16603661 -0.18724477 -0.19610793\n",
      "  0.10056022 -0.28603732]\n",
      "Training Error:  9.842481161187644\n",
      "====================================================================================================\n",
      "Iteration:  385\n",
      "Previous theta :  [-0.01745367 -0.06479767  0.08362939 -0.01244194  0.09402958 -0.10847184\n",
      "  0.37225717 -0.07915957 -0.24890206  0.16603661 -0.18724477 -0.19610793\n",
      "  0.10056022 -0.28603732]\n",
      "New theta_0 : [-0.01744548 -0.0649442   0.0838352  -0.01259297  0.09402873 -0.10898489\n",
      "  0.37193525 -0.07906146 -0.24952572  0.1663627  -0.18726103 -0.1962047\n",
      "  0.10048866 -0.28623551]\n",
      "Training Error:  9.841474571996043\n",
      "====================================================================================================\n",
      "Iteration:  386\n",
      "Previous theta :  [-0.01744548 -0.0649442   0.0838352  -0.01259297  0.09402873 -0.10898489\n",
      "  0.37193525 -0.07906146 -0.24952572  0.1663627  -0.18726103 -0.1962047\n",
      "  0.10048866 -0.28623551]\n",
      "New theta_0 : [-0.01743735 -0.06508964  0.08403973 -0.01274226  0.09402784 -0.10949452\n",
      "  0.37161588 -0.07896348 -0.25014443  0.16668682 -0.18727796 -0.19630073\n",
      "  0.10041764 -0.28643208]\n",
      "Training Error:  9.84048261124504\n",
      "====================================================================================================\n",
      "Iteration:  387\n",
      "Previous theta :  [-0.01743735 -0.06508964  0.08403973 -0.01274226  0.09402784 -0.10949452\n",
      "  0.37161588 -0.07896348 -0.25014443  0.16668682 -0.18727796 -0.19630073\n",
      "  0.10041764 -0.28643208]\n",
      "New theta_0 : [-0.0174293  -0.065234    0.08424298 -0.01288982  0.0940269  -0.11000074\n",
      "  0.37129907 -0.07886564 -0.25075822  0.16700901 -0.18729555 -0.19639601\n",
      "  0.10034715 -0.28662706]\n",
      "Training Error:  9.839505059947026\n",
      "====================================================================================================\n",
      "Iteration:  388\n",
      "Previous theta :  [-0.0174293  -0.065234    0.08424298 -0.01288982  0.0940269  -0.11000074\n",
      "  0.37129907 -0.07886564 -0.25075822  0.16700901 -0.18729555 -0.19639601\n",
      "  0.10034715 -0.28662706]\n",
      "New theta_0 : [-0.01742131 -0.06537728  0.08444496 -0.01303568  0.09402594 -0.11050357\n",
      "  0.37098477 -0.07876794 -0.25136713  0.16732927 -0.1873138  -0.19649056\n",
      "  0.10027719 -0.28682045]\n",
      "Training Error:  9.83854170244635\n",
      "====================================================================================================\n",
      "Iteration:  389\n",
      "Previous theta :  [-0.01742131 -0.06537728  0.08444496 -0.01303568  0.09402594 -0.11050357\n",
      "  0.37098477 -0.07876794 -0.25136713  0.16732927 -0.1873138  -0.19649056\n",
      "  0.10027719 -0.28682045]\n",
      "New theta_0 : [-0.01741338 -0.0655195   0.08464568 -0.01317984  0.09402493 -0.11100304\n",
      "  0.37067298 -0.07867038 -0.2519712   0.16764762 -0.18733269 -0.19658438\n",
      "  0.10020775 -0.28701228]\n",
      "Training Error:  9.837592326367906\n",
      "====================================================================================================\n",
      "Iteration:  390\n",
      "Previous theta :  [-0.01741338 -0.0655195   0.08464568 -0.01317984  0.09402493 -0.11100304\n",
      "  0.37067298 -0.07867038 -0.2519712   0.16764762 -0.18733269 -0.19658438\n",
      "  0.10020775 -0.28701228]\n",
      "New theta_0 : [-0.01740552 -0.06566065  0.08484513 -0.01332233  0.09402388 -0.11149917\n",
      "  0.37036366 -0.07857298 -0.25257047  0.16796407 -0.18735222 -0.19667748\n",
      "  0.10013883 -0.28720255]\n",
      "Training Error:  9.83665672256651\n",
      "====================================================================================================\n",
      "Iteration:  391\n",
      "Previous theta :  [-0.01740552 -0.06566065  0.08484513 -0.01332233  0.09402388 -0.11149917\n",
      "  0.37036366 -0.07857298 -0.25257047  0.16796407 -0.18735222 -0.19667748\n",
      "  0.10013883 -0.28720255]\n",
      "New theta_0 : [-0.01739772 -0.06580076  0.08504333 -0.01346315  0.0940228  -0.11199197\n",
      "  0.3700568  -0.07847575 -0.25316498  0.16827865 -0.18737239 -0.19676987\n",
      "  0.10007043 -0.28739128]\n",
      "Training Error:  9.835734685077094\n",
      "====================================================================================================\n",
      "Iteration:  392\n",
      "Previous theta :  [-0.01739772 -0.06580076  0.08504333 -0.01346315  0.0940228  -0.11199197\n",
      "  0.3700568  -0.07847575 -0.25316498  0.16827865 -0.18737239 -0.19676987\n",
      "  0.10007043 -0.28739128]\n",
      "New theta_0 : [-0.01738999 -0.06593983  0.08524027 -0.01360233  0.09402169 -0.11248148\n",
      "  0.36975238 -0.07837868 -0.25375476  0.16859136 -0.18739318 -0.19686156\n",
      "  0.10000254 -0.28757849]\n",
      "Training Error:  9.8348260110657\n",
      "====================================================================================================\n",
      "Iteration:  393\n",
      "Previous theta :  [-0.01738999 -0.06593983  0.08524027 -0.01360233  0.09402169 -0.11248148\n",
      "  0.36975238 -0.07837868 -0.25375476  0.16859136 -0.18739318 -0.19686156\n",
      "  0.10000254 -0.28757849]\n",
      "New theta_0 : [-0.01738232 -0.06607786  0.08543598 -0.01373988  0.09402054 -0.11296771\n",
      "  0.36945037 -0.07828178 -0.25433986  0.16890222 -0.18741459 -0.19695255\n",
      "  0.09993515 -0.28776418]\n",
      "Training Error:  9.83393050078119\n",
      "====================================================================================================\n",
      "Iteration:  394\n",
      "Previous theta :  [-0.01738232 -0.06607786  0.08543598 -0.01373988  0.09402054 -0.11296771\n",
      "  0.36945037 -0.07828178 -0.25433986  0.16890222 -0.18741459 -0.19695255\n",
      "  0.09993515 -0.28776418]\n",
      "New theta_0 : [-0.01737471 -0.06621486  0.08563045 -0.01387581  0.09401935 -0.11345069\n",
      "  0.36915076 -0.07818505 -0.25492031  0.16921125 -0.18743661 -0.19704285\n",
      "  0.09986827 -0.28794838]\n",
      "Training Error:  9.833047957507759\n",
      "====================================================================================================\n",
      "Iteration:  395\n",
      "Previous theta :  [-0.01737471 -0.06621486  0.08563045 -0.01387581  0.09401935 -0.11345069\n",
      "  0.36915076 -0.07818505 -0.25492031  0.16921125 -0.18743661 -0.19704285\n",
      "  0.09986827 -0.28794838]\n",
      "New theta_0 : [-0.01736716 -0.06635084  0.08582368 -0.01401015  0.09401813 -0.11393043\n",
      "  0.36885351 -0.07808851 -0.25549615  0.16951845 -0.18745923 -0.19713247\n",
      "  0.09980189 -0.28813109]\n",
      "Training Error:  9.832178187518188\n",
      "====================================================================================================\n",
      "Iteration:  396\n",
      "Previous theta :  [-0.01736716 -0.06635084  0.08582368 -0.01401015  0.09401813 -0.11393043\n",
      "  0.36885351 -0.07808851 -0.25549615  0.16951845 -0.18745923 -0.19713247\n",
      "  0.09980189 -0.28813109]\n",
      "New theta_0 : [-0.01735968 -0.06648581  0.0860157  -0.01414289  0.09401687 -0.11440697\n",
      "  0.36855862 -0.07799216 -0.25606741  0.16982385 -0.18748246 -0.1972214\n",
      "  0.09973601 -0.28831234]\n",
      "Training Error:  9.831321000027808\n",
      "====================================================================================================\n",
      "Iteration:  397\n",
      "Previous theta :  [-0.01735968 -0.06648581  0.0860157  -0.01414289  0.09401687 -0.11440697\n",
      "  0.36855862 -0.07799216 -0.25606741  0.16982385 -0.18748246 -0.1972214\n",
      "  0.09973601 -0.28831234]\n",
      "New theta_0 : [-0.01735225 -0.06661978  0.08620649 -0.01427406  0.09401558 -0.11488031\n",
      "  0.36826606 -0.077896   -0.25663414  0.17012745 -0.18750627 -0.19730967\n",
      "  0.09967061 -0.28849212]\n",
      "Training Error:  9.830476207149209\n",
      "====================================================================================================\n",
      "Iteration:  398\n",
      "Previous theta :  [-0.01735225 -0.06661978  0.08620649 -0.01427406  0.09401558 -0.11488031\n",
      "  0.36826606 -0.077896   -0.25663414  0.17012745 -0.18750627 -0.19730967\n",
      "  0.09967061 -0.28849212]\n",
      "New theta_0 : [-0.01734489 -0.06675275  0.08639607 -0.01440368  0.09401426 -0.11535048\n",
      "  0.36797582 -0.07780004 -0.25719636  0.17042928 -0.18753067 -0.19739727\n",
      "  0.09960571 -0.28867047]\n",
      "Training Error:  9.829643623847648\n",
      "====================================================================================================\n",
      "Iteration:  399\n",
      "Previous theta :  [-0.01734489 -0.06675275  0.08639607 -0.01440368  0.09401426 -0.11535048\n",
      "  0.36797582 -0.07780004 -0.25719636  0.17042928 -0.18753067 -0.19739727\n",
      "  0.09960571 -0.28867047]\n",
      "New theta_0 : [-0.01733759 -0.06688473  0.08658444 -0.01453175  0.09401291 -0.1158175\n",
      "  0.36768786 -0.07770428 -0.25775412  0.17072934 -0.18755564 -0.19748422\n",
      "  0.09954129 -0.28884739]\n",
      "Training Error:  9.82882306789715\n",
      "====================================================================================================\n",
      "Iteration:  400\n",
      "Previous theta :  [-0.01733759 -0.06688473  0.08658444 -0.01453175  0.09401291 -0.1158175\n",
      "  0.36768786 -0.07770428 -0.25775412  0.17072934 -0.18755564 -0.19748422\n",
      "  0.09954129 -0.28884739]\n",
      "New theta_0 : [-0.01733034 -0.06701572  0.08677161 -0.01465829  0.09401152 -0.11628139\n",
      "  0.36740218 -0.07760873 -0.25830745  0.17102764 -0.18758118 -0.19757052\n",
      "  0.09947735 -0.28902289]\n",
      "Training Error:  9.828014359837315\n",
      "====================================================================================================\n",
      "Iteration:  401\n",
      "Previous theta :  [-0.01733034 -0.06701572  0.08677161 -0.01465829  0.09401152 -0.11628139\n",
      "  0.36740218 -0.07760873 -0.25830745  0.17102764 -0.18758118 -0.19757052\n",
      "  0.09947735 -0.28902289]\n",
      "New theta_0 : [-0.01732315 -0.06714574  0.08695759 -0.01478332  0.0940101  -0.11674218\n",
      "  0.36711874 -0.0775134  -0.25885638  0.17132421 -0.18760729 -0.19765617\n",
      "  0.09941388 -0.28919699]\n",
      "Training Error:  9.827217322930771\n",
      "====================================================================================================\n",
      "Iteration:  402\n",
      "Previous theta :  [-0.01732315 -0.06714574  0.08695759 -0.01478332  0.0940101  -0.11674218\n",
      "  0.36711874 -0.0775134  -0.25885638  0.17132421 -0.18760729 -0.19765617\n",
      "  0.09941388 -0.28919699]\n",
      "New theta_0 : [-0.01731603 -0.06727479  0.08714238 -0.01490685  0.09400864 -0.11719987\n",
      "  0.36683755 -0.07741827 -0.25940095  0.17161905 -0.18763396 -0.19774118\n",
      "  0.09935089 -0.2893697 ]\n",
      "Training Error:  9.826431783121325\n",
      "====================================================================================================\n",
      "Iteration:  403\n",
      "Previous theta :  [-0.01731603 -0.06727479  0.08714238 -0.01490685  0.09400864 -0.11719987\n",
      "  0.36683755 -0.07741827 -0.25940095  0.17161905 -0.18763396 -0.19774118\n",
      "  0.09935089 -0.2893697 ]\n",
      "New theta_0 : [-0.01730896 -0.06740289  0.08732599 -0.01502889  0.09400716 -0.1176545\n",
      "  0.36655856 -0.07732337 -0.2599412   0.17191219 -0.18766117 -0.19782556\n",
      "  0.09928836 -0.28954103]\n",
      "Training Error:  9.825657568992748\n",
      "====================================================================================================\n",
      "Iteration:  404\n",
      "Previous theta :  [-0.01730896 -0.06740289  0.08732599 -0.01502889  0.09400716 -0.1176545\n",
      "  0.36655856 -0.07732337 -0.2599412   0.17191219 -0.18766117 -0.19782556\n",
      "  0.09928836 -0.28954103]\n",
      "New theta_0 : [-0.01730194 -0.06753002  0.08750842 -0.01514946  0.09400564 -0.11810609\n",
      "  0.36628177 -0.07722869 -0.26047716  0.17220362 -0.18768894 -0.19790931\n",
      "  0.09922631 -0.289711  ]\n",
      "Training Error:  9.824894511728196\n",
      "====================================================================================================\n",
      "Iteration:  405\n",
      "Previous theta :  [-0.01730194 -0.06753002  0.08750842 -0.01514946  0.09400564 -0.11810609\n",
      "  0.36628177 -0.07722869 -0.26047716  0.17220362 -0.18768894 -0.19790931\n",
      "  0.09922631 -0.289711  ]\n",
      "New theta_0 : [-0.01729499 -0.06765622  0.08768968 -0.01526857  0.0940041  -0.11855464\n",
      "  0.36600716 -0.07713425 -0.26100887  0.17249337 -0.18771723 -0.19799245\n",
      "  0.09916471 -0.28987962]\n",
      "Training Error:  9.824142445070308\n",
      "====================================================================================================\n",
      "Iteration:  406\n",
      "Previous theta :  [-0.01729499 -0.06765622  0.08768968 -0.01526857  0.0940041  -0.11855464\n",
      "  0.36600716 -0.07713425 -0.26100887  0.17249337 -0.18771723 -0.19799245\n",
      "  0.09916471 -0.28987962]\n",
      "New theta_0 : [-0.01728809 -0.06778147  0.08786977 -0.01538623  0.09400252 -0.11900019\n",
      "  0.3657347  -0.07704003 -0.26153635  0.17278144 -0.18774607 -0.19807497\n",
      "  0.09910357 -0.2900469 ]\n",
      "Training Error:  9.823401205281856\n",
      "====================================================================================================\n",
      "Iteration:  407\n",
      "Previous theta :  [-0.01728809 -0.06778147  0.08786977 -0.01538623  0.09400252 -0.11900019\n",
      "  0.3657347  -0.07704003 -0.26153635  0.17278144 -0.18774607 -0.19807497\n",
      "  0.09910357 -0.2900469 ]\n",
      "New theta_0 : [-0.01728124 -0.06790579  0.08804871 -0.01550246  0.09400091 -0.11944276\n",
      "  0.36546438 -0.07694605 -0.26205964  0.17306786 -0.18777542 -0.19815688\n",
      "  0.09904289 -0.29021285]\n",
      "Training Error:  9.822670631107076\n",
      "====================================================================================================\n",
      "Iteration:  408\n",
      "Previous theta :  [-0.01728124 -0.06790579  0.08804871 -0.01550246  0.09400091 -0.11944276\n",
      "  0.36546438 -0.07694605 -0.26205964  0.17306786 -0.18777542 -0.19815688\n",
      "  0.09904289 -0.29021285]\n",
      "New theta_0 : [-0.01727445 -0.06802918  0.08822649 -0.01561727  0.09399928 -0.11988235\n",
      "  0.36519618 -0.07685232 -0.26257878  0.17335263 -0.1878053  -0.19823818\n",
      "  0.09898265 -0.29037748]\n",
      "Training Error:  9.821950563733575\n",
      "====================================================================================================\n",
      "Iteration:  409\n",
      "Previous theta :  [-0.01727445 -0.06802918  0.08822649 -0.01561727  0.09399928 -0.11988235\n",
      "  0.36519618 -0.07685232 -0.26257878  0.17335263 -0.1878053  -0.19823818\n",
      "  0.09898265 -0.29037748]\n",
      "New theta_0 : [-0.01726772 -0.06815165  0.08840313 -0.01573068  0.09399761 -0.120319\n",
      "  0.36493009 -0.07675882 -0.2630938   0.17363577 -0.18783569 -0.1983189\n",
      "  0.09892287 -0.29054081]\n",
      "Training Error:  9.821240846754813\n",
      "====================================================================================================\n",
      "Iteration:  410\n",
      "Previous theta :  [-0.01726772 -0.06815165  0.08840313 -0.01573068  0.09399761 -0.120319\n",
      "  0.36493009 -0.07675882 -0.2630938   0.17363577 -0.18783569 -0.1983189\n",
      "  0.09892287 -0.29054081]\n",
      "New theta_0 : [-0.01726104 -0.06827322  0.08857863 -0.01584269  0.09399592 -0.12075272\n",
      "  0.36466607 -0.07666558 -0.26360473  0.17391728 -0.18786659 -0.19839902\n",
      "  0.09886353 -0.29070285]\n",
      "Training Error:  9.820541326133206\n",
      "====================================================================================================\n",
      "Iteration:  411\n",
      "Previous theta :  [-0.01726104 -0.06827322  0.08857863 -0.01584269  0.09399592 -0.12075272\n",
      "  0.36466607 -0.07666558 -0.26360473  0.17391728 -0.18786659 -0.19839902\n",
      "  0.09886353 -0.29070285]\n",
      "New theta_0 : [-0.01725441 -0.06839387  0.08875299 -0.01595333  0.09399419 -0.12118353\n",
      "  0.36440413 -0.07657258 -0.26411161  0.17419719 -0.18789798 -0.19847855\n",
      "  0.09880463 -0.29086361]\n",
      "Training Error:  9.81985185016378\n",
      "====================================================================================================\n",
      "Iteration:  412\n",
      "Previous theta :  [-0.01725441 -0.06839387  0.08875299 -0.01595333  0.09399419 -0.12118353\n",
      "  0.36440413 -0.07657258 -0.26411161  0.17419719 -0.18789798 -0.19847855\n",
      "  0.09880463 -0.29086361]\n",
      "New theta_0 : [-0.01724784 -0.06851363  0.08892623 -0.01606259  0.09399244 -0.12161146\n",
      "  0.36414423 -0.07647985 -0.26461446  0.17447549 -0.18792988 -0.19855751\n",
      "  0.09874616 -0.2910231 ]\n",
      "Training Error:  9.819172269438385\n",
      "====================================================================================================\n",
      "Iteration:  413\n",
      "Previous theta :  [-0.01724784 -0.06851363  0.08892623 -0.01606259  0.09399244 -0.12161146\n",
      "  0.36414423 -0.07647985 -0.26461446  0.17447549 -0.18792988 -0.19855751\n",
      "  0.09874616 -0.2910231 ]\n",
      "New theta_0 : [-0.01724132 -0.0686325   0.08909835 -0.01617051  0.09399066 -0.12203651\n",
      "  0.36388637 -0.07638736 -0.26511332  0.17475222 -0.18796226 -0.19863589\n",
      "  0.09868813 -0.29118134]\n",
      "Training Error:  9.81850243681051\n",
      "====================================================================================================\n",
      "Iteration:  414\n",
      "Previous theta :  [-0.01724132 -0.0686325   0.08909835 -0.01617051  0.09399066 -0.12203651\n",
      "  0.36388637 -0.07638736 -0.26511332  0.17475222 -0.18796226 -0.19863589\n",
      "  0.09868813 -0.29118134]\n",
      "New theta_0 : [-0.01723485 -0.06875048  0.08926935 -0.01627708  0.09398886 -0.12245871\n",
      "  0.36363051 -0.07629514 -0.26560822  0.17502737 -0.18799513 -0.1987137\n",
      "  0.09863053 -0.29133833]\n",
      "Training Error:  9.817842207360568\n",
      "====================================================================================================\n",
      "Iteration:  415\n",
      "Previous theta :  [-0.01723485 -0.06875048  0.08926935 -0.01627708  0.09398886 -0.12245871\n",
      "  0.36363051 -0.07629514 -0.26560822  0.17502737 -0.18799513 -0.1987137\n",
      "  0.09863053 -0.29133833]\n",
      "New theta_0 : [-0.01722843 -0.06886759  0.08943924 -0.01638232  0.09398702 -0.12287807\n",
      "  0.36337666 -0.07620318 -0.26609919  0.17530096 -0.18802848 -0.19879094\n",
      "  0.09857336 -0.29149408]\n",
      "Training Error:  9.817191438361812\n",
      "====================================================================================================\n",
      "Iteration:  416\n",
      "Previous theta :  [-0.01722843 -0.06886759  0.08943924 -0.01638232  0.09398702 -0.12287807\n",
      "  0.36337666 -0.07620318 -0.26609919  0.17530096 -0.18802848 -0.19879094\n",
      "  0.09857336 -0.29149408]\n",
      "New theta_0 : [-0.01722207 -0.06898382  0.08960802 -0.01648625  0.09398516 -0.12329463\n",
      "  0.36312479 -0.07611149 -0.26658626  0.175573   -0.18806229 -0.19886763\n",
      "  0.09851661 -0.29164861]\n",
      "Training Error:  9.816549989246697\n",
      "====================================================================================================\n",
      "Iteration:  417\n",
      "Previous theta :  [-0.01722207 -0.06898382  0.08960802 -0.01648625  0.09398516 -0.12329463\n",
      "  0.36312479 -0.07611149 -0.26658626  0.175573   -0.18806229 -0.19886763\n",
      "  0.09851661 -0.29164861]\n",
      "New theta_0 : [-0.01721575 -0.06909919  0.08977571 -0.01658888  0.09398327 -0.12370838\n",
      "  0.36287487 -0.07602007 -0.26706947  0.1758435  -0.18809658 -0.19894377\n",
      "  0.09846029 -0.29180193]\n",
      "Training Error:  9.815917721573829\n",
      "====================================================================================================\n",
      "Iteration:  418\n",
      "Previous theta :  [-0.01721575 -0.06909919  0.08977571 -0.01658888  0.09398327 -0.12370838\n",
      "  0.36287487 -0.07602007 -0.26706947  0.1758435  -0.18809658 -0.19894377\n",
      "  0.09846029 -0.29180193]\n",
      "New theta_0 : [-0.01720949 -0.0692137   0.08994231 -0.01669021  0.09398136 -0.12411937\n",
      "  0.36262691 -0.07592892 -0.26754885  0.17611248 -0.18813133 -0.19901935\n",
      "  0.09840438 -0.29195405]\n",
      "Training Error:  9.815294498995383\n",
      "====================================================================================================\n",
      "Iteration:  419\n",
      "Previous theta :  [-0.01720949 -0.0692137   0.08994231 -0.01669021  0.09398136 -0.12411937\n",
      "  0.36262691 -0.07592892 -0.26754885  0.17611248 -0.18813133 -0.19901935\n",
      "  0.09840438 -0.29195405]\n",
      "New theta_0 : [-0.01720328 -0.06932735  0.09010782 -0.01679026  0.09397942 -0.12452759\n",
      "  0.36238088 -0.07583805 -0.26802442  0.17637995 -0.18816653 -0.1990944\n",
      "  0.09834888 -0.29210498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.81468018722506\n",
      "====================================================================================================\n",
      "Iteration:  420\n",
      "Previous theta :  [-0.01720328 -0.06932735  0.09010782 -0.01679026  0.09397942 -0.12452759\n",
      "  0.36238088 -0.07583805 -0.26802442  0.17637995 -0.18816653 -0.1990944\n",
      "  0.09834888 -0.29210498]\n",
      "New theta_0 : [-0.01719711 -0.06944017  0.09027226 -0.01688905  0.09397745 -0.12493307\n",
      "  0.36213675 -0.07574746 -0.26849622  0.17664591 -0.18820218 -0.1991689\n",
      "  0.0982938  -0.29225472]\n",
      "Training Error:  9.814074654006516\n",
      "====================================================================================================\n",
      "Iteration:  421\n",
      "Previous theta :  [-0.01719711 -0.06944017  0.09027226 -0.01688905  0.09397745 -0.12493307\n",
      "  0.36213675 -0.07574746 -0.26849622  0.17664591 -0.18820218 -0.1991689\n",
      "  0.0982938  -0.29225472]\n",
      "New theta_0 : [-0.017191   -0.06955214  0.09043562 -0.01698658  0.09397546 -0.12533583\n",
      "  0.36189453 -0.07565714 -0.26896427  0.17691038 -0.18823828 -0.19924287\n",
      "  0.09823912 -0.2924033 ]\n",
      "Training Error:  9.813477769082292\n",
      "====================================================================================================\n",
      "Iteration:  422\n",
      "Previous theta :  [-0.017191   -0.06955214  0.09043562 -0.01698658  0.09397546 -0.12533583\n",
      "  0.36189453 -0.07565714 -0.26896427  0.17691038 -0.18823828 -0.19924287\n",
      "  0.09823912 -0.2924033 ]\n",
      "New theta_0 : [-0.01718494 -0.06966328  0.09059791 -0.01708287  0.09397345 -0.12573589\n",
      "  0.36165419 -0.07556711 -0.26942861  0.17717337 -0.18827481 -0.19931631\n",
      "  0.09818485 -0.29255072]\n",
      "Training Error:  9.812889404163233\n",
      "====================================================================================================\n",
      "Iteration:  423\n",
      "Previous theta :  [-0.01718494 -0.06966328  0.09059791 -0.01708287  0.09397345 -0.12573589\n",
      "  0.36165419 -0.07556711 -0.26942861  0.17717337 -0.18827481 -0.19931631\n",
      "  0.09818485 -0.29255072]\n",
      "New theta_0 : [-0.01717892 -0.06977359  0.09075914 -0.01717793  0.09397141 -0.12613326\n",
      "  0.36141571 -0.07547736 -0.26988926  0.17743489 -0.18831179 -0.19938923\n",
      "  0.09813098 -0.29269699]\n",
      "Training Error:  9.812309432898365\n",
      "====================================================================================================\n",
      "Iteration:  424\n",
      "Previous theta :  [-0.01717892 -0.06977359  0.09075914 -0.01717793  0.09397141 -0.12613326\n",
      "  0.36141571 -0.07547736 -0.26988926  0.17743489 -0.18831179 -0.19938923\n",
      "  0.09813098 -0.29269699]\n",
      "New theta_0 : [-0.01717295 -0.06988308  0.09091932 -0.01727176  0.09396935 -0.12652796\n",
      "  0.36117909 -0.0753879  -0.27034626  0.17769496 -0.18834919 -0.19946163\n",
      "  0.0980775  -0.29284212]\n",
      "Training Error:  9.811737730845255\n",
      "====================================================================================================\n",
      "Iteration:  425\n",
      "Previous theta :  [-0.01717295 -0.06988308  0.09091932 -0.01727176  0.09396935 -0.12652796\n",
      "  0.36117909 -0.0753879  -0.27034626  0.17769496 -0.18834919 -0.19946163\n",
      "  0.0980775  -0.29284212]\n",
      "New theta_0 : [-0.01716703 -0.06999175  0.09107845 -0.01736439  0.09396726 -0.12692001\n",
      "  0.36094429 -0.07529873 -0.27079964  0.17795358 -0.18838701 -0.19953352\n",
      "  0.09802443 -0.29298612]\n",
      "Training Error:  9.811174175440811\n",
      "====================================================================================================\n",
      "Iteration:  426\n",
      "Previous theta :  [-0.01716703 -0.06999175  0.09107845 -0.01736439  0.09396726 -0.12692001\n",
      "  0.36094429 -0.07529873 -0.27079964  0.17795358 -0.18838701 -0.19953352\n",
      "  0.09802443 -0.29298612]\n",
      "New theta_0 : [-0.01716116 -0.07009962  0.09123653 -0.01745582  0.09396515 -0.12730943\n",
      "  0.36071132 -0.07520985 -0.27124942  0.17821076 -0.18842525 -0.19960489\n",
      "  0.09797174 -0.293129  ]\n",
      "Training Error:  9.810618645972568\n",
      "====================================================================================================\n",
      "Iteration:  427\n",
      "Previous theta :  [-0.01716116 -0.07009962  0.09123653 -0.01745582  0.09396515 -0.12730943\n",
      "  0.36071132 -0.07520985 -0.27124942  0.17821076 -0.18842525 -0.19960489\n",
      "  0.09797174 -0.293129  ]\n",
      "New theta_0 : [-0.01715534 -0.07020669  0.09139358 -0.01754607  0.09396301 -0.12769623\n",
      "  0.36048015 -0.07512126 -0.27169562  0.17846651 -0.18846391 -0.19967577\n",
      "  0.09791945 -0.29327078]\n",
      "Training Error:  9.810071023550373\n",
      "====================================================================================================\n",
      "Iteration:  428\n",
      "Previous theta :  [-0.01715534 -0.07020669  0.09139358 -0.01754607  0.09396301 -0.12769623\n",
      "  0.36048015 -0.07512126 -0.27169562  0.17846651 -0.18846391 -0.19967577\n",
      "  0.09791945 -0.29327078]\n",
      "New theta_0 : [-0.01714956 -0.07031296  0.0915496  -0.01763514  0.09396085 -0.12808043\n",
      "  0.36025077 -0.07503297 -0.27213829  0.17872085 -0.18850297 -0.19974614\n",
      "  0.09786754 -0.29341145]\n",
      "Training Error:  9.80953119107854\n",
      "====================================================================================================\n",
      "Iteration:  429\n",
      "Previous theta :  [-0.01714956 -0.07031296  0.0915496  -0.01763514  0.09396085 -0.12808043\n",
      "  0.36025077 -0.07503297 -0.27213829  0.17872085 -0.18850297 -0.19974614\n",
      "  0.09786754 -0.29341145]\n",
      "New theta_0 : [-0.01714383 -0.07041843  0.09170459 -0.01772305  0.09395867 -0.12846206\n",
      "  0.36002316 -0.07494498 -0.27257745  0.17897379 -0.18854244 -0.19981601\n",
      "  0.09781602 -0.29355104]\n",
      "Training Error:  9.808999033228446\n",
      "====================================================================================================\n",
      "Iteration:  430\n",
      "Previous theta :  [-0.01714383 -0.07041843  0.09170459 -0.01772305  0.09395867 -0.12846206\n",
      "  0.36002316 -0.07494498 -0.27257745  0.17897379 -0.18854244 -0.19981601\n",
      "  0.09781602 -0.29355104]\n",
      "New theta_0 : [-0.01713814 -0.07052313  0.09185856 -0.01780981  0.09395647 -0.12884112\n",
      "  0.35979731 -0.07485728 -0.27301313  0.17922533 -0.1885823  -0.1998854\n",
      "  0.09776487 -0.29368954]\n",
      "Training Error:  9.808474436411503\n",
      "====================================================================================================\n",
      "Iteration:  431\n",
      "Previous theta :  [-0.01713814 -0.07052313  0.09185856 -0.01780981  0.09395647 -0.12884112\n",
      "  0.35979731 -0.07485728 -0.27301313  0.17922533 -0.1885823  -0.1998854\n",
      "  0.09776487 -0.29368954]\n",
      "New theta_0 : [-0.0171325  -0.07062705  0.09201152 -0.01789543  0.09395424 -0.12921763\n",
      "  0.3595732  -0.07476989 -0.27344534  0.17947549 -0.18862256 -0.19995429\n",
      "  0.09771411 -0.29382698]\n",
      "Training Error:  9.807957288752608\n",
      "====================================================================================================\n",
      "Iteration:  432\n",
      "Previous theta :  [-0.0171325  -0.07062705  0.09201152 -0.01789543  0.09395424 -0.12921763\n",
      "  0.3595732  -0.07476989 -0.27344534  0.17947549 -0.18862256 -0.19995429\n",
      "  0.09771411 -0.29382698]\n",
      "New theta_0 : [-0.0171269  -0.07073019  0.09216347 -0.01797992  0.09395199 -0.12959161\n",
      "  0.35935083 -0.0746828  -0.27387413  0.17972428 -0.18866321 -0.20002271\n",
      "  0.09766372 -0.29396335]\n",
      "Training Error:  9.807447480063946\n",
      "====================================================================================================\n",
      "Iteration:  433\n",
      "Previous theta :  [-0.0171269  -0.07073019  0.09216347 -0.01797992  0.09395199 -0.12959161\n",
      "  0.35935083 -0.0746828  -0.27387413  0.17972428 -0.18866321 -0.20002271\n",
      "  0.09766372 -0.29396335]\n",
      "New theta_0 : [-0.01712135 -0.07083257  0.09231442 -0.01806328  0.09394972 -0.12996308\n",
      "  0.35913017 -0.07459601 -0.27429952  0.17997171 -0.18870424 -0.20009064\n",
      "  0.0976137  -0.29409867]\n",
      "Training Error:  9.806944901819254\n",
      "====================================================================================================\n",
      "Iteration:  434\n",
      "Previous theta :  [-0.01712135 -0.07083257  0.09231442 -0.01806328  0.09394972 -0.12996308\n",
      "  0.35913017 -0.07459601 -0.27429952  0.17997171 -0.18870424 -0.20009064\n",
      "  0.0976137  -0.29409867]\n",
      "New theta_0 : [-0.01711584 -0.07093418  0.09246437 -0.01814554  0.09394743 -0.13033205\n",
      "  0.3589112  -0.07450953 -0.27472153  0.18021778 -0.18874565 -0.2001581\n",
      "  0.09756405 -0.29423295]\n",
      "Training Error:  9.806449447128438\n",
      "====================================================================================================\n",
      "Iteration:  435\n",
      "Previous theta :  [-0.01711584 -0.07093418  0.09246437 -0.01814554  0.09394743 -0.13033205\n",
      "  0.3589112  -0.07450953 -0.27472153  0.18021778 -0.18874565 -0.2001581\n",
      "  0.09756405 -0.29423295]\n",
      "New theta_0 : [-0.01711038 -0.07103504  0.09261334 -0.01822671  0.09394512 -0.13069854\n",
      "  0.35869393 -0.07442335 -0.2751402   0.18046251 -0.18878744 -0.20022509\n",
      "  0.09751477 -0.2943662 ]\n",
      "Training Error:  9.805961010712597\n",
      "====================================================================================================\n",
      "Iteration:  436\n",
      "Previous theta :  [-0.01711038 -0.07103504  0.09261334 -0.01822671  0.09394512 -0.13069854\n",
      "  0.35869393 -0.07442335 -0.2751402   0.18046251 -0.18878744 -0.20022509\n",
      "  0.09751477 -0.2943662 ]\n",
      "New theta_0 : [-0.01710496 -0.07113516  0.09276132 -0.01830678  0.09394279 -0.13106257\n",
      "  0.35847832 -0.07433749 -0.27555555  0.1807059  -0.18882959 -0.20029162\n",
      "  0.09746585 -0.29449842]\n",
      "Training Error:  9.805479488879449\n",
      "====================================================================================================\n",
      "Iteration:  437\n",
      "Previous theta :  [-0.01710496 -0.07113516  0.09276132 -0.01830678  0.09394279 -0.13106257\n",
      "  0.35847832 -0.07433749 -0.27555555  0.1807059  -0.18882959 -0.20029162\n",
      "  0.09746585 -0.29449842]\n",
      "New theta_0 : [-0.01709958 -0.07123452  0.09290832 -0.01838578  0.09394044 -0.13142416\n",
      "  0.35826438 -0.07425193 -0.2759676   0.18094797 -0.18887211 -0.20035768\n",
      "  0.09741729 -0.29462963]\n",
      "Training Error:  9.805004779499113\n",
      "====================================================================================================\n",
      "Iteration:  438\n",
      "Previous theta :  [-0.01709958 -0.07123452  0.09290832 -0.01838578  0.09394044 -0.13142416\n",
      "  0.35826438 -0.07425193 -0.2759676   0.18094797 -0.18887211 -0.20035768\n",
      "  0.09741729 -0.29462963]\n",
      "New theta_0 : [-0.01709425 -0.07133316  0.09305435 -0.01846371  0.09393806 -0.13178331\n",
      "  0.35805208 -0.07416668 -0.27637638  0.18118873 -0.18891499 -0.20042329\n",
      "  0.09736909 -0.29475983]\n",
      "Training Error:  9.804536781980268\n",
      "====================================================================================================\n",
      "Iteration:  439\n",
      "Previous theta :  [-0.01709425 -0.07133316  0.09305435 -0.01846371  0.09393806 -0.13178331\n",
      "  0.35805208 -0.07416668 -0.27637638  0.18118873 -0.18891499 -0.20042329\n",
      "  0.09736909 -0.29475983]\n",
      "New theta_0 : [-0.01708896 -0.07143105  0.09319941 -0.01854059  0.09393567 -0.13214004\n",
      "  0.35784141 -0.07408175 -0.27678192  0.18142819 -0.18895823 -0.20048844\n",
      "  0.09732124 -0.29488903]\n",
      "Training Error:  9.804075397246706\n",
      "====================================================================================================\n",
      "Iteration:  440\n",
      "Previous theta :  [-0.01708896 -0.07143105  0.09319941 -0.01854059  0.09393567 -0.13214004\n",
      "  0.35784141 -0.07408175 -0.27678192  0.18142819 -0.18895823 -0.20048844\n",
      "  0.09732124 -0.29488903]\n",
      "New theta_0 : [-0.01708371 -0.07152822  0.09334351 -0.01861642  0.09393326 -0.13249438\n",
      "  0.35763235 -0.07399713 -0.27718425  0.18166635 -0.18900182 -0.20055314\n",
      "  0.09727375 -0.29501724]\n",
      "Training Error:  9.803620527714207\n",
      "====================================================================================================\n",
      "Iteration:  441\n",
      "Previous theta :  [-0.01708371 -0.07152822  0.09334351 -0.01861642  0.09393326 -0.13249438\n",
      "  0.35763235 -0.07399713 -0.27718425  0.18166635 -0.18900182 -0.20055314\n",
      "  0.09727375 -0.29501724]\n",
      "New theta_0 : [-0.01707851 -0.07162467  0.09348666 -0.01869121  0.09393083 -0.13284634\n",
      "  0.3574249  -0.07391283 -0.27758338  0.18190323 -0.18904575 -0.20061739\n",
      "  0.09722661 -0.29514447]\n",
      "Training Error:  9.803172077267803\n",
      "====================================================================================================\n",
      "Iteration:  442\n",
      "Previous theta :  [-0.01707851 -0.07162467  0.09348666 -0.01869121  0.09393083 -0.13284634\n",
      "  0.3574249  -0.07391283 -0.27758338  0.18190323 -0.18904575 -0.20061739\n",
      "  0.09722661 -0.29514447]\n",
      "New theta_0 : [-0.01707334 -0.07172041  0.09362886 -0.01876498  0.09392837 -0.13319593\n",
      "  0.35721904 -0.07382884 -0.27797935  0.18213883 -0.18909003 -0.20068121\n",
      "  0.09717982 -0.29527073]\n",
      "Training Error:  9.802729951239373\n",
      "====================================================================================================\n",
      "Iteration:  443\n",
      "Previous theta :  [-0.01707334 -0.07172041  0.09362886 -0.01876498  0.09392837 -0.13319593\n",
      "  0.35721904 -0.07382884 -0.27797935  0.18213883 -0.18909003 -0.20068121\n",
      "  0.09717982 -0.29527073]\n",
      "New theta_0 : [-0.01706822 -0.07181543  0.09377011 -0.01883774  0.0939259  -0.13354316\n",
      "  0.35701476 -0.07374517 -0.27837218  0.18237317 -0.18913464 -0.20074458\n",
      "  0.09713337 -0.29539602]\n",
      "Training Error:  9.802294056385602\n",
      "====================================================================================================\n",
      "Iteration:  444\n",
      "Previous theta :  [-0.01706822 -0.07181543  0.09377011 -0.01883774  0.0939259  -0.13354316\n",
      "  0.35701476 -0.07374517 -0.27837218  0.18237317 -0.18913464 -0.20074458\n",
      "  0.09713337 -0.29539602]\n",
      "New theta_0 : [-0.01706313 -0.07190975  0.09391043 -0.01890948  0.09392341 -0.13388807\n",
      "  0.35681204 -0.07366181 -0.27876189  0.18260624 -0.18917959 -0.20080753\n",
      "  0.09708726 -0.29552036]\n",
      "Training Error:  9.801864300866256\n",
      "====================================================================================================\n",
      "Iteration:  445\n",
      "Previous theta :  [-0.01706313 -0.07190975  0.09391043 -0.01890948  0.09392341 -0.13388807\n",
      "  0.35681204 -0.07366181 -0.27876189  0.18260624 -0.18917959 -0.20080753\n",
      "  0.09708726 -0.29552036]\n",
      "New theta_0 : [-0.01705809 -0.07200337  0.09404981 -0.01898024  0.09392091 -0.13423065\n",
      "  0.35661087 -0.07357877 -0.27914851  0.18283808 -0.18922487 -0.20087004\n",
      "  0.09704149 -0.29564375]\n",
      "Training Error:  9.80144059422281\n",
      "====================================================================================================\n",
      "Iteration:  446\n",
      "Previous theta :  [-0.01705809 -0.07200337  0.09404981 -0.01898024  0.09392091 -0.13423065\n",
      "  0.35661087 -0.07357877 -0.27914851  0.18283808 -0.18922487 -0.20087004\n",
      "  0.09704149 -0.29564375]\n",
      "New theta_0 : [-0.01705309 -0.07209629  0.09418827 -0.01905     0.09391838 -0.13457093\n",
      "  0.35641124 -0.07349606 -0.27953207  0.18306867 -0.18927047 -0.20093212\n",
      "  0.09699607 -0.2957662 ]\n",
      "Training Error:  9.801022847357409\n",
      "====================================================================================================\n",
      "Iteration:  447\n",
      "Previous theta :  [-0.01705309 -0.07209629  0.09418827 -0.01905     0.09391838 -0.13457093\n",
      "  0.35641124 -0.07349606 -0.27953207  0.18306867 -0.18927047 -0.20093212\n",
      "  0.09699607 -0.2957662 ]\n",
      "New theta_0 : [-0.01704813 -0.07218852  0.09432581 -0.01911879  0.09391584 -0.13490892\n",
      "  0.35621314 -0.07341366 -0.27991258  0.18329803 -0.18931639 -0.20099378\n",
      "  0.09695097 -0.29588772]\n",
      "Training Error:  9.800610972512123\n",
      "====================================================================================================\n",
      "Iteration:  448\n",
      "Previous theta :  [-0.01704813 -0.07218852  0.09432581 -0.01911879  0.09391584 -0.13490892\n",
      "  0.35621314 -0.07341366 -0.27991258  0.18329803 -0.18931639 -0.20099378\n",
      "  0.09695097 -0.29588772]\n",
      "New theta_0 : [-0.01704321 -0.07228008  0.09446243 -0.01918661  0.09391328 -0.13524463\n",
      "  0.35601655 -0.07333158 -0.28029008  0.18352618 -0.18936263 -0.20105502\n",
      "  0.09690621 -0.29600832]\n",
      "Training Error:  9.800204883248567\n",
      "====================================================================================================\n",
      "Iteration:  449\n",
      "Previous theta :  [-0.01704321 -0.07228008  0.09446243 -0.01918661  0.09391328 -0.13524463\n",
      "  0.35601655 -0.07333158 -0.28029008  0.18352618 -0.18936263 -0.20105502\n",
      "  0.09690621 -0.29600832]\n",
      "New theta_0 : [-0.01703832 -0.07237095  0.09459814 -0.01925347  0.0939107  -0.13557809\n",
      "  0.35582146 -0.07324983 -0.28066458  0.18375311 -0.18940919 -0.20111584\n",
      "  0.09686177 -0.296128  ]\n",
      "Training Error:  9.79980449442779\n",
      "====================================================================================================\n",
      "Iteration:  450\n",
      "Previous theta :  [-0.01703832 -0.07237095  0.09459814 -0.01925347  0.0939107  -0.13557809\n",
      "  0.35582146 -0.07324983 -0.28066458  0.18375311 -0.18940919 -0.20111584\n",
      "  0.09686177 -0.296128  ]\n",
      "New theta_0 : [-0.01703348 -0.07246115  0.09473295 -0.01931938  0.0939081  -0.1359093\n",
      "  0.35562785 -0.0731684  -0.28103612  0.18397884 -0.18945605 -0.20117625\n",
      "  0.09681767 -0.29624677]\n",
      "Training Error:  9.799409722190505\n",
      "====================================================================================================\n",
      "Iteration:  451\n",
      "Previous theta :  [-0.01703348 -0.07246115  0.09473295 -0.01931938  0.0939081  -0.1359093\n",
      "  0.35562785 -0.0731684  -0.28103612  0.18397884 -0.18945605 -0.20117625\n",
      "  0.09681767 -0.29624677]\n",
      "New theta_0 : [-0.01702867 -0.07255068  0.09486686 -0.01938436  0.09390549 -0.13623828\n",
      "  0.35543573 -0.07308729 -0.2814047   0.18420337 -0.18950321 -0.20123625\n",
      "  0.09677389 -0.29636464]\n",
      "Training Error:  9.799020483937614\n",
      "====================================================================================================\n",
      "Iteration:  452\n",
      "Previous theta :  [-0.01702867 -0.07255068  0.09486686 -0.01938436  0.09390549 -0.13623828\n",
      "  0.35543573 -0.07308729 -0.2814047   0.18420337 -0.18950321 -0.20123625\n",
      "  0.09677389 -0.29636464]\n",
      "New theta_0 : [-0.01702391 -0.07263954  0.09499987 -0.0194484   0.09390286 -0.13656505\n",
      "  0.35524506 -0.0730065  -0.28177037  0.18442672 -0.18955068 -0.20129585\n",
      "  0.09673043 -0.29648162]\n",
      "Training Error:  9.79863669831102\n",
      "====================================================================================================\n",
      "Iteration:  453\n",
      "Previous theta :  [-0.01702391 -0.07263954  0.09499987 -0.0194484   0.09390286 -0.13656505\n",
      "  0.35524506 -0.0730065  -0.28177037  0.18442672 -0.18955068 -0.20129585\n",
      "  0.09673043 -0.29648162]\n",
      "New theta_0 : [-0.01701918 -0.07272775  0.095132   -0.01951153  0.09390021 -0.13688963\n",
      "  0.35505585 -0.07292604 -0.28213313  0.18464889 -0.18959844 -0.20135504\n",
      "  0.09668729 -0.29659772]\n",
      "Training Error:  9.798258285174759\n",
      "====================================================================================================\n",
      "Iteration:  454\n",
      "Previous theta :  [-0.01701918 -0.07272775  0.095132   -0.01951153  0.09390021 -0.13688963\n",
      "  0.35505585 -0.07292604 -0.28213313  0.18464889 -0.18959844 -0.20135504\n",
      "  0.09668729 -0.29659772]\n",
      "New theta_0 : [-0.01701449 -0.07281531  0.09526325 -0.01957374  0.09389755 -0.13721201\n",
      "  0.35486808 -0.0728459  -0.28249302  0.1848699  -0.1896465  -0.20141384\n",
      "  0.09664446 -0.29671294]\n",
      "Training Error:  9.797885165596393\n",
      "====================================================================================================\n",
      "Iteration:  455\n",
      "Previous theta :  [-0.01701449 -0.07281531  0.09526325 -0.01957374  0.09389755 -0.13721201\n",
      "  0.35486808 -0.0728459  -0.28249302  0.1848699  -0.1896465  -0.20141384\n",
      "  0.09664446 -0.29671294]\n",
      "New theta_0 : [-0.01700983 -0.07290221  0.09539362 -0.01963505  0.09389487 -0.13753223\n",
      "  0.35468173 -0.07276609 -0.28285006  0.18508974 -0.18969484 -0.20147224\n",
      "  0.09660196 -0.29682728]\n",
      "Training Error:  9.797517261828716\n",
      "====================================================================================================\n",
      "Iteration:  456\n",
      "Previous theta :  [-0.01700983 -0.07290221  0.09539362 -0.01963505  0.09389487 -0.13753223\n",
      "  0.35468173 -0.07276609 -0.28285006  0.18508974 -0.18969484 -0.20147224\n",
      "  0.09660196 -0.29682728]\n",
      "New theta_0 : [-0.01700522 -0.07298848  0.09552312 -0.01969546  0.09389218 -0.13785029\n",
      "  0.3544968  -0.0726866  -0.28320426  0.18530843 -0.18974347 -0.20153024\n",
      "  0.09655976 -0.29694077]\n",
      "Training Error:  9.797154497291732\n",
      "====================================================================================================\n",
      "Iteration:  457\n",
      "Previous theta :  [-0.01700522 -0.07298848  0.09552312 -0.01969546  0.09389218 -0.13785029\n",
      "  0.3544968  -0.0726866  -0.28320426  0.18530843 -0.18974347 -0.20153024\n",
      "  0.09655976 -0.29694077]\n",
      "New theta_0 : [-0.01700064 -0.0730741   0.09565175 -0.01975499  0.09388947 -0.13816621\n",
      "  0.35431328 -0.07260744 -0.28355566  0.18552598 -0.18979238 -0.20158786\n",
      "  0.09651788 -0.2970534 ]\n",
      "Training Error:  9.796796796554887\n",
      "====================================================================================================\n",
      "Iteration:  458\n",
      "Previous theta :  [-0.01700064 -0.0730741   0.09565175 -0.01975499  0.09388947 -0.13816621\n",
      "  0.35431328 -0.07260744 -0.28355566  0.18552598 -0.18979238 -0.20158786\n",
      "  0.09651788 -0.2970534 ]\n",
      "New theta_0 : [-0.01699609 -0.07315909  0.09577953 -0.01981364  0.09388674 -0.13848001\n",
      "  0.35413115 -0.07252861 -0.28390427  0.18574239 -0.18984157 -0.20164509\n",
      "  0.0964763  -0.29716518]\n",
      "Training Error:  9.796444085319624\n",
      "====================================================================================================\n",
      "Iteration:  459\n",
      "Previous theta :  [-0.01699609 -0.07315909  0.09577953 -0.01981364  0.09388674 -0.13848001\n",
      "  0.35413115 -0.07252861 -0.28390427  0.18574239 -0.18984157 -0.20164509\n",
      "  0.0964763  -0.29716518]\n",
      "New theta_0 : [-0.01699159 -0.07324346  0.09590645 -0.01987143  0.093884   -0.13879169\n",
      "  0.3539504  -0.0724501  -0.28425011  0.18595768 -0.18989103 -0.20170194\n",
      "  0.09643503 -0.29727612]\n",
      "Training Error:  9.796096290402158\n",
      "====================================================================================================\n",
      "Iteration:  460\n",
      "Previous theta :  [-0.01699159 -0.07324346  0.09590645 -0.01987143  0.093884   -0.13879169\n",
      "  0.3539504  -0.0724501  -0.28425011  0.18595768 -0.18989103 -0.20170194\n",
      "  0.09643503 -0.29727612]\n",
      "New theta_0 : [-0.01698712 -0.07332719  0.09603252 -0.01992835  0.09388125 -0.13910127\n",
      "  0.35377102 -0.07237191 -0.28459321  0.18617185 -0.18994076 -0.20175841\n",
      "  0.09639407 -0.29738622]\n",
      "Training Error:  9.795753339716534\n",
      "====================================================================================================\n",
      "Iteration:  461\n",
      "Previous theta :  [-0.01698712 -0.07332719  0.09603252 -0.01992835  0.09388125 -0.13910127\n",
      "  0.35377102 -0.07237191 -0.28459321  0.18617185 -0.18994076 -0.20175841\n",
      "  0.09639407 -0.29738622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01698268 -0.07341031  0.09615774 -0.01998442  0.09387848 -0.13940877\n",
      "  0.353593   -0.07229406 -0.2849336   0.1863849  -0.18999076 -0.2018145\n",
      "  0.0963534  -0.2974955 ]\n",
      "Training Error:  9.795415162257955\n",
      "====================================================================================================\n",
      "Iteration:  462\n",
      "Previous theta :  [-0.01698268 -0.07341031  0.09615774 -0.01998442  0.09387848 -0.13940877\n",
      "  0.353593   -0.07229406 -0.2849336   0.1863849  -0.18999076 -0.2018145\n",
      "  0.0963534  -0.2974955 ]\n",
      "New theta_0 : [-0.01697828 -0.07349282  0.09628213 -0.02003966  0.09387569 -0.1397142\n",
      "  0.35341633 -0.07221653 -0.28527128  0.18659685 -0.19004101 -0.20187022\n",
      "  0.09631303 -0.29760396]\n",
      "Training Error:  9.795081688086347\n",
      "====================================================================================================\n",
      "Iteration:  463\n",
      "Previous theta :  [-0.01697828 -0.07349282  0.09628213 -0.02003966  0.09387569 -0.1397142\n",
      "  0.35341633 -0.07221653 -0.28527128  0.18659685 -0.19004101 -0.20187022\n",
      "  0.09631303 -0.29760396]\n",
      "New theta_0 : [-0.01697392 -0.07357471  0.09640568 -0.02009405  0.09387289 -0.14001757\n",
      "  0.35324099 -0.07213932 -0.28560629  0.18680771 -0.19009153 -0.20192557\n",
      "  0.09627296 -0.29771161]\n",
      "Training Error:  9.794752848310194\n",
      "====================================================================================================\n",
      "Iteration:  464\n",
      "Previous theta :  [-0.01697392 -0.07357471  0.09640568 -0.02009405  0.09387289 -0.14001757\n",
      "  0.35324099 -0.07213932 -0.28560629  0.18680771 -0.19009153 -0.20192557\n",
      "  0.09627296 -0.29771161]\n",
      "New theta_0 : [-0.01696959 -0.073656    0.09652841 -0.02014762  0.09387008 -0.1403189\n",
      "  0.35306698 -0.07206245 -0.28593864  0.18701748 -0.1901423  -0.20198055\n",
      "  0.09623319 -0.29781845]\n",
      "Training Error:  9.79442857507061\n",
      "====================================================================================================\n",
      "Iteration:  465\n",
      "Previous theta :  [-0.01696959 -0.073656    0.09652841 -0.02014762  0.09387008 -0.1403189\n",
      "  0.35306698 -0.07206245 -0.28593864  0.18701748 -0.1901423  -0.20198055\n",
      "  0.09623319 -0.29781845]\n",
      "New theta_0 : [-0.01696529 -0.07373669  0.09665031 -0.02020038  0.09386725 -0.1406182\n",
      "  0.35289429 -0.0719859  -0.28626835  0.18722617 -0.19019333 -0.20203517\n",
      "  0.0961937  -0.29792449]\n",
      "Training Error:  9.794108801525653\n",
      "====================================================================================================\n",
      "Iteration:  466\n",
      "Previous theta :  [-0.01696529 -0.07373669  0.09665031 -0.02020038  0.09386725 -0.1406182\n",
      "  0.35289429 -0.0719859  -0.28626835  0.18722617 -0.19019333 -0.20203517\n",
      "  0.0961937  -0.29792449]\n",
      "New theta_0 : [-0.01696103 -0.07381679  0.0967714  -0.02025232  0.09386441 -0.14091549\n",
      "  0.3527229  -0.07190967 -0.28659545  0.18743378 -0.1902446  -0.20208943\n",
      "  0.09615451 -0.29802973]\n",
      "Training Error:  9.793793461834895\n",
      "====================================================================================================\n",
      "Iteration:  467\n",
      "Previous theta :  [-0.01696103 -0.07381679  0.0967714  -0.02025232  0.09386441 -0.14091549\n",
      "  0.3527229  -0.07190967 -0.28659545  0.18743378 -0.1902446  -0.20208943\n",
      "  0.09615451 -0.29802973]\n",
      "New theta_0 : [-0.01695681 -0.07389629  0.09689167 -0.02030346  0.09386156 -0.14121077\n",
      "  0.3525528  -0.07183378 -0.28691996  0.18764033 -0.19029612 -0.20214332\n",
      "  0.09611561 -0.29813419]\n",
      "Training Error:  9.793482491144212\n",
      "====================================================================================================\n",
      "Iteration:  468\n",
      "Previous theta :  [-0.01695681 -0.07389629  0.09689167 -0.02030346  0.09386156 -0.14121077\n",
      "  0.3525528  -0.07183378 -0.28691996  0.18764033 -0.19029612 -0.20214332\n",
      "  0.09611561 -0.29813419]\n",
      "New theta_0 : [-0.01695261 -0.07397521  0.09701114 -0.02035381  0.09385869 -0.14150406\n",
      "  0.35238399 -0.07175821 -0.28724189  0.18784583 -0.19034788 -0.20219686\n",
      "  0.09607699 -0.29823787]\n",
      "Training Error:  9.793175825570811\n",
      "====================================================================================================\n",
      "Iteration:  469\n",
      "Previous theta :  [-0.01695261 -0.07397521  0.09701114 -0.02035381  0.09385869 -0.14150406\n",
      "  0.35238399 -0.07175821 -0.28724189  0.18784583 -0.19034788 -0.20219686\n",
      "  0.09607699 -0.29823787]\n",
      "New theta_0 : [-0.01694846 -0.07405354  0.0971298  -0.02040337  0.09385581 -0.14179538\n",
      "  0.35221645 -0.07168297 -0.28756127  0.18805027 -0.19039987 -0.20225005\n",
      "  0.09603865 -0.29834078]\n",
      "Training Error:  9.792873402188507\n",
      "====================================================================================================\n",
      "Iteration:  470\n",
      "Previous theta :  [-0.01694846 -0.07405354  0.0971298  -0.02040337  0.09385581 -0.14179538\n",
      "  0.35221645 -0.07168297 -0.28756127  0.18805027 -0.19039987 -0.20225005\n",
      "  0.09603865 -0.29834078]\n",
      "New theta_0 : [-0.01694433 -0.07413129  0.09724767 -0.02045216  0.09385292 -0.14208473\n",
      "  0.35205017 -0.07160805 -0.28787812  0.18825367 -0.1904521  -0.20230289\n",
      "  0.0960006  -0.29844292]\n",
      "Training Error:  9.792575159013179\n",
      "====================================================================================================\n",
      "Iteration:  471\n",
      "Previous theta :  [-0.01694433 -0.07413129  0.09724767 -0.02045216  0.09385292 -0.14208473\n",
      "  0.35205017 -0.07160805 -0.28787812  0.18825367 -0.1904521  -0.20230289\n",
      "  0.0960006  -0.29844292]\n",
      "New theta_0 : [-0.01694024 -0.07420848  0.09736474 -0.02050018  0.09385002 -0.14237214\n",
      "  0.35188514 -0.07153346 -0.28819245  0.18845604 -0.19050456 -0.20235539\n",
      "  0.09596282 -0.2985443 ]\n",
      "Training Error:  9.792281034988509\n",
      "====================================================================================================\n",
      "Iteration:  472\n",
      "Previous theta :  [-0.01694024 -0.07420848  0.09736474 -0.02050018  0.09385002 -0.14237214\n",
      "  0.35188514 -0.07153346 -0.28819245  0.18845604 -0.19050456 -0.20235539\n",
      "  0.09596282 -0.2985443 ]\n",
      "New theta_0 : [-0.01693618 -0.07428509  0.09748103 -0.02054743  0.0938471  -0.14265761\n",
      "  0.35172136 -0.0714592  -0.2885043   0.18865738 -0.19055725 -0.20240754\n",
      "  0.09592532 -0.29864493]\n",
      "Training Error:  9.791990969971886\n",
      "====================================================================================================\n",
      "Iteration:  473\n",
      "Previous theta :  [-0.01693618 -0.07428509  0.09748103 -0.02054743  0.0938471  -0.14265761\n",
      "  0.35172136 -0.0714592  -0.2885043   0.18865738 -0.19055725 -0.20240754\n",
      "  0.09592532 -0.29864493]\n",
      "New theta_0 : [-0.01693215 -0.07436114  0.09759654 -0.02059393  0.09384417 -0.14294116\n",
      "  0.35155881 -0.07138526 -0.28881367  0.18885769 -0.19061017 -0.20245934\n",
      "  0.0958881  -0.2987448 ]\n",
      "Training Error:  9.791704904720563\n",
      "====================================================================================================\n",
      "Iteration:  474\n",
      "Previous theta :  [-0.01693215 -0.07436114  0.09759654 -0.02059393  0.09384417 -0.14294116\n",
      "  0.35155881 -0.07138526 -0.28881367  0.18885769 -0.19061017 -0.20245934\n",
      "  0.0958881  -0.2987448 ]\n",
      "New theta_0 : [-0.01692816 -0.07443662  0.09771127 -0.02063968  0.09384123 -0.14322279\n",
      "  0.35139748 -0.07131165 -0.28912058  0.189057   -0.1906633  -0.20251081\n",
      "  0.09585115 -0.29884394]\n",
      "Training Error:  9.791422780878008\n",
      "====================================================================================================\n",
      "Iteration:  475\n",
      "Previous theta :  [-0.01692816 -0.07443662  0.09771127 -0.02063968  0.09384123 -0.14322279\n",
      "  0.35139748 -0.07131165 -0.28912058  0.189057   -0.1906633  -0.20251081\n",
      "  0.09585115 -0.29884394]\n",
      "New theta_0 : [-0.01692419 -0.07451156  0.09782523 -0.02068469  0.09383827 -0.14350253\n",
      "  0.35123736 -0.07123837 -0.28942507  0.1892553  -0.19071665 -0.20256194\n",
      "  0.09581447 -0.29894234]\n",
      "Training Error:  9.791144540960463\n",
      "====================================================================================================\n",
      "Iteration:  476\n",
      "Previous theta :  [-0.01692419 -0.07451156  0.09782523 -0.02068469  0.09383827 -0.14350253\n",
      "  0.35123736 -0.07123837 -0.28942507  0.1892553  -0.19071665 -0.20256194\n",
      "  0.09581447 -0.29894234]\n",
      "New theta_0 : [-0.01692026 -0.07458594  0.09793842 -0.02072897  0.09383531 -0.14378039\n",
      "  0.35107844 -0.07116541 -0.28972714  0.18945259 -0.19077022 -0.20261274\n",
      "  0.09577806 -0.29904001]\n",
      "Training Error:  9.790870128343721\n",
      "====================================================================================================\n",
      "Iteration:  477\n",
      "Previous theta :  [-0.01692026 -0.07458594  0.09793842 -0.02072897  0.09383531 -0.14378039\n",
      "  0.35107844 -0.07116541 -0.28972714  0.18945259 -0.19077022 -0.20261274\n",
      "  0.09577806 -0.29904001]\n",
      "New theta_0 : [-0.01691636 -0.07465977  0.09805085 -0.02077252  0.09383233 -0.14405637\n",
      "  0.35092072 -0.07109278 -0.29002681  0.1896489  -0.190824   -0.20266321\n",
      "  0.09574192 -0.29913695]\n",
      "Training Error:  9.790599487250091\n",
      "====================================================================================================\n",
      "Iteration:  478\n",
      "Previous theta :  [-0.01691636 -0.07465977  0.09805085 -0.02077252  0.09383233 -0.14405637\n",
      "  0.35092072 -0.07109278 -0.29002681  0.1896489  -0.190824   -0.20266321\n",
      "  0.09574192 -0.29913695]\n",
      "New theta_0 : [-0.0169125  -0.07473306  0.09816253 -0.02081536  0.09382934 -0.14433049\n",
      "  0.35076418 -0.07102047 -0.29032411  0.18984422 -0.19087799 -0.20271335\n",
      "  0.09570605 -0.29923318]\n",
      "Training Error:  9.790332562735585\n",
      "====================================================================================================\n",
      "Iteration:  479\n",
      "Previous theta :  [-0.0169125  -0.07473306  0.09816253 -0.02081536  0.09382934 -0.14433049\n",
      "  0.35076418 -0.07102047 -0.29032411  0.18984422 -0.19087799 -0.20271335\n",
      "  0.09570605 -0.29923318]\n",
      "New theta_0 : [-0.01690866 -0.0748058   0.09827345 -0.02085749  0.09382634 -0.14460277\n",
      "  0.35060882 -0.07094848 -0.29061905  0.19003856 -0.19093218 -0.20276316\n",
      "  0.09567043 -0.2993287 ]\n",
      "Training Error:  9.790069300677267\n",
      "====================================================================================================\n",
      "Iteration:  480\n",
      "Previous theta :  [-0.01690866 -0.0748058   0.09827345 -0.02085749  0.09382634 -0.14460277\n",
      "  0.35060882 -0.07094848 -0.29061905  0.19003856 -0.19093218 -0.20276316\n",
      "  0.09567043 -0.2993287 ]\n",
      "New theta_0 : [-0.01690485 -0.07487802  0.09838362 -0.02089891  0.09382333 -0.14487321\n",
      "  0.35045461 -0.07087682 -0.29091165  0.19023193 -0.19098657 -0.20281265\n",
      "  0.09563508 -0.29942351]\n",
      "Training Error:  9.789809647760825\n",
      "====================================================================================================\n",
      "Iteration:  481\n",
      "Previous theta :  [-0.01690485 -0.07487802  0.09838362 -0.02089891  0.09382333 -0.14487321\n",
      "  0.35045461 -0.07087682 -0.29091165  0.19023193 -0.19098657 -0.20281265\n",
      "  0.09563508 -0.29942351]\n",
      "New theta_0 : [-0.01690108 -0.0749497   0.09849306 -0.02093964  0.09382031 -0.14514183\n",
      "  0.35030157 -0.07080549 -0.29120193  0.19042433 -0.19104117 -0.20286182\n",
      "  0.09559999 -0.29951761]\n",
      "Training Error:  9.789553551468318\n",
      "====================================================================================================\n",
      "Iteration:  482\n",
      "Previous theta :  [-0.01690108 -0.0749497   0.09849306 -0.02093964  0.09382031 -0.14514183\n",
      "  0.35030157 -0.07080549 -0.29120193  0.19042433 -0.19104117 -0.20286182\n",
      "  0.09559999 -0.29951761]\n",
      "New theta_0 : [-0.01689733 -0.07502086  0.09860176 -0.02097968  0.09381728 -0.14540863\n",
      "  0.35014966 -0.07073447 -0.29148991  0.19061578 -0.19109596 -0.20291068\n",
      "  0.09556515 -0.29961103]\n",
      "Training Error:  9.789300960066132\n",
      "====================================================================================================\n",
      "Iteration:  483\n",
      "Previous theta :  [-0.01689733 -0.07502086  0.09860176 -0.02097968  0.09381728 -0.14540863\n",
      "  0.35014966 -0.07073447 -0.29148991  0.19061578 -0.19109596 -0.20291068\n",
      "  0.09556515 -0.29961103]\n",
      "New theta_0 : [-0.01689362 -0.07509149  0.09870972 -0.02101904  0.09381423 -0.14567364\n",
      "  0.3499989  -0.07066378 -0.29177561  0.19080627 -0.19115094 -0.20295921\n",
      "  0.09553057 -0.29970376]\n",
      "Training Error:  9.789051822593079\n",
      "====================================================================================================\n",
      "Iteration:  484\n",
      "Previous theta :  [-0.01689362 -0.07509149  0.09870972 -0.02101904  0.09381423 -0.14567364\n",
      "  0.3499989  -0.07066378 -0.29177561  0.19080627 -0.19115094 -0.20295921\n",
      "  0.09553057 -0.29970376]\n",
      "New theta_0 : [-0.01688993 -0.0751616   0.09881696 -0.02105772  0.09381118 -0.14593687\n",
      "  0.34984926 -0.07059342 -0.29205904  0.19099582 -0.19120612 -0.20300744\n",
      "  0.09549625 -0.2997958 ]\n",
      "Training Error:  9.788806088848716\n",
      "====================================================================================================\n",
      "Iteration:  485\n",
      "Previous theta :  [-0.01688993 -0.0751616   0.09881696 -0.02105772  0.09381118 -0.14593687\n",
      "  0.34984926 -0.07059342 -0.29205904  0.19099582 -0.19120612 -0.20300744\n",
      "  0.09549625 -0.2997958 ]\n",
      "New theta_0 : [-0.01688628 -0.0752312   0.09892347 -0.02109573  0.09380812 -0.14619832\n",
      "  0.34970074 -0.07052337 -0.29234022  0.19118443 -0.19126148 -0.20305535\n",
      "  0.09546217 -0.29988716]\n",
      "Training Error:  9.788563709381833\n",
      "====================================================================================================\n",
      "Iteration:  486\n",
      "Previous theta :  [-0.01688628 -0.0752312   0.09892347 -0.02109573  0.09380812 -0.14619832\n",
      "  0.34970074 -0.07052337 -0.29234022  0.19118443 -0.19126148 -0.20305535\n",
      "  0.09546217 -0.29988716]\n",
      "New theta_0 : [-0.01688265 -0.07530029  0.09902927 -0.02113309  0.09380505 -0.146458\n",
      "  0.34955333 -0.07045364 -0.29261917  0.1913721  -0.19131703 -0.20310295\n",
      "  0.09542835 -0.29997785]\n",
      "Training Error:  9.788324635479107\n",
      "====================================================================================================\n",
      "Iteration:  487\n",
      "Previous theta :  [-0.01688265 -0.07530029  0.09902927 -0.02113309  0.09380505 -0.146458\n",
      "  0.34955333 -0.07045364 -0.29261917  0.1913721  -0.19131703 -0.20310295\n",
      "  0.09542835 -0.29997785]\n",
      "New theta_0 : [-0.01687906 -0.07536887  0.09913435 -0.02116979  0.09380196 -0.14671594\n",
      "  0.34940701 -0.07038424 -0.29289591  0.19155885 -0.19137276 -0.20315025\n",
      "  0.09539477 -0.30006788]\n",
      "Training Error:  9.788088819153932\n",
      "====================================================================================================\n",
      "Iteration:  488\n",
      "Previous theta :  [-0.01687906 -0.07536887  0.09913435 -0.02116979  0.09380196 -0.14671594\n",
      "  0.34940701 -0.07038424 -0.29289591  0.19155885 -0.19137276 -0.20315025\n",
      "  0.09539477 -0.30006788]\n",
      "New theta_0 : [-0.01687549 -0.07543695  0.09923873 -0.02120584  0.09379887 -0.14697214\n",
      "  0.34926179 -0.07031516 -0.29317046  0.19174468 -0.19142866 -0.20319725\n",
      "  0.09536144 -0.30015724]\n",
      "Training Error:  9.787856213135433\n",
      "====================================================================================================\n",
      "Iteration:  489\n",
      "Previous theta :  [-0.01687549 -0.07543695  0.09923873 -0.02120584  0.09379887 -0.14697214\n",
      "  0.34926179 -0.07031516 -0.29317046  0.19174468 -0.19142866 -0.20319725\n",
      "  0.09536144 -0.30015724]\n",
      "New theta_0 : [-0.01687195 -0.07550453  0.0993424  -0.02124125  0.09379577 -0.14722661\n",
      "  0.34911765 -0.07024639 -0.29344283  0.1919296  -0.19148475 -0.20324394\n",
      "  0.09532835 -0.30024595]\n",
      "Training Error:  9.787626770857635\n",
      "====================================================================================================\n",
      "Iteration:  490\n",
      "Previous theta :  [-0.01687195 -0.07550453  0.0993424  -0.02124125  0.09379577 -0.14722661\n",
      "  0.34911765 -0.07024639 -0.29344283  0.1919296  -0.19148475 -0.20324394\n",
      "  0.09532835 -0.30024595]\n",
      "New theta_0 : [-0.01686844 -0.07557161  0.09944537 -0.02127602  0.09379266 -0.14747936\n",
      "  0.34897459 -0.07017795 -0.29371304  0.19211361 -0.191541   -0.20329034\n",
      "  0.09529551 -0.30033401]\n",
      "Training Error:  9.787400446448798\n",
      "====================================================================================================\n",
      "Iteration:  491\n",
      "Previous theta :  [-0.01686844 -0.07557161  0.09944537 -0.02127602  0.09379266 -0.14747936\n",
      "  0.34897459 -0.07017795 -0.29371304  0.19211361 -0.191541   -0.20329034\n",
      "  0.09529551 -0.30033401]\n",
      "New theta_0 : [-0.01686496 -0.0756382   0.09954765 -0.02131017  0.09378954 -0.14773041\n",
      "  0.34883259 -0.07010982 -0.2939811   0.19229671 -0.19159743 -0.20333644\n",
      "  0.0952629  -0.30042142]\n",
      "Training Error:  9.787177194720924\n",
      "====================================================================================================\n",
      "Iteration:  492\n",
      "Previous theta :  [-0.01686496 -0.0756382   0.09954765 -0.02131017  0.09378954 -0.14773041\n",
      "  0.34883259 -0.07010982 -0.2939811   0.19229671 -0.19159743 -0.20333644\n",
      "  0.0952629  -0.30042142]\n",
      "New theta_0 : [-0.01686151 -0.0757043   0.09964924 -0.02134369  0.09378641 -0.14797977\n",
      "  0.34869164 -0.07004202 -0.29424704  0.19247893 -0.19165402 -0.20338224\n",
      "  0.09523054 -0.30050819]\n",
      "Training Error:  9.78695697115941\n",
      "====================================================================================================\n",
      "Iteration:  493\n",
      "Previous theta :  [-0.01686151 -0.0757043   0.09964924 -0.02134369  0.09378641 -0.14797977\n",
      "  0.34869164 -0.07004202 -0.29424704  0.19247893 -0.19165402 -0.20338224\n",
      "  0.09523054 -0.30050819]\n",
      "New theta_0 : [-0.01685808 -0.07576992  0.09975014 -0.0213766   0.09378327 -0.14822745\n",
      "  0.34855175 -0.06997453 -0.29451087  0.19266025 -0.19171078 -0.20342775\n",
      "  0.09519841 -0.30059433]\n",
      "Training Error:  9.786739731912878\n",
      "====================================================================================================\n",
      "Iteration:  494\n",
      "Previous theta :  [-0.01685808 -0.07576992  0.09975014 -0.0213766   0.09378327 -0.14822745\n",
      "  0.34855175 -0.06997453 -0.29451087  0.19266025 -0.19171078 -0.20342775\n",
      "  0.09519841 -0.30059433]\n",
      "New theta_0 : [-0.01685469 -0.07583506  0.09985037 -0.0214089   0.09378013 -0.14847346\n",
      "  0.34841289 -0.06990735 -0.29477261  0.19284069 -0.1917677  -0.20347297\n",
      "  0.09516652 -0.30067984]\n",
      "Training Error:  9.786525433783138\n",
      "====================================================================================================\n",
      "Iteration:  495\n",
      "Previous theta :  [-0.01685469 -0.07583506  0.09985037 -0.0214089   0.09378013 -0.14847346\n",
      "  0.34841289 -0.06990735 -0.29477261  0.19284069 -0.1917677  -0.20347297\n",
      "  0.09516652 -0.30067984]\n",
      "New theta_0 : [-0.01685132 -0.07589972  0.09994991 -0.0214406   0.09377697 -0.14871781\n",
      "  0.34827507 -0.06984049 -0.29503227  0.19302026 -0.19182478 -0.20351791\n",
      "  0.09513486 -0.30076472]\n",
      "Training Error:  9.786314034215321\n",
      "====================================================================================================\n",
      "Iteration:  496\n",
      "Previous theta :  [-0.01685132 -0.07589972  0.09994991 -0.0214406   0.09377697 -0.14871781\n",
      "  0.34827507 -0.06984049 -0.29503227  0.19302026 -0.19182478 -0.20351791\n",
      "  0.09513486 -0.30076472]\n",
      "New theta_0 : [-0.01684797 -0.07596391  0.10004879 -0.0214717   0.09377381 -0.14896051\n",
      "  0.34813827 -0.06977395 -0.29528988  0.19319895 -0.19188202 -0.20356256\n",
      "  0.09510343 -0.30084898]\n",
      "Training Error:  9.786105491288165\n",
      "====================================================================================================\n",
      "Iteration:  497\n",
      "Previous theta :  [-0.01684797 -0.07596391  0.10004879 -0.0214717   0.09377381 -0.14896051\n",
      "  0.34813827 -0.06977395 -0.29528988  0.19319895 -0.19188202 -0.20356256\n",
      "  0.09510343 -0.30084898]\n",
      "New theta_0 : [-0.01684466 -0.07602763  0.10014699 -0.02150221  0.09377064 -0.14920157\n",
      "  0.34800248 -0.06970772 -0.29554544  0.19337678 -0.19193941 -0.20360692\n",
      "  0.09507224 -0.30093263]\n",
      "Training Error:  9.785899763704425\n",
      "====================================================================================================\n",
      "Iteration:  498\n",
      "Previous theta :  [-0.01684466 -0.07602763  0.10014699 -0.02150221  0.09377064 -0.14920157\n",
      "  0.34800248 -0.06970772 -0.29554544  0.19337678 -0.19193941 -0.20360692\n",
      "  0.09507224 -0.30093263]\n",
      "New theta_0 : [-0.01684137 -0.07609088  0.10024454 -0.02153214  0.09376746 -0.14944101\n",
      "  0.3478677  -0.06964181 -0.29579897  0.19355375 -0.19199696 -0.203651\n",
      "  0.09504127 -0.30101566]\n",
      "Training Error:  9.785696810781465\n",
      "====================================================================================================\n",
      "Iteration:  499\n",
      "Previous theta :  [-0.01684137 -0.07609088  0.10024454 -0.02153214  0.09376746 -0.14944101\n",
      "  0.3478677  -0.06964181 -0.29579897  0.19355375 -0.19199696 -0.203651\n",
      "  0.09504127 -0.30101566]\n",
      "New theta_0 : [-0.01683811 -0.07615367  0.10034143 -0.02156149  0.09376427 -0.14967884\n",
      "  0.34773392 -0.06957621 -0.29605049  0.19372986 -0.19205465 -0.20369481\n",
      "  0.09501053 -0.30109809]\n",
      "Training Error:  9.78549659244196\n",
      "====================================================================================================\n",
      "Iteration:  500\n",
      "Previous theta :  [-0.01683811 -0.07615367  0.10034143 -0.02156149  0.09376427 -0.14967884\n",
      "  0.34773392 -0.06957621 -0.29605049  0.19372986 -0.19205465 -0.20369481\n",
      "  0.09501053 -0.30109809]\n",
      "New theta_0 : [-0.01683487 -0.076216    0.10043766 -0.02159027  0.09376108 -0.14991506\n",
      "  0.34760113 -0.06951092 -0.29630001  0.19390513 -0.19211249 -0.20373834\n",
      "  0.09498001 -0.30117993]\n",
      "Training Error:  9.78529906920476\n",
      "====================================================================================================\n",
      "Iteration:  501\n",
      "Previous theta :  [-0.01683487 -0.076216    0.10043766 -0.02159027  0.09376108 -0.14991506\n",
      "  0.34760113 -0.06951092 -0.29630001  0.19390513 -0.19211249 -0.20373834\n",
      "  0.09498001 -0.30117993]\n",
      "New theta_0 : [-0.01683166 -0.07627788  0.10053324 -0.02161848  0.09375788 -0.15014969\n",
      "  0.34746932 -0.06944594 -0.29654756  0.19407956 -0.19217048 -0.20378159\n",
      "  0.09494972 -0.30126116]\n",
      "Training Error:  9.785104202175894\n",
      "====================================================================================================\n",
      "Iteration:  502\n",
      "Previous theta :  [-0.01683166 -0.07627788  0.10053324 -0.02161848  0.09375788 -0.15014969\n",
      "  0.34746932 -0.06944594 -0.29654756  0.19407956 -0.19217048 -0.20378159\n",
      "  0.09494972 -0.30126116]\n",
      "New theta_0 : [-0.01682848 -0.0763393   0.10062818 -0.02164613  0.09375467 -0.15038273\n",
      "  0.34733849 -0.06938128 -0.29679314  0.19425315 -0.1922286  -0.20382457\n",
      "  0.09491965 -0.30134181]\n",
      "Training Error:  9.784911953039694\n",
      "====================================================================================================\n",
      "Iteration:  503\n",
      "Previous theta :  [-0.01682848 -0.0763393   0.10062818 -0.02164613  0.09375467 -0.15038273\n",
      "  0.34733849 -0.06938128 -0.29679314  0.19425315 -0.1922286  -0.20382457\n",
      "  0.09491965 -0.30134181]\n",
      "New theta_0 : [-0.01682532 -0.07640028  0.10072248 -0.02167322  0.09375145 -0.15061421\n",
      "  0.34720863 -0.06931692 -0.29703678  0.19442591 -0.19228687 -0.20386728\n",
      "  0.09488979 -0.30142187]\n",
      "Training Error:  9.784722284050071\n",
      "====================================================================================================\n",
      "Iteration:  504\n",
      "Previous theta :  [-0.01682532 -0.07640028  0.10072248 -0.02167322  0.09375145 -0.15061421\n",
      "  0.34720863 -0.06931692 -0.29703678  0.19442591 -0.19228687 -0.20386728\n",
      "  0.09488979 -0.30142187]\n",
      "New theta_0 : [-0.01682219 -0.07646081  0.10081614 -0.02169977  0.09374823 -0.15084412\n",
      "  0.34707973 -0.06925288 -0.29727848  0.19459784 -0.19234527 -0.20390971\n",
      "  0.09486016 -0.30150134]\n",
      "Training Error:  9.784535158021923\n",
      "====================================================================================================\n",
      "Iteration:  505\n",
      "Previous theta :  [-0.01682219 -0.07646081  0.10081614 -0.02169977  0.09374823 -0.15084412\n",
      "  0.34707973 -0.06925288 -0.29727848  0.19459784 -0.19234527 -0.20390971\n",
      "  0.09486016 -0.30150134]\n",
      "New theta_0 : [-0.01681909 -0.0765209   0.10090917 -0.02172577  0.093745   -0.15107248\n",
      "  0.34695177 -0.06918914 -0.29751827  0.19476895 -0.19240381 -0.20395189\n",
      "  0.09483075 -0.30158025]\n",
      "Training Error:  9.784350538322657\n",
      "====================================================================================================\n",
      "Iteration:  506\n",
      "Previous theta :  [-0.01681909 -0.0765209   0.10090917 -0.02172577  0.093745   -0.15107248\n",
      "  0.34695177 -0.06918914 -0.29751827  0.19476895 -0.19240381 -0.20395189\n",
      "  0.09483075 -0.30158025]\n",
      "New theta_0 : [-0.01681601 -0.07658055  0.10100157 -0.02175124  0.09374176 -0.15129931\n",
      "  0.34682477 -0.06912571 -0.29775615  0.19493925 -0.19246247 -0.20399379\n",
      "  0.09480154 -0.30165857]\n",
      "Training Error:  9.784168388863879\n",
      "====================================================================================================\n",
      "Iteration:  507\n",
      "Previous theta :  [-0.01681601 -0.07658055  0.10100157 -0.02175124  0.09374176 -0.15129931\n",
      "  0.34682477 -0.06912571 -0.29775615  0.19493925 -0.19246247 -0.20399379\n",
      "  0.09480154 -0.30165857]\n",
      "New theta_0 : [-0.01681295 -0.07663977  0.10109334 -0.02177618  0.09373851 -0.1515246\n",
      "  0.3466987  -0.06906258 -0.29799214  0.19510874 -0.19252127 -0.20403544\n",
      "  0.09477256 -0.30173634]\n",
      "Training Error:  9.78398867409314\n",
      "====================================================================================================\n",
      "Iteration:  508\n",
      "Previous theta :  [-0.01681295 -0.07663977  0.10109334 -0.02177618  0.09373851 -0.1515246\n",
      "  0.3466987  -0.06906258 -0.29799214  0.19510874 -0.19252127 -0.20403544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.09477256 -0.30173634]\n",
      "New theta_0 : [-0.01680992 -0.07669856  0.1011845  -0.02180059  0.09373526 -0.15174837\n",
      "  0.34657356 -0.06899977 -0.29822626  0.19527743 -0.1925802  -0.20407682\n",
      "  0.09474378 -0.30181353]\n",
      "Training Error:  9.783811358985899\n",
      "====================================================================================================\n",
      "Iteration:  509\n",
      "Previous theta :  [-0.01680992 -0.07669856  0.1011845  -0.02180059  0.09373526 -0.15174837\n",
      "  0.34657356 -0.06899977 -0.29822626  0.19527743 -0.1925802  -0.20407682\n",
      "  0.09474378 -0.30181353]\n",
      "New theta_0 : [-0.01680692 -0.07675691  0.10127504 -0.02182447  0.09373201 -0.15197063\n",
      "  0.34644934 -0.06893725 -0.29845853  0.19544532 -0.19263925 -0.20411794\n",
      "  0.09471522 -0.30189017]\n",
      "Training Error:  9.783636409037532\n",
      "====================================================================================================\n",
      "Iteration:  510\n",
      "Previous theta :  [-0.01680692 -0.07675691  0.10127504 -0.02182447  0.09373201 -0.15197063\n",
      "  0.34644934 -0.06893725 -0.29845853  0.19544532 -0.19263925 -0.20411794\n",
      "  0.09471522 -0.30189017]\n",
      "New theta_0 : [-0.01680394 -0.07681485  0.10136497 -0.02184785  0.09372874 -0.1521914\n",
      "  0.34632604 -0.06887505 -0.29868895  0.19561242 -0.19269842 -0.20415881\n",
      "  0.09468686 -0.30196626]\n",
      "Training Error:  9.783463790255512\n",
      "====================================================================================================\n",
      "Iteration:  511\n",
      "Previous theta :  [-0.01680394 -0.07681485  0.10136497 -0.02184785  0.09372874 -0.1521914\n",
      "  0.34632604 -0.06887505 -0.29868895  0.19561242 -0.19269842 -0.20415881\n",
      "  0.09468686 -0.30196626]\n",
      "New theta_0 : [-0.01680098 -0.07687236  0.1014543  -0.02187071  0.09372547 -0.15241068\n",
      "  0.34620365 -0.06881314 -0.29891755  0.19577873 -0.19275771 -0.20419942\n",
      "  0.09465871 -0.3020418 ]\n",
      "Training Error:  9.783293469151667\n",
      "====================================================================================================\n",
      "Iteration:  512\n",
      "Previous theta :  [-0.01680098 -0.07687236  0.1014543  -0.02187071  0.09372547 -0.15241068\n",
      "  0.34620365 -0.06881314 -0.29891755  0.19577873 -0.19275771 -0.20419942\n",
      "  0.09465871 -0.3020418 ]\n",
      "New theta_0 : [-0.01679805 -0.07692945  0.10154302 -0.02189307  0.0937222  -0.15262847\n",
      "  0.34608215 -0.06875154 -0.29914433  0.19594425 -0.19281712 -0.20423978\n",
      "  0.09463077 -0.30211679]\n",
      "Training Error:  9.783125412734602\n",
      "====================================================================================================\n",
      "Iteration:  513\n",
      "Previous theta :  [-0.01679805 -0.07692945  0.10154302 -0.02189307  0.0937222  -0.15262847\n",
      "  0.34608215 -0.06875154 -0.29914433  0.19594425 -0.19281712 -0.20423978\n",
      "  0.09463077 -0.30211679]\n",
      "New theta_0 : [-0.01679514 -0.07698613  0.10163114 -0.02191493  0.09371892 -0.1528448\n",
      "  0.34596155 -0.06869024 -0.29936931  0.196109   -0.19287665 -0.20427989\n",
      "  0.09460303 -0.30219124]\n",
      "Training Error:  9.78295958850218\n",
      "====================================================================================================\n",
      "Iteration:  514\n",
      "Previous theta :  [-0.01679514 -0.07698613  0.10163114 -0.02191493  0.09371892 -0.1528448\n",
      "  0.34596155 -0.06869024 -0.29936931  0.196109   -0.19287665 -0.20427989\n",
      "  0.09460303 -0.30219124]\n",
      "New theta_0 : [-0.01679226 -0.0770424   0.10171867 -0.0219363   0.09371563 -0.15305967\n",
      "  0.34584184 -0.06862924 -0.2995925   0.19627298 -0.19293629 -0.20431974\n",
      "  0.0945755  -0.30226515]\n",
      "Training Error:  9.782795964434191\n",
      "====================================================================================================\n",
      "Iteration:  515\n",
      "Previous theta :  [-0.01679226 -0.0770424   0.10171867 -0.0219363   0.09371563 -0.15305967\n",
      "  0.34584184 -0.06862924 -0.2995925   0.19627298 -0.19293629 -0.20431974\n",
      "  0.0945755  -0.30226515]\n",
      "New theta_0 : [-0.0167894  -0.07709825  0.10180561 -0.02195717  0.09371233 -0.15327309\n",
      "  0.345723   -0.06856854 -0.29981393  0.19643619 -0.19299604 -0.20435935\n",
      "  0.09454816 -0.30233853]\n",
      "Training Error:  9.78263450898506\n",
      "====================================================================================================\n",
      "Iteration:  516\n",
      "Previous theta :  [-0.0167894  -0.07709825  0.10180561 -0.02195717  0.09371233 -0.15327309\n",
      "  0.345723   -0.06856854 -0.29981393  0.19643619 -0.19299604 -0.20435935\n",
      "  0.09454816 -0.30233853]\n",
      "New theta_0 : [-0.01678656 -0.0771537   0.10189196 -0.02197757  0.09370904 -0.15348507\n",
      "  0.34560504 -0.06850814 -0.30003359  0.19659864 -0.19305591 -0.20439871\n",
      "  0.09452103 -0.30241138]\n",
      "Training Error:  9.7824751910767\n",
      "====================================================================================================\n",
      "Iteration:  517\n",
      "Previous theta :  [-0.01678656 -0.0771537   0.10189196 -0.02197757  0.09370904 -0.15348507\n",
      "  0.34560504 -0.06850814 -0.30003359  0.19659864 -0.19305591 -0.20439871\n",
      "  0.09452103 -0.30241138]\n",
      "New theta_0 : [-0.01678375 -0.07720875  0.10197773 -0.02199749  0.09370573 -0.15369562\n",
      "  0.34548795 -0.06844803 -0.30025152  0.19676033 -0.19311587 -0.20443783\n",
      "  0.09449409 -0.30248371]\n",
      "Training Error:  9.782317980091484\n",
      "====================================================================================================\n",
      "Iteration:  518\n",
      "Previous theta :  [-0.01678375 -0.07720875  0.10197773 -0.02199749  0.09370573 -0.15369562\n",
      "  0.34548795 -0.06844803 -0.30025152  0.19676033 -0.19311587 -0.20443783\n",
      "  0.09449409 -0.30248371]\n",
      "New theta_0 : [-0.01678096 -0.0772634   0.10206292 -0.02201693  0.09370242 -0.15390474\n",
      "  0.34537171 -0.06838823 -0.30046771  0.19692126 -0.19317595 -0.2044767\n",
      "  0.09446736 -0.30255551]\n",
      "Training Error:  9.782162845865304\n",
      "====================================================================================================\n",
      "Iteration:  519\n",
      "Previous theta :  [-0.01678096 -0.0772634   0.10206292 -0.02201693  0.09370242 -0.15390474\n",
      "  0.34537171 -0.06838823 -0.30046771  0.19692126 -0.19317595 -0.2044767\n",
      "  0.09446736 -0.30255551]\n",
      "New theta_0 : [-0.01677819 -0.07731766  0.10214753 -0.0220359   0.09369911 -0.15411246\n",
      "  0.34525632 -0.06832872 -0.30068219  0.19708146 -0.19323612 -0.20451533\n",
      "  0.09444081 -0.3026268 ]\n",
      "Training Error:  9.782009758680736\n",
      "====================================================================================================\n",
      "Iteration:  520\n",
      "Previous theta :  [-0.01677819 -0.07731766  0.10214753 -0.0220359   0.09369911 -0.15411246\n",
      "  0.34525632 -0.06832872 -0.30068219  0.19708146 -0.19323612 -0.20451533\n",
      "  0.09444081 -0.3026268 ]\n",
      "New theta_0 : [-0.01677544 -0.07737152  0.10223158 -0.02205442  0.09369579 -0.15431878\n",
      "  0.34514179 -0.0682695  -0.30089496  0.1972409  -0.1932964  -0.20455373\n",
      "  0.09441446 -0.30269758]\n",
      "Training Error:  9.781858689260332\n",
      "====================================================================================================\n",
      "Iteration:  521\n",
      "Previous theta :  [-0.01677544 -0.07737152  0.10223158 -0.02205442  0.09369579 -0.15431878\n",
      "  0.34514179 -0.0682695  -0.30089496  0.1972409  -0.1932964  -0.20455373\n",
      "  0.09441446 -0.30269758]\n",
      "New theta_0 : [-0.01677272 -0.07742499  0.10231506 -0.02207247  0.09369246 -0.15452371\n",
      "  0.34502808 -0.06821058 -0.30110605  0.19739962 -0.19335678 -0.20459188\n",
      "  0.09438831 -0.30276785]\n",
      "Training Error:  9.78170960875998\n",
      "====================================================================================================\n",
      "Iteration:  522\n",
      "Previous theta :  [-0.01677272 -0.07742499  0.10231506 -0.02207247  0.09369246 -0.15452371\n",
      "  0.34502808 -0.06821058 -0.30110605  0.19739962 -0.19335678 -0.20459188\n",
      "  0.09438831 -0.30276785]\n",
      "New theta_0 : [-0.01677002 -0.07747807  0.10239797 -0.02209007  0.09368914 -0.15472725\n",
      "  0.34491522 -0.06815195 -0.30131546  0.1975576  -0.19341725 -0.2046298\n",
      "  0.09436234 -0.30283762]\n",
      "Training Error:  9.781562488762386\n",
      "====================================================================================================\n",
      "Iteration:  523\n",
      "Previous theta :  [-0.01677002 -0.07747807  0.10239797 -0.02209007  0.09368914 -0.15472725\n",
      "  0.34491522 -0.06815195 -0.30131546  0.1975576  -0.19341725 -0.2046298\n",
      "  0.09436234 -0.30283762]\n",
      "New theta_0 : [-0.01676735 -0.07753077  0.10248033 -0.02210723  0.0936858  -0.15492942\n",
      "  0.34480317 -0.06809362 -0.30152321  0.19771485 -0.19347782 -0.20466749\n",
      "  0.09433656 -0.30290689]\n",
      "Training Error:  9.78141730127067\n",
      "====================================================================================================\n",
      "Iteration:  524\n",
      "Previous theta :  [-0.01676735 -0.07753077  0.10248033 -0.02210723  0.0936858  -0.15492942\n",
      "  0.34480317 -0.06809362 -0.30152321  0.19771485 -0.19347782 -0.20466749\n",
      "  0.09433656 -0.30290689]\n",
      "New theta_0 : [-0.01676469 -0.07758309  0.10256213 -0.02212393  0.09368246 -0.15513022\n",
      "  0.34469195 -0.06803557 -0.30172931  0.19787137 -0.19353848 -0.20470494\n",
      "  0.09431098 -0.30297566]\n",
      "Training Error:  9.781274018702012\n",
      "====================================================================================================\n",
      "Iteration:  525\n",
      "Previous theta :  [-0.01676469 -0.07758309  0.10256213 -0.02212393  0.09368246 -0.15513022\n",
      "  0.34469195 -0.06803557 -0.30172931  0.19787137 -0.19353848 -0.20470494\n",
      "  0.09431098 -0.30297566]\n",
      "New theta_0 : [-0.01676206 -0.07763503  0.10264338 -0.02214021  0.09367912 -0.15532967\n",
      "  0.34458154 -0.06797782 -0.30193378  0.19802718 -0.19359923 -0.20474216\n",
      "  0.09428557 -0.30304393]\n",
      "Training Error:  9.781132613881445\n",
      "====================================================================================================\n",
      "Iteration:  526\n",
      "Previous theta :  [-0.01676206 -0.07763503  0.10264338 -0.02214021  0.09367912 -0.15532967\n",
      "  0.34458154 -0.06797782 -0.30193378  0.19802718 -0.19359923 -0.20474216\n",
      "  0.09428557 -0.30304393]\n",
      "New theta_0 : [-0.01675945 -0.07768659  0.10272408 -0.02215604  0.09367577 -0.15552778\n",
      "  0.34447193 -0.06792035 -0.30213662  0.19818228 -0.19366007 -0.20477916\n",
      "  0.09426036 -0.30311172]\n",
      "Training Error:  9.780993060035708\n",
      "====================================================================================================\n",
      "Iteration:  527\n",
      "Previous theta :  [-0.01675945 -0.07768659  0.10272408 -0.02215604  0.09367577 -0.15552778\n",
      "  0.34447193 -0.06792035 -0.30213662  0.19818228 -0.19366007 -0.20477916\n",
      "  0.09426036 -0.30311172]\n",
      "New theta_0 : [-0.01675686 -0.07773778  0.10280423 -0.02217145  0.09367242 -0.15572455\n",
      "  0.34436313 -0.06786317 -0.30233785  0.19833666 -0.19372099 -0.20481592\n",
      "  0.09423533 -0.30317903]\n",
      "Training Error:  9.780855330787224\n",
      "====================================================================================================\n",
      "Iteration:  528\n",
      "Previous theta :  [-0.01675686 -0.07773778  0.10280423 -0.02217145  0.09367242 -0.15572455\n",
      "  0.34436313 -0.06786317 -0.30233785  0.19833666 -0.19372099 -0.20481592\n",
      "  0.09423533 -0.30317903]\n",
      "New theta_0 : [-0.01675429 -0.0777886   0.10288385 -0.02218643  0.09366907 -0.15591999\n",
      "  0.34425512 -0.06780628 -0.30253748  0.19849034 -0.193782   -0.20485246\n",
      "  0.09421048 -0.30324585]\n",
      "Training Error:  9.780719400148127\n",
      "====================================================================================================\n",
      "Iteration:  529\n",
      "Previous theta :  [-0.01675429 -0.0777886   0.10288385 -0.02218643  0.09366907 -0.15591999\n",
      "  0.34425512 -0.06780628 -0.30253748  0.19849034 -0.193782   -0.20485246\n",
      "  0.09421048 -0.30324585]\n",
      "New theta_0 : [-0.01675175 -0.07783906  0.10296293 -0.02220099  0.09366571 -0.15611411\n",
      "  0.3441479  -0.06774968 -0.30273553  0.19864333 -0.19384309 -0.20488878\n",
      "  0.09418581 -0.3033122 ]\n",
      "Training Error:  9.780585242514421\n",
      "====================================================================================================\n",
      "Iteration:  530\n",
      "Previous theta :  [-0.01675175 -0.07783906  0.10296293 -0.02220099  0.09366571 -0.15611411\n",
      "  0.3441479  -0.06774968 -0.30273553  0.19864333 -0.19384309 -0.20488878\n",
      "  0.09418581 -0.3033122 ]\n",
      "New theta_0 : [-0.01674922 -0.07788915  0.10304148 -0.02221514  0.09366234 -0.15630693\n",
      "  0.34404146 -0.06769336 -0.302932    0.19879561 -0.19390427 -0.20492487\n",
      "  0.09416132 -0.30337807]\n",
      "Training Error:  9.7804528326602\n",
      "====================================================================================================\n",
      "Iteration:  531\n",
      "Previous theta :  [-0.01674922 -0.07788915  0.10304148 -0.02221514  0.09366234 -0.15630693\n",
      "  0.34404146 -0.06769336 -0.302932    0.19879561 -0.19390427 -0.20492487\n",
      "  0.09416132 -0.30337807]\n",
      "New theta_0 : [-0.01674672 -0.07793888  0.1031195  -0.02222888  0.09365898 -0.15649844\n",
      "  0.34393579 -0.06763733 -0.30312692  0.1989472  -0.19396552 -0.20496074\n",
      "  0.09413702 -0.30344347]\n",
      "Training Error:  9.780322145731976\n",
      "====================================================================================================\n",
      "Iteration:  532\n",
      "Previous theta :  [-0.01674672 -0.07793888  0.1031195  -0.02222888  0.09365898 -0.15649844\n",
      "  0.34393579 -0.06763733 -0.30312692  0.1989472  -0.19396552 -0.20496074\n",
      "  0.09413702 -0.30344347]\n",
      "New theta_0 : [-0.01674424 -0.07798825  0.103197   -0.02224221  0.09365561 -0.15668866\n",
      "  0.34383089 -0.06758157 -0.30332029  0.19909811 -0.19402685 -0.20499639\n",
      "  0.09411289 -0.30350841]\n",
      "Training Error:  9.780193157243076\n",
      "====================================================================================================\n",
      "Iteration:  533\n",
      "Previous theta :  [-0.01674424 -0.07798825  0.103197   -0.02224221  0.09365561 -0.15668866\n",
      "  0.34383089 -0.06758157 -0.30332029  0.19909811 -0.19402685 -0.20499639\n",
      "  0.09411289 -0.30350841]\n",
      "New theta_0 : [-0.01674177 -0.07803726  0.10327397 -0.02225513  0.09365223 -0.1568776\n",
      "  0.34372676 -0.0675261  -0.30351212  0.19924834 -0.19408826 -0.20503182\n",
      "  0.09408893 -0.30357289]\n",
      "Training Error:  9.780065843068137\n",
      "====================================================================================================\n",
      "Iteration:  534\n",
      "Previous theta :  [-0.01674177 -0.07803726  0.10327397 -0.02225513  0.09365223 -0.1568776\n",
      "  0.34372676 -0.0675261  -0.30351212  0.19924834 -0.19408826 -0.20503182\n",
      "  0.09408893 -0.30357289]\n",
      "New theta_0 : [-0.01673933 -0.07808592  0.10335042 -0.02226766  0.09364886 -0.15706526\n",
      "  0.34362338 -0.06747091 -0.30370243  0.19939788 -0.19414973 -0.20506704\n",
      "  0.09406515 -0.3036369 ]\n",
      "Training Error:  9.77994017943767\n",
      "====================================================================================================\n",
      "Iteration:  535\n",
      "Previous theta :  [-0.01673933 -0.07808592  0.10335042 -0.02226766  0.09364886 -0.15706526\n",
      "  0.34362338 -0.06747091 -0.30370243  0.19939788 -0.19414973 -0.20506704\n",
      "  0.09406515 -0.3036369 ]\n",
      "New theta_0 : [-0.01673691 -0.07813424  0.10342636 -0.0222798   0.09364547 -0.15725166\n",
      "  0.34352076 -0.067416   -0.30389122  0.19954676 -0.19421128 -0.20510204\n",
      "  0.09404155 -0.30370046]\n",
      "Training Error:  9.779816142932725\n",
      "====================================================================================================\n",
      "Iteration:  536\n",
      "Previous theta :  [-0.01673691 -0.07813424  0.10342636 -0.0222798   0.09364547 -0.15725166\n",
      "  0.34352076 -0.067416   -0.30389122  0.19954676 -0.19421128 -0.20510204\n",
      "  0.09404155 -0.30370046]\n",
      "New theta_0 : [-0.01673451 -0.0781822   0.10350179 -0.02229155  0.09364209 -0.15743679\n",
      "  0.34341888 -0.06736137 -0.30407852  0.19969496 -0.1942729  -0.20513683\n",
      "  0.09401811 -0.30376357]\n",
      "Training Error:  9.77969371047963\n",
      "====================================================================================================\n",
      "Iteration:  537\n",
      "Previous theta :  [-0.01673451 -0.0781822   0.10350179 -0.02229155  0.09364209 -0.15743679\n",
      "  0.34341888 -0.06736137 -0.30407852  0.19969496 -0.1942729  -0.20513683\n",
      "  0.09401811 -0.30376357]\n",
      "New theta_0 : [-0.01673213 -0.07822982  0.10357671 -0.02230291  0.0936387  -0.15762068\n",
      "  0.34331774 -0.06730702 -0.30426433  0.1998425  -0.19433459 -0.2051714\n",
      "  0.09399485 -0.30382623]\n",
      "Training Error:  9.779572859344794\n",
      "====================================================================================================\n",
      "Iteration:  538\n",
      "Previous theta :  [-0.01673213 -0.07822982  0.10357671 -0.02230291  0.0936387  -0.15762068\n",
      "  0.34331774 -0.06730702 -0.30426433  0.1998425  -0.19433459 -0.2051714\n",
      "  0.09399485 -0.30382623]\n",
      "New theta_0 : [-0.01672977 -0.07827709  0.10365113 -0.02231389  0.09363531 -0.15780333\n",
      "  0.34321733 -0.06725295 -0.30444867  0.19998937 -0.19439635 -0.20520577\n",
      "  0.09397175 -0.30388844]\n",
      "Training Error:  9.779453567129611\n",
      "====================================================================================================\n",
      "Iteration:  539\n",
      "Previous theta :  [-0.01672977 -0.07827709  0.10365113 -0.02231389  0.09363531 -0.15780333\n",
      "  0.34321733 -0.06725295 -0.30444867  0.19998937 -0.19439635 -0.20520577\n",
      "  0.09397175 -0.30388844]\n",
      "New theta_0 : [-0.01672743 -0.07832403  0.10372505 -0.0223245   0.09363192 -0.15798475\n",
      "  0.34311765 -0.06719915 -0.30463154  0.20013559 -0.19445817 -0.20523992\n",
      "  0.09394883 -0.30395022]\n",
      "Training Error:  9.779335811765442\n",
      "====================================================================================================\n",
      "Iteration:  540\n",
      "Previous theta :  [-0.01672743 -0.07832403  0.10372505 -0.0223245   0.09363192 -0.15798475\n",
      "  0.34311765 -0.06719915 -0.30463154  0.20013559 -0.19445817 -0.20523992\n",
      "  0.09394883 -0.30395022]\n",
      "New theta_0 : [-0.01672511 -0.07837063  0.10379847 -0.02233473  0.09362852 -0.15816494\n",
      "  0.3430187  -0.06714562 -0.30481295  0.20028116 -0.19452005 -0.20527387\n",
      "  0.09392607 -0.30401155]\n",
      "Training Error:  9.77921957150864\n",
      "====================================================================================================\n",
      "Iteration:  541\n",
      "Previous theta :  [-0.01672511 -0.07837063  0.10379847 -0.02233473  0.09362852 -0.15816494\n",
      "  0.3430187  -0.06714562 -0.30481295  0.20028116 -0.19452005 -0.20527387\n",
      "  0.09392607 -0.30401155]\n",
      "New theta_0 : [-0.01672281 -0.0784169   0.10387139 -0.02234459  0.09362512 -0.15834392\n",
      "  0.34292046 -0.06709237 -0.30499293  0.20042608 -0.19458199 -0.20530761\n",
      "  0.09390348 -0.30407245]\n",
      "Training Error:  9.779104824935702\n",
      "====================================================================================================\n",
      "Iteration:  542\n",
      "Previous theta :  [-0.01672281 -0.0784169   0.10387139 -0.02234459  0.09362512 -0.15834392\n",
      "  0.34292046 -0.06709237 -0.30499293  0.20042608 -0.19458199 -0.20530761\n",
      "  0.09390348 -0.30407245]\n",
      "New theta_0 : [-0.01672052 -0.07846283  0.10394383 -0.02235409  0.09362172 -0.15852169\n",
      "  0.34282293 -0.06703939 -0.30517148  0.20057036 -0.19464399 -0.20534114\n",
      "  0.09388105 -0.30413292]\n",
      "Training Error:  9.778991550938443\n",
      "====================================================================================================\n",
      "Iteration:  543\n",
      "Previous theta :  [-0.01672052 -0.07846283  0.10394383 -0.02235409  0.09362172 -0.15852169\n",
      "  0.34282293 -0.06703939 -0.30517148  0.20057036 -0.19464399 -0.20534114\n",
      "  0.09388105 -0.30413292]\n",
      "New theta_0 : [-0.01671826 -0.07850843  0.10401578 -0.02236323  0.09361832 -0.15869826\n",
      "  0.34272611 -0.06698668 -0.3053486   0.20071399 -0.19470606 -0.20537447\n",
      "  0.09385879 -0.30419296]\n",
      "Training Error:  9.77887972871928\n",
      "====================================================================================================\n",
      "Iteration:  544\n",
      "Previous theta :  [-0.01671826 -0.07850843  0.10401578 -0.02236323  0.09361832 -0.15869826\n",
      "  0.34272611 -0.06698668 -0.3053486   0.20071399 -0.19470606 -0.20537447\n",
      "  0.09385879 -0.30419296]\n",
      "New theta_0 : [-0.01671602 -0.07855371  0.10408725 -0.02237202  0.09361491 -0.15887364\n",
      "  0.34262999 -0.06693425 -0.30552433  0.20085699 -0.19476817 -0.2054076\n",
      "  0.09383669 -0.30425258]\n",
      "Training Error:  9.778769337786576\n",
      "====================================================================================================\n",
      "Iteration:  545\n",
      "Previous theta :  [-0.01671602 -0.07855371  0.10408725 -0.02237202  0.09361491 -0.15887364\n",
      "  0.34262999 -0.06693425 -0.30552433  0.20085699 -0.19476817 -0.2054076\n",
      "  0.09383669 -0.30425258]\n",
      "New theta_0 : [-0.01671379 -0.07859866  0.10415823 -0.02238045  0.0936115  -0.15904783\n",
      "  0.34253456 -0.06688208 -0.30569865  0.20099935 -0.19483034 -0.20544053\n",
      "  0.09381475 -0.30431177]\n",
      "Training Error:  9.778660357950049\n",
      "====================================================================================================\n",
      "Iteration:  546\n",
      "Previous theta :  [-0.01671379 -0.07859866  0.10415823 -0.02238045  0.0936115  -0.15904783\n",
      "  0.34253456 -0.06688208 -0.30569865  0.20099935 -0.19483034 -0.20544053\n",
      "  0.09381475 -0.30431177]\n",
      "New theta_0 : [-0.01671159 -0.07864329  0.10422874 -0.02238854  0.09360809 -0.15922085\n",
      "  0.34243983 -0.06683018 -0.30587159  0.20114109 -0.19489257 -0.20547326\n",
      "  0.09379297 -0.30437055]\n",
      "Training Error:  9.778552769316253\n",
      "====================================================================================================\n",
      "Iteration:  547\n",
      "Previous theta :  [-0.01671159 -0.07864329  0.10422874 -0.02238854  0.09360809 -0.15922085\n",
      "  0.34243983 -0.06683018 -0.30587159  0.20114109 -0.19489257 -0.20547326\n",
      "  0.09379297 -0.30437055]\n",
      "New theta_0 : [-0.0167094  -0.07868761  0.10429878 -0.02239628  0.09360468 -0.15939271\n",
      "  0.34234578 -0.06677854 -0.30604315  0.2012822  -0.19495484 -0.20550579\n",
      "  0.09377135 -0.30442891]\n",
      "Training Error:  9.778446552284128\n",
      "====================================================================================================\n",
      "Iteration:  548\n",
      "Previous theta :  [-0.0167094  -0.07868761  0.10429878 -0.02239628  0.09360468 -0.15939271\n",
      "  0.34234578 -0.06677854 -0.30604315  0.2012822  -0.19495484 -0.20550579\n",
      "  0.09377135 -0.30442891]\n",
      "New theta_0 : [-0.01670723 -0.0787316   0.10436835 -0.02240368  0.09360127 -0.1595634\n",
      "  0.3422524  -0.06672718 -0.30621336  0.20142269 -0.19501717 -0.20553813\n",
      "  0.09374989 -0.30448686]\n",
      "Training Error:  9.778341687540632\n",
      "====================================================================================================\n",
      "Iteration:  549\n",
      "Previous theta :  [-0.01670723 -0.0787316   0.10436835 -0.02240368  0.09360127 -0.1595634\n",
      "  0.3422524  -0.06672718 -0.30621336  0.20142269 -0.19501717 -0.20553813\n",
      "  0.09374989 -0.30448686]\n",
      "New theta_0 : [-0.01670508 -0.07877528  0.10443745 -0.02241074  0.09359785 -0.15973294\n",
      "  0.3421597  -0.06667608 -0.3063822   0.20156257 -0.19507954 -0.20557027\n",
      "  0.09372858 -0.3045444 ]\n",
      "Training Error:  9.778238156056407\n",
      "====================================================================================================\n",
      "Iteration:  550\n",
      "Previous theta :  [-0.01670508 -0.07877528  0.10443745 -0.02241074  0.09359785 -0.15973294\n",
      "  0.3421597  -0.06667608 -0.3063822   0.20156257 -0.19507954 -0.20557027\n",
      "  0.09372858 -0.3045444 ]\n",
      "New theta_0 : [-0.01670295 -0.07881865  0.10450608 -0.02241747  0.09359443 -0.15990134\n",
      "  0.34206767 -0.06662524 -0.30654971  0.20170183 -0.19514196 -0.20560221\n",
      "  0.09370743 -0.30460153]\n",
      "Training Error:  9.778135939081546\n",
      "====================================================================================================\n",
      "Iteration:  551\n",
      "Previous theta :  [-0.01670295 -0.07881865  0.10450608 -0.02241747  0.09359443 -0.15990134\n",
      "  0.34206767 -0.06662524 -0.30654971  0.20170183 -0.19514196 -0.20560221\n",
      "  0.09370743 -0.30460153]\n",
      "New theta_0 : [-0.01670084 -0.07886171  0.10457426 -0.02242387  0.09359101 -0.1600686\n",
      "  0.3419763  -0.06657466 -0.30671589  0.20184048 -0.19520442 -0.20563396\n",
      "  0.09368643 -0.30465827]\n",
      "Training Error:  9.778035018141397\n",
      "====================================================================================================\n",
      "Iteration:  552\n",
      "Previous theta :  [-0.01670084 -0.07886171  0.10457426 -0.02242387  0.09359101 -0.1600686\n",
      "  0.3419763  -0.06657466 -0.30671589  0.20184048 -0.19520442 -0.20563396\n",
      "  0.09368643 -0.30465827]\n",
      "New theta_0 : [-0.01669874 -0.07890446  0.10464198 -0.02242994  0.09358759 -0.16023473\n",
      "  0.34188559 -0.06652435 -0.30688074  0.20197853 -0.19526693 -0.20566552\n",
      "  0.09366559 -0.3047146 ]\n",
      "Training Error:  9.777935375032447\n",
      "====================================================================================================\n",
      "Iteration:  553\n",
      "Previous theta :  [-0.01669874 -0.07890446  0.10464198 -0.02242994  0.09358759 -0.16023473\n",
      "  0.34188559 -0.06652435 -0.30688074  0.20197853 -0.19526693 -0.20566552\n",
      "  0.09366559 -0.3047146 ]\n",
      "New theta_0 : [-0.01669667 -0.0789469   0.10470925 -0.0224357   0.09358416 -0.16039975\n",
      "  0.34179554 -0.0664743  -0.30704429  0.20211597 -0.19532948 -0.20569689\n",
      "  0.09364489 -0.30477053]\n",
      "Training Error:  9.77783699181826\n",
      "====================================================================================================\n",
      "Iteration:  554\n",
      "Previous theta :  [-0.01669667 -0.0789469   0.10470925 -0.0224357   0.09358416 -0.16039975\n",
      "  0.34179554 -0.0664743  -0.30704429  0.20211597 -0.19532948 -0.20569689\n",
      "  0.09364489 -0.30477053]\n",
      "New theta_0 : [-0.01669461 -0.07898905  0.10477606 -0.02244113  0.09358074 -0.16056365\n",
      "  0.34170613 -0.0664245  -0.30720653  0.20225282 -0.19539207 -0.20572808\n",
      "  0.09362435 -0.30482608]\n",
      "Training Error:  9.777739850825482\n",
      "====================================================================================================\n",
      "Iteration:  555\n",
      "Previous theta :  [-0.01669461 -0.07898905  0.10477606 -0.02244113  0.09358074 -0.16056365\n",
      "  0.34170613 -0.0664245  -0.30720653  0.20225282 -0.19539207 -0.20572808\n",
      "  0.09362435 -0.30482608]\n",
      "New theta_0 : [-0.01669256 -0.07903089  0.10484243 -0.02244625  0.09357731 -0.16072644\n",
      "  0.34161736 -0.06637497 -0.30736748  0.20238907 -0.1954547  -0.20575907\n",
      "  0.09360396 -0.30488123]\n",
      "Training Error:  9.777643934639897\n",
      "====================================================================================================\n",
      "Iteration:  556\n",
      "Previous theta :  [-0.01669256 -0.07903089  0.10484243 -0.02244625  0.09357731 -0.16072644\n",
      "  0.34161736 -0.06637497 -0.30736748  0.20238907 -0.1954547  -0.20575907\n",
      "  0.09360396 -0.30488123]\n",
      "New theta_0 : [-0.01669054 -0.07907244  0.10490835 -0.02245106  0.09357388 -0.16088814\n",
      "  0.34152923 -0.06632569 -0.30752716  0.20252474 -0.19551736 -0.20578988\n",
      "  0.09358371 -0.30493599]\n",
      "Training Error:  9.777549226102563\n",
      "====================================================================================================\n",
      "Iteration:  557\n",
      "Previous theta :  [-0.01669054 -0.07907244  0.10490835 -0.02245106  0.09357388 -0.16088814\n",
      "  0.34152923 -0.06632569 -0.30752716  0.20252474 -0.19551736 -0.20578988\n",
      "  0.09358371 -0.30493599]\n",
      "New theta_0 : [-0.01668853 -0.07911368  0.10497384 -0.02245557  0.09357045 -0.16104874\n",
      "  0.34144174 -0.06627667 -0.30768556  0.20265981 -0.19558006 -0.2058205\n",
      "  0.09356362 -0.30499037]\n",
      "Training Error:  9.777455708305974\n",
      "====================================================================================================\n",
      "Iteration:  558\n",
      "Previous theta :  [-0.01668853 -0.07911368  0.10497384 -0.02245557  0.09357045 -0.16104874\n",
      "  0.34144174 -0.06627667 -0.30768556  0.20265981 -0.19558006 -0.2058205\n",
      "  0.09356362 -0.30499037]\n",
      "New theta_0 : [-0.01668654 -0.07915464  0.10503888 -0.02245977  0.09356702 -0.16120826\n",
      "  0.34135487 -0.0662279  -0.30784271  0.20279431 -0.1956428  -0.20585094\n",
      "  0.09354367 -0.30504437]\n",
      "Training Error:  9.77736336459032\n",
      "====================================================================================================\n",
      "Iteration:  559\n",
      "Previous theta :  [-0.01668654 -0.07915464  0.10503888 -0.02245977  0.09356702 -0.16120826\n",
      "  0.34135487 -0.0662279  -0.30784271  0.20279431 -0.1956428  -0.20585094\n",
      "  0.09354367 -0.30504437]\n",
      "New theta_0 : [-0.01668457 -0.0791953   0.10510349 -0.02246366  0.09356359 -0.16136671\n",
      "  0.34126863 -0.06617939 -0.30799861  0.20292822 -0.19570557 -0.2058812\n",
      "  0.09352386 -0.30509799]\n",
      "Training Error:  9.777272178539768\n",
      "====================================================================================================\n",
      "Iteration:  560\n",
      "Previous theta :  [-0.01668457 -0.0791953   0.10510349 -0.02246366  0.09356359 -0.16136671\n",
      "  0.34126863 -0.06617939 -0.30799861  0.20292822 -0.19570557 -0.2058812\n",
      "  0.09352386 -0.30509799]\n",
      "New theta_0 : [-0.01668261 -0.07923568  0.10516767 -0.02246727  0.09356016 -0.16152408\n",
      "  0.341183   -0.06613113 -0.30815326  0.20306156 -0.19576837 -0.20591127\n",
      "  0.0935042  -0.30515124]\n",
      "Training Error:  9.777182133978815\n",
      "====================================================================================================\n",
      "Iteration:  561\n",
      "Previous theta :  [-0.01668261 -0.07923568  0.10516767 -0.02246727  0.09356016 -0.16152408\n",
      "  0.341183   -0.06613113 -0.30815326  0.20306156 -0.19576837 -0.20591127\n",
      "  0.0935042  -0.30515124]\n",
      "New theta_0 : [-0.01668068 -0.07927577  0.10523142 -0.02247057  0.09355672 -0.1616804\n",
      "  0.34109799 -0.06608312 -0.30830669  0.20319432 -0.1958312  -0.20594116\n",
      "  0.09348469 -0.30520411]\n",
      "Training Error:  9.777093214968698\n",
      "====================================================================================================\n",
      "Iteration:  562\n",
      "Previous theta :  [-0.01668068 -0.07927577  0.10523142 -0.02247057  0.09355672 -0.1616804\n",
      "  0.34109799 -0.06608312 -0.30830669  0.20319432 -0.1958312  -0.20594116\n",
      "  0.09348469 -0.30520411]\n",
      "New theta_0 : [-0.01667875 -0.07931557  0.10529474 -0.02247359  0.09355329 -0.16183566\n",
      "  0.34101359 -0.06603537 -0.30845889  0.20332651 -0.19589406 -0.20597088\n",
      "  0.09346531 -0.30525661]\n",
      "Training Error:  9.777005405803862\n",
      "====================================================================================================\n",
      "Iteration:  563\n",
      "Previous theta :  [-0.01667875 -0.07931557  0.10529474 -0.02247359  0.09355329 -0.16183566\n",
      "  0.34101359 -0.06603537 -0.30845889  0.20332651 -0.19589406 -0.20597088\n",
      "  0.09346531 -0.30525661]\n",
      "New theta_0 : [-0.01667685 -0.07935509  0.10535764 -0.02247632  0.09354985 -0.16198987\n",
      "  0.34092979 -0.06598786 -0.30860989  0.20345814 -0.19595695 -0.20600042\n",
      "  0.09344608 -0.30530874]\n",
      "Training Error:  9.776918691008468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  564\n",
      "Previous theta :  [-0.01667685 -0.07935509  0.10535764 -0.02247632  0.09354985 -0.16198987\n",
      "  0.34092979 -0.06598786 -0.30860989  0.20345814 -0.19595695 -0.20600042\n",
      "  0.09344608 -0.30530874]\n",
      "New theta_0 : [-0.01667496 -0.07939434  0.10542012 -0.02247877  0.09354642 -0.16214304\n",
      "  0.3408466  -0.0659406  -0.30875968  0.20358921 -0.19601986 -0.20602978\n",
      "  0.09342698 -0.30536051]\n",
      "Training Error:  9.776833055332949\n",
      "====================================================================================================\n",
      "Iteration:  565\n",
      "Previous theta :  [-0.01667496 -0.07939434  0.10542012 -0.02247877  0.09354642 -0.16214304\n",
      "  0.3408466  -0.0659406  -0.30875968  0.20358921 -0.19601986 -0.20602978\n",
      "  0.09342698 -0.30536051]\n",
      "New theta_0 : [-0.01667309 -0.0794333   0.10548219 -0.02248093  0.09354298 -0.16229518\n",
      "  0.34076399 -0.06589359 -0.30890829  0.20371972 -0.1960828  -0.20605896\n",
      "  0.09340803 -0.30541191]\n",
      "Training Error:  9.776748483750657\n",
      "====================================================================================================\n",
      "Iteration:  566\n",
      "Previous theta :  [-0.01667309 -0.0794333   0.10548219 -0.02248093  0.09354298 -0.16229518\n",
      "  0.34076399 -0.06589359 -0.30890829  0.20371972 -0.1960828  -0.20605896\n",
      "  0.09340803 -0.30541191]\n",
      "New theta_0 : [-0.01667123 -0.07947199  0.10554384 -0.02248282  0.09353954 -0.16244629\n",
      "  0.34068198 -0.06584682 -0.30905571  0.20384967 -0.19614576 -0.20608798\n",
      "  0.09338921 -0.30546296]\n",
      "Training Error:  9.776664961454511\n",
      "====================================================================================================\n",
      "Iteration:  567\n",
      "Previous theta :  [-0.01667123 -0.07947199  0.10554384 -0.02248282  0.09353954 -0.16244629\n",
      "  0.34068198 -0.06584682 -0.30905571  0.20384967 -0.19614576 -0.20608798\n",
      "  0.09338921 -0.30546296]\n",
      "New theta_0 : [-0.01666939 -0.0795104   0.10560507 -0.02248444  0.0935361  -0.16259639\n",
      "  0.34060056 -0.0658003  -0.30920195  0.20397907 -0.19620875 -0.20611681\n",
      "  0.09337053 -0.30551365]\n",
      "Training Error:  9.776582473853727\n",
      "====================================================================================================\n",
      "Iteration:  568\n",
      "Previous theta :  [-0.01666939 -0.0795104   0.10560507 -0.02248444  0.0935361  -0.16259639\n",
      "  0.34060056 -0.0658003  -0.30920195  0.20397907 -0.19620875 -0.20611681\n",
      "  0.09337053 -0.30551365]\n",
      "New theta_0 : [-0.01666757 -0.07954854  0.1056659  -0.02248578  0.09353267 -0.16274547\n",
      "  0.34051971 -0.06575403 -0.30934704  0.20410792 -0.19627175 -0.20614548\n",
      "  0.09335198 -0.30556399]\n",
      "Training Error:  9.776501006570587\n",
      "====================================================================================================\n",
      "Iteration:  569\n",
      "Previous theta :  [-0.01666757 -0.07954854  0.1056659  -0.02248578  0.09353267 -0.16274547\n",
      "  0.34051971 -0.06575403 -0.30934704  0.20410792 -0.19627175 -0.20614548\n",
      "  0.09335198 -0.30556399]\n",
      "New theta_0 : [-0.01666576 -0.07958641  0.10572633 -0.02248686  0.09352923 -0.16289354\n",
      "  0.34043944 -0.065708   -0.30949097  0.20423623 -0.19633477 -0.20617398\n",
      "  0.09333358 -0.30561398]\n",
      "Training Error:  9.776420545437256\n",
      "====================================================================================================\n",
      "Iteration:  570\n",
      "Previous theta :  [-0.01666576 -0.07958641  0.10572633 -0.02248686  0.09352923 -0.16289354\n",
      "  0.34043944 -0.065708   -0.30949097  0.20423623 -0.19633477 -0.20617398\n",
      "  0.09333358 -0.30561398]\n",
      "New theta_0 : [-0.01666397 -0.07962402  0.10578635 -0.02248767  0.09352579 -0.16304062\n",
      "  0.34035975 -0.06566221 -0.30963375  0.20436399 -0.19639782 -0.2062023\n",
      "  0.0933153  -0.30566361]\n",
      "Training Error:  9.77634107649266\n",
      "====================================================================================================\n",
      "Iteration:  571\n",
      "Previous theta :  [-0.01666397 -0.07962402  0.10578635 -0.02248767  0.09352579 -0.16304062\n",
      "  0.34035975 -0.06566221 -0.30963375  0.20436399 -0.19639782 -0.2062023\n",
      "  0.0933153  -0.30566361]\n",
      "New theta_0 : [-0.01666219 -0.07966136  0.10584597 -0.02248823  0.09352235 -0.1631867\n",
      "  0.34028062 -0.06561666 -0.3097754   0.20449122 -0.19646087 -0.20623046\n",
      "  0.09329716 -0.30571291]\n",
      "Training Error:  9.77626258597938\n",
      "====================================================================================================\n",
      "Iteration:  572\n",
      "Previous theta :  [-0.01666219 -0.07966136  0.10584597 -0.02248823  0.09352235 -0.1631867\n",
      "  0.34028062 -0.06561666 -0.3097754   0.20449122 -0.19646087 -0.20623046\n",
      "  0.09329716 -0.30571291]\n",
      "New theta_0 : [-0.01666043 -0.07969843  0.1059052  -0.02248852  0.09351891 -0.1633318\n",
      "  0.34020206 -0.06557135 -0.30991592  0.20461791 -0.19652395 -0.20625845\n",
      "  0.09327915 -0.30576185]\n",
      "Training Error:  9.776185060340637\n",
      "====================================================================================================\n",
      "Iteration:  573\n",
      "Previous theta :  [-0.01666043 -0.07969843  0.1059052  -0.02248852  0.09351891 -0.1633318\n",
      "  0.34020206 -0.06557135 -0.30991592  0.20461791 -0.19652395 -0.20625845\n",
      "  0.09327915 -0.30576185]\n",
      "New theta_0 : [-0.01665869 -0.07973525  0.10596403 -0.02248856  0.09351547 -0.16347592\n",
      "  0.34012406 -0.06552628 -0.31005532  0.20474406 -0.19658704 -0.20628627\n",
      "  0.09326127 -0.30581046]\n",
      "Training Error:  9.776108486217286\n",
      "====================================================================================================\n",
      "Iteration:  574\n",
      "Previous theta :  [-0.01665869 -0.07973525  0.10596403 -0.02248856  0.09351547 -0.16347592\n",
      "  0.34012406 -0.06552628 -0.31005532  0.20474406 -0.19658704 -0.20628627\n",
      "  0.09326127 -0.30581046]\n",
      "New theta_0 : [-0.01665696 -0.0797718   0.10602247 -0.02248834  0.09351203 -0.16361907\n",
      "  0.34004661 -0.06548144 -0.31019362  0.20486969 -0.19665014 -0.20631393\n",
      "  0.09324352 -0.30585873]\n",
      "Training Error:  9.776032850444867\n",
      "====================================================================================================\n",
      "Iteration:  575\n",
      "Previous theta :  [-0.01665696 -0.0797718   0.10602247 -0.02248834  0.09351203 -0.16361907\n",
      "  0.34004661 -0.06548144 -0.31019362  0.20486969 -0.19665014 -0.20631393\n",
      "  0.09324352 -0.30585873]\n",
      "New theta_0 : [-0.01665524 -0.0798081   0.10608052 -0.02248788  0.09350859 -0.16376126\n",
      "  0.33996972 -0.06543685 -0.31033081  0.20499479 -0.19671325 -0.20634142\n",
      "  0.0932259  -0.30590667]\n",
      "Training Error:  9.775958140050713\n",
      "====================================================================================================\n",
      "Iteration:  576\n",
      "Previous theta :  [-0.01665524 -0.0798081   0.10608052 -0.02248788  0.09350859 -0.16376126\n",
      "  0.33996972 -0.06543685 -0.31033081  0.20499479 -0.19671325 -0.20634142\n",
      "  0.0932259  -0.30590667]\n",
      "New theta_0 : [-0.01665354 -0.07984414  0.10613819 -0.02248717  0.09350515 -0.16390248\n",
      "  0.33989337 -0.06539249 -0.31046691  0.20511937 -0.19677638 -0.20636875\n",
      "  0.0932084  -0.30595427]\n",
      "Training Error:  9.775884342251072\n",
      "====================================================================================================\n",
      "Iteration:  577\n",
      "Previous theta :  [-0.01665354 -0.07984414  0.10613819 -0.02248717  0.09350515 -0.16390248\n",
      "  0.33989337 -0.06539249 -0.31046691  0.20511937 -0.19677638 -0.20636875\n",
      "  0.0932084  -0.30595427]\n",
      "New theta_0 : [-0.01665186 -0.07987993  0.10619547 -0.02248622  0.09350171 -0.16404275\n",
      "  0.33981756 -0.06534836 -0.31060192  0.20524343 -0.19683951 -0.20639592\n",
      "  0.09319104 -0.30600154]\n",
      "Training Error:  9.775811444448319\n",
      "====================================================================================================\n",
      "Iteration:  578\n",
      "Previous theta :  [-0.01665186 -0.07987993  0.10619547 -0.02248622  0.09350171 -0.16404275\n",
      "  0.33981756 -0.06534836 -0.31060192  0.20524343 -0.19683951 -0.20639592\n",
      "  0.09319104 -0.30600154]\n",
      "New theta_0 : [-0.01665019 -0.07991546  0.10625238 -0.02248502  0.09349828 -0.16418208\n",
      "  0.33974229 -0.06530446 -0.31073586  0.20536697 -0.19690265 -0.20642293\n",
      "  0.0931738  -0.30604848]\n",
      "Training Error:  9.775739434228154\n",
      "====================================================================================================\n",
      "Iteration:  579\n",
      "Previous theta :  [-0.01665019 -0.07991546  0.10625238 -0.02248502  0.09349828 -0.16418208\n",
      "  0.33974229 -0.06530446 -0.31073586  0.20536697 -0.19690265 -0.20642293\n",
      "  0.0931738  -0.30604848]\n",
      "New theta_0 : [-0.01664853 -0.07995075  0.1063089  -0.02248359  0.09349484 -0.16432046\n",
      "  0.33966756 -0.0652608  -0.31086874  0.20549    -0.1969658  -0.20644977\n",
      "  0.09315668 -0.3060951 ]\n",
      "Training Error:  9.775668299356889\n",
      "====================================================================================================\n",
      "Iteration:  580\n",
      "Previous theta :  [-0.01664853 -0.07995075  0.1063089  -0.02248359  0.09349484 -0.16432046\n",
      "  0.33966756 -0.0652608  -0.31086874  0.20549    -0.1969658  -0.20644977\n",
      "  0.09315668 -0.3060951 ]\n",
      "New theta_0 : [-0.01664689 -0.07998579  0.10636505 -0.02248193  0.0934914  -0.16445792\n",
      "  0.33959335 -0.06521737 -0.31100055  0.20561251 -0.19702896 -0.20647646\n",
      "  0.09313969 -0.30614139]\n",
      "Training Error:  9.775598027778747\n",
      "====================================================================================================\n",
      "Iteration:  581\n",
      "Previous theta :  [-0.01664689 -0.07998579  0.10636505 -0.02248193  0.0934914  -0.16445792\n",
      "  0.33959335 -0.06521737 -0.31100055  0.20561251 -0.19702896 -0.20647646\n",
      "  0.09313969 -0.30614139]\n",
      "New theta_0 : [-0.01664527 -0.08002058  0.10642083 -0.02248003  0.09348796 -0.16459444\n",
      "  0.33951968 -0.06517417 -0.31113132  0.20573452 -0.19709212 -0.20650299\n",
      "  0.09312283 -0.30618736]\n",
      "Training Error:  9.775528607613222\n",
      "====================================================================================================\n",
      "Iteration:  582\n",
      "Previous theta :  [-0.01664527 -0.08002058  0.10642083 -0.02248003  0.09348796 -0.16459444\n",
      "  0.33951968 -0.06517417 -0.31113132  0.20573452 -0.19709212 -0.20650299\n",
      "  0.09312283 -0.30618736]\n",
      "New theta_0 : [-0.01664366 -0.08005513  0.10647624 -0.0224779   0.09348453 -0.16473005\n",
      "  0.33944652 -0.0651312  -0.31126105  0.20585603 -0.19715528 -0.20652937\n",
      "  0.09310608 -0.30623302]\n",
      "Training Error:  9.775460027152457\n",
      "====================================================================================================\n",
      "Iteration:  583\n",
      "Previous theta :  [-0.01664366 -0.08005513  0.10647624 -0.0224779   0.09348453 -0.16473005\n",
      "  0.33944652 -0.0651312  -0.31126105  0.20585603 -0.19715528 -0.20652937\n",
      "  0.09310608 -0.30623302]\n",
      "New theta_0 : [-0.01664206 -0.08008943  0.10653128 -0.02247555  0.09348109 -0.16486474\n",
      "  0.33937388 -0.06508846 -0.31138974  0.20597703 -0.19721845 -0.20655558\n",
      "  0.09308946 -0.30627836]\n",
      "Training Error:  9.77539227485869\n",
      "====================================================================================================\n",
      "Iteration:  584\n",
      "Previous theta :  [-0.01664206 -0.08008943  0.10653128 -0.02247555  0.09348109 -0.16486474\n",
      "  0.33937388 -0.06508846 -0.31138974  0.20597703 -0.19721845 -0.20655558\n",
      "  0.09308946 -0.30627836]\n",
      "New theta_0 : [-0.01664048 -0.0801235   0.10658596 -0.02247297  0.09347765 -0.16499852\n",
      "  0.33930176 -0.06504594 -0.3115174   0.20609753 -0.19728162 -0.20658165\n",
      "  0.09307296 -0.30632338]\n",
      "Training Error:  9.775325339361705\n",
      "====================================================================================================\n",
      "Iteration:  585\n",
      "Previous theta :  [-0.01664048 -0.0801235   0.10658596 -0.02247297  0.09347765 -0.16499852\n",
      "  0.33930176 -0.06504594 -0.3115174   0.20609753 -0.19728162 -0.20658165\n",
      "  0.09307296 -0.30632338]\n",
      "New theta_0 : [-0.01663891 -0.08015732  0.10664028 -0.02247017  0.09347422 -0.1651314\n",
      "  0.33923015 -0.06500365 -0.31164405  0.20621754 -0.19734478 -0.20660756\n",
      "  0.09305658 -0.30636809]\n",
      "Training Error:  9.775259209456348\n",
      "====================================================================================================\n",
      "Iteration:  586\n",
      "Previous theta :  [-0.01663891 -0.08015732  0.10664028 -0.02247017  0.09347422 -0.1651314\n",
      "  0.33923015 -0.06500365 -0.31164405  0.20621754 -0.19734478 -0.20660756\n",
      "  0.09305658 -0.30636809]\n",
      "New theta_0 : [-0.01663735 -0.08019091  0.10669423 -0.02246716  0.09347079 -0.16526339\n",
      "  0.33915905 -0.06496158 -0.3117697   0.20633706 -0.19740795 -0.20663331\n",
      "  0.09304032 -0.3064125 ]\n",
      "Training Error:  9.775193874100072\n",
      "====================================================================================================\n",
      "Iteration:  587\n",
      "Previous theta :  [-0.01663735 -0.08019091  0.10669423 -0.02246716  0.09347079 -0.16526339\n",
      "  0.33915905 -0.06496158 -0.3117697   0.20633706 -0.19740795 -0.20663331\n",
      "  0.09304032 -0.3064125 ]\n",
      "New theta_0 : [-0.01663581 -0.08022427  0.10674783 -0.02246392  0.09346735 -0.16539448\n",
      "  0.33908844 -0.06491974 -0.31189433  0.20645608 -0.19747112 -0.20665892\n",
      "  0.09302417 -0.3064566 ]\n",
      "Training Error:  9.77512932241051\n",
      "====================================================================================================\n",
      "Iteration:  588\n",
      "Previous theta :  [-0.01663581 -0.08022427  0.10674783 -0.02246392  0.09346735 -0.16539448\n",
      "  0.33908844 -0.06491974 -0.31189433  0.20645608 -0.19747112 -0.20665892\n",
      "  0.09302417 -0.3064566 ]\n",
      "New theta_0 : [-0.01663429 -0.08025739  0.10680108 -0.02246048  0.09346392 -0.16552469\n",
      "  0.33901834 -0.06487812 -0.31201798  0.20657462 -0.19753428 -0.20668437\n",
      "  0.09300815 -0.30650039]\n",
      "Training Error:  9.77506554366311\n",
      "====================================================================================================\n",
      "Iteration:  589\n",
      "Previous theta :  [-0.01663429 -0.08025739  0.10680108 -0.02246048  0.09346392 -0.16552469\n",
      "  0.33901834 -0.06487812 -0.31201798  0.20657462 -0.19753428 -0.20668437\n",
      "  0.09300815 -0.30650039]\n",
      "New theta_0 : [-0.01663278 -0.08029028  0.10685397 -0.02245682  0.09346049 -0.16565403\n",
      "  0.33894873 -0.06483672 -0.31214064  0.20669267 -0.19759744 -0.20670967\n",
      "  0.09299224 -0.30654388]\n",
      "Training Error:  9.77500252728876\n",
      "====================================================================================================\n",
      "Iteration:  590\n",
      "Previous theta :  [-0.01663278 -0.08029028  0.10685397 -0.02245682  0.09346049 -0.16565403\n",
      "  0.33894873 -0.06483672 -0.31214064  0.20669267 -0.19759744 -0.20670967\n",
      "  0.09299224 -0.30654388]\n",
      "New theta_0 : [-0.01663128 -0.08032294  0.10690652 -0.02245296  0.09345706 -0.16578249\n",
      "  0.33887961 -0.06479554 -0.31226233  0.20681025 -0.19766059 -0.20673483\n",
      "  0.09297644 -0.30658707]\n",
      "Training Error:  9.774940262871512\n",
      "====================================================================================================\n",
      "Iteration:  591\n",
      "Previous theta :  [-0.01663128 -0.08032294  0.10690652 -0.02245296  0.09345706 -0.16578249\n",
      "  0.33887961 -0.06479554 -0.31226233  0.20681025 -0.19766059 -0.20673483\n",
      "  0.09297644 -0.30658707]\n",
      "New theta_0 : [-0.01662979 -0.08035538  0.10695871 -0.02244889  0.09345363 -0.16591008\n",
      "  0.33881098 -0.06475458 -0.31238304  0.20692734 -0.19772374 -0.20675983\n",
      "  0.09296076 -0.30662996]\n",
      "Training Error:  9.774878740146269\n",
      "====================================================================================================\n",
      "Iteration:  592\n",
      "Previous theta :  [-0.01662979 -0.08035538  0.10695871 -0.02244889  0.09345363 -0.16591008\n",
      "  0.33881098 -0.06475458 -0.31238304  0.20692734 -0.19772374 -0.20675983\n",
      "  0.09296076 -0.30662996]\n",
      "New theta_0 : [-0.01662832 -0.08038758  0.10701057 -0.02244462  0.0934502  -0.16603682\n",
      "  0.33874284 -0.06471384 -0.31250279  0.20704396 -0.19778688 -0.20678469\n",
      "  0.09294519 -0.30667256]\n",
      "Training Error:  9.774817948996574\n",
      "====================================================================================================\n",
      "Iteration:  593\n",
      "Previous theta :  [-0.01662832 -0.08038758  0.10701057 -0.02244462  0.0934502  -0.16603682\n",
      "  0.33874284 -0.06471384 -0.31250279  0.20704396 -0.19778688 -0.20678469\n",
      "  0.09294519 -0.30667256]\n",
      "New theta_0 : [-0.01662686 -0.08041957  0.10706208 -0.02244015  0.09344678 -0.1661627\n",
      "  0.33867517 -0.06467332 -0.31262159  0.2071601  -0.19785001 -0.2068094\n",
      "  0.09292974 -0.30671487]\n",
      "Training Error:  9.774757879452387\n",
      "====================================================================================================\n",
      "Iteration:  594\n",
      "Previous theta :  [-0.01662686 -0.08041957  0.10706208 -0.02244015  0.09344678 -0.1661627\n",
      "  0.33867517 -0.06467332 -0.31262159  0.2071601  -0.19785001 -0.2068094\n",
      "  0.09292974 -0.30671487]\n",
      "New theta_0 : [-0.01662542 -0.08045133  0.10711325 -0.02243548  0.09344335 -0.16628773\n",
      "  0.33860798 -0.06463301 -0.31273944  0.20727578 -0.19791313 -0.20683397\n",
      "  0.0929144  -0.30675688]\n",
      "Training Error:  9.774698521687908\n",
      "====================================================================================================\n",
      "Iteration:  595\n",
      "Previous theta :  [-0.01662542 -0.08045133  0.10711325 -0.02243548  0.09344335 -0.16628773\n",
      "  0.33860798 -0.06463301 -0.31273944  0.20727578 -0.19791313 -0.20683397\n",
      "  0.0929144  -0.30675688]\n",
      "New theta_0 : [-0.01662398 -0.08048287  0.10716409 -0.02243061  0.09343993 -0.16641192\n",
      "  0.33854127 -0.06459292 -0.31285635  0.20739098 -0.19797624 -0.2068584\n",
      "  0.09289917 -0.3067986 ]\n",
      "Training Error:  9.774639866019442\n",
      "====================================================================================================\n",
      "Iteration:  596\n",
      "Previous theta :  [-0.01662398 -0.08048287  0.10716409 -0.02243061  0.09343993 -0.16641192\n",
      "  0.33854127 -0.06459292 -0.31285635  0.20739098 -0.19797624 -0.2068584\n",
      "  0.09289917 -0.3067986 ]\n",
      "New theta_0 : [-0.01662257 -0.08051419  0.10721459 -0.02242555  0.09343651 -0.16653527\n",
      "  0.33847502 -0.06455304 -0.31297232  0.20750572 -0.19803934 -0.20688268\n",
      "  0.09288405 -0.30684004]\n",
      "Training Error:  9.774581902903286\n",
      "====================================================================================================\n",
      "Iteration:  597\n",
      "Previous theta :  [-0.01662257 -0.08051419  0.10721459 -0.02242555  0.09343651 -0.16653527\n",
      "  0.33847502 -0.06455304 -0.31297232  0.20750572 -0.19803934 -0.20688268\n",
      "  0.09288405 -0.30684004]\n",
      "New theta_0 : [-0.01662116 -0.08054529  0.10726475 -0.0224203   0.09343308 -0.16665779\n",
      "  0.33840924 -0.06451338 -0.31308738  0.20762    -0.19810243 -0.20690681\n",
      "  0.09286904 -0.30688119]\n",
      "Training Error:  9.774524622933647\n",
      "====================================================================================================\n",
      "Iteration:  598\n",
      "Previous theta :  [-0.01662116 -0.08054529  0.10726475 -0.0224203   0.09343308 -0.16665779\n",
      "  0.33840924 -0.06451338 -0.31308738  0.20762    -0.19810243 -0.20690681\n",
      "  0.09286904 -0.30688119]\n",
      "New theta_0 : [-0.01661977 -0.08057617  0.10731459 -0.02241487  0.09342967 -0.16677948\n",
      "  0.33834392 -0.06447392 -0.31320151  0.20773382 -0.19816551 -0.20693081\n",
      "  0.09285414 -0.30692206]\n",
      "Training Error:  9.774468016840606\n",
      "====================================================================================================\n",
      "Iteration:  599\n",
      "Previous theta :  [-0.01661977 -0.08057617  0.10731459 -0.02241487  0.09342967 -0.16677948\n",
      "  0.33834392 -0.06447392 -0.31320151  0.20773382 -0.19816551 -0.20693081\n",
      "  0.09285414 -0.30692206]\n",
      "New theta_0 : [-0.01661839 -0.08060685  0.1073641  -0.02240924  0.09342625 -0.16690036\n",
      "  0.33827906 -0.06443468 -0.31331474  0.20784718 -0.19822857 -0.20695466\n",
      "  0.09283934 -0.30696265]\n",
      "Training Error:  9.774412075488089\n",
      "====================================================================================================\n",
      "Iteration:  600\n",
      "Previous theta :  [-0.01661839 -0.08060685  0.1073641  -0.02240924  0.09342625 -0.16690036\n",
      "  0.33827906 -0.06443468 -0.31331474  0.20784718 -0.19822857 -0.20695466\n",
      "  0.09283934 -0.30696265]\n",
      "New theta_0 : [-0.01661702 -0.08063731  0.10741329 -0.02240344  0.09342283 -0.16702042\n",
      "  0.33821466 -0.06439565 -0.31342706  0.20796009 -0.19829161 -0.20697838\n",
      "  0.09282466 -0.30700296]\n",
      "Training Error:  9.774356789871888\n",
      "====================================================================================================\n",
      "Iteration:  601\n",
      "Previous theta :  [-0.01661702 -0.08063731  0.10741329 -0.02240344  0.09342283 -0.16702042\n",
      "  0.33821466 -0.06439565 -0.31342706  0.20796009 -0.19829161 -0.20697838\n",
      "  0.09282466 -0.30700296]\n",
      "New theta_0 : [-0.01661566 -0.08066755  0.10746215 -0.02239745  0.09341942 -0.16713967\n",
      "  0.33815071 -0.06435683 -0.31353849  0.20807255 -0.19835465 -0.20700196\n",
      "  0.09281008 -0.307043  ]\n",
      "Training Error:  9.774302151117704\n",
      "====================================================================================================\n",
      "Iteration:  602\n",
      "Previous theta :  [-0.01661566 -0.08066755  0.10746215 -0.02239745  0.09341942 -0.16713967\n",
      "  0.33815071 -0.06435683 -0.31353849  0.20807255 -0.19835465 -0.20700196\n",
      "  0.09281008 -0.307043  ]\n",
      "New theta_0 : [-0.01661432 -0.08069759  0.1075107  -0.02239128  0.093416   -0.16725811\n",
      "  0.3380872  -0.06431821 -0.31364902  0.20818455 -0.19841766 -0.2070254\n",
      "  0.0927956  -0.30708276]\n",
      "Training Error:  9.774248150479224\n",
      "====================================================================================================\n",
      "Iteration:  603\n",
      "Previous theta :  [-0.01661432 -0.08069759  0.1075107  -0.02239128  0.093416   -0.16725811\n",
      "  0.3380872  -0.06431821 -0.31364902  0.20818455 -0.19841766 -0.2070254\n",
      "  0.0927956  -0.30708276]\n",
      "New theta_0 : [-0.01661299 -0.08072742  0.10755892 -0.02238494  0.09341259 -0.16737576\n",
      "  0.33802415 -0.0642798  -0.31375868  0.20829611 -0.19848065 -0.2070487\n",
      "  0.09278123 -0.30712224]\n",
      "Training Error:  9.774194779336213\n",
      "====================================================================================================\n",
      "Iteration:  604\n",
      "Previous theta :  [-0.01661299 -0.08072742  0.10755892 -0.02238494  0.09341259 -0.16737576\n",
      "  0.33802415 -0.0642798  -0.31375868  0.20829611 -0.19848065 -0.2070487\n",
      "  0.09278123 -0.30712224]\n",
      "New theta_0 : [-0.01661167 -0.08075705  0.10760683 -0.02237842  0.09340918 -0.16749262\n",
      "  0.33796153 -0.0642416  -0.31386746  0.20840723 -0.19854363 -0.20707186\n",
      "  0.09276697 -0.30716146]\n",
      "Training Error:  9.774142029192664\n",
      "====================================================================================================\n",
      "Iteration:  605\n",
      "Previous theta :  [-0.01661167 -0.08075705  0.10760683 -0.02237842  0.09340918 -0.16749262\n",
      "  0.33796153 -0.0642416  -0.31386746  0.20840723 -0.19854363 -0.20707186\n",
      "  0.09276697 -0.30716146]\n",
      "New theta_0 : [-0.01661037 -0.08078647  0.10765442 -0.02237173  0.09340577 -0.16760868\n",
      "  0.33789935 -0.0642036  -0.31397537  0.2085179  -0.19860659 -0.20709489\n",
      "  0.09275281 -0.30720041]\n",
      "Training Error:  9.77408989167493\n",
      "====================================================================================================\n",
      "Iteration:  606\n",
      "Previous theta :  [-0.01661037 -0.08078647  0.10765442 -0.02237173  0.09340577 -0.16760868\n",
      "  0.33789935 -0.0642036  -0.31397537  0.2085179  -0.19860659 -0.20709489\n",
      "  0.09275281 -0.30720041]\n",
      "New theta_0 : [-0.01660907 -0.08081568  0.10770171 -0.02236487  0.09340237 -0.16772397\n",
      "  0.33783761 -0.06416581 -0.31408242  0.20862814 -0.19866953 -0.20711779\n",
      "  0.09273875 -0.30723909]\n",
      "Training Error:  9.774038358529939\n",
      "====================================================================================================\n",
      "Iteration:  607\n",
      "Previous theta :  [-0.01660907 -0.08081568  0.10770171 -0.02236487  0.09340237 -0.16772397\n",
      "  0.33783761 -0.06416581 -0.31408242  0.20862814 -0.19866953 -0.20711779\n",
      "  0.09273875 -0.30723909]\n",
      "New theta_0 : [-0.01660779 -0.0808447   0.10774868 -0.02235785  0.09339897 -0.16783848\n",
      "  0.3377763  -0.06412822 -0.31418862  0.20873793 -0.19873244 -0.20714055\n",
      "  0.09272479 -0.30727751]\n",
      "Training Error:  9.77398742162339\n",
      "====================================================================================================\n",
      "Iteration:  608\n",
      "Previous theta :  [-0.01660779 -0.0808447   0.10774868 -0.02235785  0.09339897 -0.16783848\n",
      "  0.3377763  -0.06412822 -0.31418862  0.20873793 -0.19873244 -0.20714055\n",
      "  0.09272479 -0.30727751]\n",
      "New theta_0 : [-0.01660652 -0.08087351  0.10779535 -0.02235065  0.09339556 -0.16795222\n",
      "  0.33771541 -0.06409083 -0.31429397  0.2088473  -0.19879533 -0.20716318\n",
      "  0.09271094 -0.30731567]\n",
      "Training Error:  9.773937072938002\n",
      "====================================================================================================\n",
      "Iteration:  609\n",
      "Previous theta :  [-0.01660652 -0.08087351  0.10779535 -0.02235065  0.09339556 -0.16795222\n",
      "  0.33771541 -0.06409083 -0.31429397  0.2088473  -0.19879533 -0.20716318\n",
      "  0.09271094 -0.30731567]\n",
      "New theta_0 : [-0.01660527 -0.08090213  0.10784171 -0.0223433   0.09339216 -0.16806519\n",
      "  0.33765496 -0.06405364 -0.31439847  0.20895623 -0.1988582  -0.20718568\n",
      "  0.09269718 -0.30735356]\n",
      "Training Error:  9.773887304571772\n",
      "====================================================================================================\n",
      "Iteration:  610\n",
      "Previous theta :  [-0.01660527 -0.08090213  0.10784171 -0.0223433   0.09339216 -0.16806519\n",
      "  0.33765496 -0.06405364 -0.31439847  0.20895623 -0.1988582  -0.20718568\n",
      "  0.09269718 -0.30735356]\n",
      "New theta_0 : [-0.01660402 -0.08093055  0.10788777 -0.02233578  0.09338877 -0.1681774\n",
      "  0.33759492 -0.06401665 -0.31450215  0.20906473 -0.19892105 -0.20720804\n",
      "  0.09268353 -0.3073912 ]\n",
      "Training Error:  9.773838108736284\n",
      "====================================================================================================\n",
      "Iteration:  611\n",
      "Previous theta :  [-0.01660402 -0.08093055  0.10788777 -0.02233578  0.09338877 -0.1681774\n",
      "  0.33759492 -0.06401665 -0.31450215  0.20906473 -0.19892105 -0.20720804\n",
      "  0.09268353 -0.3073912 ]\n",
      "New theta_0 : [-0.01660279 -0.08095877  0.10793353 -0.0223281   0.09338537 -0.16828885\n",
      "  0.3375353  -0.06397986 -0.31460499  0.20917281 -0.19898387 -0.20723028\n",
      "  0.09266997 -0.30742858]\n",
      "Training Error:  9.773789477755011\n",
      "====================================================================================================\n",
      "Iteration:  612\n",
      "Previous theta :  [-0.01660279 -0.08095877  0.10793353 -0.0223281   0.09338537 -0.16828885\n",
      "  0.3375353  -0.06397986 -0.31460499  0.20917281 -0.19898387 -0.20723028\n",
      "  0.09266997 -0.30742858]\n",
      "New theta_0 : [-0.01660156 -0.0809868   0.10797899 -0.02232027  0.09338198 -0.16839955\n",
      "  0.3374761  -0.06394326 -0.31470702  0.20928046 -0.19904666 -0.20725238\n",
      "  0.09265651 -0.3074657 ]\n",
      "Training Error:  9.773741404061674\n",
      "====================================================================================================\n",
      "Iteration:  613\n",
      "Previous theta :  [-0.01660156 -0.0809868   0.10797899 -0.02232027  0.09338198 -0.16839955\n",
      "  0.3374761  -0.06394326 -0.31470702  0.20928046 -0.19904666 -0.20725238\n",
      "  0.09265651 -0.3074657 ]\n",
      "New theta_0 : [-0.01660035 -0.08101464  0.10802415 -0.02231228  0.09337859 -0.16850951\n",
      "  0.33741731 -0.06390687 -0.31480823  0.20938769 -0.19910943 -0.20727436\n",
      "  0.09264315 -0.30750257]\n",
      "Training Error:  9.7736938801986\n",
      "====================================================================================================\n",
      "Iteration:  614\n",
      "Previous theta :  [-0.01660035 -0.08101464  0.10802415 -0.02231228  0.09337859 -0.16850951\n",
      "  0.33741731 -0.06390687 -0.31480823  0.20938769 -0.19910943 -0.20727436\n",
      "  0.09264315 -0.30750257]\n",
      "New theta_0 : [-0.01659915 -0.08104228  0.10806902 -0.02230413  0.0933752  -0.16861873\n",
      "  0.33735894 -0.06387066 -0.31490863  0.2094945  -0.19917217 -0.20729621\n",
      "  0.09262988 -0.30753919]\n",
      "Training Error:  9.773646898815123\n",
      "====================================================================================================\n",
      "Iteration:  615\n",
      "Previous theta :  [-0.01659915 -0.08104228  0.10806902 -0.02230413  0.0933752  -0.16861873\n",
      "  0.33735894 -0.06387066 -0.31490863  0.2094945  -0.19917217 -0.20729621\n",
      "  0.09262988 -0.30753919]\n",
      "New theta_0 : [-0.01659796 -0.08106974  0.1081136  -0.02229584  0.09337181 -0.16872721\n",
      "  0.33730096 -0.06383466 -0.31500823  0.20960089 -0.19923489 -0.20731793\n",
      "  0.09261672 -0.30757556]\n",
      "Training Error:  9.773600452665997\n",
      "====================================================================================================\n",
      "Iteration:  616\n",
      "Previous theta :  [-0.01659796 -0.08106974  0.1081136  -0.02229584  0.09337181 -0.16872721\n",
      "  0.33730096 -0.06383466 -0.31500823  0.20960089 -0.19923489 -0.20731793\n",
      "  0.09261672 -0.30757556]\n",
      "New theta_0 : [-0.01659679 -0.08109701  0.10815788 -0.0222874   0.09336843 -0.16883496\n",
      "  0.3372434  -0.06379885 -0.31510703  0.20970687 -0.19929757 -0.20733953\n",
      "  0.09260364 -0.30761169]\n",
      "Training Error:  9.773554534609843\n",
      "====================================================================================================\n",
      "Iteration:  617\n",
      "Previous theta :  [-0.01659679 -0.08109701  0.10815788 -0.0222874   0.09336843 -0.16883496\n",
      "  0.3372434  -0.06379885 -0.31510703  0.20970687 -0.19929757 -0.20733953\n",
      "  0.09260364 -0.30761169]\n",
      "New theta_0 : [-0.01659562 -0.08112409  0.10820188 -0.02227881  0.09336505 -0.16894198\n",
      "  0.33718623 -0.06376323 -0.31520504  0.20981244 -0.19936022 -0.207361\n",
      "  0.09259066 -0.30764756]\n",
      "Training Error:  9.773509137607608\n",
      "====================================================================================================\n",
      "Iteration:  618\n",
      "Previous theta :  [-0.01659562 -0.08112409  0.10820188 -0.02227881  0.09336505 -0.16894198\n",
      "  0.33718623 -0.06376323 -0.31520504  0.20981244 -0.19936022 -0.207361\n",
      "  0.09259066 -0.30764756]\n",
      "New theta_0 : [-0.01659447 -0.08115098  0.1082456  -0.02227007  0.09336167 -0.16904828\n",
      "  0.33712946 -0.0637278  -0.31530227  0.20991759 -0.19942285 -0.20738235\n",
      "  0.09257778 -0.3076832 ]\n",
      "Training Error:  9.773464254721052\n",
      "====================================================================================================\n",
      "Iteration:  619\n",
      "Previous theta :  [-0.01659447 -0.08115098  0.1082456  -0.02227007  0.09336167 -0.16904828\n",
      "  0.33712946 -0.0637278  -0.31530227  0.20991759 -0.19942285 -0.20738235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.09257778 -0.3076832 ]\n",
      "New theta_0 : [-0.01659332 -0.08117769  0.10828902 -0.02226119  0.09335829 -0.16915387\n",
      "  0.33707308 -0.06369256 -0.31539873  0.21002233 -0.19948544 -0.20740357\n",
      "  0.09256499 -0.30771859]\n",
      "Training Error:  9.773419879111266\n",
      "====================================================================================================\n",
      "Iteration:  620\n",
      "Previous theta :  [-0.01659332 -0.08117769  0.10828902 -0.02226119  0.09335829 -0.16915387\n",
      "  0.33707308 -0.06369256 -0.31539873  0.21002233 -0.19948544 -0.20740357\n",
      "  0.09256499 -0.30771859]\n",
      "New theta_0 : [-0.01659219 -0.08120422  0.10833217 -0.02225217  0.09335492 -0.16925875\n",
      "  0.3370171  -0.06365751 -0.31549441  0.21012667 -0.199548   -0.20742467\n",
      "  0.09255229 -0.30775374]\n",
      "Training Error:  9.773376004037205\n",
      "====================================================================================================\n",
      "Iteration:  621\n",
      "Previous theta :  [-0.01659219 -0.08120422  0.10833217 -0.02225217  0.09335492 -0.16925875\n",
      "  0.3370171  -0.06365751 -0.31549441  0.21012667 -0.199548   -0.20742467\n",
      "  0.09255229 -0.30775374]\n",
      "New theta_0 : [-0.01659107 -0.08123057  0.10837504 -0.02224301  0.09335154 -0.16936292\n",
      "  0.3369615  -0.06362265 -0.31558933  0.21023061 -0.19961053 -0.20744564\n",
      "  0.09253968 -0.30778865]\n",
      "Training Error:  9.773332622854236\n",
      "====================================================================================================\n",
      "Iteration:  622\n",
      "Previous theta :  [-0.01659107 -0.08123057  0.10837504 -0.02224301  0.09335154 -0.16936292\n",
      "  0.3369615  -0.06362265 -0.31558933  0.21023061 -0.19961053 -0.20744564\n",
      "  0.09253968 -0.30778865]\n",
      "New theta_0 : [-0.01658996 -0.08125673  0.10841763 -0.02223372  0.09334817 -0.16946639\n",
      "  0.33690629 -0.06358798 -0.31568349  0.21033415 -0.19967302 -0.2074665\n",
      "  0.09252717 -0.30782333]\n",
      "Training Error:  9.773289729012708\n",
      "====================================================================================================\n",
      "Iteration:  623\n",
      "Previous theta :  [-0.01658996 -0.08125673  0.10841763 -0.02223372  0.09334817 -0.16946639\n",
      "  0.33690629 -0.06358798 -0.31568349  0.21033415 -0.19967302 -0.2074665\n",
      "  0.09252717 -0.30782333]\n",
      "New theta_0 : [-0.01658886 -0.08128272  0.10845994 -0.02222428  0.09334481 -0.16956916\n",
      "  0.33685146 -0.0635535  -0.31577689  0.21043728 -0.19973548 -0.20748723\n",
      "  0.09251474 -0.30785777]\n",
      "Training Error:  9.773247316056576\n",
      "====================================================================================================\n",
      "Iteration:  624\n",
      "Previous theta :  [-0.01658886 -0.08128272  0.10845994 -0.02222428  0.09334481 -0.16956916\n",
      "  0.33685146 -0.0635535  -0.31577689  0.21043728 -0.19973548 -0.20748723\n",
      "  0.09251474 -0.30785777]\n",
      "New theta_0 : [-0.01658777 -0.08130853  0.10850198 -0.02221472  0.09334144 -0.16967124\n",
      "  0.33679701 -0.0635192  -0.31586955  0.21054002 -0.1997979  -0.20750785\n",
      "  0.09250241 -0.30789197]\n",
      "Training Error:  9.773205377621995\n",
      "====================================================================================================\n",
      "Iteration:  625\n",
      "Previous theta :  [-0.01658777 -0.08130853  0.10850198 -0.02221472  0.09334144 -0.16967124\n",
      "  0.33679701 -0.0635192  -0.31586955  0.21054002 -0.1997979  -0.20750785\n",
      "  0.09250241 -0.30789197]\n",
      "New theta_0 : [-0.01658669 -0.08133417  0.10854375 -0.02220502  0.09333808 -0.16977263\n",
      "  0.33674294 -0.06348509 -0.31596147  0.21064236 -0.19986029 -0.20752834\n",
      "  0.09249016 -0.30792595]\n",
      "Training Error:  9.773163907435976\n",
      "====================================================================================================\n",
      "Iteration:  626\n",
      "Previous theta :  [-0.01658669 -0.08133417  0.10854375 -0.02220502  0.09333808 -0.16977263\n",
      "  0.33674294 -0.06348509 -0.31596147  0.21064236 -0.19986029 -0.20752834\n",
      "  0.09249016 -0.30792595]\n",
      "New theta_0 : [-0.01658562 -0.08135963  0.10858525 -0.02219519  0.09333473 -0.16987334\n",
      "  0.33668925 -0.06345116 -0.31605266  0.21074431 -0.19992264 -0.20754872\n",
      "  0.092478   -0.30795969]\n",
      "Training Error:  9.773122899315018\n",
      "====================================================================================================\n",
      "Iteration:  627\n",
      "Previous theta :  [-0.01658562 -0.08135963  0.10858525 -0.02219519  0.09333473 -0.16987334\n",
      "  0.33668925 -0.06345116 -0.31605266  0.21074431 -0.19992264 -0.20754872\n",
      "  0.092478   -0.30795969]\n",
      "New theta_0 : [-0.01658456 -0.08138492  0.10862648 -0.02218523  0.09333137 -0.16997337\n",
      "  0.33663592 -0.06341741 -0.31614311  0.21084587 -0.19998496 -0.20756897\n",
      "  0.09246593 -0.30799321]\n",
      "Training Error:  9.773082347163843\n",
      "====================================================================================================\n",
      "Iteration:  628\n",
      "Previous theta :  [-0.01658456 -0.08138492  0.10862648 -0.02218523  0.09333137 -0.16997337\n",
      "  0.33663592 -0.06341741 -0.31614311  0.21084587 -0.19998496 -0.20756897\n",
      "  0.09246593 -0.30799321]\n",
      "New theta_0 : [-0.01658352 -0.08141004  0.10866744 -0.02217515  0.09332802 -0.17007273\n",
      "  0.33658296 -0.06338385 -0.31623284  0.21094705 -0.20004723 -0.20758912\n",
      "  0.09245395 -0.3080265 ]\n",
      "Training Error:  9.773042244974027\n",
      "====================================================================================================\n",
      "Iteration:  629\n",
      "Previous theta :  [-0.01658352 -0.08141004  0.10866744 -0.02217515  0.09332802 -0.17007273\n",
      "  0.33658296 -0.06338385 -0.31623284  0.21094705 -0.20004723 -0.20758912\n",
      "  0.09245395 -0.3080265 ]\n",
      "New theta_0 : [-0.01658248 -0.08143498  0.10870814 -0.02216494  0.09332467 -0.17017142\n",
      "  0.33653037 -0.06335047 -0.31632185  0.21104783 -0.20010947 -0.20760914\n",
      "  0.09244206 -0.30805956]\n",
      "Training Error:  9.773002586822782\n",
      "====================================================================================================\n",
      "Iteration:  630\n",
      "Previous theta :  [-0.01658248 -0.08143498  0.10870814 -0.02216494  0.09332467 -0.17017142\n",
      "  0.33653037 -0.06335047 -0.31632185  0.21104783 -0.20010947 -0.20760914\n",
      "  0.09244206 -0.30805956]\n",
      "New theta_0 : [-0.01658145 -0.08145976  0.10874858 -0.02215461  0.09332132 -0.17026944\n",
      "  0.33647815 -0.06331726 -0.31641015  0.21114823 -0.20017167 -0.20762905\n",
      "  0.09243025 -0.30809241]\n",
      "Training Error:  9.772963366871652\n",
      "====================================================================================================\n",
      "Iteration:  631\n",
      "Previous theta :  [-0.01658145 -0.08145976  0.10874858 -0.02215461  0.09332132 -0.17026944\n",
      "  0.33647815 -0.06331726 -0.31641015  0.21114823 -0.20017167 -0.20762905\n",
      "  0.09243025 -0.30809241]\n",
      "New theta_0 : [-0.01658043 -0.08148436  0.10878876 -0.02214415  0.09331798 -0.17036681\n",
      "  0.33642628 -0.06328424 -0.31649775  0.21124825 -0.20023382 -0.20764884\n",
      "  0.09241852 -0.30812503]\n",
      "Training Error:  9.77292457936529\n",
      "====================================================================================================\n",
      "Iteration:  632\n",
      "Previous theta :  [-0.01658043 -0.08148436  0.10878876 -0.02214415  0.09331798 -0.17036681\n",
      "  0.33642628 -0.06328424 -0.31649775  0.21124825 -0.20023382 -0.20764884\n",
      "  0.09241852 -0.30812503]\n",
      "New theta_0 : [-0.01657943 -0.08150881  0.10882867 -0.02213358  0.09331464 -0.17046352\n",
      "  0.33637477 -0.06325139 -0.31658464  0.21134789 -0.20029594 -0.20766852\n",
      "  0.09240688 -0.30815742]\n",
      "Training Error:  9.772886218630228\n",
      "====================================================================================================\n",
      "Iteration:  633\n",
      "Previous theta :  [-0.01657943 -0.08150881  0.10882867 -0.02213358  0.09331464 -0.17046352\n",
      "  0.33637477 -0.06325139 -0.31658464  0.21134789 -0.20029594 -0.20766852\n",
      "  0.09240688 -0.30815742]\n",
      "New theta_0 : [-0.01657843 -0.08153308  0.10886833 -0.02212289  0.0933113  -0.17055958\n",
      "  0.33632362 -0.06321873 -0.31667084  0.21144715 -0.20035801 -0.20768809\n",
      "  0.09239533 -0.3081896 ]\n",
      "Training Error:  9.772848279073678\n",
      "====================================================================================================\n",
      "Iteration:  634\n",
      "Previous theta :  [-0.01657843 -0.08153308  0.10886833 -0.02212289  0.0933113  -0.17055958\n",
      "  0.33632362 -0.06321873 -0.31667084  0.21144715 -0.20035801 -0.20768809\n",
      "  0.09239533 -0.3081896 ]\n",
      "New theta_0 : [-0.01657744 -0.08155719  0.10890774 -0.02211208  0.09330796 -0.17065499\n",
      "  0.33627281 -0.06318623 -0.31675635  0.21154604 -0.20042005 -0.20770754\n",
      "  0.09238385 -0.30822157]\n",
      "Training Error:  9.772810755182336\n",
      "====================================================================================================\n",
      "Iteration:  635\n",
      "Previous theta :  [-0.01657744 -0.08155719  0.10890774 -0.02211208  0.09330796 -0.17065499\n",
      "  0.33627281 -0.06318623 -0.31675635  0.21154604 -0.20042005 -0.20770754\n",
      "  0.09238385 -0.30822157]\n",
      "New theta_0 : [-0.01657646 -0.08158114  0.10894689 -0.02210116  0.09330463 -0.17074976\n",
      "  0.33622236 -0.06315392 -0.31684117  0.21164455 -0.20048204 -0.20772688\n",
      "  0.09237246 -0.30825332]\n",
      "Training Error:  9.772773641521217\n",
      "====================================================================================================\n",
      "Iteration:  636\n",
      "Previous theta :  [-0.01657646 -0.08158114  0.10894689 -0.02210116  0.09330463 -0.17074976\n",
      "  0.33622236 -0.06315392 -0.31684117  0.21164455 -0.20048204 -0.20772688\n",
      "  0.09237246 -0.30825332]\n",
      "New theta_0 : [-0.0165755  -0.08160493  0.10898579 -0.02209012  0.0933013  -0.17084389\n",
      "  0.33617226 -0.06312178 -0.31692531  0.21174269 -0.20054398 -0.20774611\n",
      "  0.09236116 -0.30828485]\n",
      "Training Error:  9.772736932732506\n",
      "====================================================================================================\n",
      "Iteration:  637\n",
      "Previous theta :  [-0.0165755  -0.08160493  0.10898579 -0.02209012  0.0933013  -0.17084389\n",
      "  0.33617226 -0.06312178 -0.31692531  0.21174269 -0.20054398 -0.20774611\n",
      "  0.09236116 -0.30828485]\n",
      "New theta_0 : [-0.01657454 -0.08162855  0.10902445 -0.02207898  0.09329798 -0.17093739\n",
      "  0.3361225  -0.06308981 -0.31700878  0.21184046 -0.20060589 -0.20776523\n",
      "  0.09234993 -0.30831617]\n",
      "Training Error:  9.77270062353441\n",
      "====================================================================================================\n",
      "Iteration:  638\n",
      "Previous theta :  [-0.01657454 -0.08162855  0.10902445 -0.02207898  0.09329798 -0.17093739\n",
      "  0.3361225  -0.06308981 -0.31700878  0.21184046 -0.20060589 -0.20776523\n",
      "  0.09234993 -0.30831617]\n",
      "New theta_0 : [-0.01657359 -0.08165202  0.10906285 -0.02206772  0.09329466 -0.17103026\n",
      "  0.33607308 -0.06305801 -0.31709159  0.21193786 -0.20066774 -0.20778423\n",
      "  0.09233879 -0.30834728]\n",
      "Training Error:  9.77266470872006\n",
      "====================================================================================================\n",
      "Iteration:  639\n",
      "Previous theta :  [-0.01657359 -0.08165202  0.10906285 -0.02206772  0.09329466 -0.17103026\n",
      "  0.33607308 -0.06305801 -0.31709159  0.21193786 -0.20066774 -0.20778423\n",
      "  0.09233879 -0.30834728]\n",
      "New theta_0 : [-0.01657265 -0.08167533  0.10910101 -0.02205635  0.09329134 -0.1711225\n",
      "  0.336024   -0.06302639 -0.31717372  0.2120349  -0.20072956 -0.20780313\n",
      "  0.09232772 -0.30837818]\n",
      "Training Error:  9.772629183156386\n",
      "====================================================================================================\n",
      "Iteration:  640\n",
      "Previous theta :  [-0.01657265 -0.08167533  0.10910101 -0.02205635  0.09329134 -0.1711225\n",
      "  0.336024   -0.06302639 -0.31717372  0.2120349  -0.20072956 -0.20780313\n",
      "  0.09232772 -0.30837818]\n",
      "New theta_0 : [-0.01657172 -0.08169848  0.10913892 -0.02204488  0.09328802 -0.17121413\n",
      "  0.33597526 -0.06299494 -0.3172552   0.21213157 -0.20079132 -0.20782192\n",
      "  0.09231674 -0.30840888]\n",
      "Training Error:  9.772594041783062\n",
      "====================================================================================================\n",
      "Iteration:  641\n",
      "Previous theta :  [-0.01657172 -0.08169848  0.10913892 -0.02204488  0.09328802 -0.17121413\n",
      "  0.33597526 -0.06299494 -0.3172552   0.21213157 -0.20079132 -0.20782192\n",
      "  0.09231674 -0.30840888]\n",
      "New theta_0 : [-0.0165708  -0.08172148  0.10917659 -0.0220333   0.09328471 -0.17130514\n",
      "  0.33592685 -0.06296366 -0.31733603  0.21222788 -0.20085304 -0.2078406\n",
      "  0.09230583 -0.30843936]\n",
      "Training Error:  9.772559279611409\n",
      "====================================================================================================\n",
      "Iteration:  642\n",
      "Previous theta :  [-0.0165708  -0.08172148  0.10917659 -0.0220333   0.09328471 -0.17130514\n",
      "  0.33592685 -0.06296366 -0.31733603  0.21222788 -0.20085304 -0.2078406\n",
      "  0.09230583 -0.30843936]\n",
      "New theta_0 : [-0.01656989 -0.08174432  0.10921402 -0.02202162  0.0932814  -0.17139553\n",
      "  0.33587877 -0.06293255 -0.31741621  0.21232383 -0.20091472 -0.20785918\n",
      "  0.09229501 -0.30846965]\n",
      "Training Error:  9.772524891723357\n",
      "====================================================================================================\n",
      "Iteration:  643\n",
      "Previous theta :  [-0.01656989 -0.08174432  0.10921402 -0.02202162  0.0932814  -0.17139553\n",
      "  0.33587877 -0.06293255 -0.31741621  0.21232383 -0.20091472 -0.20785918\n",
      "  0.09229501 -0.30846965]\n",
      "New theta_0 : [-0.01656899 -0.08176701  0.10925121 -0.02200984  0.0932781  -0.17148532\n",
      "  0.33583103 -0.0629016  -0.31749575  0.21241942 -0.20097634 -0.20787764\n",
      "  0.09228426 -0.30849972]\n",
      "Training Error:  9.772490873270405\n",
      "====================================================================================================\n",
      "Iteration:  644\n",
      "Previous theta :  [-0.01656899 -0.08176701  0.10925121 -0.02200984  0.0932781  -0.17148532\n",
      "  0.33583103 -0.0629016  -0.31749575  0.21241942 -0.20097634 -0.20787764\n",
      "  0.09228426 -0.30849972]\n",
      "New theta_0 : [-0.01656809 -0.08178954  0.10928817 -0.02199795  0.09327479 -0.1715745\n",
      "  0.33578361 -0.06287082 -0.31757465  0.21251465 -0.20103792 -0.207896\n",
      "  0.09227359 -0.3085296 ]\n",
      "Training Error:  9.772457219472596\n",
      "====================================================================================================\n",
      "Iteration:  645\n",
      "Previous theta :  [-0.01656809 -0.08178954  0.10928817 -0.02199795  0.09327479 -0.1715745\n",
      "  0.33578361 -0.06287082 -0.31757465  0.21251465 -0.20103792 -0.207896\n",
      "  0.09227359 -0.3085296 ]\n",
      "New theta_0 : [-0.01656721 -0.08181192  0.10932489 -0.02198597  0.09327149 -0.17166309\n",
      "  0.33573651 -0.06284021 -0.31765292  0.21260953 -0.20109944 -0.20791426\n",
      "  0.09226299 -0.30855928]\n",
      "Training Error:  9.772423925617522\n",
      "====================================================================================================\n",
      "Iteration:  646\n",
      "Previous theta :  [-0.01656721 -0.08181192  0.10932489 -0.02198597  0.09327149 -0.17166309\n",
      "  0.33573651 -0.06284021 -0.31765292  0.21260953 -0.20109944 -0.20791426\n",
      "  0.09226299 -0.30855928]\n",
      "New theta_0 : [-0.01656634 -0.08183416  0.10936137 -0.02197389  0.0932682  -0.17175107\n",
      "  0.33568974 -0.06280977 -0.31773056  0.21270406 -0.20116092 -0.20793241\n",
      "  0.09225248 -0.30858876]\n",
      "Training Error:  9.772390987059323\n",
      "====================================================================================================\n",
      "Iteration:  647\n",
      "Previous theta :  [-0.01656634 -0.08183416  0.10936137 -0.02197389  0.0932682  -0.17175107\n",
      "  0.33568974 -0.06280977 -0.31773056  0.21270406 -0.20116092 -0.20793241\n",
      "  0.09225248 -0.30858876]\n",
      "New theta_0 : [-0.01656547 -0.08185624  0.10939762 -0.02196171  0.09326491 -0.17183847\n",
      "  0.33564329 -0.06277949 -0.31780758  0.21279824 -0.20122235 -0.20795046\n",
      "  0.09224204 -0.30861804]\n",
      "Training Error:  9.772358399217714\n",
      "====================================================================================================\n",
      "Iteration:  648\n",
      "Previous theta :  [-0.01656547 -0.08185624  0.10939762 -0.02196171  0.09326491 -0.17183847\n",
      "  0.33564329 -0.06277949 -0.31780758  0.21279824 -0.20122235 -0.20795046\n",
      "  0.09224204 -0.30861804]\n",
      "New theta_0 : [-0.01656461 -0.08187818  0.10943364 -0.02194944  0.09326162 -0.17192528\n",
      "  0.33559716 -0.06274937 -0.31788398  0.21289207 -0.20128373 -0.2079684\n",
      "  0.09223167 -0.30864712]\n",
      "Training Error:  9.772326157577018\n",
      "====================================================================================================\n",
      "Iteration:  649\n",
      "Previous theta :  [-0.01656461 -0.08187818  0.10943364 -0.02194944  0.09326162 -0.17192528\n",
      "  0.33559716 -0.06274937 -0.31788398  0.21289207 -0.20128373 -0.2079684\n",
      "  0.09223167 -0.30864712]\n",
      "New theta_0 : [-0.01656377 -0.08189997  0.10946944 -0.02193707  0.09325833 -0.1720115\n",
      "  0.33555134 -0.06271942 -0.31795976  0.21298555 -0.20134505 -0.20798624\n",
      "  0.09222138 -0.30867601]\n",
      "Training Error:  9.772294257685232\n",
      "====================================================================================================\n",
      "Iteration:  650\n",
      "Previous theta :  [-0.01656377 -0.08189997  0.10946944 -0.02193707  0.09325833 -0.1720115\n",
      "  0.33555134 -0.06271942 -0.31795976  0.21298555 -0.20134505 -0.20798624\n",
      "  0.09222138 -0.30867601]\n",
      "New theta_0 : [-0.01656293 -0.08192162  0.109505   -0.02192461  0.09325505 -0.17209715\n",
      "  0.33550583 -0.06268963 -0.31803494  0.21307869 -0.20140633 -0.20800398\n",
      "  0.09221116 -0.3087047 ]\n",
      "Training Error:  9.772262695153078\n",
      "====================================================================================================\n",
      "Iteration:  651\n",
      "Previous theta :  [-0.01656293 -0.08192162  0.109505   -0.02192461  0.09325505 -0.17209715\n",
      "  0.33550583 -0.06268963 -0.31803494  0.21307869 -0.20140633 -0.20800398\n",
      "  0.09221116 -0.3087047 ]\n",
      "New theta_0 : [-0.0165621  -0.08194312  0.10954034 -0.02191207  0.09325178 -0.17218221\n",
      "  0.33546063 -0.06266    -0.31810952  0.21317148 -0.20146755 -0.20802161\n",
      "  0.09220102 -0.30873321]\n",
      "Training Error:  9.772231465653096\n",
      "====================================================================================================\n",
      "Iteration:  652\n",
      "Previous theta :  [-0.0165621  -0.08194312  0.10954034 -0.02191207  0.09325178 -0.17218221\n",
      "  0.33546063 -0.06266    -0.31810952  0.21317148 -0.20146755 -0.20802161\n",
      "  0.09220102 -0.30873321]\n",
      "New theta_0 : [-0.01656127 -0.08196448  0.10957545 -0.02189943  0.0932485  -0.17226671\n",
      "  0.33541575 -0.06263053 -0.3181835   0.21326393 -0.20152872 -0.20803915\n",
      "  0.09219095 -0.30876152]\n",
      "Training Error:  9.77220056491873\n",
      "====================================================================================================\n",
      "Iteration:  653\n",
      "Previous theta :  [-0.01656127 -0.08196448  0.10957545 -0.02189943  0.0932485  -0.17226671\n",
      "  0.33541575 -0.06263053 -0.3181835   0.21326393 -0.20152872 -0.20803915\n",
      "  0.09219095 -0.30876152]\n",
      "New theta_0 : [-0.01656046 -0.08198569  0.10961035 -0.0218867   0.09324523 -0.17235064\n",
      "  0.33537116 -0.06260122 -0.31825688  0.21335604 -0.20158983 -0.20805658\n",
      "  0.09218095 -0.30878964]\n",
      "Training Error:  9.772169988743444\n",
      "====================================================================================================\n",
      "Iteration:  654\n",
      "Previous theta :  [-0.01656046 -0.08198569  0.10961035 -0.0218867   0.09324523 -0.17235064\n",
      "  0.33537116 -0.06260122 -0.31825688  0.21335604 -0.20158983 -0.20805658\n",
      "  0.09218095 -0.30878964]\n",
      "New theta_0 : [-0.01655966 -0.08200676  0.10964502 -0.02187389  0.09324196 -0.172434\n",
      "  0.33532688 -0.06257206 -0.31832968  0.21344782 -0.20165089 -0.20807392\n",
      "  0.09217102 -0.30881758]\n",
      "Training Error:  9.772139732979836\n",
      "====================================================================================================\n",
      "Iteration:  655\n",
      "Previous theta :  [-0.01655966 -0.08200676  0.10964502 -0.02187389  0.09324196 -0.172434\n",
      "  0.33532688 -0.06257206 -0.31832968  0.21344782 -0.20165089 -0.20807392\n",
      "  0.09217102 -0.30881758]\n",
      "New theta_0 : [-0.01655886 -0.0820277   0.10967947 -0.02186099  0.0932387  -0.17251681\n",
      "  0.33528291 -0.06254307 -0.31840189  0.21353926 -0.2017119  -0.20809115\n",
      "  0.09216117 -0.30884533]\n",
      "Training Error:  9.77210979353878\n",
      "====================================================================================================\n",
      "Iteration:  656\n",
      "Previous theta :  [-0.01655886 -0.0820277   0.10967947 -0.02186099  0.0932387  -0.17251681\n",
      "  0.33528291 -0.06254307 -0.31840189  0.21353926 -0.2017119  -0.20809115\n",
      "  0.09216117 -0.30884533]\n",
      "New theta_0 : [-0.01655807 -0.08204849  0.1097137  -0.02184801  0.09323544 -0.17259906\n",
      "  0.33523923 -0.06251423 -0.31847352  0.21363036 -0.20177285 -0.20810829\n",
      "  0.09215138 -0.30887289]\n",
      "Training Error:  9.772080166388559\n",
      "====================================================================================================\n",
      "Iteration:  657\n",
      "Previous theta :  [-0.01655807 -0.08204849  0.1097137  -0.02184801  0.09323544 -0.17259906\n",
      "  0.33523923 -0.06251423 -0.31847352  0.21363036 -0.20177285 -0.20810829\n",
      "  0.09215138 -0.30887289]\n",
      "New theta_0 : [-0.01655729 -0.08206915  0.10974772 -0.02183495  0.09323219 -0.17268075\n",
      "  0.33519585 -0.06248555 -0.31854458  0.21372113 -0.20183375 -0.20812533\n",
      "  0.09214167 -0.30890027]\n",
      "Training Error:  9.772050847554045\n",
      "====================================================================================================\n",
      "Iteration:  658\n",
      "Previous theta :  [-0.01655729 -0.08206915  0.10974772 -0.02183495  0.09323219 -0.17268075\n",
      "  0.33519585 -0.06248555 -0.31854458  0.21372113 -0.20183375 -0.20812533\n",
      "  0.09214167 -0.30890027]\n",
      "New theta_0 : [-0.01655652 -0.08208967  0.10978152 -0.0218218   0.09322893 -0.1727619\n",
      "  0.33515276 -0.06245703 -0.31861506  0.21381157 -0.20189459 -0.20814227\n",
      "  0.09213203 -0.30892747]\n",
      "Training Error:  9.77202183311586\n",
      "====================================================================================================\n",
      "Iteration:  659\n",
      "Previous theta :  [-0.01655652 -0.08208967  0.10978152 -0.0218218   0.09322893 -0.1727619\n",
      "  0.33515276 -0.06245703 -0.31861506  0.21381157 -0.20189459 -0.20814227\n",
      "  0.09213203 -0.30892747]\n",
      "New theta_0 : [-0.01655576 -0.08211005  0.10981511 -0.02180858  0.09322569 -0.1728425\n",
      "  0.33510997 -0.06242866 -0.31868498  0.21390168 -0.20195537 -0.20815911\n",
      "  0.09212246 -0.30895449]\n",
      "Training Error:  9.771993119209554\n",
      "====================================================================================================\n",
      "Iteration:  660\n",
      "Previous theta :  [-0.01655576 -0.08211005  0.10981511 -0.02180858  0.09322569 -0.1728425\n",
      "  0.33510997 -0.06242866 -0.31868498  0.21390168 -0.20195537 -0.20815911\n",
      "  0.09212246 -0.30895449]\n",
      "New theta_0 : [-0.016555   -0.0821303   0.10984849 -0.02179528  0.09322244 -0.17292255\n",
      "  0.33506746 -0.06240044 -0.31875434  0.21399146 -0.2020161  -0.20817586\n",
      "  0.09211295 -0.30898133]\n",
      "Training Error:  9.771964702024825\n",
      "====================================================================================================\n",
      "Iteration:  661\n",
      "Previous theta :  [-0.016555   -0.0821303   0.10984849 -0.02179528  0.09322244 -0.17292255\n",
      "  0.33506746 -0.06240044 -0.31875434  0.21399146 -0.2020161  -0.20817586\n",
      "  0.09211295 -0.30898133]\n",
      "New theta_0 : [-0.01655426 -0.08215041  0.10988166 -0.0217819   0.0932192  -0.17300207\n",
      "  0.33502525 -0.06237237 -0.31882314  0.21408092 -0.20207677 -0.20819251\n",
      "  0.09210351 -0.30900798]\n",
      "Training Error:  9.771936577804698\n",
      "====================================================================================================\n",
      "Iteration:  662\n",
      "Previous theta :  [-0.01655426 -0.08215041  0.10988166 -0.0217819   0.0932192  -0.17300207\n",
      "  0.33502525 -0.06237237 -0.31882314  0.21408092 -0.20207677 -0.20819251\n",
      "  0.09210351 -0.30900798]\n",
      "New theta_0 : [-0.01655352 -0.08217039  0.10991462 -0.02176844  0.09321597 -0.17308106\n",
      "  0.33498332 -0.06234446 -0.31889139  0.21417005 -0.20213738 -0.20820907\n",
      "  0.09209415 -0.30903446]\n",
      "Training Error:  9.77190874284477\n",
      "====================================================================================================\n",
      "Iteration:  663\n",
      "Previous theta :  [-0.01655352 -0.08217039  0.10991462 -0.02176844  0.09321597 -0.17308106\n",
      "  0.33498332 -0.06234446 -0.31889139  0.21417005 -0.20213738 -0.20820907\n",
      "  0.09209415 -0.30903446]\n",
      "New theta_0 : [-0.01655279 -0.08219024  0.10994737 -0.02175491  0.09321273 -0.17315952\n",
      "  0.33494167 -0.0623167  -0.31895909  0.21425886 -0.20219793 -0.20822553\n",
      "  0.09208484 -0.30906077]\n",
      "Training Error:  9.77188119349244\n",
      "====================================================================================================\n",
      "Iteration:  664\n",
      "Previous theta :  [-0.01655279 -0.08219024  0.10994737 -0.02175491  0.09321273 -0.17315952\n",
      "  0.33494167 -0.0623167  -0.31895909  0.21425886 -0.20219793 -0.20822553\n",
      "  0.09208484 -0.30906077]\n",
      "New theta_0 : [-0.01655206 -0.08220996  0.10997991 -0.0217413   0.09320951 -0.17323744\n",
      "  0.33490031 -0.06228909 -0.31902625  0.21434735 -0.20225842 -0.2082419\n",
      "  0.09207561 -0.3090869 ]\n",
      "Training Error:  9.771853926146132\n",
      "====================================================================================================\n",
      "Iteration:  665\n",
      "Previous theta :  [-0.01655206 -0.08220996  0.10997991 -0.0217413   0.09320951 -0.17323744\n",
      "  0.33490031 -0.06228909 -0.31902625  0.21434735 -0.20225842 -0.2082419\n",
      "  0.09207561 -0.3090869 ]\n",
      "New theta_0 : [-0.01655135 -0.08222955  0.11001226 -0.02172763  0.09320628 -0.17331485\n",
      "  0.33485923 -0.06226163 -0.31909286  0.21443552 -0.20231886 -0.20825817\n",
      "  0.09206644 -0.30911286]\n",
      "Training Error:  9.771826937254577\n",
      "====================================================================================================\n",
      "Iteration:  666\n",
      "Previous theta :  [-0.01655135 -0.08222955  0.11001226 -0.02172763  0.09320628 -0.17331485\n",
      "  0.33485923 -0.06226163 -0.31909286  0.21443552 -0.20231886 -0.20825817\n",
      "  0.09206644 -0.30911286]\n",
      "New theta_0 : [-0.01655064 -0.08224901  0.11004439 -0.02171388  0.09320306 -0.17339173\n",
      "  0.33481842 -0.06223431 -0.31915895  0.21452337 -0.20237923 -0.20827436\n",
      "  0.09205734 -0.30913864]\n",
      "Training Error:  9.771800223316058\n",
      "====================================================================================================\n",
      "Iteration:  667\n",
      "Previous theta :  [-0.01655064 -0.08224901  0.11004439 -0.02171388  0.09320306 -0.17339173\n",
      "  0.33481842 -0.06223431 -0.31915895  0.21452337 -0.20237923 -0.20827436\n",
      "  0.09205734 -0.30913864]\n",
      "New theta_0 : [-0.01654994 -0.08226834  0.11007633 -0.02170006  0.09319984 -0.1734681\n",
      "  0.33477789 -0.06220715 -0.3192245   0.21461091 -0.20243954 -0.20829045\n",
      "  0.09204831 -0.30916425]\n",
      "Training Error:  9.771773780877702\n",
      "====================================================================================================\n",
      "Iteration:  668\n",
      "Previous theta :  [-0.01654994 -0.08226834  0.11007633 -0.02170006  0.09319984 -0.1734681\n",
      "  0.33477789 -0.06220715 -0.3192245   0.21461091 -0.20243954 -0.20829045\n",
      "  0.09204831 -0.30916425]\n",
      "New theta_0 : [-0.01654925 -0.08228754  0.11010807 -0.02168617  0.09319663 -0.17354396\n",
      "  0.33473764 -0.06218013 -0.31928952  0.21469813 -0.2024998  -0.20830644\n",
      "  0.09203933 -0.30918969]\n",
      "Training Error:  9.771747606534763\n",
      "====================================================================================================\n",
      "Iteration:  669\n",
      "Previous theta :  [-0.01654925 -0.08228754  0.11010807 -0.02168617  0.09319663 -0.17354396\n",
      "  0.33473764 -0.06218013 -0.31928952  0.21469813 -0.2024998  -0.20830644\n",
      "  0.09203933 -0.30918969]\n",
      "New theta_0 : [-0.01654856 -0.08230662  0.11013961 -0.02167221  0.09319342 -0.1736193\n",
      "  0.33469765 -0.06215326 -0.31935402  0.21478504 -0.20255999 -0.20832235\n",
      "  0.09203043 -0.30921497]\n",
      "Training Error:  9.771721696929918\n",
      "====================================================================================================\n",
      "Iteration:  670\n",
      "Previous theta :  [-0.01654856 -0.08230662  0.11013961 -0.02167221  0.09319342 -0.1736193\n",
      "  0.33469765 -0.06215326 -0.31935402  0.21478504 -0.20255999 -0.20832235\n",
      "  0.09203043 -0.30921497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01654789 -0.08232557  0.11017095 -0.02165819  0.09319022 -0.17369414\n",
      "  0.33465794 -0.06212653 -0.319418    0.21487164 -0.20262012 -0.20833817\n",
      "  0.09202158 -0.30924007]\n",
      "Training Error:  9.771696048752572\n",
      "====================================================================================================\n",
      "Iteration:  671\n",
      "Previous theta :  [-0.01654789 -0.08232557  0.11017095 -0.02165819  0.09319022 -0.17369414\n",
      "  0.33465794 -0.06212653 -0.319418    0.21487164 -0.20262012 -0.20833817\n",
      "  0.09202158 -0.30924007]\n",
      "New theta_0 : [-0.01654722 -0.0823444   0.1102021  -0.0216441   0.09318702 -0.17376848\n",
      "  0.33461849 -0.06209995 -0.31948146  0.21495793 -0.20268019 -0.20835389\n",
      "  0.09201281 -0.30926501]\n",
      "Training Error:  9.771670658738191\n",
      "====================================================================================================\n",
      "Iteration:  672\n",
      "Previous theta :  [-0.01654722 -0.0823444   0.1102021  -0.0216441   0.09318702 -0.17376848\n",
      "  0.33461849 -0.06209995 -0.31948146  0.21495793 -0.20268019 -0.20835389\n",
      "  0.09201281 -0.30926501]\n",
      "New theta_0 : [-0.01654655 -0.0823631   0.11023305 -0.02162995  0.09318382 -0.17384232\n",
      "  0.33457931 -0.06207351 -0.31954442  0.21504391 -0.20274019 -0.20836953\n",
      "  0.09200409 -0.30928979]\n",
      "Training Error:  9.771645523667619\n",
      "====================================================================================================\n",
      "Iteration:  673\n",
      "Previous theta :  [-0.01654655 -0.0823631   0.11023305 -0.02162995  0.09318382 -0.17384232\n",
      "  0.33457931 -0.06207351 -0.31954442  0.21504391 -0.20274019 -0.20836953\n",
      "  0.09200409 -0.30928979]\n",
      "New theta_0 : [-0.0165459  -0.08238168  0.11026381 -0.02161574  0.09318063 -0.17391566\n",
      "  0.33454039 -0.06204722 -0.31960687  0.21512958 -0.20280013 -0.20838508\n",
      "  0.09199544 -0.3093144 ]\n",
      "Training Error:  9.771620640366425\n",
      "====================================================================================================\n",
      "Iteration:  674\n",
      "Previous theta :  [-0.0165459  -0.08238168  0.11026381 -0.02161574  0.09318063 -0.17391566\n",
      "  0.33454039 -0.06204722 -0.31960687  0.21512958 -0.20280013 -0.20838508\n",
      "  0.09199544 -0.3093144 ]\n",
      "New theta_0 : [-0.01654525 -0.08240014  0.11029437 -0.02160146  0.09317744 -0.17398851\n",
      "  0.33450174 -0.06202106 -0.31966881  0.21521495 -0.20286001 -0.20840054\n",
      "  0.09198684 -0.30933885]\n",
      "Training Error:  9.771596005704243\n",
      "====================================================================================================\n",
      "Iteration:  675\n",
      "Previous theta :  [-0.01654525 -0.08240014  0.11029437 -0.02160146  0.09317744 -0.17398851\n",
      "  0.33450174 -0.06202106 -0.31966881  0.21521495 -0.20286001 -0.20840054\n",
      "  0.09198684 -0.30933885]\n",
      "New theta_0 : [-0.01654461 -0.08241848  0.11032475 -0.02158712  0.09317426 -0.17406087\n",
      "  0.33446334 -0.06199505 -0.31973026  0.21530002 -0.20291983 -0.20841591\n",
      "  0.09197831 -0.30936314]\n",
      "Training Error:  9.771571616594137\n",
      "====================================================================================================\n",
      "Iteration:  676\n",
      "Previous theta :  [-0.01654461 -0.08241848  0.11032475 -0.02158712  0.09317426 -0.17406087\n",
      "  0.33446334 -0.06199505 -0.31973026  0.21530002 -0.20291983 -0.20841591\n",
      "  0.09197831 -0.30936314]\n",
      "New theta_0 : [-0.01654398 -0.0824367   0.11035494 -0.02157272  0.09317108 -0.17413275\n",
      "  0.3344252  -0.06196918 -0.31979121  0.21538478 -0.20297958 -0.20843119\n",
      "  0.09196985 -0.30938726]\n",
      "Training Error:  9.771547469991976\n",
      "====================================================================================================\n",
      "Iteration:  677\n",
      "Previous theta :  [-0.01654398 -0.0824367   0.11035494 -0.02157272  0.09317108 -0.17413275\n",
      "  0.3344252  -0.06196918 -0.31979121  0.21538478 -0.20297958 -0.20843119\n",
      "  0.09196985 -0.30938726]\n",
      "New theta_0 : [-0.01654335 -0.0824548   0.11038494 -0.02155827  0.0931679  -0.17420414\n",
      "  0.33438732 -0.06194345 -0.31985168  0.21546925 -0.20303926 -0.20844639\n",
      "  0.09196144 -0.30941123]\n",
      "Training Error:  9.771523562895798\n",
      "====================================================================================================\n",
      "Iteration:  678\n",
      "Previous theta :  [-0.01654335 -0.0824548   0.11038494 -0.02155827  0.0931679  -0.17420414\n",
      "  0.33438732 -0.06194345 -0.31985168  0.21546925 -0.20303926 -0.20844639\n",
      "  0.09196144 -0.30941123]\n",
      "New theta_0 : [-0.01654273 -0.08247278  0.11041475 -0.02154375  0.09316473 -0.17427505\n",
      "  0.33434969 -0.06191786 -0.31991165  0.21555341 -0.20309888 -0.2084615\n",
      "  0.09195309 -0.30943504]\n",
      "Training Error:  9.771499892345206\n",
      "====================================================================================================\n",
      "Iteration:  679\n",
      "Previous theta :  [-0.01654273 -0.08247278  0.11041475 -0.02154375  0.09316473 -0.17427505\n",
      "  0.33434969 -0.06191786 -0.31991165  0.21555341 -0.20309888 -0.2084615\n",
      "  0.09195309 -0.30943504]\n",
      "New theta_0 : [-0.01654212 -0.08249065  0.11044438 -0.02152918  0.09316156 -0.17434549\n",
      "  0.33431232 -0.06189241 -0.31997114  0.21563728 -0.20315844 -0.20847653\n",
      "  0.0919448  -0.30945869]\n",
      "Training Error:  9.771476455420764\n",
      "====================================================================================================\n",
      "Iteration:  680\n",
      "Previous theta :  [-0.01654212 -0.08249065  0.11044438 -0.02152918  0.09316156 -0.17434549\n",
      "  0.33431232 -0.06189241 -0.31997114  0.21563728 -0.20315844 -0.20847653\n",
      "  0.0919448  -0.30945869]\n",
      "New theta_0 : [-0.01654152 -0.0825084   0.11047383 -0.02151455  0.0931584  -0.17441546\n",
      "  0.33427519 -0.0618671  -0.32003015  0.21572085 -0.20321793 -0.20849147\n",
      "  0.09193658 -0.30948218]\n",
      "Training Error:  9.771453249243388\n",
      "====================================================================================================\n",
      "Iteration:  681\n",
      "Previous theta :  [-0.01654152 -0.0825084   0.11047383 -0.02151455  0.0931584  -0.17441546\n",
      "  0.33427519 -0.0618671  -0.32003015  0.21572085 -0.20321793 -0.20849147\n",
      "  0.09193658 -0.30948218]\n",
      "New theta_0 : [-0.01654092 -0.08252603  0.11050309 -0.02149987  0.09315524 -0.17448495\n",
      "  0.33423832 -0.06184192 -0.32008869  0.21580413 -0.20327735 -0.20850632\n",
      "  0.09192841 -0.30950552]\n",
      "Training Error:  9.771430270973784\n",
      "====================================================================================================\n",
      "Iteration:  682\n",
      "Previous theta :  [-0.01654092 -0.08252603  0.11050309 -0.02149987  0.09315524 -0.17448495\n",
      "  0.33423832 -0.06184192 -0.32008869  0.21580413 -0.20327735 -0.20850632\n",
      "  0.09192841 -0.30950552]\n",
      "New theta_0 : [-0.01654033 -0.08254355  0.11053217 -0.02148514  0.09315209 -0.17455398\n",
      "  0.33420169 -0.06181688 -0.32014676  0.21588711 -0.20333671 -0.20852109\n",
      "  0.0919203  -0.30952871]\n",
      "Training Error:  9.771407517811857\n",
      "====================================================================================================\n",
      "Iteration:  683\n",
      "Previous theta :  [-0.01654033 -0.08254355  0.11053217 -0.02148514  0.09315209 -0.17455398\n",
      "  0.33420169 -0.06181688 -0.32014676  0.21588711 -0.20333671 -0.20852109\n",
      "  0.0919203  -0.30952871]\n",
      "New theta_0 : [-0.01653974 -0.08256096  0.11056108 -0.02147035  0.09314894 -0.17462255\n",
      "  0.33416531 -0.06179197 -0.32020435  0.2159698  -0.203396   -0.20853578\n",
      "  0.09191225 -0.30955174]\n",
      "Training Error:  9.77138498699614\n",
      "====================================================================================================\n",
      "Iteration:  684\n",
      "Previous theta :  [-0.01653974 -0.08256096  0.11056108 -0.02147035  0.09314894 -0.17462255\n",
      "  0.33416531 -0.06179197 -0.32020435  0.2159698  -0.203396   -0.20853578\n",
      "  0.09191225 -0.30955174]\n",
      "New theta_0 : [-0.01653916 -0.08257825  0.1105898  -0.02145551  0.09314579 -0.17469065\n",
      "  0.33412917 -0.0617672  -0.32026149  0.2160522  -0.20345523 -0.20855038\n",
      "  0.09190425 -0.30957463]\n",
      "Training Error:  9.77136267580323\n",
      "====================================================================================================\n",
      "Iteration:  685\n",
      "Previous theta :  [-0.01653916 -0.08257825  0.1105898  -0.02145551  0.09314579 -0.17469065\n",
      "  0.33412917 -0.0617672  -0.32026149  0.2160522  -0.20345523 -0.20855038\n",
      "  0.09190425 -0.30957463]\n",
      "New theta_0 : [-0.01653859 -0.08259543  0.11061835 -0.02144062  0.09314265 -0.1747583\n",
      "  0.33409327 -0.06174256 -0.32031816  0.21613432 -0.20351438 -0.2085649\n",
      "  0.09189632 -0.30959736]\n",
      "Training Error:  9.771340581547264\n",
      "====================================================================================================\n",
      "Iteration:  686\n",
      "Previous theta :  [-0.01653859 -0.08259543  0.11061835 -0.02144062  0.09314265 -0.1747583\n",
      "  0.33409327 -0.06174256 -0.32031816  0.21613432 -0.20351438 -0.2085649\n",
      "  0.09189632 -0.30959736]\n",
      "New theta_0 : [-0.01653803 -0.0826125   0.11064672 -0.02142568  0.09313952 -0.1748255\n",
      "  0.33405761 -0.06171806 -0.32037437  0.21621615 -0.20357347 -0.20857934\n",
      "  0.09188844 -0.30961994]\n",
      "Training Error:  9.771318701579325\n",
      "====================================================================================================\n",
      "Iteration:  687\n",
      "Previous theta :  [-0.01653803 -0.0826125   0.11064672 -0.02142568  0.09313952 -0.1748255\n",
      "  0.33405761 -0.06171806 -0.32037437  0.21621615 -0.20357347 -0.20857934\n",
      "  0.09188844 -0.30961994]\n",
      "New theta_0 : [-0.01653747 -0.08262946  0.11067492 -0.02141069  0.09313638 -0.17489224\n",
      "  0.33402219 -0.06169369 -0.32043014  0.21629769 -0.20363249 -0.2085937\n",
      "  0.09188061 -0.30964238]\n",
      "Training Error:  9.771297033286963\n",
      "====================================================================================================\n",
      "Iteration:  688\n",
      "Previous theta :  [-0.01653747 -0.08262946  0.11067492 -0.02141069  0.09313638 -0.17489224\n",
      "  0.33402219 -0.06169369 -0.32043014  0.21629769 -0.20363249 -0.2085937\n",
      "  0.09188061 -0.30964238]\n",
      "New theta_0 : [-0.01653692 -0.08264631  0.11070294 -0.02139565  0.09313326 -0.17495854\n",
      "  0.333987   -0.06166945 -0.32048545  0.21637894 -0.20369144 -0.20860798\n",
      "  0.09187285 -0.30966466]\n",
      "Training Error:  9.77127557409362\n",
      "====================================================================================================\n",
      "Iteration:  689\n",
      "Previous theta :  [-0.01653692 -0.08264631  0.11070294 -0.02139565  0.09313326 -0.17495854\n",
      "  0.333987   -0.06166945 -0.32048545  0.21637894 -0.20369144 -0.20860798\n",
      "  0.09187285 -0.30966466]\n",
      "New theta_0 : [-0.01653638 -0.08266305  0.11073079 -0.02138057  0.09313013 -0.17502439\n",
      "  0.33395205 -0.06164534 -0.32054031  0.21645992 -0.20375032 -0.20862217\n",
      "  0.09186513 -0.3096868 ]\n",
      "Training Error:  9.771254321458137\n",
      "====================================================================================================\n",
      "Iteration:  690\n",
      "Previous theta :  [-0.01653638 -0.08266305  0.11073079 -0.02138057  0.09313013 -0.17502439\n",
      "  0.33395205 -0.06164534 -0.32054031  0.21645992 -0.20375032 -0.20862217\n",
      "  0.09186513 -0.3096868 ]\n",
      "New theta_0 : [-0.01653584 -0.08267968  0.11075847 -0.02136544  0.09312701 -0.1750898\n",
      "  0.33391734 -0.06162136 -0.32059474  0.21654061 -0.20380913 -0.20863628\n",
      "  0.09185748 -0.3097088 ]\n",
      "Training Error:  9.771233272874234\n",
      "====================================================================================================\n",
      "Iteration:  691\n",
      "Previous theta :  [-0.01653584 -0.08267968  0.11075847 -0.02136544  0.09312701 -0.1750898\n",
      "  0.33391734 -0.06162136 -0.32059474  0.21654061 -0.20380913 -0.20863628\n",
      "  0.09185748 -0.3097088 ]\n",
      "New theta_0 : [-0.01653531 -0.08269621  0.11078598 -0.02135026  0.0931239  -0.17515478\n",
      "  0.33388285 -0.06159751 -0.32064872  0.21662102 -0.20386787 -0.20865032\n",
      "  0.09184988 -0.30973065]\n",
      "Training Error:  9.77121242587\n",
      "====================================================================================================\n",
      "Iteration:  692\n",
      "Previous theta :  [-0.01653531 -0.08269621  0.11078598 -0.02135026  0.0931239  -0.17515478\n",
      "  0.33388285 -0.06159751 -0.32064872  0.21662102 -0.20386787 -0.20865032\n",
      "  0.09184988 -0.30973065]\n",
      "New theta_0 : [-0.01653478 -0.08271263  0.11081332 -0.02133504  0.09312079 -0.17521931\n",
      "  0.33384859 -0.06157379 -0.32070227  0.21670115 -0.20392654 -0.20866427\n",
      "  0.09184233 -0.30975235]\n",
      "Training Error:  9.771191778007415\n",
      "====================================================================================================\n",
      "Iteration:  693\n",
      "Previous theta :  [-0.01653478 -0.08271263  0.11081332 -0.02133504  0.09312079 -0.17521931\n",
      "  0.33384859 -0.06157379 -0.32070227  0.21670115 -0.20392654 -0.20866427\n",
      "  0.09184233 -0.30975235]\n",
      "New theta_0 : [-0.01653426 -0.08272894  0.1108405  -0.02131978  0.09311768 -0.17528342\n",
      "  0.33381456 -0.0615502  -0.32075538  0.21678101 -0.20398515 -0.20867815\n",
      "  0.09183484 -0.30977392]\n",
      "Training Error:  9.771171326881825\n",
      "====================================================================================================\n",
      "Iteration:  694\n",
      "Previous theta :  [-0.01653426 -0.08272894  0.1108405  -0.02131978  0.09311768 -0.17528342\n",
      "  0.33381456 -0.0615502  -0.32075538  0.21678101 -0.20398515 -0.20867815\n",
      "  0.09183484 -0.30977392]\n",
      "New theta_0 : [-0.01653375 -0.08274515  0.11086751 -0.02130448  0.09311458 -0.17534709\n",
      "  0.33378076 -0.06152673 -0.32080807  0.21686059 -0.20404368 -0.20869195\n",
      "  0.0918274  -0.30979534]\n",
      "Training Error:  9.771151070121498\n",
      "====================================================================================================\n",
      "Iteration:  695\n",
      "Previous theta :  [-0.01653375 -0.08274515  0.11086751 -0.02130448  0.09311458 -0.17534709\n",
      "  0.33378076 -0.06152673 -0.32080807  0.21686059 -0.20404368 -0.20869195\n",
      "  0.0918274  -0.30979534]\n",
      "New theta_0 : [-0.01653324 -0.08276125  0.11089435 -0.02128913  0.09311149 -0.17541034\n",
      "  0.33374718 -0.06150339 -0.32086033  0.21693989 -0.20410214 -0.20870567\n",
      "  0.09182001 -0.30981663]\n",
      "Training Error:  9.77113100538712\n",
      "====================================================================================================\n",
      "Iteration:  696\n",
      "Previous theta :  [-0.01653324 -0.08276125  0.11089435 -0.02128913  0.09311149 -0.17541034\n",
      "  0.33374718 -0.06150339 -0.32086033  0.21693989 -0.20410214 -0.20870567\n",
      "  0.09182001 -0.30981663]\n",
      "New theta_0 : [-0.01653274 -0.08277725  0.11092103 -0.02127375  0.09310839 -0.17547316\n",
      "  0.33371383 -0.06148018 -0.32091217  0.21701893 -0.20416052 -0.20871931\n",
      "  0.09181268 -0.30983777]\n",
      "Training Error:  9.771111130371343\n",
      "====================================================================================================\n",
      "Iteration:  697\n",
      "Previous theta :  [-0.01653274 -0.08277725  0.11092103 -0.02127375  0.09310839 -0.17547316\n",
      "  0.33371383 -0.06148018 -0.32091217  0.21701893 -0.20416052 -0.20871931\n",
      "  0.09181268 -0.30983777]\n",
      "New theta_0 : [-0.01653225 -0.08279315  0.11094755 -0.02125832  0.09310531 -0.17553557\n",
      "  0.33368069 -0.0614571  -0.32096359  0.21709768 -0.20421884 -0.20873288\n",
      "  0.0918054  -0.30985878]\n",
      "Training Error:  9.771091442798317\n",
      "====================================================================================================\n",
      "Iteration:  698\n",
      "Previous theta :  [-0.01653225 -0.08279315  0.11094755 -0.02125832  0.09310531 -0.17553557\n",
      "  0.33368069 -0.0614571  -0.32096359  0.21709768 -0.20421884 -0.20873288\n",
      "  0.0918054  -0.30985878]\n",
      "New theta_0 : [-0.01653176 -0.08280895  0.1109739  -0.02124285  0.09310222 -0.17559755\n",
      "  0.33364778 -0.06143413 -0.32101459  0.21717617 -0.20427708 -0.20874636\n",
      "  0.09179817 -0.30987965]\n",
      "Training Error:  9.771071940423235\n",
      "====================================================================================================\n",
      "Iteration:  699\n",
      "Previous theta :  [-0.01653176 -0.08280895  0.1109739  -0.02124285  0.09310222 -0.17559755\n",
      "  0.33364778 -0.06143413 -0.32101459  0.21717617 -0.20427708 -0.20874636\n",
      "  0.09179817 -0.30987965]\n",
      "New theta_0 : [-0.01653128 -0.08282465  0.1110001  -0.02122735  0.09309914 -0.17565912\n",
      "  0.33361508 -0.0614113  -0.32106519  0.21725439 -0.20433526 -0.20875978\n",
      "  0.09179099 -0.30990038]\n",
      "Training Error:  9.77105262103189\n",
      "====================================================================================================\n",
      "Iteration:  700\n",
      "Previous theta :  [-0.01653128 -0.08282465  0.1110001  -0.02122735  0.09309914 -0.17565912\n",
      "  0.33361508 -0.0614113  -0.32106519  0.21725439 -0.20433526 -0.20875978\n",
      "  0.09179099 -0.30990038]\n",
      "New theta_0 : [-0.0165308  -0.08284024  0.11102613 -0.02121181  0.09309607 -0.17572028\n",
      "  0.3335826  -0.06138858 -0.32111537  0.21733234 -0.20439336 -0.20877311\n",
      "  0.09178387 -0.30992098]\n",
      "Training Error:  9.771033482440224\n",
      "====================================================================================================\n",
      "Iteration:  701\n",
      "Previous theta :  [-0.0165308  -0.08284024  0.11102613 -0.02121181  0.09309607 -0.17572028\n",
      "  0.3335826  -0.06138858 -0.32111537  0.21733234 -0.20439336 -0.20877311\n",
      "  0.09178387 -0.30992098]\n",
      "New theta_0 : [-0.01653033 -0.08285574  0.11105201 -0.02119623  0.093093   -0.17578102\n",
      "  0.33355034 -0.06136599 -0.32116515  0.21741003 -0.20445138 -0.20878638\n",
      "  0.09177679 -0.30994144]\n",
      "Training Error:  9.771014522493902\n",
      "====================================================================================================\n",
      "Iteration:  702\n",
      "Previous theta :  [-0.01653033 -0.08285574  0.11105201 -0.02119623  0.093093   -0.17578102\n",
      "  0.33355034 -0.06136599 -0.32116515  0.21741003 -0.20445138 -0.20878638\n",
      "  0.09177679 -0.30994144]\n",
      "New theta_0 : [-0.01652987 -0.08287114  0.11107773 -0.02118062  0.09308994 -0.17584136\n",
      "  0.33351828 -0.06134352 -0.32121452  0.21748745 -0.20450934 -0.20879956\n",
      "  0.09176977 -0.30996177]\n",
      "Training Error:  9.770995739067878\n",
      "====================================================================================================\n",
      "Iteration:  703\n",
      "Previous theta :  [-0.01652987 -0.08287114  0.11107773 -0.02118062  0.09308994 -0.17584136\n",
      "  0.33351828 -0.06134352 -0.32121452  0.21748745 -0.20450934 -0.20879956\n",
      "  0.09176977 -0.30996177]\n",
      "New theta_0 : [-0.01652941 -0.08288644  0.1111033  -0.02116498  0.09308688 -0.1759013\n",
      "  0.33348644 -0.06132117 -0.3212635   0.2175646  -0.20456722 -0.20881268\n",
      "  0.0917628  -0.30998196]\n",
      "Training Error:  9.770977130065985\n",
      "====================================================================================================\n",
      "Iteration:  704\n",
      "Previous theta :  [-0.01652941 -0.08288644  0.1111033  -0.02116498  0.09308688 -0.1759013\n",
      "  0.33348644 -0.06132117 -0.3212635   0.2175646  -0.20456722 -0.20881268\n",
      "  0.0917628  -0.30998196]\n",
      "New theta_0 : [-0.01652896 -0.08290164  0.11112871 -0.02114929  0.09308382 -0.17596083\n",
      "  0.33345481 -0.06129894 -0.32131207  0.21764149 -0.20462502 -0.20882571\n",
      "  0.09175587 -0.31000203]\n",
      "Training Error:  9.770958693420498\n",
      "====================================================================================================\n",
      "Iteration:  705\n",
      "Previous theta :  [-0.01652896 -0.08290164  0.11112871 -0.02114929  0.09308382 -0.17596083\n",
      "  0.33345481 -0.06129894 -0.32131207  0.21764149 -0.20462502 -0.20882571\n",
      "  0.09175587 -0.31000203]\n",
      "New theta_0 : [-0.01652851 -0.08291675  0.11115396 -0.02113358  0.09308077 -0.17601997\n",
      "  0.33342339 -0.06127684 -0.32136026  0.21771812 -0.20468276 -0.20883868\n",
      "  0.091749   -0.31002196]\n",
      "Training Error:  9.770940427091745\n",
      "====================================================================================================\n",
      "Iteration:  706\n",
      "Previous theta :  [-0.01652851 -0.08291675  0.11115396 -0.02113358  0.09308077 -0.17601997\n",
      "  0.33342339 -0.06127684 -0.32136026  0.21771812 -0.20468276 -0.20883868\n",
      "  0.091749   -0.31002196]\n",
      "New theta_0 : [-0.01652807 -0.08293175  0.11117907 -0.02111783  0.09307772 -0.17607871\n",
      "  0.33339218 -0.06125485 -0.32140806  0.21779449 -0.20474041 -0.20885157\n",
      "  0.09174217 -0.31004177]\n",
      "Training Error:  9.77092232906769\n",
      "====================================================================================================\n",
      "Iteration:  707\n",
      "Previous theta :  [-0.01652807 -0.08293175  0.11117907 -0.02111783  0.09307772 -0.17607871\n",
      "  0.33339218 -0.06125485 -0.32140806  0.21779449 -0.20474041 -0.20885157\n",
      "  0.09174217 -0.31004177]\n",
      "New theta_0 : [-0.01652763 -0.08294667  0.11120402 -0.02110206  0.09307468 -0.17613706\n",
      "  0.33336117 -0.06123298 -0.32145547  0.2178706  -0.204798   -0.20886439\n",
      "  0.0917354  -0.31006144]\n",
      "Training Error:  9.770904397363541\n",
      "====================================================================================================\n",
      "Iteration:  708\n",
      "Previous theta :  [-0.01652763 -0.08294667  0.11120402 -0.02110206  0.09307468 -0.17613706\n",
      "  0.33336117 -0.06123298 -0.32145547  0.2178706  -0.204798   -0.20886439\n",
      "  0.0917354  -0.31006144]\n",
      "New theta_0 : [-0.0165272  -0.08296149  0.11122882 -0.02108625  0.09307164 -0.17619501\n",
      "  0.33333036 -0.06121122 -0.32150249  0.21794645 -0.20485551 -0.20887714\n",
      "  0.09172867 -0.31008099]\n",
      "Training Error:  9.770886630021359\n",
      "====================================================================================================\n",
      "Iteration:  709\n",
      "Previous theta :  [-0.0165272  -0.08296149  0.11122882 -0.02108625  0.09307164 -0.17619501\n",
      "  0.33333036 -0.06121122 -0.32150249  0.21794645 -0.20485551 -0.20887714\n",
      "  0.09172867 -0.31008099]\n",
      "New theta_0 : [-0.01652678 -0.08297622  0.11125347 -0.02107041  0.09306861 -0.17625258\n",
      "  0.33329976 -0.06118959 -0.32154913  0.21802204 -0.20491294 -0.20888981\n",
      "  0.09172199 -0.31010041]\n",
      "Training Error:  9.770869025109667\n",
      "====================================================================================================\n",
      "Iteration:  710\n",
      "Previous theta :  [-0.01652678 -0.08297622  0.11125347 -0.02107041  0.09306861 -0.17625258\n",
      "  0.33329976 -0.06118959 -0.32154913  0.21802204 -0.20491294 -0.20888981\n",
      "  0.09172199 -0.31010041]\n",
      "New theta_0 : [-0.01652636 -0.08299085  0.11127798 -0.02105454  0.09306559 -0.17630976\n",
      "  0.33326936 -0.06116807 -0.3215954   0.21809738 -0.2049703  -0.20890242\n",
      "  0.09171536 -0.3101197 ]\n",
      "Training Error:  9.770851580723077\n",
      "====================================================================================================\n",
      "Iteration:  711\n",
      "Previous theta :  [-0.01652636 -0.08299085  0.11127798 -0.02105454  0.09306559 -0.17630976\n",
      "  0.33326936 -0.06116807 -0.3215954   0.21809738 -0.2049703  -0.20890242\n",
      "  0.09171536 -0.3101197 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01652595 -0.08300539  0.11130233 -0.02103864  0.09306256 -0.17636656\n",
      "  0.33323916 -0.06114667 -0.32164129  0.21817247 -0.20502758 -0.20891495\n",
      "  0.09170877 -0.31013887]\n",
      "Training Error:  9.770834294981906\n",
      "====================================================================================================\n",
      "Iteration:  712\n",
      "Previous theta :  [-0.01652595 -0.08300539  0.11130233 -0.02103864  0.09306256 -0.17636656\n",
      "  0.33323916 -0.06114667 -0.32164129  0.21817247 -0.20502758 -0.20891495\n",
      "  0.09170877 -0.31013887]\n",
      "New theta_0 : [-0.01652554 -0.08301984  0.11132654 -0.02102272  0.09305954 -0.17642298\n",
      "  0.33320916 -0.06112538 -0.32168681  0.2182473  -0.20508479 -0.20892742\n",
      "  0.09170224 -0.31015792]\n",
      "Training Error:  9.77081716603182\n",
      "====================================================================================================\n",
      "Iteration:  713\n",
      "Previous theta :  [-0.01652554 -0.08301984  0.11132654 -0.02102272  0.09305954 -0.17642298\n",
      "  0.33320916 -0.06112538 -0.32168681  0.2182473  -0.20508479 -0.20892742\n",
      "  0.09170224 -0.31015792]\n",
      "New theta_0 : [-0.01652514 -0.0830342   0.11135061 -0.02100677  0.09305653 -0.17647903\n",
      "  0.33317935 -0.06110421 -0.32173196  0.21832188 -0.20514192 -0.20893981\n",
      "  0.09169574 -0.31017684]\n",
      "Training Error:  9.770800192043456\n",
      "====================================================================================================\n",
      "Iteration:  714\n",
      "Previous theta :  [-0.01652514 -0.0830342   0.11135061 -0.02100677  0.09305653 -0.17647903\n",
      "  0.33317935 -0.06110421 -0.32173196  0.21832188 -0.20514192 -0.20893981\n",
      "  0.09169574 -0.31017684]\n",
      "New theta_0 : [-0.01652474 -0.08304846  0.11137453 -0.02099079  0.09305352 -0.17653469\n",
      "  0.33314974 -0.06108315 -0.32177675  0.2183962  -0.20519897 -0.20895213\n",
      "  0.0916893  -0.31019564]\n",
      "Training Error:  9.770783371212067\n",
      "====================================================================================================\n",
      "Iteration:  715\n",
      "Previous theta :  [-0.01652474 -0.08304846  0.11137453 -0.02099079  0.09305352 -0.17653469\n",
      "  0.33314974 -0.06108315 -0.32177675  0.2183962  -0.20519897 -0.20895213\n",
      "  0.0916893  -0.31019564]\n",
      "New theta_0 : [-0.01652435 -0.08306264  0.11139831 -0.02097478  0.09305052 -0.17658999\n",
      "  0.33312033 -0.0610622  -0.32182117  0.21847028 -0.20525595 -0.20896439\n",
      "  0.0916829  -0.31021431]\n",
      "Training Error:  9.770766701757186\n",
      "====================================================================================================\n",
      "Iteration:  716\n",
      "Previous theta :  [-0.01652435 -0.08306264  0.11139831 -0.02097478  0.09305052 -0.17658999\n",
      "  0.33312033 -0.0610622  -0.32182117  0.21847028 -0.20525595 -0.20896439\n",
      "  0.0916829  -0.31021431]\n",
      "New theta_0 : [-0.01652396 -0.08307673  0.11142194 -0.02095876  0.09304752 -0.17664491\n",
      "  0.3330911  -0.06104137 -0.32186523  0.21854411 -0.20531285 -0.20897657\n",
      "  0.09167655 -0.31023287]\n",
      "Training Error:  9.770750181922248\n",
      "====================================================================================================\n",
      "Iteration:  717\n",
      "Previous theta :  [-0.01652396 -0.08307673  0.11142194 -0.02095876  0.09304752 -0.17664491\n",
      "  0.3330911  -0.06104137 -0.32186523  0.21854411 -0.20531285 -0.20897657\n",
      "  0.09167655 -0.31023287]\n",
      "New theta_0 : [-0.01652358 -0.08309073  0.11144544 -0.0209427   0.09304452 -0.17669947\n",
      "  0.33306207 -0.06102065 -0.32190893  0.21861769 -0.20536968 -0.20898869\n",
      "  0.09167024 -0.3102513 ]\n",
      "Training Error:  9.770733809974274\n",
      "====================================================================================================\n",
      "Iteration:  718\n",
      "Previous theta :  [-0.01652358 -0.08309073  0.11144544 -0.0209427   0.09304452 -0.17669947\n",
      "  0.33306207 -0.06102065 -0.32190893  0.21861769 -0.20536968 -0.20898869\n",
      "  0.09167024 -0.3102513 ]\n",
      "New theta_0 : [-0.01652321 -0.08310464  0.11146879 -0.02092663  0.09304154 -0.17675366\n",
      "  0.33303323 -0.06100004 -0.32195228  0.21869103 -0.20542642 -0.20900074\n",
      "  0.09166398 -0.31026962]\n",
      "Training Error:  9.770717584203522\n",
      "====================================================================================================\n",
      "Iteration:  719\n",
      "Previous theta :  [-0.01652321 -0.08310464  0.11146879 -0.02092663  0.09304154 -0.17675366\n",
      "  0.33303323 -0.06100004 -0.32195228  0.21869103 -0.20542642 -0.20900074\n",
      "  0.09166398 -0.31026962]\n",
      "New theta_0 : [-0.01652284 -0.08311847  0.111492   -0.02091053  0.09303855 -0.17680749\n",
      "  0.33300457 -0.06097954 -0.32199528  0.21876412 -0.20548309 -0.20901272\n",
      "  0.09165776 -0.31028782]\n",
      "Training Error:  9.77070150292315\n",
      "====================================================================================================\n",
      "Iteration:  720\n",
      "Previous theta :  [-0.01652284 -0.08311847  0.111492   -0.02091053  0.09303855 -0.17680749\n",
      "  0.33300457 -0.06097954 -0.32199528  0.21876412 -0.20548309 -0.20901272\n",
      "  0.09165776 -0.31028782]\n",
      "New theta_0 : [-0.01652247 -0.08313221  0.11151508 -0.0208944   0.09303557 -0.17686096\n",
      "  0.33297611 -0.06095915 -0.32203793  0.21883697 -0.20553968 -0.20902464\n",
      "  0.09165159 -0.3103059 ]\n",
      "Training Error:  9.770685564468893\n",
      "====================================================================================================\n",
      "Iteration:  721\n",
      "Previous theta :  [-0.01652247 -0.08313221  0.11151508 -0.0208944   0.09303557 -0.17686096\n",
      "  0.33297611 -0.06095915 -0.32203793  0.21883697 -0.20553968 -0.20902464\n",
      "  0.09165159 -0.3103059 ]\n",
      "New theta_0 : [-0.01652211 -0.08314586  0.11153802 -0.02087826  0.0930326  -0.17691407\n",
      "  0.33294783 -0.06093887 -0.32208023  0.21890957 -0.2055962  -0.20903648\n",
      "  0.09164546 -0.31032386]\n",
      "Training Error:  9.770669767198754\n",
      "====================================================================================================\n",
      "Iteration:  722\n",
      "Previous theta :  [-0.01652211 -0.08314586  0.11153802 -0.02087826  0.0930326  -0.17691407\n",
      "  0.33294783 -0.06093887 -0.32208023  0.21890957 -0.2055962  -0.20903648\n",
      "  0.09164546 -0.31032386]\n",
      "New theta_0 : [-0.01652175 -0.08315943  0.11156082 -0.0208621   0.09302962 -0.17696683\n",
      "  0.33291973 -0.0609187  -0.32212219  0.21898194 -0.20565263 -0.20904827\n",
      "  0.09163937 -0.31034171]\n",
      "Training Error:  9.770654109492654\n",
      "====================================================================================================\n",
      "Iteration:  723\n",
      "Previous theta :  [-0.01652175 -0.08315943  0.11156082 -0.0208621   0.09302962 -0.17696683\n",
      "  0.33291973 -0.0609187  -0.32212219  0.21898194 -0.20565263 -0.20904827\n",
      "  0.09163937 -0.31034171]\n",
      "New theta_0 : [-0.0165214  -0.08317291  0.11158349 -0.02084591  0.09302666 -0.17701924\n",
      "  0.33289182 -0.06089864 -0.32216381  0.21905406 -0.20570899 -0.20905998\n",
      "  0.09163333 -0.31035944]\n",
      "Training Error:  9.770638589752147\n",
      "====================================================================================================\n",
      "Iteration:  724\n",
      "Previous theta :  [-0.0165214  -0.08317291  0.11158349 -0.02084591  0.09302666 -0.17701924\n",
      "  0.33289182 -0.06089864 -0.32216381  0.21905406 -0.20570899 -0.20905998\n",
      "  0.09163333 -0.31035944]\n",
      "New theta_0 : [-0.01652106 -0.08318631  0.11160602 -0.02082971  0.0930237  -0.17707129\n",
      "  0.33286409 -0.06087869 -0.32220509  0.21912594 -0.20576527 -0.20907163\n",
      "  0.09162733 -0.31037706]\n",
      "Training Error:  9.770623206400101\n",
      "====================================================================================================\n",
      "Iteration:  725\n",
      "Previous theta :  [-0.01652106 -0.08318631  0.11160602 -0.02082971  0.0930237  -0.17707129\n",
      "  0.33286409 -0.06087869 -0.32220509  0.21912594 -0.20576527 -0.20907163\n",
      "  0.09162733 -0.31037706]\n",
      "New theta_0 : [-0.01652072 -0.08319962  0.11162842 -0.02081348  0.09302074 -0.177123\n",
      "  0.33283654 -0.06085884 -0.32224603  0.21919759 -0.20582147 -0.20908322\n",
      "  0.09162137 -0.31039456]\n",
      "Training Error:  9.770607957880387\n",
      "====================================================================================================\n",
      "Iteration:  726\n",
      "Previous theta :  [-0.01652072 -0.08319962  0.11162842 -0.02081348  0.09302074 -0.177123\n",
      "  0.33283654 -0.06085884 -0.32224603  0.21919759 -0.20582147 -0.20908322\n",
      "  0.09162137 -0.31039456]\n",
      "New theta_0 : [-0.01652038 -0.08321286  0.11165069 -0.02079724  0.09301779 -0.17717436\n",
      "  0.33280916 -0.0608391  -0.32228664  0.219269   -0.20587759 -0.20909473\n",
      "  0.09161546 -0.31041195]\n",
      "Training Error:  9.770592842657596\n",
      "====================================================================================================\n",
      "Iteration:  727\n",
      "Previous theta :  [-0.01652038 -0.08321286  0.11165069 -0.02079724  0.09301779 -0.17717436\n",
      "  0.33280916 -0.0608391  -0.32228664  0.219269   -0.20587759 -0.20909473\n",
      "  0.09161546 -0.31041195]\n",
      "New theta_0 : [-0.01652005 -0.08322601  0.11167283 -0.02078098  0.09301485 -0.17722538\n",
      "  0.33278197 -0.06081947 -0.32232693  0.21934017 -0.20593363 -0.20910619\n",
      "  0.09160959 -0.31042923]\n",
      "Training Error:  9.770577859216722\n",
      "====================================================================================================\n",
      "Iteration:  728\n",
      "Previous theta :  [-0.01652005 -0.08322601  0.11167283 -0.02078098  0.09301485 -0.17722538\n",
      "  0.33278197 -0.06081947 -0.32232693  0.21934017 -0.20593363 -0.20910619\n",
      "  0.09160959 -0.31042923]\n",
      "New theta_0 : [-0.01651972 -0.08323908  0.11169483 -0.0207647   0.0930119  -0.17727605\n",
      "  0.33275495 -0.06079994 -0.32236688  0.2194111  -0.20598959 -0.20911758\n",
      "  0.09160376 -0.3104464 ]\n",
      "Training Error:  9.770563006062892\n",
      "====================================================================================================\n",
      "Iteration:  729\n",
      "Previous theta :  [-0.01651972 -0.08323908  0.11169483 -0.0207647   0.0930119  -0.17727605\n",
      "  0.33275495 -0.06079994 -0.32236688  0.2194111  -0.20598959 -0.20911758\n",
      "  0.09160376 -0.3104464 ]\n",
      "New theta_0 : [-0.0165194  -0.08325206  0.11171671 -0.02074841  0.09300897 -0.17732639\n",
      "  0.33272811 -0.06078051 -0.32240651  0.21948181 -0.20604547 -0.20912891\n",
      "  0.09159797 -0.31046346]\n",
      "Training Error:  9.77054828172106\n",
      "====================================================================================================\n",
      "Iteration:  730\n",
      "Previous theta :  [-0.0165194  -0.08325206  0.11171671 -0.02074841  0.09300897 -0.17732639\n",
      "  0.33272811 -0.06078051 -0.32240651  0.21948181 -0.20604547 -0.20912891\n",
      "  0.09159797 -0.31046346]\n",
      "New theta_0 : [-0.01651909 -0.08326497  0.11173845 -0.0207321   0.09300604 -0.17737639\n",
      "  0.33270144 -0.06076119 -0.32244581  0.21955228 -0.20610127 -0.20914017\n",
      "  0.09159222 -0.3104804 ]\n",
      "Training Error:  9.770533684735739\n",
      "====================================================================================================\n",
      "Iteration:  731\n",
      "Previous theta :  [-0.01651909 -0.08326497  0.11173845 -0.0207321   0.09300604 -0.17737639\n",
      "  0.33270144 -0.06076119 -0.32244581  0.21955228 -0.20610127 -0.20914017\n",
      "  0.09159222 -0.3104804 ]\n",
      "New theta_0 : [-0.01651877 -0.0832778   0.11176007 -0.02071578  0.09300311 -0.17742606\n",
      "  0.33267495 -0.06074198 -0.3224848   0.21962251 -0.206157   -0.20915137\n",
      "  0.09158652 -0.31049724]\n",
      "Training Error:  9.770519213670715\n",
      "====================================================================================================\n",
      "Iteration:  732\n",
      "Previous theta :  [-0.01651877 -0.0832778   0.11176007 -0.02071578  0.09300311 -0.17742606\n",
      "  0.33267495 -0.06074198 -0.3224848   0.21962251 -0.206157   -0.20915137\n",
      "  0.09158652 -0.31049724]\n",
      "New theta_0 : [-0.01651847 -0.08329055  0.11178156 -0.02069944  0.09300019 -0.1774754\n",
      "  0.33264862 -0.06072286 -0.32252347  0.21969252 -0.20621264 -0.20916251\n",
      "  0.09158085 -0.31051397]\n",
      "Training Error:  9.770504867108778\n",
      "====================================================================================================\n",
      "Iteration:  733\n",
      "Previous theta :  [-0.01651847 -0.08329055  0.11178156 -0.02069944  0.09300019 -0.1774754\n",
      "  0.33264862 -0.06072286 -0.32252347  0.21969252 -0.20621264 -0.20916251\n",
      "  0.09158085 -0.31051397]\n",
      "New theta_0 : [-0.01651816 -0.08330321  0.11180293 -0.02068308  0.09299727 -0.1775244\n",
      "  0.33262247 -0.06070385 -0.32256183  0.2197623  -0.2062682  -0.20917359\n",
      "  0.09157522 -0.3105306 ]\n",
      "Training Error:  9.770490643651447\n",
      "====================================================================================================\n",
      "Iteration:  734\n",
      "Previous theta :  [-0.01651816 -0.08330321  0.11180293 -0.02068308  0.09299727 -0.1775244\n",
      "  0.33262247 -0.06070385 -0.32256183  0.2197623  -0.2062682  -0.20917359\n",
      "  0.09157522 -0.3105306 ]\n",
      "New theta_0 : [-0.01651787 -0.08331581  0.11182417 -0.02066672  0.09299436 -0.17757308\n",
      "  0.33259649 -0.06068494 -0.32259987  0.21983185 -0.20632368 -0.2091846\n",
      "  0.09156964 -0.31054711]\n",
      "Training Error:  9.770476541918702\n",
      "====================================================================================================\n",
      "Iteration:  735\n",
      "Previous theta :  [-0.01651787 -0.08331581  0.11182417 -0.02066672  0.09299436 -0.17757308\n",
      "  0.33259649 -0.06068494 -0.32259987  0.21983185 -0.20632368 -0.2091846\n",
      "  0.09156964 -0.31054711]\n",
      "New theta_0 : [-0.01651757 -0.08332832  0.11184528 -0.02065033  0.09299145 -0.17762144\n",
      "  0.33257067 -0.06066614 -0.3226376   0.21990117 -0.20637908 -0.20919556\n",
      "  0.09156409 -0.31056352]\n",
      "Training Error:  9.770462560548728\n",
      "====================================================================================================\n",
      "Iteration:  736\n",
      "Previous theta :  [-0.01651757 -0.08332832  0.11184528 -0.02065033  0.09299145 -0.17762144\n",
      "  0.33257067 -0.06066614 -0.3226376   0.21990117 -0.20637908 -0.20919556\n",
      "  0.09156409 -0.31056352]\n",
      "New theta_0 : [-0.01651728 -0.08334076  0.11186627 -0.02063394  0.09298855 -0.17766947\n",
      "  0.33254502 -0.06064743 -0.32267503  0.21997026 -0.2064344  -0.20920645\n",
      "  0.09155859 -0.31057983]\n",
      "Training Error:  9.770448698197649\n",
      "====================================================================================================\n",
      "Iteration:  737\n",
      "Previous theta :  [-0.01651728 -0.08334076  0.11186627 -0.02063394  0.09298855 -0.17766947\n",
      "  0.33254502 -0.06064743 -0.32267503  0.21997026 -0.2064344  -0.20920645\n",
      "  0.09155859 -0.31057983]\n",
      "New theta_0 : [-0.016517   -0.08335312  0.11188714 -0.02061754  0.09298565 -0.17771718\n",
      "  0.33251954 -0.06062882 -0.32271215  0.22003913 -0.20648964 -0.20921728\n",
      "  0.09155312 -0.31059603]\n",
      "Training Error:  9.770434953539281\n",
      "====================================================================================================\n",
      "Iteration:  738\n",
      "Previous theta :  [-0.016517   -0.08335312  0.11188714 -0.02061754  0.09298565 -0.17771718\n",
      "  0.33251954 -0.06062882 -0.32271215  0.22003913 -0.20648964 -0.20921728\n",
      "  0.09155312 -0.31059603]\n",
      "New theta_0 : [-0.01651672 -0.0833654   0.11190789 -0.02060112  0.09298276 -0.17776457\n",
      "  0.33249422 -0.06061032 -0.32274896  0.22010778 -0.2065448  -0.20922805\n",
      "  0.09154769 -0.31061213]\n",
      "Training Error:  9.770421325264874\n",
      "====================================================================================================\n",
      "Iteration:  739\n",
      "Previous theta :  [-0.01651672 -0.0833654   0.11190789 -0.02060112  0.09298276 -0.17776457\n",
      "  0.33249422 -0.06061032 -0.32274896  0.22010778 -0.2065448  -0.20922805\n",
      "  0.09154769 -0.31061213]\n",
      "New theta_0 : [-0.01651644 -0.08337761  0.11192852 -0.02058469  0.09297987 -0.17781165\n",
      "  0.33246906 -0.06059191 -0.32278548  0.2201762  -0.20659988 -0.20923876\n",
      "  0.0915423  -0.31062812]\n",
      "Training Error:  9.77040781208287\n",
      "====================================================================================================\n",
      "Iteration:  740\n",
      "Previous theta :  [-0.01651644 -0.08337761  0.11192852 -0.02058469  0.09297987 -0.17781165\n",
      "  0.33246906 -0.06059191 -0.32278548  0.2201762  -0.20659988 -0.20923876\n",
      "  0.0915423  -0.31062812]\n",
      "New theta_0 : [-0.01651617 -0.08338974  0.11194902 -0.02056825  0.09297699 -0.17785841\n",
      "  0.33244407 -0.0605736  -0.3228217   0.2202444  -0.20665487 -0.20924941\n",
      "  0.09153695 -0.31064401]\n",
      "Training Error:  9.770394412718659\n",
      "====================================================================================================\n",
      "Iteration:  741\n",
      "Previous theta :  [-0.01651617 -0.08338974  0.11194902 -0.02056825  0.09297699 -0.17785841\n",
      "  0.33244407 -0.0605736  -0.3228217   0.2202444  -0.20665487 -0.20924941\n",
      "  0.09153695 -0.31064401]\n",
      "New theta_0 : [-0.01651591 -0.0834018   0.11196941 -0.02055181  0.09297411 -0.17790486\n",
      "  0.33241924 -0.06055539 -0.32285762  0.22031237 -0.20670978 -0.20926001\n",
      "  0.09153164 -0.3106598 ]\n",
      "Training Error:  9.770381125914328\n",
      "====================================================================================================\n",
      "Iteration:  742\n",
      "Previous theta :  [-0.01651591 -0.0834018   0.11196941 -0.02055181  0.09297411 -0.17790486\n",
      "  0.33241924 -0.06055539 -0.32285762  0.22031237 -0.20670978 -0.20926001\n",
      "  0.09153164 -0.3106598 ]\n",
      "New theta_0 : [-0.01651564 -0.08341379  0.11198968 -0.02053535  0.09297124 -0.177951\n",
      "  0.33239456 -0.06053727 -0.32289326  0.22038013 -0.20676462 -0.20927054\n",
      "  0.09152636 -0.31067549]\n",
      "Training Error:  9.770367950428438\n",
      "====================================================================================================\n",
      "Iteration:  743\n",
      "Previous theta :  [-0.01651564 -0.08341379  0.11198968 -0.02053535  0.09297124 -0.177951\n",
      "  0.33239456 -0.06053727 -0.32289326  0.22038013 -0.20676462 -0.20927054\n",
      "  0.09152636 -0.31067549]\n",
      "New theta_0 : [-0.01651538 -0.0834257   0.11200983 -0.02051888  0.09296837 -0.17799683\n",
      "  0.33237005 -0.06051925 -0.3229286   0.22044767 -0.20681936 -0.20928101\n",
      "  0.09152112 -0.31069108]\n",
      "Training Error:  9.770354885035792\n",
      "====================================================================================================\n",
      "Iteration:  744\n",
      "Previous theta :  [-0.01651538 -0.0834257   0.11200983 -0.02051888  0.09296837 -0.17799683\n",
      "  0.33237005 -0.06051925 -0.3229286   0.22044767 -0.20681936 -0.20928101\n",
      "  0.09152112 -0.31069108]\n",
      "New theta_0 : [-0.01651513 -0.08343754  0.11202986 -0.02050241  0.09296551 -0.17804236\n",
      "  0.33234569 -0.06050133 -0.32296365  0.22051498 -0.20687403 -0.20929143\n",
      "  0.09151592 -0.31070657]\n",
      "Training Error:  9.77034192852719\n",
      "====================================================================================================\n",
      "Iteration:  745\n",
      "Previous theta :  [-0.01651513 -0.08343754  0.11202986 -0.02050241  0.09296551 -0.17804236\n",
      "  0.33234569 -0.06050133 -0.32296365  0.22051498 -0.20687403 -0.20929143\n",
      "  0.09151592 -0.31070657]\n",
      "New theta_0 : [-0.01651488 -0.08344931  0.11204978 -0.02048593  0.09296265 -0.17808758\n",
      "  0.33232149 -0.06048351 -0.32299841  0.22058208 -0.20692862 -0.20930179\n",
      "  0.09151076 -0.31072196]\n",
      "Training Error:  9.770329079709212\n",
      "====================================================================================================\n",
      "Iteration:  746\n",
      "Previous theta :  [-0.01651488 -0.08344931  0.11204978 -0.02048593  0.09296265 -0.17808758\n",
      "  0.33232149 -0.06048351 -0.32299841  0.22058208 -0.20692862 -0.20930179\n",
      "  0.09151076 -0.31072196]\n",
      "New theta_0 : [-0.01651463 -0.08346101  0.11206958 -0.02046944  0.0929598  -0.1781325\n",
      "  0.33229744 -0.06046578 -0.3230329   0.22064897 -0.20698312 -0.20931209\n",
      "  0.09150563 -0.31073725]\n",
      "Training Error:  9.770316337404\n",
      "====================================================================================================\n",
      "Iteration:  747\n",
      "Previous theta :  [-0.01651463 -0.08346101  0.11206958 -0.02046944  0.0929598  -0.1781325\n",
      "  0.33229744 -0.06046578 -0.3230329   0.22064897 -0.20698312 -0.20931209\n",
      "  0.09150563 -0.31073725]\n",
      "New theta_0 : [-0.01651439 -0.08347263  0.11208927 -0.02045294  0.09295695 -0.17817713\n",
      "  0.33227355 -0.06044814 -0.3230671   0.22071564 -0.20703754 -0.20932233\n",
      "  0.09150054 -0.31075245]\n",
      "Training Error:  9.770303700449022\n",
      "====================================================================================================\n",
      "Iteration:  748\n",
      "Previous theta :  [-0.01651439 -0.08347263  0.11208927 -0.02045294  0.09295695 -0.17817713\n",
      "  0.33227355 -0.06044814 -0.3230671   0.22071564 -0.20703754 -0.20932233\n",
      "  0.09150054 -0.31075245]\n",
      "New theta_0 : [-0.01651415 -0.08348419  0.11210885 -0.02043644  0.09295411 -0.17822145\n",
      "  0.33224981 -0.0604306  -0.32310102  0.22078209 -0.20709188 -0.20933252\n",
      "  0.09149549 -0.31076754]\n",
      "Training Error:  9.770291167696884\n",
      "====================================================================================================\n",
      "Iteration:  749\n",
      "Previous theta :  [-0.01651415 -0.08348419  0.11210885 -0.02043644  0.09295411 -0.17822145\n",
      "  0.33224981 -0.0604306  -0.32310102  0.22078209 -0.20709188 -0.20933252\n",
      "  0.09149549 -0.31076754]\n",
      "New theta_0 : [-0.01651392 -0.08349567  0.11212831 -0.02041993  0.09295127 -0.17826548\n",
      "  0.33222623 -0.06041315 -0.32313466  0.22084833 -0.20714613 -0.20934265\n",
      "  0.09149047 -0.31078255]\n",
      "Training Error:  9.770278738015076\n",
      "====================================================================================================\n",
      "Iteration:  750\n",
      "Previous theta :  [-0.01651392 -0.08349567  0.11212831 -0.02041993  0.09295127 -0.17826548\n",
      "  0.33222623 -0.06041315 -0.32313466  0.22084833 -0.20714613 -0.20934265\n",
      "  0.09149047 -0.31078255]\n",
      "New theta_0 : [-0.01651369 -0.08350709  0.11214766 -0.02040342  0.09294844 -0.17830921\n",
      "  0.33220279 -0.06039579 -0.32316803  0.22091436 -0.2072003  -0.20935272\n",
      "  0.09148548 -0.31079745]\n",
      "Training Error:  9.770266410285803\n",
      "====================================================================================================\n",
      "Iteration:  751\n",
      "Previous theta :  [-0.01651369 -0.08350709  0.11214766 -0.02040342  0.09294844 -0.17830921\n",
      "  0.33220279 -0.06039579 -0.32316803  0.22091436 -0.2072003  -0.20935272\n",
      "  0.09148548 -0.31079745]\n",
      "New theta_0 : [-0.01651347 -0.08351844  0.1121669  -0.0203869   0.09294561 -0.17835266\n",
      "  0.3321795  -0.06037853 -0.32320112  0.22098017 -0.20725439 -0.20936274\n",
      "  0.09148054 -0.31081226]\n",
      "Training Error:  9.770254183405749\n",
      "====================================================================================================\n",
      "Iteration:  752\n",
      "Previous theta :  [-0.01651347 -0.08351844  0.1121669  -0.0203869   0.09294561 -0.17835266\n",
      "  0.3321795  -0.06037853 -0.32320112  0.22098017 -0.20725439 -0.20936274\n",
      "  0.09148054 -0.31081226]\n",
      "New theta_0 : [-0.01651324 -0.08352971  0.11218603 -0.02037038  0.09294279 -0.17839581\n",
      "  0.33215637 -0.06036136 -0.32323395  0.22104578 -0.2073084  -0.2093727\n",
      "  0.09147562 -0.31082698]\n",
      "Training Error:  9.770242056285884\n",
      "====================================================================================================\n",
      "Iteration:  753\n",
      "Previous theta :  [-0.01651324 -0.08352971  0.11218603 -0.02037038  0.09294279 -0.17839581\n",
      "  0.33215637 -0.06036136 -0.32323395  0.22104578 -0.2073084  -0.2093727\n",
      "  0.09147562 -0.31082698]\n",
      "New theta_0 : [-0.01651303 -0.08354092  0.11220504 -0.02035385  0.09293997 -0.17843868\n",
      "  0.33213338 -0.06034428 -0.32326651  0.22111117 -0.20736232 -0.20938261\n",
      "  0.09147075 -0.3108416 ]\n",
      "Training Error:  9.770230027851262\n",
      "====================================================================================================\n",
      "Iteration:  754\n",
      "Previous theta :  [-0.01651303 -0.08354092  0.11220504 -0.02035385  0.09293997 -0.17843868\n",
      "  0.33213338 -0.06034428 -0.32326651  0.22111117 -0.20736232 -0.20938261\n",
      "  0.09147075 -0.3108416 ]\n",
      "New theta_0 : [-0.01651281 -0.08355207  0.11222395 -0.02033732  0.09293716 -0.17848126\n",
      "  0.33211053 -0.06032729 -0.3232988   0.22117635 -0.20741616 -0.20939246\n",
      "  0.0914659  -0.31085614]\n",
      "Training Error:  9.770218097040821\n",
      "====================================================================================================\n",
      "Iteration:  755\n",
      "Previous theta :  [-0.01651281 -0.08355207  0.11222395 -0.02033732  0.09293716 -0.17848126\n",
      "  0.33211053 -0.06032729 -0.3232988   0.22117635 -0.20741616 -0.20939246\n",
      "  0.0914659  -0.31085614]\n",
      "New theta_0 : [-0.0165126  -0.08356314  0.11224275 -0.02032079  0.09293435 -0.17852356\n",
      "  0.33208783 -0.0603104  -0.32333082  0.22124133 -0.20746991 -0.20940226\n",
      "  0.09146109 -0.31087057]\n",
      "Training Error:  9.770206262807193\n",
      "====================================================================================================\n",
      "Iteration:  756\n",
      "Previous theta :  [-0.0165126  -0.08356314  0.11224275 -0.02032079  0.09293435 -0.17852356\n",
      "  0.33208783 -0.0603104  -0.32333082  0.22124133 -0.20746991 -0.20940226\n",
      "  0.09146109 -0.31087057]\n",
      "New theta_0 : [-0.0165124  -0.08357415  0.11226145 -0.02030426  0.09293155 -0.17856557\n",
      "  0.33206528 -0.06029359 -0.32336259  0.2213061  -0.20752358 -0.209412\n",
      "  0.09145632 -0.31088492]\n",
      "Training Error:  9.770194524116496\n",
      "====================================================================================================\n",
      "Iteration:  757\n",
      "Previous theta :  [-0.0165124  -0.08357415  0.11226145 -0.02030426  0.09293155 -0.17856557\n",
      "  0.33206528 -0.06029359 -0.32336259  0.2213061  -0.20752358 -0.209412\n",
      "  0.09145632 -0.31088492]\n",
      "New theta_0 : [-0.01651219 -0.08358509  0.11228003 -0.02028772  0.09292875 -0.17860731\n",
      "  0.33204287 -0.06027687 -0.32339409  0.22137066 -0.20757717 -0.20942169\n",
      "  0.09145158 -0.31089918]\n",
      "Training Error:  9.770182879948171\n",
      "====================================================================================================\n",
      "Iteration:  758\n",
      "Previous theta :  [-0.01651219 -0.08358509  0.11228003 -0.02028772  0.09292875 -0.17860731\n",
      "  0.33204287 -0.06027687 -0.32339409  0.22137066 -0.20757717 -0.20942169\n",
      "  0.09145158 -0.31089918]\n",
      "New theta_0 : [-0.016512   -0.08359597  0.11229852 -0.02027118  0.09292595 -0.17864877\n",
      "  0.3320206  -0.06026024 -0.32342533  0.22143502 -0.20763067 -0.20943132\n",
      "  0.09144687 -0.31091334]\n",
      "Training Error:  9.770171329294769\n",
      "====================================================================================================\n",
      "Iteration:  759\n",
      "Previous theta :  [-0.016512   -0.08359597  0.11229852 -0.02027118  0.09292595 -0.17864877\n",
      "  0.3320206  -0.06026024 -0.32342533  0.22143502 -0.20763067 -0.20943132\n",
      "  0.09144687 -0.31091334]\n",
      "New theta_0 : [-0.0165118  -0.08360678  0.11231689 -0.02025464  0.09292317 -0.17868995\n",
      "  0.33199848 -0.0602437  -0.32345632  0.22149917 -0.20768409 -0.2094409\n",
      "  0.0914422  -0.31092742]\n",
      "Training Error:  9.770159871161775\n",
      "====================================================================================================\n",
      "Iteration:  760\n",
      "Previous theta :  [-0.0165118  -0.08360678  0.11231689 -0.02025464  0.09292317 -0.17868995\n",
      "  0.33199848 -0.0602437  -0.32345632  0.22149917 -0.20768409 -0.2094409\n",
      "  0.0914422  -0.31092742]\n",
      "New theta_0 : [-0.01651161 -0.08361752  0.11233516 -0.0202381   0.09292038 -0.17873086\n",
      "  0.33197649 -0.06022724 -0.32348706  0.22156312 -0.20773743 -0.20945043\n",
      "  0.09143755 -0.31094141]\n",
      "Training Error:  9.770148504567434\n",
      "====================================================================================================\n",
      "Iteration:  761\n",
      "Previous theta :  [-0.01651161 -0.08361752  0.11233516 -0.0202381   0.09292038 -0.17873086\n",
      "  0.33197649 -0.06022724 -0.32348706  0.22156312 -0.20773743 -0.20945043\n",
      "  0.09143755 -0.31094141]\n",
      "New theta_0 : [-0.01651142 -0.08362821  0.11235333 -0.02022155  0.09291761 -0.17877149\n",
      "  0.33195464 -0.06021088 -0.32351754  0.22162687 -0.20779068 -0.20945991\n",
      "  0.09143295 -0.31095531]\n",
      "Training Error:  9.770137228542566\n",
      "====================================================================================================\n",
      "Iteration:  762\n",
      "Previous theta :  [-0.01651142 -0.08362821  0.11235333 -0.02022155  0.09291761 -0.17877149\n",
      "  0.33195464 -0.06021088 -0.32351754  0.22162687 -0.20779068 -0.20945991\n",
      "  0.09143295 -0.31095531]\n",
      "New theta_0 : [-0.01651124 -0.08363882  0.11237139 -0.02020501  0.09291483 -0.17881186\n",
      "  0.33193294 -0.0601946  -0.32354777  0.22169042 -0.20784385 -0.20946933\n",
      "  0.09142837 -0.31096912]\n",
      "Training Error:  9.77012604213039\n",
      "====================================================================================================\n",
      "Iteration:  763\n",
      "Previous theta :  [-0.01651124 -0.08363882  0.11237139 -0.02020501  0.09291483 -0.17881186\n",
      "  0.33193294 -0.0601946  -0.32354777  0.22169042 -0.20784385 -0.20946933\n",
      "  0.09142837 -0.31096912]\n",
      "New theta_0 : [-0.01651106 -0.08364938  0.11238936 -0.02018847  0.09291207 -0.17885195\n",
      "  0.33191137 -0.06017841 -0.32357776  0.22175376 -0.20789693 -0.2094787\n",
      "  0.09142383 -0.31098284]\n",
      "Training Error:  9.770114944386348\n",
      "====================================================================================================\n",
      "Iteration:  764\n",
      "Previous theta :  [-0.01651106 -0.08364938  0.11238936 -0.02018847  0.09291207 -0.17885195\n",
      "  0.33191137 -0.06017841 -0.32357776  0.22175376 -0.20789693 -0.2094787\n",
      "  0.09142383 -0.31098284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01651088 -0.08365987  0.11240722 -0.02017193  0.0929093  -0.17889178\n",
      "  0.33188993 -0.0601623  -0.3236075   0.2218169  -0.20794993 -0.20948802\n",
      "  0.09141932 -0.31099648]\n",
      "Training Error:  9.770103934377936\n",
      "====================================================================================================\n",
      "Iteration:  765\n",
      "Previous theta :  [-0.01651088 -0.08365987  0.11240722 -0.02017193  0.0929093  -0.17889178\n",
      "  0.33188993 -0.0601623  -0.3236075   0.2218169  -0.20794993 -0.20948802\n",
      "  0.09141932 -0.31099648]\n",
      "New theta_0 : [-0.01651071 -0.0836703   0.11242498 -0.02015539  0.09290655 -0.17893135\n",
      "  0.33186863 -0.06014628 -0.32363699  0.22187985 -0.20800284 -0.20949729\n",
      "  0.09141484 -0.31101003]\n",
      "Training Error:  9.77009301118454\n",
      "====================================================================================================\n",
      "Iteration:  766\n",
      "Previous theta :  [-0.01651071 -0.0836703   0.11242498 -0.02015539  0.09290655 -0.17893135\n",
      "  0.33186863 -0.06014628 -0.32363699  0.22187985 -0.20800284 -0.20949729\n",
      "  0.09141484 -0.31101003]\n",
      "New theta_0 : [-0.01651054 -0.08368067  0.11244263 -0.02013885  0.09290379 -0.17897065\n",
      "  0.33184747 -0.06013034 -0.32366625  0.22194259 -0.20805567 -0.20950651\n",
      "  0.09141039 -0.31102349]\n",
      "Training Error:  9.770082173897261\n",
      "====================================================================================================\n",
      "Iteration:  767\n",
      "Previous theta :  [-0.01651054 -0.08368067  0.11244263 -0.02013885  0.09290379 -0.17897065\n",
      "  0.33184747 -0.06013034 -0.32366625  0.22194259 -0.20805567 -0.20950651\n",
      "  0.09141039 -0.31102349]\n",
      "New theta_0 : [-0.01651037 -0.08369097  0.11246019 -0.02012231  0.09290104 -0.17900969\n",
      "  0.33182644 -0.06011449 -0.32369526  0.22200514 -0.20810841 -0.20951567\n",
      "  0.09140597 -0.31103687]\n",
      "Training Error:  9.77007142161876\n",
      "====================================================================================================\n",
      "Iteration:  768\n",
      "Previous theta :  [-0.01651037 -0.08369097  0.11246019 -0.02012231  0.09290104 -0.17900969\n",
      "  0.33182644 -0.06011449 -0.32369526  0.22200514 -0.20810841 -0.20951567\n",
      "  0.09140597 -0.31103687]\n",
      "New theta_0 : [-0.01651021 -0.08370122  0.11247765 -0.02010578  0.0928983  -0.17904847\n",
      "  0.33180554 -0.06009872 -0.32372403  0.22206749 -0.20816107 -0.20952479\n",
      "  0.09140159 -0.31105017]\n",
      "Training Error:  9.770060753463087\n",
      "====================================================================================================\n",
      "Iteration:  769\n",
      "Previous theta :  [-0.01651021 -0.08370122  0.11247765 -0.02010578  0.0928983  -0.17904847\n",
      "  0.33180554 -0.06009872 -0.32372403  0.22206749 -0.20816107 -0.20952479\n",
      "  0.09140159 -0.31105017]\n",
      "New theta_0 : [-0.01651005 -0.0837114   0.11249502 -0.02008925  0.09289556 -0.17908699\n",
      "  0.33178478 -0.06008304 -0.32375257  0.22212965 -0.20821365 -0.20953386\n",
      "  0.09139724 -0.31106338]\n",
      "Training Error:  9.770050168555528\n",
      "====================================================================================================\n",
      "Iteration:  770\n",
      "Previous theta :  [-0.01651005 -0.0837114   0.11249502 -0.02008925  0.09289556 -0.17908699\n",
      "  0.33178478 -0.06008304 -0.32375257  0.22212965 -0.20821365 -0.20953386\n",
      "  0.09139724 -0.31106338]\n",
      "New theta_0 : [-0.0165099  -0.08372153  0.11251228 -0.02007272  0.09289283 -0.17912526\n",
      "  0.33176414 -0.06006743 -0.32378088  0.22219161 -0.20826613 -0.20954287\n",
      "  0.09139291 -0.31107651]\n",
      "Training Error:  9.770039666032451\n",
      "====================================================================================================\n",
      "Iteration:  771\n",
      "Previous theta :  [-0.0165099  -0.08372153  0.11251228 -0.02007272  0.09289283 -0.17912526\n",
      "  0.33176414 -0.06006743 -0.32378088  0.22219161 -0.20826613 -0.20954287\n",
      "  0.09139291 -0.31107651]\n",
      "New theta_0 : [-0.01650974 -0.08373159  0.11252945 -0.02005619  0.0928901  -0.17916327\n",
      "  0.33174363 -0.06005192 -0.32380895  0.22225337 -0.20831854 -0.20955184\n",
      "  0.09138862 -0.31108956]\n",
      "Training Error:  9.770029245041142\n",
      "====================================================================================================\n",
      "Iteration:  772\n",
      "Previous theta :  [-0.01650974 -0.08373159  0.11252945 -0.02005619  0.0928901  -0.17916327\n",
      "  0.33174363 -0.06005192 -0.32380895  0.22225337 -0.20831854 -0.20955184\n",
      "  0.09138862 -0.31108956]\n",
      "New theta_0 : [-0.0165096  -0.0837416   0.11254652 -0.02003967  0.09288738 -0.17920103\n",
      "  0.33172326 -0.06003648 -0.32383679  0.22231495 -0.20837086 -0.20956075\n",
      "  0.09138436 -0.31110252]\n",
      "Training Error:  9.770018904739663\n",
      "====================================================================================================\n",
      "Iteration:  773\n",
      "Previous theta :  [-0.0165096  -0.0837416   0.11254652 -0.02003967  0.09288738 -0.17920103\n",
      "  0.33172326 -0.06003648 -0.32383679  0.22231495 -0.20837086 -0.20956075\n",
      "  0.09138436 -0.31110252]\n",
      "New theta_0 : [-0.01650945 -0.08375154  0.1125635  -0.02002316  0.09288466 -0.17923854\n",
      "  0.33170301 -0.06002112 -0.3238644   0.22237633 -0.20842309 -0.20956962\n",
      "  0.09138013 -0.31111541]\n",
      "Training Error:  9.770008644296697\n",
      "====================================================================================================\n",
      "Iteration:  774\n",
      "Previous theta :  [-0.01650945 -0.08375154  0.1125635  -0.02002316  0.09288466 -0.17923854\n",
      "  0.33170301 -0.06002112 -0.3238644   0.22237633 -0.20842309 -0.20956962\n",
      "  0.09138013 -0.31111541]\n",
      "New theta_0 : [-0.01650931 -0.08376143  0.11258038 -0.02000664  0.09288195 -0.1792758\n",
      "  0.33168289 -0.06000585 -0.32389178  0.22243751 -0.20847524 -0.20957844\n",
      "  0.09137592 -0.31112821]\n",
      "Training Error:  9.769998462891396\n",
      "====================================================================================================\n",
      "Iteration:  775\n",
      "Previous theta :  [-0.01650931 -0.08376143  0.11258038 -0.02000664  0.09288195 -0.1792758\n",
      "  0.33168289 -0.06000585 -0.32389178  0.22243751 -0.20847524 -0.20957844\n",
      "  0.09137592 -0.31112821]\n",
      "New theta_0 : [-0.01650917 -0.08377126  0.11259717 -0.01999014  0.09287924 -0.17931281\n",
      "  0.33166289 -0.05999066 -0.32391894  0.22249851 -0.2085273  -0.20958721\n",
      "  0.09137175 -0.31114093]\n",
      "Training Error:  9.769988359713244\n",
      "====================================================================================================\n",
      "Iteration:  776\n",
      "Previous theta :  [-0.01650917 -0.08377126  0.11259717 -0.01999014  0.09287924 -0.17931281\n",
      "  0.33166289 -0.05999066 -0.32391894  0.22249851 -0.2085273  -0.20958721\n",
      "  0.09137175 -0.31114093]\n",
      "New theta_0 : [-0.01650903 -0.08378103  0.11261386 -0.01997363  0.09287654 -0.17934957\n",
      "  0.33164302 -0.05997554 -0.32394587  0.22255932 -0.20857928 -0.20959593\n",
      "  0.09136761 -0.31115357]\n",
      "Training Error:  9.769978333961905\n",
      "====================================================================================================\n",
      "Iteration:  777\n",
      "Previous theta :  [-0.01650903 -0.08378103  0.11261386 -0.01997363  0.09287654 -0.17934957\n",
      "  0.33164302 -0.05997554 -0.32394587  0.22255932 -0.20857928 -0.20959593\n",
      "  0.09136761 -0.31115357]\n",
      "New theta_0 : [-0.0165089  -0.08379074  0.11263046 -0.01995714  0.09287384 -0.1793861\n",
      "  0.33162328 -0.05996051 -0.32397258  0.22261994 -0.20863117 -0.2096046\n",
      "  0.09136349 -0.31116613]\n",
      "Training Error:  9.769968384847095\n",
      "====================================================================================================\n",
      "Iteration:  778\n",
      "Previous theta :  [-0.0165089  -0.08379074  0.11263046 -0.01995714  0.09287384 -0.1793861\n",
      "  0.33162328 -0.05996051 -0.32397258  0.22261994 -0.20863117 -0.2096046\n",
      "  0.09136349 -0.31116613]\n",
      "New theta_0 : [-0.01650877 -0.0838004   0.11264697 -0.01994065  0.09287115 -0.17942237\n",
      "  0.33160366 -0.05994556 -0.32399908  0.22268037 -0.20868297 -0.20961322\n",
      "  0.09135941 -0.31117862]\n",
      "Training Error:  9.769958511588417\n",
      "====================================================================================================\n",
      "Iteration:  779\n",
      "Previous theta :  [-0.01650877 -0.0838004   0.11264697 -0.01994065  0.09287115 -0.17942237\n",
      "  0.33160366 -0.05994556 -0.32399908  0.22268037 -0.20868297 -0.20961322\n",
      "  0.09135941 -0.31117862]\n",
      "New theta_0 : [-0.01650865 -0.08381     0.11266338 -0.01992416  0.09286846 -0.17945841\n",
      "  0.33158416 -0.05993068 -0.32402535  0.22274061 -0.20873469 -0.2096218\n",
      "  0.09135535 -0.31119102]\n",
      "Training Error:  9.769948713415259\n",
      "====================================================================================================\n",
      "Iteration:  780\n",
      "Previous theta :  [-0.01650865 -0.08381     0.11266338 -0.01992416  0.09286846 -0.17945841\n",
      "  0.33158416 -0.05993068 -0.32402535  0.22274061 -0.20873469 -0.2096218\n",
      "  0.09135535 -0.31119102]\n",
      "New theta_0 : [-0.01650852 -0.08381954  0.11267971 -0.01990768  0.09286578 -0.17949421\n",
      "  0.33156478 -0.05991588 -0.32405141  0.22280066 -0.20878633 -0.20963033\n",
      "  0.09135133 -0.31120335]\n",
      "Training Error:  9.769938989566624\n",
      "====================================================================================================\n",
      "Iteration:  781\n",
      "Previous theta :  [-0.01650852 -0.08381954  0.11267971 -0.01990768  0.09286578 -0.17949421\n",
      "  0.33156478 -0.05991588 -0.32405141  0.22280066 -0.20878633 -0.20963033\n",
      "  0.09135133 -0.31120335]\n",
      "New theta_0 : [-0.0165084  -0.08382903  0.11269594 -0.01989121  0.09286311 -0.17952977\n",
      "  0.33154552 -0.05990117 -0.32407725  0.22286053 -0.20883788 -0.20963882\n",
      "  0.09134733 -0.3112156 ]\n",
      "Training Error:  9.769929339291016\n",
      "====================================================================================================\n",
      "Iteration:  782\n",
      "Previous theta :  [-0.0165084  -0.08382903  0.11269594 -0.01989121  0.09286311 -0.17952977\n",
      "  0.33154552 -0.05990117 -0.32407725  0.22286053 -0.20883788 -0.20963882\n",
      "  0.09134733 -0.3112156 ]\n",
      "New theta_0 : [-0.01650829 -0.08383846  0.11271209 -0.01987475  0.09286043 -0.1795651\n",
      "  0.33152639 -0.05988652 -0.32410288  0.22292021 -0.20888934 -0.20964725\n",
      "  0.09134336 -0.31122778]\n",
      "Training Error:  9.76991976184631\n",
      "====================================================================================================\n",
      "Iteration:  783\n",
      "Previous theta :  [-0.01650829 -0.08383846  0.11271209 -0.01987475  0.09286043 -0.1795651\n",
      "  0.33152639 -0.05988652 -0.32410288  0.22292021 -0.20888934 -0.20964725\n",
      "  0.09134336 -0.31122778]\n",
      "New theta_0 : [-0.01650817 -0.08384784  0.11272814 -0.01985829  0.09285777 -0.17960019\n",
      "  0.33150737 -0.05987196 -0.3241283   0.22297971 -0.20894072 -0.20965564\n",
      "  0.09133941 -0.31123988]\n",
      "Training Error:  9.76991025649961\n",
      "====================================================================================================\n",
      "Iteration:  784\n",
      "Previous theta :  [-0.01650817 -0.08384784  0.11272814 -0.01985829  0.09285777 -0.17960019\n",
      "  0.33150737 -0.05987196 -0.3241283   0.22297971 -0.20894072 -0.20965564\n",
      "  0.09133941 -0.31123988]\n",
      "New theta_0 : [-0.01650806 -0.08385716  0.11274411 -0.01984184  0.0928551  -0.17963504\n",
      "  0.33148847 -0.05985747 -0.3241535   0.22303903 -0.20899201 -0.20966399\n",
      "  0.0913355  -0.3112519 ]\n",
      "Training Error:  9.76990082252713\n",
      "====================================================================================================\n",
      "Iteration:  785\n",
      "Previous theta :  [-0.01650806 -0.08385716  0.11274411 -0.01984184  0.0928551  -0.17963504\n",
      "  0.33148847 -0.05985747 -0.3241535   0.22303903 -0.20899201 -0.20966399\n",
      "  0.0913355  -0.3112519 ]\n",
      "New theta_0 : [-0.01650795 -0.08386643  0.11275999 -0.0198254   0.09285245 -0.17966967\n",
      "  0.33146969 -0.05984306 -0.3241785   0.22309816 -0.20904321 -0.20967229\n",
      "  0.09133161 -0.31126385]\n",
      "Training Error:  9.769891459214062\n",
      "====================================================================================================\n",
      "Iteration:  786\n",
      "Previous theta :  [-0.01650795 -0.08386643  0.11275999 -0.0198254   0.09285245 -0.17966967\n",
      "  0.33146969 -0.05984306 -0.3241785   0.22309816 -0.20904321 -0.20967229\n",
      "  0.09133161 -0.31126385]\n",
      "New theta_0 : [-0.01650785 -0.08387565  0.11277578 -0.01980897  0.0928498  -0.17970407\n",
      "  0.33145103 -0.05982873 -0.3242033   0.22315711 -0.20909433 -0.20968054\n",
      "  0.09132775 -0.31127572]\n",
      "Training Error:  9.769882165854467\n",
      "====================================================================================================\n",
      "Iteration:  787\n",
      "Previous theta :  [-0.01650785 -0.08387565  0.11277578 -0.01980897  0.0928498  -0.17970407\n",
      "  0.33145103 -0.05982873 -0.3242033   0.22315711 -0.20909433 -0.20968054\n",
      "  0.09132775 -0.31127572]\n",
      "New theta_0 : [-0.01650775 -0.08388481  0.11279149 -0.01979254  0.09284715 -0.17973824\n",
      "  0.33143248 -0.05981447 -0.32422788  0.22321587 -0.20914536 -0.20968875\n",
      "  0.09132392 -0.31128752]\n",
      "Training Error:  9.769872941751126\n",
      "====================================================================================================\n",
      "Iteration:  788\n",
      "Previous theta :  [-0.01650775 -0.08388481  0.11279149 -0.01979254  0.09284715 -0.17973824\n",
      "  0.33143248 -0.05981447 -0.32422788  0.22321587 -0.20914536 -0.20968875\n",
      "  0.09132392 -0.31128752]\n",
      "New theta_0 : [-0.01650765 -0.08389392  0.11280711 -0.01977613  0.09284451 -0.17977218\n",
      "  0.33141405 -0.05980028 -0.32425227  0.22327446 -0.20919631 -0.20969691\n",
      "  0.09132011 -0.31129925]\n",
      "Training Error:  9.76986378621545\n",
      "====================================================================================================\n",
      "Iteration:  789\n",
      "Previous theta :  [-0.01650765 -0.08389392  0.11280711 -0.01977613  0.09284451 -0.17977218\n",
      "  0.33141405 -0.05980028 -0.32425227  0.22327446 -0.20919631 -0.20969691\n",
      "  0.09132011 -0.31129925]\n",
      "New theta_0 : [-0.01650755 -0.08390298  0.11282264 -0.01975972  0.09284187 -0.17980589\n",
      "  0.33139573 -0.05978617 -0.32427645  0.22333287 -0.20924717 -0.20970503\n",
      "  0.09131633 -0.3113109 ]\n",
      "Training Error:  9.76985469856733\n",
      "====================================================================================================\n",
      "Iteration:  790\n",
      "Previous theta :  [-0.01650755 -0.08390298  0.11282264 -0.01975972  0.09284187 -0.17980589\n",
      "  0.33139573 -0.05978617 -0.32427645  0.22333287 -0.20924717 -0.20970503\n",
      "  0.09131633 -0.3113109 ]\n",
      "New theta_0 : [-0.01650746 -0.08391198  0.11283809 -0.01974333  0.09283924 -0.17983939\n",
      "  0.33137752 -0.05977214 -0.32430044  0.22339109 -0.20929794 -0.2097131\n",
      "  0.09131258 -0.31132248]\n",
      "Training Error:  9.769845678135056\n",
      "====================================================================================================\n",
      "Iteration:  791\n",
      "Previous theta :  [-0.01650746 -0.08391198  0.11283809 -0.01974333  0.09283924 -0.17983939\n",
      "  0.33137752 -0.05977214 -0.32430044  0.22339109 -0.20929794 -0.2097131\n",
      "  0.09131258 -0.31132248]\n",
      "New theta_0 : [-0.01650737 -0.08392093  0.11285345 -0.01972694  0.09283661 -0.17987266\n",
      "  0.33135943 -0.05975817 -0.32432422  0.22344914 -0.20934863 -0.20972113\n",
      "  0.09130886 -0.31133399]\n",
      "Training Error:  9.769836724255164\n",
      "====================================================================================================\n",
      "Iteration:  792\n",
      "Previous theta :  [-0.01650737 -0.08392093  0.11285345 -0.01972694  0.09283661 -0.17987266\n",
      "  0.33135943 -0.05975817 -0.32432422  0.22344914 -0.20934863 -0.20972113\n",
      "  0.09130886 -0.31133399]\n",
      "New theta_0 : [-0.01650728 -0.08392983  0.11286873 -0.01971057  0.09283399 -0.17990571\n",
      "  0.33134145 -0.05974428 -0.32434781  0.22350701 -0.20939923 -0.20972912\n",
      "  0.09130516 -0.31134542]\n",
      "Training Error:  9.76982783627235\n",
      "====================================================================================================\n",
      "Iteration:  793\n",
      "Previous theta :  [-0.01650728 -0.08392983  0.11286873 -0.01971057  0.09283399 -0.17990571\n",
      "  0.33134145 -0.05974428 -0.32434781  0.22350701 -0.20939923 -0.20972912\n",
      "  0.09130516 -0.31134542]\n",
      "New theta_0 : [-0.0165072  -0.08393868  0.11288393 -0.0196942   0.09283137 -0.17993854\n",
      "  0.33132358 -0.05973047 -0.3243712   0.22356471 -0.20944974 -0.20973706\n",
      "  0.09130148 -0.31135679]\n",
      "Training Error:  9.769819013539344\n",
      "====================================================================================================\n",
      "Iteration:  794\n",
      "Previous theta :  [-0.0165072  -0.08393868  0.11288393 -0.0196942   0.09283137 -0.17993854\n",
      "  0.33132358 -0.05973047 -0.3243712   0.22356471 -0.20944974 -0.20973706\n",
      "  0.09130148 -0.31135679]\n",
      "New theta_0 : [-0.01650712 -0.08394748  0.11289904 -0.01967785  0.09282876 -0.17997115\n",
      "  0.33130582 -0.05971672 -0.3243944   0.22362222 -0.20950017 -0.20974496\n",
      "  0.09129783 -0.31136808]\n",
      "Training Error:  9.769810255416806\n",
      "====================================================================================================\n",
      "Iteration:  795\n",
      "Previous theta :  [-0.01650712 -0.08394748  0.11289904 -0.01967785  0.09282876 -0.17997115\n",
      "  0.33130582 -0.05971672 -0.3243944   0.22362222 -0.20950017 -0.20974496\n",
      "  0.09129783 -0.31136808]\n",
      "New theta_0 : [-0.01650704 -0.08395623  0.11291407 -0.0196615   0.09282615 -0.18000355\n",
      "  0.33128818 -0.05970305 -0.32441741  0.22367956 -0.20955051 -0.20975281\n",
      "  0.09129421 -0.31137931]\n",
      "Training Error:  9.769801561273214\n",
      "====================================================================================================\n",
      "Iteration:  796\n",
      "Previous theta :  [-0.01650704 -0.08395623  0.11291407 -0.0196615   0.09282615 -0.18000355\n",
      "  0.33128818 -0.05970305 -0.32441741  0.22367956 -0.20955051 -0.20975281\n",
      "  0.09129421 -0.31137931]\n",
      "New theta_0 : [-0.01650696 -0.08396493  0.11292902 -0.01964517  0.09282355 -0.18003573\n",
      "  0.33127064 -0.05968945 -0.32444022  0.22373673 -0.20960077 -0.20976063\n",
      "  0.09129062 -0.31139046]\n",
      "Training Error:  9.76979293048475\n",
      "====================================================================================================\n",
      "Iteration:  797\n",
      "Previous theta :  [-0.01650696 -0.08396493  0.11292902 -0.01964517  0.09282355 -0.18003573\n",
      "  0.33127064 -0.05968945 -0.32444022  0.22373673 -0.20960077 -0.20976063\n",
      "  0.09129062 -0.31139046]\n",
      "New theta_0 : [-0.01650689 -0.08397357  0.11294389 -0.01962885  0.09282096 -0.1800677\n",
      "  0.3312532  -0.05967592 -0.32446285  0.22379372 -0.20965094 -0.2097684\n",
      "  0.09128704 -0.31140155]\n",
      "Training Error:  9.769784362435216\n",
      "====================================================================================================\n",
      "Iteration:  798\n",
      "Previous theta :  [-0.01650689 -0.08397357  0.11294389 -0.01962885  0.09282096 -0.1800677\n",
      "  0.3312532  -0.05967592 -0.32446285  0.22379372 -0.20965094 -0.2097684\n",
      "  0.09128704 -0.31140155]\n",
      "New theta_0 : [-0.01650682 -0.08398217  0.11295868 -0.01961254  0.09281836 -0.18009946\n",
      "  0.33123588 -0.05966246 -0.32448529  0.22385054 -0.20970102 -0.20977612\n",
      "  0.0912835  -0.31141257]\n",
      "Training Error:  9.769775856515905\n",
      "====================================================================================================\n",
      "Iteration:  799\n",
      "Previous theta :  [-0.01650682 -0.08398217  0.11295868 -0.01961254  0.09281836 -0.18009946\n",
      "  0.33123588 -0.05966246 -0.32448529  0.22385054 -0.20970102 -0.20977612\n",
      "  0.0912835  -0.31141257]\n",
      "New theta_0 : [-0.01650675 -0.08399072  0.11297339 -0.01959625  0.09281578 -0.18013101\n",
      "  0.33121866 -0.05964907 -0.32450754  0.22390719 -0.20975101 -0.20978381\n",
      "  0.09127998 -0.31142352]\n",
      "Training Error:  9.76976741212551\n",
      "====================================================================================================\n",
      "Iteration:  800\n",
      "Previous theta :  [-0.01650675 -0.08399072  0.11297339 -0.01959625  0.09281578 -0.18013101\n",
      "  0.33121866 -0.05964907 -0.32450754  0.22390719 -0.20975101 -0.20978381\n",
      "  0.09127998 -0.31142352]\n",
      "New theta_0 : [-0.01650668 -0.08399922  0.11298802 -0.01957996  0.0928132  -0.18016235\n",
      "  0.33120155 -0.05963576 -0.32452961  0.22396366 -0.20980092 -0.20979145\n",
      "  0.09127648 -0.3114344 ]\n",
      "Training Error:  9.769759028670025\n",
      "====================================================================================================\n",
      "Iteration:  801\n",
      "Previous theta :  [-0.01650668 -0.08399922  0.11298802 -0.01957996  0.0928132  -0.18016235\n",
      "  0.33120155 -0.05963576 -0.32452961  0.22396366 -0.20980092 -0.20979145\n",
      "  0.09127648 -0.3114344 ]\n",
      "New theta_0 : [-0.01650662 -0.08400768  0.11300257 -0.01956369  0.09281062 -0.18019348\n",
      "  0.33118454 -0.05962251 -0.32455149  0.22401996 -0.20985075 -0.20979905\n",
      "  0.09127301 -0.31144521]\n",
      "Training Error:  9.76975070556264\n",
      "====================================================================================================\n",
      "Iteration:  802\n",
      "Previous theta :  [-0.01650662 -0.08400768  0.11300257 -0.01956369  0.09281062 -0.18019348\n",
      "  0.33118454 -0.05962251 -0.32455149  0.22401996 -0.20985075 -0.20979905\n",
      "  0.09127301 -0.31144521]\n",
      "New theta_0 : [-0.01650656 -0.08401608  0.11301704 -0.01954743  0.09280805 -0.18022441\n",
      "  0.33116764 -0.05960933 -0.3245732   0.22407609 -0.20990048 -0.20980661\n",
      "  0.09126956 -0.31145596]\n",
      "Training Error:  9.769742442223645\n",
      "====================================================================================================\n",
      "Iteration:  803\n",
      "Previous theta :  [-0.01650656 -0.08401608  0.11301704 -0.01954743  0.09280805 -0.18022441\n",
      "  0.33116764 -0.05960933 -0.3245732   0.22407609 -0.20990048 -0.20980661\n",
      "  0.09126956 -0.31145596]\n",
      "New theta_0 : [-0.0165065  -0.08402444  0.11303143 -0.01953119  0.09280548 -0.18025513\n",
      "  0.33115084 -0.05959622 -0.32459472  0.22413205 -0.20995013 -0.20981413\n",
      "  0.09126614 -0.31146664]\n",
      "Training Error:  9.769734238080327\n",
      "====================================================================================================\n",
      "Iteration:  804\n",
      "Previous theta :  [-0.0165065  -0.08402444  0.11303143 -0.01953119  0.09280548 -0.18025513\n",
      "  0.33115084 -0.05959622 -0.32459472  0.22413205 -0.20995013 -0.20981413\n",
      "  0.09126614 -0.31146664]\n",
      "New theta_0 : [-0.01650645 -0.08403274  0.11304575 -0.01951495  0.09280292 -0.18028565\n",
      "  0.33113414 -0.05958317 -0.32461606  0.22418785 -0.20999969 -0.20982161\n",
      "  0.09126274 -0.31147726]\n",
      "Training Error:  9.769726092566891\n",
      "====================================================================================================\n",
      "Iteration:  805\n",
      "Previous theta :  [-0.01650645 -0.08403274  0.11304575 -0.01951495  0.09280292 -0.18028565\n",
      "  0.33113414 -0.05958317 -0.32461606  0.22418785 -0.20999969 -0.20982161\n",
      "  0.09126274 -0.31147726]\n",
      "New theta_0 : [-0.0165064  -0.08404101  0.11305999 -0.01949874  0.09280036 -0.18031596\n",
      "  0.33111755 -0.0595702  -0.32463723  0.22424347 -0.21004917 -0.20982904\n",
      "  0.09125936 -0.31148781]\n",
      "Training Error:  9.769718005124346\n",
      "====================================================================================================\n",
      "Iteration:  806\n",
      "Previous theta :  [-0.0165064  -0.08404101  0.11305999 -0.01949874  0.09280036 -0.18031596\n",
      "  0.33111755 -0.0595702  -0.32463723  0.22424347 -0.21004917 -0.20982904\n",
      "  0.09125936 -0.31148781]\n",
      "New theta_0 : [-0.01650635 -0.08404922  0.11307415 -0.01948253  0.09279781 -0.18034608\n",
      "  0.33110106 -0.05955729 -0.32465822  0.22429893 -0.21009856 -0.20983644\n",
      "  0.09125601 -0.31149829]\n",
      "Training Error:  9.769709975200422\n",
      "====================================================================================================\n",
      "Iteration:  807\n",
      "Previous theta :  [-0.01650635 -0.08404922  0.11307415 -0.01948253  0.09279781 -0.18034608\n",
      "  0.33110106 -0.05955729 -0.32465822  0.22429893 -0.21009856 -0.20983644\n",
      "  0.09125601 -0.31149829]\n",
      "New theta_0 : [-0.0165063  -0.08405739  0.11308824 -0.01946634  0.09279526 -0.18037599\n",
      "  0.33108466 -0.05954445 -0.32467903  0.22435421 -0.21014786 -0.2098438\n",
      "  0.09125268 -0.31150871]\n",
      "Training Error:  9.769702002249481\n",
      "====================================================================================================\n",
      "Iteration:  808\n",
      "Previous theta :  [-0.0165063  -0.08405739  0.11308824 -0.01946634  0.09279526 -0.18037599\n",
      "  0.33108466 -0.05954445 -0.32467903  0.22435421 -0.21014786 -0.2098438\n",
      "  0.09125268 -0.31150871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01650625 -0.08406551  0.11310225 -0.01945016  0.09279272 -0.18040571\n",
      "  0.33106837 -0.05953168 -0.32469968  0.22440933 -0.21019708 -0.20985111\n",
      "  0.09124937 -0.31151907]\n",
      "Training Error:  9.769694085732423\n",
      "====================================================================================================\n",
      "Iteration:  809\n",
      "Previous theta :  [-0.01650625 -0.08406551  0.11310225 -0.01945016  0.09279272 -0.18040571\n",
      "  0.33106837 -0.05953168 -0.32469968  0.22440933 -0.21019708 -0.20985111\n",
      "  0.09124937 -0.31151907]\n",
      "New theta_0 : [-0.01650621 -0.08407359  0.11311619 -0.019434    0.09279019 -0.18043523\n",
      "  0.33105218 -0.05951898 -0.32472015  0.22446429 -0.2102462  -0.20985839\n",
      "  0.09124609 -0.31152936]\n",
      "Training Error:  9.769686225116594\n",
      "====================================================================================================\n",
      "Iteration:  810\n",
      "Previous theta :  [-0.01650621 -0.08407359  0.11311619 -0.019434    0.09279019 -0.18043523\n",
      "  0.33105218 -0.05951898 -0.32472015  0.22446429 -0.2102462  -0.20985839\n",
      "  0.09124609 -0.31152936]\n",
      "New theta_0 : [-0.01650617 -0.08408162  0.11313005 -0.01941785  0.09278766 -0.18046456\n",
      "  0.33103609 -0.05950634 -0.32474045  0.22451908 -0.21029525 -0.20986562\n",
      "  0.09124283 -0.31153959]\n",
      "Training Error:  9.769678419875705\n",
      "====================================================================================================\n",
      "Iteration:  811\n",
      "Previous theta :  [-0.01650617 -0.08408162  0.11313005 -0.01941785  0.09278766 -0.18046456\n",
      "  0.33103609 -0.05950634 -0.32474045  0.22451908 -0.21029525 -0.20986562\n",
      "  0.09124283 -0.31153959]\n",
      "New theta_0 : [-0.01650613 -0.08408961  0.11314384 -0.01940172  0.09278513 -0.18049369\n",
      "  0.33102009 -0.05949376 -0.32476058  0.22457371 -0.2103442  -0.20987282\n",
      "  0.0912396  -0.31154976]\n",
      "Training Error:  9.769670669489743\n",
      "====================================================================================================\n",
      "Iteration:  812\n",
      "Previous theta :  [-0.01650613 -0.08408961  0.11314384 -0.01940172  0.09278513 -0.18049369\n",
      "  0.33102009 -0.05949376 -0.32476058  0.22457371 -0.2103442  -0.20987282\n",
      "  0.0912396  -0.31154976]\n",
      "New theta_0 : [-0.0165061  -0.08409755  0.11315755 -0.0193856   0.09278261 -0.18052263\n",
      "  0.33100419 -0.05948125 -0.32478054  0.22462817 -0.21039307 -0.20987998\n",
      "  0.09123638 -0.31155986]\n",
      "Training Error:  9.769662973444882\n",
      "====================================================================================================\n",
      "Iteration:  813\n",
      "Previous theta :  [-0.0165061  -0.08409755  0.11315755 -0.0193856   0.09278261 -0.18052263\n",
      "  0.33100419 -0.05948125 -0.32478054  0.22462817 -0.21039307 -0.20987998\n",
      "  0.09123638 -0.31155986]\n",
      "New theta_0 : [-0.01650606 -0.08410545  0.1131712  -0.0193695   0.09278009 -0.18055138\n",
      "  0.33098839 -0.05946881 -0.32480033  0.22468246 -0.21044185 -0.2098871\n",
      "  0.09123319 -0.3115699 ]\n",
      "Training Error:  9.769655331233405\n",
      "====================================================================================================\n",
      "Iteration:  814\n",
      "Previous theta :  [-0.01650606 -0.08410545  0.1131712  -0.0193695   0.09278009 -0.18055138\n",
      "  0.33098839 -0.05946881 -0.32480033  0.22468246 -0.21044185 -0.2098871\n",
      "  0.09123319 -0.3115699 ]\n",
      "New theta_0 : [-0.01650603 -0.0841133   0.11318477 -0.01935341  0.09277758 -0.18057994\n",
      "  0.33097269 -0.05945643 -0.32481997  0.2247366  -0.21049055 -0.20989418\n",
      "  0.09123002 -0.31157988]\n",
      "Training Error:  9.769647742353627\n",
      "====================================================================================================\n",
      "Iteration:  815\n",
      "Previous theta :  [-0.01650603 -0.0841133   0.11318477 -0.01935341  0.09277758 -0.18057994\n",
      "  0.33097269 -0.05945643 -0.32481997  0.2247366  -0.21049055 -0.20989418\n",
      "  0.09123002 -0.31157988]\n",
      "New theta_0 : [-0.01650601 -0.08412111  0.11319827 -0.01933734  0.09277507 -0.18060831\n",
      "  0.33095708 -0.05944412 -0.32483943  0.22479057 -0.21053915 -0.20990122\n",
      "  0.09122688 -0.3115898 ]\n",
      "Training Error:  9.769640206309788\n",
      "====================================================================================================\n",
      "Iteration:  816\n",
      "Previous theta :  [-0.01650601 -0.08412111  0.11319827 -0.01933734  0.09277507 -0.18060831\n",
      "  0.33095708 -0.05944412 -0.32483943  0.22479057 -0.21053915 -0.20990122\n",
      "  0.09122688 -0.3115898 ]\n",
      "New theta_0 : [-0.01650598 -0.08412887  0.11321169 -0.01932129  0.09277257 -0.18063649\n",
      "  0.33094156 -0.05943186 -0.32485874  0.22484438 -0.21058768 -0.20990822\n",
      "  0.09122375 -0.31159966]\n",
      "Training Error:  9.769632722612007\n",
      "====================================================================================================\n",
      "Iteration:  817\n",
      "Previous theta :  [-0.01650598 -0.08412887  0.11321169 -0.01932129  0.09277257 -0.18063649\n",
      "  0.33094156 -0.05943186 -0.32485874  0.22484438 -0.21058768 -0.20990822\n",
      "  0.09122375 -0.31159966]\n",
      "New theta_0 : [-0.01650596 -0.08413659  0.11322505 -0.01930525  0.09277007 -0.18066449\n",
      "  0.33092614 -0.05941968 -0.32487788  0.22489804 -0.21063611 -0.20991519\n",
      "  0.09122065 -0.31160946]\n",
      "Training Error:  9.769625290776178\n",
      "====================================================================================================\n",
      "Iteration:  818\n",
      "Previous theta :  [-0.01650596 -0.08413659  0.11322505 -0.01930525  0.09277007 -0.18066449\n",
      "  0.33092614 -0.05941968 -0.32487788  0.22489804 -0.21063611 -0.20991519\n",
      "  0.09122065 -0.31160946]\n",
      "New theta_0 : [-0.01650593 -0.08414427  0.11323834 -0.01928923  0.09276758 -0.1806923\n",
      "  0.33091081 -0.05940755 -0.32489686  0.22495153 -0.21068446 -0.20992212\n",
      "  0.09121757 -0.31161919]\n",
      "Training Error:  9.769617910323896\n",
      "====================================================================================================\n",
      "Iteration:  819\n",
      "Previous theta :  [-0.01650593 -0.08414427  0.11323834 -0.01928923  0.09276758 -0.1806923\n",
      "  0.33091081 -0.05940755 -0.32489686  0.22495153 -0.21068446 -0.20992212\n",
      "  0.09121757 -0.31161919]\n",
      "New theta_0 : [-0.01650591 -0.08415191  0.11325155 -0.01927322  0.0927651  -0.18071993\n",
      "  0.33089558 -0.05939549 -0.32491569  0.22500486 -0.21073272 -0.20992901\n",
      "  0.09121451 -0.31162887]\n",
      "Training Error:  9.769610580782405\n",
      "====================================================================================================\n",
      "Iteration:  820\n",
      "Previous theta :  [-0.01650591 -0.08415191  0.11325155 -0.01927322  0.0927651  -0.18071993\n",
      "  0.33089558 -0.05939549 -0.32491569  0.22500486 -0.21073272 -0.20992901\n",
      "  0.09121451 -0.31162887]\n",
      "New theta_0 : [-0.0165059  -0.0841595   0.1132647  -0.01925723  0.09276261 -0.18074738\n",
      "  0.33088043 -0.05938349 -0.32493435  0.22505803 -0.21078089 -0.20993586\n",
      "  0.09121147 -0.31163849]\n",
      "Training Error:  9.769603301684471\n",
      "====================================================================================================\n",
      "Iteration:  821\n",
      "Previous theta :  [-0.0165059  -0.0841595   0.1132647  -0.01925723  0.09276261 -0.18074738\n",
      "  0.33088043 -0.05938349 -0.32493435  0.22505803 -0.21078089 -0.20993586\n",
      "  0.09121147 -0.31163849]\n",
      "New theta_0 : [-0.01650588 -0.08416705  0.11327778 -0.01924126  0.09276014 -0.18077464\n",
      "  0.33086538 -0.05937156 -0.32495286  0.22511104 -0.21082898 -0.20994268\n",
      "  0.09120846 -0.31164805]\n",
      "Training Error:  9.769596072568362\n",
      "====================================================================================================\n",
      "Iteration:  822\n",
      "Previous theta :  [-0.01650588 -0.08416705  0.11327778 -0.01924126  0.09276014 -0.18077464\n",
      "  0.33086538 -0.05937156 -0.32495286  0.22511104 -0.21082898 -0.20994268\n",
      "  0.09120846 -0.31164805]\n",
      "New theta_0 : [-0.01650587 -0.08417456  0.11329079 -0.0192253   0.09275767 -0.18080173\n",
      "  0.33085042 -0.05935968 -0.32497122  0.2251639  -0.21087698 -0.20994945\n",
      "  0.09120546 -0.31165755]\n",
      "Training Error:  9.769588892977739\n",
      "====================================================================================================\n",
      "Iteration:  823\n",
      "Previous theta :  [-0.01650587 -0.08417456  0.11329079 -0.0192253   0.09275767 -0.18080173\n",
      "  0.33085042 -0.05935968 -0.32497122  0.2251639  -0.21087698 -0.20994945\n",
      "  0.09120546 -0.31165755]\n",
      "New theta_0 : [-0.01650586 -0.08418203  0.11330373 -0.01920936  0.0927552  -0.18082864\n",
      "  0.33083555 -0.05934787 -0.32498942  0.2252166  -0.2109249  -0.2099562\n",
      "  0.09120249 -0.311667  ]\n",
      "Training Error:  9.769581762461595\n",
      "====================================================================================================\n",
      "Iteration:  824\n",
      "Previous theta :  [-0.01650586 -0.08418203  0.11330373 -0.01920936  0.0927552  -0.18082864\n",
      "  0.33083555 -0.05934787 -0.32498942  0.2252166  -0.2109249  -0.2099562\n",
      "  0.09120249 -0.311667  ]\n",
      "New theta_0 : [-0.01650585 -0.08418946  0.1133166  -0.01919344  0.09275274 -0.18085537\n",
      "  0.33082077 -0.05933611 -0.32500747  0.22526914 -0.21097272 -0.2099629\n",
      "  0.09119953 -0.31167638]\n",
      "Training Error:  9.769574680574188\n",
      "====================================================================================================\n",
      "Iteration:  825\n",
      "Previous theta :  [-0.01650585 -0.08418946  0.1133166  -0.01919344  0.09275274 -0.18085537\n",
      "  0.33082077 -0.05933611 -0.32500747  0.22526914 -0.21097272 -0.2099629\n",
      "  0.09119953 -0.31167638]\n",
      "New theta_0 : [-0.01650585 -0.08419684  0.11332941 -0.01917754  0.09275028 -0.18088192\n",
      "  0.33080607 -0.05932442 -0.32502537  0.22532153 -0.21102047 -0.20996957\n",
      "  0.0911966  -0.31168571]\n",
      "Training Error:  9.769567646874957\n",
      "====================================================================================================\n",
      "Iteration:  826\n",
      "Previous theta :  [-0.01650585 -0.08419684  0.11332941 -0.01917754  0.09275028 -0.18088192\n",
      "  0.33080607 -0.05932442 -0.32502537  0.22532153 -0.21102047 -0.20996957\n",
      "  0.0911966  -0.31168571]\n",
      "New theta_0 : [-0.01650584 -0.08420419  0.11334215 -0.01916166  0.09274783 -0.1809083\n",
      "  0.33079147 -0.05931279 -0.32504312  0.22537376 -0.21106812 -0.20997621\n",
      "  0.09119369 -0.31169499]\n",
      "Training Error:  9.769560660928475\n",
      "====================================================================================================\n",
      "Iteration:  827\n",
      "Previous theta :  [-0.01650584 -0.08420419  0.11334215 -0.01916166  0.09274783 -0.1809083\n",
      "  0.33079147 -0.05931279 -0.32504312  0.22537376 -0.21106812 -0.20997621\n",
      "  0.09119369 -0.31169499]\n",
      "New theta_0 : [-0.01650584 -0.08421149  0.11335482 -0.01914579  0.09274538 -0.1809345\n",
      "  0.33077695 -0.05930122 -0.32506072  0.22542584 -0.21111569 -0.2099828\n",
      "  0.09119079 -0.3117042 ]\n",
      "Training Error:  9.769553722304348\n",
      "====================================================================================================\n",
      "Iteration:  828\n",
      "Previous theta :  [-0.01650584 -0.08421149  0.11335482 -0.01914579  0.09274538 -0.1809345\n",
      "  0.33077695 -0.05930122 -0.32506072  0.22542584 -0.21111569 -0.2099828\n",
      "  0.09119079 -0.3117042 ]\n",
      "New theta_0 : [-0.01650584 -0.08421876  0.11336743 -0.01912994  0.09274294 -0.18096053\n",
      "  0.33076252 -0.05928971 -0.32507817  0.22547776 -0.21116317 -0.20998936\n",
      "  0.09118792 -0.31171336]\n",
      "Training Error:  9.76954683057718\n",
      "====================================================================================================\n",
      "Iteration:  829\n",
      "Previous theta :  [-0.01650584 -0.08421876  0.11336743 -0.01912994  0.09274294 -0.18096053\n",
      "  0.33076252 -0.05928971 -0.32507817  0.22547776 -0.21116317 -0.20998936\n",
      "  0.09118792 -0.31171336]\n",
      "New theta_0 : [-0.01650584 -0.08422598  0.11337997 -0.01911411  0.0927405  -0.18098639\n",
      "  0.33074818 -0.05927825 -0.32509547  0.22552953 -0.21121056 -0.20999589\n",
      "  0.09118507 -0.31172247]\n",
      "Training Error:  9.769539985326489\n",
      "====================================================================================================\n",
      "Iteration:  830\n",
      "Previous theta :  [-0.01650584 -0.08422598  0.11337997 -0.01911411  0.0927405  -0.18098639\n",
      "  0.33074818 -0.05927825 -0.32509547  0.22552953 -0.21121056 -0.20999589\n",
      "  0.09118507 -0.31172247]\n",
      "New theta_0 : [-0.01650585 -0.08423317  0.11339245 -0.0190983   0.09273807 -0.18101208\n",
      "  0.33073392 -0.05926686 -0.32511263  0.22558115 -0.21125787 -0.21000238\n",
      "  0.09118224 -0.31173151]\n",
      "Training Error:  9.769533186136634\n",
      "====================================================================================================\n",
      "Iteration:  831\n",
      "Previous theta :  [-0.01650585 -0.08423317  0.11339245 -0.0190983   0.09273807 -0.18101208\n",
      "  0.33073392 -0.05926686 -0.32511263  0.22558115 -0.21125787 -0.21000238\n",
      "  0.09118224 -0.31173151]\n",
      "New theta_0 : [-0.01650585 -0.08424031  0.11340486 -0.01908251  0.09273564 -0.1810376\n",
      "  0.33071975 -0.05925552 -0.32512965  0.22563262 -0.21130509 -0.21000884\n",
      "  0.09117942 -0.31174051]\n",
      "Training Error:  9.769526432596782\n",
      "====================================================================================================\n",
      "Iteration:  832\n",
      "Previous theta :  [-0.01650585 -0.08424031  0.11340486 -0.01908251  0.09273564 -0.1810376\n",
      "  0.33071975 -0.05925552 -0.32512965  0.22563262 -0.21130509 -0.21000884\n",
      "  0.09117942 -0.31174051]\n",
      "New theta_0 : [-0.01650586 -0.08424742  0.11341721 -0.01906673  0.09273322 -0.18106295\n",
      "  0.33070567 -0.05924425 -0.32514652  0.22568393 -0.21135222 -0.21001526\n",
      "  0.09117663 -0.31174945]\n",
      "Training Error:  9.7695197243008\n",
      "====================================================================================================\n",
      "Iteration:  833\n",
      "Previous theta :  [-0.01650586 -0.08424742  0.11341721 -0.01906673  0.09273322 -0.18106295\n",
      "  0.33070567 -0.05924425 -0.32514652  0.22568393 -0.21135222 -0.21001526\n",
      "  0.09117663 -0.31174945]\n",
      "New theta_0 : [-0.01650587 -0.08425449  0.1134295  -0.01905098  0.0927308  -0.18108814\n",
      "  0.33069166 -0.05923303 -0.32516325  0.22573509 -0.21139927 -0.21002165\n",
      "  0.09117386 -0.31175833]\n",
      "Training Error:  9.769513060847231\n",
      "====================================================================================================\n",
      "Iteration:  834\n",
      "Previous theta :  [-0.01650587 -0.08425449  0.1134295  -0.01905098  0.0927308  -0.18108814\n",
      "  0.33069166 -0.05923303 -0.32516325  0.22573509 -0.21139927 -0.21002165\n",
      "  0.09117386 -0.31175833]\n",
      "New theta_0 : [-0.01650588 -0.08426152  0.11344172 -0.01903524  0.09272839 -0.18111316\n",
      "  0.33067774 -0.05922187 -0.32517984  0.2257861  -0.21144623 -0.210028\n",
      "  0.0911711  -0.31176717]\n",
      "Training Error:  9.769506441839209\n",
      "====================================================================================================\n",
      "Iteration:  835\n",
      "Previous theta :  [-0.01650588 -0.08426152  0.11344172 -0.01903524  0.09272839 -0.18111316\n",
      "  0.33067774 -0.05922187 -0.32517984  0.2257861  -0.21144623 -0.210028\n",
      "  0.0911711  -0.31176717]\n",
      "New theta_0 : [-0.0165059  -0.08426851  0.11345388 -0.01901952  0.09272598 -0.18113801\n",
      "  0.33066391 -0.05921076 -0.32519629  0.22583697 -0.21149311 -0.21003432\n",
      "  0.09116837 -0.31177594]\n",
      "Training Error:  9.769499866884404\n",
      "====================================================================================================\n",
      "Iteration:  836\n",
      "Previous theta :  [-0.0165059  -0.08426851  0.11345388 -0.01901952  0.09272598 -0.18113801\n",
      "  0.33066391 -0.05921076 -0.32519629  0.22583697 -0.21149311 -0.21003432\n",
      "  0.09116837 -0.31177594]\n",
      "New theta_0 : [-0.01650591 -0.08427546  0.11346597 -0.01900383  0.09272358 -0.1811627\n",
      "  0.33065015 -0.05919972 -0.3252126   0.22588768 -0.2115399  -0.2100406\n",
      "  0.09116565 -0.31178467]\n",
      "Training Error:  9.769493335594975\n",
      "====================================================================================================\n",
      "Iteration:  837\n",
      "Previous theta :  [-0.01650591 -0.08427546  0.11346597 -0.01900383  0.09272358 -0.1811627\n",
      "  0.33065015 -0.05919972 -0.3252126   0.22588768 -0.2115399  -0.2100406\n",
      "  0.09116565 -0.31178467]\n",
      "New theta_0 : [-0.01650593 -0.08428237  0.11347801 -0.01898815  0.09272118 -0.18118723\n",
      "  0.33063648 -0.05918873 -0.32522877  0.22593824 -0.2115866  -0.21004685\n",
      "  0.09116295 -0.31179334]\n",
      "Training Error:  9.769486847587476\n",
      "====================================================================================================\n",
      "Iteration:  838\n",
      "Previous theta :  [-0.01650593 -0.08428237  0.11347801 -0.01898815  0.09272118 -0.18118723\n",
      "  0.33063648 -0.05918873 -0.32522877  0.22593824 -0.2115866  -0.21004685\n",
      "  0.09116295 -0.31179334]\n",
      "New theta_0 : [-0.01650595 -0.08428925  0.11348998 -0.01897249  0.09271879 -0.1812116\n",
      "  0.33062289 -0.05917779 -0.32524481  0.22598866 -0.21163321 -0.21005307\n",
      "  0.09116028 -0.31180196]\n",
      "Training Error:  9.769480402482841\n",
      "====================================================================================================\n",
      "Iteration:  839\n",
      "Previous theta :  [-0.01650595 -0.08428925  0.11348998 -0.01897249  0.09271879 -0.1812116\n",
      "  0.33062289 -0.05917779 -0.32524481  0.22598866 -0.21163321 -0.21005307\n",
      "  0.09116028 -0.31180196]\n",
      "New theta_0 : [-0.01650597 -0.08429609  0.11350189 -0.01895685  0.0927164  -0.18123581\n",
      "  0.33060938 -0.05916691 -0.32526071  0.22603893 -0.21167974 -0.21005925\n",
      "  0.09115762 -0.31181053]\n",
      "Training Error:  9.769473999906296\n",
      "====================================================================================================\n",
      "Iteration:  840\n",
      "Previous theta :  [-0.01650597 -0.08429609  0.11350189 -0.01895685  0.0927164  -0.18123581\n",
      "  0.33060938 -0.05916691 -0.32526071  0.22603893 -0.21167974 -0.21005925\n",
      "  0.09115762 -0.31181053]\n",
      "New theta_0 : [-0.016506   -0.0843029   0.11351374 -0.01894124  0.09271402 -0.18125986\n",
      "  0.33059595 -0.05915609 -0.32527648  0.22608905 -0.21172618 -0.2100654\n",
      "  0.09115498 -0.31181904]\n",
      "Training Error:  9.769467639487308\n",
      "====================================================================================================\n",
      "Iteration:  841\n",
      "Previous theta :  [-0.016506   -0.0843029   0.11351374 -0.01894124  0.09271402 -0.18125986\n",
      "  0.33059595 -0.05915609 -0.32527648  0.22608905 -0.21172618 -0.2100654\n",
      "  0.09115498 -0.31181904]\n",
      "New theta_0 : [-0.01650602 -0.08430966  0.11352553 -0.01892564  0.09271164 -0.18128375\n",
      "  0.3305826  -0.05914532 -0.32529212  0.22613902 -0.21177254 -0.21007152\n",
      "  0.09115235 -0.31182751]\n",
      "Training Error:  9.769461320859541\n",
      "====================================================================================================\n",
      "Iteration:  842\n",
      "Previous theta :  [-0.01650602 -0.08430966  0.11352553 -0.01892564  0.09271164 -0.18128375\n",
      "  0.3305826  -0.05914532 -0.32529212  0.22613902 -0.21177254 -0.21007152\n",
      "  0.09115235 -0.31182751]\n",
      "New theta_0 : [-0.01650605 -0.08431639  0.11353726 -0.01891006  0.09270927 -0.18130748\n",
      "  0.33056933 -0.05913461 -0.32530762  0.22618885 -0.21181881 -0.2100776\n",
      "  0.09114975 -0.31183592]\n",
      "Training Error:  9.769455043660784\n",
      "====================================================================================================\n",
      "Iteration:  843\n",
      "Previous theta :  [-0.01650605 -0.08431639  0.11353726 -0.01891006  0.09270927 -0.18130748\n",
      "  0.33056933 -0.05913461 -0.32530762  0.22618885 -0.21181881 -0.2100776\n",
      "  0.09114975 -0.31183592]\n",
      "New theta_0 : [-0.01650608 -0.08432309  0.11354893 -0.0188945   0.0927069  -0.18133106\n",
      "  0.33055614 -0.05912396 -0.32532299  0.22623853 -0.211865   -0.21008365\n",
      "  0.09114716 -0.31184429]\n",
      "Training Error:  9.769448807532907\n",
      "====================================================================================================\n",
      "Iteration:  844\n",
      "Previous theta :  [-0.01650608 -0.08432309  0.11354893 -0.0188945   0.0927069  -0.18133106\n",
      "  0.33055614 -0.05912396 -0.32532299  0.22623853 -0.211865   -0.21008365\n",
      "  0.09114716 -0.31184429]\n",
      "New theta_0 : [-0.01650611 -0.08432975  0.11356054 -0.01887897  0.09270454 -0.18135448\n",
      "  0.33054302 -0.05911335 -0.32533823  0.22628807 -0.21191109 -0.21008967\n",
      "  0.09114459 -0.3118526 ]\n",
      "Training Error:  9.769442612121807\n",
      "====================================================================================================\n",
      "Iteration:  845\n",
      "Previous theta :  [-0.01650611 -0.08432975  0.11356054 -0.01887897  0.09270454 -0.18135448\n",
      "  0.33054302 -0.05911335 -0.32533823  0.22628807 -0.21191109 -0.21008967\n",
      "  0.09114459 -0.3118526 ]\n",
      "New theta_0 : [-0.01650614 -0.08433637  0.1135721  -0.01886345  0.09270218 -0.18137775\n",
      "  0.33052999 -0.05910281 -0.32535335  0.22633747 -0.2119571  -0.21009566\n",
      "  0.09114204 -0.31186086]\n",
      "Training Error:  9.769436457077346\n",
      "====================================================================================================\n",
      "Iteration:  846\n",
      "Previous theta :  [-0.01650614 -0.08433637  0.1135721  -0.01886345  0.09270218 -0.18137775\n",
      "  0.33052999 -0.05910281 -0.32535335  0.22633747 -0.2119571  -0.21009566\n",
      "  0.09114204 -0.31186086]\n",
      "New theta_0 : [-0.01650617 -0.08434295  0.11358359 -0.01884796  0.09269982 -0.18140086\n",
      "  0.33051703 -0.05909231 -0.32536833  0.22638672 -0.21200303 -0.21010161\n",
      "  0.09113951 -0.31186907]\n",
      "Training Error:  9.769430342053317\n",
      "====================================================================================================\n",
      "Iteration:  847\n",
      "Previous theta :  [-0.01650617 -0.08434295  0.11358359 -0.01884796  0.09269982 -0.18140086\n",
      "  0.33051703 -0.05909231 -0.32536833  0.22638672 -0.21200303 -0.21010161\n",
      "  0.09113951 -0.31186907]\n",
      "New theta_0 : [-0.01650621 -0.08434951  0.11359503 -0.01883248  0.09269748 -0.18142382\n",
      "  0.33050414 -0.05908187 -0.32538319  0.22643582 -0.21204887 -0.21010753\n",
      "  0.09113699 -0.31187724]\n",
      "Training Error:  9.76942426670737\n",
      "====================================================================================================\n",
      "Iteration:  848\n",
      "Previous theta :  [-0.01650621 -0.08434951  0.11359503 -0.01883248  0.09269748 -0.18142382\n",
      "  0.33050414 -0.05908187 -0.32538319  0.22643582 -0.21204887 -0.21010753\n",
      "  0.09113699 -0.31187724]\n",
      "New theta_0 : [-0.01650625 -0.08435602  0.1136064  -0.01881703  0.09269513 -0.18144664\n",
      "  0.33049134 -0.05907148 -0.32539792  0.22648479 -0.21209462 -0.21011342\n",
      "  0.0911345  -0.31188535]\n",
      "Training Error:  9.769418230700975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  849\n",
      "Previous theta :  [-0.01650625 -0.08435602  0.1136064  -0.01881703  0.09269513 -0.18144664\n",
      "  0.33049134 -0.05907148 -0.32539792  0.22648479 -0.21209462 -0.21011342\n",
      "  0.0911345  -0.31188535]\n",
      "New theta_0 : [-0.01650629 -0.0843625   0.11361772 -0.0188016   0.09269279 -0.1814693\n",
      "  0.3304786  -0.05906115 -0.32541253  0.22653361 -0.21214029 -0.21011928\n",
      "  0.09113202 -0.31189342]\n",
      "Training Error:  9.769412233699372\n",
      "====================================================================================================\n",
      "Iteration:  850\n",
      "Previous theta :  [-0.01650629 -0.0843625   0.11361772 -0.0188016   0.09269279 -0.1814693\n",
      "  0.3304786  -0.05906115 -0.32541253  0.22653361 -0.21214029 -0.21011928\n",
      "  0.09113202 -0.31189342]\n",
      "New theta_0 : [-0.01650633 -0.08436895  0.11362899 -0.01878619  0.09269046 -0.18149181\n",
      "  0.33046595 -0.05905087 -0.32542701  0.22658229 -0.21218587 -0.21012511\n",
      "  0.09112955 -0.31190144]\n",
      "Training Error:  9.769406275371512\n",
      "====================================================================================================\n",
      "Iteration:  851\n",
      "Previous theta :  [-0.01650633 -0.08436895  0.11362899 -0.01878619  0.09269046 -0.18149181\n",
      "  0.33046595 -0.05905087 -0.32542701  0.22658229 -0.21218587 -0.21012511\n",
      "  0.09112955 -0.31190144]\n",
      "New theta_0 : [-0.01650637 -0.08437536  0.1136402  -0.0187708   0.09268813 -0.18151418\n",
      "  0.33045336 -0.05904064 -0.32544137  0.22663083 -0.21223136 -0.21013091\n",
      "  0.09112711 -0.31190941]\n",
      "Training Error:  9.76940035539003\n",
      "====================================================================================================\n",
      "Iteration:  852\n",
      "Previous theta :  [-0.01650637 -0.08437536  0.1136402  -0.0187708   0.09268813 -0.18151418\n",
      "  0.33045336 -0.05904064 -0.32544137  0.22663083 -0.21223136 -0.21013091\n",
      "  0.09112711 -0.31190941]\n",
      "New theta_0 : [-0.01650642 -0.08438174  0.11365135 -0.01875543  0.0926858  -0.1815364\n",
      "  0.33044085 -0.05903046 -0.32545561  0.22667923 -0.21227677 -0.21013667\n",
      "  0.09112468 -0.31191733]\n",
      "Training Error:  9.769394473431161\n",
      "====================================================================================================\n",
      "Iteration:  853\n",
      "Previous theta :  [-0.01650642 -0.08438174  0.11365135 -0.01875543  0.0926858  -0.1815364\n",
      "  0.33044085 -0.05903046 -0.32545561  0.22667923 -0.21227677 -0.21013667\n",
      "  0.09112468 -0.31191733]\n",
      "New theta_0 : [-0.01650646 -0.08438809  0.11366244 -0.01874009  0.09268348 -0.18155847\n",
      "  0.33042842 -0.05902033 -0.32546973  0.22672749 -0.2123221  -0.21014241\n",
      "  0.09112226 -0.3119252 ]\n",
      "Training Error:  9.769388629174731\n",
      "====================================================================================================\n",
      "Iteration:  854\n",
      "Previous theta :  [-0.01650646 -0.08438809  0.11366244 -0.01874009  0.09268348 -0.18155847\n",
      "  0.33042842 -0.05902033 -0.32546973  0.22672749 -0.2123221  -0.21014241\n",
      "  0.09112226 -0.3119252 ]\n",
      "New theta_0 : [-0.01650651 -0.0843944   0.11367348 -0.01872477  0.09268117 -0.1815804\n",
      "  0.33041605 -0.05901026 -0.32548373  0.22677561 -0.21236734 -0.21014811\n",
      "  0.09111987 -0.31193303]\n",
      "Training Error:  9.769382822304088\n",
      "====================================================================================================\n",
      "Iteration:  855\n",
      "Previous theta :  [-0.01650651 -0.0843944   0.11367348 -0.01872477  0.09268117 -0.1815804\n",
      "  0.33041605 -0.05901026 -0.32548373  0.22677561 -0.21236734 -0.21014811\n",
      "  0.09111987 -0.31193303]\n",
      "New theta_0 : [-0.01650656 -0.08440068  0.11368447 -0.01870946  0.09267886 -0.18160219\n",
      "  0.33040376 -0.05900024 -0.32549761  0.22682359 -0.21241249 -0.21015378\n",
      "  0.09111749 -0.31194081]\n",
      "Training Error:  9.769377052506059\n",
      "====================================================================================================\n",
      "Iteration:  856\n",
      "Previous theta :  [-0.01650656 -0.08440068  0.11368447 -0.01870946  0.09267886 -0.18160219\n",
      "  0.33040376 -0.05900024 -0.32549761  0.22682359 -0.21241249 -0.21015378\n",
      "  0.09111749 -0.31194081]\n",
      "New theta_0 : [-0.01650661 -0.08440692  0.11369539 -0.01869418  0.09267655 -0.18162383\n",
      "  0.33039154 -0.05899026 -0.32551137  0.22687143 -0.21245755 -0.21015943\n",
      "  0.09111513 -0.31194855]\n",
      "Training Error:  9.76937131947091\n",
      "====================================================================================================\n",
      "Iteration:  857\n",
      "Previous theta :  [-0.01650661 -0.08440692  0.11369539 -0.01869418  0.09267655 -0.18162383\n",
      "  0.33039154 -0.05899026 -0.32551137  0.22687143 -0.21245755 -0.21015943\n",
      "  0.09111513 -0.31194855]\n",
      "New theta_0 : [-0.01650666 -0.08441313  0.11370627 -0.01867893  0.09267425 -0.18164533\n",
      "  0.3303794  -0.05898034 -0.32552501  0.22691914 -0.21250253 -0.21016504\n",
      "  0.09111278 -0.31195623]\n",
      "Training Error:  9.769365622892295\n",
      "====================================================================================================\n",
      "Iteration:  858\n",
      "Previous theta :  [-0.01650666 -0.08441313  0.11370627 -0.01867893  0.09267425 -0.18164533\n",
      "  0.3303794  -0.05898034 -0.32552501  0.22691914 -0.21250253 -0.21016504\n",
      "  0.09111278 -0.31195623]\n",
      "New theta_0 : [-0.01650672 -0.08441931  0.11371709 -0.01866369  0.09267196 -0.18166669\n",
      "  0.33036732 -0.05897047 -0.32553854  0.22696671 -0.21254743 -0.21017062\n",
      "  0.09111045 -0.31196388]\n",
      "Training Error:  9.769359962467218\n",
      "====================================================================================================\n",
      "Iteration:  859\n",
      "Previous theta :  [-0.01650672 -0.08441931  0.11371709 -0.01866369  0.09267196 -0.18166669\n",
      "  0.33036732 -0.05897047 -0.32553854  0.22696671 -0.21254743 -0.21017062\n",
      "  0.09111045 -0.31196388]\n",
      "New theta_0 : [-0.01650677 -0.08442546  0.11372786 -0.01864848  0.09266967 -0.18168791\n",
      "  0.33035531 -0.05896065 -0.32555195  0.22701414 -0.21259224 -0.21017618\n",
      "  0.09110814 -0.31197147]\n",
      "Training Error:  9.769354337895988\n",
      "====================================================================================================\n",
      "Iteration:  860\n",
      "Previous theta :  [-0.01650677 -0.08442546  0.11372786 -0.01864848  0.09266967 -0.18168791\n",
      "  0.33035531 -0.05896065 -0.32555195  0.22701414 -0.21259224 -0.21017618\n",
      "  0.09110814 -0.31197147]\n",
      "New theta_0 : [-0.01650683 -0.08443157  0.11373857 -0.01863329  0.09266738 -0.18170899\n",
      "  0.33034338 -0.05895088 -0.32556525  0.22706143 -0.21263696 -0.2101817\n",
      "  0.09110584 -0.31197902]\n",
      "Training Error:  9.769348748882173\n",
      "====================================================================================================\n",
      "Iteration:  861\n",
      "Previous theta :  [-0.01650683 -0.08443157  0.11373857 -0.01863329  0.09266738 -0.18170899\n",
      "  0.33034338 -0.05895088 -0.32556525  0.22706143 -0.21263696 -0.2101817\n",
      "  0.09110584 -0.31197902]\n",
      "New theta_0 : [-0.01650689 -0.08443765  0.11374923 -0.01861812  0.0926651  -0.18172994\n",
      "  0.33033151 -0.05894116 -0.32557844  0.22710859 -0.2126816  -0.21018719\n",
      "  0.09110356 -0.31198653]\n",
      "Training Error:  9.769343195132562\n",
      "====================================================================================================\n",
      "Iteration:  862\n",
      "Previous theta :  [-0.01650689 -0.08443765  0.11374923 -0.01861812  0.0926651  -0.18172994\n",
      "  0.33033151 -0.05894116 -0.32557844  0.22710859 -0.2126816  -0.21018719\n",
      "  0.09110356 -0.31198653]\n",
      "New theta_0 : [-0.01650695 -0.0844437   0.11375984 -0.01860298  0.09266282 -0.18175074\n",
      "  0.33031971 -0.05893148 -0.32559151  0.22715561 -0.21272615 -0.21019266\n",
      "  0.09110129 -0.31199399]\n",
      "Training Error:  9.769337676357114\n",
      "====================================================================================================\n",
      "Iteration:  863\n",
      "Previous theta :  [-0.01650695 -0.0844437   0.11375984 -0.01860298  0.09266282 -0.18175074\n",
      "  0.33031971 -0.05893148 -0.32559151  0.22715561 -0.21272615 -0.21019266\n",
      "  0.09110129 -0.31199399]\n",
      "New theta_0 : [-0.01650701 -0.08444972  0.1137704  -0.01858786  0.09266055 -0.18177141\n",
      "  0.33030798 -0.05892186 -0.32560447  0.2272025  -0.21277062 -0.21019809\n",
      "  0.09109904 -0.31200141]\n",
      "Training Error:  9.769332192268939\n",
      "====================================================================================================\n",
      "Iteration:  864\n",
      "Previous theta :  [-0.01650701 -0.08444972  0.1137704  -0.01858786  0.09266055 -0.18177141\n",
      "  0.33030798 -0.05892186 -0.32560447  0.2272025  -0.21277062 -0.21019809\n",
      "  0.09109904 -0.31200141]\n",
      "New theta_0 : [-0.01650707 -0.08445571  0.1137809  -0.01857276  0.09265828 -0.18179194\n",
      "  0.33029632 -0.05891228 -0.32561732  0.22724925 -0.212815   -0.2102035\n",
      "  0.09109681 -0.31200878]\n",
      "Training Error:  9.769326742584227\n",
      "====================================================================================================\n",
      "Iteration:  865\n",
      "Previous theta :  [-0.01650707 -0.08445571  0.1137809  -0.01857276  0.09265828 -0.18179194\n",
      "  0.33029632 -0.05891228 -0.32561732  0.22724925 -0.212815   -0.2102035\n",
      "  0.09109681 -0.31200878]\n",
      "New theta_0 : [-0.01650714 -0.08446166  0.11379135 -0.01855768  0.09265602 -0.18181234\n",
      "  0.33028473 -0.05890276 -0.32563006  0.22729587 -0.2128593  -0.21020888\n",
      "  0.09109459 -0.31201611]\n",
      "Training Error:  9.769321327022231\n",
      "====================================================================================================\n",
      "Iteration:  866\n",
      "Previous theta :  [-0.01650714 -0.08446166  0.11379135 -0.01855768  0.09265602 -0.18181234\n",
      "  0.33028473 -0.05890276 -0.32563006  0.22729587 -0.2128593  -0.21020888\n",
      "  0.09109459 -0.31201611]\n",
      "New theta_0 : [-0.0165072  -0.08446759  0.11380176 -0.01854263  0.09265376 -0.18183261\n",
      "  0.3302732  -0.05889328 -0.32564269  0.22734236 -0.21290351 -0.21021423\n",
      "  0.09109238 -0.3120234 ]\n",
      "Training Error:  9.769315945305221\n",
      "====================================================================================================\n",
      "Iteration:  867\n",
      "Previous theta :  [-0.0165072  -0.08446759  0.11380176 -0.01854263  0.09265376 -0.18183261\n",
      "  0.3302732  -0.05889328 -0.32564269  0.22734236 -0.21290351 -0.21021423\n",
      "  0.09109238 -0.3120234 ]\n",
      "New theta_0 : [-0.01650727 -0.08447348  0.11381211 -0.0185276   0.09265151 -0.18185274\n",
      "  0.33026174 -0.05888385 -0.32565521  0.22738871 -0.21294764 -0.21021955\n",
      "  0.09109019 -0.31203064]\n",
      "Training Error:  9.769310597158448\n",
      "====================================================================================================\n",
      "Iteration:  868\n",
      "Previous theta :  [-0.01650727 -0.08447348  0.11381211 -0.0185276   0.09265151 -0.18185274\n",
      "  0.33026174 -0.05888385 -0.32565521  0.22738871 -0.21294764 -0.21021955\n",
      "  0.09109019 -0.31203064]\n",
      "New theta_0 : [-0.01650734 -0.08447935  0.1138224  -0.01851259  0.09264926 -0.18187275\n",
      "  0.33025035 -0.05887446 -0.32566763  0.22743493 -0.21299168 -0.21022484\n",
      "  0.09108802 -0.31203784]\n",
      "Training Error:  9.769305282310091\n",
      "====================================================================================================\n",
      "Iteration:  869\n",
      "Previous theta :  [-0.01650734 -0.08447935  0.1138224  -0.01851259  0.09264926 -0.18187275\n",
      "  0.33025035 -0.05887446 -0.32566763  0.22743493 -0.21299168 -0.21022484\n",
      "  0.09108802 -0.31203784]\n",
      "New theta_0 : [-0.01650741 -0.08448518  0.11383265 -0.01849761  0.09264702 -0.18189262\n",
      "  0.33023902 -0.05886512 -0.32567994  0.22748102 -0.21303564 -0.21023011\n",
      "  0.09108586 -0.312045  ]\n",
      "Training Error:  9.769300000491247\n",
      "====================================================================================================\n",
      "Iteration:  870\n",
      "Previous theta :  [-0.01650741 -0.08448518  0.11383265 -0.01849761  0.09264702 -0.18189262\n",
      "  0.33023902 -0.05886512 -0.32567994  0.22748102 -0.21303564 -0.21023011\n",
      "  0.09108586 -0.312045  ]\n",
      "New theta_0 : [-0.01650748 -0.08449098  0.11384285 -0.01848265  0.09264478 -0.18191236\n",
      "  0.33022776 -0.05885584 -0.32569214  0.22752698 -0.21307951 -0.21023534\n",
      "  0.09108372 -0.31205212]\n",
      "Training Error:  9.769294751435863\n",
      "====================================================================================================\n",
      "Iteration:  871\n",
      "Previous theta :  [-0.01650748 -0.08449098  0.11384285 -0.01848265  0.09264478 -0.18191236\n",
      "  0.33022776 -0.05885584 -0.32569214  0.22752698 -0.21307951 -0.21023534\n",
      "  0.09108372 -0.31205212]\n",
      "New theta_0 : [-0.01650755 -0.08449675  0.113853   -0.01846771  0.09264255 -0.18193197\n",
      "  0.33021656 -0.05884659 -0.32570424  0.2275728  -0.2131233  -0.21024055\n",
      "  0.09108159 -0.31205919]\n",
      "Training Error:  9.769289534880725\n",
      "====================================================================================================\n",
      "Iteration:  872\n",
      "Previous theta :  [-0.01650755 -0.08449675  0.113853   -0.01846771  0.09264255 -0.18193197\n",
      "  0.33021656 -0.05884659 -0.32570424  0.2275728  -0.2131233  -0.21024055\n",
      "  0.09108159 -0.31205919]\n",
      "New theta_0 : [-0.01650763 -0.0845025   0.1138631  -0.0184528   0.09264032 -0.18195146\n",
      "  0.33020543 -0.0588374  -0.32571624  0.2276185  -0.213167   -0.21024574\n",
      "  0.09107947 -0.31206622]\n",
      "Training Error:  9.769284350565401\n",
      "====================================================================================================\n",
      "Iteration:  873\n",
      "Previous theta :  [-0.01650763 -0.0845025   0.1138631  -0.0184528   0.09264032 -0.18195146\n",
      "  0.33020543 -0.0588374  -0.32571624  0.2276185  -0.213167   -0.21024574\n",
      "  0.09107947 -0.31206622]\n",
      "New theta_0 : [-0.0165077  -0.08450821  0.11387315 -0.01843791  0.09263809 -0.18197081\n",
      "  0.33019436 -0.05882825 -0.32572813  0.22766406 -0.21321062 -0.21025089\n",
      "  0.09107737 -0.31207321]\n",
      "Training Error:  9.769279198232223\n",
      "====================================================================================================\n",
      "Iteration:  874\n",
      "Previous theta :  [-0.0165077  -0.08450821  0.11387315 -0.01843791  0.09263809 -0.18197081\n",
      "  0.33019436 -0.05882825 -0.32572813  0.22766406 -0.21321062 -0.21025089\n",
      "  0.09107737 -0.31207321]\n",
      "New theta_0 : [-0.01650778 -0.08451389  0.11388315 -0.01842304  0.09263587 -0.18199004\n",
      "  0.33018335 -0.05881914 -0.32573992  0.2277095  -0.21325415 -0.21025602\n",
      "  0.09107529 -0.31208016]\n",
      "Training Error:  9.769274077626243\n",
      "====================================================================================================\n",
      "Iteration:  875\n",
      "Previous theta :  [-0.01650778 -0.08451389  0.11388315 -0.01842304  0.09263587 -0.18199004\n",
      "  0.33018335 -0.05881914 -0.32573992  0.2277095  -0.21325415 -0.21025602\n",
      "  0.09107529 -0.31208016]\n",
      "New theta_0 : [-0.01650786 -0.08451955  0.11389311 -0.0184082   0.09263366 -0.18200915\n",
      "  0.33017241 -0.05881008 -0.32575161  0.22775481 -0.2132976  -0.21026111\n",
      "  0.09107322 -0.31208707]\n",
      "Training Error:  9.769268988495195\n",
      "====================================================================================================\n",
      "Iteration:  876\n",
      "Previous theta :  [-0.01650786 -0.08451955  0.11389311 -0.0184082   0.09263366 -0.18200915\n",
      "  0.33017241 -0.05881008 -0.32575161  0.22775481 -0.2132976  -0.21026111\n",
      "  0.09107322 -0.31208707]\n",
      "New theta_0 : [-0.01650794 -0.08452517  0.11390301 -0.01839338  0.09263145 -0.18202813\n",
      "  0.33016153 -0.05880107 -0.3257632   0.22779998 -0.21334096 -0.21026619\n",
      "  0.09107116 -0.31209394]\n",
      "Training Error:  9.769263930589473\n",
      "====================================================================================================\n",
      "Iteration:  877\n",
      "Previous theta :  [-0.01650794 -0.08452517  0.11390301 -0.01839338  0.09263145 -0.18202813\n",
      "  0.33016153 -0.05880107 -0.3257632   0.22779998 -0.21334096 -0.21026619\n",
      "  0.09107116 -0.31209394]\n",
      "New theta_0 : [-0.01650802 -0.08453077  0.11391287 -0.01837859  0.09262924 -0.18204699\n",
      "  0.33015072 -0.0587921  -0.32577469  0.22784503 -0.21338424 -0.21027123\n",
      "  0.09106912 -0.31210076]\n",
      "Training Error:  9.769258903662077\n",
      "====================================================================================================\n",
      "Iteration:  878\n",
      "Previous theta :  [-0.01650802 -0.08453077  0.11391287 -0.01837859  0.09262924 -0.18204699\n",
      "  0.33015072 -0.0587921  -0.32577469  0.22784503 -0.21338424 -0.21027123\n",
      "  0.09106912 -0.31210076]\n",
      "New theta_0 : [-0.0165081  -0.08453634  0.11392268 -0.01836382  0.09262704 -0.18206572\n",
      "  0.33013996 -0.05878318 -0.32578608  0.22788996 -0.21342744 -0.21027625\n",
      "  0.09106709 -0.31210755]\n",
      "Training Error:  9.76925390746861\n",
      "====================================================================================================\n",
      "Iteration:  879\n",
      "Previous theta :  [-0.0165081  -0.08453634  0.11392268 -0.01836382  0.09262704 -0.18206572\n",
      "  0.33013996 -0.05878318 -0.32578608  0.22788996 -0.21342744 -0.21027625\n",
      "  0.09106709 -0.31210755]\n",
      "New theta_0 : [-0.01650818 -0.08454188  0.11393244 -0.01834907  0.09262485 -0.18208433\n",
      "  0.33012927 -0.0587743  -0.32579737  0.22793475 -0.21347055 -0.21028124\n",
      "  0.09106508 -0.3121143 ]\n",
      "Training Error:  9.76924894176721\n",
      "====================================================================================================\n",
      "Iteration:  880\n",
      "Previous theta :  [-0.01650818 -0.08454188  0.11393244 -0.01834907  0.09262485 -0.18208433\n",
      "  0.33012927 -0.0587743  -0.32579737  0.22793475 -0.21347055 -0.21028124\n",
      "  0.09106508 -0.3121143 ]\n",
      "New theta_0 : [-0.01650827 -0.08454739  0.11394216 -0.01833435  0.09262265 -0.18210282\n",
      "  0.33011863 -0.05876547 -0.32580856  0.22797942 -0.21351358 -0.21028621\n",
      "  0.09106308 -0.31212101]\n",
      "Training Error:  9.769244006318548\n",
      "====================================================================================================\n",
      "Iteration:  881\n",
      "Previous theta :  [-0.01650827 -0.08454739  0.11394216 -0.01833435  0.09262265 -0.18210282\n",
      "  0.33011863 -0.05876547 -0.32580856  0.22797942 -0.21351358 -0.21028621\n",
      "  0.09106308 -0.31212101]\n",
      "New theta_0 : [-0.01650836 -0.08455287  0.11395183 -0.01831965  0.09262047 -0.18212119\n",
      "  0.33010806 -0.05875668 -0.32581966  0.22802396 -0.21355652 -0.21029115\n",
      "  0.09106109 -0.31212767]\n",
      "Training Error:  9.769239100885775\n",
      "====================================================================================================\n",
      "Iteration:  882\n",
      "Previous theta :  [-0.01650836 -0.08455287  0.11395183 -0.01831965  0.09262047 -0.18212119\n",
      "  0.33010806 -0.05875668 -0.32581966  0.22802396 -0.21355652 -0.21029115\n",
      "  0.09106109 -0.31212767]\n",
      "New theta_0 : [-0.01650844 -0.08455832  0.11396145 -0.01830498  0.09261829 -0.18213944\n",
      "  0.33009755 -0.05874793 -0.32583066  0.22806838 -0.21359938 -0.21029606\n",
      "  0.09105912 -0.3121343 ]\n",
      "Training Error:  9.769234225234504\n",
      "====================================================================================================\n",
      "Iteration:  883\n",
      "Previous theta :  [-0.01650844 -0.08455832  0.11396145 -0.01830498  0.09261829 -0.18213944\n",
      "  0.33009755 -0.05874793 -0.32583066  0.22806838 -0.21359938 -0.21029606\n",
      "  0.09105912 -0.3121343 ]\n",
      "New theta_0 : [-0.01650853 -0.08456375  0.11397103 -0.01829033  0.09261611 -0.18215757\n",
      "  0.3300871  -0.05873923 -0.32584157  0.22811267 -0.21364215 -0.21030095\n",
      "  0.09105716 -0.31214089]\n",
      "Training Error:  9.769229379132776\n",
      "====================================================================================================\n",
      "Iteration:  884\n",
      "Previous theta :  [-0.01650853 -0.08456375  0.11397103 -0.01829033  0.09261611 -0.18215757\n",
      "  0.3300871  -0.05873923 -0.32584157  0.22811267 -0.21364215 -0.21030095\n",
      "  0.09105716 -0.31214089]\n",
      "New theta_0 : [-0.01650862 -0.08456915  0.11398056 -0.01827571  0.09261394 -0.18217558\n",
      "  0.3300767  -0.05873057 -0.32585238  0.22815683 -0.21368484 -0.21030581\n",
      "  0.09105521 -0.31214744]\n",
      "Training Error:  9.769224562351022\n",
      "====================================================================================================\n",
      "Iteration:  885\n",
      "Previous theta :  [-0.01650862 -0.08456915  0.11398056 -0.01827571  0.09261394 -0.18217558\n",
      "  0.3300767  -0.05873057 -0.32585238  0.22815683 -0.21368484 -0.21030581\n",
      "  0.09105521 -0.31214744]\n",
      "New theta_0 : [-0.01650871 -0.08457452  0.11399004 -0.01826111  0.09261177 -0.18219348\n",
      "  0.33006637 -0.05872195 -0.3258631   0.22820088 -0.21372745 -0.21031065\n",
      "  0.09105328 -0.31215396]\n",
      "Training Error:  9.76921977466204\n",
      "====================================================================================================\n",
      "Iteration:  886\n",
      "Previous theta :  [-0.01650871 -0.08457452  0.11399004 -0.01826111  0.09261177 -0.18219348\n",
      "  0.33006637 -0.05872195 -0.3258631   0.22820088 -0.21372745 -0.21031065\n",
      "  0.09105328 -0.31215396]\n",
      "New theta_0 : [-0.0165088  -0.08457987  0.11399948 -0.01824653  0.0926096  -0.18221125\n",
      "  0.3300561  -0.05871338 -0.32587373  0.22824479 -0.21376997 -0.21031546\n",
      "  0.09105136 -0.31216043]\n",
      "Training Error:  9.769215015840967\n",
      "====================================================================================================\n",
      "Iteration:  887\n",
      "Previous theta :  [-0.0165088  -0.08457987  0.11399948 -0.01824653  0.0926096  -0.18221125\n",
      "  0.3300561  -0.05871338 -0.32587373  0.22824479 -0.21376997 -0.21031546\n",
      "  0.09105136 -0.31216043]\n",
      "New theta_0 : [-0.0165089  -0.08458519  0.11400888 -0.01823198  0.09260744 -0.18222892\n",
      "  0.33004588 -0.05870485 -0.32588426  0.22828859 -0.21381241 -0.21032025\n",
      "  0.09104945 -0.31216687]\n",
      "Training Error:  9.76921028566524\n",
      "====================================================================================================\n",
      "Iteration:  888\n",
      "Previous theta :  [-0.0165089  -0.08458519  0.11400888 -0.01823198  0.09260744 -0.18222892\n",
      "  0.33004588 -0.05870485 -0.32588426  0.22828859 -0.21381241 -0.21032025\n",
      "  0.09104945 -0.31216687]\n",
      "New theta_0 : [-0.01650899 -0.08459048  0.11401823 -0.01821745  0.09260529 -0.18224646\n",
      "  0.33003572 -0.05869636 -0.32589471  0.22833225 -0.21385476 -0.21032501\n",
      "  0.09104756 -0.31217327]\n",
      "Training Error:  9.76920558391458\n",
      "====================================================================================================\n",
      "Iteration:  889\n",
      "Previous theta :  [-0.01650899 -0.08459048  0.11401823 -0.01821745  0.09260529 -0.18224646\n",
      "  0.33003572 -0.05869636 -0.32589471  0.22833225 -0.21385476 -0.21032501\n",
      "  0.09104756 -0.31217327]\n",
      "New theta_0 : [-0.01650909 -0.08459574  0.11402753 -0.01820295  0.09260314 -0.1822639\n",
      "  0.33002562 -0.05868792 -0.32590506  0.2283758  -0.21389703 -0.21032974\n",
      "  0.09104568 -0.31217963]\n",
      "Training Error:  9.769200910370953\n",
      "====================================================================================================\n",
      "Iteration:  890\n",
      "Previous theta :  [-0.01650909 -0.08459574  0.11402753 -0.01820295  0.09260314 -0.1822639\n",
      "  0.33002562 -0.05868792 -0.32590506  0.2283758  -0.21389703 -0.21032974\n",
      "  0.09104568 -0.31217963]\n",
      "New theta_0 : [-0.01650918 -0.08460098  0.1140368  -0.01818848  0.092601   -0.18228122\n",
      "  0.33001557 -0.05867952 -0.32591532  0.22841923 -0.21393922 -0.21033445\n",
      "  0.09104381 -0.31218596]\n",
      "Training Error:  9.769196264818548\n",
      "====================================================================================================\n",
      "Iteration:  891\n",
      "Previous theta :  [-0.01650918 -0.08460098  0.1140368  -0.01818848  0.092601   -0.18228122\n",
      "  0.33001557 -0.05867952 -0.32591532  0.22841923 -0.21393922 -0.21033445\n",
      "  0.09104381 -0.31218596]\n",
      "New theta_0 : [-0.01650928 -0.08460619  0.11404602 -0.01817402  0.09259886 -0.18229843\n",
      "  0.33000559 -0.05867115 -0.32592549  0.22846253 -0.21398132 -0.21033914\n",
      "  0.09104196 -0.31219224]\n",
      "Training Error:  9.76919164704375\n",
      "====================================================================================================\n",
      "Iteration:  892\n",
      "Previous theta :  [-0.01650928 -0.08460619  0.11404602 -0.01817402  0.09259886 -0.18229843\n",
      "  0.33000559 -0.05867115 -0.32592549  0.22846253 -0.21398132 -0.21033914\n",
      "  0.09104196 -0.31219224]\n",
      "New theta_0 : [-0.01650938 -0.08461138  0.11405519 -0.0181596   0.09259672 -0.18231552\n",
      "  0.32999566 -0.05866283 -0.32593558  0.22850571 -0.21402335 -0.2103438\n",
      "  0.09104012 -0.3121985 ]\n",
      "Training Error:  9.769187056835102\n",
      "====================================================================================================\n",
      "Iteration:  893\n",
      "Previous theta :  [-0.01650938 -0.08461138  0.11405519 -0.0181596   0.09259672 -0.18231552\n",
      "  0.32999566 -0.05866283 -0.32593558  0.22850571 -0.21402335 -0.2103438\n",
      "  0.09104012 -0.3121985 ]\n",
      "New theta_0 : [-0.01650948 -0.08461654  0.11406432 -0.01814519  0.09259459 -0.1823325\n",
      "  0.32998578 -0.05865455 -0.32594558  0.22854877 -0.21406528 -0.21034844\n",
      "  0.09103829 -0.31220471]\n",
      "Training Error:  9.769182493983289\n",
      "====================================================================================================\n",
      "Iteration:  894\n",
      "Previous theta :  [-0.01650948 -0.08461654  0.11406432 -0.01814519  0.09259459 -0.1823325\n",
      "  0.32998578 -0.05865455 -0.32594558  0.22854877 -0.21406528 -0.21034844\n",
      "  0.09103829 -0.31220471]\n",
      "New theta_0 : [-0.01650958 -0.08462167  0.11407341 -0.01813082  0.09259246 -0.18234938\n",
      "  0.32997596 -0.05864632 -0.32595549  0.22859171 -0.21410714 -0.21035305\n",
      "  0.09103647 -0.31221089]\n",
      "Training Error:  9.769177958281114\n",
      "====================================================================================================\n",
      "Iteration:  895\n",
      "Previous theta :  [-0.01650958 -0.08462167  0.11407341 -0.01813082  0.09259246 -0.18234938\n",
      "  0.32997596 -0.05864632 -0.32595549  0.22859171 -0.21410714 -0.21035305\n",
      "  0.09103647 -0.31221089]\n",
      "New theta_0 : [-0.01650968 -0.08462678  0.11408246 -0.01811647  0.09259034 -0.18236614\n",
      "  0.3299662  -0.05863812 -0.32596531  0.22863453 -0.21414891 -0.21035764\n",
      "  0.09103467 -0.31221703]\n",
      "Training Error:  9.769173449523462\n",
      "====================================================================================================\n",
      "Iteration:  896\n",
      "Previous theta :  [-0.01650968 -0.08462678  0.11408246 -0.01811647  0.09259034 -0.18236614\n",
      "  0.3299662  -0.05863812 -0.32596531  0.22863453 -0.21414891 -0.21035764\n",
      "  0.09103467 -0.31221703]\n",
      "New theta_0 : [-0.01650979 -0.08463186  0.11409146 -0.01810214  0.09258822 -0.1823828\n",
      "  0.32995649 -0.05862996 -0.32597505  0.22867723 -0.2141906  -0.2103622\n",
      "  0.09103287 -0.31222314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.769168967507275\n",
      "====================================================================================================\n",
      "Iteration:  897\n",
      "Previous theta :  [-0.01650979 -0.08463186  0.11409146 -0.01810214  0.09258822 -0.1823828\n",
      "  0.32995649 -0.05862996 -0.32597505  0.22867723 -0.2141906  -0.2103622\n",
      "  0.09103287 -0.31222314]\n",
      "New theta_0 : [-0.01650989 -0.08463692  0.11410042 -0.01808784  0.09258611 -0.18239934\n",
      "  0.32994683 -0.05862185 -0.32598471  0.22871981 -0.2142322  -0.21036674\n",
      "  0.09103109 -0.31222921]\n",
      "Training Error:  9.769164512031535\n",
      "====================================================================================================\n",
      "Iteration:  898\n",
      "Previous theta :  [-0.01650989 -0.08463692  0.11410042 -0.01808784  0.09258611 -0.18239934\n",
      "  0.32994683 -0.05862185 -0.32598471  0.22871981 -0.2142322  -0.21036674\n",
      "  0.09103109 -0.31222921]\n",
      "New theta_0 : [-0.01651    -0.08464195  0.11410934 -0.01807356  0.092584   -0.18241578\n",
      "  0.32993723 -0.05861377 -0.32599428  0.22876227 -0.21427372 -0.21037126\n",
      "  0.09102933 -0.31223525]\n",
      "Training Error:  9.769160082897232\n",
      "====================================================================================================\n",
      "Iteration:  899\n",
      "Previous theta :  [-0.01651    -0.08464195  0.11410934 -0.01807356  0.092584   -0.18241578\n",
      "  0.32993723 -0.05861377 -0.32599428  0.22876227 -0.21427372 -0.21037126\n",
      "  0.09102933 -0.31223525]\n",
      "New theta_0 : [-0.0165101  -0.08464696  0.11411822 -0.01805931  0.0925819  -0.18243212\n",
      "  0.32992768 -0.05860574 -0.32600376  0.22880461 -0.21431516 -0.21037575\n",
      "  0.09102757 -0.31224125]\n",
      "Training Error:  9.769155679907337\n",
      "====================================================================================================\n",
      "Iteration:  900\n",
      "Previous theta :  [-0.0165101  -0.08464696  0.11411822 -0.01805931  0.0925819  -0.18243212\n",
      "  0.32992768 -0.05860574 -0.32600376  0.22880461 -0.21431516 -0.21037575\n",
      "  0.09102757 -0.31224125]\n",
      "New theta_0 : [-0.01651021 -0.08465194  0.11412706 -0.01804508  0.0925798  -0.18244834\n",
      "  0.32991819 -0.05859774 -0.32601317  0.22884684 -0.21435652 -0.21038022\n",
      "  0.09102583 -0.31224722]\n",
      "Training Error:  9.769151302866788\n",
      "====================================================================================================\n",
      "Iteration:  901\n",
      "Previous theta :  [-0.01651021 -0.08465194  0.11412706 -0.01804508  0.0925798  -0.18244834\n",
      "  0.32991819 -0.05859774 -0.32601317  0.22884684 -0.21435652 -0.21038022\n",
      "  0.09102583 -0.31224722]\n",
      "New theta_0 : [-0.01651032 -0.0846569   0.11413585 -0.01803088  0.0925777  -0.18246446\n",
      "  0.32990875 -0.05858978 -0.32602249  0.22888894 -0.2143978  -0.21038466\n",
      "  0.0910241  -0.31225315]\n",
      "Training Error:  9.76914695158246\n",
      "====================================================================================================\n",
      "Iteration:  902\n",
      "Previous theta :  [-0.01651032 -0.0846569   0.11413585 -0.01803088  0.0925777  -0.18246446\n",
      "  0.32990875 -0.05858978 -0.32602249  0.22888894 -0.2143978  -0.21038466\n",
      "  0.0910241  -0.31225315]\n",
      "New theta_0 : [-0.01651043 -0.08466183  0.11414461 -0.01801671  0.09257561 -0.18248048\n",
      "  0.32989936 -0.05858186 -0.32603173  0.22893093 -0.21443899 -0.21038909\n",
      "  0.09102238 -0.31225905]\n",
      "Training Error:  9.76914262586313\n",
      "====================================================================================================\n",
      "Iteration:  903\n",
      "Previous theta :  [-0.01651043 -0.08466183  0.11414461 -0.01801671  0.09257561 -0.18248048\n",
      "  0.32989936 -0.05858186 -0.32603173  0.22893093 -0.21443899 -0.21038909\n",
      "  0.09102238 -0.31225905]\n",
      "New theta_0 : [-0.01651054 -0.08466674  0.11415332 -0.01800256  0.09257353 -0.18249639\n",
      "  0.32989003 -0.05857399 -0.32604089  0.22897281 -0.2144801  -0.21039349\n",
      "  0.09102067 -0.31226492]\n",
      "Training Error:  9.769138325519474\n",
      "====================================================================================================\n",
      "Iteration:  904\n",
      "Previous theta :  [-0.01651054 -0.08466674  0.11415332 -0.01800256  0.09257353 -0.18249639\n",
      "  0.32989003 -0.05857399 -0.32604089  0.22897281 -0.2144801  -0.21039349\n",
      "  0.09102067 -0.31226492]\n",
      "New theta_0 : [-0.01651065 -0.08467163  0.11416199 -0.01798843  0.09257145 -0.1825122\n",
      "  0.32988074 -0.05856615 -0.32604996  0.22901456 -0.21452112 -0.21039786\n",
      "  0.09101897 -0.31227075]\n",
      "Training Error:  9.76913405036403\n",
      "====================================================================================================\n",
      "Iteration:  905\n",
      "Previous theta :  [-0.01651065 -0.08467163  0.11416199 -0.01798843  0.09257145 -0.1825122\n",
      "  0.32988074 -0.05856615 -0.32604996  0.22901456 -0.21452112 -0.21039786\n",
      "  0.09101897 -0.31227075]\n",
      "New theta_0 : [-0.01651076 -0.08467649  0.11417063 -0.01797433  0.09256937 -0.18252791\n",
      "  0.32987151 -0.05855834 -0.32605896  0.2290562  -0.21456207 -0.21040222\n",
      "  0.09101729 -0.31227655]\n",
      "Training Error:  9.76912980021118\n",
      "====================================================================================================\n",
      "Iteration:  906\n",
      "Previous theta :  [-0.01651076 -0.08467649  0.11417063 -0.01797433  0.09256937 -0.18252791\n",
      "  0.32987151 -0.05855834 -0.32605896  0.2290562  -0.21456207 -0.21040222\n",
      "  0.09101729 -0.31227655]\n",
      "New theta_0 : [-0.01651087 -0.08468132  0.11417922 -0.01796026  0.0925673  -0.18254352\n",
      "  0.32986233 -0.05855058 -0.32606788  0.22909773 -0.21460293 -0.21040655\n",
      "  0.09101562 -0.31228231]\n",
      "Training Error:  9.769125574877126\n",
      "====================================================================================================\n",
      "Iteration:  907\n",
      "Previous theta :  [-0.01651087 -0.08468132  0.11417922 -0.01796026  0.0925673  -0.18254352\n",
      "  0.32986233 -0.05855058 -0.32606788  0.22909773 -0.21460293 -0.21040655\n",
      "  0.09101562 -0.31228231]\n",
      "New theta_0 : [-0.01651099 -0.08468614  0.11418777 -0.01794621  0.09256523 -0.18255902\n",
      "  0.3298532  -0.05854286 -0.32607673  0.22913914 -0.21464371 -0.21041085\n",
      "  0.09101396 -0.31228804]\n",
      "Training Error:  9.769121374179868\n",
      "====================================================================================================\n",
      "Iteration:  908\n",
      "Previous theta :  [-0.01651099 -0.08468614  0.11418777 -0.01794621  0.09256523 -0.18255902\n",
      "  0.3298532  -0.05854286 -0.32607673  0.22913914 -0.21464371 -0.21041085\n",
      "  0.09101396 -0.31228804]\n",
      "New theta_0 : [-0.0165111  -0.08469093  0.11419629 -0.01793219  0.09256317 -0.18257442\n",
      "  0.32984412 -0.05853517 -0.32608549  0.22918043 -0.21468441 -0.21041514\n",
      "  0.09101231 -0.31229374]\n",
      "Training Error:  9.769117197939188\n",
      "====================================================================================================\n",
      "Iteration:  909\n",
      "Previous theta :  [-0.0165111  -0.08469093  0.11419629 -0.01793219  0.09256317 -0.18257442\n",
      "  0.32984412 -0.05853517 -0.32608549  0.22918043 -0.21468441 -0.21041514\n",
      "  0.09101231 -0.31229374]\n",
      "New theta_0 : [-0.01651122 -0.08469569  0.11420476 -0.01791819  0.09256111 -0.18258973\n",
      "  0.32983509 -0.05852752 -0.32609418  0.22922161 -0.21472502 -0.2104194\n",
      "  0.09101067 -0.3122994 ]\n",
      "Training Error:  9.76911304597661\n",
      "====================================================================================================\n",
      "Iteration:  910\n",
      "Previous theta :  [-0.01651122 -0.08469569  0.11420476 -0.01791819  0.09256111 -0.18258973\n",
      "  0.32983509 -0.05852752 -0.32609418  0.22922161 -0.21472502 -0.2104194\n",
      "  0.09101067 -0.3122994 ]\n",
      "New theta_0 : [-0.01651134 -0.08470044  0.1142132  -0.01790422  0.09255906 -0.18260493\n",
      "  0.32982611 -0.05851991 -0.32610279  0.22926267 -0.21476556 -0.21042365\n",
      "  0.09100904 -0.31230504]\n",
      "Training Error:  9.769108918115403\n",
      "====================================================================================================\n",
      "Iteration:  911\n",
      "Previous theta :  [-0.01651134 -0.08470044  0.1142132  -0.01790422  0.09255906 -0.18260493\n",
      "  0.32982611 -0.05851991 -0.32610279  0.22926267 -0.21476556 -0.21042365\n",
      "  0.09100904 -0.31230504]\n",
      "New theta_0 : [-0.01651145 -0.08470515  0.1142216  -0.01789027  0.09255701 -0.18262004\n",
      "  0.32981718 -0.05851233 -0.32611132  0.22930363 -0.21480601 -0.21042786\n",
      "  0.09100742 -0.31231064]\n",
      "Training Error:  9.769104814180546\n",
      "====================================================================================================\n",
      "Iteration:  912\n",
      "Previous theta :  [-0.01651145 -0.08470515  0.1142216  -0.01789027  0.09255701 -0.18262004\n",
      "  0.32981718 -0.05851233 -0.32611132  0.22930363 -0.21480601 -0.21042786\n",
      "  0.09100742 -0.31231064]\n",
      "New theta_0 : [-0.01651157 -0.08470985  0.11422996 -0.01787635  0.09255496 -0.18263505\n",
      "  0.3298083  -0.0585048  -0.32611978  0.22934447 -0.21484638 -0.21043206\n",
      "  0.09100582 -0.3123162 ]\n",
      "Training Error:  9.769100733998709\n",
      "====================================================================================================\n",
      "Iteration:  913\n",
      "Previous theta :  [-0.01651157 -0.08470985  0.11422996 -0.01787635  0.09255496 -0.18263505\n",
      "  0.3298083  -0.0585048  -0.32611978  0.22934447 -0.21484638 -0.21043206\n",
      "  0.09100582 -0.3123162 ]\n",
      "New theta_0 : [-0.01651169 -0.08471453  0.11423828 -0.01786246  0.09255292 -0.18264996\n",
      "  0.32979947 -0.05849729 -0.32612817  0.22938519 -0.21488667 -0.21043624\n",
      "  0.09100422 -0.31232174]\n",
      "Training Error:  9.769096677398231\n",
      "====================================================================================================\n",
      "Iteration:  914\n",
      "Previous theta :  [-0.01651169 -0.08471453  0.11423828 -0.01786246  0.09255292 -0.18264996\n",
      "  0.32979947 -0.05849729 -0.32612817  0.22938519 -0.21488667 -0.21043624\n",
      "  0.09100422 -0.31232174]\n",
      "New theta_0 : [-0.01651181 -0.08471918  0.11424656 -0.01784859  0.09255088 -0.18266477\n",
      "  0.32979069 -0.05848983 -0.32613648  0.2294258  -0.21492688 -0.21044039\n",
      "  0.09100264 -0.31232724]\n",
      "Training Error:  9.769092644209106\n",
      "====================================================================================================\n",
      "Iteration:  915\n",
      "Previous theta :  [-0.01651181 -0.08471918  0.11424656 -0.01784859  0.09255088 -0.18266477\n",
      "  0.32979069 -0.05848983 -0.32613648  0.2294258  -0.21492688 -0.21044039\n",
      "  0.09100264 -0.31232724]\n",
      "New theta_0 : [-0.01651194 -0.08472381  0.11425481 -0.01783475  0.09254885 -0.18267949\n",
      "  0.32978196 -0.0584824  -0.32614472  0.2294663  -0.214967   -0.21044452\n",
      "  0.09100107 -0.31233272]\n",
      "Training Error:  9.769088634262955\n",
      "====================================================================================================\n",
      "Iteration:  916\n",
      "Previous theta :  [-0.01651194 -0.08472381  0.11425481 -0.01783475  0.09254885 -0.18267949\n",
      "  0.32978196 -0.0584824  -0.32614472  0.2294663  -0.214967   -0.21044452\n",
      "  0.09100107 -0.31233272]\n",
      "New theta_0 : [-0.01651206 -0.08472841  0.11426302 -0.01782093  0.09254682 -0.18269412\n",
      "  0.32977327 -0.05847501 -0.32615288  0.22950669 -0.21500705 -0.21044863\n",
      "  0.0909995  -0.31233816]\n",
      "Training Error:  9.769084647393015\n",
      "====================================================================================================\n",
      "Iteration:  917\n",
      "Previous theta :  [-0.01651206 -0.08472841  0.11426302 -0.01782093  0.09254682 -0.18269412\n",
      "  0.32977327 -0.05847501 -0.32615288  0.22950669 -0.21500705 -0.21044863\n",
      "  0.0909995  -0.31233816]\n",
      "New theta_0 : [-0.01651218 -0.084733    0.11427119 -0.01780714  0.0925448  -0.18270865\n",
      "  0.32976463 -0.05846766 -0.32616097  0.22954697 -0.21504701 -0.21045272\n",
      "  0.09099795 -0.31234357]\n",
      "Training Error:  9.769080683434114\n",
      "====================================================================================================\n",
      "Iteration:  918\n",
      "Previous theta :  [-0.01651218 -0.084733    0.11427119 -0.01780714  0.0925448  -0.18270865\n",
      "  0.32976463 -0.05846766 -0.32616097  0.22954697 -0.21504701 -0.21045272\n",
      "  0.09099795 -0.31234357]\n",
      "New theta_0 : [-0.0165123  -0.08473756  0.11427932 -0.01779337  0.09254278 -0.18272308\n",
      "  0.32975604 -0.05846034 -0.326169    0.22958714 -0.21508689 -0.21045679\n",
      "  0.09099641 -0.31234895]\n",
      "Training Error:  9.76907674222265\n",
      "====================================================================================================\n",
      "Iteration:  919\n",
      "Previous theta :  [-0.0165123  -0.08473756  0.11427932 -0.01779337  0.09254278 -0.18272308\n",
      "  0.32975604 -0.05846034 -0.326169    0.22958714 -0.21508689 -0.21045679\n",
      "  0.09099641 -0.31234895]\n",
      "New theta_0 : [-0.01651243 -0.0847421   0.11428742 -0.01777963  0.09254077 -0.18273742\n",
      "  0.3297475  -0.05845305 -0.32617695  0.22962719 -0.2151267  -0.21046084\n",
      "  0.09099488 -0.3123543 ]\n",
      "Training Error:  9.76907282359658\n",
      "====================================================================================================\n",
      "Iteration:  920\n",
      "Previous theta :  [-0.01651243 -0.0847421   0.11428742 -0.01777963  0.09254077 -0.18273742\n",
      "  0.3297475  -0.05845305 -0.32617695  0.22962719 -0.2151267  -0.21046084\n",
      "  0.09099488 -0.3123543 ]\n",
      "New theta_0 : [-0.01651255 -0.08474661  0.11429548 -0.01776592  0.09253876 -0.18275167\n",
      "  0.329739   -0.05844581 -0.32618483  0.22966714 -0.21516642 -0.21046487\n",
      "  0.09099336 -0.31235962]\n",
      "Training Error:  9.769068927395393\n",
      "====================================================================================================\n",
      "Iteration:  921\n",
      "Previous theta :  [-0.01651255 -0.08474661  0.11429548 -0.01776592  0.09253876 -0.18275167\n",
      "  0.329739   -0.05844581 -0.32618483  0.22966714 -0.21516642 -0.21046487\n",
      "  0.09099336 -0.31235962]\n",
      "New theta_0 : [-0.01651268 -0.08475111  0.1143035  -0.01775223  0.09253676 -0.18276583\n",
      "  0.32973055 -0.05843859 -0.32619263  0.22970697 -0.21520606 -0.21046887\n",
      "  0.09099185 -0.31236491]\n",
      "Training Error:  9.769065053460098\n",
      "====================================================================================================\n",
      "Iteration:  922\n",
      "Previous theta :  [-0.01651268 -0.08475111  0.1143035  -0.01775223  0.09253676 -0.18276583\n",
      "  0.32973055 -0.05843859 -0.32619263  0.22970697 -0.21520606 -0.21046887\n",
      "  0.09099185 -0.31236491]\n",
      "New theta_0 : [-0.01651281 -0.08475559  0.11431149 -0.01773857  0.09253475 -0.1827799\n",
      "  0.32972215 -0.05843142 -0.32620038  0.2297467  -0.21524562 -0.21047286\n",
      "  0.09099035 -0.31237016]\n",
      "Training Error:  9.7690612016332\n",
      "====================================================================================================\n",
      "Iteration:  923\n",
      "Previous theta :  [-0.01651281 -0.08475559  0.11431149 -0.01773857  0.09253475 -0.1827799\n",
      "  0.32972215 -0.05843142 -0.32620038  0.2297467  -0.21524562 -0.21047286\n",
      "  0.09099035 -0.31237016]\n",
      "New theta_0 : [-0.01651294 -0.08476004  0.11431944 -0.01772494  0.09253276 -0.18279387\n",
      "  0.32971379 -0.05842427 -0.32620805  0.22978632 -0.21528509 -0.21047682\n",
      "  0.09098886 -0.31237539]\n",
      "Training Error:  9.769057371758691\n",
      "====================================================================================================\n",
      "Iteration:  924\n",
      "Previous theta :  [-0.01651294 -0.08476004  0.11431944 -0.01772494  0.09253276 -0.18279387\n",
      "  0.32971379 -0.05842427 -0.32620805  0.22978632 -0.21528509 -0.21047682\n",
      "  0.09098886 -0.31237539]\n",
      "New theta_0 : [-0.01651306 -0.08476447  0.11432736 -0.01771133  0.09253077 -0.18280776\n",
      "  0.32970548 -0.05841716 -0.32621565  0.22982583 -0.21532449 -0.21048076\n",
      "  0.09098738 -0.31238059]\n",
      "Training Error:  9.769053563682025\n",
      "====================================================================================================\n",
      "Iteration:  925\n",
      "Previous theta :  [-0.01651306 -0.08476447  0.11432736 -0.01771133  0.09253077 -0.18280776\n",
      "  0.32970548 -0.05841716 -0.32621565  0.22982583 -0.21532449 -0.21048076\n",
      "  0.09098738 -0.31238059]\n",
      "New theta_0 : [-0.01651319 -0.08476888  0.11433524 -0.01769774  0.09252878 -0.18282155\n",
      "  0.32969721 -0.05841009 -0.32622319  0.22986523 -0.21536381 -0.21048469\n",
      "  0.09098591 -0.31238576]\n",
      "Training Error:  9.769049777250093\n",
      "====================================================================================================\n",
      "Iteration:  926\n",
      "Previous theta :  [-0.01651319 -0.08476888  0.11433524 -0.01769774  0.09252878 -0.18282155\n",
      "  0.32969721 -0.05841009 -0.32622319  0.22986523 -0.21536381 -0.21048469\n",
      "  0.09098591 -0.31238576]\n",
      "New theta_0 : [-0.01651332 -0.08477327  0.11434308 -0.01768418  0.0925268  -0.18283526\n",
      "  0.32968899 -0.05840305 -0.32623065  0.22990452 -0.21540304 -0.21048859\n",
      "  0.09098445 -0.3123909 ]\n",
      "Training Error:  9.76904601231123\n",
      "====================================================================================================\n",
      "Iteration:  927\n",
      "Previous theta :  [-0.01651332 -0.08477327  0.11434308 -0.01768418  0.0925268  -0.18283526\n",
      "  0.32968899 -0.05840305 -0.32623065  0.22990452 -0.21540304 -0.21048859\n",
      "  0.09098445 -0.3123909 ]\n",
      "New theta_0 : [-0.01651346 -0.08477764  0.11435089 -0.01767065  0.09252482 -0.18284888\n",
      "  0.32968081 -0.05839605 -0.32623806  0.2299437  -0.2154422  -0.21049247\n",
      "  0.090983   -0.31239601]\n",
      "Training Error:  9.769042268715175\n",
      "====================================================================================================\n",
      "Iteration:  928\n",
      "Previous theta :  [-0.01651346 -0.08477764  0.11435089 -0.01767065  0.09252482 -0.18284888\n",
      "  0.32968081 -0.05839605 -0.32623806  0.2299437  -0.2154422  -0.21049247\n",
      "  0.090983   -0.31239601]\n",
      "New theta_0 : [-0.01651359 -0.08478199  0.11435867 -0.01765715  0.09252284 -0.18286241\n",
      "  0.32967268 -0.05838907 -0.32624539  0.22998278 -0.21548128 -0.21049634\n",
      "  0.09098156 -0.31240109]\n",
      "Training Error:  9.769038546313068\n",
      "====================================================================================================\n",
      "Iteration:  929\n",
      "Previous theta :  [-0.01651359 -0.08478199  0.11435867 -0.01765715  0.09252284 -0.18286241\n",
      "  0.32967268 -0.05838907 -0.32624539  0.22998278 -0.21548128 -0.21049634\n",
      "  0.09098156 -0.31240109]\n",
      "New theta_0 : [-0.01651372 -0.08478632  0.11436641 -0.01764367  0.09252087 -0.18287585\n",
      "  0.32966459 -0.05838214 -0.32625266  0.23002175 -0.21552027 -0.21050018\n",
      "  0.09098013 -0.31240615]\n",
      "Training Error:  9.76903484495742\n",
      "====================================================================================================\n",
      "Iteration:  930\n",
      "Previous theta :  [-0.01651372 -0.08478632  0.11436641 -0.01764367  0.09252087 -0.18287585\n",
      "  0.32966459 -0.05838214 -0.32625266  0.23002175 -0.21552027 -0.21050018\n",
      "  0.09098013 -0.31240615]\n",
      "New theta_0 : [-0.01651385 -0.08479062  0.11437412 -0.01763021  0.09251891 -0.18288921\n",
      "  0.32965654 -0.05837523 -0.32625987  0.23006061 -0.21555919 -0.210504\n",
      "  0.09097871 -0.31241117]\n",
      "Training Error:  9.769031164502113\n",
      "====================================================================================================\n",
      "Iteration:  931\n",
      "Previous theta :  [-0.01651385 -0.08479062  0.11437412 -0.01763021  0.09251891 -0.18288921\n",
      "  0.32965654 -0.05837523 -0.32625987  0.23006061 -0.21555919 -0.210504\n",
      "  0.09097871 -0.31241117]\n",
      "New theta_0 : [-0.01651399 -0.08479491  0.11438179 -0.01761679  0.09251694 -0.18290248\n",
      "  0.32964854 -0.05836836 -0.32626701  0.23009937 -0.21559803 -0.2105078\n",
      "  0.0909773  -0.31241617]\n",
      "Training Error:  9.769027504802375\n",
      "====================================================================================================\n",
      "Iteration:  932\n",
      "Previous theta :  [-0.01651399 -0.08479491  0.11438179 -0.01761679  0.09251694 -0.18290248\n",
      "  0.32964854 -0.05836836 -0.32626701  0.23009937 -0.21559803 -0.2105078\n",
      "  0.0909773  -0.31241617]\n",
      "New theta_0 : [-0.01651412 -0.08479918  0.11438943 -0.01760338  0.09251499 -0.18291566\n",
      "  0.32964058 -0.05836152 -0.32627408  0.23013802 -0.21563678 -0.21051159\n",
      "  0.0909759  -0.31242113]\n",
      "Training Error:  9.76902386571476\n",
      "====================================================================================================\n",
      "Iteration:  933\n",
      "Previous theta :  [-0.01651412 -0.08479918  0.11438943 -0.01760338  0.09251499 -0.18291566\n",
      "  0.32964058 -0.05836152 -0.32627408  0.23013802 -0.21563678 -0.21051159\n",
      "  0.0909759  -0.31242113]\n",
      "New theta_0 : [-0.01651426 -0.08480342  0.11439703 -0.01759001  0.09251303 -0.18292876\n",
      "  0.32963267 -0.05835472 -0.3262811   0.23017656 -0.21567546 -0.21051535\n",
      "  0.09097451 -0.31242607]\n",
      "Training Error:  9.769020247097144\n",
      "====================================================================================================\n",
      "Iteration:  934\n",
      "Previous theta :  [-0.01651426 -0.08480342  0.11439703 -0.01759001  0.09251303 -0.18292876\n",
      "  0.32963267 -0.05835472 -0.3262811   0.23017656 -0.21567546 -0.21051535\n",
      "  0.09097451 -0.31242607]\n",
      "New theta_0 : [-0.01651439 -0.08480765  0.11440461 -0.01757666  0.09251109 -0.18294178\n",
      "  0.32962479 -0.05834795 -0.32628805  0.230215   -0.21571406 -0.2105191\n",
      "  0.09097313 -0.31243099]\n",
      "Training Error:  9.7690166488087\n",
      "====================================================================================================\n",
      "Iteration:  935\n",
      "Previous theta :  [-0.01651439 -0.08480765  0.11440461 -0.01757666  0.09251109 -0.18294178\n",
      "  0.32962479 -0.05834795 -0.32628805  0.230215   -0.21571406 -0.2105191\n",
      "  0.09097313 -0.31243099]\n",
      "New theta_0 : [-0.01651453 -0.08481186  0.11441214 -0.01756334  0.09250914 -0.18295471\n",
      "  0.32961696 -0.05834121 -0.32629494  0.23025334 -0.21575257 -0.21052282\n",
      "  0.09097176 -0.31243587]\n",
      "Training Error:  9.769013070709885\n",
      "====================================================================================================\n",
      "Iteration:  936\n",
      "Previous theta :  [-0.01651453 -0.08481186  0.11441214 -0.01756334  0.09250914 -0.18295471\n",
      "  0.32961696 -0.05834121 -0.32629494  0.23025334 -0.21575257 -0.21052282\n",
      "  0.09097176 -0.31243587]\n",
      "New theta_0 : [-0.01651467 -0.08481604  0.11441965 -0.01755004  0.0925072  -0.18296756\n",
      "  0.32960917 -0.0583345  -0.32630176  0.23029157 -0.21579101 -0.21052653\n",
      "  0.09097039 -0.31244073]\n",
      "Training Error:  9.769009512662434\n",
      "====================================================================================================\n",
      "Iteration:  937\n",
      "Previous theta :  [-0.01651467 -0.08481604  0.11441965 -0.01755004  0.0925072  -0.18296756\n",
      "  0.32960917 -0.0583345  -0.32630176  0.23029157 -0.21579101 -0.21052653\n",
      "  0.09097039 -0.31244073]\n",
      "New theta_0 : [-0.0165148  -0.08482021  0.11442712 -0.01753677  0.09250527 -0.18298033\n",
      "  0.32960143 -0.05832783 -0.32630853  0.2303297  -0.21582937 -0.21053022\n",
      "  0.09096904 -0.31244556]\n",
      "Training Error:  9.769005974529325\n",
      "====================================================================================================\n",
      "Iteration:  938\n",
      "Previous theta :  [-0.0165148  -0.08482021  0.11442712 -0.01753677  0.09250527 -0.18298033\n",
      "  0.32960143 -0.05832783 -0.32630853  0.2303297  -0.21582937 -0.21053022\n",
      "  0.09096904 -0.31244556]\n",
      "New theta_0 : [-0.01651494 -0.08482436  0.11443456 -0.01752352  0.09250334 -0.18299301\n",
      "  0.32959372 -0.05832118 -0.32631523  0.23036772 -0.21586765 -0.21053389\n",
      "  0.09096769 -0.31245036]\n",
      "Training Error:  9.76900245617479\n",
      "====================================================================================================\n",
      "Iteration:  939\n",
      "Previous theta :  [-0.01651494 -0.08482436  0.11443456 -0.01752352  0.09250334 -0.18299301\n",
      "  0.32959372 -0.05832118 -0.32631523  0.23036772 -0.21586765 -0.21053389\n",
      "  0.09096769 -0.31245036]\n",
      "New theta_0 : [-0.01651508 -0.08482849  0.11444196 -0.01751031  0.09250141 -0.18300562\n",
      "  0.32958606 -0.05831457 -0.32632188  0.23040564 -0.21590585 -0.21053754\n",
      "  0.09096636 -0.31245514]\n",
      "Training Error:  9.768998957464277\n",
      "====================================================================================================\n",
      "Iteration:  940\n",
      "Previous theta :  [-0.01651508 -0.08482849  0.11444196 -0.01751031  0.09250141 -0.18300562\n",
      "  0.32958606 -0.05831457 -0.32632188  0.23040564 -0.21590585 -0.21053754\n",
      "  0.09096636 -0.31245514]\n",
      "New theta_0 : [-0.01651522 -0.08483259  0.11444934 -0.01749711  0.09249949 -0.18301814\n",
      "  0.32957843 -0.05830799 -0.32632846  0.23044346 -0.21594397 -0.21054117\n",
      "  0.09096503 -0.31245989]\n",
      "Training Error:  9.768995478264452\n",
      "====================================================================================================\n",
      "Iteration:  941\n",
      "Previous theta :  [-0.01651522 -0.08483259  0.11444934 -0.01749711  0.09249949 -0.18301814\n",
      "  0.32957843 -0.05830799 -0.32632846  0.23044346 -0.21594397 -0.21054117\n",
      "  0.09096503 -0.31245989]\n",
      "New theta_0 : [-0.01651536 -0.08483668  0.11445668 -0.01748395  0.09249757 -0.18303058\n",
      "  0.32957085 -0.05830145 -0.32633498  0.23048117 -0.21598202 -0.21054478\n",
      "  0.09096371 -0.31246461]\n",
      "Training Error:  9.768992018443178\n",
      "====================================================================================================\n",
      "Iteration:  942\n",
      "Previous theta :  [-0.01651536 -0.08483668  0.11445668 -0.01748395  0.09249757 -0.18303058\n",
      "  0.32957085 -0.05830145 -0.32633498  0.23048117 -0.21598202 -0.21054478\n",
      "  0.09096371 -0.31246461]\n",
      "New theta_0 : [-0.0165155  -0.08484076  0.11446399 -0.01747081  0.09249565 -0.18304294\n",
      "  0.32956331 -0.05829493 -0.32634145  0.23051878 -0.21601998 -0.21054838\n",
      "  0.0909624  -0.3124693 ]\n",
      "Training Error:  9.768988577869504\n",
      "====================================================================================================\n",
      "Iteration:  943\n",
      "Previous theta :  [-0.0165155  -0.08484076  0.11446399 -0.01747081  0.09249565 -0.18304294\n",
      "  0.32956331 -0.05829493 -0.32634145  0.23051878 -0.21601998 -0.21054838\n",
      "  0.0909624  -0.3124693 ]\n",
      "New theta_0 : [-0.01651565 -0.08484481  0.11447127 -0.01745769  0.09249374 -0.18305522\n",
      "  0.32955581 -0.05828844 -0.32634786  0.23055629 -0.21605787 -0.21055195\n",
      "  0.0909611  -0.31247397]\n",
      "Training Error:  9.768985156413645\n",
      "====================================================================================================\n",
      "Iteration:  944\n",
      "Previous theta :  [-0.01651565 -0.08484481  0.11447127 -0.01745769  0.09249374 -0.18305522\n",
      "  0.32955581 -0.05828844 -0.32634786  0.23055629 -0.21605787 -0.21055195\n",
      "  0.0909611  -0.31247397]\n",
      "New theta_0 : [-0.01651579 -0.08484884  0.11447851 -0.01744461  0.09249184 -0.18306743\n",
      "  0.32954835 -0.05828199 -0.3263542   0.2305937  -0.21609567 -0.21055551\n",
      "  0.09095981 -0.31247862]\n",
      "Training Error:  9.768981753946978\n",
      "====================================================================================================\n",
      "Iteration:  945\n",
      "Previous theta :  [-0.01651579 -0.08484884  0.11447851 -0.01744461  0.09249184 -0.18306743\n",
      "  0.32954835 -0.05828199 -0.3263542   0.2305937  -0.21609567 -0.21055551\n",
      "  0.09095981 -0.31247862]\n",
      "New theta_0 : [-0.01651593 -0.08485285  0.11448573 -0.01743154  0.09248994 -0.18307955\n",
      "  0.32954093 -0.05827557 -0.32636049  0.230631   -0.2161334  -0.21055905\n",
      "  0.09095853 -0.31248323]\n",
      "Training Error:  9.768978370342026\n",
      "====================================================================================================\n",
      "Iteration:  946\n",
      "Previous theta :  [-0.01651593 -0.08485285  0.11448573 -0.01743154  0.09248994 -0.18307955\n",
      "  0.32954093 -0.05827557 -0.32636049  0.230631   -0.2161334  -0.21055905\n",
      "  0.09095853 -0.31248323]\n",
      "New theta_0 : [-0.01651608 -0.08485685  0.11449291 -0.01741851  0.09248804 -0.1830916\n",
      "  0.32953354 -0.05826917 -0.32636673  0.23066821 -0.21617105 -0.21056257\n",
      "  0.09095725 -0.31248783]\n",
      "Training Error:  9.76897500547244\n",
      "====================================================================================================\n",
      "Iteration:  947\n",
      "Previous theta :  [-0.01651608 -0.08485685  0.11449291 -0.01741851  0.09248804 -0.1830916\n",
      "  0.32953354 -0.05826917 -0.32636673  0.23066821 -0.21617105 -0.21056257\n",
      "  0.09095725 -0.31248783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01651622 -0.08486083  0.11450006 -0.0174055   0.09248615 -0.18310357\n",
      "  0.3295262  -0.05826281 -0.32637291  0.23070531 -0.21620862 -0.21056607\n",
      "  0.09095599 -0.31249239]\n",
      "Training Error:  9.768971659212985\n",
      "====================================================================================================\n",
      "Iteration:  948\n",
      "Previous theta :  [-0.01651622 -0.08486083  0.11450006 -0.0174055   0.09248615 -0.18310357\n",
      "  0.3295262  -0.05826281 -0.32637291  0.23070531 -0.21620862 -0.21056607\n",
      "  0.09095599 -0.31249239]\n",
      "New theta_0 : [-0.01651636 -0.08486479  0.11450718 -0.01739252  0.09248426 -0.18311547\n",
      "  0.3295189  -0.05825648 -0.32637903  0.23074231 -0.21624612 -0.21056956\n",
      "  0.09095473 -0.31249693]\n",
      "Training Error:  9.768968331439542\n",
      "====================================================================================================\n",
      "Iteration:  949\n",
      "Previous theta :  [-0.01651636 -0.08486479  0.11450718 -0.01739252  0.09248426 -0.18311547\n",
      "  0.3295189  -0.05825648 -0.32637903  0.23074231 -0.21624612 -0.21056956\n",
      "  0.09095473 -0.31249693]\n",
      "New theta_0 : [-0.01651651 -0.08486873  0.11451427 -0.01737956  0.09248237 -0.18312728\n",
      "  0.32951163 -0.05825018 -0.32638509  0.23077922 -0.21628353 -0.21057303\n",
      "  0.09095348 -0.31250145]\n",
      "Training Error:  9.768965022029073\n",
      "====================================================================================================\n",
      "Iteration:  950\n",
      "Previous theta :  [-0.01651651 -0.08486873  0.11451427 -0.01737956  0.09248237 -0.18312728\n",
      "  0.32951163 -0.05825018 -0.32638509  0.23077922 -0.21628353 -0.21057303\n",
      "  0.09095348 -0.31250145]\n",
      "New theta_0 : [-0.01651666 -0.08487265  0.11452133 -0.01736663  0.09248049 -0.18313902\n",
      "  0.32950441 -0.05824391 -0.3263911   0.23081602 -0.21632087 -0.21057648\n",
      "  0.09095224 -0.31250594]\n",
      "Training Error:  9.768961730859631\n",
      "====================================================================================================\n",
      "Iteration:  951\n",
      "Previous theta :  [-0.01651666 -0.08487265  0.11452133 -0.01736663  0.09248049 -0.18313902\n",
      "  0.32950441 -0.05824391 -0.3263911   0.23081602 -0.21632087 -0.21057648\n",
      "  0.09095224 -0.31250594]\n",
      "New theta_0 : [-0.0165168  -0.08487656  0.11452836 -0.01735372  0.09247862 -0.18315069\n",
      "  0.32949722 -0.05823767 -0.32639706  0.23085273 -0.21635813 -0.21057991\n",
      "  0.09095101 -0.3125104 ]\n",
      "Training Error:  9.768958457810331\n",
      "====================================================================================================\n",
      "Iteration:  952\n",
      "Previous theta :  [-0.0165168  -0.08487656  0.11452836 -0.01735372  0.09247862 -0.18315069\n",
      "  0.32949722 -0.05823767 -0.32639706  0.23085273 -0.21635813 -0.21057991\n",
      "  0.09095101 -0.3125104 ]\n",
      "New theta_0 : [-0.01651695 -0.08488044  0.11453536 -0.01734085  0.09247674 -0.18316228\n",
      "  0.32949007 -0.05823145 -0.32640296  0.23088933 -0.21639531 -0.21058332\n",
      "  0.09094979 -0.31251484]\n",
      "Training Error:  9.768955202761347\n",
      "====================================================================================================\n",
      "Iteration:  953\n",
      "Previous theta :  [-0.01651695 -0.08488044  0.11453536 -0.01734085  0.09247674 -0.18316228\n",
      "  0.32949007 -0.05823145 -0.32640296  0.23088933 -0.21639531 -0.21058332\n",
      "  0.09094979 -0.31251484]\n",
      "New theta_0 : [-0.0165171  -0.08488431  0.11454233 -0.01732799  0.09247488 -0.1831738\n",
      "  0.32948295 -0.05822527 -0.32640881  0.23092584 -0.21643242 -0.21058672\n",
      "  0.09094857 -0.31251926]\n",
      "Training Error:  9.768951965593896\n",
      "====================================================================================================\n",
      "Iteration:  954\n",
      "Previous theta :  [-0.0165171  -0.08488431  0.11454233 -0.01732799  0.09247488 -0.1831738\n",
      "  0.32948295 -0.05822527 -0.32640881  0.23092584 -0.21643242 -0.21058672\n",
      "  0.09094857 -0.31251926]\n",
      "New theta_0 : [-0.01651724 -0.08488816  0.11454927 -0.01731517  0.09247301 -0.18318524\n",
      "  0.32947588 -0.05821912 -0.3264146   0.23096224 -0.21646944 -0.2105901\n",
      "  0.09094737 -0.31252365]\n",
      "Training Error:  9.768948746190224\n",
      "====================================================================================================\n",
      "Iteration:  955\n",
      "Previous theta :  [-0.01651724 -0.08488816  0.11454927 -0.01731517  0.09247301 -0.18318524\n",
      "  0.32947588 -0.05821912 -0.3264146   0.23096224 -0.21646944 -0.2105901\n",
      "  0.09094737 -0.31252365]\n",
      "New theta_0 : [-0.01651739 -0.084892    0.11455618 -0.01730237  0.09247115 -0.18319662\n",
      "  0.32946884 -0.058213   -0.32642034  0.23099855 -0.21650639 -0.21059347\n",
      "  0.09094617 -0.31252802]\n",
      "Training Error:  9.768945544433604\n",
      "====================================================================================================\n",
      "Iteration:  956\n",
      "Previous theta :  [-0.01651739 -0.084892    0.11455618 -0.01730237  0.09247115 -0.18319662\n",
      "  0.32946884 -0.058213   -0.32642034  0.23099855 -0.21650639 -0.21059347\n",
      "  0.09094617 -0.31252802]\n",
      "New theta_0 : [-0.01651754 -0.08489581  0.11456306 -0.01728959  0.0924693  -0.18320791\n",
      "  0.32946184 -0.0582069  -0.32642603  0.23103477 -0.21654326 -0.21059681\n",
      "  0.09094498 -0.31253236]\n",
      "Training Error:  9.76894236020832\n",
      "====================================================================================================\n",
      "Iteration:  957\n",
      "Previous theta :  [-0.01651754 -0.08489581  0.11456306 -0.01728959  0.0924693  -0.18320791\n",
      "  0.32946184 -0.0582069  -0.32642603  0.23103477 -0.21654326 -0.21059681\n",
      "  0.09094498 -0.31253236]\n",
      "New theta_0 : [-0.01651769 -0.08489961  0.11456991 -0.01727685  0.09246745 -0.18321914\n",
      "  0.32945488 -0.05820083 -0.32643167  0.23107088 -0.21658006 -0.21060014\n",
      "  0.09094379 -0.31253668]\n",
      "Training Error:  9.76893919339964\n",
      "====================================================================================================\n",
      "Iteration:  958\n",
      "Previous theta :  [-0.01651769 -0.08489961  0.11456991 -0.01727685  0.09246745 -0.18321914\n",
      "  0.32945488 -0.05820083 -0.32643167  0.23107088 -0.21658006 -0.21060014\n",
      "  0.09094379 -0.31253668]\n",
      "New theta_0 : [-0.01651784 -0.0849034   0.11457674 -0.01726412  0.0924656  -0.18323029\n",
      "  0.32944795 -0.0581948  -0.32643725  0.2311069  -0.21661678 -0.21060345\n",
      "  0.09094262 -0.31254098]\n",
      "Training Error:  9.768936043893838\n",
      "====================================================================================================\n",
      "Iteration:  959\n",
      "Previous theta :  [-0.01651784 -0.0849034   0.11457674 -0.01726412  0.0924656  -0.18323029\n",
      "  0.32944795 -0.0581948  -0.32643725  0.2311069  -0.21661678 -0.21060345\n",
      "  0.09094262 -0.31254098]\n",
      "New theta_0 : [-0.01651799 -0.08490716  0.11458353 -0.01725143  0.09246376 -0.18324138\n",
      "  0.32944106 -0.05818879 -0.32644279  0.23114282 -0.21665342 -0.21060675\n",
      "  0.09094145 -0.31254525]\n",
      "Training Error:  9.768932911578151\n",
      "====================================================================================================\n",
      "Iteration:  960\n",
      "Previous theta :  [-0.01651799 -0.08490716  0.11458353 -0.01725143  0.09246376 -0.18324138\n",
      "  0.32944106 -0.05818879 -0.32644279  0.23114282 -0.21665342 -0.21060675\n",
      "  0.09094145 -0.31254525]\n",
      "New theta_0 : [-0.01651814 -0.08491091  0.11459029 -0.01723876  0.09246192 -0.18325239\n",
      "  0.3294342  -0.05818281 -0.32644827  0.23117864 -0.21668998 -0.21061003\n",
      "  0.09094029 -0.3125495 ]\n",
      "Training Error:  9.768929796340782\n",
      "====================================================================================================\n",
      "Iteration:  961\n",
      "Previous theta :  [-0.01651814 -0.08491091  0.11459029 -0.01723876  0.09246192 -0.18325239\n",
      "  0.3294342  -0.05818281 -0.32644827  0.23117864 -0.21668998 -0.21061003\n",
      "  0.09094029 -0.3125495 ]\n",
      "New theta_0 : [-0.0165183  -0.08491464  0.11459703 -0.01722612  0.09246008 -0.18326333\n",
      "  0.32942738 -0.05817686 -0.3264537   0.23121437 -0.21672647 -0.21061329\n",
      "  0.09093914 -0.31255372]\n",
      "Training Error:  9.768926698070898\n",
      "====================================================================================================\n",
      "Iteration:  962\n",
      "Previous theta :  [-0.0165183  -0.08491464  0.11459703 -0.01722612  0.09246008 -0.18326333\n",
      "  0.32942738 -0.05817686 -0.3264537   0.23121437 -0.21672647 -0.21061329\n",
      "  0.09093914 -0.31255372]\n",
      "New theta_0 : [-0.01651845 -0.08491835  0.11460374 -0.0172135   0.09245825 -0.1832742\n",
      "  0.3294206  -0.05817093 -0.32645908  0.23125    -0.21676288 -0.21061654\n",
      "  0.090938   -0.31255792]\n",
      "Training Error:  9.768923616658594\n",
      "====================================================================================================\n",
      "Iteration:  963\n",
      "Previous theta :  [-0.01651845 -0.08491835  0.11460374 -0.0172135   0.09245825 -0.1832742\n",
      "  0.3294206  -0.05817093 -0.32645908  0.23125    -0.21676288 -0.21061654\n",
      "  0.090938   -0.31255792]\n",
      "New theta_0 : [-0.0165186  -0.08492205  0.11461042 -0.01720091  0.09245643 -0.18328501\n",
      "  0.32941385 -0.05816504 -0.32646441  0.23128553 -0.21679921 -0.21061977\n",
      "  0.09093686 -0.3125621 ]\n",
      "Training Error:  9.768920551994915\n",
      "====================================================================================================\n",
      "Iteration:  964\n",
      "Previous theta :  [-0.0165186  -0.08492205  0.11461042 -0.01720091  0.09245643 -0.18328501\n",
      "  0.32941385 -0.05816504 -0.32646441  0.23128553 -0.21679921 -0.21061977\n",
      "  0.09093686 -0.3125621 ]\n",
      "New theta_0 : [-0.01651875 -0.08492573  0.11461707 -0.01718834  0.09245461 -0.18329574\n",
      "  0.32940714 -0.05815917 -0.3264697   0.23132098 -0.21683547 -0.21062298\n",
      "  0.09093573 -0.31256626]\n",
      "Training Error:  9.768917503971817\n",
      "====================================================================================================\n",
      "Iteration:  965\n",
      "Previous theta :  [-0.01651875 -0.08492573  0.11461707 -0.01718834  0.09245461 -0.18329574\n",
      "  0.32940714 -0.05815917 -0.3264697   0.23132098 -0.21683547 -0.21062298\n",
      "  0.09093573 -0.31256626]\n",
      "New theta_0 : [-0.01651891 -0.0849294   0.11462369 -0.01717581  0.09245279 -0.1833064\n",
      "  0.32940046 -0.05815333 -0.32647493  0.23135632 -0.21687165 -0.21062618\n",
      "  0.09093461 -0.31257039]\n",
      "Training Error:  9.768914472482171\n",
      "====================================================================================================\n",
      "Iteration:  966\n",
      "Previous theta :  [-0.01651891 -0.0849294   0.11462369 -0.01717581  0.09245279 -0.1833064\n",
      "  0.32940046 -0.05815333 -0.32647493  0.23135632 -0.21687165 -0.21062618\n",
      "  0.09093461 -0.31257039]\n",
      "New theta_0 : [-0.01651906 -0.08493304  0.11463028 -0.01716329  0.09245097 -0.183317\n",
      "  0.32939381 -0.05814751 -0.32648011  0.23139157 -0.21690776 -0.21062936\n",
      "  0.0909335  -0.3125745 ]\n",
      "Training Error:  9.768911457419755\n",
      "====================================================================================================\n",
      "Iteration:  967\n",
      "Previous theta :  [-0.01651906 -0.08493304  0.11463028 -0.01716329  0.09245097 -0.183317\n",
      "  0.32939381 -0.05814751 -0.32648011  0.23139157 -0.21690776 -0.21062936\n",
      "  0.0909335  -0.3125745 ]\n",
      "New theta_0 : [-0.01651921 -0.08493667  0.11463685 -0.01715081  0.09244916 -0.18332753\n",
      "  0.3293872  -0.05814173 -0.32648525  0.23142673 -0.21694379 -0.21063252\n",
      "  0.09093239 -0.31257859]\n",
      "Training Error:  9.768908458679235\n",
      "====================================================================================================\n",
      "Iteration:  968\n",
      "Previous theta :  [-0.01651921 -0.08493667  0.11463685 -0.01715081  0.09244916 -0.18332753\n",
      "  0.3293872  -0.05814173 -0.32648525  0.23142673 -0.21694379 -0.21063252\n",
      "  0.09093239 -0.31257859]\n",
      "New theta_0 : [-0.01651937 -0.08494029  0.11464339 -0.01713835  0.09244736 -0.18333799\n",
      "  0.32938063 -0.05813597 -0.32649034  0.23146179 -0.21697974 -0.21063567\n",
      "  0.09093129 -0.31258265]\n",
      "Training Error:  9.768905476156165\n",
      "====================================================================================================\n",
      "Iteration:  969\n",
      "Previous theta :  [-0.01651937 -0.08494029  0.11464339 -0.01713835  0.09244736 -0.18333799\n",
      "  0.32938063 -0.05813597 -0.32649034  0.23146179 -0.21697974 -0.21063567\n",
      "  0.09093129 -0.31258265]\n",
      "New theta_0 : [-0.01651952 -0.08494389  0.1146499  -0.01712591  0.09244556 -0.18334839\n",
      "  0.32937409 -0.05813024 -0.32649538  0.23149676 -0.21701561 -0.2106388\n",
      "  0.0909302  -0.31258669]\n",
      "Training Error:  9.768902509746964\n",
      "====================================================================================================\n",
      "Iteration:  970\n",
      "Previous theta :  [-0.01651952 -0.08494389  0.1146499  -0.01712591  0.09244556 -0.18334839\n",
      "  0.32937409 -0.05813024 -0.32649538  0.23149676 -0.21701561 -0.2106388\n",
      "  0.0909302  -0.31258669]\n",
      "New theta_0 : [-0.01651968 -0.08494747  0.11465639 -0.0171135   0.09244376 -0.18335872\n",
      "  0.32936758 -0.05812453 -0.32650038  0.23153163 -0.21705142 -0.21064192\n",
      "  0.09092912 -0.31259071]\n",
      "Training Error:  9.768899559348926\n",
      "====================================================================================================\n",
      "Iteration:  971\n",
      "Previous theta :  [-0.01651968 -0.08494747  0.11465639 -0.0171135   0.09244376 -0.18335872\n",
      "  0.32936758 -0.05812453 -0.32650038  0.23153163 -0.21705142 -0.21064192\n",
      "  0.09092912 -0.31259071]\n",
      "New theta_0 : [-0.01651984 -0.08495104  0.11466285 -0.01710112  0.09244196 -0.18336899\n",
      "  0.32936111 -0.05811885 -0.32650533  0.23156641 -0.21708714 -0.21064502\n",
      "  0.09092804 -0.31259471]\n",
      "Training Error:  9.768896624860192\n",
      "====================================================================================================\n",
      "Iteration:  972\n",
      "Previous theta :  [-0.01651984 -0.08495104  0.11466285 -0.01710112  0.09244196 -0.18336899\n",
      "  0.32936111 -0.05811885 -0.32650533  0.23156641 -0.21708714 -0.21064502\n",
      "  0.09092804 -0.31259471]\n",
      "New theta_0 : [-0.01651999 -0.08495459  0.11466928 -0.01708876  0.09244017 -0.18337918\n",
      "  0.32935467 -0.0581132  -0.32651023  0.2316011  -0.21712279 -0.21064811\n",
      "  0.09092697 -0.31259869]\n",
      "Training Error:  9.768893706179748\n",
      "====================================================================================================\n",
      "Iteration:  973\n",
      "Previous theta :  [-0.01651999 -0.08495459  0.11466928 -0.01708876  0.09244017 -0.18337918\n",
      "  0.32935467 -0.0581132  -0.32651023  0.2316011  -0.21712279 -0.21064811\n",
      "  0.09092697 -0.31259869]\n",
      "New theta_0 : [-0.01652015 -0.08495813  0.11467568 -0.01707643  0.09243839 -0.18338932\n",
      "  0.32934826 -0.05810758 -0.32651509  0.2316357  -0.21715837 -0.21065118\n",
      "  0.09092591 -0.31260265]\n",
      "Training Error:  9.768890803207418\n",
      "====================================================================================================\n",
      "Iteration:  974\n",
      "Previous theta :  [-0.01652015 -0.08495813  0.11467568 -0.01707643  0.09243839 -0.18338932\n",
      "  0.32934826 -0.05810758 -0.32651509  0.2316357  -0.21715837 -0.21065118\n",
      "  0.09092591 -0.31260265]\n",
      "New theta_0 : [-0.01652031 -0.08496165  0.11468206 -0.01706413  0.09243661 -0.18339939\n",
      "  0.32934189 -0.05810198 -0.3265199   0.2316702  -0.21719386 -0.21065424\n",
      "  0.09092485 -0.31260658]\n",
      "Training Error:  9.768887915843852\n",
      "====================================================================================================\n",
      "Iteration:  975\n",
      "Previous theta :  [-0.01652031 -0.08496165  0.11468206 -0.01706413  0.09243661 -0.18339939\n",
      "  0.32934189 -0.05810198 -0.3265199   0.2316702  -0.21719386 -0.21065424\n",
      "  0.09092485 -0.31260658]\n",
      "New theta_0 : [-0.01652046 -0.08496515  0.11468841 -0.01705185  0.09243483 -0.18340939\n",
      "  0.32933554 -0.0580964  -0.32652467  0.23170461 -0.21722929 -0.21065728\n",
      "  0.0909238  -0.31261049]\n",
      "Training Error:  9.768885043990519\n",
      "====================================================================================================\n",
      "Iteration:  976\n",
      "Previous theta :  [-0.01652046 -0.08496515  0.11468841 -0.01705185  0.09243483 -0.18340939\n",
      "  0.32933554 -0.0580964  -0.32652467  0.23170461 -0.21722929 -0.21065728\n",
      "  0.0909238  -0.31261049]\n",
      "New theta_0 : [-0.01652062 -0.08496864  0.11469474 -0.0170396   0.09243306 -0.18341934\n",
      "  0.32932924 -0.05809086 -0.32652939  0.23173893 -0.21726464 -0.2106603\n",
      "  0.09092276 -0.31261438]\n",
      "Training Error:  9.768882187549695\n",
      "====================================================================================================\n",
      "Iteration:  977\n",
      "Previous theta :  [-0.01652062 -0.08496864  0.11469474 -0.0170396   0.09243306 -0.18341934\n",
      "  0.32932924 -0.05809086 -0.32652939  0.23173893 -0.21726464 -0.2106603\n",
      "  0.09092276 -0.31261438]\n",
      "New theta_0 : [-0.01652078 -0.08497211  0.11470104 -0.01702737  0.09243129 -0.18342922\n",
      "  0.32932296 -0.05808534 -0.32653406  0.23177316 -0.21729991 -0.21066331\n",
      "  0.09092173 -0.31261825]\n",
      "Training Error:  9.76887934642446\n",
      "====================================================================================================\n",
      "Iteration:  978\n",
      "Previous theta :  [-0.01652078 -0.08497211  0.11470104 -0.01702737  0.09243129 -0.18342922\n",
      "  0.32932296 -0.05808534 -0.32653406  0.23177316 -0.21729991 -0.21066331\n",
      "  0.09092173 -0.31261825]\n",
      "New theta_0 : [-0.01652094 -0.08497557  0.11470731 -0.01701517  0.09242952 -0.18343903\n",
      "  0.32931672 -0.05807984 -0.3265387   0.2318073  -0.21733511 -0.2106663\n",
      "  0.0909207  -0.3126221 ]\n",
      "Training Error:  9.768876520518681\n",
      "====================================================================================================\n",
      "Iteration:  979\n",
      "Previous theta :  [-0.01652094 -0.08497557  0.11470731 -0.01701517  0.09242952 -0.18343903\n",
      "  0.32931672 -0.05807984 -0.3265387   0.2318073  -0.21733511 -0.2106663\n",
      "  0.0909207  -0.3126221 ]\n",
      "New theta_0 : [-0.0165211  -0.08497901  0.11471356 -0.017003    0.09242776 -0.18344879\n",
      "  0.3293105  -0.05807437 -0.32654329  0.23184134 -0.21737023 -0.21066928\n",
      "  0.09091968 -0.31262593]\n",
      "Training Error:  9.76887370973701\n",
      "====================================================================================================\n",
      "Iteration:  980\n",
      "Previous theta :  [-0.0165211  -0.08497901  0.11471356 -0.017003    0.09242776 -0.18344879\n",
      "  0.3293105  -0.05807437 -0.32654329  0.23184134 -0.21737023 -0.21066928\n",
      "  0.09091968 -0.31262593]\n",
      "New theta_0 : [-0.01652126 -0.08498244  0.11471978 -0.01699085  0.092426   -0.18345848\n",
      "  0.32930432 -0.05806893 -0.32654783  0.2318753  -0.21740528 -0.21067225\n",
      "  0.09091866 -0.31262974]\n",
      "Training Error:  9.768870913984877\n",
      "====================================================================================================\n",
      "Iteration:  981\n",
      "Previous theta :  [-0.01652126 -0.08498244  0.11471978 -0.01699085  0.092426   -0.18345848\n",
      "  0.32930432 -0.05806893 -0.32654783  0.2318753  -0.21740528 -0.21067225\n",
      "  0.09091866 -0.31262974]\n",
      "New theta_0 : [-0.01652142 -0.08498586  0.11472598 -0.01697872  0.09242425 -0.18346811\n",
      "  0.32929817 -0.05806351 -0.32655234  0.23190916 -0.21744026 -0.2106752\n",
      "  0.09091766 -0.31263352]\n",
      "Training Error:  9.768868133168475\n",
      "====================================================================================================\n",
      "Iteration:  982\n",
      "Previous theta :  [-0.01652142 -0.08498586  0.11472598 -0.01697872  0.09242425 -0.18346811\n",
      "  0.32929817 -0.05806351 -0.32655234  0.23190916 -0.21744026 -0.2106752\n",
      "  0.09091766 -0.31263352]\n",
      "New theta_0 : [-0.01652158 -0.08498925  0.11473215 -0.01696663  0.0924225  -0.18347768\n",
      "  0.32929206 -0.05805811 -0.3265568   0.23194294 -0.21747516 -0.21067813\n",
      "  0.09091666 -0.31263729]\n",
      "Training Error:  9.768865367194756\n",
      "====================================================================================================\n",
      "Iteration:  983\n",
      "Previous theta :  [-0.01652158 -0.08498925  0.11473215 -0.01696663  0.0924225  -0.18347768\n",
      "  0.32929206 -0.05805811 -0.3265568   0.23194294 -0.21747516 -0.21067813\n",
      "  0.09091666 -0.31263729]\n",
      "New theta_0 : [-0.01652174 -0.08499264  0.1147383  -0.01695455  0.09242075 -0.18348719\n",
      "  0.32928597 -0.05805274 -0.32656122  0.23197662 -0.21750998 -0.21068105\n",
      "  0.09091566 -0.31264103]\n",
      "Training Error:  9.768862615971425\n",
      "====================================================================================================\n",
      "Iteration:  984\n",
      "Previous theta :  [-0.01652174 -0.08499264  0.1147383  -0.01695455  0.09242075 -0.18348719\n",
      "  0.32928597 -0.05805274 -0.32656122  0.23197662 -0.21750998 -0.21068105\n",
      "  0.09091566 -0.31264103]\n",
      "New theta_0 : [-0.0165219  -0.08499601  0.11474442 -0.01694251  0.09241901 -0.18349664\n",
      "  0.32927991 -0.0580474  -0.3265656   0.23201022 -0.21754474 -0.21068396\n",
      "  0.09091468 -0.31264476]\n",
      "Training Error:  9.768859879406927\n",
      "====================================================================================================\n",
      "Iteration:  985\n",
      "Previous theta :  [-0.0165219  -0.08499601  0.11474442 -0.01694251  0.09241901 -0.18349664\n",
      "  0.32927991 -0.0580474  -0.3265656   0.23201022 -0.21754474 -0.21068396\n",
      "  0.09091468 -0.31264476]\n",
      "New theta_0 : [-0.01652206 -0.08499936  0.11475051 -0.01693049  0.09241727 -0.18350602\n",
      "  0.32927389 -0.05804208 -0.32656993  0.23204373 -0.21757941 -0.21068685\n",
      "  0.0909137  -0.31264847]\n",
      "Training Error:  9.768857157410439\n",
      "====================================================================================================\n",
      "Iteration:  986\n",
      "Previous theta :  [-0.01652206 -0.08499936  0.11475051 -0.01693049  0.09241727 -0.18350602\n",
      "  0.32927389 -0.05804208 -0.32656993  0.23204373 -0.21757941 -0.21068685\n",
      "  0.0909137  -0.31264847]\n",
      "New theta_0 : [-0.01652222 -0.0850027   0.11475658 -0.01691849  0.09241554 -0.18351535\n",
      "  0.3292679  -0.05803679 -0.32657423  0.23207714 -0.21761402 -0.21068973\n",
      "  0.09091272 -0.31265215]\n",
      "Training Error:  9.768854449891872\n",
      "====================================================================================================\n",
      "Iteration:  987\n",
      "Previous theta :  [-0.01652222 -0.0850027   0.11475658 -0.01691849  0.09241554 -0.18351535\n",
      "  0.3292679  -0.05803679 -0.32657423  0.23207714 -0.21761402 -0.21068973\n",
      "  0.09091272 -0.31265215]\n",
      "New theta_0 : [-0.01652239 -0.08500602  0.11476263 -0.01690652  0.09241381 -0.18352462\n",
      "  0.32926193 -0.05803152 -0.32657848  0.23211047 -0.21764855 -0.21069259\n",
      "  0.09091175 -0.31265582]\n",
      "Training Error:  9.768851756761846\n",
      "====================================================================================================\n",
      "Iteration:  988\n",
      "Previous theta :  [-0.01652239 -0.08500602  0.11476263 -0.01690652  0.09241381 -0.18352462\n",
      "  0.32926193 -0.05803152 -0.32657848  0.23211047 -0.21764855 -0.21069259\n",
      "  0.09091175 -0.31265582]\n",
      "New theta_0 : [-0.01652255 -0.08500933  0.11476865 -0.01689458  0.09241208 -0.18353384\n",
      "  0.329256   -0.05802627 -0.3265827   0.23214371 -0.217683   -0.21069544\n",
      "  0.09091079 -0.31265946]\n",
      "Training Error:  9.768849077931705\n",
      "====================================================================================================\n",
      "Iteration:  989\n",
      "Previous theta :  [-0.01652255 -0.08500933  0.11476865 -0.01689458  0.09241208 -0.18353384\n",
      "  0.329256   -0.05802627 -0.3265827   0.23214371 -0.217683   -0.21069544\n",
      "  0.09091079 -0.31265946]\n",
      "New theta_0 : [-0.01652271 -0.08501263  0.11477465 -0.01688266  0.09241036 -0.18354299\n",
      "  0.32925009 -0.05802105 -0.32658687  0.23217687 -0.21771739 -0.21069827\n",
      "  0.09090984 -0.31266309]\n",
      "Training Error:  9.768846413313486\n",
      "====================================================================================================\n",
      "Iteration:  990\n",
      "Previous theta :  [-0.01652271 -0.08501263  0.11477465 -0.01688266  0.09241036 -0.18354299\n",
      "  0.32925009 -0.05802105 -0.32658687  0.23217687 -0.21771739 -0.21069827\n",
      "  0.09090984 -0.31266309]\n",
      "New theta_0 : [-0.01652287 -0.08501591  0.11478062 -0.01687077  0.09240864 -0.18355209\n",
      "  0.32924422 -0.05801585 -0.326591    0.23220993 -0.21775169 -0.21070109\n",
      "  0.09090889 -0.3126667 ]\n",
      "Training Error:  9.76884376281993\n",
      "====================================================================================================\n",
      "Iteration:  991\n",
      "Previous theta :  [-0.01652287 -0.08501591  0.11478062 -0.01687077  0.09240864 -0.18355209\n",
      "  0.32924422 -0.05801585 -0.326591    0.23220993 -0.21775169 -0.21070109\n",
      "  0.09090889 -0.3126667 ]\n",
      "New theta_0 : [-0.01652304 -0.08501918  0.11478657 -0.01685891  0.09240693 -0.18356112\n",
      "  0.32923838 -0.05801068 -0.3265951   0.23224291 -0.21778593 -0.2107039\n",
      "  0.09090795 -0.31267028]\n",
      "Training Error:  9.768841126364464\n",
      "====================================================================================================\n",
      "Iteration:  992\n",
      "Previous theta :  [-0.01652304 -0.08501918  0.11478657 -0.01685891  0.09240693 -0.18356112\n",
      "  0.32923838 -0.05801068 -0.3265951   0.23224291 -0.21778593 -0.2107039\n",
      "  0.09090795 -0.31267028]\n",
      "New theta_0 : [-0.0165232  -0.08502243  0.1147925  -0.01684707  0.09240522 -0.1835701\n",
      "  0.32923256 -0.05800553 -0.32659915  0.2322758  -0.21782009 -0.21070669\n",
      "  0.09090701 -0.31267385]\n",
      "Training Error:  9.768838503861197\n",
      "====================================================================================================\n",
      "Iteration:  993\n",
      "Previous theta :  [-0.0165232  -0.08502243  0.1147925  -0.01684707  0.09240522 -0.1835701\n",
      "  0.32923256 -0.05800553 -0.32659915  0.2322758  -0.21782009 -0.21070669\n",
      "  0.09090701 -0.31267385]\n",
      "New theta_0 : [-0.01652336 -0.08502567  0.1147984  -0.01683525  0.09240351 -0.18357903\n",
      "  0.32922678 -0.0580004  -0.32660317  0.2323086  -0.21785418 -0.21070947\n",
      "  0.09090608 -0.3126774 ]\n",
      "Training Error:  9.768835895224916\n",
      "====================================================================================================\n",
      "Iteration:  994\n",
      "Previous theta :  [-0.01652336 -0.08502567  0.1147984  -0.01683525  0.09240351 -0.18357903\n",
      "  0.32922678 -0.0580004  -0.32660317  0.2323086  -0.21785418 -0.21070947\n",
      "  0.09090608 -0.3126774 ]\n",
      "New theta_0 : [-0.01652353 -0.0850289   0.11480428 -0.01682346  0.09240181 -0.1835879\n",
      "  0.32922102 -0.0579953  -0.32660715  0.23234132 -0.2178882  -0.21071223\n",
      "  0.09090516 -0.31268093]\n",
      "Training Error:  9.76883330037107\n",
      "====================================================================================================\n",
      "Iteration:  995\n",
      "Previous theta :  [-0.01652353 -0.0850289   0.11480428 -0.01682346  0.09240181 -0.1835879\n",
      "  0.32922102 -0.0579953  -0.32660715  0.23234132 -0.2178882  -0.21071223\n",
      "  0.09090516 -0.31268093]\n",
      "New theta_0 : [-0.01652369 -0.08503211  0.11481013 -0.0168117   0.09240011 -0.18359671\n",
      "  0.32921529 -0.05799022 -0.32661109  0.23237395 -0.21792214 -0.21071498\n",
      "  0.09090424 -0.31268444]\n",
      "Training Error:  9.768830719215778\n",
      "====================================================================================================\n",
      "Iteration:  996\n",
      "Previous theta :  [-0.01652369 -0.08503211  0.11481013 -0.0168117   0.09240011 -0.18359671\n",
      "  0.32921529 -0.05799022 -0.32661109  0.23237395 -0.21792214 -0.21071498\n",
      "  0.09090424 -0.31268444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01652386 -0.08503531  0.11481596 -0.01679996  0.09239841 -0.18360547\n",
      "  0.32920959 -0.05798516 -0.32661499  0.23240649 -0.21795601 -0.21071772\n",
      "  0.09090333 -0.31268794]\n",
      "Training Error:  9.768828151675812\n",
      "====================================================================================================\n",
      "Iteration:  997\n",
      "Previous theta :  [-0.01652386 -0.08503531  0.11481596 -0.01679996  0.09239841 -0.18360547\n",
      "  0.32920959 -0.05798516 -0.32661499  0.23240649 -0.21795601 -0.21071772\n",
      "  0.09090333 -0.31268794]\n",
      "New theta_0 : [-0.01652402 -0.08503849  0.11482177 -0.01678825  0.09239672 -0.18361417\n",
      "  0.32920392 -0.05798013 -0.32661885  0.23243895 -0.21798981 -0.21072045\n",
      "  0.09090242 -0.31269141]\n",
      "Training Error:  9.768825597668581\n",
      "====================================================================================================\n",
      "Iteration:  998\n",
      "Previous theta :  [-0.01652402 -0.08503849  0.11482177 -0.01678825  0.09239672 -0.18361417\n",
      "  0.32920392 -0.05798013 -0.32661885  0.23243895 -0.21798981 -0.21072045\n",
      "  0.09090242 -0.31269141]\n",
      "New theta_0 : [-0.01652419 -0.08504167  0.11482755 -0.01677656  0.09239504 -0.18362281\n",
      "  0.32919828 -0.05797512 -0.32662268  0.23247132 -0.21802353 -0.21072316\n",
      "  0.09090152 -0.31269487]\n",
      "Training Error:  9.768823057112145\n",
      "====================================================================================================\n",
      "Iteration:  999\n",
      "Previous theta :  [-0.01652419 -0.08504167  0.11482755 -0.01677656  0.09239504 -0.18362281\n",
      "  0.32919828 -0.05797512 -0.32662268  0.23247132 -0.21802353 -0.21072316\n",
      "  0.09090152 -0.31269487]\n",
      "New theta_0 : [-0.01652435 -0.08504482  0.11483332 -0.0167649   0.09239335 -0.1836314\n",
      "  0.32919267 -0.05797013 -0.32662647  0.23250361 -0.21805718 -0.21072585\n",
      "  0.09090063 -0.3126983 ]\n",
      "Training Error:  9.768820529925199\n",
      "====================================================================================================\n",
      "Iteration:  1000\n",
      "Previous theta :  [-0.01652435 -0.08504482  0.11483332 -0.0167649   0.09239335 -0.1836314\n",
      "  0.32919267 -0.05797013 -0.32662647  0.23250361 -0.21805718 -0.21072585\n",
      "  0.09090063 -0.3126983 ]\n",
      "New theta_0 : [-0.01652452 -0.08504797  0.11483905 -0.01675326  0.09239167 -0.18363994\n",
      "  0.32918708 -0.05796517 -0.32663022  0.23253581 -0.21809076 -0.21072854\n",
      "  0.09089974 -0.31270172]\n",
      "Training Error:  9.76881801602706\n",
      "====================================================================================================\n",
      "Iteration:  1001\n",
      "Previous theta :  [-0.01652452 -0.08504797  0.11483905 -0.01675326  0.09239167 -0.18363994\n",
      "  0.32918708 -0.05796517 -0.32663022  0.23253581 -0.21809076 -0.21072854\n",
      "  0.09089974 -0.31270172]\n",
      "New theta_0 : [-0.01652468 -0.0850511   0.11484477 -0.01674165  0.09239    -0.18364843\n",
      "  0.32918152 -0.05796023 -0.32663394  0.23256793 -0.21812427 -0.21073121\n",
      "  0.09089886 -0.31270512]\n",
      "Training Error:  9.768815515337671\n",
      "====================================================================================================\n",
      "Iteration:  1002\n",
      "Previous theta :  [-0.01652468 -0.0850511   0.11484477 -0.01674165  0.09239    -0.18364843\n",
      "  0.32918152 -0.05796023 -0.32663394  0.23256793 -0.21812427 -0.21073121\n",
      "  0.09089886 -0.31270512]\n",
      "New theta_0 : [-0.01652485 -0.08505422  0.11485046 -0.01673007  0.09238833 -0.18365686\n",
      "  0.32917599 -0.05795531 -0.32663762  0.23259996 -0.21815771 -0.21073386\n",
      "  0.09089798 -0.31270851]\n",
      "Training Error:  9.768813027777586\n",
      "====================================================================================================\n",
      "Iteration:  1003\n",
      "Previous theta :  [-0.01652485 -0.08505422  0.11485046 -0.01673007  0.09238833 -0.18365686\n",
      "  0.32917599 -0.05795531 -0.32663762  0.23259996 -0.21815771 -0.21073386\n",
      "  0.09089798 -0.31270851]\n",
      "New theta_0 : [-0.01652501 -0.08505732  0.11485613 -0.01671851  0.09238666 -0.18366523\n",
      "  0.32917049 -0.05795041 -0.32664126  0.23263191 -0.21819107 -0.21073651\n",
      "  0.09089711 -0.31271187]\n",
      "Training Error:  9.768810553267972\n",
      "====================================================================================================\n",
      "Iteration:  1004\n",
      "Previous theta :  [-0.01652501 -0.08505732  0.11485613 -0.01671851  0.09238666 -0.18366523\n",
      "  0.32917049 -0.05795041 -0.32664126  0.23263191 -0.21819107 -0.21073651\n",
      "  0.09089711 -0.31271187]\n",
      "New theta_0 : [-0.01652518 -0.08506041  0.11486178 -0.01670697  0.09238499 -0.18367356\n",
      "  0.32916502 -0.05794554 -0.32664487  0.23266377 -0.21822436 -0.21073914\n",
      "  0.09089625 -0.31271522]\n",
      "Training Error:  9.7688080917306\n",
      "====================================================================================================\n",
      "Iteration:  1005\n",
      "Previous theta :  [-0.01652518 -0.08506041  0.11486178 -0.01670697  0.09238499 -0.18367356\n",
      "  0.32916502 -0.05794554 -0.32664487  0.23266377 -0.21822436 -0.21073914\n",
      "  0.09089625 -0.31271522]\n",
      "New theta_0 : [-0.01652535 -0.08506349  0.11486741 -0.01669546  0.09238333 -0.18368183\n",
      "  0.32915957 -0.05794069 -0.32664845  0.23269555 -0.21825758 -0.21074176\n",
      "  0.09089539 -0.31271855]\n",
      "Training Error:  9.76880564308783\n",
      "====================================================================================================\n",
      "Iteration:  1006\n",
      "Previous theta :  [-0.01652535 -0.08506349  0.11486741 -0.01669546  0.09238333 -0.18368183\n",
      "  0.32915957 -0.05794069 -0.32664845  0.23269555 -0.21825758 -0.21074176\n",
      "  0.09089539 -0.31271855]\n",
      "New theta_0 : [-0.01652552 -0.08506655  0.11487301 -0.01668398  0.09238168 -0.18369005\n",
      "  0.32915415 -0.05793586 -0.32665199  0.23272725 -0.21829073 -0.21074436\n",
      "  0.09089453 -0.31272186]\n",
      "Training Error:  9.768803207262621\n",
      "====================================================================================================\n",
      "Iteration:  1007\n",
      "Previous theta :  [-0.01652552 -0.08506655  0.11487301 -0.01668398  0.09238168 -0.18369005\n",
      "  0.32915415 -0.05793586 -0.32665199  0.23272725 -0.21829073 -0.21074436\n",
      "  0.09089453 -0.31272186]\n",
      "New theta_0 : [-0.01652568 -0.08506961  0.11487859 -0.01667252  0.09238002 -0.18369822\n",
      "  0.32914875 -0.05793105 -0.32665549  0.23275886 -0.21832381 -0.21074696\n",
      "  0.09089369 -0.31272515]\n",
      "Training Error:  9.768800784178513\n",
      "====================================================================================================\n",
      "Iteration:  1008\n",
      "Previous theta :  [-0.01652568 -0.08506961  0.11487859 -0.01667252  0.09238002 -0.18369822\n",
      "  0.32914875 -0.05793105 -0.32665549  0.23275886 -0.21832381 -0.21074696\n",
      "  0.09089369 -0.31272515]\n",
      "New theta_0 : [-0.01652585 -0.08507265  0.11488415 -0.01666108  0.09237837 -0.18370634\n",
      "  0.32914338 -0.05792626 -0.32665896  0.23279039 -0.21835681 -0.21074954\n",
      "  0.09089284 -0.31272843]\n",
      "Training Error:  9.768798373759621\n",
      "====================================================================================================\n",
      "Iteration:  1009\n",
      "Previous theta :  [-0.01652585 -0.08507265  0.11488415 -0.01666108  0.09237837 -0.18370634\n",
      "  0.32914338 -0.05792626 -0.32665896  0.23279039 -0.21835681 -0.21074954\n",
      "  0.09089284 -0.31272843]\n",
      "New theta_0 : [-0.01652602 -0.08507567  0.11488969 -0.01664968  0.09237673 -0.18371441\n",
      "  0.32913804 -0.0579215  -0.3266624   0.23282184 -0.21838975 -0.2107521\n",
      "  0.09089201 -0.31273169]\n",
      "Training Error:  9.76879597593064\n",
      "====================================================================================================\n",
      "Iteration:  1010\n",
      "Previous theta :  [-0.01652602 -0.08507567  0.11488969 -0.01664968  0.09237673 -0.18371441\n",
      "  0.32913804 -0.0579215  -0.3266624   0.23282184 -0.21838975 -0.2107521\n",
      "  0.09089201 -0.31273169]\n",
      "New theta_0 : [-0.01652619 -0.08507869  0.1148952  -0.01663829  0.09237509 -0.18372242\n",
      "  0.32913273 -0.05791676 -0.3266658   0.2328532  -0.21842261 -0.21075466\n",
      "  0.09089118 -0.31273493]\n",
      "Training Error:  9.768793590616827\n",
      "====================================================================================================\n",
      "Iteration:  1011\n",
      "Previous theta :  [-0.01652619 -0.08507869  0.1148952  -0.01663829  0.09237509 -0.18372242\n",
      "  0.32913273 -0.05791676 -0.3266658   0.2328532  -0.21842261 -0.21075466\n",
      "  0.09089118 -0.31273493]\n",
      "New theta_0 : [-0.01652635 -0.08508169  0.1149007  -0.01662693  0.09237345 -0.18373039\n",
      "  0.32912744 -0.05791204 -0.32666917  0.23288448 -0.2184554  -0.2107572\n",
      "  0.09089035 -0.31273815]\n",
      "Training Error:  9.768791217744003\n",
      "====================================================================================================\n",
      "Iteration:  1012\n",
      "Previous theta :  [-0.01652635 -0.08508169  0.1149007  -0.01662693  0.09237345 -0.18373039\n",
      "  0.32912744 -0.05791204 -0.32666917  0.23288448 -0.2184554  -0.2107572\n",
      "  0.09089035 -0.31273815]\n",
      "New theta_0 : [-0.01652652 -0.08508468  0.11490617 -0.0166156   0.09237182 -0.1837383\n",
      "  0.32912217 -0.05790734 -0.32667251  0.23291568 -0.21848812 -0.21075973\n",
      "  0.09088953 -0.31274136]\n",
      "Training Error:  9.768788857238544\n",
      "====================================================================================================\n",
      "Iteration:  1013\n",
      "Previous theta :  [-0.01652652 -0.08508468  0.11490617 -0.0166156   0.09237182 -0.1837383\n",
      "  0.32912217 -0.05790734 -0.32667251  0.23291568 -0.21848812 -0.21075973\n",
      "  0.09088953 -0.31274136]\n",
      "New theta_0 : [-0.01652669 -0.08508765  0.11491162 -0.01660429  0.09237019 -0.18374617\n",
      "  0.32911694 -0.05790266 -0.32667581  0.2329468  -0.21852077 -0.21076225\n",
      "  0.09088872 -0.31274455]\n",
      "Training Error:  9.76878650902738\n",
      "====================================================================================================\n",
      "Iteration:  1014\n",
      "Previous theta :  [-0.01652669 -0.08508765  0.11491162 -0.01660429  0.09237019 -0.18374617\n",
      "  0.32911694 -0.05790266 -0.32667581  0.2329468  -0.21852077 -0.21076225\n",
      "  0.09088872 -0.31274455]\n",
      "New theta_0 : [-0.01652686 -0.08509062  0.11491705 -0.01659301  0.09236856 -0.18375399\n",
      "  0.32911173 -0.057898   -0.32667908  0.23297784 -0.21855335 -0.21076475\n",
      "  0.09088791 -0.31274773]\n",
      "Training Error:  9.768784173037979\n",
      "====================================================================================================\n",
      "Iteration:  1015\n",
      "Previous theta :  [-0.01652686 -0.08509062  0.11491705 -0.01659301  0.09236856 -0.18375399\n",
      "  0.32911173 -0.057898   -0.32667908  0.23297784 -0.21855335 -0.21076475\n",
      "  0.09088791 -0.31274773]\n",
      "New theta_0 : [-0.01652703 -0.08509357  0.11492246 -0.01658175  0.09236694 -0.18376175\n",
      "  0.32910654 -0.05789336 -0.32668232  0.2330088  -0.21858586 -0.21076725\n",
      "  0.0908871  -0.31275089]\n",
      "Training Error:  9.768781849198355\n",
      "====================================================================================================\n",
      "Iteration:  1016\n",
      "Previous theta :  [-0.01652703 -0.08509357  0.11492246 -0.01658175  0.09236694 -0.18376175\n",
      "  0.32910654 -0.05789336 -0.32668232  0.2330088  -0.21858586 -0.21076725\n",
      "  0.0908871  -0.31275089]\n",
      "New theta_0 : [-0.0165272  -0.08509651  0.11492785 -0.01657052  0.09236532 -0.18376947\n",
      "  0.32910138 -0.05788875 -0.32668553  0.23303967 -0.21861829 -0.21076973\n",
      "  0.0908863  -0.31275403]\n",
      "Training Error:  9.76877953743705\n",
      "====================================================================================================\n",
      "Iteration:  1017\n",
      "Previous theta :  [-0.0165272  -0.08509651  0.11492785 -0.01657052  0.09236532 -0.18376947\n",
      "  0.32910138 -0.05788875 -0.32668553  0.23303967 -0.21861829 -0.21076973\n",
      "  0.0908863  -0.31275403]\n",
      "New theta_0 : [-0.01652737 -0.08509944  0.11493322 -0.01655931  0.0923637  -0.18377714\n",
      "  0.32909624 -0.05788415 -0.3266887   0.23307046 -0.21865066 -0.2107722\n",
      "  0.09088551 -0.31275715]\n",
      "Training Error:  9.76877723768314\n",
      "====================================================================================================\n",
      "Iteration:  1018\n",
      "Previous theta :  [-0.01652737 -0.08509944  0.11493322 -0.01655931  0.0923637  -0.18377714\n",
      "  0.32909624 -0.05788415 -0.3266887   0.23307046 -0.21865066 -0.2107722\n",
      "  0.09088551 -0.31275715]\n",
      "New theta_0 : [-0.01652753 -0.08510235  0.11493856 -0.01654813  0.09236209 -0.18378477\n",
      "  0.32909113 -0.05787958 -0.32669184  0.23310118 -0.21868296 -0.21077465\n",
      "  0.09088472 -0.31276026]\n",
      "Training Error:  9.768774949866224\n",
      "====================================================================================================\n",
      "Iteration:  1019\n",
      "Previous theta :  [-0.01652753 -0.08510235  0.11493856 -0.01654813  0.09236209 -0.18378477\n",
      "  0.32909113 -0.05787958 -0.32669184  0.23310118 -0.21868296 -0.21077465\n",
      "  0.09088472 -0.31276026]\n",
      "New theta_0 : [-0.0165277  -0.08510526  0.11494389 -0.01653697  0.09236048 -0.18379234\n",
      "  0.32908605 -0.05787502 -0.32669495  0.23313181 -0.21871519 -0.2107771\n",
      "  0.09088394 -0.31276335]\n",
      "Training Error:  9.76877267391642\n",
      "====================================================================================================\n",
      "Iteration:  1020\n",
      "Previous theta :  [-0.0165277  -0.08510526  0.11494389 -0.01653697  0.09236048 -0.18379234\n",
      "  0.32908605 -0.05787502 -0.32669495  0.23313181 -0.21871519 -0.2107771\n",
      "  0.09088394 -0.31276335]\n",
      "New theta_0 : [-0.01652787 -0.08510815  0.11494919 -0.01652583  0.09235888 -0.18379987\n",
      "  0.32908099 -0.05787049 -0.32669803  0.23316236 -0.21874734 -0.21077953\n",
      "  0.09088316 -0.31276643]\n",
      "Training Error:  9.768770409764358\n",
      "====================================================================================================\n",
      "Iteration:  1021\n",
      "Previous theta :  [-0.01652787 -0.08510815  0.11494919 -0.01652583  0.09235888 -0.18379987\n",
      "  0.32908099 -0.05787049 -0.32669803  0.23316236 -0.21874734 -0.21077953\n",
      "  0.09088316 -0.31276643]\n",
      "New theta_0 : [-0.01652804 -0.08511103  0.11495448 -0.01651472  0.09235728 -0.18380735\n",
      "  0.32907595 -0.05786598 -0.32670108  0.23319284 -0.21877943 -0.21078195\n",
      "  0.09088239 -0.31276949]\n",
      "Training Error:  9.768768157341173\n",
      "====================================================================================================\n",
      "Iteration:  1022\n",
      "Previous theta :  [-0.01652804 -0.08511103  0.11495448 -0.01651472  0.09235728 -0.18380735\n",
      "  0.32907595 -0.05786598 -0.32670108  0.23319284 -0.21877943 -0.21078195\n",
      "  0.09088239 -0.31276949]\n",
      "New theta_0 : [-0.01652821 -0.0851139   0.11495974 -0.01650364  0.09235568 -0.18381478\n",
      "  0.32907094 -0.05786149 -0.3267041   0.23322323 -0.21881145 -0.21078436\n",
      "  0.09088162 -0.31277253]\n",
      "Training Error:  9.768765916578516\n",
      "====================================================================================================\n",
      "Iteration:  1023\n",
      "Previous theta :  [-0.01652821 -0.0851139   0.11495974 -0.01650364  0.09235568 -0.18381478\n",
      "  0.32907094 -0.05786149 -0.3267041   0.23322323 -0.21881145 -0.21078436\n",
      "  0.09088162 -0.31277253]\n",
      "New theta_0 : [-0.01652838 -0.08511675  0.11496499 -0.01649258  0.09235409 -0.18382217\n",
      "  0.32906595 -0.05785701 -0.32670709  0.23325354 -0.21884339 -0.21078676\n",
      "  0.09088086 -0.31277556]\n",
      "Training Error:  9.76876368740852\n",
      "====================================================================================================\n",
      "Iteration:  1024\n",
      "Previous theta :  [-0.01652838 -0.08511675  0.11496499 -0.01649258  0.09235409 -0.18382217\n",
      "  0.32906595 -0.05785701 -0.32670709  0.23325354 -0.21884339 -0.21078676\n",
      "  0.09088086 -0.31277556]\n",
      "New theta_0 : [-0.01652855 -0.0851196   0.11497021 -0.01648155  0.0923525  -0.18382951\n",
      "  0.32906099 -0.05785256 -0.32671005  0.23328378 -0.21887527 -0.21078914\n",
      "  0.0908801  -0.31277858]\n",
      "Training Error:  9.768761469763826\n",
      "====================================================================================================\n",
      "Iteration:  1025\n",
      "Previous theta :  [-0.01652855 -0.0851196   0.11497021 -0.01648155  0.0923525  -0.18382951\n",
      "  0.32906099 -0.05785256 -0.32671005  0.23328378 -0.21887527 -0.21078914\n",
      "  0.0908801  -0.31277858]\n",
      "New theta_0 : [-0.01652872 -0.08512243  0.11497541 -0.01647054  0.09235091 -0.18383681\n",
      "  0.32905605 -0.05784813 -0.32671298  0.23331394 -0.21890708 -0.21079152\n",
      "  0.09087934 -0.31278157]\n",
      "Training Error:  9.768759263577556\n",
      "====================================================================================================\n",
      "Iteration:  1026\n",
      "Previous theta :  [-0.01652872 -0.08512243  0.11497541 -0.01647054  0.09235091 -0.18383681\n",
      "  0.32905605 -0.05784813 -0.32671298  0.23331394 -0.21890708 -0.21079152\n",
      "  0.09087934 -0.31278157]\n",
      "New theta_0 : [-0.0165289  -0.08512525  0.1149806  -0.01645955  0.09234933 -0.18384406\n",
      "  0.32905113 -0.05784372 -0.32671588  0.23334401 -0.21893882 -0.21079388\n",
      "  0.0908786  -0.31278455]\n",
      "Training Error:  9.768757068783316\n",
      "====================================================================================================\n",
      "Iteration:  1027\n",
      "Previous theta :  [-0.0165289  -0.08512525  0.1149806  -0.01645955  0.09234933 -0.18384406\n",
      "  0.32905113 -0.05784372 -0.32671588  0.23334401 -0.21893882 -0.21079388\n",
      "  0.0908786  -0.31278455]\n",
      "New theta_0 : [-0.01652907 -0.08512806  0.11498576 -0.01644859  0.09234775 -0.18385126\n",
      "  0.32904624 -0.05783932 -0.32671875  0.23337401 -0.21897049 -0.21079623\n",
      "  0.09087785 -0.31278752]\n",
      "Training Error:  9.7687548853152\n",
      "====================================================================================================\n",
      "Iteration:  1028\n",
      "Previous theta :  [-0.01652907 -0.08512806  0.11498576 -0.01644859  0.09234775 -0.18385126\n",
      "  0.32904624 -0.05783932 -0.32671875  0.23337401 -0.21897049 -0.21079623\n",
      "  0.09087785 -0.31278752]\n",
      "New theta_0 : [-0.01652924 -0.08513086  0.11499091 -0.01643765  0.09234617 -0.18385842\n",
      "  0.32904137 -0.05783495 -0.32672159  0.23340393 -0.21900209 -0.21079857\n",
      "  0.09087711 -0.31279047]\n",
      "Training Error:  9.768752713107771\n",
      "====================================================================================================\n",
      "Iteration:  1029\n",
      "Previous theta :  [-0.01652924 -0.08513086  0.11499091 -0.01643765  0.09234617 -0.18385842\n",
      "  0.32904137 -0.05783495 -0.32672159  0.23340393 -0.21900209 -0.21079857\n",
      "  0.09087711 -0.31279047]\n",
      "New theta_0 : [-0.01652941 -0.08513364  0.11499603 -0.01642674  0.0923446  -0.18386554\n",
      "  0.32903653 -0.0578306  -0.3267244   0.23343378 -0.21903362 -0.2108009\n",
      "  0.09087638 -0.31279341]\n",
      "Training Error:  9.768750552096064\n",
      "====================================================================================================\n",
      "Iteration:  1030\n",
      "Previous theta :  [-0.01652941 -0.08513364  0.11499603 -0.01642674  0.0923446  -0.18386554\n",
      "  0.32903653 -0.0578306  -0.3267244   0.23343378 -0.21903362 -0.2108009\n",
      "  0.09087638 -0.31279341]\n",
      "New theta_0 : [-0.01652958 -0.08513642  0.11500114 -0.01641586  0.09234303 -0.18387261\n",
      "  0.32903171 -0.05782626 -0.32672719  0.23346354 -0.21906509 -0.21080322\n",
      "  0.09087565 -0.31279633]\n",
      "Training Error:  9.768748402215573\n",
      "====================================================================================================\n",
      "Iteration:  1031\n",
      "Previous theta :  [-0.01652958 -0.08513642  0.11500114 -0.01641586  0.09234303 -0.18387261\n",
      "  0.32903171 -0.05782626 -0.32672719  0.23346354 -0.21906509 -0.21080322\n",
      "  0.09087565 -0.31279633]\n",
      "New theta_0 : [-0.01652975 -0.08513918  0.11500622 -0.01640499  0.09234147 -0.18387964\n",
      "  0.32902691 -0.05782195 -0.32672994  0.23349323 -0.21909648 -0.21080552\n",
      "  0.09087493 -0.31279923]\n",
      "Training Error:  9.768746263402265\n",
      "====================================================================================================\n",
      "Iteration:  1032\n",
      "Previous theta :  [-0.01652975 -0.08513918  0.11500622 -0.01640499  0.09234147 -0.18387964\n",
      "  0.32902691 -0.05782195 -0.32672994  0.23349323 -0.21909648 -0.21080552\n",
      "  0.09087493 -0.31279923]\n",
      "New theta_0 : [-0.01652992 -0.08514194  0.11501129 -0.01639416  0.09233991 -0.18388662\n",
      "  0.32902213 -0.05781765 -0.32673267  0.23352284 -0.2191278  -0.21080782\n",
      "  0.09087421 -0.31280212]\n",
      "Training Error:  9.768744135592561\n",
      "====================================================================================================\n",
      "Iteration:  1033\n",
      "Previous theta :  [-0.01652992 -0.08514194  0.11501129 -0.01639416  0.09233991 -0.18388662\n",
      "  0.32902213 -0.05781765 -0.32673267  0.23352284 -0.2191278  -0.21080782\n",
      "  0.09087421 -0.31280212]\n",
      "New theta_0 : [-0.01653009 -0.08514468  0.11501634 -0.01638334  0.09233835 -0.18389356\n",
      "  0.32901738 -0.05781337 -0.32673537  0.23355238 -0.21915906 -0.2108101\n",
      "  0.09087349 -0.312805  ]\n",
      "Training Error:  9.76874201872333\n",
      "====================================================================================================\n",
      "Iteration:  1034\n",
      "Previous theta :  [-0.01653009 -0.08514468  0.11501634 -0.01638334  0.09233835 -0.18389356\n",
      "  0.32901738 -0.05781337 -0.32673537  0.23355238 -0.21915906 -0.2108101\n",
      "  0.09087349 -0.312805  ]\n",
      "New theta_0 : [-0.01653026 -0.08514741  0.11502137 -0.01637255  0.0923368  -0.18390046\n",
      "  0.32901265 -0.05780912 -0.32673804  0.23358183 -0.21919025 -0.21081238\n",
      "  0.09087278 -0.31280786]\n",
      "Training Error:  9.768739912731897\n",
      "====================================================================================================\n",
      "Iteration:  1035\n",
      "Previous theta :  [-0.01653026 -0.08514741  0.11502137 -0.01637255  0.0923368  -0.18390046\n",
      "  0.32901265 -0.05780912 -0.32673804  0.23358183 -0.21919025 -0.21081238\n",
      "  0.09087278 -0.31280786]\n",
      "New theta_0 : [-0.01653044 -0.08515013  0.11502638 -0.01636179  0.09233525 -0.18390731\n",
      "  0.32900794 -0.05780488 -0.32674068  0.23361121 -0.21922137 -0.21081464\n",
      "  0.09087208 -0.3128107 ]\n",
      "Training Error:  9.768737817556023\n",
      "====================================================================================================\n",
      "Iteration:  1036\n",
      "Previous theta :  [-0.01653044 -0.08515013  0.11502638 -0.01636179  0.09233525 -0.18390731\n",
      "  0.32900794 -0.05780488 -0.32674068  0.23361121 -0.21922137 -0.21081464\n",
      "  0.09087208 -0.3128107 ]\n",
      "New theta_0 : [-0.01653061 -0.08515284  0.11503137 -0.01635105  0.0923337  -0.18391412\n",
      "  0.32900326 -0.05780066 -0.3267433   0.23364052 -0.21925242 -0.21081689\n",
      "  0.09087138 -0.31281353]\n",
      "Training Error:  9.768735733133916\n",
      "====================================================================================================\n",
      "Iteration:  1037\n",
      "Previous theta :  [-0.01653061 -0.08515284  0.11503137 -0.01635105  0.0923337  -0.18391412\n",
      "  0.32900326 -0.05780066 -0.3267433   0.23364052 -0.21925242 -0.21081689\n",
      "  0.09087138 -0.31281353]\n",
      "New theta_0 : [-0.01653078 -0.08515554  0.11503634 -0.01634033  0.09233216 -0.18392089\n",
      "  0.3289986  -0.05779646 -0.32674589  0.23366974 -0.21928341 -0.21081913\n",
      "  0.09087068 -0.31281635]\n",
      "Training Error:  9.768733659404218\n",
      "====================================================================================================\n",
      "Iteration:  1038\n",
      "Previous theta :  [-0.01653078 -0.08515554  0.11503634 -0.01634033  0.09233216 -0.18392089\n",
      "  0.3289986  -0.05779646 -0.32674589  0.23366974 -0.21928341 -0.21081913\n",
      "  0.09087068 -0.31281635]\n",
      "New theta_0 : [-0.01653095 -0.08515822  0.11504129 -0.01632964  0.09233062 -0.18392762\n",
      "  0.32899395 -0.05779227 -0.32674846  0.2336989  -0.21931432 -0.21082136\n",
      "  0.09086999 -0.31281915]\n",
      "Training Error:  9.768731596306\n",
      "====================================================================================================\n",
      "Iteration:  1039\n",
      "Previous theta :  [-0.01653095 -0.08515822  0.11504129 -0.01632964  0.09233062 -0.18392762\n",
      "  0.32899395 -0.05779227 -0.32674846  0.2336989  -0.21931432 -0.21082136\n",
      "  0.09086999 -0.31281915]\n",
      "New theta_0 : [-0.01653112 -0.0851609   0.11504623 -0.01631897  0.09232908 -0.1839343\n",
      "  0.32898934 -0.05778811 -0.32675099  0.23372797 -0.21934517 -0.21082358\n",
      "  0.0908693  -0.31282194]\n",
      "Training Error:  9.768729543778772\n",
      "====================================================================================================\n",
      "Iteration:  1040\n",
      "Previous theta :  [-0.01653112 -0.0851609   0.11504623 -0.01631897  0.09232908 -0.1839343\n",
      "  0.32898934 -0.05778811 -0.32675099  0.23372797 -0.21934517 -0.21082358\n",
      "  0.0908693  -0.31282194]\n",
      "New theta_0 : [-0.01653129 -0.08516357  0.11505115 -0.01630833  0.09232755 -0.18394095\n",
      "  0.32898474 -0.05778396 -0.3267535   0.23375697 -0.21937595 -0.21082579\n",
      "  0.09086862 -0.31282471]\n",
      "Training Error:  9.76872750176245\n",
      "====================================================================================================\n",
      "Iteration:  1041\n",
      "Previous theta :  [-0.01653129 -0.08516357  0.11505115 -0.01630833  0.09232755 -0.18394095\n",
      "  0.32898474 -0.05778396 -0.3267535   0.23375697 -0.21937595 -0.21082579\n",
      "  0.09086862 -0.31282471]\n",
      "New theta_0 : [-0.01653147 -0.08516622  0.11505604 -0.01629771  0.09232602 -0.18394755\n",
      "  0.32898017 -0.05777984 -0.32675599  0.2337859  -0.21940667 -0.21082799\n",
      "  0.09086794 -0.31282747]\n",
      "Training Error:  9.768725470197388\n",
      "====================================================================================================\n",
      "Iteration:  1042\n",
      "Previous theta :  [-0.01653147 -0.08516622  0.11505604 -0.01629771  0.09232602 -0.18394755\n",
      "  0.32898017 -0.05777984 -0.32675599  0.2337859  -0.21940667 -0.21082799\n",
      "  0.09086794 -0.31282747]\n",
      "New theta_0 : [-0.01653164 -0.08516887  0.11506092 -0.01628711  0.0923245  -0.18395411\n",
      "  0.32897561 -0.05777573 -0.32675845  0.23381475 -0.21943731 -0.21083017\n",
      "  0.09086727 -0.31283022]\n",
      "Training Error:  9.768723449024343\n",
      "====================================================================================================\n",
      "Iteration:  1043\n",
      "Previous theta :  [-0.01653164 -0.08516887  0.11506092 -0.01628711  0.0923245  -0.18395411\n",
      "  0.32897561 -0.05777573 -0.32675845  0.23381475 -0.21943731 -0.21083017\n",
      "  0.09086727 -0.31283022]\n",
      "New theta_0 : [-0.01653181 -0.0851715   0.11506578 -0.01627654  0.09232298 -0.18396063\n",
      "  0.32897108 -0.05777163 -0.32676088  0.23384353 -0.21946789 -0.21083235\n",
      "  0.0908666  -0.31283295]\n",
      "Training Error:  9.768721438184492\n",
      "====================================================================================================\n",
      "Iteration:  1044\n",
      "Previous theta :  [-0.01653181 -0.0851715   0.11506578 -0.01627654  0.09232298 -0.18396063\n",
      "  0.32897108 -0.05777163 -0.32676088  0.23384353 -0.21946789 -0.21083235\n",
      "  0.0908666  -0.31283295]\n",
      "New theta_0 : [-0.01653198 -0.08517412  0.11507063 -0.01626599  0.09232146 -0.18396711\n",
      "  0.32896657 -0.05776756 -0.32676329  0.23387223 -0.2194984  -0.21083452\n",
      "  0.09086593 -0.31283567]\n",
      "Training Error:  9.768719437619417\n",
      "====================================================================================================\n",
      "Iteration:  1045\n",
      "Previous theta :  [-0.01653198 -0.08517412  0.11507063 -0.01626599  0.09232146 -0.18396711\n",
      "  0.32896657 -0.05776756 -0.32676329  0.23387223 -0.2194984  -0.21083452\n",
      "  0.09086593 -0.31283567]\n",
      "New theta_0 : [-0.01653216 -0.08517674  0.11507545 -0.01625547  0.09231994 -0.18397356\n",
      "  0.32896208 -0.0577635  -0.32676567  0.23390086 -0.21952885 -0.21083667\n",
      "  0.09086527 -0.31283837]\n",
      "Training Error:  9.768717447271108\n",
      "====================================================================================================\n",
      "Iteration:  1046\n",
      "Previous theta :  [-0.01653216 -0.08517674  0.11507545 -0.01625547  0.09231994 -0.18397356\n",
      "  0.32896208 -0.0577635  -0.32676567  0.23390086 -0.21952885 -0.21083667\n",
      "  0.09086527 -0.31283837]\n",
      "New theta_0 : [-0.01653233 -0.08517934  0.11508026 -0.01624497  0.09231843 -0.18397996\n",
      "  0.32895761 -0.05775947 -0.32676803  0.23392941 -0.21955922 -0.21083882\n",
      "  0.09086461 -0.31284106]\n",
      "Training Error:  9.768715467081952\n",
      "====================================================================================================\n",
      "Iteration:  1047\n",
      "Previous theta :  [-0.01653233 -0.08517934  0.11508026 -0.01624497  0.09231843 -0.18397996\n",
      "  0.32895761 -0.05775947 -0.32676803  0.23392941 -0.21955922 -0.21083882\n",
      "  0.09086461 -0.31284106]\n",
      "New theta_0 : [-0.0165325  -0.08518193  0.11508505 -0.0162345   0.09231693 -0.18398632\n",
      "  0.32895317 -0.05775545 -0.32677036  0.23395789 -0.21958954 -0.21084095\n",
      "  0.09086396 -0.31284374]\n",
      "Training Error:  9.768713496994739\n",
      "====================================================================================================\n",
      "Iteration:  1048\n",
      "Previous theta :  [-0.0165325  -0.08518193  0.11508505 -0.0162345   0.09231693 -0.18398632\n",
      "  0.32895317 -0.05775545 -0.32677036  0.23395789 -0.21958954 -0.21084095\n",
      "  0.09086396 -0.31284374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01653267 -0.08518451  0.11508982 -0.01622404  0.09231542 -0.18399264\n",
      "  0.32894874 -0.05775144 -0.32677267  0.2339863  -0.21961978 -0.21084308\n",
      "  0.09086331 -0.3128464 ]\n",
      "Training Error:  9.76871153695264\n",
      "====================================================================================================\n",
      "Iteration:  1049\n",
      "Previous theta :  [-0.01653267 -0.08518451  0.11508982 -0.01622404  0.09231542 -0.18399264\n",
      "  0.32894874 -0.05775144 -0.32677267  0.2339863  -0.21961978 -0.21084308\n",
      "  0.09086331 -0.3128464 ]\n",
      "New theta_0 : [-0.01653285 -0.08518709  0.11509458 -0.01621362  0.09231392 -0.18399892\n",
      "  0.32894434 -0.05774746 -0.32677495  0.23401463 -0.21964996 -0.21084519\n",
      "  0.09086267 -0.31284905]\n",
      "Training Error:  9.768709586899236\n",
      "====================================================================================================\n",
      "Iteration:  1050\n",
      "Previous theta :  [-0.01653285 -0.08518709  0.11509458 -0.01621362  0.09231392 -0.18399892\n",
      "  0.32894434 -0.05774746 -0.32677495  0.23401463 -0.21964996 -0.21084519\n",
      "  0.09086267 -0.31284905]\n",
      "New theta_0 : [-0.01653302 -0.08518965  0.11509931 -0.01620321  0.09231242 -0.18400517\n",
      "  0.32893995 -0.05774349 -0.32677721  0.23404289 -0.21968007 -0.2108473\n",
      "  0.09086203 -0.31285168]\n",
      "Training Error:  9.768707646778477\n",
      "====================================================================================================\n",
      "Iteration:  1051\n",
      "Previous theta :  [-0.01653302 -0.08518965  0.11509931 -0.01620321  0.09231242 -0.18400517\n",
      "  0.32893995 -0.05774349 -0.32677721  0.23404289 -0.21968007 -0.2108473\n",
      "  0.09086203 -0.31285168]\n",
      "New theta_0 : [-0.01653319 -0.0851922   0.11510403 -0.01619283  0.09231093 -0.18401137\n",
      "  0.32893559 -0.05773954 -0.32677945  0.23407107 -0.21971011 -0.21084939\n",
      "  0.09086139 -0.3128543 ]\n",
      "Training Error:  9.76870571653471\n",
      "====================================================================================================\n",
      "Iteration:  1052\n",
      "Previous theta :  [-0.01653319 -0.0851922   0.11510403 -0.01619283  0.09231093 -0.18401137\n",
      "  0.32893559 -0.05773954 -0.32677945  0.23407107 -0.21971011 -0.21084939\n",
      "  0.09086139 -0.3128543 ]\n",
      "New theta_0 : [-0.01653336 -0.08519474  0.11510874 -0.01618248  0.09230944 -0.18401754\n",
      "  0.32893124 -0.05773561 -0.32678166  0.23409919 -0.21974009 -0.21085148\n",
      "  0.09086076 -0.31285691]\n",
      "Training Error:  9.768703796112645\n",
      "====================================================================================================\n",
      "Iteration:  1053\n",
      "Previous theta :  [-0.01653336 -0.08519474  0.11510874 -0.01618248  0.09230944 -0.18401754\n",
      "  0.32893124 -0.05773561 -0.32678166  0.23409919 -0.21974009 -0.21085148\n",
      "  0.09086076 -0.31285691]\n",
      "New theta_0 : [-0.01653354 -0.08519727  0.11511342 -0.01617214  0.09230795 -0.18402367\n",
      "  0.32892692 -0.05773169 -0.32678385  0.23412723 -0.21977    -0.21085356\n",
      "  0.09086013 -0.31285951]\n",
      "Training Error:  9.768701885457386\n",
      "====================================================================================================\n",
      "Iteration:  1054\n",
      "Previous theta :  [-0.01653354 -0.08519727  0.11511342 -0.01617214  0.09230795 -0.18402367\n",
      "  0.32892692 -0.05773169 -0.32678385  0.23412723 -0.21977    -0.21085356\n",
      "  0.09086013 -0.31285951]\n",
      "New theta_0 : [-0.01653371 -0.0851998   0.11511809 -0.01616183  0.09230647 -0.18402976\n",
      "  0.32892262 -0.05772779 -0.32678602  0.2341552  -0.21979985 -0.21085562\n",
      "  0.09085951 -0.31286209]\n",
      "Training Error:  9.768699984514404\n",
      "====================================================================================================\n",
      "Iteration:  1055\n",
      "Previous theta :  [-0.01653371 -0.0851998   0.11511809 -0.01616183  0.09230647 -0.18402976\n",
      "  0.32892262 -0.05772779 -0.32678602  0.2341552  -0.21979985 -0.21085562\n",
      "  0.09085951 -0.31286209]\n",
      "New theta_0 : [-0.01653388 -0.08520231  0.11512274 -0.01615155  0.09230499 -0.18403581\n",
      "  0.32891833 -0.05772391 -0.32678816  0.23418309 -0.21982963 -0.21085768\n",
      "  0.09085889 -0.31286466]\n",
      "Training Error:  9.768698093229526\n",
      "====================================================================================================\n",
      "Iteration:  1056\n",
      "Previous theta :  [-0.01653388 -0.08520231  0.11512274 -0.01615155  0.09230499 -0.18403581\n",
      "  0.32891833 -0.05772391 -0.32678816  0.23418309 -0.21982963 -0.21085768\n",
      "  0.09085889 -0.31286466]\n",
      "New theta_0 : [-0.01653406 -0.08520481  0.11512737 -0.01614129  0.09230351 -0.18404183\n",
      "  0.32891407 -0.05772005 -0.32679028  0.23421092 -0.21985934 -0.21085972\n",
      "  0.09085827 -0.31286722]\n",
      "Training Error:  9.768696211548967\n",
      "====================================================================================================\n",
      "Iteration:  1057\n",
      "Previous theta :  [-0.01653406 -0.08520481  0.11512737 -0.01614129  0.09230351 -0.18404183\n",
      "  0.32891407 -0.05772005 -0.32679028  0.23421092 -0.21985934 -0.21085972\n",
      "  0.09085827 -0.31286722]\n",
      "New theta_0 : [-0.01653423 -0.0852073   0.11513199 -0.01613105  0.09230204 -0.18404781\n",
      "  0.32890983 -0.0577162  -0.32679237  0.23423867 -0.21988899 -0.21086176\n",
      "  0.09085766 -0.31286976]\n",
      "Training Error:  9.768694339419293\n",
      "====================================================================================================\n",
      "Iteration:  1058\n",
      "Previous theta :  [-0.01653423 -0.0852073   0.11513199 -0.01613105  0.09230204 -0.18404781\n",
      "  0.32890983 -0.0577162  -0.32679237  0.23423867 -0.21988899 -0.21086176\n",
      "  0.09085766 -0.31286976]\n",
      "New theta_0 : [-0.0165344  -0.08520979  0.11513659 -0.01612083  0.09230057 -0.18405375\n",
      "  0.3289056  -0.05771237 -0.32679445  0.23426635 -0.21991857 -0.21086379\n",
      "  0.09085705 -0.31287229]\n",
      "Training Error:  9.768692476787427\n",
      "====================================================================================================\n",
      "Iteration:  1059\n",
      "Previous theta :  [-0.0165344  -0.08520979  0.11513659 -0.01612083  0.09230057 -0.18405375\n",
      "  0.3289056  -0.05771237 -0.32679445  0.23426635 -0.21991857 -0.21086379\n",
      "  0.09085705 -0.31287229]\n",
      "New theta_0 : [-0.01653457 -0.08521226  0.11514117 -0.01611064  0.0922991  -0.18405966\n",
      "  0.3289014  -0.05770855 -0.3267965   0.23429396 -0.21994809 -0.2108658\n",
      "  0.09085645 -0.31287481]\n",
      "Training Error:  9.768690623600659\n",
      "====================================================================================================\n",
      "Iteration:  1060\n",
      "Previous theta :  [-0.01653457 -0.08521226  0.11514117 -0.01611064  0.0922991  -0.18405966\n",
      "  0.3289014  -0.05770855 -0.3267965   0.23429396 -0.21994809 -0.2108658\n",
      "  0.09085645 -0.31287481]\n",
      "New theta_0 : [-0.01653475 -0.08521472  0.11514574 -0.01610047  0.09229764 -0.18406553\n",
      "  0.32889721 -0.05770476 -0.32679853  0.2343215  -0.21997754 -0.21086781\n",
      "  0.09085585 -0.31287732]\n",
      "Training Error:  9.768688779806622\n",
      "====================================================================================================\n",
      "Iteration:  1061\n",
      "Previous theta :  [-0.01653475 -0.08521472  0.11514574 -0.01610047  0.09229764 -0.18406553\n",
      "  0.32889721 -0.05770476 -0.32679853  0.2343215  -0.21997754 -0.21086781\n",
      "  0.09085585 -0.31287732]\n",
      "New theta_0 : [-0.01653492 -0.08521718  0.11515029 -0.01609033  0.09229618 -0.18407136\n",
      "  0.32889305 -0.05770097 -0.32680053  0.23434897 -0.22000693 -0.21086981\n",
      "  0.09085525 -0.31287981]\n",
      "Training Error:  9.768686945353302\n",
      "====================================================================================================\n",
      "Iteration:  1062\n",
      "Previous theta :  [-0.01653492 -0.08521718  0.11515029 -0.01609033  0.09229618 -0.18407136\n",
      "  0.32889305 -0.05770097 -0.32680053  0.23434897 -0.22000693 -0.21086981\n",
      "  0.09085525 -0.31287981]\n",
      "New theta_0 : [-0.01653509 -0.08521962  0.11515482 -0.01608021  0.09229473 -0.18407716\n",
      "  0.3288889  -0.05769721 -0.32680252  0.23437637 -0.22003625 -0.2108718\n",
      "  0.09085466 -0.31288229]\n",
      "Training Error:  9.768685120189035\n",
      "====================================================================================================\n",
      "Iteration:  1063\n",
      "Previous theta :  [-0.01653509 -0.08521962  0.11515482 -0.01608021  0.09229473 -0.18407716\n",
      "  0.3288889  -0.05769721 -0.32680252  0.23437637 -0.22003625 -0.2108718\n",
      "  0.09085466 -0.31288229]\n",
      "New theta_0 : [-0.01653527 -0.08522206  0.11515934 -0.01607011  0.09229327 -0.18408293\n",
      "  0.32888477 -0.05769346 -0.32680448  0.23440369 -0.22006551 -0.21087378\n",
      "  0.09085407 -0.31288476]\n",
      "Training Error:  9.768683304262504\n",
      "====================================================================================================\n",
      "Iteration:  1064\n",
      "Previous theta :  [-0.01653527 -0.08522206  0.11515934 -0.01607011  0.09229327 -0.18408293\n",
      "  0.32888477 -0.05769346 -0.32680448  0.23440369 -0.22006551 -0.21087378\n",
      "  0.09085407 -0.31288476]\n",
      "New theta_0 : [-0.01653544 -0.08522448  0.11516384 -0.01606004  0.09229182 -0.18408865\n",
      "  0.32888066 -0.05768973 -0.32680643  0.23443095 -0.2200947  -0.21087575\n",
      "  0.09085349 -0.31288721]\n",
      "Training Error:  9.768681497522723\n",
      "====================================================================================================\n",
      "Iteration:  1065\n",
      "Previous theta :  [-0.01653544 -0.08522448  0.11516384 -0.01606004  0.09229182 -0.18408865\n",
      "  0.32888066 -0.05768973 -0.32680643  0.23443095 -0.2200947  -0.21087575\n",
      "  0.09085349 -0.31288721]\n",
      "New theta_0 : [-0.01653561 -0.0852269   0.11516832 -0.01604999  0.09229038 -0.18409434\n",
      "  0.32887657 -0.05768601 -0.32680835  0.23445814 -0.22012383 -0.21087771\n",
      "  0.0908529  -0.31288966]\n",
      "Training Error:  9.768679699919051\n",
      "====================================================================================================\n",
      "Iteration:  1066\n",
      "Previous theta :  [-0.01653561 -0.0852269   0.11516832 -0.01604999  0.09229038 -0.18409434\n",
      "  0.32887657 -0.05768601 -0.32680835  0.23445814 -0.22012383 -0.21087771\n",
      "  0.0908529  -0.31288966]\n",
      "New theta_0 : [-0.01653579 -0.08522931  0.11517279 -0.01603996  0.09228894 -0.1841\n",
      "  0.3288725  -0.05768231 -0.32681025  0.23448525 -0.22015289 -0.21087966\n",
      "  0.09085233 -0.31289209]\n",
      "Training Error:  9.768677911401188\n",
      "====================================================================================================\n",
      "Iteration:  1067\n",
      "Previous theta :  [-0.01653579 -0.08522931  0.11517279 -0.01603996  0.09228894 -0.1841\n",
      "  0.3288725  -0.05768231 -0.32681025  0.23448525 -0.22015289 -0.21087966\n",
      "  0.09085233 -0.31289209]\n",
      "New theta_0 : [-0.01653596 -0.0852317   0.11517724 -0.01602995  0.0922875  -0.18410562\n",
      "  0.32886845 -0.05767862 -0.32681212  0.2345123  -0.22018189 -0.2108816\n",
      "  0.09085175 -0.31289451]\n",
      "Training Error:  9.76867613191915\n",
      "====================================================================================================\n",
      "Iteration:  1068\n",
      "Previous theta :  [-0.01653596 -0.0852317   0.11517724 -0.01602995  0.0922875  -0.18410562\n",
      "  0.32886845 -0.05767862 -0.32681212  0.2345123  -0.22018189 -0.2108816\n",
      "  0.09085175 -0.31289451]\n",
      "New theta_0 : [-0.01653613 -0.08523409  0.11518168 -0.01601997  0.09228606 -0.18411121\n",
      "  0.32886442 -0.05767495 -0.32681398  0.23453928 -0.22021082 -0.21088354\n",
      "  0.09085118 -0.31289692]\n",
      "Training Error:  9.768674361423296\n",
      "====================================================================================================\n",
      "Iteration:  1069\n",
      "Previous theta :  [-0.01653613 -0.08523409  0.11518168 -0.01601997  0.09228606 -0.18411121\n",
      "  0.32886442 -0.05767495 -0.32681398  0.23453928 -0.22021082 -0.21088354\n",
      "  0.09085118 -0.31289692]\n",
      "New theta_0 : [-0.0165363  -0.08523647  0.1151861  -0.01601001  0.09228463 -0.18411677\n",
      "  0.3288604  -0.0576713  -0.32681582  0.23456619 -0.22023969 -0.21088546\n",
      "  0.09085062 -0.31289931]\n",
      "Training Error:  9.768672599864303\n",
      "====================================================================================================\n",
      "Iteration:  1070\n",
      "Previous theta :  [-0.0165363  -0.08523647  0.1151861  -0.01601001  0.09228463 -0.18411677\n",
      "  0.3288604  -0.0576713  -0.32681582  0.23456619 -0.22023969 -0.21088546\n",
      "  0.09085062 -0.31289931]\n",
      "New theta_0 : [-0.01653648 -0.08523884  0.1151905  -0.01600008  0.0922832  -0.18412229\n",
      "  0.32885641 -0.05766766 -0.32681764  0.23459303 -0.2202685  -0.21088737\n",
      "  0.09085005 -0.3129017 ]\n",
      "Training Error:  9.768670847193185\n",
      "====================================================================================================\n",
      "Iteration:  1071\n",
      "Previous theta :  [-0.01653648 -0.08523884  0.1151905  -0.01600008  0.0922832  -0.18412229\n",
      "  0.32885641 -0.05766766 -0.32681764  0.23459303 -0.2202685  -0.21088737\n",
      "  0.09085005 -0.3129017 ]\n",
      "New theta_0 : [-0.01653665 -0.08524121  0.11519489 -0.01599016  0.09228177 -0.18412777\n",
      "  0.32885243 -0.05766404 -0.32681943  0.2346198  -0.22029724 -0.21088928\n",
      "  0.09084949 -0.31290407]\n",
      "Training Error:  9.768669103361256\n",
      "====================================================================================================\n",
      "Iteration:  1072\n",
      "Previous theta :  [-0.01653665 -0.08524121  0.11519489 -0.01599016  0.09228177 -0.18412777\n",
      "  0.32885243 -0.05766404 -0.32681943  0.2346198  -0.22029724 -0.21088928\n",
      "  0.09084949 -0.31290407]\n",
      "New theta_0 : [-0.01653682 -0.08524356  0.11519927 -0.01598027  0.09228035 -0.18413323\n",
      "  0.32884847 -0.05766043 -0.32682121  0.2346465  -0.22032592 -0.21089118\n",
      "  0.09084894 -0.31290643]\n",
      "Training Error:  9.768667368320168\n",
      "====================================================================================================\n",
      "Iteration:  1073\n",
      "Previous theta :  [-0.01653682 -0.08524356  0.11519927 -0.01598027  0.09228035 -0.18413323\n",
      "  0.32884847 -0.05766043 -0.32682121  0.2346465  -0.22032592 -0.21089118\n",
      "  0.09084894 -0.31290643]\n",
      "New theta_0 : [-0.016537   -0.0852459   0.11520362 -0.01597041  0.09227893 -0.18413864\n",
      "  0.32884452 -0.05765684 -0.32682297  0.23467313 -0.22035453 -0.21089307\n",
      "  0.09084839 -0.31290878]\n",
      "Training Error:  9.76866564202188\n",
      "====================================================================================================\n",
      "Iteration:  1074\n",
      "Previous theta :  [-0.016537   -0.0852459   0.11520362 -0.01597041  0.09227893 -0.18413864\n",
      "  0.32884452 -0.05765684 -0.32682297  0.23467313 -0.22035453 -0.21089307\n",
      "  0.09084839 -0.31290878]\n",
      "New theta_0 : [-0.01653717 -0.08524824  0.11520796 -0.01596056  0.09227752 -0.18414403\n",
      "  0.3288406  -0.05765327 -0.32682471  0.2346997  -0.22038309 -0.21089495\n",
      "  0.09084784 -0.31291111]\n",
      "Training Error:  9.768663924418663\n",
      "====================================================================================================\n",
      "Iteration:  1075\n",
      "Previous theta :  [-0.01653717 -0.08524824  0.11520796 -0.01596056  0.09227752 -0.18414403\n",
      "  0.3288406  -0.05765327 -0.32682471  0.2346997  -0.22038309 -0.21089495\n",
      "  0.09084784 -0.31291111]\n",
      "New theta_0 : [-0.01653734 -0.08525056  0.11521229 -0.01595074  0.0922761  -0.18414938\n",
      "  0.32883669 -0.05764971 -0.32682642  0.23472619 -0.22041157 -0.21089682\n",
      "  0.09084729 -0.31291344]\n",
      "Training Error:  9.768662215463095\n",
      "====================================================================================================\n",
      "Iteration:  1076\n",
      "Previous theta :  [-0.01653734 -0.08525056  0.11521229 -0.01595074  0.0922761  -0.18414938\n",
      "  0.32883669 -0.05764971 -0.32682642  0.23472619 -0.22041157 -0.21089682\n",
      "  0.09084729 -0.31291344]\n",
      "New theta_0 : [-0.01653752 -0.08525288  0.1152166  -0.01594094  0.09227469 -0.1841547\n",
      "  0.3288328  -0.05764616 -0.32682812  0.23475262 -0.22044    -0.21089868\n",
      "  0.09084675 -0.31291575]\n",
      "Training Error:  9.768660515108069\n",
      "====================================================================================================\n",
      "Iteration:  1077\n",
      "Previous theta :  [-0.01653752 -0.08525288  0.1152166  -0.01594094  0.09227469 -0.1841547\n",
      "  0.3288328  -0.05764616 -0.32682812  0.23475262 -0.22044    -0.21089868\n",
      "  0.09084675 -0.31291575]\n",
      "New theta_0 : [-0.01653769 -0.08525519  0.1152209  -0.01593117  0.09227329 -0.18415999\n",
      "  0.32882893 -0.05764263 -0.3268298   0.23477898 -0.22046836 -0.21090053\n",
      "  0.09084621 -0.31291805]\n",
      "Training Error:  9.768658823306781\n",
      "====================================================================================================\n",
      "Iteration:  1078\n",
      "Previous theta :  [-0.01653769 -0.08525519  0.1152209  -0.01593117  0.09227329 -0.18415999\n",
      "  0.32882893 -0.05764263 -0.3268298   0.23477898 -0.22046836 -0.21090053\n",
      "  0.09084621 -0.31291805]\n",
      "New theta_0 : [-0.01653786 -0.08525749  0.11522518 -0.01592142  0.09227188 -0.18416525\n",
      "  0.32882508 -0.05763912 -0.32683146  0.23480528 -0.22049665 -0.21090238\n",
      "  0.09084568 -0.31292034]\n",
      "Training Error:  9.768657140012724\n",
      "====================================================================================================\n",
      "Iteration:  1079\n",
      "Previous theta :  [-0.01653786 -0.08525749  0.11522518 -0.01592142  0.09227188 -0.18416525\n",
      "  0.32882508 -0.05763912 -0.32683146  0.23480528 -0.22049665 -0.21090238\n",
      "  0.09084568 -0.31292034]\n",
      "New theta_0 : [-0.01653803 -0.08525978  0.11522944 -0.01591169  0.09227048 -0.18417047\n",
      "  0.32882124 -0.05763562 -0.3268331   0.2348315  -0.22052489 -0.21090421\n",
      "  0.09084515 -0.31292262]\n",
      "Training Error:  9.768655465179695\n",
      "====================================================================================================\n",
      "Iteration:  1080\n",
      "Previous theta :  [-0.01653803 -0.08525978  0.11522944 -0.01591169  0.09227048 -0.18417047\n",
      "  0.32882124 -0.05763562 -0.3268331   0.2348315  -0.22052489 -0.21090421\n",
      "  0.09084515 -0.31292262]\n",
      "New theta_0 : [-0.01653821 -0.08526206  0.11523369 -0.01590198  0.09226909 -0.18417567\n",
      "  0.32881742 -0.05763213 -0.32683472  0.23485766 -0.22055306 -0.21090604\n",
      "  0.09084462 -0.31292489]\n",
      "Training Error:  9.768653798761788\n",
      "====================================================================================================\n",
      "Iteration:  1081\n",
      "Previous theta :  [-0.01653821 -0.08526206  0.11523369 -0.01590198  0.09226909 -0.18417567\n",
      "  0.32881742 -0.05763213 -0.32683472  0.23485766 -0.22055306 -0.21090604\n",
      "  0.09084462 -0.31292489]\n",
      "New theta_0 : [-0.01653838 -0.08526433  0.11523793 -0.01589229  0.0922677  -0.18418083\n",
      "  0.32881362 -0.05762866 -0.32683633  0.23488376 -0.22058117 -0.21090786\n",
      "  0.09084409 -0.31292715]\n",
      "Training Error:  9.76865214071339\n",
      "====================================================================================================\n",
      "Iteration:  1082\n",
      "Previous theta :  [-0.01653838 -0.08526433  0.11523793 -0.01589229  0.0922677  -0.18418083\n",
      "  0.32881362 -0.05762866 -0.32683633  0.23488376 -0.22058117 -0.21090786\n",
      "  0.09084409 -0.31292715]\n",
      "New theta_0 : [-0.01653855 -0.0852666   0.11524215 -0.01588263  0.09226631 -0.18418596\n",
      "  0.32880983 -0.05762521 -0.32683791  0.23490978 -0.22060921 -0.21090967\n",
      "  0.09084357 -0.3129294 ]\n",
      "Training Error:  9.768650490989184\n",
      "====================================================================================================\n",
      "Iteration:  1083\n",
      "Previous theta :  [-0.01653855 -0.0852666   0.11524215 -0.01588263  0.09226631 -0.18418596\n",
      "  0.32880983 -0.05762521 -0.32683791  0.23490978 -0.22060921 -0.21090967\n",
      "  0.09084357 -0.3129294 ]\n",
      "New theta_0 : [-0.01653872 -0.08526886  0.11524635 -0.01587299  0.09226492 -0.18419105\n",
      "  0.32880606 -0.05762177 -0.32683948  0.23493574 -0.2206372  -0.21091147\n",
      "  0.09084305 -0.31293163]\n",
      "Training Error:  9.768648849544137\n",
      "====================================================================================================\n",
      "Iteration:  1084\n",
      "Previous theta :  [-0.01653872 -0.08526886  0.11524635 -0.01587299  0.09226492 -0.18419105\n",
      "  0.32880606 -0.05762177 -0.32683948  0.23493574 -0.2206372  -0.21091147\n",
      "  0.09084305 -0.31293163]\n",
      "New theta_0 : [-0.0165389  -0.0852711   0.11525055 -0.01586337  0.09226354 -0.18419612\n",
      "  0.32880231 -0.05761834 -0.32684103  0.23496163 -0.22066512 -0.21091327\n",
      "  0.09084254 -0.31293386]\n",
      "Training Error:  9.768647216333507\n",
      "====================================================================================================\n",
      "Iteration:  1085\n",
      "Previous theta :  [-0.0165389  -0.0852711   0.11525055 -0.01586337  0.09226354 -0.18419612\n",
      "  0.32880231 -0.05761834 -0.32684103  0.23496163 -0.22066512 -0.21091327\n",
      "  0.09084254 -0.31293386]\n",
      "New theta_0 : [-0.01653907 -0.08527334  0.11525472 -0.01585378  0.09226216 -0.18420116\n",
      "  0.32879858 -0.05761493 -0.32684256  0.23498746 -0.22069297 -0.21091505\n",
      "  0.09084203 -0.31293607]\n",
      "Training Error:  9.768645591312834\n",
      "====================================================================================================\n",
      "Iteration:  1086\n",
      "Previous theta :  [-0.01653907 -0.08527334  0.11525472 -0.01585378  0.09226216 -0.18420116\n",
      "  0.32879858 -0.05761493 -0.32684256  0.23498746 -0.22069297 -0.21091505\n",
      "  0.09084203 -0.31293607]\n",
      "New theta_0 : [-0.01653924 -0.08527558  0.11525888 -0.01584421  0.09226078 -0.18420616\n",
      "  0.32879486 -0.05761153 -0.32684407  0.23501322 -0.22072077 -0.21091683\n",
      "  0.09084152 -0.31293827]\n",
      "Training Error:  9.768643974437948\n",
      "====================================================================================================\n",
      "Iteration:  1087\n",
      "Previous theta :  [-0.01653924 -0.08527558  0.11525888 -0.01584421  0.09226078 -0.18420616\n",
      "  0.32879486 -0.05761153 -0.32684407  0.23501322 -0.22072077 -0.21091683\n",
      "  0.09084152 -0.31293827]\n",
      "New theta_0 : [-0.01653941 -0.0852778   0.11526303 -0.01583466  0.09225941 -0.18421114\n",
      "  0.32879116 -0.05760815 -0.32684557  0.23503892 -0.2207485  -0.2109186\n",
      "  0.09084101 -0.31294046]\n",
      "Training Error:  9.76864236566495\n",
      "====================================================================================================\n",
      "Iteration:  1088\n",
      "Previous theta :  [-0.01653941 -0.0852778   0.11526303 -0.01583466  0.09225941 -0.18421114\n",
      "  0.32879116 -0.05760815 -0.32684557  0.23503892 -0.2207485  -0.2109186\n",
      "  0.09084101 -0.31294046]\n",
      "New theta_0 : [-0.01653959 -0.08528001  0.11526716 -0.01582513  0.09225803 -0.18421608\n",
      "  0.32878747 -0.05760478 -0.32684705  0.23506455 -0.22077618 -0.21092036\n",
      "  0.09084051 -0.31294264]\n",
      "Training Error:  9.768640764950224\n",
      "====================================================================================================\n",
      "Iteration:  1089\n",
      "Previous theta :  [-0.01653959 -0.08528001  0.11526716 -0.01582513  0.09225803 -0.18421608\n",
      "  0.32878747 -0.05760478 -0.32684705  0.23506455 -0.22077618 -0.21092036\n",
      "  0.09084051 -0.31294264]\n",
      "New theta_0 : [-0.01653976 -0.08528222  0.11527128 -0.01581562  0.09225667 -0.184221\n",
      "  0.3287838  -0.05760142 -0.32684851  0.23509011 -0.22080379 -0.21092212\n",
      "  0.09084001 -0.31294481]\n",
      "Training Error:  9.76863917225043\n",
      "====================================================================================================\n",
      "Iteration:  1090\n",
      "Previous theta :  [-0.01653976 -0.08528222  0.11527128 -0.01581562  0.09225667 -0.184221\n",
      "  0.3287838  -0.05760142 -0.32684851  0.23509011 -0.22080379 -0.21092212\n",
      "  0.09084001 -0.31294481]\n",
      "New theta_0 : [-0.01653993 -0.08528442  0.11527538 -0.01580614  0.0922553  -0.18422588\n",
      "  0.32878015 -0.05759808 -0.32684995  0.23511561 -0.22083133 -0.21092386\n",
      "  0.09083952 -0.31294697]\n",
      "Training Error:  9.768637587522496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  1091\n",
      "Previous theta :  [-0.01653993 -0.08528442  0.11527538 -0.01580614  0.0922553  -0.18422588\n",
      "  0.32878015 -0.05759808 -0.32684995  0.23511561 -0.22083133 -0.21092386\n",
      "  0.09083952 -0.31294697]\n",
      "New theta_0 : [-0.0165401  -0.08528661  0.11527947 -0.01579668  0.09225394 -0.18423074\n",
      "  0.32877652 -0.05759476 -0.32685138  0.23514104 -0.22085882 -0.2109256\n",
      "  0.09083902 -0.31294912]\n",
      "Training Error:  9.768636010723629\n",
      "====================================================================================================\n",
      "Iteration:  1092\n",
      "Previous theta :  [-0.0165401  -0.08528661  0.11527947 -0.01579668  0.09225394 -0.18423074\n",
      "  0.32877652 -0.05759476 -0.32685138  0.23514104 -0.22085882 -0.2109256\n",
      "  0.09083902 -0.31294912]\n",
      "New theta_0 : [-0.01654028 -0.08528879  0.11528355 -0.01578724  0.09225258 -0.18423557\n",
      "  0.3287729  -0.05759144 -0.32685279  0.23516641 -0.22088625 -0.21092733\n",
      "  0.09083854 -0.31295126]\n",
      "Training Error:  9.7686344418113\n",
      "====================================================================================================\n",
      "Iteration:  1093\n",
      "Previous theta :  [-0.01654028 -0.08528879  0.11528355 -0.01578724  0.09225258 -0.18423557\n",
      "  0.3287729  -0.05759144 -0.32685279  0.23516641 -0.22088625 -0.21092733\n",
      "  0.09083854 -0.31295126]\n",
      "New theta_0 : [-0.01654045 -0.08529096  0.11528761 -0.01577782  0.09225123 -0.18424036\n",
      "  0.32876929 -0.05758815 -0.32685418  0.23519172 -0.22091361 -0.21092905\n",
      "  0.09083805 -0.31295339]\n",
      "Training Error:  9.768632880743247\n",
      "====================================================================================================\n",
      "Iteration:  1094\n",
      "Previous theta :  [-0.01654045 -0.08529096  0.11528761 -0.01577782  0.09225123 -0.18424036\n",
      "  0.32876929 -0.05758815 -0.32685418  0.23519172 -0.22091361 -0.21092905\n",
      "  0.09083805 -0.31295339]\n",
      "New theta_0 : [-0.01654062 -0.08529313  0.11529166 -0.01576843  0.09224988 -0.18424513\n",
      "  0.3287657  -0.05758486 -0.32685556  0.23521696 -0.22094091 -0.21093076\n",
      "  0.09083757 -0.31295551]\n",
      "Training Error:  9.768631327477474\n",
      "====================================================================================================\n",
      "Iteration:  1095\n",
      "Previous theta :  [-0.01654062 -0.08529313  0.11529166 -0.01576843  0.09224988 -0.18424513\n",
      "  0.3287657  -0.05758486 -0.32685556  0.23521696 -0.22094091 -0.21093076\n",
      "  0.09083757 -0.31295551]\n",
      "New theta_0 : [-0.01654079 -0.08529529  0.11529569 -0.01575905  0.09224853 -0.18424987\n",
      "  0.32876213 -0.05758159 -0.32685692  0.23524213 -0.22096815 -0.21093247\n",
      "  0.09083709 -0.31295762]\n",
      "Training Error:  9.768629781972246\n",
      "====================================================================================================\n",
      "Iteration:  1096\n",
      "Previous theta :  [-0.01654079 -0.08529529  0.11529569 -0.01575905  0.09224853 -0.18424987\n",
      "  0.32876213 -0.05758159 -0.32685692  0.23524213 -0.22096815 -0.21093247\n",
      "  0.09083709 -0.31295762]\n",
      "New theta_0 : [-0.01654096 -0.08529744  0.11529971 -0.0157497   0.09224719 -0.18425458\n",
      "  0.32875858 -0.05757833 -0.32685826  0.23526725 -0.22099533 -0.21093416\n",
      "  0.09083661 -0.31295972]\n",
      "Training Error:  9.768628244186091\n",
      "====================================================================================================\n",
      "Iteration:  1097\n",
      "Previous theta :  [-0.01654096 -0.08529744  0.11529971 -0.0157497   0.09224719 -0.18425458\n",
      "  0.32875858 -0.05757833 -0.32685826  0.23526725 -0.22099533 -0.21093416\n",
      "  0.09083661 -0.31295972]\n",
      "New theta_0 : [-0.01654114 -0.08529958  0.11530371 -0.01574038  0.09224584 -0.18425926\n",
      "  0.32875503 -0.05757509 -0.32685959  0.23529229 -0.22102245 -0.21093585\n",
      "  0.09083613 -0.31296181]\n",
      "Training Error:  9.768626714077795\n",
      "====================================================================================================\n",
      "Iteration:  1098\n",
      "Previous theta :  [-0.01654114 -0.08529958  0.11530371 -0.01574038  0.09224584 -0.18425926\n",
      "  0.32875503 -0.05757509 -0.32685959  0.23529229 -0.22102245 -0.21093585\n",
      "  0.09083613 -0.31296181]\n",
      "New theta_0 : [-0.01654131 -0.08530172  0.1153077  -0.01573107  0.0922445  -0.18426392\n",
      "  0.32875151 -0.05757186 -0.3268609   0.23531728 -0.22104951 -0.21093754\n",
      "  0.09083566 -0.31296388]\n",
      "Training Error:  9.768625191606393\n",
      "====================================================================================================\n",
      "Iteration:  1099\n",
      "Previous theta :  [-0.01654131 -0.08530172  0.1153077  -0.01573107  0.0922445  -0.18426392\n",
      "  0.32875151 -0.05757186 -0.3268609   0.23531728 -0.22104951 -0.21093754\n",
      "  0.09083566 -0.31296388]\n",
      "New theta_0 : [-0.01654148 -0.08530384  0.11531168 -0.01572178  0.09224317 -0.18426854\n",
      "  0.328748   -0.05756864 -0.32686219  0.2353422  -0.22107651 -0.21093921\n",
      "  0.09083519 -0.31296595]\n",
      "Training Error:  9.768623676731181\n",
      "====================================================================================================\n",
      "Iteration:  1100\n",
      "Previous theta :  [-0.01654148 -0.08530384  0.11531168 -0.01572178  0.09224317 -0.18426854\n",
      "  0.328748   -0.05756864 -0.32686219  0.2353422  -0.22107651 -0.21093921\n",
      "  0.09083519 -0.31296595]\n",
      "New theta_0 : [-0.01654165 -0.08530596  0.11531564 -0.01571252  0.09224184 -0.18427314\n",
      "  0.3287445  -0.05756544 -0.32686347  0.23536705 -0.22110345 -0.21094088\n",
      "  0.09083473 -0.31296801]\n",
      "Training Error:  9.76862216941171\n",
      "====================================================================================================\n",
      "Iteration:  1101\n",
      "Previous theta :  [-0.01654165 -0.08530596  0.11531564 -0.01571252  0.09224184 -0.18427314\n",
      "  0.3287445  -0.05756544 -0.32686347  0.23536705 -0.22110345 -0.21094088\n",
      "  0.09083473 -0.31296801]\n",
      "New theta_0 : [-0.01654182 -0.08530807  0.11531959 -0.01570328  0.09224051 -0.18427771\n",
      "  0.32874103 -0.05756225 -0.32686474  0.23539185 -0.22113032 -0.21094254\n",
      "  0.09083427 -0.31297006]\n",
      "Training Error:  9.768620669607774\n",
      "====================================================================================================\n",
      "Iteration:  1102\n",
      "Previous theta :  [-0.01654182 -0.08530807  0.11531959 -0.01570328  0.09224051 -0.18427771\n",
      "  0.32874103 -0.05756225 -0.32686474  0.23539185 -0.22113032 -0.21094254\n",
      "  0.09083427 -0.31297006]\n",
      "New theta_0 : [-0.01654199 -0.08531018  0.11532353 -0.01569406  0.09223918 -0.18428226\n",
      "  0.32873756 -0.05755907 -0.32686599  0.23541658 -0.22115714 -0.21094419\n",
      "  0.09083381 -0.3129721 ]\n",
      "Training Error:  9.768619177279415\n",
      "====================================================================================================\n",
      "Iteration:  1103\n",
      "Previous theta :  [-0.01654199 -0.08531018  0.11532353 -0.01569406  0.09223918 -0.18428226\n",
      "  0.32873756 -0.05755907 -0.32686599  0.23541658 -0.22115714 -0.21094419\n",
      "  0.09083381 -0.3129721 ]\n",
      "New theta_0 : [-0.01654216 -0.08531227  0.11532745 -0.01568486  0.09223786 -0.18428677\n",
      "  0.32873411 -0.05755591 -0.32686722  0.23544125 -0.2211839  -0.21094583\n",
      "  0.09083335 -0.31297412]\n",
      "Training Error:  9.76861769238693\n",
      "====================================================================================================\n",
      "Iteration:  1104\n",
      "Previous theta :  [-0.01654216 -0.08531227  0.11532745 -0.01568486  0.09223786 -0.18428677\n",
      "  0.32873411 -0.05755591 -0.32686722  0.23544125 -0.2211839  -0.21094583\n",
      "  0.09083335 -0.31297412]\n",
      "New theta_0 : [-0.01654234 -0.08531436  0.11533136 -0.01567568  0.09223654 -0.18429126\n",
      "  0.32873068 -0.05755276 -0.32686844  0.23546585 -0.22121059 -0.21094747\n",
      "  0.0908329  -0.31297614]\n",
      "Training Error:  9.768616214890848\n",
      "====================================================================================================\n",
      "Iteration:  1105\n",
      "Previous theta :  [-0.01654234 -0.08531436  0.11533136 -0.01567568  0.09223654 -0.18429126\n",
      "  0.32873068 -0.05755276 -0.32686844  0.23546585 -0.22121059 -0.21094747\n",
      "  0.0908329  -0.31297614]\n",
      "New theta_0 : [-0.01654251 -0.08531644  0.11533526 -0.01566653  0.09223522 -0.18429572\n",
      "  0.32872726 -0.05754962 -0.32686964  0.2354904  -0.22123723 -0.2109491\n",
      "  0.09083245 -0.31297815]\n",
      "Training Error:  9.76861474475195\n",
      "====================================================================================================\n",
      "Iteration:  1106\n",
      "Previous theta :  [-0.01654251 -0.08531644  0.11533526 -0.01566653  0.09223522 -0.18429572\n",
      "  0.32872726 -0.05754962 -0.32686964  0.2354904  -0.22123723 -0.2109491\n",
      "  0.09083245 -0.31297815]\n",
      "New theta_0 : [-0.01654268 -0.08531851  0.11533914 -0.0156574   0.09223391 -0.18430016\n",
      "  0.32872386 -0.0575465  -0.32687083  0.23551488 -0.2212638  -0.21095072\n",
      "  0.090832   -0.31298015]\n",
      "Training Error:  9.768613281931252\n",
      "====================================================================================================\n",
      "Iteration:  1107\n",
      "Previous theta :  [-0.01654268 -0.08531851  0.11533914 -0.0156574   0.09223391 -0.18430016\n",
      "  0.32872386 -0.0575465  -0.32687083  0.23551488 -0.2212638  -0.21095072\n",
      "  0.090832   -0.31298015]\n",
      "New theta_0 : [-0.01654285 -0.08532058  0.11534301 -0.01564828  0.0922326  -0.18430456\n",
      "  0.32872047 -0.05754339 -0.326872    0.2355393  -0.22129032 -0.21095233\n",
      "  0.09083155 -0.31298214]\n",
      "Training Error:  9.76861182639001\n",
      "====================================================================================================\n",
      "Iteration:  1108\n",
      "Previous theta :  [-0.01654285 -0.08532058  0.11534301 -0.01564828  0.0922326  -0.18430456\n",
      "  0.32872047 -0.05754339 -0.326872    0.2355393  -0.22129032 -0.21095233\n",
      "  0.09083155 -0.31298214]\n",
      "New theta_0 : [-0.01654302 -0.08532264  0.11534687 -0.01563919  0.09223129 -0.18430894\n",
      "  0.32871709 -0.05754029 -0.32687316  0.23556365 -0.22131678 -0.21095394\n",
      "  0.09083111 -0.31298412]\n",
      "Training Error:  9.768610378089717\n",
      "====================================================================================================\n",
      "Iteration:  1109\n",
      "Previous theta :  [-0.01654302 -0.08532264  0.11534687 -0.01563919  0.09223129 -0.18430894\n",
      "  0.32871709 -0.05754029 -0.32687316  0.23556365 -0.22131678 -0.21095394\n",
      "  0.09083111 -0.31298412]\n",
      "New theta_0 : [-0.01654319 -0.08532469  0.11535071 -0.01563013  0.09222998 -0.1843133\n",
      "  0.32871373 -0.05753721 -0.3268743   0.23558795 -0.22134317 -0.21095554\n",
      "  0.09083067 -0.31298609]\n",
      "Training Error:  9.768608936992102\n",
      "====================================================================================================\n",
      "Iteration:  1110\n",
      "Previous theta :  [-0.01654319 -0.08532469  0.11535071 -0.01563013  0.09222998 -0.1843133\n",
      "  0.32871373 -0.05753721 -0.3268743   0.23558795 -0.22134317 -0.21095554\n",
      "  0.09083067 -0.31298609]\n",
      "New theta_0 : [-0.01654336 -0.08532673  0.11535455 -0.01562108  0.09222868 -0.18431763\n",
      "  0.32871039 -0.05753413 -0.32687543  0.23561218 -0.22136951 -0.21095713\n",
      "  0.09083023 -0.31298805]\n",
      "Training Error:  9.768607503059119\n",
      "====================================================================================================\n",
      "Iteration:  1111\n",
      "Previous theta :  [-0.01654336 -0.08532673  0.11535455 -0.01562108  0.09222868 -0.18431763\n",
      "  0.32871039 -0.05753413 -0.32687543  0.23561218 -0.22136951 -0.21095713\n",
      "  0.09083023 -0.31298805]\n",
      "New theta_0 : [-0.01654353 -0.08532877  0.11535836 -0.01561205  0.09222738 -0.18432193\n",
      "  0.32870706 -0.05753107 -0.32687655  0.23563635 -0.22139579 -0.21095872\n",
      "  0.0908298  -0.31299001]\n",
      "Training Error:  9.768606076252963\n",
      "====================================================================================================\n",
      "Iteration:  1112\n",
      "Previous theta :  [-0.01654353 -0.08532877  0.11535836 -0.01561205  0.09222738 -0.18432193\n",
      "  0.32870706 -0.05753107 -0.32687655  0.23563635 -0.22139579 -0.21095872\n",
      "  0.0908298  -0.31299001]\n",
      "New theta_0 : [-0.0165437  -0.08533079  0.11536217 -0.01560305  0.09222609 -0.18432621\n",
      "  0.32870374 -0.05752803 -0.32687765  0.23566046 -0.22142201 -0.2109603\n",
      "  0.09082937 -0.31299195]\n",
      "Training Error:  9.768604656536057\n",
      "====================================================================================================\n",
      "Iteration:  1113\n",
      "Previous theta :  [-0.0165437  -0.08533079  0.11536217 -0.01560305  0.09222609 -0.18432621\n",
      "  0.32870374 -0.05752803 -0.32687765  0.23566046 -0.22142201 -0.2109603\n",
      "  0.09082937 -0.31299195]\n",
      "New theta_0 : [-0.01654387 -0.08533282  0.11536596 -0.01559406  0.09222479 -0.18433046\n",
      "  0.32870044 -0.05752499 -0.32687873  0.23568451 -0.22144817 -0.21096187\n",
      "  0.09082894 -0.31299388]\n",
      "Training Error:  9.768603243871045\n",
      "====================================================================================================\n",
      "Iteration:  1114\n",
      "Previous theta :  [-0.01654387 -0.08533282  0.11536596 -0.01559406  0.09222479 -0.18433046\n",
      "  0.32870044 -0.05752499 -0.32687873  0.23568451 -0.22144817 -0.21096187\n",
      "  0.09082894 -0.31299388]\n",
      "New theta_0 : [-0.01654404 -0.08533483  0.11536974 -0.0155851   0.0922235  -0.18433469\n",
      "  0.32869715 -0.05752197 -0.32687981  0.2357085  -0.22147427 -0.21096343\n",
      "  0.09082851 -0.31299581]\n",
      "Training Error:  9.768601838220802\n",
      "====================================================================================================\n",
      "Iteration:  1115\n",
      "Previous theta :  [-0.01654404 -0.08533483  0.11536974 -0.0155851   0.0922235  -0.18433469\n",
      "  0.32869715 -0.05752197 -0.32687981  0.2357085  -0.22147427 -0.21096343\n",
      "  0.09082851 -0.31299581]\n",
      "New theta_0 : [-0.01654421 -0.08533684  0.11537351 -0.01557616  0.09222222 -0.18433889\n",
      "  0.32869388 -0.05751896 -0.32688086  0.23573243 -0.22150031 -0.21096499\n",
      "  0.09082809 -0.31299772]\n",
      "Training Error:  9.768600439548424\n",
      "====================================================================================================\n",
      "Iteration:  1116\n",
      "Previous theta :  [-0.01654421 -0.08533684  0.11537351 -0.01557616  0.09222222 -0.18433889\n",
      "  0.32869388 -0.05751896 -0.32688086  0.23573243 -0.22150031 -0.21096499\n",
      "  0.09082809 -0.31299772]\n",
      "New theta_0 : [-0.01654438 -0.08533884  0.11537726 -0.01556724  0.09222093 -0.18434307\n",
      "  0.32869062 -0.05751596 -0.32688191  0.23575629 -0.22152629 -0.21096654\n",
      "  0.09082767 -0.31299963]\n",
      "Training Error:  9.768599047817233\n",
      "====================================================================================================\n",
      "Iteration:  1117\n",
      "Previous theta :  [-0.01654438 -0.08533884  0.11537726 -0.01556724  0.09222093 -0.18434307\n",
      "  0.32869062 -0.05751596 -0.32688191  0.23575629 -0.22152629 -0.21096654\n",
      "  0.09082767 -0.31299963]\n",
      "New theta_0 : [-0.01654455 -0.08534083  0.115381   -0.01555834  0.09221965 -0.18434722\n",
      "  0.32868737 -0.05751298 -0.32688294  0.2357801  -0.22155222 -0.21096808\n",
      "  0.09082725 -0.31300153]\n",
      "Training Error:  9.768597662990764\n",
      "====================================================================================================\n",
      "Iteration:  1118\n",
      "Previous theta :  [-0.01654455 -0.08534083  0.115381   -0.01555834  0.09221965 -0.18434722\n",
      "  0.32868737 -0.05751298 -0.32688294  0.2357801  -0.22155222 -0.21096808\n",
      "  0.09082725 -0.31300153]\n",
      "New theta_0 : [-0.01654472 -0.08534281  0.11538473 -0.01554946  0.09221838 -0.18435134\n",
      "  0.32868414 -0.05751    -0.32688396  0.23580385 -0.22157809 -0.21096961\n",
      "  0.09082683 -0.31300342]\n",
      "Training Error:  9.768596285032784\n",
      "====================================================================================================\n",
      "Iteration:  1119\n",
      "Previous theta :  [-0.01654472 -0.08534281  0.11538473 -0.01554946  0.09221838 -0.18435134\n",
      "  0.32868414 -0.05751    -0.32688396  0.23580385 -0.22157809 -0.21096961\n",
      "  0.09082683 -0.31300342]\n",
      "New theta_0 : [-0.01654489 -0.08534479  0.11538844 -0.01554061  0.0922171  -0.18435544\n",
      "  0.32868092 -0.05750704 -0.32688496  0.23582753 -0.22160389 -0.21097114\n",
      "  0.09082642 -0.3130053 ]\n",
      "Training Error:  9.768594913907268\n",
      "====================================================================================================\n",
      "Iteration:  1120\n",
      "Previous theta :  [-0.01654489 -0.08534479  0.11538844 -0.01554061  0.0922171  -0.18435544\n",
      "  0.32868092 -0.05750704 -0.32688496  0.23582753 -0.22160389 -0.21097114\n",
      "  0.09082642 -0.3130053 ]\n",
      "New theta_0 : [-0.01654506 -0.08534676  0.11539215 -0.01553177  0.09221583 -0.18435952\n",
      "  0.32867772 -0.0575041  -0.32688595  0.23585116 -0.22162964 -0.21097267\n",
      "  0.09082601 -0.31300717]\n",
      "Training Error:  9.768593549578403\n",
      "====================================================================================================\n",
      "Iteration:  1121\n",
      "Previous theta :  [-0.01654506 -0.08534676  0.11539215 -0.01553177  0.09221583 -0.18435952\n",
      "  0.32867772 -0.0575041  -0.32688595  0.23585116 -0.22162964 -0.21097267\n",
      "  0.09082601 -0.31300717]\n",
      "New theta_0 : [-0.01654523 -0.08534873  0.11539584 -0.01552296  0.09221456 -0.18436357\n",
      "  0.32867453 -0.05750116 -0.32688693  0.23587473 -0.22165533 -0.21097418\n",
      "  0.0908256  -0.31300903]\n",
      "Training Error:  9.768592192010598\n",
      "====================================================================================================\n",
      "Iteration:  1122\n",
      "Previous theta :  [-0.01654523 -0.08534873  0.11539584 -0.01552296  0.09221456 -0.18436357\n",
      "  0.32867453 -0.05750116 -0.32688693  0.23587473 -0.22165533 -0.21097418\n",
      "  0.0908256  -0.31300903]\n",
      "New theta_0 : [-0.0165454  -0.08535068  0.11539952 -0.01551416  0.0922133  -0.1843676\n",
      "  0.32867135 -0.05749823 -0.3268879   0.23589823 -0.22168097 -0.21097569\n",
      "  0.09082519 -0.31301088]\n",
      "Training Error:  9.768590841168471\n",
      "====================================================================================================\n",
      "Iteration:  1123\n",
      "Previous theta :  [-0.0165454  -0.08535068  0.11539952 -0.01551416  0.0922133  -0.1843676\n",
      "  0.32867135 -0.05749823 -0.3268879   0.23589823 -0.22168097 -0.21097569\n",
      "  0.09082519 -0.31301088]\n",
      "New theta_0 : [-0.01654557 -0.08535263  0.11540318 -0.01550539  0.09221203 -0.18437161\n",
      "  0.32866819 -0.05749532 -0.32688885  0.23592168 -0.22170654 -0.21097719\n",
      "  0.09082479 -0.31301273]\n",
      "Training Error:  9.76858949701685\n",
      "====================================================================================================\n",
      "Iteration:  1124\n",
      "Previous theta :  [-0.01654557 -0.08535263  0.11540318 -0.01550539  0.09221203 -0.18437161\n",
      "  0.32866819 -0.05749532 -0.32688885  0.23592168 -0.22170654 -0.21097719\n",
      "  0.09082479 -0.31301273]\n",
      "New theta_0 : [-0.01654574 -0.08535458  0.11540684 -0.01549664  0.09221077 -0.18437559\n",
      "  0.32866504 -0.05749242 -0.32688979  0.23594507 -0.22173206 -0.21097869\n",
      "  0.09082439 -0.31301456]\n",
      "Training Error:  9.768588159520775\n",
      "====================================================================================================\n",
      "Iteration:  1125\n",
      "Previous theta :  [-0.01654574 -0.08535458  0.11540684 -0.01549664  0.09221077 -0.18437559\n",
      "  0.32866504 -0.05749242 -0.32688979  0.23594507 -0.22173206 -0.21097869\n",
      "  0.09082439 -0.31301456]\n",
      "New theta_0 : [-0.01654591 -0.08535651  0.11541048 -0.01548791  0.09220952 -0.18437955\n",
      "  0.3286619  -0.05748953 -0.32689071  0.2359684  -0.22175752 -0.21098017\n",
      "  0.09082399 -0.31301639]\n",
      "Training Error:  9.768586828645487\n",
      "====================================================================================================\n",
      "Iteration:  1126\n",
      "Previous theta :  [-0.01654591 -0.08535651  0.11541048 -0.01548791  0.09220952 -0.18437955\n",
      "  0.3286619  -0.05748953 -0.32689071  0.2359684  -0.22175752 -0.21098017\n",
      "  0.09082399 -0.31301639]\n",
      "New theta_0 : [-0.01654607 -0.08535844  0.11541411 -0.0154792   0.09220826 -0.18438348\n",
      "  0.32865877 -0.05748666 -0.32689163  0.23599167 -0.22178292 -0.21098166\n",
      "  0.0908236  -0.31301821]\n",
      "Training Error:  9.768585504356446\n",
      "====================================================================================================\n",
      "Iteration:  1127\n",
      "Previous theta :  [-0.01654607 -0.08535844  0.11541411 -0.0154792   0.09220826 -0.18438348\n",
      "  0.32865877 -0.05748666 -0.32689163  0.23599167 -0.22178292 -0.21098166\n",
      "  0.0908236  -0.31301821]\n",
      "New theta_0 : [-0.01654624 -0.08536037  0.11541773 -0.01547051  0.09220701 -0.18438739\n",
      "  0.32865566 -0.05748379 -0.32689253  0.23601488 -0.22180827 -0.21098313\n",
      "  0.0908232  -0.31302002]\n",
      "Training Error:  9.768584186619298\n",
      "====================================================================================================\n",
      "Iteration:  1128\n",
      "Previous theta :  [-0.01654624 -0.08536037  0.11541773 -0.01547051  0.09220701 -0.18438739\n",
      "  0.32865566 -0.05748379 -0.32689253  0.23601488 -0.22180827 -0.21098313\n",
      "  0.0908232  -0.31302002]\n",
      "New theta_0 : [-0.01654641 -0.08536228  0.11542134 -0.01546184  0.09220576 -0.18439128\n",
      "  0.32865257 -0.05748094 -0.32689342  0.23603803 -0.22183355 -0.2109846\n",
      "  0.09082281 -0.31302182]\n",
      "Training Error:  9.76858287539991\n",
      "====================================================================================================\n",
      "Iteration:  1129\n",
      "Previous theta :  [-0.01654641 -0.08536228  0.11542134 -0.01546184  0.09220576 -0.18439128\n",
      "  0.32865257 -0.05748094 -0.32689342  0.23603803 -0.22183355 -0.2109846\n",
      "  0.09082281 -0.31302182]\n",
      "New theta_0 : [-0.01654658 -0.08536419  0.11542493 -0.01545319  0.09220452 -0.18439514\n",
      "  0.32864948 -0.05747809 -0.3268943   0.23606113 -0.22185878 -0.21098606\n",
      "  0.09082242 -0.31302362]\n",
      "Training Error:  9.768581570664338\n",
      "====================================================================================================\n",
      "Iteration:  1130\n",
      "Previous theta :  [-0.01654658 -0.08536419  0.11542493 -0.01545319  0.09220452 -0.18439514\n",
      "  0.32864948 -0.05747809 -0.3268943   0.23606113 -0.22185878 -0.21098606\n",
      "  0.09082242 -0.31302362]\n",
      "New theta_0 : [-0.01654675 -0.0853661   0.11542851 -0.01544456  0.09220328 -0.18439898\n",
      "  0.32864641 -0.05747526 -0.32689516  0.23608416 -0.22188396 -0.21098752\n",
      "  0.09082204 -0.3130254 ]\n",
      "Training Error:  9.768580272378841\n",
      "====================================================================================================\n",
      "Iteration:  1131\n",
      "Previous theta :  [-0.01654675 -0.0853661   0.11542851 -0.01544456  0.09220328 -0.18439898\n",
      "  0.32864641 -0.05747526 -0.32689516  0.23608416 -0.22188396 -0.21098752\n",
      "  0.09082204 -0.3130254 ]\n",
      "New theta_0 : [-0.01654692 -0.08536799  0.11543208 -0.01543595  0.09220204 -0.1844028\n",
      "  0.32864335 -0.05747244 -0.32689601  0.23610714 -0.22190907 -0.21098897\n",
      "  0.09082165 -0.31302718]\n",
      "Training Error:  9.768578980509883\n",
      "====================================================================================================\n",
      "Iteration:  1132\n",
      "Previous theta :  [-0.01654692 -0.08536799  0.11543208 -0.01543595  0.09220204 -0.1844028\n",
      "  0.32864335 -0.05747244 -0.32689601  0.23610714 -0.22190907 -0.21098897\n",
      "  0.09082165 -0.31302718]\n",
      "New theta_0 : [-0.01654708 -0.08536988  0.11543564 -0.01542737  0.0922008  -0.1844066\n",
      "  0.32864031 -0.05746964 -0.32689685  0.23613006 -0.22193413 -0.21099041\n",
      "  0.09082127 -0.31302895]\n",
      "Training Error:  9.768577695024113\n",
      "====================================================================================================\n",
      "Iteration:  1133\n",
      "Previous theta :  [-0.01654708 -0.08536988  0.11543564 -0.01542737  0.0922008  -0.1844066\n",
      "  0.32864031 -0.05746964 -0.32689685  0.23613006 -0.22193413 -0.21099041\n",
      "  0.09082127 -0.31302895]\n",
      "New theta_0 : [-0.01654725 -0.08537176  0.11543919 -0.0154188   0.09219957 -0.18441037\n",
      "  0.32863728 -0.05746684 -0.32689768  0.23615292 -0.22195914 -0.21099184\n",
      "  0.09082089 -0.31303071]\n",
      "Training Error:  9.768576415888388\n",
      "====================================================================================================\n",
      "Iteration:  1134\n",
      "Previous theta :  [-0.01654725 -0.08537176  0.11543919 -0.0154188   0.09219957 -0.18441037\n",
      "  0.32863728 -0.05746684 -0.32689768  0.23615292 -0.22195914 -0.21099184\n",
      "  0.09082089 -0.31303071]\n",
      "New theta_0 : [-0.01654742 -0.08537364  0.11544272 -0.01541025  0.09219834 -0.18441412\n",
      "  0.32863426 -0.05746405 -0.3268985   0.23617573 -0.22198408 -0.21099327\n",
      "  0.09082052 -0.31303246]\n",
      "Training Error:  9.768575143069748\n",
      "====================================================================================================\n",
      "Iteration:  1135\n",
      "Previous theta :  [-0.01654742 -0.08537364  0.11544272 -0.01541025  0.09219834 -0.18441412\n",
      "  0.32863426 -0.05746405 -0.3268985   0.23617573 -0.22198408 -0.21099327\n",
      "  0.09082052 -0.31303246]\n",
      "New theta_0 : [-0.01654759 -0.08537551  0.11544625 -0.01540173  0.09219711 -0.18441785\n",
      "  0.32863125 -0.05746128 -0.32689931  0.23619848 -0.22200897 -0.2109947\n",
      "  0.09082014 -0.3130342 ]\n",
      "Training Error:  9.768573876535436\n",
      "====================================================================================================\n",
      "Iteration:  1136\n",
      "Previous theta :  [-0.01654759 -0.08537551  0.11544625 -0.01540173  0.09219711 -0.18441785\n",
      "  0.32863125 -0.05746128 -0.32689931  0.23619848 -0.22200897 -0.2109947\n",
      "  0.09082014 -0.3130342 ]\n",
      "New theta_0 : [-0.01654775 -0.08537737  0.11544976 -0.01539322  0.09219589 -0.18442156\n",
      "  0.32862825 -0.05745852 -0.3269001   0.23622117 -0.2220338  -0.21099611\n",
      "  0.09081977 -0.31303594]\n",
      "Training Error:  9.768572616252873\n",
      "====================================================================================================\n",
      "Iteration:  1137\n",
      "Previous theta :  [-0.01654775 -0.08537737  0.11544976 -0.01539322  0.09219589 -0.18442156\n",
      "  0.32862825 -0.05745852 -0.3269001   0.23622117 -0.2220338  -0.21099611\n",
      "  0.09081977 -0.31303594]\n",
      "New theta_0 : [-0.01654792 -0.08537923  0.11545326 -0.01538474  0.09219467 -0.18442524\n",
      "  0.32862527 -0.05745577 -0.32690088  0.2362438  -0.22205858 -0.21099753\n",
      "  0.0908194  -0.31303767]\n",
      "Training Error:  9.768571362189688\n",
      "====================================================================================================\n",
      "Iteration:  1138\n",
      "Previous theta :  [-0.01654792 -0.08537923  0.11545326 -0.01538474  0.09219467 -0.18442524\n",
      "  0.32862527 -0.05745577 -0.32690088  0.2362438  -0.22205858 -0.21099753\n",
      "  0.0908194  -0.31303767]\n",
      "New theta_0 : [-0.01654809 -0.08538108  0.11545675 -0.01537627  0.09219345 -0.18442891\n",
      "  0.3286223  -0.05745303 -0.32690165  0.23626638 -0.2220833  -0.21099893\n",
      "  0.09081903 -0.31303939]\n",
      "Training Error:  9.768570114313682\n",
      "====================================================================================================\n",
      "Iteration:  1139\n",
      "Previous theta :  [-0.01654809 -0.08538108  0.11545675 -0.01537627  0.09219345 -0.18442891\n",
      "  0.3286223  -0.05745303 -0.32690165  0.23626638 -0.2220833  -0.21099893\n",
      "  0.09081903 -0.31303939]\n",
      "New theta_0 : [-0.01654826 -0.08538292  0.11546023 -0.01536783  0.09219223 -0.18443255\n",
      "  0.32861935 -0.0574503  -0.32690241  0.23628889 -0.22210796 -0.21100033\n",
      "  0.09081867 -0.3130411 ]\n",
      "Training Error:  9.768568872592853\n",
      "====================================================================================================\n",
      "Iteration:  1140\n",
      "Previous theta :  [-0.01654826 -0.08538292  0.11546023 -0.01536783  0.09219223 -0.18443255\n",
      "  0.32861935 -0.0574503  -0.32690241  0.23628889 -0.22210796 -0.21100033\n",
      "  0.09081867 -0.3130411 ]\n",
      "New theta_0 : [-0.01654842 -0.08538476  0.11546369 -0.0153594   0.09219102 -0.18443617\n",
      "  0.3286164  -0.05744758 -0.32690316  0.23631136 -0.22213257 -0.21100172\n",
      "  0.0908183  -0.3130428 ]\n",
      "Training Error:  9.768567636995378\n",
      "====================================================================================================\n",
      "Iteration:  1141\n",
      "Previous theta :  [-0.01654842 -0.08538476  0.11546369 -0.0153594   0.09219102 -0.18443617\n",
      "  0.3286164  -0.05744758 -0.32690316  0.23631136 -0.22213257 -0.21100172\n",
      "  0.0908183  -0.3130428 ]\n",
      "New theta_0 : [-0.01654859 -0.08538659  0.11546715 -0.015351    0.09218981 -0.18443977\n",
      "  0.32861347 -0.05744487 -0.3269039   0.23633376 -0.22215712 -0.21100311\n",
      "  0.09081794 -0.3130445 ]\n",
      "Training Error:  9.768566407489619\n",
      "====================================================================================================\n",
      "Iteration:  1142\n",
      "Previous theta :  [-0.01654859 -0.08538659  0.11546715 -0.015351    0.09218981 -0.18443977\n",
      "  0.32861347 -0.05744487 -0.3269039   0.23633376 -0.22215712 -0.21100311\n",
      "  0.09081794 -0.3130445 ]\n",
      "New theta_0 : [-0.01654876 -0.08538842  0.11547059 -0.01534261  0.0921886  -0.18444335\n",
      "  0.32861055 -0.05744217 -0.32690463  0.23635611 -0.22218162 -0.21100449\n",
      "  0.09081759 -0.31304619]\n",
      "Training Error:  9.768565184044132\n",
      "====================================================================================================\n",
      "Iteration:  1143\n",
      "Previous theta :  [-0.01654876 -0.08538842  0.11547059 -0.01534261  0.0921886  -0.18444335\n",
      "  0.32861055 -0.05744217 -0.32690463  0.23635611 -0.22218162 -0.21100449\n",
      "  0.09081759 -0.31304619]\n",
      "New theta_0 : [-0.01654892 -0.08539023  0.11547403 -0.01533425  0.0921874  -0.1844469\n",
      "  0.32860764 -0.05743949 -0.32690534  0.23637841 -0.22220606 -0.21100586\n",
      "  0.09081723 -0.31304787]\n",
      "Training Error:  9.76856396662764\n",
      "====================================================================================================\n",
      "Iteration:  1144\n",
      "Previous theta :  [-0.01654892 -0.08539023  0.11547403 -0.01533425  0.0921874  -0.1844469\n",
      "  0.32860764 -0.05743949 -0.32690534  0.23637841 -0.22220606 -0.21100586\n",
      "  0.09081723 -0.31304787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.01654909 -0.08539205  0.11547745 -0.0153259   0.09218619 -0.18445044\n",
      "  0.32860474 -0.05743681 -0.32690605  0.23640064 -0.22223044 -0.21100723\n",
      "  0.09081687 -0.31304954]\n",
      "Training Error:  9.76856275520905\n",
      "====================================================================================================\n",
      "Iteration:  1145\n",
      "Previous theta :  [-0.01654909 -0.08539205  0.11547745 -0.0153259   0.09218619 -0.18445044\n",
      "  0.32860474 -0.05743681 -0.32690605  0.23640064 -0.22223044 -0.21100723\n",
      "  0.09081687 -0.31304954]\n",
      "New theta_0 : [-0.01654925 -0.08539385  0.11548086 -0.01531758  0.09218499 -0.18445395\n",
      "  0.32860186 -0.05743415 -0.32690674  0.23642282 -0.22225477 -0.21100859\n",
      "  0.09081652 -0.31305121]\n",
      "Training Error:  9.768561549757461\n",
      "====================================================================================================\n",
      "Iteration:  1146\n",
      "Previous theta :  [-0.01654925 -0.08539385  0.11548086 -0.01531758  0.09218499 -0.18445395\n",
      "  0.32860186 -0.05743415 -0.32690674  0.23642282 -0.22225477 -0.21100859\n",
      "  0.09081652 -0.31305121]\n",
      "New theta_0 : [-0.01654942 -0.08539565  0.11548426 -0.01530927  0.0921838  -0.18445745\n",
      "  0.32859898 -0.05743149 -0.32690743  0.23644495 -0.22227905 -0.21100995\n",
      "  0.09081617 -0.31305287]\n",
      "Training Error:  9.768560350242131\n",
      "====================================================================================================\n",
      "Iteration:  1147\n",
      "Previous theta :  [-0.01654942 -0.08539565  0.11548426 -0.01530927  0.0921838  -0.18445745\n",
      "  0.32859898 -0.05743149 -0.32690743  0.23644495 -0.22227905 -0.21100995\n",
      "  0.09081617 -0.31305287]\n",
      "New theta_0 : [-0.01654959 -0.08539745  0.11548765 -0.01530099  0.09218261 -0.18446092\n",
      "  0.32859612 -0.05742885 -0.3269081   0.23646702 -0.22230327 -0.2110113\n",
      "  0.09081582 -0.31305452]\n",
      "Training Error:  9.76855915663251\n",
      "====================================================================================================\n",
      "Iteration:  1148\n",
      "Previous theta :  [-0.01654959 -0.08539745  0.11548765 -0.01530099  0.09218261 -0.18446092\n",
      "  0.32859612 -0.05742885 -0.3269081   0.23646702 -0.22230327 -0.2110113\n",
      "  0.09081582 -0.31305452]\n",
      "New theta_0 : [-0.01654975 -0.08539923  0.11549102 -0.01529272  0.09218142 -0.18446437\n",
      "  0.32859327 -0.05742622 -0.32690877  0.23648903 -0.22232743 -0.21101264\n",
      "  0.09081548 -0.31305616]\n",
      "Training Error:  9.768557968898207\n",
      "====================================================================================================\n",
      "Iteration:  1149\n",
      "Previous theta :  [-0.01654975 -0.08539923  0.11549102 -0.01529272  0.09218142 -0.18446437\n",
      "  0.32859327 -0.05742622 -0.32690877  0.23648903 -0.22232743 -0.21101264\n",
      "  0.09081548 -0.31305616]\n",
      "New theta_0 : [-0.01654992 -0.08540101  0.11549439 -0.01528448  0.09218023 -0.18446781\n",
      "  0.32859044 -0.0574236  -0.32690942  0.23651099 -0.22235154 -0.21101398\n",
      "  0.09081514 -0.3130578 ]\n",
      "Training Error:  9.768556787009025\n",
      "====================================================================================================\n",
      "Iteration:  1150\n",
      "Previous theta :  [-0.01654992 -0.08540101  0.11549439 -0.01528448  0.09218023 -0.18446781\n",
      "  0.32859044 -0.0574236  -0.32690942  0.23651099 -0.22235154 -0.21101398\n",
      "  0.09081514 -0.3130578 ]\n",
      "New theta_0 : [-0.01655008 -0.08540279  0.11549774 -0.01527625  0.09217904 -0.18447122\n",
      "  0.32858761 -0.05742098 -0.32691006  0.2365329  -0.22237559 -0.21101531\n",
      "  0.09081479 -0.31305942]\n",
      "Training Error:  9.768555610934927\n",
      "====================================================================================================\n",
      "Iteration:  1151\n",
      "Previous theta :  [-0.01655008 -0.08540279  0.11549774 -0.01527625  0.09217904 -0.18447122\n",
      "  0.32858761 -0.05742098 -0.32691006  0.2365329  -0.22237559 -0.21101531\n",
      "  0.09081479 -0.31305942]\n",
      "New theta_0 : [-0.01655025 -0.08540456  0.11550109 -0.01526804  0.09217786 -0.18447461\n",
      "  0.3285848  -0.05741838 -0.3269107   0.23655475 -0.22239959 -0.21101664\n",
      "  0.09081445 -0.31306105]\n",
      "Training Error:  9.768554440646048\n",
      "====================================================================================================\n",
      "Iteration:  1152\n",
      "Previous theta :  [-0.01655025 -0.08540456  0.11550109 -0.01526804  0.09217786 -0.18447461\n",
      "  0.3285848  -0.05741838 -0.3269107   0.23655475 -0.22239959 -0.21101664\n",
      "  0.09081445 -0.31306105]\n",
      "New theta_0 : [-0.01655041 -0.08540632  0.11550442 -0.01525986  0.09217668 -0.18447799\n",
      "  0.32858199 -0.05741579 -0.32691132  0.23657654 -0.22242354 -0.21101796\n",
      "  0.09081412 -0.31306266]\n",
      "Training Error:  9.768553276112696\n",
      "====================================================================================================\n",
      "Iteration:  1153\n",
      "Previous theta :  [-0.01655041 -0.08540632  0.11550442 -0.01525986  0.09217668 -0.18447799\n",
      "  0.32858199 -0.05741579 -0.32691132  0.23657654 -0.22242354 -0.21101796\n",
      "  0.09081412 -0.31306266]\n",
      "New theta_0 : [-0.01655058 -0.08540808  0.11550775 -0.01525169  0.0921755  -0.18448134\n",
      "  0.3285792  -0.05741321 -0.32691193  0.23659828 -0.22244743 -0.21101927\n",
      "  0.09081378 -0.31306426]\n",
      "Training Error:  9.768552117305353\n",
      "====================================================================================================\n",
      "Iteration:  1154\n",
      "Previous theta :  [-0.01655058 -0.08540808  0.11550775 -0.01525169  0.0921755  -0.18448134\n",
      "  0.3285792  -0.05741321 -0.32691193  0.23659828 -0.22244743 -0.21101927\n",
      "  0.09081378 -0.31306426]\n",
      "New theta_0 : [-0.01655074 -0.08540983  0.11551106 -0.01524354  0.09217433 -0.18448467\n",
      "  0.32857642 -0.05741064 -0.32691254  0.23661996 -0.22247126 -0.21102058\n",
      "  0.09081345 -0.31306586]\n",
      "Training Error:  9.768550964194654\n",
      "====================================================================================================\n",
      "Iteration:  1155\n",
      "Previous theta :  [-0.01655074 -0.08540983  0.11551106 -0.01524354  0.09217433 -0.18448467\n",
      "  0.32857642 -0.05741064 -0.32691254  0.23661996 -0.22247126 -0.21102058\n",
      "  0.09081345 -0.31306586]\n",
      "New theta_0 : [-0.01655091 -0.08541158  0.11551436 -0.01523542  0.09217316 -0.18448799\n",
      "  0.32857365 -0.05740808 -0.32691313  0.23664159 -0.22249504 -0.21102189\n",
      "  0.09081312 -0.31306745]\n",
      "Training Error:  9.76854981675142\n",
      "====================================================================================================\n",
      "Iteration:  1156\n",
      "Previous theta :  [-0.01655091 -0.08541158  0.11551436 -0.01523542  0.09217316 -0.18448799\n",
      "  0.32857365 -0.05740808 -0.32691313  0.23664159 -0.22249504 -0.21102189\n",
      "  0.09081312 -0.31306745]\n",
      "New theta_0 : [-0.01655107 -0.08541331  0.11551765 -0.01522731  0.09217199 -0.18449128\n",
      "  0.3285709  -0.05740553 -0.32691371  0.23666317 -0.22251877 -0.21102318\n",
      "  0.09081279 -0.31306904]\n",
      "Training Error:  9.768548674946626\n",
      "====================================================================================================\n",
      "Iteration:  1157\n",
      "Previous theta :  [-0.01655107 -0.08541331  0.11551765 -0.01522731  0.09217199 -0.18449128\n",
      "  0.3285709  -0.05740553 -0.32691371  0.23666317 -0.22251877 -0.21102318\n",
      "  0.09081279 -0.31306904]\n",
      "New theta_0 : [-0.01655123 -0.08541505  0.11552093 -0.01521922  0.09217083 -0.18449456\n",
      "  0.32856815 -0.05740299 -0.32691429  0.23668469 -0.22254244 -0.21102448\n",
      "  0.09081246 -0.31307062]\n",
      "Training Error:  9.768547538751411\n",
      "====================================================================================================\n",
      "Iteration:  1158\n",
      "Previous theta :  [-0.01655123 -0.08541505  0.11552093 -0.01521922  0.09217083 -0.18449456\n",
      "  0.32856815 -0.05740299 -0.32691429  0.23668469 -0.22254244 -0.21102448\n",
      "  0.09081246 -0.31307062]\n",
      "New theta_0 : [-0.0165514  -0.08541678  0.1155242  -0.01521115  0.09216966 -0.18449782\n",
      "  0.32856542 -0.05740046 -0.32691485  0.23670616 -0.22256606 -0.21102576\n",
      "  0.09081214 -0.31307219]\n",
      "Training Error:  9.768546408137086\n",
      "====================================================================================================\n",
      "Iteration:  1159\n",
      "Previous theta :  [-0.0165514  -0.08541678  0.1155242  -0.01521115  0.09216966 -0.18449782\n",
      "  0.32856542 -0.05740046 -0.32691485  0.23670616 -0.22256606 -0.21102576\n",
      "  0.09081214 -0.31307219]\n",
      "New theta_0 : [-0.01655156 -0.0854185   0.11552746 -0.0152031   0.0921685  -0.18450106\n",
      "  0.32856269 -0.05739794 -0.32691541  0.23672757 -0.22258963 -0.21102704\n",
      "  0.09081181 -0.31307375]\n",
      "Training Error:  9.768545283075117\n",
      "====================================================================================================\n",
      "Iteration:  1160\n",
      "Previous theta :  [-0.01655156 -0.0854185   0.11552746 -0.0152031   0.0921685  -0.18450106\n",
      "  0.32856269 -0.05739794 -0.32691541  0.23672757 -0.22258963 -0.21102704\n",
      "  0.09081181 -0.31307375]\n",
      "New theta_0 : [-0.01655172 -0.08542021  0.11553071 -0.01519507  0.09216735 -0.18450427\n",
      "  0.32855998 -0.05739543 -0.32691596  0.23674894 -0.22261314 -0.21102832\n",
      "  0.09081149 -0.3130753 ]\n",
      "Training Error:  9.768544163537133\n",
      "====================================================================================================\n",
      "Iteration:  1161\n",
      "Previous theta :  [-0.01655172 -0.08542021  0.11553071 -0.01519507  0.09216735 -0.18450427\n",
      "  0.32855998 -0.05739543 -0.32691596  0.23674894 -0.22261314 -0.21102832\n",
      "  0.09081149 -0.3130753 ]\n",
      "New theta_0 : [-0.01655189 -0.08542192  0.11553395 -0.01518706  0.09216619 -0.18450747\n",
      "  0.32855728 -0.05739293 -0.32691649  0.23677024 -0.2226366  -0.21102959\n",
      "  0.09081117 -0.31307685]\n",
      "Training Error:  9.76854304949492\n",
      "====================================================================================================\n",
      "Iteration:  1162\n",
      "Previous theta :  [-0.01655189 -0.08542192  0.11553395 -0.01518706  0.09216619 -0.18450747\n",
      "  0.32855728 -0.05739293 -0.32691649  0.23677024 -0.2226366  -0.21102959\n",
      "  0.09081117 -0.31307685]\n",
      "New theta_0 : [-0.01655205 -0.08542363  0.11553718 -0.01517906  0.09216504 -0.18451066\n",
      "  0.32855459 -0.05739043 -0.32691702  0.2367915  -0.22266    -0.21103085\n",
      "  0.09081085 -0.3130784 ]\n",
      "Training Error:  9.768541940920429\n",
      "====================================================================================================\n",
      "Iteration:  1163\n",
      "Previous theta :  [-0.01655205 -0.08542363  0.11553718 -0.01517906  0.09216504 -0.18451066\n",
      "  0.32855459 -0.05739043 -0.32691702  0.2367915  -0.22266    -0.21103085\n",
      "  0.09081085 -0.3130784 ]\n",
      "New theta_0 : [-0.01655221 -0.08542533  0.1155404  -0.01517109  0.09216389 -0.18451382\n",
      "  0.32855191 -0.05738795 -0.32691754  0.2368127  -0.22268335 -0.21103211\n",
      "  0.09081054 -0.31307993]\n",
      "Training Error:  9.768540837785764\n",
      "====================================================================================================\n",
      "Iteration:  1164\n",
      "Previous theta :  [-0.01655221 -0.08542533  0.1155404  -0.01517109  0.09216389 -0.18451382\n",
      "  0.32855191 -0.05738795 -0.32691754  0.2368127  -0.22268335 -0.21103211\n",
      "  0.09081054 -0.31307993]\n",
      "New theta_0 : [-0.01655238 -0.08542702  0.11554361 -0.01516314  0.09216275 -0.18451696\n",
      "  0.32854924 -0.05738548 -0.32691805  0.23683384 -0.22270665 -0.21103337\n",
      "  0.09081022 -0.31308146]\n",
      "Training Error:  9.76853974006319\n",
      "====================================================================================================\n",
      "Iteration:  1165\n",
      "Previous theta :  [-0.01655238 -0.08542702  0.11554361 -0.01516314  0.09216275 -0.18451696\n",
      "  0.32854924 -0.05738548 -0.32691805  0.23683384 -0.22270665 -0.21103337\n",
      "  0.09081022 -0.31308146]\n",
      "New theta_0 : [-0.01655254 -0.08542871  0.11554681 -0.0151552   0.0921616  -0.18452009\n",
      "  0.32854658 -0.05738302 -0.32691855  0.23685494 -0.22272989 -0.21103461\n",
      "  0.09080991 -0.31308298]\n",
      "Training Error:  9.768538647725123\n",
      "====================================================================================================\n",
      "Iteration:  1166\n",
      "Previous theta :  [-0.01655254 -0.08542871  0.11554681 -0.0151552   0.0921616  -0.18452009\n",
      "  0.32854658 -0.05738302 -0.32691855  0.23685494 -0.22272989 -0.21103461\n",
      "  0.09080991 -0.31308298]\n",
      "New theta_0 : [-0.0165527  -0.08543039  0.11555    -0.01514728  0.09216046 -0.1845232\n",
      "  0.32854393 -0.05738057 -0.32691904  0.23687598 -0.22275308 -0.21103586\n",
      "  0.0908096  -0.3130845 ]\n",
      "Training Error:  9.76853756074414\n",
      "====================================================================================================\n",
      "Iteration:  1167\n",
      "Previous theta :  [-0.0165527  -0.08543039  0.11555    -0.01514728  0.09216046 -0.1845232\n",
      "  0.32854393 -0.05738057 -0.32691904  0.23687598 -0.22275308 -0.21103586\n",
      "  0.0908096  -0.3130845 ]\n",
      "New theta_0 : [-0.01655286 -0.08543206  0.11555318 -0.01513939  0.09215932 -0.18452629\n",
      "  0.32854129 -0.05737813 -0.32691953  0.23689697 -0.22277622 -0.21103709\n",
      "  0.09080929 -0.313086  ]\n",
      "Training Error:  9.768536479092958\n",
      "====================================================================================================\n",
      "Iteration:  1168\n",
      "Previous theta :  [-0.01655286 -0.08543206  0.11555318 -0.01513939  0.09215932 -0.18452629\n",
      "  0.32854129 -0.05737813 -0.32691953  0.23689697 -0.22277622 -0.21103709\n",
      "  0.09080929 -0.313086  ]\n",
      "New theta_0 : [-0.01655303 -0.08543373  0.11555634 -0.01513151  0.09215819 -0.18452936\n",
      "  0.32853867 -0.05737569 -0.32692     0.23691791 -0.2227993  -0.21103833\n",
      "  0.09080899 -0.3130875 ]\n",
      "Training Error:  9.768535402744472\n",
      "====================================================================================================\n",
      "Iteration:  1169\n",
      "Previous theta :  [-0.01655303 -0.08543373  0.11555634 -0.01513151  0.09215819 -0.18452936\n",
      "  0.32853867 -0.05737569 -0.32692     0.23691791 -0.2227993  -0.21103833\n",
      "  0.09080899 -0.3130875 ]\n",
      "New theta_0 : [-0.01655319 -0.0854354   0.1155595  -0.01512365  0.09215705 -0.18453242\n",
      "  0.32853605 -0.05737327 -0.32692047  0.23693879 -0.22282234 -0.21103955\n",
      "  0.09080868 -0.313089  ]\n",
      "Training Error:  9.768534331671695\n",
      "====================================================================================================\n",
      "Iteration:  1170\n",
      "Previous theta :  [-0.01655319 -0.0854354   0.1155595  -0.01512365  0.09215705 -0.18453242\n",
      "  0.32853605 -0.05737327 -0.32692047  0.23693879 -0.22282234 -0.21103955\n",
      "  0.09080868 -0.313089  ]\n",
      "New theta_0 : [-0.01655335 -0.08543706  0.11556265 -0.01511581  0.09215592 -0.18453545\n",
      "  0.32853345 -0.05737086 -0.32692093  0.23695962 -0.22284531 -0.21104077\n",
      "  0.09080838 -0.31309049]\n",
      "Training Error:  9.768533265847822\n",
      "====================================================================================================\n",
      "Iteration:  1171\n",
      "Previous theta :  [-0.01655335 -0.08543706  0.11556265 -0.01511581  0.09215592 -0.18453545\n",
      "  0.32853345 -0.05737086 -0.32692093  0.23695962 -0.22284531 -0.21104077\n",
      "  0.09080838 -0.31309049]\n",
      "New theta_0 : [-0.01655351 -0.08543871  0.11556579 -0.01510799  0.0921548  -0.18453847\n",
      "  0.32853085 -0.05736845 -0.32692138  0.2369804  -0.22286824 -0.21104199\n",
      "  0.09080808 -0.31309197]\n",
      "Training Error:  9.76853220524617\n",
      "====================================================================================================\n",
      "Iteration:  1172\n",
      "Previous theta :  [-0.01655351 -0.08543871  0.11556579 -0.01510799  0.0921548  -0.18453847\n",
      "  0.32853085 -0.05736845 -0.32692138  0.2369804  -0.22286824 -0.21104199\n",
      "  0.09080808 -0.31309197]\n",
      "New theta_0 : [-0.01655367 -0.08544036  0.11556892 -0.01510019  0.09215367 -0.18454148\n",
      "  0.32852827 -0.05736606 -0.32692182  0.23700113 -0.22289112 -0.2110432\n",
      "  0.09080778 -0.31309344]\n",
      "Training Error:  9.76853114984023\n",
      "====================================================================================================\n",
      "Iteration:  1173\n",
      "Previous theta :  [-0.01655367 -0.08544036  0.11556892 -0.01510019  0.09215367 -0.18454148\n",
      "  0.32852827 -0.05736606 -0.32692182  0.23700113 -0.22289112 -0.2110432\n",
      "  0.09080778 -0.31309344]\n",
      "New theta_0 : [-0.01655383 -0.085442    0.11557203 -0.0150924   0.09215255 -0.18454446\n",
      "  0.32852569 -0.05736367 -0.32692225  0.23702181 -0.22291394 -0.21104441\n",
      "  0.09080748 -0.31309491]\n",
      "Training Error:  9.768530099603625\n",
      "====================================================================================================\n",
      "Iteration:  1174\n",
      "Previous theta :  [-0.01655383 -0.085442    0.11557203 -0.0150924   0.09215255 -0.18454446\n",
      "  0.32852569 -0.05736367 -0.32692225  0.23702181 -0.22291394 -0.21104441\n",
      "  0.09080748 -0.31309491]\n",
      "New theta_0 : [-0.01655399 -0.08544364  0.11557514 -0.01508464  0.09215143 -0.18454743\n",
      "  0.32852313 -0.05736129 -0.32692268  0.23704243 -0.22293671 -0.21104561\n",
      "  0.09080719 -0.31309637]\n",
      "Training Error:  9.768529054510124\n",
      "====================================================================================================\n",
      "Iteration:  1175\n",
      "Previous theta :  [-0.01655399 -0.08544364  0.11557514 -0.01508464  0.09215143 -0.18454743\n",
      "  0.32852313 -0.05736129 -0.32692268  0.23704243 -0.22293671 -0.21104561\n",
      "  0.09080719 -0.31309637]\n",
      "New theta_0 : [-0.01655416 -0.08544527  0.11557824 -0.01507689  0.09215031 -0.18455038\n",
      "  0.32852057 -0.05735893 -0.32692309  0.237063   -0.22295942 -0.2110468\n",
      "  0.09080689 -0.31309783]\n",
      "Training Error:  9.768528014533645\n",
      "====================================================================================================\n",
      "Iteration:  1176\n",
      "Previous theta :  [-0.01655416 -0.08544527  0.11557824 -0.01507689  0.09215031 -0.18455038\n",
      "  0.32852057 -0.05735893 -0.32692309  0.237063   -0.22295942 -0.2110468\n",
      "  0.09080689 -0.31309783]\n",
      "New theta_0 : [-0.01655432 -0.0854469   0.11558133 -0.01506916  0.0921492  -0.18455331\n",
      "  0.32851803 -0.05735657 -0.3269235   0.23708352 -0.22298209 -0.21104799\n",
      "  0.0908066  -0.31309928]\n",
      "Training Error:  9.768526979648257\n",
      "====================================================================================================\n",
      "Iteration:  1177\n",
      "Previous theta :  [-0.01655432 -0.0854469   0.11558133 -0.01506916  0.0921492  -0.18455331\n",
      "  0.32851803 -0.05735657 -0.3269235   0.23708352 -0.22298209 -0.21104799\n",
      "  0.0908066  -0.31309928]\n",
      "New theta_0 : [-0.01655448 -0.08544852  0.11558441 -0.01506145  0.09214809 -0.18455623\n",
      "  0.32851549 -0.05735422 -0.3269239   0.23710399 -0.2230047  -0.21104918\n",
      "  0.09080631 -0.31310072]\n",
      "Training Error:  9.768525949828161\n",
      "====================================================================================================\n",
      "Iteration:  1178\n",
      "Previous theta :  [-0.01655448 -0.08544852  0.11558441 -0.01506145  0.09214809 -0.18455623\n",
      "  0.32851549 -0.05735422 -0.3269239   0.23710399 -0.2230047  -0.21104918\n",
      "  0.09080631 -0.31310072]\n",
      "New theta_0 : [-0.01655464 -0.08545013  0.11558748 -0.01505376  0.09214698 -0.18455913\n",
      "  0.32851297 -0.05735188 -0.32692429  0.23712441 -0.22302726 -0.21105036\n",
      "  0.09080602 -0.31310215]\n",
      "Training Error:  9.768524925047707\n",
      "====================================================================================================\n",
      "Iteration:  1179\n",
      "Previous theta :  [-0.01655464 -0.08545013  0.11558748 -0.01505376  0.09214698 -0.18455913\n",
      "  0.32851297 -0.05735188 -0.32692429  0.23712441 -0.22302726 -0.21105036\n",
      "  0.09080602 -0.31310215]\n",
      "New theta_0 : [-0.0165548  -0.08545174  0.11559054 -0.01504609  0.09214587 -0.18456201\n",
      "  0.32851046 -0.05734955 -0.32692468  0.23714478 -0.22304977 -0.21105154\n",
      "  0.09080574 -0.31310358]\n",
      "Training Error:  9.768523905281386\n",
      "====================================================================================================\n",
      "Iteration:  1180\n",
      "Previous theta :  [-0.0165548  -0.08545174  0.11559054 -0.01504609  0.09214587 -0.18456201\n",
      "  0.32851046 -0.05734955 -0.32692468  0.23714478 -0.22304977 -0.21105154\n",
      "  0.09080574 -0.31310358]\n",
      "New theta_0 : [-0.01655496 -0.08545335  0.11559359 -0.01503844  0.09214477 -0.18456488\n",
      "  0.32850795 -0.05734723 -0.32692506  0.2371651  -0.22307223 -0.21105271\n",
      "  0.09080545 -0.31310501]\n",
      "Training Error:  9.76852289050383\n",
      "====================================================================================================\n",
      "Iteration:  1181\n",
      "Previous theta :  [-0.01655496 -0.08545335  0.11559359 -0.01503844  0.09214477 -0.18456488\n",
      "  0.32850795 -0.05734723 -0.32692506  0.2371651  -0.22307223 -0.21105271\n",
      "  0.09080545 -0.31310501]\n",
      "New theta_0 : [-0.01655512 -0.08545495  0.11559663 -0.0150308   0.09214367 -0.18456773\n",
      "  0.32850546 -0.05734491 -0.32692543  0.23718537 -0.22309464 -0.21105387\n",
      "  0.09080517 -0.31310642]\n",
      "Training Error:  9.768521880689807\n",
      "====================================================================================================\n",
      "Iteration:  1182\n",
      "Previous theta :  [-0.01655512 -0.08545495  0.11559663 -0.0150308   0.09214367 -0.18456773\n",
      "  0.32850546 -0.05734491 -0.32692543  0.23718537 -0.22309464 -0.21105387\n",
      "  0.09080517 -0.31310642]\n",
      "New theta_0 : [-0.01655528 -0.08545654  0.11559967 -0.01502319  0.09214257 -0.18457056\n",
      "  0.32850297 -0.05734261 -0.32692579  0.23720558 -0.223117   -0.21105503\n",
      "  0.09080489 -0.31310783]\n",
      "Training Error:  9.76852087581423\n",
      "====================================================================================================\n",
      "Iteration:  1183\n",
      "Previous theta :  [-0.01655528 -0.08545654  0.11559967 -0.01502319  0.09214257 -0.18457056\n",
      "  0.32850297 -0.05734261 -0.32692579  0.23720558 -0.223117   -0.21105503\n",
      "  0.09080489 -0.31310783]\n",
      "New theta_0 : [-0.01655543 -0.08545813  0.11560269 -0.01501559  0.09214147 -0.18457338\n",
      "  0.3285005  -0.05734031 -0.32692614  0.23722575 -0.2231393  -0.21105619\n",
      "  0.09080461 -0.31310924]\n",
      "Training Error:  9.768519875852144\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = test_train_split(X, y, validation_sample2)\n",
    "learning_rate = 0.01\n",
    "train_error2, valid_error2, theta2 = linear_regression(X_train, y_train, X_test, y_test, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Second Sample')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXZ2aykQRCIKxBwKVKWMWAeBERoSjWglaqUlFRW3/lttVqe1u0vbX1cdtrl5+lWn+1ttbllqL+tFbaulv8KW0BwQVZCypIWEPYQ4As398f5yRMkslkmWxneD8fj3nMWb7nzPfkwHu+8z2bOecQEZHkFeroCoiISNtS0IuIJDkFvYhIklPQi4gkOQW9iEiSU9CLiCQ5Bb2Iz8zmmNmSjq5HY8zsDTP7YkfXQ4JDQS/txszON7N/mNkBM9trZn83szEdXa+mMrObzWy9mR0ys11m9oKZZXd0vUQaE+noCsjJwcy6An8B5gJPA6nABOBYR9arqcxsIvAj4BLn3Ltmlgt8toOrJdIkatFLe/kUgHNuoXOu0jlX5px7xTm3qrqAmd1kZuvMbJ+ZvWxmA6PmDTWzV/1fArvM7C5/epqZzTez7f5rvpml+fMuNLMiM/uGme02sx1mdmPUOnuY2SIzO2hmy4HT4tR/DPBP59y7/nbsdc497pw75K/rM2b2rr+urWb2/ajPGWRmzsxu9OftM7Mvm9kYM1tlZvvN7JdR5ef4v3Z+6f/6WW9mkxuqWLy/mwgo6KX9/AuoNLPHzWyamXWPnmlmM4C7gM8BecBbwEJ/XjbwGvAS0A84HXjdX/Q7wDhgFDASGAt8N2rVfYBuQH/gZuDBqM9+EDgK9AVu8l8NWQZcbGY/MLPx1V8mUUqB64Ec4DPAXDO7vE6Zc4EzgKuB+X7dpwBDgav8Xw3RZT8EegJ3A3/0f0XUEu/vJlLDOaeXXu3yAoYAjwFFQAWwCOjtz3sRuDmqbAg4AgwEZgHvNrDOD4FLo8YvBjb7wxcCZUAkav5uvC+GMFAOnBU170fAkjj1nwb8GdgPHAbuA8INlJ0P/NwfHgQ4oH/U/BLg6qjxZ4Gv+8NzgO2ARc1fDlznD78BfLGxv1tH72+9Os9LLXppN865dc65Oc65fGAYXut8vj97IPALvxtjP7AXMLyW+AC8QI+lH7AlanyLP61aiXOuImr8CJCF1/qNAFvrLBuv/i865z4L5AIz8AL5iwBmdq6ZLTazYjM7AHwZrzUebVfUcFmM8ayo8W3Oueg7Dtbdrmrx/m4igLpupIM459bjte6H+ZO2Av/LOZcT9cpwzv3Dn3dqA6vajhd21U7xpzWmGO9XxYA6yzal7lXOudeBv0XV/w94v1AGOOe6AQ/hBW5L9Tez6OUb2q54fzcRQEEv7cTMzvIPiub74wPwumSW+kUeAu40s6H+/G5m9nl/3l+Avmb2df/ga7aZnevPWwh818zyzKwn8D3g943VxzlXCfwR+L6ZdTGzAuCGOPWfYWbXmFl384wFJkbVPxvY65w76s/7QlP/Ng3oBdxqZin+32EI8EKMcvH+biKAgl7azyG8A4zLzKwULyBXA98AcM49B/wYeNLMDvrzpvnzDgGfxjudcSewEZjkr/e/gBXAKuAD4B1/WlN8Fa+7ZCfer4tH45TdB3zJ/+yDeF8mP3XOLfDn/ztwj5kdwvuyebqJdWjIMrwDt3uAHwIznXMldQvF+7uJVLPa3YAi0tHMbA7ewdbzO7oukhzUohcRSXIKehGRJKeuGxGRJKcWvYhIkusUNzXr2bOnGzRoUEdXQ0QkUFauXLnHOZfXWLlOEfSDBg1ixYoVHV0NEZFAMbO4V3NXU9eNiEiSU9CLiCQ5Bb2ISJLrFH30ItJ2ysvLKSoq4ujRox1dFWmh9PR08vPzSUlJadHyCnqRJFdUVER2djaDBg2i9g0xJQicc5SUlFBUVMTgwYNbtA513YgkuaNHj9KjRw+FfECZGT169EjoF5mCXuQkoJAPtkT3X6CDfsPOQ/zvVzaw5/Cxjq6KiEinFeig37T7MA/8bRN7S493dFVEpAElJSWMGjWKUaNG0adPH/r3718zfvx40/7v3njjjWzYsCFumQcffJAFCxbELXOyCvTB2JD/a6aySjdmE+msevTowXvvvQfA97//fbKysvjmN79Zq0zNQ6xDsduejz4a75kwnq985SuJV7YZKioqiEQiDY43dbn2EOgWfchPegW9SPBs2rSJgoICrr32WoYOHcqOHTu45ZZbKCwsZOjQodxzzz01Zc8//3zee+89KioqyMnJYd68eYwcOZLzzjuP3bt3A/Dd736X+fPn15SfN28eY8eO5cwzz+Qf//AeoVtaWsqVV15JQUEBM2fOpLCwsOZLKNrbb7/NxIkTOeecc5g2bRq7du2qWe/tt99OYWEhv/zlL5k9ezZz585l7Nix3HXXXezZs4fp06czYsQI/u3f/o3Vq1fX1O36669n/PjxzJkzpy3/rDEFukUf9g9Q6E7LIk3zgz+vYe32g626zoJ+Xbn7s0NbtOz69et54oknKCwsBODee+8lNzeXiooKJk2axMyZMykoKKi1zIEDB5g4cSL33nsvd9xxB7/73e+YN29evXU751i+fDmLFi3innvu4aWXXuKBBx6gT58+PPvss7z//vuMHj263nLHjh3jtttuY9GiRfTs2ZMFCxbwn//5nzz88MMAVFZW1tyba/bs2ezYsYOlS5cSCoWYO3cu5557LosWLeKVV15hzpw5NWXXr1/Pm2++SXp6eov+VokIdNBX/8qrVNKLBNJpp51WE/IACxcu5JFHHqGiooLt27ezdu3aekGfkZHBtGneY3HPOecc3nrrrZjr/tznPldTZvPmzQAsWbKEb3/72wCMHDmSoUPrf0GtW7eONWvWMGXKFMAL9vz8/Jr5V199da3yn//852u6nJYsWcJf//pXAKZOncqcOXMoLS0FYMaMGR0S8hD0oDd13Yg0R0tb3m0lMzOzZnjjxo384he/YPny5eTk5DB79uyY546npqbWDIfDYSoqKmKuOy0trdEysTjnGDFiRINfINF1jjXekKaWawuB7qMPh6q7bhT0IkF38OBBsrOz6dq1Kzt27ODll19u9c8YP348Tz/9NAAffPABa9eurVemoKCAbdu2sXz5cgCOHz/OmjVrmrT+CRMm1Jz589prr9G/f/8ODfhqatGLSKcwevRoCgoKOOussxg4cCDjx49v9c/42te+xvXXX09BQUHNq1u3brXKpKWl8cwzz3Drrbdy8OBBKisr+cY3vhGzm6eue+65h5tuuokRI0aQlZXVpLOF2kOjz4w1s98BlwG7nXPD/Gk/BT4LHAc+BG50zu33590J3AxUArc65xr9Wi4sLHQtefDIPz8sYdZvlrLwS+M477QezV5e5GSwbt06hgwZ0tHV6BQqKiqoqKggPT2djRs3MnXqVDZu3Njupzu2RKz9aGYrnXOFDSxSoylb9xjwS+CJqGmvAnc65yrM7MfAncC3zawAuAYYCvQDXjOzTznnKpu0Jc1UfR59lbpuRKQJDh8+zOTJk6moqMA5x69//etAhHyiGt1C59ybZjaozrRXokaXAjP94RnAk865Y8DHZrYJGAv8s1VqW0dY59GLSDPk5OSwcuXKjq5Gu2uNg7E3AS/6w/2BrVHzivxp9ZjZLWa2wsxWFBcXt+iDqy+YUoteRKRhCQW9mX0HqACafYMJ59zDzrlC51xhXl6jDzGPqfpgrIJeRKRhLe6cMrM5eAdpJ7sTR3S3AQOiiuX709pE9ZWxVVVt9QkiIsHXoha9mV0CfAuY7pw7EjVrEXCNmaWZ2WDgDGB54tVsqB7eu66MFRFpWKNBb2YL8Q6mnmlmRWZ2M95ZONnAq2b2npk9BOCcWwM8DawFXgK+0lZn3MCJg7FVOhgr0mlNmjSp3sVP8+fPZ+7cuXGXy8rKAmD79u3MnDkzZpkLL7yQxk7Nnj9/PkeOnGiPXnrppezfv78pVU8ajQa9c26Wc66vcy7FOZfvnHvEOXe6c26Ac26U//pyVPkfOudOc86d6Zx7Md66E1UT9Mp5kU5r1qxZPPnkk7WmPfnkk8yaNatJy/fr149nnnmmxZ9fN+hfeOEFcnJyWry+5qh764Wm3oqhObdsaIpA3wIhpK4bkU5v5syZ/PWvf615yMjmzZvZvn07EyZMqDmvffTo0QwfPpznn3++3vKbN29m2LBhAJSVlXHNNdcwZMgQrrjiCsrKymrKzZ07t+YWx3fffTcA999/P9u3b2fSpElMmjQJgEGDBrFnzx4A7rvvPoYNG8awYcNqbnG8efNmhgwZwpe+9CWGDh3K1KlTa31OteLiYq688krGjBnDmDFj+Pvf/w5499y/7rrrGD9+PNdddx2PPfYY06dP56KLLmLy5Mk45/iP//gPhg0bxvDhw3nqqacAeOONN5gwYQLTp0+vdyO3RAX6SoGas27UpBdpmhfnwc4PWnedfYbDtHsbnJ2bm8vYsWN58cUXmTFjBk8++SRXXXUVZkZ6ejrPPfccXbt2Zc+ePYwbN47p06c3+IzUX/3qV3Tp0oV169axatWqWrcZ/uEPf0hubi6VlZVMnjyZVatWceutt3LfffexePFievbsWWtdK1eu5NFHH2XZsmU45zj33HOZOHEi3bt3Z+PGjSxcuJDf/OY3XHXVVTz77LPMnj271vK33XYbt99+O+effz6ffPIJF198MevWrQNg7dq1LFmyhIyMDB577DHeeecdVq1aRW5uLs8++yzvvfce77//Pnv27GHMmDFccMEFALzzzjusXr2awYMHt2hXNCTQLfqwzqMXCYTo7pvobhvnHHfddRcjRoxgypQpbNu2reYhH7G8+eabNYE7YsQIRowYUTPv6aefZvTo0Zx99tmsWbMm5g3Loi1ZsoQrrriCzMxMsrKy+NznPldzx8rBgwczatQooPZtjqO99tprfPWrX2XUqFFMnz6dgwcPcvjwYQCmT59ORkZGTdlPf/rT5Obm1nzurFmzCIfD9O7dm4kTJ/L2228DMHbs2FYPeUiSFr2ujBVpojgt77Y0Y8YMbr/9dt555x2OHDnCOeecA8CCBQsoLi5m5cqVpKSkMGjQoJi3Jm7Mxx9/zM9+9jPefvttunfvzpw5c1q0nmrVtzgG7zbHsbpuqqqqWLp0acx7zHe2WxkHukUfCukJUyJBkJWVxaRJk7jppptqHYQ9cOAAvXr1IiUlhcWLF7Nly5a467ngggv4wx/+AMDq1atZtWoV4N3iODMzk27durFr1y5efPHEeSDZ2dkcOnSo3romTJjAn/70J44cOUJpaSnPPfccEyZMaPI2TZ06lQceeKBmPNYjCWOZMGECTz31FJWVlRQXF/Pmm28yduzYJn9uSwQ76HUwViQwZs2axfvvv18r6K+99lpWrFjB8OHDeeKJJzjrrLPirmPu3LkcPnyYIUOG8L3vfa/ml8HIkSM5++yzOeuss/jCF75Q6xbHt9xyC5dccknNwdhqo0ePZs6cOYwdO5Zzzz2XL37xi5x99tlN3p7777+fFStWMGLECAoKCnjooYeatNwVV1zBiBEjGDlyJBdddBE/+clP6NOnT5M/tyUavU1xe2jpbYp3HzzK2B+9zn9dPozZ4wa2Qc1Egk+3KU4OidymONgtej1hSkSkUcEOeh2MFRFpVKCDvvqmZpXKeZG49Ks32BLdf4EOevNrr3/EIg1LT0+npKRE/08CyjlHSUlJzNM4myrQ59GH1XUj0qj8/HyKiopo6QN+pOOlp6eTn5/f4uWDHfS6qZlIo1JSUtrkaksJjmB33ejh4CIijQp00KvrRkSkccEOet3UTESkUYEOetNtikVEGhXooAevVa+cFxFpWOCDPmS6qZmISDxJEPSmrhsRkTgCH/Re142CXkSkIYEP+pAZlVUdXQsRkc4rCYJep1eKiMQT/KBX142ISFyNBr2Z/c7MdpvZ6qhpuWb2qplt9N+7+9PNzO43s01mtsrMRrdl5cG7OlZXxoqINKwpLfrHgEvqTJsHvO6cOwN43R8HmAac4b9uAX7VOtVsWEjn0YuIxNVo0Dvn3gT21pk8A3jcH34cuDxq+hPOsxTIMbO+rVXZWEKmK2NFROJpaR99b+fcDn94J9DbH+4PbI0qV+RPq8fMbjGzFWa2IpH7ZIfNdMGUiEgcCR+Mdd5ja5qdtM65h51zhc65wry8vBZ/vg7GiojE19Kg31XdJeO/7/anbwMGRJXL96e1GV0ZKyISX0uDfhFwgz98A/B81PTr/bNvxgEHorp42oRuaiYiEl+jjxI0s4XAhUBPMysC7gbuBZ42s5uBLcBVfvEXgEuBTcAR4MY2qHOd+ummZiIi8TQa9M65WQ3MmhyjrAO+kmilmiOsrhsRkbgCf2VsOKQLpkRE4lHQi4gkucAHfSQcolxBLyLSoMAHfUrIqNB9ikVEGhT4oI+EjYpKtehFRBoS+KBPCYcor1KLXkSkIUkR9GrRi4g0LPBBHwkZ5eqjFxFpUOCDPiUcokJn3YiINCjwQR8Jq0UvIhJP8IM+pD56EZF4Ah/0KWrRi4jEFfigj4RNffQiInEEP+hDIbXoRUTiCHzQp+jKWBGRuAIf9JFwiApdGSsi0qDAB31KyCivdDg9ZUpEJKbAB30k7G2C7kkvIhJb4IM+xQ96nXkjIhJbEgS9AejMGxGRBgQ+6CMhL+h15o2ISGzBD3q/60b3pBcRiS3wQV/ddaMWvYhIbIEP+kjIPxiroBcRiSmhoDez281sjZmtNrOFZpZuZoPNbJmZbTKzp8wstbUqG0uk+mCsum5ERGJqcdCbWX/gVqDQOTcMCAPXAD8Gfu6cOx3YB9zcGhVtSM3plWrRi4jElGjXTQTIMLMI0AXYAVwEPOPPfxy4PMHPiKs66HV6pYhIbC0OeufcNuBnwCd4AX8AWAnsd85V+MWKgP6xljezW8xshZmtKC4ubmk1SIt4m3CsorLF6xARSWaJdN10B2YAg4F+QCZwSVOXd8497JwrdM4V5uXltbQapKeEATharha9iEgsiXTdTAE+ds4VO+fKgT8C44EcvysHIB/YlmAd40pP8TbhaLla9CIisSQS9J8A48ysi5kZMBlYCywGZvplbgCeT6yK8alFLyISXyJ99MvwDrq+A3zgr+th4NvAHWa2CegBPNIK9WxQeqQ66NWiFxGJJdJ4kYY55+4G7q4z+SNgbCLrbY606q4bHYwVEYkp8FfGnmjRq+tGRCSWwAd9mg7GiojEFfygj4QwU9CLiDQk8EFvZqRFQgp6EZEGBD7owTvFUn30IiKxJUfQR8Jq0YuINCA5gj4lxNEKtehFRGJJkqBXi15EpCFJEfQZqWHKjivoRURiSYqgz05P4dCxisYLioichJIj6NMiHDpa3tHVEBHplJIj6NMjHD6qFr2ISCxJE/SHFPQiIjElRdBnpaVQVl6p58aKiMSQFEGfne7dbblUB2RFROpJqqBX942ISH1JFfQHdeaNiEg9SRL0KQA680ZEJIYkCXp13YiINCQpgj4rzQv6wzoYKyJST1IEfXXXja6OFRGpL0mCvvpgrFr0IiJ1JUXQp6eEyUgJs6/0eEdXRUSk00mKoAfIzUxlr4JeRKSehILezHLM7BkzW29m68zsPDPLNbNXzWyj/969tSobT4+sVEoU9CIi9STaov8F8JJz7ixgJLAOmAe87pw7A3jdH29zatGLiMTW4qA3s27ABcAjAM654865/cAM4HG/2OPA5YlWsikU9CIisSXSoh8MFAOPmtm7ZvZbM8sEejvndvhldgK9Yy1sZreY2QozW1FcXJxANTw9MlMpKT2W8HpERJJNIkEfAUYDv3LOnQ2UUqebxjnnABdrYefcw865QudcYV5eXgLV8ORmpnG0vIojx3WKpYhItESCvggocs4t88efwQv+XWbWF8B/351YFZumR2YqACWH1X0jIhKtxUHvnNsJbDWzM/1Jk4G1wCLgBn/aDcDzCdUwnk+WwVOz4cA2cv2gVz+9iEhtkQSX/xqwwMxSgY+AG/G+PJ42s5uBLcBVCX5Gww7vhHV/hgvvJDerH6CgFxGpK6Ggd869BxTGmDU5kfU2Wci7xw2Vx0903SjoRURqCfaVsWEv3KmsiOq60Zk3IiLRAh70/g+SyuNkpUVIjYTYo4OxIiK1BDzo/RZ9VTlmRu+uaew+eLRj6yQi0skEO+hr+ui9+9D36ZrOTgW9iEgtwQ768ImDsQC9uqaz+6D66EVEoiVJ0Ndu0XsX5IqICAQ+6KvPuvGCvnfXNI4cr9SzY0VEogQ86P0WfVV10KcDsEv99CIiNYId9KHaffQngl799CIi1YId9PW6btSiFxGpK+BBX33B1Ik+ekCnWIqIRAl40J+4YAqgS2qEbhkp7NivoBcRqRbsoK/TRw+Q3z2Don1HOqhCIiKdT7CDvuY8+hOnU3pBX9ZBFRIR6XyCHfRmEIrUatEP6N6Fon1lumhKRMQX7KAHr5++TtdNWXml7mIpIuILftCHUqDqRNfNgNwuAOqnFxHxBT/owyl1WvRe0G9VP72ICJA0QV9eM5rfPQNQi15EpFrSBX1mWoTczFS27lWLXkQEkiLoU2sumKo2QOfSi4jUCH7Qh2r30QPk53bhk70KehERSIagT0mH8tq3PDgtL4ute49wtLyygyolItJ5JEHQd4Hy2v3xp+VlUuVgS4la9SIiCQe9mYXN7F0z+4s/PtjMlpnZJjN7ysxSE69mHCldoLy01qTT8rIA2LT7cJt+tIhIELRGi/42YF3U+I+BnzvnTgf2ATe3wmc0LCUjRoveC/oPixX0IiIJBb2Z5QOfAX7rjxtwEfCMX+Rx4PJEPqNRqZlwvHYXTUZqmP45GQp6ERESb9HPB74FVPnjPYD9zrnqexIUAf1jLWhmt5jZCjNbUVxc3PIapGRAef2++NN6ZanrRkSEBILezC4DdjvnVrZkeefcw865QudcYV5eXkur4ffR1w/60/Oy+Ki4lKoq3cVSRE5ukQSWHQ9MN7NLgXSgK/ALIMfMIn6rPh/Ylng146gOeue82xb7TuuVSVl5Jdv2l9Xc6ExE5GTU4ha9c+5O51y+c24QcA3wN+fctcBiYKZf7Abg+YRrGU+qH+J1DsgW9O0KwJrtB9v040VEOru2OI/+28AdZrYJr8/+kTb4jBNSMr33OkE/pG9XwiFjzfYDbfrxIiKdXSJdNzWcc28Ab/jDHwFjW2O9TZLi3a3SO5e+R83k9JQwp+dlqUUvIie94F8Z20DXDcDQfl1ZvU0tehE5uSVB0HsXR3Gs/qmUQ/t3Y/ehY+w+dLTePBGRk0Xwgz6ju/detq/erGH9/AOy29R9IyInryQK+r31Zg3t342Qwbtb97dzpUREOo8kCPpc7/1I/aDPSoswpG9X3v64/jwRkZNFEgR9DmAxW/QAYwbl8u7WfZRXVsWcLyKS7IIf9KEwpHeL2aIHGDs4l6PlVTr7RkROWsEPeoAuuQ226AsHeX34b29W942InJySJOh7QmnsO2D2yk5ncM9Mln6koBeRk1NyBH23fDjQ8L3TJpzRk39+WKJnyIrISSmJgr4IqmIfcJ10Zi/KyitZrrNvROQklCRBPwAqj8GRPTFnjzu1B6mREG9sSOABJyIiAZUkQZ/vve//JObsjNQw553ag8UbduOcHkQiIieX5Aj6np/y3os3NFhkSkFvPt5Tyvqdh9qpUiIinUNyBH3uYIikw+61DRa5dFgfwiFj0fvb27FiIiIdLzmCPhSGvDPjBn2PrDTGn96TP7+/Xd03InJSSY6gB+hVALvXxS0yfWQ/ivaVsXJL/Ttdiogkq+QJ+j7D4dAOOLijwSLThvUhKy3CgmWxD9qKiCSj5An6U8Z575/8s8EimWkRrhzdn7+u2kHJ4WPtVDERkY6VPEHfZ6T3oPA4QQ8we9xAjldW8eTbW9upYiIiHSt5gj4cgQFjYEv8oD+jdzYTP5XHI0s+pvRYRTtVTkSk4yRP0AMMHA+7VkNpSdxit005g72lx/mfpVvaqWIiIh0nuYL+jE8DDja+ErfY6FO6c8Gn8nj4zY84dLS8feomItJBWhz0ZjbAzBab2VozW2Nmt/nTc83sVTPb6L93b73qNqLvKMjuCxteaLToN6d+in1HjjP/tY3tUDERkY6TSIu+AviGc64AGAd8xcwKgHnA6865M4DX/fH2YQZnToNNr0N5WdyiI/JzuGbMKTz2j82s33mwnSooItL+Whz0zrkdzrl3/OFDwDqgPzADeNwv9jhweaKVbJahV0B5Kaz7S6NFv3XxmXRNj/CtZ1ZxvELPlBWR5NQqffRmNgg4G1gG9HbOVV+1tBPo3Rqf0WQDz4ecU+C93zdatHtmKj+6Yjirig7w89f+1Q6VExFpfwkHvZllAc8CX3fO1eoDcd5NZWLeWMbMbjGzFWa2ori4Fe8THwrBqNnw0Ruwr/GzaqYN78ussQN46P99yKtrd7VePUREOomEgt7MUvBCfoFz7o/+5F1m1tef3xfYHWtZ59zDzrlC51xhXl5eItWob9QXwMKw7NdNKv69y4YyIj+HWxe+ywdFB1q3LiIiHSyRs24MeARY55y7L2rWIuAGf/gG4PmWV6+FcgbA8M/DykehNPZTp6JlpIb57fWF5GamcuNjy/nXLt2zXkSSRyIt+vHAdcBFZvae/7oUuBf4tJltBKb44+1vwh3emTf/uL9JxfOy03j8prGEzLjm4aWs3qaWvYgkh0TOulninDPn3Ajn3Cj/9YJzrsQ5N9k5d4ZzbopzrmOeyJ13Joy8Bpb+CvZsatIip/fK4un/dR7pkRBX//qfvLR6ZxtXUkSk7SXXlbF1TfmB9+SpF74BTXzYyKCemfzx38dzeu9svvz7lfz05fU69VJEAi25gz67N0y52zsDZ+n/afJifbql89Qt47hmzAAeXPwhlz/4d9Zu10VVIhJMyR30AIU3w1mXwat3w8dvNXmx9JQw9145goevO4fdh45x2QNv8Z3nPmCP7mMvIgGT/EFvBjN+CT1Ogye/ADveb9biU4f24bU7LuD68wbx1NtbmfiTxfz3C+u7PAOhAAAKXElEQVTYdfBoG1VYRKR1WWd4UHZhYaFbsWJF237IgW3wyFQ4fhhmPQkDz2v2Kj4sPszPX/0XL3ywg0goxGUj+3J14QDGDs7FO9tURKT9mNlK51xho+VOmqAH2LcZfn8l7N8Kn/kZnH2d1+Jvpi0lpfz2rY957t1tHD5WwcAeXZg+sh9ThvRmeP9uhEIKfRFpewr6hpSWwDNz4OM3vRugTfsJZPVq0aqOHK/gpdU7eWZlEUs/KqHKQe+uaUw6sxfnnprL2ME96J+T0br1FxHxKejjqaqEv8+Hxf8NKV1g0p1QeBNE0lq8yn2lx1m8YTevrdvFWxv3cOio95jC/jkZjBqQQ0G/rgzpm01B32707pqmrh4RSZiCvin2bIQXvwUf/g2y+8H422D0dZCamdBqK6scG3YeYvnHJSzfvJfV2w7yyd4jNfO7ZaQwqEcXTumRycDcLgzs0YX87l3o1TWNXtlpZKVF9EUgIo1S0DeVc9559m/+FLb8HVKzYfhMOOcG74lVrRS4h46Ws37nIdZuP8i/dh3ik71H2FJyhG37y6isqr0PuqSG6ZWdRq/sdHpkpdItI4VuGSl09d+jx7ukhslICZNR/Z4S1jECkZOEgr4lPlnm3QhtzXNQcRRyT/XOwR/yWehf6N0CuZWVV1axbV8Z2/eXsfvQMXYdPMruQ8dqhveWHudAWTkHysqbfIVuWiRERmqYLilh0lPDpIZDRMJGSjhESihESsSIhELeuD89EraacpFQiJAZIYNQyDCDsFmtadXDZkY45E+vU8aqy+B98VR/Z1Z/DZ0Yrz3jxHyLXT5qubrfww0u00gdkk9yblgy7q/BPTP5VO/sFi2roE9E2X4v7Nf92TtoW1UOGd1h4HgYNAEGjYe8IRCOtGu1jpZX1oT+gbJyDh0tp+x4FWXllZQdr6CsvJIjxyv9cf9VXkl5ZRUVlY7j/nt5ZRXlVY7yiioqqqoor3QcjxquqKzCOahyjkrnqHLg/Pe6vz5EJDFfnnga86ad1aJlmxr07ZtUQZGRA4U3eq+y/bDxVfj4De/K2vX+IwojGdBnGPQd6XXx9CrwLsrKyGmzaqWnhElPCdO7a3qbfUZTVId+lXNUVrlaXwquyhuuGXfVy/jv/nNoToyfWGf09BOf1fByNcvUKUuDnxF7Xckmabcr9jOMAq9nVstPAmkqteiba/8nsOWfsOM97yrbHavgeNT967v0hJ5neKGfMxC69vNf/b33tJb9RBMRqUst+raSc4r3Gnm1N15VBXs/gj0boGST//oQ/vUKlMZ4uFZaV8jMgy650KWH/4oaTu8GqVneF0Jatj+c5R0kbueuIhFJDkqORIVC0PN071VXxTE4uD3qVeS9HynxXge3wc4PvOGKJtw7J5LuhX9KhjccSfO6kCJpUePpdYbTIJwKoYj3RRGq8wqnNDAtDKHoeWHvSJiFGnmZ9xjHuPNjTA+FAfOPtkUddU3Go28i7UxB35YiaZA72Hs15vgROLIHjh707sdz7LDXJXTskD982Bs+fth7clbFUe+LpOIolB/1vyyORU0v897Ly8BVtv22tovo027qDNd8ITRnOPoUnDjrbu5nNmlTmvMF1tR1NmOVHVrPk3idsYy+Hv7tqy1fvgkU9J1FahdIPaVt1u0cVFV4r8pyf7jSO5uoZlqlP716WkXtcefAVcV5+fOrKhsvU+9VGTW/5tBpM4ajj/g2NEzt6S36nMY+s8k7pKkFm3FkVevs/OtsQAtvwdIcCvqTgZnXHRNO8bp9ROSkkvz3oxcROckp6EVEkpyCXkQkySnoRUSSnIJeRCTJKehFRJKcgl5EJMkp6EVEklynuHulmRUDW1q4eE9gTytWp6Ml0/Yk07ZAcm1PMm0LJNf2NGdbBjrn8hor1CmCPhFmtqIpt+kMimTanmTaFkiu7UmmbYHk2p622BZ13YiIJDkFvYhIkkuGoH+4oyvQypJpe5JpWyC5tieZtgWSa3tafVsC30cvIiLxJUOLXkRE4lDQi4gkuUAHvZldYmYbzGyTmc3r6Po0xswGmNliM1trZmvM7DZ/eq6ZvWpmG/337v50M7P7/e1bZWajO3YL6jOzsJm9a2Z/8ccHm9kyv85PmVmqPz3NH9/kzx/UkfWOxcxyzOwZM1tvZuvM7Lyg7hszu93/N7bazBaaWXqQ9o2Z/c7MdpvZ6qhpzd4XZnaDX36jmd3QEdvi1yPW9vzU/7e2ysyeM7OcqHl3+tuzwcwujpressxzzgXyBYSBD4FTgVTgfaCgo+vVSJ37AqP94WzgX0AB8BNgnj99HvBjf/hS4EW8B1KOA5Z19DbE2KY7gD8Af/HHnwau8YcfAub6w/8OPOQPXwM81dF1j7EtjwNf9IdTgZwg7hugP/AxkBG1T+YEad8AFwCjgdVR05q1L4Bc4CP/vbs/3L0Tbc9UIOIP/zhqewr8PEsDBvs5F04k8zr8H2UCf7jzgJejxu8E7uzoejVzG54HPg1sAPr60/oCG/zhXwOzosrXlOsMLyAfeB24CPiL/x9tT9Q/3pp9BLwMnOcPR/xy1tHbELUt3fxwtDrTA7dv/KDf6gdcxN83Fwdt3wCD6gRjs/YFMAv4ddT0WuU6envqzLsCWOAP18qy6v2TSOYFueum+h9ztSJ/WiD4P4/PBpYBvZ1zO/xZO4He/nBn38b5wLeAKn+8B7DfOVfhj0fXt2Zb/PkH/PKdxWCgGHjU74r6rZllEsB945zbBvwM+ATYgfe3Xklw90215u6LTruPYrgJ71cJtMH2BDnoA8vMsoBnga875w5Gz3PeV3WnP+fVzC4DdjvnVnZ0XVpJBO+n9a+cc2cDpXjdAzUCtG+6AzPwvrz6AZnAJR1aqVYWlH3RFGb2HaACWNBWnxHkoN8GDIgaz/endWpmloIX8gucc3/0J+8ys77+/L7Abn96Z97G8cB0M9sMPInXffMLIMfMIn6Z6PrWbIs/vxtQ0p4VbkQRUOScW+aPP4MX/EHcN1OAj51zxc65cuCPePsrqPumWnP3RWfeRwCY2RzgMuBa/8sL2mB7ghz0bwNn+GcSpOIdRFrUwXWKy8wMeARY55y7L2rWIqD6jIAb8Pruq6df759VMA44EPXTtUM55+50zuU75wbh/e3/5py7FlgMzPSL1d2W6m2c6ZfvNC0y59xOYKuZnelPmgysJYD7Bq/LZpyZdfH/zVVvSyD3TZTm7ouXgalm1t3/lTPVn9YpmNkleF2f051zR6JmLQKu8c+GGgycASwnkczr6AMuCR7cuBTvzJUPge90dH2aUN/z8X5urgLe81+X4vWHvg5sBF4Dcv3yBjzob98HQGFHb0MD23UhJ866OdX/R7kJ+L9Amj893R/f5M8/taPrHWM7RgEr/P3zJ7wzNQK5b4AfAOuB1cD/4J3BEZh9AyzEO75Qjvdr6+aW7Au8vu9N/uvGTrY9m/D63Kuz4KGo8t/xt2cDMC1qeosyT7dAEBFJckHuuhERkSZQ0IuIJDkFvYhIklPQi4gkOQW9iEiSU9CLiCQ5Bb2ISJL7/7dl6oLVEOX1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(train_error2))], train_error2, label='Training error')\n",
    "plt.plot([i for i in range(len(valid_error2))], valid_error2, label='Validation error')\n",
    "plt.gca().legend(('Training error','Validation error'))\n",
    "plt.title('Second Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  0\n",
      "Previous theta :  [1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5]\n",
      "New theta_0 : [1.43776642 1.29794495 1.58758672 1.29046651 1.45470428 1.30567128\n",
      " 1.56717293 1.32860196 1.63040565 1.28219499 1.28365147 1.36945835\n",
      " 1.56300111 1.34050264]\n",
      "Training Error:  124.46514624129296\n",
      "====================================================================================================\n",
      "Iteration:  1\n",
      "Previous theta :  [1.43776642 1.29794495 1.58758672 1.29046651 1.45470428 1.30567128\n",
      " 1.56717293 1.32860196 1.63040565 1.28219499 1.28365147 1.36945835\n",
      " 1.56300111 1.34050264]\n",
      "New theta_0 : [1.3770235  1.1346588  1.63869959 1.12891502 1.40988965 1.15681205\n",
      " 1.6122226  1.19753908 1.72093248 1.10606205 1.10925418 1.26346422\n",
      " 1.60277699 1.21515492]\n",
      "Training Error:  107.53699428164059\n",
      "====================================================================================================\n",
      "Iteration:  2\n",
      "Previous theta :  [1.3770235  1.1346588  1.63869959 1.12891502 1.40988965 1.15681205\n",
      " 1.6122226  1.19753908 1.72093248 1.10606205 1.10925418 1.26346422\n",
      " 1.60277699 1.21515492]\n",
      "New theta_0 : [1.31800702 1.00153594 1.66255066 1.00408046 1.36577406 1.04268913\n",
      " 1.64054704 1.09717316 1.78123069 0.96233965 0.96740305 1.17645531\n",
      " 1.62485097 1.11592832]\n",
      "Training Error:  95.42887472317697\n",
      "====================================================================================================\n",
      "Iteration:  3\n",
      "Previous theta :  [1.31800702 1.00153594 1.66255066 1.00408046 1.36577406 1.04268913\n",
      " 1.64054704 1.09717316 1.78123069 0.96233965 0.96740305 1.17645531\n",
      " 1.62485097 1.11592832]\n",
      "New theta_0 : [1.2608712  0.89195989 1.66616202 0.90733982 1.32251559 0.95508933\n",
      " 1.65626898 1.0201377  1.81867497 0.84390939 0.85087466 1.10416437\n",
      " 1.63345998 1.03667978]\n",
      "Training Error:  86.72716059684338\n",
      "====================================================================================================\n",
      "Iteration:  4\n",
      "Previous theta :  [1.2608712  0.89195989 1.66616202 0.90733982 1.32251559 0.95508933\n",
      " 1.65626898 1.0201377  1.81867497 0.84390939 0.85087466 1.10416437\n",
      " 1.63345998 1.03667978]\n",
      "New theta_0 : [1.20570902 0.80083881 1.65488051 0.83209307 1.28022655 0.88772876\n",
      " 1.66253519 0.96080491 1.83889827 0.7452955  0.75411737 1.04331624\n",
      " 1.63185511 0.97270975]\n",
      "Training Error:  80.36279430734079\n",
      "====================================================================================================\n",
      "Iteration:  5\n",
      "Previous theta :  [1.20570902 0.80083881 1.65488051 0.83209307 1.28022655 0.88772876\n",
      " 1.66253519 0.96080491 1.83889827 0.7452955  0.75411737 1.04331624\n",
      " 1.63185511 0.97270975]\n",
      "New theta_0 : [1.15256769 0.72424989 1.63277172 0.77328904 1.23898434 0.83580065\n",
      " 1.66174563 0.91487761 1.84620065 0.66228134 0.67286078 0.99139583\n",
      " 1.62253176 0.92042377]\n",
      "Training Error:  75.56526007491921\n",
      "====================================================================================================\n",
      "Iteration:  6\n",
      "Previous theta :  [1.15256769 0.72424989 1.63277172 0.77328904 1.23898434 0.83580065\n",
      " 1.66174563 0.91487761 1.84620065 0.66228134 0.67286078 0.99139583\n",
      " 1.62253176 0.92042377]\n",
      "New theta_0 : [1.1014605  0.65916677 1.60292161 0.72706239 1.19883971 0.79562895\n",
      " 1.65572894 0.8790768  1.84386221 0.59161583 0.60381669 0.94647049\n",
      " 1.60740593 0.8770733 ]\n",
      "Training Error:  71.80402155883813\n",
      "====================================================================================================\n",
      "Iteration:  7\n",
      "Previous theta :  [1.1014605  0.65916677 1.60292161 0.72706239 1.19883971 0.79562895\n",
      " 1.65572894 0.8790768  1.84386221 0.59161583 0.60381669 0.94647049\n",
      " 1.60740593 0.8770733 ]\n",
      "New theta_0 : [1.05237579 0.60325091 1.56766745 0.69045566 1.15982313 0.76440322\n",
      " 1.64587676 0.85090241 1.8343827  0.5307884  0.54444996 0.90705386\n",
      " 1.58794933 0.84055734]\n",
      "Training Error:  68.72710942807029\n",
      "====================================================================================================\n",
      "Iteration:  8\n",
      "Previous theta :  [1.05237579 0.60325091 1.56766745 0.69045566 1.15982313 0.76440322\n",
      " 1.64587676 0.85090241 1.8343827  0.5307884  0.54444996 0.90705386\n",
      " 1.58794933 0.84055734]\n",
      "New theta_0 : [1.00528377 0.55469161 1.52877451 0.66120641 1.12194966 0.73997554\n",
      " 1.6332466  0.82845018 1.81966498 0.4778567  0.49280302 0.87200171\n",
      " 1.56529285 0.80927048]\n",
      "Training Error:  66.10719378937749\n",
      "====================================================================================================\n",
      "Iteration:  9\n",
      "Previous theta :  [1.00528377 0.55469161 1.52877451 0.66120641 1.12194966 0.73997554\n",
      " 1.6332466  0.82845018 1.81966498 0.4778567  0.49280302 0.87200171\n",
      " 1.56529285 0.80927048]\n",
      "New theta_0 : [0.96014173 0.51208353 1.48757135 0.63758422 1.08522272 0.72070511\n",
      " 1.6186405  0.81027147 1.80115548 0.43131461 0.44736149 0.84043204\n",
      " 1.54030583 0.78198657]\n",
      "Training Error:  63.79991481328803\n",
      "====================================================================================================\n",
      "Iteration:  10\n",
      "Previous theta :  [0.96014173 0.51208353 1.48757135 0.63758422 1.08522272 0.72070511\n",
      " 1.6186405  0.81027147 1.80115548 0.43131461 0.44736149 0.84043204\n",
      " 1.54030583 0.78198657]\n",
      "New theta_0 : [0.916898   0.47433278 1.4450533  0.61826592 1.04963692 0.70533914\n",
      " 1.60266536 0.7952659  1.77995166 0.38999099 0.40695111 0.81166402\n",
      " 1.51365683 0.75776967]\n",
      "Training Error:  61.714355857752\n",
      "====================================================================================================\n",
      "Iteration:  11\n",
      "Previous theta :  [0.916898   0.47433278 1.4450533  0.61826592 1.04963692 0.70533914\n",
      " 1.60266536 0.7952659  1.77995166 0.38999099 0.40695111 0.81166402\n",
      " 1.51365683 0.75776967]\n",
      "New theta_0 : [0.87549484 0.44058498 1.40196165 0.60224003 1.01518031 0.69292179\n",
      " 1.58577903 0.78259923 1.75688434 0.35297223 0.37065891 0.78517104\n",
      " 1.4858602  0.73590585]\n",
      "Training Error:  59.79328086934771\n",
      "====================================================================================================\n",
      "Iteration:  12\n",
      "Previous theta :  [0.87549484 0.44058498 1.40196165 0.60224003 1.01518031 0.69292179\n",
      " 1.58577903 0.78259923 1.75688434 0.35297223 0.37065891 0.78517104\n",
      " 1.4858602  0.73590585]\n",
      "New theta_0 : [0.83587077 0.41017009 1.35884428 0.58873363 0.98183604 0.68272436\n",
      " 1.5683256  0.77164048 1.73258066 0.31954281 0.3377727  0.76054491\n",
      " 1.45731175 0.71585099]\n",
      "Training Error:  58.00038787530455\n",
      "====================================================================================================\n",
      "Iteration:  13\n",
      "Previous theta :  [0.83587077 0.41017009 1.35884428 0.58873363 0.98183604 0.68272436\n",
      " 1.5683256  0.77164048 1.73258066 0.31954281 0.3377727  0.76054491\n",
      " 1.45731175 0.71585099]\n",
      "New theta_0 : [0.79796214 0.38256013 1.31610192 0.5771563  0.94958369 0.67419186\n",
      " 1.5505624  0.76191384 1.70751232 0.28913975 0.30773469 0.73746836\n",
      " 1.42831614 0.69719083]\n",
      "Training Error:  56.31228146746825\n",
      "====================================================================================================\n",
      "Iteration:  14\n",
      "Previous theta :  [0.79796214 0.38256013 1.31610192 0.5771563  0.94958369 0.67419186\n",
      " 1.5505624  0.76191384 1.70751232 0.28913975 0.30773469 0.73746836\n",
      " 1.42831614 0.69719083]\n",
      "New theta_0 : [0.76170447 0.35733674 1.27402363 0.56705728 0.91840025 0.66690217\n",
      " 1.53268068 0.75306181 1.68203238 0.26131768 0.28010605 0.7156939\n",
      " 1.39910787 0.67961034]\n",
      "Training Error:  54.71349411183302\n",
      "====================================================================================================\n",
      "Iteration:  15\n",
      "Previous theta :  [0.76170447 0.35733674 1.27402363 0.56705728 0.91840025 0.66690217\n",
      " 1.53268068 0.75306181 1.68203238 0.26131768 0.28010605 0.7156939\n",
      " 1.39910787 0.67961034]\n",
      "New theta_0 : [0.7270333  0.33416626 1.23281385 0.55809263 0.88826087 0.66053468\n",
      " 1.51482141 0.74481708 1.65640358 0.23572206 0.25453957 0.69502777\n",
      " 1.36986734 0.66287034]\n",
      "Training Error:  53.19342862291542\n",
      "====================================================================================================\n",
      "Iteration:  16\n",
      "Previous theta :  [0.7270333  0.33416626 1.23281385 0.55809263 0.88826087 0.66053468\n",
      " 1.51482141 0.74481708 1.65640358 0.23572206 0.25453957 0.69502777\n",
      " 1.36986734 0.66287034]\n",
      "New theta_0 : [0.69388488 0.3127807  1.19261306 0.55000008 0.8591395  0.6548464\n",
      " 1.49708736 0.73698099 1.63081981 0.2120686  0.23075886 0.67531751\n",
      " 1.34073329 0.64678957]\n",
      "Training Error:  51.74449227472094\n",
      "====================================================================================================\n",
      "Iteration:  17\n",
      "Previous theta :  [0.69388488 0.3127807  1.19261306 0.55000008 0.8591395  0.6548464\n",
      " 1.49708736 0.73698099 1.63081981 0.2120686  0.23075886 0.67531751\n",
      " 1.34073329 0.64678957]\n",
      "New theta_0 : [0.66219668 0.292963   1.15351362 0.54257982 0.83100929 0.64965355\n",
      " 1.47955231 0.72940703 1.60542272 0.19012751 0.20854223 0.65644249\n",
      " 1.3118122  0.63123097]\n",
      "Training Error:  50.360962570220146\n",
      "====================================================================================================\n",
      "Iteration:  18\n",
      "Previous theta :  [0.66219668 0.292963   1.15351362 0.54257982 0.83100929 0.64965355\n",
      " 1.47955231 0.72940703 1.60542272 0.19012751 0.20854223 0.65644249\n",
      " 1.3118122  0.63123097]\n",
      "New theta_0 : [0.63190767 0.27453579 1.11557176 0.53567977 0.80384295 0.64481759\n",
      " 1.46226814 0.72198828 1.58031426 0.16971134 0.18771045 0.63830663\n",
      " 1.28318564 0.61609119]\n",
      "Training Error:  49.038299229174186\n",
      "====================================================================================================\n",
      "Iteration:  19\n",
      "Previous theta :  [0.63190767 0.27453579 1.11557176 0.53567977 0.80384295 0.64481759\n",
      " 1.46226814 0.72198828 1.58031426 0.16971134 0.18771045 0.63830663\n",
      " 1.28318564 0.61609119]\n",
      "New theta_0 : [0.60295863 0.25735272 1.0788168  0.52918431 0.77761305 0.64023446\n",
      " 1.4452702  0.71464781 1.55556633 0.15066572 0.16811728 0.62083281\n",
      " 1.25491587 0.60129257]\n",
      "Training Error:  47.77272705027199\n",
      "====================================================================================================\n",
      "Iteration:  20\n",
      "Previous theta :  [0.60295863 0.25735272 1.0788168  0.52918431 0.77761305 0.64023446\n",
      " 1.4452702  0.71464781 1.55556633 0.15066572 0.16811728 0.62083281\n",
      " 1.25491587 0.60129257]\n",
      "New theta_0 : [0.57529222 0.24129175 1.04325814 0.52300564 0.75229218 0.63582637\n",
      " 1.42858143 0.70733127 1.53122816 0.13286212 0.14964217 0.60395861\n",
      " 1.22705011 0.58677697]\n",
      "Training Error:  46.5609826519361\n",
      "====================================================================================================\n",
      "Iteration:  21\n",
      "Previous theta :  [0.57529222 0.24129175 1.04325814 0.52300564 0.75229218 0.63582637\n",
      " 1.42858143 0.70733127 1.53122816 0.13286212 0.14964217 0.60395861\n",
      " 1.22705011 0.58677697]\n",
      "New theta_0 : [0.54885312 0.22625007 1.00889056 0.51707722 0.72785313 0.63153553\n",
      " 1.41221548 0.70000138 1.50733194 0.11619238 0.13218474 0.58763302\n",
      " 1.19962391 0.57250114]\n",
      "Training Error:  45.40016010421925\n",
      "====================================================================================================\n",
      "Iteration:  22\n",
      "Previous theta :  [0.54885312 0.22625007 1.00889056 0.51707722 0.72785313 0.63153553\n",
      " 1.41221548 0.70000138 1.50733194 0.11619238 0.13218474 0.58763302\n",
      " 1.19962391 0.57250114]\n",
      "New theta_0 : [0.52358805 0.21214005 0.97569827 0.51134871 0.70426898 0.62731933\n",
      " 1.39617913 0.69263357 1.48389706 0.10056444 0.11566041 0.57181388\n",
      " 1.17266371 0.55843307]\n",
      "Training Error:  44.28761611515548\n",
      "====================================================================================================\n",
      "Iteration:  23\n",
      "Previous theta :  [0.52358805 0.21214005 0.97569827 0.51134871 0.70426898 0.62731933\n",
      " 1.39617913 0.69263357 1.48389706 0.10056444 0.11566041 0.57181388\n",
      " 1.17266371 0.55843307]\n",
      "New theta_0 : [0.49944581 0.19888626 0.94365797 0.50578208 0.68151323 0.6231467\n",
      " 1.38047407 0.68521278 1.46093341 0.08589904 0.09999713 0.55646599\n",
      " 1.14618878 0.54454928]\n",
      "Training Error:  43.22091102810634\n",
      "====================================================================================================\n",
      "Iteration:  24\n",
      "Previous theta :  [0.49944581 0.19888626 0.94365797 0.50578208 0.68151323 0.6231467\n",
      " 1.38047407 0.68521278 1.46093341 0.08589904 0.09999713 0.55646599\n",
      " 1.14618878 0.54454928]\n",
      "New theta_0 : [0.47637723 0.18642298 0.91274114 0.50034871 0.65955983 0.61899529\n",
      " 1.36509829 0.67773098 1.43844386 0.07212719 0.08513279 0.54155955\n",
      " 1.12021279 0.53083271]\n",
      "Training Error:  42.19777133465812\n",
      "====================================================================================================\n",
      "Iteration:  25\n",
      "Previous theta :  [0.47637723 0.18642298 0.91274114 0.50034871 0.65955983 0.61899529\n",
      " 1.36509829 0.67773098 1.43844386 0.07212719 0.08513279 0.54155955\n",
      " 1.12021279 0.53083271]\n",
      "New theta_0 : [0.45433514 0.17469245 0.8829158  0.49502711 0.63838326 0.61484933\n",
      " 1.35004713 0.67018525 1.41642612 0.05918821 0.07101325 0.52706908\n",
      " 1.09474497 0.51727117]\n",
      "Training Error:  41.21606511710118\n",
      "====================================================================================================\n",
      "Iteration:  26\n",
      "Previous theta :  [0.45433514 0.17469245 0.8829158  0.49502711 0.63838326 0.61484933\n",
      " 1.35004713 0.67018525 1.41642612 0.05918821 0.07101325 0.52706908\n",
      " 1.09474497 0.51727117]\n",
      "New theta_0 : [0.43327435 0.16364339 0.85414783 0.48980117 0.61795853 0.61069799\n",
      " 1.33531409 0.66257641 1.39487424 0.04702813 0.05759083 0.51297248\n",
      " 1.06979106 0.50385605]\n",
      "Training Error:  40.27378527660396\n",
      "====================================================================================================\n",
      "Iteration:  27\n",
      "Previous theta :  [0.43327435 0.16364339 0.85414783 0.48980117 0.61795853 0.61069799\n",
      " 1.33531409 0.66257641 1.39487424 0.04702813 0.05759083 0.51297248\n",
      " 1.06979106 0.50385605]\n",
      "New theta_0 : [0.4131516  0.15322985 0.82640188 0.48465892 0.59826123 0.60653415\n",
      " 1.32089139 0.6549079  1.37377959 0.0355986  0.04482304 0.49925039\n",
      " 1.04535399 0.49058146]\n",
      "Training Error:  39.36903747346554\n",
      "====================================================================================================\n",
      "Iteration:  28\n",
      "Previous theta :  [0.4131516  0.15322985 0.82640188 0.48465892 0.59826123 0.60653415\n",
      " 1.32089139 0.6549079  1.37377959 0.0355986  0.04482304 0.49925039\n",
      " 1.04535399 0.49058146]\n",
      "New theta_0 : [0.39392544 0.14341037 0.79964218 0.47959146 0.57926755 0.60235346\n",
      " 1.30677043 0.64718498 1.35313177 0.02485586 0.03267176 0.48588559\n",
      " 1.02143449 0.47744349]\n",
      "Training Error:  38.50003094790501\n",
      "====================================================================================================\n",
      "Iteration:  29\n",
      "Previous theta :  [0.39392544 0.14341037 0.79964218 0.47959146 0.57926755 0.60235346\n",
      " 1.30677043 0.64718498 1.35313177 0.02485586 0.03267176 0.48588559\n",
      " 1.02143449 0.47744349]\n",
      "New theta_0 : [0.37555625 0.13414726 0.77383297 0.47459221 0.56095426 0.5981536\n",
      " 1.29294214 0.63941413 1.3329192  0.01476003 0.0211024  0.47286266\n",
      " 0.9980315  0.46443968]\n",
      "Training Error:  37.66507113294787\n",
      "====================================================================================================\n",
      "Iteration:  30\n",
      "Previous theta :  [0.37555625 0.13414726 0.77383297 0.47459221 0.56095426 0.5981536\n",
      " 1.29294214 0.63941413 1.3329192  0.01476003 0.0211024  0.47286266\n",
      " 0.9980315  0.46443968]\n",
      "New theta_0 : [0.35800611 0.12540603 0.74893896 0.46965634 0.54329877 0.59393374\n",
      " 1.2793972  0.63160257 1.31312954 0.00527456 0.0100834  0.46016762\n",
      " 0.97514251 0.45156863]\n",
      "Training Error:  36.86255341410501\n",
      "====================================================================================================\n",
      "Iteration:  31\n",
      "Previous theta :  [0.35800611 0.12540603 0.74893896 0.46965634 0.54329877 0.59393374\n",
      " 1.2793972  0.63160257 1.31312954 0.00527456 0.0100834  0.46016762\n",
      " 0.97514251 0.45156863]\n",
      "New theta_0 : [ 3.41238757e-01  1.17154976e-01  7.24925581e-01  4.64780321e-01\n",
      "  5.26279075e-01  5.89694127e-01  1.26612625e+00  6.23757959e-01\n",
      "  1.29375008e+00 -3.63429313e-03 -4.14239706e-04  4.47787697e-01\n",
      "  9.52763862e-01  4.38829678e-01]\n",
      "Training Error:  36.09095765378493\n",
      "====================================================================================================\n",
      "Iteration:  32\n",
      "Previous theta :  [ 3.41238757e-01  1.17154976e-01  7.24925581e-01  4.64780321e-01\n",
      "  5.26279075e-01  5.89694127e-01  1.26612625e+00  6.23757959e-01\n",
      "  1.29375008e+00 -3.63429313e-03 -4.14239706e-04  4.47787697e-01\n",
      "  9.52763862e-01  4.38829678e-01]\n",
      "New theta_0 : [ 0.32521954  0.10936482  0.70175914  0.4599616   0.50987377  0.58543577\n",
      "  1.25311999  0.6158881   1.27476797 -0.01199778 -0.01041733  0.43571111\n",
      "  0.93089095  0.42622266]\n",
      "Training Error:  35.348843254051275\n",
      "====================================================================================================\n",
      "Iteration:  33\n",
      "Previous theta :  [ 0.32521954  0.10936482  0.70175914  0.4599616   0.50987377  0.58543577\n",
      "  1.25311999  0.6158881   1.27476797 -0.01199778 -0.01041733  0.43571111\n",
      "  0.93089095  0.42622266]\n",
      "New theta_0 : [ 0.30991531  0.10200839  0.67940699  0.45519832  0.49406207  0.58116019\n",
      "  1.24036933  0.60800079  1.25617041 -0.01984499 -0.01995078  0.42392694\n",
      "  0.90951841  0.41374777]\n",
      "Training Error:  34.634844622899465\n",
      "====================================================================================================\n",
      "Iteration:  34\n",
      "Previous theta :  [ 0.30991531  0.10200839  0.67940699  0.45519832  0.49406207  0.58116019\n",
      "  1.24036933  0.60800079  1.25617041 -0.01984499 -0.01995078  0.42392694\n",
      "  0.90951841  0.41374777]\n",
      "New theta_0 : [ 0.2952944   0.09506042  0.65783758  0.45048915  0.47882378  0.5768693\n",
      "  1.22786537  0.60010369  1.23794479 -0.02720311 -0.02903782  0.41242498\n",
      "  0.88864024  0.40140541]\n",
      "Training Error:  33.94766696274165\n",
      "====================================================================================================\n",
      "Iteration:  35\n",
      "Previous theta :  [ 0.2952944   0.09506042  0.65783758  0.45048915  0.47882378  0.5768693\n",
      "  1.22786537  0.60010369  1.23794479 -0.02720311 -0.02903782  0.41242498\n",
      "  0.88864024  0.40140541]\n",
      "New theta_0 : [ 0.28132652  0.08849733  0.6370205   0.44583312  0.4641393   0.57256518\n",
      "  1.21559953  0.5922042   1.22007877 -0.0340976  -0.03770019  0.40119566\n",
      "  0.86824995  0.38919609]\n",
      "Training Error:  33.286082330840124\n",
      "====================================================================================================\n",
      "Iteration:  36\n",
      "Previous theta :  [ 0.28132652  0.08849733  0.6370205   0.44583312  0.4641393   0.57256518\n",
      "  1.21559953  0.5922042   1.22007877 -0.0340976  -0.03770019  0.40119566\n",
      "  0.86824995  0.38919609]\n",
      "New theta_0 : [ 0.26798276  0.08229707  0.61692654  0.44122953  0.44998959  0.56825006\n",
      "  1.20356353  0.58430943  1.20256033 -0.04055235 -0.04595831  0.39022998\n",
      "  0.84834061  0.37712036]\n",
      "Training Error:  32.648925939303474\n",
      "====================================================================================================\n",
      "Iteration:  37\n",
      "Previous theta :  [ 0.26798276  0.08229707  0.61692654  0.44122953  0.44998959  0.56825006\n",
      "  1.20356353  0.58430943  1.20256033 -0.04055235 -0.04595831  0.39022998\n",
      "  0.84834061  0.37712036]\n",
      "New theta_0 : [ 0.25523545  0.07643899  0.59752762  0.43667787  0.4363562   0.56392621\n",
      "  1.1917494   0.57642617  1.18537786 -0.04658987 -0.0538314   0.37951938\n",
      "  0.82890497  0.36517878]\n",
      "Training Error:  32.03509267246702\n",
      "====================================================================================================\n",
      "Iteration:  38\n",
      "Previous theta :  [ 0.25523545  0.07643899  0.59752762  0.43667787  0.4363562   0.56392621\n",
      "  1.1917494   0.57642617  1.18537786 -0.04658987 -0.0538314   0.37951938\n",
      "  0.82890497  0.36517878]\n",
      "New theta_0 : [ 0.24305817  0.07090371  0.57879683  0.43217772  0.42322123  0.5595959\n",
      "  1.18014954  0.56856082  1.16852015 -0.05223136 -0.06133756  0.3690558\n",
      "  0.80993551  0.35337186]\n",
      "Training Error:  31.44353380527211\n",
      "====================================================================================================\n",
      "Iteration:  39\n",
      "Previous theta :  [ 0.24305817  0.07090371  0.57879683  0.43217772  0.42322123  0.5595959\n",
      "  1.18014954  0.56856082  1.16852015 -0.05223136 -0.06133756  0.3690558\n",
      "  0.80993551  0.35337186]\n",
      "New theta_0 : [ 0.23142567  0.065673    0.56070837  0.42772877  0.41056734  0.55526134\n",
      "  1.16875665  0.56071942  1.15197641 -0.05749683 -0.06849394  0.35883151\n",
      "  0.79142449  0.34170004]\n",
      "Training Error:  30.87325390954551\n",
      "====================================================================================================\n",
      "Iteration:  40\n",
      "Previous theta :  [ 0.23142567  0.065673    0.56070837  0.42772877  0.41056734  0.55526134\n",
      "  1.16875665  0.56071942  1.15197641 -0.05749683 -0.06849394  0.35883151\n",
      "  0.79142449  0.34170004]\n",
      "New theta_0 : [ 0.22031382  0.06072974  0.54323756  0.42333072  0.39837772  0.55092469\n",
      "  1.15756379  0.55290762  1.13573625 -0.06240521 -0.07531672  0.3488392\n",
      "  0.77336398  0.33016368]\n",
      "Training Error:  30.323307936967623\n",
      "====================================================================================================\n",
      "Iteration:  41\n",
      "Previous theta :  [ 0.22031382  0.06072974  0.54323756  0.42333072  0.39837772  0.55092469\n",
      "  1.15756379  0.55290762  1.13573625 -0.06240521 -0.07531672  0.3488392\n",
      "  0.77336398  0.33016368]\n",
      "New theta_0 : [ 0.20969955  0.0560578   0.52636075  0.41898332  0.38663608  0.54658801\n",
      "  1.14656433  0.5451307   1.11978975 -0.06697439 -0.08182127  0.33907184\n",
      "  0.75574595  0.31876305]\n",
      "Training Error:  29.792798468644865\n",
      "====================================================================================================\n",
      "Iteration:  42\n",
      "Previous theta :  [ 0.20969955  0.0560578   0.52636075  0.41898332  0.38663608  0.54658801\n",
      "  1.14656433  0.5451307   1.11978975 -0.06697439 -0.08182127  0.33907184\n",
      "  0.75574595  0.31876305]\n",
      "New theta_0 : [ 0.19956082  0.05164198  0.51005534  0.41468628  0.37532666  0.54225328\n",
      "  1.13575195  0.53739356  1.10412737 -0.07122132 -0.08802213  0.32952273\n",
      "  0.73856224  0.30749831]\n",
      "Training Error:  29.28087312192653\n",
      "====================================================================================================\n",
      "Iteration:  43\n",
      "Previous theta :  [ 0.19956082  0.05164198  0.51005534  0.41468628  0.37532666  0.54225328\n",
      "  1.13575195  0.53739356  1.10412737 -0.07122132 -0.08802213  0.32952273\n",
      "  0.73856224  0.30749831]\n",
      "New theta_0 : [ 0.18987659  0.04746795  0.49429969  0.41043935  0.36443419  0.53792236\n",
      "  1.12512065  0.52970077  1.08873999 -0.07516206 -0.09393312  0.32018544\n",
      "  0.72180464  0.29636953]\n",
      "Training Error:  28.786722105629625\n",
      "====================================================================================================\n",
      "Iteration:  44\n",
      "Previous theta :  [ 0.18987659  0.04746795  0.49429969  0.41043935  0.36443419  0.53792236\n",
      "  1.12512065  0.52970077  1.08873999 -0.07516206 -0.09393312  0.32018544\n",
      "  0.72180464  0.29636953]\n",
      "New theta_0 : [ 0.18062672  0.0435222   0.4790731   0.40624222  0.35394388  0.533597\n",
      "  1.11466471  0.52205654  1.07361887 -0.07881183 -0.09956736  0.31105383\n",
      "  0.70546489  0.28537666]\n",
      "Training Error:  28.309575915263686\n",
      "====================================================================================================\n",
      "Iteration:  45\n",
      "Previous theta :  [ 0.18062672  0.0435222   0.4790731   0.40624222  0.35394388  0.533597\n",
      "  1.11466471  0.52205654  1.07361887 -0.07881183 -0.09956736  0.31105383\n",
      "  0.70546489  0.28537666]\n",
      "New theta_0 : [ 0.17179197  0.03979197  0.46435578  0.40209458  0.34384144  0.52927885\n",
      "  1.10437868  0.51446474  1.05875567 -0.08218507 -0.10493734  0.30212196\n",
      "  0.68953472  0.27451958]\n",
      "Training Error:  27.848703160235967\n",
      "====================================================================================================\n",
      "Iteration:  46\n",
      "Previous theta :  [ 0.17179197  0.03979197  0.46435578  0.40209458  0.34384144  0.52927885\n",
      "  1.10437868  0.51446474  1.05875567 -0.08218507 -0.10493734  0.30212196\n",
      "  0.68953472  0.27451958]\n",
      "New theta_0 : [ 0.16335398  0.03626523  0.45012879  0.39799608  0.33411303  0.52496945\n",
      "  1.09425741  0.50692894  1.04414239 -0.08529548 -0.1100549   0.29338416\n",
      "  0.67400582  0.26379803]\n",
      "Training Error:  27.403408515391554\n",
      "====================================================================================================\n",
      "Iteration:  47\n",
      "Previous theta :  [ 0.16335398  0.03626523  0.45012879  0.39799608  0.33411303  0.52496945\n",
      "  1.09425741  0.50692894  1.04414239 -0.08529548 -0.1100549   0.29338416\n",
      "  0.67400582  0.26379803]\n",
      "New theta_0 : [ 0.15529518  0.03293061  0.43637401  0.39394636  0.32474528  0.52067025\n",
      "  1.08429596  0.49945241  1.02977139 -0.08815609 -0.11493135  0.28483496\n",
      "  0.65886994  0.25321169]\n",
      "Training Error:  26.973030789612952\n",
      "====================================================================================================\n",
      "Iteration:  48\n",
      "Previous theta :  [ 0.15529518  0.03293061  0.43637401  0.39394636  0.32474528  0.52067025\n",
      "  1.08429596  0.49945241  1.02977139 -0.08815609 -0.11493135  0.28483496\n",
      "  0.65886994  0.25321169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.14759877  0.02977739  0.4230741   0.38994501  0.31572523  0.51638256\n",
      "  1.07448966  0.49203814  1.01563538 -0.09077924 -0.11957742  0.27646912\n",
      "  0.64411883  0.24276013]\n",
      "Training Error:  26.556941104572456\n",
      "====================================================================================================\n",
      "Iteration:  49\n",
      "Previous theta :  [ 0.14759877  0.02977739  0.4230741   0.38994501  0.31572523  0.51638256\n",
      "  1.07448966  0.49203814  1.01563538 -0.09077924 -0.11957742  0.27646912\n",
      "  0.64411883  0.24276013]\n",
      "New theta_0 : [ 0.14024872  0.0267954   0.41021249  0.38599162  0.30704037  0.51210764\n",
      "  1.06483405  0.48468885  1.00172736 -0.09317667 -0.12400335  0.26828155\n",
      "  0.62974428  0.23244285]\n",
      "Training Error:  26.154541177096174\n",
      "====================================================================================================\n",
      "Iteration:  50\n",
      "Previous theta :  [ 0.14024872  0.0267954   0.41021249  0.38599162  0.30704037  0.51210764\n",
      "  1.06483405  0.48468885  1.00172736 -0.09317667 -0.12400335  0.26828155\n",
      "  0.62974428  0.23244285]\n",
      "New theta_0 : [ 0.13322969  0.02397509  0.39777327  0.38208573  0.29867862  0.50784661\n",
      "  1.05532491  0.47740701  0.98804065 -0.09535955 -0.12821888  0.26026739\n",
      "  0.61573816  0.22225927]\n",
      "Training Error:  25.7652616989589\n",
      "====================================================================================================\n",
      "Iteration:  51\n",
      "Previous theta :  [ 0.13322969  0.02397509  0.39777327  0.38208573  0.29867862  0.50784661\n",
      "  1.05532491  0.47740701  0.98804065 -0.09535955 -0.12821888  0.26026739\n",
      "  0.61573816  0.22225927]\n",
      "New theta_0 : [ 0.12652703  0.02130739  0.38574126  0.37822688  0.29062827  0.50360055\n",
      "  1.0459582   0.47019485  0.97456884 -0.09733846 -0.13223329  0.25242194\n",
      "  0.60209237  0.21220872]\n",
      "Training Error:  25.388560808281145\n",
      "====================================================================================================\n",
      "Iteration:  52\n",
      "Previous theta :  [ 0.12652703  0.02130739  0.38574126  0.37822688  0.29062827  0.50360055\n",
      "  1.0459582   0.47019485  0.97456884 -0.09733846 -0.13223329  0.25242194\n",
      "  0.60209237  0.21220872]\n",
      "New theta_0 : [ 0.12012674  0.01878375  0.37410189  0.37441457  0.28287804  0.49937042\n",
      "  1.03673008  0.46305438  0.96130583 -0.09912349 -0.13605545  0.24474066\n",
      "  0.58879892  0.20229048]\n",
      "Training Error:  25.02392264704064\n",
      "====================================================================================================\n",
      "Iteration:  53\n",
      "Previous theta :  [ 0.12012674  0.01878375  0.37410189  0.37441457  0.28287804  0.49937042\n",
      "  1.03673008  0.46305438  0.96130583 -0.09912349 -0.13605545  0.24474066\n",
      "  0.58879892  0.20229048]\n",
      "New theta_0 : [ 0.11401543  0.01639607  0.36284122  0.37064829  0.27541701  0.4951571\n",
      "  1.0276369   0.4559874   0.94824575 -0.10072422 -0.13969378  0.23721918\n",
      "  0.57584987  0.19250375]\n",
      "Training Error:  24.670855999539054\n",
      "====================================================================================================\n",
      "Iteration:  54\n",
      "Previous theta :  [ 0.11401543  0.01639607  0.36284122  0.37064829  0.27541701  0.4951571\n",
      "  1.0276369   0.4559874   0.94824575 -0.10072422 -0.13969378  0.23721918\n",
      "  0.57584987  0.19250375]\n",
      "New theta_0 : [ 0.1081803   0.01413673  0.35194588  0.36692751  0.26823464  0.49096143\n",
      "  1.01867518  0.44899551  0.93538299 -0.10214978 -0.14315634  0.22985329\n",
      "  0.56323738  0.18284767]\n",
      "Training Error:  24.328893006978834\n",
      "====================================================================================================\n",
      "Iteration:  55\n",
      "Previous theta :  [ 0.1081803   0.01413673  0.35194588  0.36692751  0.26823464  0.49096143\n",
      "  1.01867518  0.44899551  0.93538299 -0.10214978 -0.14315634  0.22985329\n",
      "  0.56323738  0.18284767]\n",
      "New theta_0 : [ 0.10260913  0.01199849  0.34140307  0.36325169  0.26132075  0.48678414\n",
      "  1.0098416   0.44208013  0.92271218 -0.10340882 -0.1464508   0.2226389\n",
      "  0.55095372  0.17332135]\n",
      "Training Error:  23.997587953603873\n",
      "====================================================================================================\n",
      "Iteration:  56\n",
      "Previous theta :  [ 0.10260913  0.01199849  0.34140307  0.36325169  0.26132075  0.48678414\n",
      "  1.0098416   0.44208013  0.92271218 -0.10340882 -0.1464508   0.2226389\n",
      "  0.55095372  0.17332135]\n",
      "New theta_0 : [ 0.09729023  0.00997452  0.33120051  0.35962027  0.2546655   0.48262592\n",
      "  1.00113298  0.43524252  0.91022816 -0.10450961 -0.14958449  0.21557208\n",
      "  0.53899124  0.16392381]\n",
      "Training Error:  23.67651612014113\n",
      "====================================================================================================\n",
      "Iteration:  57\n",
      "Previous theta :  [ 0.09729023  0.00997452  0.33120051  0.35962027  0.2546655   0.48262592\n",
      "  1.00113298  0.43524252  0.91022816 -0.10450961 -0.14958449  0.21557208\n",
      "  0.53899124  0.16392381]\n",
      "New theta_0 : [ 0.09221243  0.00805837  0.32132643  0.35603267  0.2482594   0.47848739\n",
      "  0.99254633  0.42848375  0.89792599 -0.10545998 -0.1525644   0.20864902\n",
      "  0.5273424   0.15465406]\n",
      "Training Error:  23.365272700547646\n",
      "====================================================================================================\n",
      "Iteration:  58\n",
      "Previous theta :  [ 0.09221243  0.00805837  0.32132643  0.35603267  0.2482594   0.47848739\n",
      "  0.99254633  0.42848375  0.89792599 -0.10545998 -0.1525644   0.20864902\n",
      "  0.5273424   0.15465406]\n",
      "New theta_0 : [ 0.08736505  0.00624393  0.31176954  0.35248832  0.24209329  0.47436911\n",
      "  0.98407874  0.42180476  0.88580094 -0.10626741 -0.1553972   0.20186606\n",
      "  0.51599978  0.14551104]\n",
      "Training Error:  23.063471778319503\n",
      "====================================================================================================\n",
      "Iteration:  59\n",
      "Previous theta :  [ 0.08736505  0.00624393  0.31176954  0.35248832  0.24209329  0.47436911\n",
      "  0.98407874  0.42180476  0.88580094 -0.10626741 -0.1553972   0.20186606\n",
      "  0.51599978  0.14551104]\n",
      "New theta_0 : [ 0.08273789  0.00452542  0.302519    0.34898664  0.23615832  0.47027158\n",
      "  0.97572746  0.41520635  0.87384846 -0.10693901 -0.15808925  0.19521964\n",
      "  0.50495606  0.13649368]\n",
      "Training Error:  22.770745358855606\n",
      "====================================================================================================\n",
      "Iteration:  60\n",
      "Previous theta :  [ 0.08273789  0.00452542  0.302519    0.34898664  0.23615832  0.47027158\n",
      "  0.97572746  0.41520635  0.87384846 -0.10693901 -0.15808925  0.19521964\n",
      "  0.50495606  0.13649368]\n",
      "New theta_0 : [ 0.07832118  0.00289739  0.29356442  0.34552702  0.23044596  0.46619526\n",
      "  0.96748988  0.40868918  0.86206419 -0.10748156 -0.16064664  0.18870632\n",
      "  0.49420406  0.12760084]\n",
      "Training Error:  22.48674245459125\n",
      "====================================================================================================\n",
      "Iteration:  61\n",
      "Previous theta :  [ 0.07832118  0.00289739  0.29356442  0.34552702  0.23044596  0.46619526\n",
      "  0.96748988  0.40868918  0.86206419 -0.10748156 -0.16064664  0.18870632\n",
      "  0.49420406  0.12760084]\n",
      "New theta_0 : [ 0.07410561  0.00135469  0.28489582  0.34210887  0.22494797  0.46214056\n",
      "  0.95936346  0.40225379  0.85044395 -0.10790149 -0.16307519  0.18232277\n",
      "  0.48373669  0.11883139]\n",
      "Training Error:  22.211128219823948\n",
      "====================================================================================================\n",
      "Iteration:  62\n",
      "Previous theta :  [ 0.07410561  0.00135469  0.28489582  0.34210887  0.22494797  0.46214056\n",
      "  0.95936346  0.40225379  0.85044395 -0.10790149 -0.16307519  0.18232277\n",
      "  0.48373669  0.11883139]\n",
      "New theta_0 : [ 7.00822550e-02 -1.07576063e-04  2.76503619e-01  3.38731595e-01\n",
      "  2.19656395e-01  4.58107841e-01  9.51345795e-01  3.95900598e-01\n",
      "  8.38983713e-01 -1.08204940e-01 -1.65380427e-01  1.76065773e-01\n",
      "  4.73546991e-01  1.10184130e-01]\n",
      "Training Error:  21.9435831323482\n",
      "====================================================================================================\n",
      "Iteration:  63\n",
      "Previous theta :  [ 7.00822550e-02 -1.07576063e-04  2.76503619e-01  3.38731595e-01\n",
      "  2.19656395e-01  4.58107841e-01  9.51345795e-01  3.95900598e-01\n",
      "  8.38983713e-01 -1.08204940e-01 -1.65380427e-01  1.76065773e-01\n",
      "  4.73546991e-01  1.10184130e-01]\n",
      "New theta_0 : [ 0.0662426  -0.00149401  0.2683786   0.33539459  0.21456357  0.45409743\n",
      "  0.94343459  0.38962993  0.82767961 -0.10839776 -0.16756767  0.16993222\n",
      "  0.46362814  0.10165786]\n",
      "Training Error:  21.683802219197453\n",
      "====================================================================================================\n",
      "Iteration:  64\n",
      "Previous theta :  [ 0.0662426  -0.00149401  0.2683786   0.33539459  0.21456357  0.45409743\n",
      "  0.94343459  0.38962993  0.82767961 -0.10839776 -0.16756767  0.16993222\n",
      "  0.46362814  0.10165786]\n",
      "New theta_0 : [ 0.0625785  -0.00280899  0.26051193  0.33209724  0.20966211  0.45010961\n",
      "  0.93562763  0.38344201  0.81652792 -0.10848552 -0.16964197  0.16391908\n",
      "  0.45397342  0.09325136]\n",
      "Training Error:  21.43149432396065\n",
      "====================================================================================================\n",
      "Iteration:  65\n",
      "Previous theta :  [ 0.0625785  -0.00280899  0.26051193  0.33209724  0.20966211  0.45010961\n",
      "  0.93562763  0.38344201  0.81652792 -0.10848552 -0.16964197  0.16391908\n",
      "  0.45397342  0.09325136]\n",
      "New theta_0 : [ 0.05908217 -0.00405662  0.25289509  0.32883895  0.20494487  0.44614463\n",
      "  0.92792279  0.37733695  0.80552508 -0.10847352 -0.17160819  0.15802345\n",
      "  0.44457626  0.08496338]\n",
      "Training Error:  21.18638141329885\n",
      "====================================================================================================\n",
      "Iteration:  66\n",
      "Previous theta :  [ 0.05908217 -0.00405662  0.25289509  0.32883895  0.20494487  0.44614463\n",
      "  0.92792279  0.37733695  0.80552508 -0.10847352 -0.17160819  0.15802345\n",
      "  0.44457626  0.08496338]\n",
      "New theta_0 : [ 0.05574616 -0.00524081  0.24551993  0.32561913  0.20040497  0.44220271\n",
      "  0.92031806  0.37131481  0.79466763 -0.10836682 -0.17347094  0.15224247\n",
      "  0.4354302   0.07679265]\n",
      "Training Error:  20.948197920435025\n",
      "====================================================================================================\n",
      "Iteration:  67\n",
      "Previous theta :  [ 0.05574616 -0.00524081  0.24551993  0.32561913  0.20040497  0.44220271\n",
      "  0.92031806  0.37131481  0.79466763 -0.10836682 -0.17347094  0.15224247\n",
      "  0.4354302   0.07679265]\n",
      "New theta_0 : [ 0.05256337 -0.00636525  0.23837857  0.32243716  0.19603577  0.43828402\n",
      "  0.91281146  0.36537554  0.78395228 -0.10817022 -0.17523466  0.14657342\n",
      "  0.42652889  0.0687379 ]\n",
      "Training Error:  20.716690123527215\n",
      "====================================================================================================\n",
      "Iteration:  68\n",
      "Previous theta :  [ 0.05256337 -0.00636525  0.23837857  0.32243716  0.19603577  0.43828402\n",
      "  0.91281146  0.36537554  0.78395228 -0.10817022 -0.17523466  0.14657342\n",
      "  0.42652889  0.0687379 ]\n",
      "New theta_0 : [ 0.04952699 -0.00743343  0.23146345  0.31929245  0.1918309   0.43438873\n",
      "  0.90540114  0.35951902  0.77337583 -0.10788833 -0.17690357  0.14101363\n",
      "  0.41786616  0.06079783]\n",
      "Training Error:  20.491615556963893\n",
      "====================================================================================================\n",
      "Iteration:  69\n",
      "Previous theta :  [ 0.04952699 -0.00743343  0.23146345  0.31929245  0.1918309   0.43438873\n",
      "  0.90540114  0.35951902  0.77337583 -0.10788833 -0.17690357  0.14101363\n",
      "  0.41786616  0.06079783]\n",
      "New theta_0 : [ 0.04663051 -0.00844863  0.22476731  0.31618442  0.18778417  0.43051697\n",
      "  0.89808528  0.35374508  0.76293521 -0.10752551 -0.17848173  0.13556051\n",
      "  0.4094359   0.05297114]\n",
      "Training Error:  20.272742453739557\n",
      "====================================================================================================\n",
      "Iteration:  70\n",
      "Previous theta :  [ 0.04663051 -0.00844863  0.22476731  0.31618442  0.18778417  0.43051697\n",
      "  0.89808528  0.35374508  0.76293521 -0.10752551 -0.17848173  0.13556051\n",
      "  0.4094359   0.05297114]\n",
      "New theta_0 : [ 0.04386773 -0.00941399  0.21828315  0.31311247  0.18388964  0.42666883\n",
      "  0.89086216  0.34805346  0.75262745 -0.10708593 -0.179973    0.13021156\n",
      "  0.40123218  0.04525653]\n",
      "Training Error:  20.059849217180474\n",
      "====================================================================================================\n",
      "Iteration:  71\n",
      "Previous theta :  [ 0.04386773 -0.00941399  0.21828315  0.31311247  0.18388964  0.42666883\n",
      "  0.89086216  0.34805346  0.75262745 -0.10708593 -0.179973    0.13021156\n",
      "  0.40123218  0.04525653]\n",
      "New theta_0 : [ 0.0412327  -0.01033244  0.21200421  0.31007603  0.18014158  0.4228444\n",
      "  0.8837301   0.34244388  0.7424497  -0.10657357 -0.1813811   0.12496436\n",
      "  0.39324916  0.03765268]\n",
      "Training Error:  19.852723920394293\n",
      "====================================================================================================\n",
      "Iteration:  72\n",
      "Previous theta :  [ 0.0412327  -0.01033244  0.21200421  0.31007603  0.18014158  0.4228444\n",
      "  0.8837301   0.34244388  0.7424497  -0.10657357 -0.1813811   0.12496436\n",
      "  0.39324916  0.03765268]\n",
      "New theta_0 : [ 0.03871974 -0.01120676  0.205924    0.30707451  0.17653448  0.41904373\n",
      "  0.8766875   0.33691595  0.7323992  -0.10599222 -0.18270957  0.11981654\n",
      "  0.38548115  0.03015826]\n",
      "Training Error:  19.651163831914545\n",
      "====================================================================================================\n",
      "Iteration:  73\n",
      "Previous theta :  [ 0.03871974 -0.01120676  0.205924    0.30707451  0.17653448  0.41904373\n",
      "  0.8766875   0.33691595  0.7323992  -0.10599222 -0.18270957  0.11981654\n",
      "  0.38548115  0.03015826]\n",
      "New theta_0 : [ 0.03632342 -0.01203961  0.20003629  0.30410734  0.17306301  0.41526688\n",
      "  0.8697328   0.33146929  0.7224733  -0.10534549 -0.1839618   0.11476582\n",
      "  0.37792257  0.02277195]\n",
      "Training Error:  19.454974966101766\n",
      "====================================================================================================\n",
      "Iteration:  74\n",
      "Previous theta :  [ 0.03632342 -0.01203961  0.20003629  0.30410734  0.17306301  0.41526688\n",
      "  0.8697328   0.33146929  0.7224733  -0.10534549 -0.1839618   0.11476582\n",
      "  0.37792257  0.02277195]\n",
      "New theta_0 : [ 0.03403856 -0.01283345  0.19433503  0.30117397  0.16972204  0.41151385\n",
      "  0.86286451  0.32610343  0.71266942 -0.10463682 -0.18514105  0.10980997\n",
      "  0.37056797  0.01549243]\n",
      "Training Error:  19.263971656947554\n",
      "====================================================================================================\n",
      "Iteration:  75\n",
      "Previous theta :  [ 0.03403856 -0.01283345  0.19433503  0.30117397  0.16972204  0.41151385\n",
      "  0.86286451  0.32610343  0.71266942 -0.10463682 -0.18514105  0.10980997\n",
      "  0.37056797  0.01549243]\n",
      "New theta_0 : [ 0.03186019 -0.01359066  0.18881443  0.29827384  0.16650664  0.40778465\n",
      "  0.85608118  0.32081786  0.70298508 -0.10386951 -0.18625041  0.10494684\n",
      "  0.363412    0.00831836]\n",
      "Training Error:  19.077976154007203\n",
      "====================================================================================================\n",
      "Iteration:  76\n",
      "Previous theta :  [ 0.03186019 -0.01359066  0.18881443  0.29827384  0.16650664  0.40778465\n",
      "  0.85608118  0.32081786  0.70298508 -0.10386951 -0.18625041  0.10494684\n",
      "  0.363412    0.00831836]\n",
      "New theta_0 : [ 0.02978357 -0.01431344  0.18346888  0.2954064   0.16341204  0.40407927\n",
      "  0.84938141  0.31561207  0.69341789 -0.10304668 -0.18729288  0.10017432\n",
      "  0.35644947  0.00124843]\n",
      "Training Error:  18.896818239260543\n",
      "====================================================================================================\n",
      "Iteration:  77\n",
      "Previous theta :  [ 0.02978357 -0.01431344  0.18346888  0.2954064   0.16341204  0.40407927\n",
      "  0.84938141  0.31561207  0.69341789 -0.10304668 -0.18729288  0.10017432\n",
      "  0.35644947  0.00124843]\n",
      "New theta_0 : [ 0.02780415 -0.01500391  0.17829299  0.29257111  0.16043366  0.40039769\n",
      "  0.84276386  0.31048546  0.68396552 -0.10217133 -0.1882713   0.09549039\n",
      "  0.34967528 -0.00571869]\n",
      "Training Error:  18.72033486376981\n",
      "====================================================================================================\n",
      "Iteration:  78\n",
      "Previous theta :  [ 0.02780415 -0.01500391  0.17829299  0.29257111  0.16043366  0.40039769\n",
      "  0.84276386  0.31048546  0.68396552 -0.10217133 -0.1882713   0.09549039\n",
      "  0.34967528 -0.00571869]\n",
      "New theta_0 : [ 0.02591762 -0.01566404  0.17328155  0.28976743  0.15756709  0.39673987\n",
      "  0.8362272   0.30543744  0.67462575 -0.10124631 -0.18918841  0.09089306\n",
      "  0.34308445 -0.01258434]\n",
      "Training Error:  18.548369803068308\n",
      "====================================================================================================\n",
      "Iteration:  79\n",
      "Previous theta :  [ 0.02591762 -0.01566404  0.17328155  0.28976743  0.15756709  0.39673987\n",
      "  0.8362272   0.30543744  0.67462575 -0.10124631 -0.18918841  0.09089306\n",
      "  0.34308445 -0.01258434]\n",
      "New theta_0 : [ 0.02411982 -0.01629572  0.16842953  0.28699485  0.15480806  0.39310575\n",
      "  0.82977019  0.30046738  0.66539639 -0.10027434 -0.19004681  0.08638041\n",
      "  0.33667213 -0.01934981]\n",
      "Training Error:  18.380773330274312\n",
      "====================================================================================================\n",
      "Iteration:  80\n",
      "Previous theta :  [ 0.02411982 -0.01629572  0.16842953  0.28699485  0.15480806  0.39310575\n",
      "  0.82977019  0.30046738  0.66539639 -0.10027434 -0.19004681  0.08638041\n",
      "  0.33667213 -0.01934981]\n",
      "New theta_0 : [ 0.02240679 -0.01690073  0.1637321   0.28425285  0.15215248  0.38949527\n",
      "  0.82339158  0.29557459  0.65627534 -0.09925801 -0.19084903  0.08195056\n",
      "  0.33043358 -0.02601642]\n",
      "Training Error:  18.21740190598148\n",
      "====================================================================================================\n",
      "Iteration:  81\n",
      "Previous theta :  [ 0.02240679 -0.01690073  0.1637321   0.28425285  0.15215248  0.38949527\n",
      "  0.82339158  0.29557459  0.65627534 -0.09925801 -0.19084903  0.08195056\n",
      "  0.33043358 -0.02601642]\n",
      "New theta_0 : [ 0.02077475 -0.01748073  0.15918456  0.28154092  0.14959641  0.38590836\n",
      "  0.81709018  0.29075841  0.64726058 -0.09819981 -0.19159746  0.07760169\n",
      "  0.32436415 -0.03258549]\n",
      "Training Error:  18.058117884030644\n",
      "====================================================================================================\n",
      "Iteration:  82\n",
      "Previous theta :  [ 0.02077475 -0.01748073  0.15918456  0.28154092  0.14959641  0.38590836\n",
      "  0.81709018  0.29075841  0.64726058 -0.09819981 -0.19159746  0.07760169\n",
      "  0.32436415 -0.03258549]\n",
      "New theta_0 : [ 0.01922007 -0.01803731  0.1547824   0.27885857  0.14713604  0.38234493\n",
      "  0.81086484  0.28601812  0.63835013 -0.09710209 -0.19229441  0.07333204\n",
      "  0.31845934 -0.03905831]\n",
      "Training Error:  17.90278923231759\n",
      "====================================================================================================\n",
      "Iteration:  83\n",
      "Previous theta :  [ 0.01922007 -0.01803731  0.1547824   0.27885857  0.14713604  0.38234493\n",
      "  0.81086484  0.28601812  0.63835013 -0.09710209 -0.19229441  0.07333204\n",
      "  0.31845934 -0.03905831]\n",
      "New theta_0 : [ 0.0177393  -0.01857196  0.15052126  0.2762053   0.14476772  0.3788049\n",
      "  0.80471443  0.28135298  0.62954209 -0.09596712 -0.19294208  0.06913988\n",
      "  0.31271473 -0.04543617]\n",
      "Training Error:  17.751289267838782\n",
      "====================================================================================================\n",
      "Iteration:  84\n",
      "Previous theta :  [ 0.0177393  -0.01857196  0.15052126  0.2762053   0.14476772  0.3788049\n",
      "  0.80471443  0.28135298  0.62954209 -0.09596712 -0.19294208  0.06913988\n",
      "  0.31271473 -0.04543617]\n",
      "New theta_0 : [ 0.01632912 -0.0190861   0.14639693  0.27358064  0.14248793  0.37528817\n",
      "  0.79863786  0.27676226  0.62083459 -0.09479705 -0.19354258  0.06502354\n",
      "  0.30712603 -0.05172037]\n",
      "Training Error:  17.603496405220938\n",
      "====================================================================================================\n",
      "Iteration:  85\n",
      "Previous theta :  [ 0.01632912 -0.0190861   0.14639693  0.27358064  0.14248793  0.37528817\n",
      "  0.79863786  0.27676226  0.62083459 -0.09479705 -0.19354258  0.06502354\n",
      "  0.30712603 -0.05172037]\n",
      "New theta_0 : [ 0.01498637 -0.01958106  0.14240532  0.27098411  0.14029327  0.37179463\n",
      "  0.79263407  0.27224517  0.61222586 -0.09359393 -0.19409796  0.06098138\n",
      "  0.30168902 -0.05791216]\n",
      "Training Error:  17.45929391802196\n",
      "====================================================================================================\n",
      "Iteration:  86\n",
      "Previous theta :  [ 0.01498637 -0.01958106  0.14240532  0.27098411  0.14029327  0.37179463\n",
      "  0.79263407  0.27224517  0.61222586 -0.09359393 -0.19409796  0.06098138\n",
      "  0.30168902 -0.05791216]\n",
      "New theta_0 : [ 0.01370803 -0.0200581   0.1385425   0.26841525  0.13818048  0.36832416\n",
      "  0.78670201  0.26780096  0.60371414 -0.09235972 -0.19461015  0.05701182\n",
      "  0.29639964 -0.06401283]\n",
      "Training Error:  17.31856971212975\n",
      "====================================================================================================\n",
      "Iteration:  87\n",
      "Previous theta :  [ 0.01370803 -0.0200581   0.1385425   0.26841525  0.13818048  0.36832416\n",
      "  0.78670201  0.26780096  0.60371414 -0.09235972 -0.19461015  0.05701182\n",
      "  0.29639964 -0.06401283]\n",
      "New theta_0 : [ 0.01249121 -0.02051841  0.13480467  0.26587361  0.13614641  0.36487665\n",
      "  0.78084068  0.26342882  0.59529774 -0.0910963  -0.19508101  0.05311331\n",
      "  0.29125387 -0.07002363]\n",
      "Training Error:  17.181216110622238\n",
      "====================================================================================================\n",
      "Iteration:  88\n",
      "Previous theta :  [ 0.01249121 -0.02051841  0.13480467  0.26587361  0.13614641  0.36487665\n",
      "  0.78084068  0.26342882  0.59529774 -0.0910963  -0.19508101  0.05311331\n",
      "  0.29125387 -0.07002363]\n",
      "New theta_0 : [ 0.01133314 -0.0209631   0.13118815  0.26335874  0.13418805  0.36145198\n",
      "  0.7750491   0.25912795  0.58697503 -0.08980546 -0.19551235  0.04928434\n",
      "  0.28624783 -0.07594581]\n",
      "Training Error:  17.047129649486447\n",
      "====================================================================================================\n",
      "Iteration:  89\n",
      "Previous theta :  [ 0.01133314 -0.0209631   0.13118815  0.26335874  0.13418805  0.36145198\n",
      "  0.7750491   0.25912795  0.58697503 -0.08980546 -0.19551235  0.04928434\n",
      "  0.28624783 -0.07594581]\n",
      "New theta_0 : [ 0.01023119 -0.02139324  0.12768938  0.26087021  0.13230248  0.35805001\n",
      "  0.7693263   0.25489754  0.5787444  -0.0884889  -0.19590587  0.04552344\n",
      "  0.28137774 -0.0817806 ]\n",
      "Training Error:  16.91621088362712\n",
      "====================================================================================================\n",
      "Iteration:  90\n",
      "Previous theta :  [ 0.01023119 -0.02139324  0.12768938  0.26087021  0.13230248  0.35805001\n",
      "  0.7693263   0.25489754  0.5787444  -0.0884889  -0.19590587  0.04552344\n",
      "  0.28137774 -0.0817806 ]\n",
      "New theta_0 : [ 0.00918283 -0.02180983  0.12430491  0.2584076   0.13048689  0.35467062\n",
      "  0.76367135  0.25073677  0.57060431 -0.08714825 -0.19626322  0.0418292\n",
      "  0.27663989 -0.08752924]\n",
      "Training Error:  16.788364202626084\n",
      "====================================================================================================\n",
      "Iteration:  91\n",
      "Previous theta :  [ 0.00918283 -0.02180983  0.12430491  0.2584076   0.13048689  0.35467062\n",
      "  0.76367135  0.25073677  0.57060431 -0.08714825 -0.19626322  0.0418292\n",
      "  0.27663989 -0.08752924]\n",
      "New theta_0 : [ 0.00818564 -0.0222138   0.12103143  0.25597047  0.1287386   0.35131366\n",
      "  0.75808333  0.24664482  0.56255325 -0.08578507 -0.19658598  0.03820021\n",
      "  0.27203068 -0.09319292]\n",
      "Training Error:  16.66349765574252\n",
      "====================================================================================================\n",
      "Iteration:  92\n",
      "Previous theta :  [ 0.00818564 -0.0222138   0.12103143  0.25597047  0.1287386   0.35131366\n",
      "  0.75808333  0.24664482  0.56255325 -0.08578507 -0.19658598  0.03820021\n",
      "  0.27203068 -0.09319292]\n",
      "New theta_0 : [ 0.00723731 -0.02260605  0.1178657   0.25355843  0.127055    0.347979\n",
      "  0.75256135  0.24262084  0.55458976 -0.08440083 -0.19687566  0.03463511\n",
      "  0.2675466  -0.09877287]\n",
      "Training Error:  16.54152278567165\n",
      "====================================================================================================\n",
      "Iteration:  93\n",
      "Previous theta :  [ 0.00723731 -0.02260605  0.1178657   0.25355843  0.127055    0.347979\n",
      "  0.75256135  0.24262084  0.55458976 -0.08440083 -0.19687566  0.03463511\n",
      "  0.2675466  -0.09877287]\n",
      "New theta_0 : [ 0.00633565 -0.02298741  0.11480461  0.25117108  0.1254336   0.34466649\n",
      "  0.74710453  0.238664    0.5467124  -0.08299697 -0.19713373  0.0311326\n",
      "  0.26318424 -0.10427026]\n",
      "Training Error:  16.42235447060506\n",
      "====================================================================================================\n",
      "Iteration:  94\n",
      "Previous theta :  [ 0.00633565 -0.02298741  0.11480461  0.25117108  0.1254336   0.34466649\n",
      "  0.74710453  0.238664    0.5467124  -0.08299697 -0.19713373  0.0311326\n",
      "  0.26318424 -0.10427026]\n",
      "New theta_0 : [ 0.00547855 -0.02335867  0.11184514  0.24880801  0.123872    0.34137599\n",
      "  0.74171201  0.23477347  0.5389198  -0.08157483 -0.19736157  0.02769136\n",
      "  0.25894026 -0.10968629]\n",
      "Training Error:  16.30591077416041\n",
      "====================================================================================================\n",
      "Iteration:  95\n",
      "Previous theta :  [ 0.00547855 -0.02335867  0.11184514  0.24880801  0.123872    0.34137599\n",
      "  0.74171201  0.23477347  0.5389198  -0.08157483 -0.19736157  0.02769136\n",
      "  0.25894026 -0.10968629]\n",
      "New theta_0 : [ 0.00466398 -0.02372058  0.10898436  0.24646886  0.12236788  0.33810734\n",
      "  0.73638296  0.23094839  0.53121061 -0.08013571 -0.19756053  0.02431016\n",
      "  0.25481143 -0.11502211]\n",
      "Training Error:  16.192112802771042\n",
      "====================================================================================================\n",
      "Iteration:  96\n",
      "Previous theta :  [ 0.00466398 -0.02372058  0.10898436  0.24646886  0.12236788  0.33810734\n",
      "  0.73638296  0.23094839  0.53121061 -0.08013571 -0.19756053  0.02431016\n",
      "  0.25481143 -0.11502211]\n",
      "New theta_0 : [ 0.00389002 -0.02407383  0.10621944  0.24415323  0.12091902  0.3348604\n",
      "  0.73111656  0.22718793  0.5235835  -0.07868084 -0.19773189  0.02098776\n",
      "  0.25079458 -0.12027888]\n",
      "Training Error:  16.080884570147944\n",
      "====================================================================================================\n",
      "Iteration:  97\n",
      "Previous theta :  [ 0.00389002 -0.02407383  0.10621944  0.24415323  0.12091902  0.3348604\n",
      "  0.73111656  0.22718793  0.5235835  -0.07868084 -0.19773189  0.02098776\n",
      "  0.25079458 -0.12027888]\n",
      "New theta_0 : [ 0.00315484 -0.02441908  0.10354765  0.24186077  0.11952328  0.33163502\n",
      "  0.72591199  0.22349124  0.51603719 -0.07721139 -0.19787688  0.01772296\n",
      "  0.24688663 -0.12545774]\n",
      "Training Error:  15.972152868446921\n",
      "====================================================================================================\n",
      "Iteration:  98\n",
      "Previous theta :  [ 0.00315484 -0.02441908  0.10354765  0.24186077  0.11952328  0.33163502\n",
      "  0.72591199  0.22349124  0.51603719 -0.07721139 -0.19787688  0.01772296\n",
      "  0.24688663 -0.12545774]\n",
      "New theta_0 : [ 0.00245666 -0.02475696  0.10096631  0.23959112  0.1181786   0.32843104\n",
      "  0.72076848  0.21985746  0.50857045 -0.0757285  -0.1979967   0.01451461\n",
      "  0.2430846  -0.13055982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  15.865847145793344\n",
      "====================================================================================================\n",
      "Iteration:  99\n",
      "Previous theta :  [ 0.00245666 -0.02475696  0.10096631  0.23959112  0.1181786   0.32843104\n",
      "  0.72076848  0.21985746  0.50857045 -0.0757285  -0.1979967   0.01451461\n",
      "  0.2430846  -0.13055982]\n",
      "New theta_0 : [ 0.00179382 -0.02508805  0.09847286  0.23734392  0.116883    0.32524831\n",
      "  0.71568524  0.21628577  0.50118205 -0.07423323 -0.19809247  0.01136155\n",
      "  0.23938557 -0.13558623]\n",
      "Training Error:  15.761899389835136\n",
      "====================================================================================================\n",
      "Iteration:  100\n",
      "Previous theta :  [ 0.00179382 -0.02508805  0.09847286  0.23734392  0.116883    0.32524831\n",
      "  0.71568524  0.21628577  0.50118205 -0.07423323 -0.19809247  0.01136155\n",
      "  0.23938557 -0.13558623]\n",
      "New theta_0 : [ 0.00116469 -0.0254129   0.09606479  0.23511883  0.11563457  0.32208667\n",
      "  0.71066152  0.21277532  0.49387081 -0.07272662 -0.1981653   0.00826269\n",
      "  0.2357867  -0.14053809]\n",
      "Training Error:  15.660244017012072\n",
      "====================================================================================================\n",
      "Iteration:  101\n",
      "Previous theta :  [ 0.00116469 -0.0254129   0.09606479  0.23511883  0.11563457  0.32208667\n",
      "  0.71066152  0.21277532  0.49387081 -0.07272662 -0.1981653   0.00826269\n",
      "  0.2357867  -0.14053809]\n",
      "New theta_0 : [ 5.67751385e-04 -2.57320180e-02  9.37396951e-02  2.32915519e-01\n",
      "  1.14431496e-01  3.18945963e-01  7.05696572e-01  2.09325254e-01\n",
      "  4.86635566e-01 -7.12096380e-02 -1.98216234e-01  5.21693268e-03\n",
      "  2.32285227e-01 -1.45416471e-01]\n",
      "Training Error:  15.560817767245897\n",
      "====================================================================================================\n",
      "Iteration:  102\n",
      "Previous theta :  [ 5.67751385e-04 -2.57320180e-02  9.37396951e-02  2.32915519e-01\n",
      "  1.14431496e-01  3.18945963e-01  7.05696572e-01  2.09325254e-01\n",
      "  4.86635566e-01 -7.12096380e-02 -1.98216234e-01  5.21693268e-03\n",
      "  2.32285227e-01 -1.45416471e-01]\n",
      "New theta_0 : [ 1.52649314e-06 -2.60458991e-02  9.14952217e-02  2.30733654e-01\n",
      "  1.13272000e-01  3.15826038e-01  7.00789657e-01  2.05934749e-01\n",
      "  4.79475196e-01 -6.96832207e-02 -1.98246273e-01  2.22322418e-03\n",
      "  2.28878465e-01 -1.50222459e-01]\n",
      "Training Error:  15.463559603771316\n",
      "====================================================================================================\n",
      "Iteration:  103\n",
      "Previous theta :  [ 1.52649314e-06 -2.60458991e-02  9.14952217e-02  2.30733654e-01\n",
      "  1.13272000e-01  3.15826038e-01  7.00789657e-01  2.05934749e-01\n",
      "  4.79475196e-01 -6.96832207e-02 -1.98246273e-01  2.22322418e-03\n",
      "  2.28878465e-01 -1.50222459e-01]\n",
      "New theta_0 : [-5.35386985e-04 -2.63549960e-02  8.93290953e-02  2.28572916e-01\n",
      "  1.12154392e-01  3.12726734e-01  6.95940057e-01  2.02602966e-01\n",
      "  4.72388595e-01 -6.81482606e-02 -1.98256389e-01 -7.19468660e-04\n",
      "  2.25563796e-01 -1.54957116e-01]\n",
      "Training Error:  15.368410617842647\n",
      "====================================================================================================\n",
      "Iteration:  104\n",
      "Previous theta :  [-5.35386985e-04 -2.63549960e-02  8.93290953e-02  2.28572916e-01\n",
      "  1.12154392e-01  3.12726734e-01  6.95940057e-01  2.02602966e-01\n",
      "  4.72388595e-01 -6.81482606e-02 -1.98256389e-01 -7.19468660e-04\n",
      "  2.25563796e-01 -1.54957116e-01]\n",
      "New theta_0 : [-0.00104433 -0.02665974  0.08723911  0.22643299  0.11107704  0.3096479\n",
      "  0.69114706  0.19932908  0.46537469 -0.06660561 -0.19824751 -0.00361215\n",
      "  0.22233868 -0.15962149]\n",
      "Training Error:  15.275313938064832\n",
      "====================================================================================================\n",
      "Iteration:  105\n",
      "Previous theta :  [-0.00104433 -0.02665974  0.08723911  0.22643299  0.11107704  0.3096479\n",
      "  0.69114706  0.19932908  0.46537469 -0.06660561 -0.19824751 -0.00361215\n",
      "  0.22233868 -0.15962149]\n",
      "New theta_0 : [-0.00152659 -0.02696052  0.08522312  0.22431357  0.11003838  0.30658937\n",
      "  0.68640998  0.19611225  0.45843243 -0.06505608 -0.19822053 -0.00645582\n",
      "  0.21920062 -0.16421662]\n",
      "Training Error:  15.18421464411075\n",
      "====================================================================================================\n",
      "Iteration:  106\n",
      "Previous theta :  [-0.00152659 -0.02696052  0.08522312  0.22431357  0.11003838  0.30658937\n",
      "  0.68640998  0.19611225  0.45843243 -0.06505608 -0.19822053 -0.00645582\n",
      "  0.21920062 -0.16421662]\n",
      "New theta_0 : [-0.00198338 -0.02725773  0.08327906  0.22221436  0.1090369   0.30355099\n",
      "  0.68172812  0.19295167  0.45156079 -0.06350044 -0.19817631 -0.00925142\n",
      "  0.21614724 -0.16874353]\n",
      "Training Error:  15.095059684599246\n",
      "====================================================================================================\n",
      "Iteration:  107\n",
      "Previous theta :  [-0.00198338 -0.02725773  0.08327906  0.22221436  0.1090369   0.30355099\n",
      "  0.68172812  0.19295167  0.45156079 -0.06350044 -0.19817631 -0.00925142\n",
      "  0.21614724 -0.16874353]\n",
      "New theta_0 : [-0.00241589 -0.02755172  0.0814049   0.22013507  0.10807116  0.3005326\n",
      "  0.67710082  0.18984651  0.44475877 -0.06193945 -0.19811566 -0.0119999\n",
      "  0.21317616 -0.17320323]\n",
      "Training Error:  15.007797798920109\n",
      "====================================================================================================\n",
      "Iteration:  108\n",
      "Previous theta :  [-0.00241589 -0.02755172  0.0814049   0.22013507  0.10807116  0.3005326\n",
      "  0.67710082  0.18984651  0.44475877 -0.06193945 -0.19811566 -0.0119999\n",
      "  0.21317616 -0.17320323]\n",
      "New theta_0 : [-0.00282522 -0.0278428   0.07959869  0.2180754   0.10713976  0.29753405\n",
      "  0.6725274   0.18679597  0.43802538 -0.06037379 -0.19803939 -0.01470218\n",
      "  0.21028512 -0.17759672]\n",
      "Training Error:  14.922379442803495\n",
      "====================================================================================================\n",
      "Iteration:  109\n",
      "Previous theta :  [-0.00282522 -0.0278428   0.07959869  0.2180754   0.10713976  0.29753405\n",
      "  0.6725274   0.18679597  0.43802538 -0.06037379 -0.19803939 -0.01470218\n",
      "  0.21028512 -0.17759672]\n",
      "New theta_0 : [-0.00321245 -0.02813131  0.07785854  0.21603508  0.10624136  0.29455519\n",
      "  0.66800721  0.18379924  0.43135968 -0.05880415 -0.19794825 -0.01735915\n",
      "  0.2074719  -0.18192497]\n",
      "Training Error:  14.83875671744186\n",
      "====================================================================================================\n",
      "Iteration:  110\n",
      "Previous theta :  [-0.00321245 -0.02813131  0.07785854  0.21603508  0.10624136  0.29455519\n",
      "  0.66800721  0.18379924  0.43135968 -0.05880415 -0.19794825 -0.01735915\n",
      "  0.2074719  -0.18192497]\n",
      "New theta_0 : [-0.0035786  -0.02841752  0.0761826   0.21401384  0.10537468  0.29159585\n",
      "  0.6635396   0.18085552  0.42476072 -0.05723117 -0.19784297 -0.01997169\n",
      "  0.20473433 -0.18618897]\n",
      "Training Error:  14.756883301982565\n",
      "====================================================================================================\n",
      "Iteration:  111\n",
      "Previous theta :  [-0.0035786  -0.02841752  0.0761826   0.21401384  0.10537468  0.29159585\n",
      "  0.6635396   0.18085552  0.42476072 -0.05723117 -0.19784297 -0.01997169\n",
      "  0.20473433 -0.18618897]\n",
      "New theta_0 : [-0.00392465 -0.0287017   0.07456907  0.21201141  0.10453847  0.28865589\n",
      "  0.65912396  0.17796402  0.41822759 -0.05565546 -0.19772425 -0.02254066\n",
      "  0.20207033 -0.19038967]\n",
      "Training Error:  14.676714389218802\n",
      "====================================================================================================\n",
      "Iteration:  112\n",
      "Previous theta :  [-0.00392465 -0.0287017   0.07456907  0.21201141  0.10453847  0.28865589\n",
      "  0.65912396  0.17796402  0.41822759 -0.05565546 -0.19772425 -0.02254066\n",
      "  0.20207033 -0.19038967]\n",
      "New theta_0 : [-0.00425153 -0.02898411  0.07301623  0.21002753  0.10373154  0.28573514\n",
      "  0.65475963  0.17512395  0.4117594  -0.05407761 -0.19759276 -0.02506688\n",
      "  0.19947783 -0.19452801]\n",
      "Training Error:  14.598206624315603\n",
      "====================================================================================================\n",
      "Iteration:  113\n",
      "Previous theta :  [-0.00425153 -0.02898411  0.07301623  0.21002753  0.10373154  0.28573514\n",
      "  0.65475963  0.17512395  0.4117594  -0.05407761 -0.19759276 -0.02506688\n",
      "  0.19947783 -0.19452801]\n",
      "New theta_0 : [-0.00456013 -0.02926498  0.07152238  0.20806194  0.10295275  0.28283347\n",
      "  0.65044602  0.17233454  0.40535526 -0.05249817 -0.19744916 -0.02755119\n",
      "  0.19695487 -0.19860492]\n",
      "Training Error:  14.521318046416154\n",
      "====================================================================================================\n",
      "Iteration:  114\n",
      "Previous theta :  [-0.00456013 -0.02926498  0.07152238  0.20806194  0.10295275  0.28283347\n",
      "  0.65044602  0.17233454  0.40535526 -0.05249817 -0.19744916 -0.02755119\n",
      "  0.19695487 -0.19860492]\n",
      "New theta_0 : [-0.00485131 -0.02954454  0.07008589  0.2061144   0.10220101  0.2799507\n",
      "  0.64618252  0.169595    0.39901432 -0.05091767 -0.19729407 -0.02999438\n",
      "  0.19449951 -0.20262133]\n",
      "Training Error:  14.446008032981805\n",
      "====================================================================================================\n",
      "Iteration:  115\n",
      "Previous theta :  [-0.00485131 -0.02954454  0.07008589  0.2061144   0.10220101  0.2799507\n",
      "  0.64618252  0.169595    0.39901432 -0.05091767 -0.19729407 -0.02999438\n",
      "  0.19449951 -0.20262133]\n",
      "New theta_0 : [-0.00512588 -0.02982298  0.06870516  0.20418466  0.10147525  0.27708671\n",
      "  0.64196851  0.16690458  0.39273575 -0.04933662 -0.19712807 -0.03239723\n",
      "  0.19210987 -0.20657815]\n",
      "Training Error:  14.37223724672683\n",
      "====================================================================================================\n",
      "Iteration:  116\n",
      "Previous theta :  [-0.00512588 -0.02982298  0.06870516  0.20418466  0.10147525  0.27708671\n",
      "  0.64196851  0.16690458  0.39273575 -0.04933662 -0.19712807 -0.03239723\n",
      "  0.19210987 -0.20657815]\n",
      "New theta_0 : [-0.00538461 -0.0301005   0.06737865  0.20227249  0.10077445  0.27424132\n",
      "  0.63780342  0.16426252  0.3865187  -0.04775551 -0.19695176 -0.0347605\n",
      "  0.18978413 -0.21047625]\n",
      "Training Error:  14.299967585016265\n",
      "====================================================================================================\n",
      "Iteration:  117\n",
      "Previous theta :  [-0.00538461 -0.0301005   0.06737865  0.20227249  0.10077445  0.27424132\n",
      "  0.63780342  0.16426252  0.3865187  -0.04775551 -0.19695176 -0.0347605\n",
      "  0.18978413 -0.21047625]\n",
      "New theta_0 : [-0.00562825 -0.03037726  0.06610485  0.20037765  0.10009765  0.27141441\n",
      "  0.63368665  0.16166807  0.3803624  -0.04617479 -0.19676567 -0.03708495\n",
      "  0.18752051 -0.21431653]\n",
      "Training Error:  14.22916213160208\n",
      "====================================================================================================\n",
      "Iteration:  118\n",
      "Previous theta :  [-0.00562825 -0.03037726  0.06610485  0.20037765  0.10009765  0.27141441\n",
      "  0.63368665  0.16166807  0.3803624  -0.04617479 -0.19676567 -0.03708495\n",
      "  0.18752051 -0.21431653]\n",
      "New theta_0 : [-0.00585751 -0.03065345  0.0648823   0.19849991  0.09944389  0.26860581\n",
      "  0.62961764  0.15912048  0.37426603 -0.04459491 -0.19657034 -0.0393713\n",
      "  0.18531729 -0.21809986]\n",
      "Training Error:  14.159785110579406\n",
      "====================================================================================================\n",
      "Iteration:  119\n",
      "Previous theta :  [-0.00585751 -0.03065345  0.0648823   0.19849991  0.09944389  0.26860581\n",
      "  0.62961764  0.15912048  0.37426603 -0.04459491 -0.19657034 -0.0393713\n",
      "  0.18531729 -0.21809986]\n",
      "New theta_0 : [-0.00607307 -0.0309292   0.06370958  0.19663906  0.09881228  0.26581539\n",
      "  0.62559581  0.15661903  0.36822883 -0.04301627 -0.19636628 -0.04162027\n",
      "  0.18317278 -0.22182709]\n",
      "Training Error:  14.091801842450797\n",
      "====================================================================================================\n",
      "Iteration:  120\n",
      "Previous theta :  [-0.00607307 -0.0309292   0.06370958  0.19663906  0.09881228  0.26581539\n",
      "  0.62559581  0.15661903  0.36822883 -0.04301627 -0.19636628 -0.04162027\n",
      "  0.18317278 -0.22182709]\n",
      "New theta_0 : [-0.00627558 -0.03120465  0.06258531  0.19479488  0.09820196  0.263043\n",
      "  0.6216206   0.15416298  0.36225004 -0.04143927 -0.19615398 -0.04383256\n",
      "  0.18108536 -0.22549906]\n",
      "Training Error:  14.025178702192372\n",
      "====================================================================================================\n",
      "Iteration:  121\n",
      "Previous theta :  [-0.00627558 -0.03120465  0.06258531  0.19479488  0.09820196  0.263043\n",
      "  0.6216206   0.15416298  0.36225004 -0.04143927 -0.19615398 -0.04383256\n",
      "  0.18108536 -0.22549906]\n",
      "New theta_0 : [-0.00646566 -0.03147994  0.06150815  0.19296716  0.09761208  0.26028849\n",
      "  0.61769147  0.15175162  0.35632892 -0.0398643  -0.1959339  -0.04600886\n",
      "  0.17905344 -0.2291166 ]\n",
      "Training Error:  13.959883079221196\n",
      "====================================================================================================\n",
      "Iteration:  122\n",
      "Previous theta :  [-0.00646566 -0.03147994  0.06150815  0.19296716  0.09761208  0.26028849\n",
      "  0.61769147  0.15175162  0.35632892 -0.0398643  -0.1959339  -0.04600886\n",
      "  0.17905344 -0.2291166 ]\n",
      "New theta_0 : [-0.00664389 -0.03175519  0.0604768   0.19115568  0.09704185  0.25755172\n",
      "  0.61380785  0.14938424  0.35046474 -0.03829172 -0.19570649 -0.04814982\n",
      "  0.17707547 -0.23268054]\n",
      "Training Error:  13.895883339168519\n",
      "====================================================================================================\n",
      "Iteration:  123\n",
      "Previous theta :  [-0.00664389 -0.03175519  0.0604768   0.19115568  0.09704185  0.25755172\n",
      "  0.61380785  0.14938424  0.35046474 -0.03829172 -0.19570649 -0.04814982\n",
      "  0.17707547 -0.23268054]\n",
      "New theta_0 : [-0.00681084 -0.03203049  0.05948998  0.18936025  0.0964905   0.25483256\n",
      "  0.60996922  0.14706014  0.34465679 -0.03672185 -0.1954722  -0.05025612\n",
      "  0.17514996 -0.23619169]\n",
      "Training Error:  13.833148787368579\n",
      "====================================================================================================\n",
      "Iteration:  124\n",
      "Previous theta :  [-0.00681084 -0.03203049  0.05948998  0.18936025  0.0964905   0.25483256\n",
      "  0.60996922  0.14706014  0.34465679 -0.03672185 -0.1954722  -0.05025612\n",
      "  0.17514996 -0.23619169]\n",
      "New theta_0 : [-0.00696705 -0.03230596  0.05854647  0.18758066  0.09595729  0.25213086\n",
      "  0.60617504  0.14477862  0.33890436 -0.03515504 -0.19523144 -0.05232839\n",
      "  0.17327546 -0.23965083]\n",
      "Training Error:  13.771649633977281\n",
      "====================================================================================================\n",
      "Iteration:  125\n",
      "Previous theta :  [-0.00696705 -0.03230596  0.05854647  0.18758066  0.09595729  0.25213086\n",
      "  0.60617504  0.14477862  0.33890436 -0.03515504 -0.19523144 -0.05232839\n",
      "  0.17327546 -0.23965083]\n",
      "New theta_0 : [-0.00711304 -0.03258169  0.05764506  0.18581674  0.09544151  0.24944649\n",
      "  0.60242477  0.142539    0.33320676 -0.03359158 -0.1949846  -0.05436725\n",
      "  0.17145054 -0.24305875]\n",
      "Training Error:  13.711356960639614\n",
      "====================================================================================================\n",
      "Iteration:  126\n",
      "Previous theta :  [-0.00711304 -0.03258169  0.05764506  0.18581674  0.09544151  0.24944649\n",
      "  0.60242477  0.142539    0.33320676 -0.03359158 -0.1949846  -0.05436725\n",
      "  0.17145054 -0.24305875]\n",
      "New theta_0 : [-0.0072493  -0.03285775  0.05678459  0.18406827  0.09494247  0.24677931\n",
      "  0.59871792  0.1403406   0.32756332 -0.03203178 -0.19473208 -0.05637332\n",
      "  0.16967383 -0.24641623]\n",
      "Training Error:  13.652242688628897\n",
      "====================================================================================================\n",
      "Iteration:  127\n",
      "Previous theta :  [-0.0072493  -0.03285775  0.05678459  0.18406827  0.09494247  0.24677931\n",
      "  0.59871792  0.1403406   0.32756332 -0.03203178 -0.19473208 -0.05637332\n",
      "  0.16967383 -0.24641623]\n",
      "New theta_0 : [-0.0073763  -0.03313422  0.05596392  0.18233509  0.09445952  0.24412917\n",
      "  0.59505394  0.13818276  0.32197339 -0.03047591 -0.19447423 -0.05834721\n",
      "  0.167944   -0.24972403]\n",
      "Training Error:  13.594279548384947\n",
      "====================================================================================================\n",
      "Iteration:  128\n",
      "Previous theta :  [-0.0073763  -0.03313422  0.05596392  0.18233509  0.09445952  0.24412917\n",
      "  0.59505394  0.13818276  0.32197339 -0.03047591 -0.19447423 -0.05834721\n",
      "  0.167944   -0.24972403]\n",
      "New theta_0 : [-0.00749449 -0.03341117  0.05518195  0.18061701  0.09399203  0.24149596\n",
      "  0.59143235  0.1360648   0.3164363  -0.02892423 -0.19421142 -0.0602895\n",
      "  0.16625973 -0.2529829 ]\n",
      "Training Error:  13.537441050382087\n",
      "====================================================================================================\n",
      "Iteration:  129\n",
      "Previous theta :  [-0.00749449 -0.03341117  0.05518195  0.18061701  0.09399203  0.24149596\n",
      "  0.59143235  0.1360648   0.3164363  -0.02892423 -0.19421142 -0.0602895\n",
      "  0.16625973 -0.2529829 ]\n",
      "New theta_0 : [-0.00760429 -0.03368866  0.0544376   0.17891385  0.0935394   0.23887954\n",
      "  0.58785264  0.13398609  0.31095141 -0.02737701 -0.19394398 -0.06220077\n",
      "  0.16461977 -0.25619357]\n",
      "Training Error:  13.48170145726152\n",
      "====================================================================================================\n",
      "Iteration:  130\n",
      "Previous theta :  [-0.00760429 -0.03368866  0.0544376   0.17891385  0.0935394   0.23887954\n",
      "  0.58785264  0.13398609  0.31095141 -0.02737701 -0.19394398 -0.06220077\n",
      "  0.16461977 -0.25619357]\n",
      "New theta_0 : [-0.00770612 -0.03396675  0.05372983  0.17722544  0.09310104  0.23627977\n",
      "  0.58431432  0.13194598  0.30551812 -0.02583446 -0.19367225 -0.06408158\n",
      "  0.16302288 -0.25935677]\n",
      "Training Error:  13.427035757166005\n",
      "====================================================================================================\n",
      "Iteration:  131\n",
      "Previous theta :  [-0.00770612 -0.03396675  0.05372983  0.17722544  0.09310104  0.23627977\n",
      "  0.58431432  0.13194598  0.30551812 -0.02583446 -0.19367225 -0.06408158\n",
      "  0.16302288 -0.25935677]\n",
      "New theta_0 : [-0.00780036 -0.03424549  0.05305763  0.17555161  0.09267639  0.23369653\n",
      "  0.58081688  0.12994383  0.30013578 -0.02429683 -0.19339652 -0.06593249\n",
      "  0.16146788 -0.26247323]\n",
      "Training Error:  13.37341963821797\n",
      "====================================================================================================\n",
      "Iteration:  132\n",
      "Previous theta :  [-0.00780036 -0.03424549  0.05305763  0.17555161  0.09267639  0.23369653\n",
      "  0.58081688  0.12994383  0.30013578 -0.02429683 -0.19339652 -0.06593249\n",
      "  0.16146788 -0.26247323]\n",
      "New theta_0 : [-0.0078874  -0.03452491  0.05242     0.17389219  0.09226492  0.23112969\n",
      "  0.57735986  0.12797902  0.29480381 -0.02276432 -0.19311712 -0.06775404\n",
      "  0.15995361 -0.26554364]\n",
      "Training Error:  13.32082946408535\n",
      "====================================================================================================\n",
      "Iteration:  133\n",
      "Previous theta :  [-0.0078874  -0.03452491  0.05242     0.17389219  0.09226492  0.23112969\n",
      "  0.57735986  0.12797902  0.29480381 -0.02276432 -0.19311712 -0.06775404\n",
      "  0.15995361 -0.26554364]\n",
      "New theta_0 : [-0.00796758 -0.03480506  0.05181598  0.17224703  0.09186612  0.22857912\n",
      "  0.57394276  0.12605093  0.28952161 -0.02123713 -0.19283432 -0.06954675\n",
      "  0.15847893 -0.2685687 ]\n",
      "Training Error:  13.269242250582256\n",
      "====================================================================================================\n",
      "Iteration:  134\n",
      "Previous theta :  [-0.00796758 -0.03480506  0.05181598  0.17224703  0.09186612  0.22857912\n",
      "  0.57394276  0.12605093  0.28952161 -0.02123713 -0.19283432 -0.06954675\n",
      "  0.15847893 -0.2685687 ]\n",
      "New theta_0 : [-0.00804124 -0.03508597  0.05124463  0.17061595  0.09147948  0.2260447\n",
      "  0.57056513  0.12415895  0.28428859 -0.01971546 -0.1925484  -0.07131115\n",
      "  0.15704274 -0.2715491 ]\n",
      "Training Error:  13.218635643254348\n",
      "====================================================================================================\n",
      "Iteration:  135\n",
      "Previous theta :  [-0.00804124 -0.03508597  0.05124463  0.17061595  0.09147948  0.2260447\n",
      "  0.57056513  0.12415895  0.28428859 -0.01971546 -0.1925484  -0.07131115\n",
      "  0.15704274 -0.2715491 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00810872 -0.03536767  0.05070504  0.16899882  0.09110453  0.2235263\n",
      "  0.56722649  0.12230248  0.27910418 -0.01819949 -0.19225963 -0.07304774\n",
      "  0.155644   -0.27448552]\n",
      "Training Error:  13.168987895901429\n",
      "====================================================================================================\n",
      "Iteration:  136\n",
      "Previous theta :  [-0.00810872 -0.03536767  0.05070504  0.16899882  0.09110453  0.2235263\n",
      "  0.56722649  0.12230248  0.27910418 -0.01819949 -0.19225963 -0.07304774\n",
      "  0.155644   -0.27448552]\n",
      "New theta_0 : [-0.00817032 -0.03565018  0.05019633  0.16739547  0.09074082  0.2210238\n",
      "  0.56392637  0.12048092  0.27396781 -0.01668939 -0.19196826 -0.07475703\n",
      "  0.15428165 -0.27737861]\n",
      "Training Error:  13.120277849992199\n",
      "====================================================================================================\n",
      "Iteration:  137\n",
      "Previous theta :  [-0.00817032 -0.03565018  0.05019633  0.16739547  0.09074082  0.2210238\n",
      "  0.56392637  0.12048092  0.27396781 -0.01668939 -0.19196826 -0.07475703\n",
      "  0.15428165 -0.27737861]\n",
      "New theta_0 : [-0.00822633 -0.03593352  0.04971762  0.16580575  0.09038791  0.21853708\n",
      "  0.56066433  0.1186937   0.26887894 -0.01518532 -0.19167454 -0.0764395\n",
      "  0.1529547  -0.28022903]\n",
      "Training Error:  13.072484914928445\n",
      "====================================================================================================\n",
      "Iteration:  138\n",
      "Previous theta :  [-0.00822633 -0.03593352  0.04971762  0.16580575  0.09038791  0.21853708\n",
      "  0.56066433  0.1186937   0.26887894 -0.01518532 -0.19167454 -0.0764395\n",
      "  0.1529547  -0.28022903]\n",
      "New theta_0 : [-0.00827704 -0.0362177   0.04926808  0.16422952  0.09004537  0.21606602\n",
      "  0.55743991  0.11694022  0.263837   -0.01368743 -0.1913787  -0.07809563\n",
      "  0.15166216 -0.28303743]\n",
      "Training Error:  13.025589049118176\n",
      "====================================================================================================\n",
      "Iteration:  139\n",
      "Previous theta :  [-0.00827704 -0.0362177   0.04926808  0.16422952  0.09004537  0.21606602\n",
      "  0.55743991  0.11694022  0.263837   -0.01368743 -0.1913787  -0.07809563\n",
      "  0.15166216 -0.28303743]\n",
      "New theta_0 : [-0.00832272 -0.03650275  0.04884689  0.16266664  0.0897128   0.21361051\n",
      "  0.55425267  0.11521993  0.25884148 -0.01219586 -0.19108098 -0.07972589\n",
      "  0.15040309 -0.28580444]\n",
      "Training Error:  12.9795707418193\n",
      "====================================================================================================\n",
      "Iteration:  140\n",
      "Previous theta :  [-0.00832272 -0.03650275  0.04884689  0.16266664  0.0897128   0.21361051\n",
      "  0.55425267  0.11521993  0.25884148 -0.01219586 -0.19108098 -0.07972589\n",
      "  0.15040309 -0.28580444]\n",
      "New theta_0 : [-0.00836362 -0.03678865  0.04845325  0.16111696  0.08938982  0.21117041\n",
      "  0.55110216  0.11353227  0.25389183 -0.01071075 -0.19078157 -0.08133074\n",
      "  0.14917656 -0.28853068]\n",
      "Training Error:  12.9344109957174\n",
      "====================================================================================================\n",
      "Iteration:  141\n",
      "Previous theta :  [-0.00836362 -0.03678865  0.04845325  0.16111696  0.08938982  0.21117041\n",
      "  0.55110216  0.11353227  0.25389183 -0.01071075 -0.19078157 -0.08133074\n",
      "  0.14917656 -0.28853068]\n",
      "New theta_0 : [-0.00839999 -0.03707544  0.04808638  0.15958036  0.08907604  0.20874563\n",
      "  0.54798795  0.11187668  0.24898754 -0.00923222 -0.1904807  -0.08291063\n",
      "  0.14798168 -0.29121678]\n",
      "Training Error:  12.890091310203044\n",
      "====================================================================================================\n",
      "Iteration:  142\n",
      "Previous theta :  [-0.00839999 -0.03707544  0.04808638  0.15958036  0.08907604  0.20874563\n",
      "  0.54798795  0.11187668  0.24898754 -0.00923222 -0.1904807  -0.08291063\n",
      "  0.14798168 -0.29121678]\n",
      "New theta_0 : [-0.00843207 -0.03736309  0.04774553  0.15805668  0.08877112  0.20633604\n",
      "  0.54490961  0.11025261  0.24412811 -0.0077604  -0.19017856 -0.084466\n",
      "  0.14681758 -0.29386333]\n",
      "Training Error:  12.846593665315904\n",
      "====================================================================================================\n",
      "Iteration:  143\n",
      "Previous theta :  [-0.00843207 -0.03736309  0.04774553  0.15805668  0.08877112  0.20633604\n",
      "  0.54490961  0.11025261  0.24412811 -0.0077604  -0.19017856 -0.084466\n",
      "  0.14681758 -0.29386333]\n",
      "New theta_0 : [-0.00846008 -0.03765162  0.04742996  0.15654581  0.0884747   0.20394153\n",
      "  0.54186671  0.10865954  0.23931302 -0.00629539 -0.18987534 -0.08599728\n",
      "  0.1456834  -0.29647094]\n",
      "Training Error:  12.803900506324524\n",
      "====================================================================================================\n",
      "Iteration:  144\n",
      "Previous theta :  [-0.00846008 -0.03765162  0.04742996  0.15654581  0.0884747   0.20394153\n",
      "  0.54186671  0.10865954  0.23931302 -0.00629539 -0.18987534 -0.08599728\n",
      "  0.1456834  -0.29647094]\n",
      "New theta_0 : [-0.00848422 -0.03794102  0.04713896  0.15504761  0.08818647  0.20156199\n",
      "  0.53885883  0.10709693  0.23454178 -0.0048373  -0.18957123 -0.0875049\n",
      "  0.14457832 -0.29904019]\n",
      "Training Error:  12.761994728912294\n",
      "====================================================================================================\n",
      "Iteration:  145\n",
      "Previous theta :  [-0.00848422 -0.03794102  0.04713896  0.15504761  0.08818647  0.20156199\n",
      "  0.53885883  0.10709693  0.23454178 -0.0048373  -0.18957123 -0.0875049\n",
      "  0.14457832 -0.29904019]\n",
      "New theta_0 : [-0.00850471 -0.03823128  0.04687182  0.15356195  0.08790609  0.19919732\n",
      "  0.53588556  0.10556426  0.22981391 -0.00338623 -0.18926639 -0.08898927\n",
      "  0.14350155 -0.30157166]\n",
      "Training Error:  12.720859664941598\n",
      "====================================================================================================\n",
      "Iteration:  146\n",
      "Previous theta :  [-0.00850471 -0.03823128  0.04687182  0.15356195  0.08790609  0.19919732\n",
      "  0.53588556  0.10556426  0.22981391 -0.00338623 -0.18926639 -0.08898927\n",
      "  0.14350155 -0.30157166]\n",
      "New theta_0 : [-0.00852174 -0.0385224   0.04662786  0.15208871  0.08763326  0.19684739\n",
      "  0.53294648  0.10406102  0.22512893 -0.00194226 -0.18896099 -0.0904508\n",
      "  0.14245231 -0.30406592]\n",
      "Training Error:  12.680479068769591\n",
      "====================================================================================================\n",
      "Iteration:  147\n",
      "Previous theta :  [-0.00852174 -0.0385224   0.04662786  0.15208871  0.08763326  0.19684739\n",
      "  0.53294648  0.10406102  0.22512893 -0.00194226 -0.18896099 -0.0904508\n",
      "  0.14245231 -0.30406592]\n",
      "New theta_0 : [-8.53548907e-03 -3.88143597e-02  4.64064226e-02  1.50627770e-01\n",
      "  8.73677030e-02  1.94512104e-01  5.30041195e-01  1.02586695e-01\n",
      "  2.20486362e-01 -5.05477339e-04 -1.88655207e-01 -9.18898898e-02\n",
      "  1.41429839e-01 -3.06523527e-01]\n",
      "Training Error:  12.64083710409039\n",
      "====================================================================================================\n",
      "Iteration:  148\n",
      "Previous theta :  [-8.53548907e-03 -3.88143597e-02  4.64064226e-02  1.50627770e-01\n",
      "  8.73677030e-02  1.94512104e-01  5.30041195e-01  1.02586695e-01\n",
      "  2.20486362e-01 -5.05477339e-04 -1.88655207e-01 -9.18898898e-02\n",
      "  1.41429839e-01 -3.06523527e-01]\n",
      "New theta_0 : [-0.00854614 -0.03910716  0.04620686  0.14917901  0.08710913  0.19219136\n",
      "  0.52716929  0.1011408   0.21588574  0.00092404 -0.18834918 -0.09330693\n",
      "  0.14043341 -0.30894504]\n",
      "Training Error:  12.601918331279736\n",
      "====================================================================================================\n",
      "Iteration:  149\n",
      "Previous theta :  [-0.00854614 -0.03910716  0.04620686  0.14917901  0.08710913  0.19219136\n",
      "  0.52716929  0.1011408   0.21588574  0.00092404 -0.18834918 -0.09330693\n",
      "  0.14043341 -0.30894504]\n",
      "New theta_0 : [-0.00855385 -0.03940078  0.04602855  0.1477423   0.08685726  0.18988504\n",
      "  0.52433038  0.09972284  0.21132662  0.00234621 -0.18804305 -0.09470231\n",
      "  0.1394623  -0.311331  ]\n",
      "Training Error:  12.563707695219419\n",
      "====================================================================================================\n",
      "Iteration:  150\n",
      "Previous theta :  [-0.00855385 -0.03940078  0.04602855  0.1477423   0.08685726  0.18988504\n",
      "  0.52433038  0.09972284  0.21132662  0.00234621 -0.18804305 -0.09470231\n",
      "  0.1394623  -0.311331  ]\n",
      "New theta_0 : [-0.00855879 -0.0396952   0.04587087  0.14631754  0.08661185  0.18759305\n",
      "  0.52152406  0.09833232  0.20680854  0.00376098 -0.18773698 -0.0960764\n",
      "  0.13851583 -0.31368195]\n",
      "Training Error:  12.526190513579879\n",
      "====================================================================================================\n",
      "Iteration:  151\n",
      "Previous theta :  [-0.00855879 -0.0396952   0.04587087  0.14631754  0.08661185  0.18759305\n",
      "  0.52152406  0.09833232  0.20680854  0.00376098 -0.18773698 -0.0960764\n",
      "  0.13851583 -0.31368195]\n",
      "New theta_0 : [-0.00856111 -0.03999041  0.04573324  0.14490462  0.08637265  0.18531528\n",
      "  0.51874995  0.09696878  0.20233106  0.00516828 -0.18743108 -0.09742957\n",
      "  0.13759331 -0.3159984 ]\n",
      "Training Error:  12.489352465540511\n",
      "====================================================================================================\n",
      "Iteration:  152\n",
      "Previous theta :  [-0.00856111 -0.03999041  0.04573324  0.14490462  0.08637265  0.18531528\n",
      "  0.51874995  0.09696878  0.20233106  0.00516828 -0.18743108 -0.09742957\n",
      "  0.13759331 -0.3159984 ]\n",
      "New theta_0 : [-0.00856096 -0.04028639  0.04561505  0.14350341  0.08613941  0.18305164\n",
      "  0.51600766  0.09563175  0.19789373  0.00656806 -0.18712549 -0.09876218\n",
      "  0.1366941  -0.31828089]\n",
      "Training Error:  12.453179580928182\n",
      "====================================================================================================\n",
      "Iteration:  153\n",
      "Previous theta :  [-0.00856096 -0.04028639  0.04561505  0.14350341  0.08613941  0.18305164\n",
      "  0.51600766  0.09563175  0.19789373  0.00656806 -0.18712549 -0.09876218\n",
      "  0.1366941  -0.31828089]\n",
      "New theta_0 : [-0.00855847 -0.04058311  0.04551576  0.1421138   0.08591191  0.18080202\n",
      "  0.51329681  0.09432076  0.19349614  0.00796026 -0.18682034 -0.1000746\n",
      "  0.13581756 -0.32052992]\n",
      "Training Error:  12.417658229755546\n",
      "====================================================================================================\n",
      "Iteration:  154\n",
      "Previous theta :  [-0.00855847 -0.04058311  0.04551576  0.1421138   0.08591191  0.18080202\n",
      "  0.51329681  0.09432076  0.19349614  0.00796026 -0.18682034 -0.1000746\n",
      "  0.13581756 -0.32052992]\n",
      "New theta_0 : [-0.00855378 -0.04088057  0.04543481  0.14073571  0.08568994  0.17856632\n",
      "  0.51061704  0.09303537  0.18913786  0.00934484 -0.18651573 -0.10136716\n",
      "  0.13496306 -0.32274599]\n",
      "Training Error:  12.382775112141484\n",
      "====================================================================================================\n",
      "Iteration:  155\n",
      "Previous theta :  [-0.00855378 -0.04088057  0.04543481  0.14073571  0.08568994  0.17856632\n",
      "  0.51061704  0.09303537  0.18913786  0.00934484 -0.18651573 -0.10136716\n",
      "  0.13496306 -0.32274599]\n",
      "New theta_0 : [-0.00854701 -0.04117873  0.04537166  0.139369    0.08547327  0.17634445\n",
      "  0.50796796  0.09177511  0.18481847  0.01072175 -0.18621178 -0.10264021\n",
      "  0.13413002 -0.32492959]\n",
      "Training Error:  12.348517248597112\n",
      "====================================================================================================\n",
      "Iteration:  156\n",
      "Previous theta :  [-0.00854701 -0.04117873  0.04537166  0.139369    0.08547327  0.17634445\n",
      "  0.50796796  0.09177511  0.18481847  0.01072175 -0.18621178 -0.10264021\n",
      "  0.13413002 -0.32492959]\n",
      "New theta_0 : [-0.00853828 -0.04147757  0.04532578  0.13801359  0.08526171  0.1741363\n",
      "  0.50534921  0.09053956  0.18053755  0.01209096 -0.1859086  -0.10389409\n",
      "  0.13331785 -0.32708123]\n",
      "Training Error:  12.314871970661361\n",
      "====================================================================================================\n",
      "Iteration:  157\n",
      "Previous theta :  [-0.00853828 -0.04147757  0.04532578  0.13801359  0.08526171  0.1741363\n",
      "  0.50534921  0.09053956  0.18053755  0.01209096 -0.1859086  -0.10389409\n",
      "  0.13331785 -0.32708123]\n",
      "New theta_0 : [-0.00852771 -0.04177707  0.04529667  0.13666937  0.08505506  0.17194178\n",
      "  0.50276044  0.08932828  0.1762947   0.01345244 -0.18560629 -0.10512912\n",
      "  0.13252598 -0.32920137]\n",
      "Training Error:  12.281826911871164\n",
      "====================================================================================================\n",
      "Iteration:  158\n",
      "Previous theta :  [-0.00852771 -0.04177707  0.04529667  0.13666937  0.08505506  0.17194178\n",
      "  0.50276044  0.08932828  0.1762947   0.01345244 -0.18560629 -0.10512912\n",
      "  0.13252598 -0.32920137]\n",
      "New theta_0 : [-0.0085154  -0.0420772   0.04528384  0.13533624  0.08485313  0.1697608\n",
      "  0.50020127  0.08814084  0.17208953  0.01480614 -0.18530495 -0.10634563\n",
      "  0.13175386 -0.3312905 ]\n",
      "Training Error:  12.249369999051853\n",
      "====================================================================================================\n",
      "Iteration:  159\n",
      "Previous theta :  [-0.0085154  -0.0420772   0.04528384  0.13533624  0.08485313  0.1697608\n",
      "  0.50020127  0.08814084  0.17208953  0.01480614 -0.18530495 -0.10634563\n",
      "  0.13175386 -0.3312905 ]\n",
      "New theta_0 : [-0.00850147 -0.04237794  0.04528678  0.1340141   0.08465576  0.16759326\n",
      "  0.49767137  0.08697682  0.16792163  0.01615205 -0.18500466 -0.10754393\n",
      "  0.13100095 -0.33334907]\n",
      "Training Error:  12.217489443914117\n",
      "====================================================================================================\n",
      "Iteration:  160\n",
      "Previous theta :  [-0.00850147 -0.04237794  0.04528678  0.1340141   0.08465576  0.16759326\n",
      "  0.49767137  0.08697682  0.16792163  0.01615205 -0.18500466 -0.10754393\n",
      "  0.13100095 -0.33334907]\n",
      "New theta_0 : [-0.008486   -0.04267926  0.04530504  0.13270285  0.08446276  0.16543907\n",
      "  0.49517037  0.08583581  0.16379062  0.01749015 -0.18470553 -0.10872433\n",
      "  0.13026673 -0.33537754]\n",
      "Training Error:  12.186173734944617\n",
      "====================================================================================================\n",
      "Iteration:  161\n",
      "Previous theta :  [-0.008486   -0.04267926  0.04530504  0.13270285  0.08446276  0.16543907\n",
      "  0.49517037  0.08583581  0.16379062  0.01749015 -0.18470553 -0.10872433\n",
      "  0.13026673 -0.33537754]\n",
      "New theta_0 : [-0.0084691  -0.04298114  0.04533816  0.1314024   0.08427397  0.16329814\n",
      "  0.49269793  0.08471741  0.15969611  0.01882041 -0.18440763 -0.10988715\n",
      "  0.12955071 -0.33737637]\n",
      "Training Error:  12.15541162957787\n",
      "====================================================================================================\n",
      "Iteration:  162\n",
      "Previous theta :  [-0.0084691  -0.04298114  0.04533816  0.1314024   0.08427397  0.16329814\n",
      "  0.49269793  0.08471741  0.15969611  0.01882041 -0.18440763 -0.10988715\n",
      "  0.12955071 -0.33737637]\n",
      "New theta_0 : [-0.00845085 -0.04328353  0.04538567  0.13011265  0.08408923  0.16117038\n",
      "  0.49025371  0.08362121  0.15563773  0.02014282 -0.18411104 -0.11103267\n",
      "  0.12885238 -0.339346  ]\n",
      "Training Error:  12.125192146637643\n",
      "====================================================================================================\n",
      "Iteration:  163\n",
      "Previous theta :  [-0.00845085 -0.04328353  0.04538567  0.13011265  0.08408923  0.16117038\n",
      "  0.49025371  0.08362121  0.15563773  0.02014282 -0.18411104 -0.11103267\n",
      "  0.12885238 -0.339346  ]\n",
      "New theta_0 : [-0.00843133 -0.04358643  0.04544716  0.12883351  0.08390839  0.15905569\n",
      "  0.48783738  0.08254682  0.15161509  0.02145736 -0.18381583 -0.1121612\n",
      "  0.12817127 -0.34128687]\n",
      "Training Error:  12.095504559036778\n",
      "====================================================================================================\n",
      "Iteration:  164\n",
      "Previous theta :  [-0.00843133 -0.04358643  0.04544716  0.12883351  0.08390839  0.15905569\n",
      "  0.48783738  0.08254682  0.15161509  0.02145736 -0.18381583 -0.1121612\n",
      "  0.12817127 -0.34128687]\n",
      "New theta_0 : [-0.00841064 -0.0438898   0.04552218  0.1275649   0.08373131  0.15695399\n",
      "  0.48544859  0.08149385  0.14762785  0.02276403 -0.18352209 -0.11327301\n",
      "  0.12750692 -0.3431994 ]\n",
      "Training Error:  12.066338386724667\n",
      "====================================================================================================\n",
      "Iteration:  165\n",
      "Previous theta :  [-0.00841064 -0.0438898   0.04552218  0.1275649   0.08373131  0.15695399\n",
      "  0.48544859  0.08149385  0.14762785  0.02276403 -0.18352209 -0.11327301\n",
      "  0.12750692 -0.3431994 ]\n",
      "New theta_0 : [-0.00838884 -0.0441936   0.04561033  0.12630671  0.08355785  0.15486519\n",
      "  0.48308703  0.08046192  0.14367562  0.02406282 -0.18322988 -0.1143684\n",
      "  0.12685887 -0.34508403]\n",
      "Training Error:  12.037683389872385\n",
      "====================================================================================================\n",
      "Iteration:  166\n",
      "Previous theta :  [-0.00838884 -0.0441936   0.04561033  0.12630671  0.08355785  0.15486519\n",
      "  0.48308703  0.08046192  0.14367562  0.02406282 -0.18322988 -0.1143684\n",
      "  0.12685887 -0.34508403]\n",
      "New theta_0 : [-0.00836601 -0.04449782  0.04571121  0.12505886  0.08338786  0.1527892\n",
      "  0.48075236  0.07945065  0.13975806  0.02535372 -0.18293927 -0.11544764\n",
      "  0.12622669 -0.34694116]\n",
      "Training Error:  12.009529562285724\n",
      "====================================================================================================\n",
      "Iteration:  167\n",
      "Previous theta :  [-0.00836601 -0.04449782  0.04571121  0.12505886  0.08338786  0.1527892\n",
      "  0.48075236  0.07945065  0.13975806  0.02535372 -0.18293927 -0.11544764\n",
      "  0.12622669 -0.34694116]\n",
      "New theta_0 : [-0.00834222 -0.04480242  0.04582441  0.12382127  0.08322123  0.15072594\n",
      "  0.47844425  0.07845968  0.13587481  0.02663673 -0.18265031 -0.116511\n",
      "  0.12560995 -0.34877122]\n",
      "Training Error:  11.981867125037033\n",
      "====================================================================================================\n",
      "Iteration:  168\n",
      "Previous theta :  [-0.00834222 -0.04480242  0.04582441  0.12382127  0.08322123  0.15072594\n",
      "  0.47844425  0.07845968  0.13587481  0.02663673 -0.18265031 -0.116511\n",
      "  0.12560995 -0.34877122]\n",
      "New theta_0 : [-0.00831754 -0.04510737  0.04594956  0.12259384  0.08305783  0.14867533\n",
      "  0.4761624   0.07748864  0.13202552  0.02791186 -0.18236307 -0.11755876\n",
      "  0.12500824 -0.3505746 ]\n",
      "Training Error:  11.954686520306979\n",
      "====================================================================================================\n",
      "Iteration:  169\n",
      "Previous theta :  [-0.00831754 -0.04510737  0.04594956  0.12259384  0.08305783  0.14867533\n",
      "  0.4761624   0.07748864  0.13202552  0.02791186 -0.18236307 -0.11755876\n",
      "  0.12500824 -0.3505746 ]\n",
      "New theta_0 : [-0.00829202 -0.04541264  0.04608628  0.1213765   0.08289755  0.14663727\n",
      "  0.47390649  0.07653718  0.12820985  0.0291791  -0.1820776  -0.11859116\n",
      "  0.12442116 -0.3523517 ]\n",
      "Training Error:  11.927978405428034\n",
      "====================================================================================================\n",
      "Iteration:  170\n",
      "Previous theta :  [-0.00829202 -0.04541264  0.04608628  0.1213765   0.08289755  0.14663727\n",
      "  0.47390649  0.07653718  0.12820985  0.0291791  -0.1820776  -0.11859116\n",
      "  0.12442116 -0.3523517 ]\n",
      "New theta_0 : [-0.00826574 -0.04571821  0.0462342   0.12016916  0.08274025  0.14461169\n",
      "  0.4716762   0.07560494  0.12442746  0.03043846 -0.18179396 -0.11960848\n",
      "  0.12384831 -0.35410292]\n",
      "Training Error:  11.901733647121583\n",
      "====================================================================================================\n",
      "Iteration:  171\n",
      "Previous theta :  [-0.00826574 -0.04571821  0.0462342   0.12016916  0.08274025  0.14461169\n",
      "  0.4716762   0.07560494  0.12442746  0.03043846 -0.18179396 -0.11960848\n",
      "  0.12384831 -0.35410292]\n",
      "New theta_0 : [-0.00823874 -0.04602404  0.04639297  0.11897174  0.08258585  0.14259849\n",
      "  0.46947124  0.07469158  0.12067801  0.03168995 -0.18151219 -0.12061096\n",
      "  0.12328931 -0.35582864]\n",
      "Training Error:  11.875943315921152\n",
      "====================================================================================================\n",
      "Iteration:  172\n",
      "Previous theta :  [-0.00823874 -0.04602404  0.04639297  0.11897174  0.08258585  0.14259849\n",
      "  0.46947124  0.07469158  0.12067801  0.03168995 -0.18151219 -0.12061096\n",
      "  0.12328931 -0.35582864]\n",
      "New theta_0 : [-0.00821108 -0.0463301   0.04656224  0.11778415  0.08243424  0.14059761\n",
      "  0.46729129  0.07379676  0.11696118  0.03293357 -0.18123234 -0.12159885\n",
      "  0.1227438  -0.35752924]\n",
      "Training Error:  11.850598680774477\n",
      "====================================================================================================\n",
      "Iteration:  173\n",
      "Previous theta :  [-0.00821108 -0.0463301   0.04656224  0.11778415  0.08243424  0.14059761\n",
      "  0.46729129  0.07379676  0.11696118  0.03293357 -0.18123234 -0.12159885\n",
      "  0.1227438  -0.35752924]\n",
      "New theta_0 : [-0.00818281 -0.04663636  0.04674168  0.11660631  0.0822853   0.13860896\n",
      "  0.46513605  0.07292014  0.11327663  0.03416935 -0.18095446 -0.1225724\n",
      "  0.12221142 -0.35920509]\n",
      "Training Error:  11.82569120381752\n",
      "====================================================================================================\n",
      "Iteration:  174\n",
      "Previous theta :  [-0.00818281 -0.04663636  0.04674168  0.11660631  0.0822853   0.13860896\n",
      "  0.46513605  0.07292014  0.11327663  0.03416935 -0.18095446 -0.1225724\n",
      "  0.12221142 -0.35920509]\n",
      "New theta_0 : [-0.00815398 -0.0469428   0.04693096  0.11543816  0.08213896  0.13663246\n",
      "  0.46300523  0.0720614   0.10962406  0.03539729 -0.18067859 -0.12353184\n",
      "  0.12169182 -0.36085657]\n",
      "Training Error:  11.80121253531381\n",
      "====================================================================================================\n",
      "Iteration:  175\n",
      "Previous theta :  [-0.00815398 -0.0469428   0.04693096  0.11543816  0.08213896  0.13663246\n",
      "  0.46300523  0.0720614   0.10962406  0.03539729 -0.18067859 -0.12353184\n",
      "  0.12169182 -0.36085657]\n",
      "New theta_0 : [-0.00812465 -0.04724938  0.04712975  0.1142796   0.08199511  0.13466803\n",
      "  0.46089854  0.07122021  0.10600313  0.03661741 -0.18040476 -0.12447741\n",
      "  0.12118465 -0.36248404]\n",
      "Training Error:  11.777154508752837\n",
      "====================================================================================================\n",
      "Iteration:  176\n",
      "Previous theta :  [-0.00812465 -0.04724938  0.04712975  0.1142796   0.08199511  0.13466803\n",
      "  0.46089854  0.07122021  0.10600313  0.03661741 -0.18040476 -0.12447741\n",
      "  0.12118465 -0.36248404]\n",
      "New theta_0 : [-0.00809484 -0.04755607  0.04733774  0.11313057  0.08185367  0.1327156\n",
      "  0.45881569  0.07039625  0.10241353  0.03782972 -0.18013302 -0.12540935\n",
      "  0.1206896  -0.36408785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  11.753509136101492\n",
      "====================================================================================================\n",
      "Iteration:  177\n",
      "Previous theta :  [-0.00809484 -0.04755607  0.04733774  0.11313057  0.08185367  0.1327156\n",
      "  0.45881569  0.07039625  0.10241353  0.03782972 -0.18013302 -0.12540935\n",
      "  0.1206896  -0.36408785]\n",
      "New theta_0 : [-0.0080646  -0.04786285  0.04755463  0.11199098  0.08171455  0.13077507\n",
      "  0.45675639  0.06958921  0.09885497  0.03903425 -0.1798634  -0.12632787\n",
      "  0.12020633 -0.36566836]\n",
      "Training Error:  11.73026860320276\n",
      "====================================================================================================\n",
      "Iteration:  178\n",
      "Previous theta :  [-0.0080646  -0.04786285  0.04755463  0.11199098  0.08171455  0.13077507\n",
      "  0.45675639  0.06958921  0.09885497  0.03903425 -0.1798634  -0.12632787\n",
      "  0.12020633 -0.36566836]\n",
      "New theta_0 : [-0.00803398 -0.04816968  0.04778012  0.11086076  0.08157768  0.12884639\n",
      "  0.45472035  0.06879879  0.09532712  0.04023101 -0.17959592 -0.1272332\n",
      "  0.11973455 -0.36722591]\n",
      "Training Error:  11.707425265316255\n",
      "====================================================================================================\n",
      "Iteration:  179\n",
      "Previous theta :  [-0.00803398 -0.04816968  0.04778012  0.11086076  0.08157768  0.12884639\n",
      "  0.45472035  0.06879879  0.09532712  0.04023101 -0.17959592 -0.1272332\n",
      "  0.11973455 -0.36722591]\n",
      "New theta_0 : [-0.00800301 -0.04847653  0.04801392  0.10973984  0.08144296  0.12692947\n",
      "  0.4527073   0.06802467  0.09182969  0.04142003 -0.17933063 -0.12812556\n",
      "  0.11927394 -0.36876084]\n",
      "Training Error:  11.684971642795261\n",
      "====================================================================================================\n",
      "Iteration:  180\n",
      "Previous theta :  [-0.00800301 -0.04847653  0.04801392  0.10973984  0.08144296  0.12692947\n",
      "  0.4527073   0.06802467  0.09182969  0.04142003 -0.17933063 -0.12812556\n",
      "  0.11927394 -0.36876084]\n",
      "New theta_0 : [-0.00797173 -0.04878339  0.04825576  0.10862815  0.08131034  0.12502424\n",
      "  0.45071697  0.06726657  0.08836238  0.04260132 -0.17906755 -0.12900516\n",
      "  0.11882421 -0.3702735 ]\n",
      "Training Error:  11.662900416895337\n",
      "====================================================================================================\n",
      "Iteration:  181\n",
      "Previous theta :  [-0.00797173 -0.04878339  0.04825576  0.10862815  0.08131034  0.12502424\n",
      "  0.45071697  0.06726657  0.08836238  0.04260132 -0.17906755 -0.12900516\n",
      "  0.11882421 -0.3702735 ]\n",
      "New theta_0 : [-0.00794017 -0.04909021  0.04850534  0.1075256   0.08117973  0.12313062\n",
      "  0.44874907  0.06652419  0.08492489  0.04377492 -0.1788067  -0.12987222\n",
      "  0.11838508 -0.3717642 ]\n",
      "Training Error:  11.641204425709647\n",
      "====================================================================================================\n",
      "Iteration:  182\n",
      "Previous theta :  [-0.00794017 -0.04909021  0.04850534  0.1075256   0.08117973  0.12313062\n",
      "  0.44874907  0.06652419  0.08492489  0.04377492 -0.1788067  -0.12987222\n",
      "  0.11838508 -0.3717642 ]\n",
      "New theta_0 : [-0.00790836 -0.04939696  0.04876242  0.10643214  0.08105106  0.12124853\n",
      "  0.44680335  0.06579724  0.08151694  0.04494084 -0.17854812 -0.13072693\n",
      "  0.11795626 -0.37323327]\n",
      "Training Error:  11.619876660226447\n",
      "====================================================================================================\n",
      "Iteration:  183\n",
      "Previous theta :  [-0.00790836 -0.04939696  0.04876242  0.10643214  0.08105106  0.12124853\n",
      "  0.44680335  0.06579724  0.08151694  0.04494084 -0.17854812 -0.13072693\n",
      "  0.11795626 -0.37323327]\n",
      "New theta_0 : [-0.00787633 -0.04970363  0.04902672  0.10534769  0.08092428  0.11937792\n",
      "  0.44487953  0.06508544  0.07813824  0.04609912 -0.17829181 -0.13156951\n",
      "  0.1175375  -0.37468105]\n",
      "Training Error:  11.598910260504315\n",
      "====================================================================================================\n",
      "Iteration:  184\n",
      "Previous theta :  [-0.00787633 -0.04970363  0.04902672  0.10534769  0.08092428  0.11937792\n",
      "  0.44487953  0.06508544  0.07813824  0.04609912 -0.17829181 -0.13156951\n",
      "  0.1175375  -0.37468105]\n",
      "New theta_0 : [-0.00784411 -0.05001019  0.04929799  0.10427217  0.08079932  0.1175187\n",
      "  0.44297735  0.06438851  0.0747885   0.04724979 -0.17803782 -0.13240016\n",
      "  0.11712852 -0.37610783]\n",
      "Training Error:  11.578298511960934\n",
      "====================================================================================================\n",
      "Iteration:  185\n",
      "Previous theta :  [-0.00784411 -0.05001019  0.04929799  0.10427217  0.08079932  0.1175187\n",
      "  0.44297735  0.06438851  0.0747885   0.04724979 -0.17803782 -0.13240016\n",
      "  0.11712852 -0.37610783]\n",
      "New theta_0 : [-0.00781174 -0.05031659  0.04957599  0.10320553  0.08067611  0.1156708\n",
      "  0.44109655  0.06370619  0.07146744  0.04839287 -0.17778614 -0.13321906\n",
      "  0.11672907 -0.37751393]\n",
      "Training Error:  11.558034841771432\n",
      "====================================================================================================\n",
      "Iteration:  186\n",
      "Previous theta :  [-0.00781174 -0.05031659  0.04957599  0.10320553  0.08067611  0.1156708\n",
      "  0.44109655  0.06370619  0.07146744  0.04839287 -0.17778614 -0.13321906\n",
      "  0.11672907 -0.37751393]\n",
      "New theta_0 : [-0.00777922 -0.05062283  0.04986047  0.10214769  0.0805546   0.11383415\n",
      "  0.43923688  0.06303819  0.06817479  0.04952838 -0.17753681 -0.13402641\n",
      "  0.11633891 -0.37889966]\n",
      "Training Error:  11.538112815372344\n",
      "====================================================================================================\n",
      "Iteration:  187\n",
      "Previous theta :  [-0.00777922 -0.05062283  0.04986047  0.10214769  0.0805546   0.11383415\n",
      "  0.43923688  0.06303819  0.06817479  0.04952838 -0.17753681 -0.13402641\n",
      "  0.11633891 -0.37889966]\n",
      "New theta_0 : [-0.0077466  -0.05092886  0.05015119  0.10109859  0.08043474  0.11200867\n",
      "  0.43739808  0.06238425  0.06491028  0.05065638 -0.17728983 -0.13482241\n",
      "  0.11595778 -0.38026532]\n",
      "Training Error:  11.51852613306758\n",
      "====================================================================================================\n",
      "Iteration:  188\n",
      "Previous theta :  [-0.0077466  -0.05092886  0.05015119  0.10109859  0.08043474  0.11200867\n",
      "  0.43739808  0.06238425  0.06491028  0.05065638 -0.17728983 -0.13482241\n",
      "  0.11595778 -0.38026532]\n",
      "New theta_0 : [-0.00771389 -0.05123467  0.05044793  0.10005816  0.08031646  0.11019431\n",
      "  0.4355799   0.06174412  0.06167363  0.05177687 -0.17704522 -0.13560723\n",
      "  0.11558547 -0.38161121]\n",
      "Training Error:  11.499268626732835\n",
      "====================================================================================================\n",
      "Iteration:  189\n",
      "Previous theta :  [-0.00771389 -0.05123467  0.05044793  0.10005816  0.08031646  0.11019431\n",
      "  0.4355799   0.06174412  0.06167363  0.05177687 -0.17704522 -0.13560723\n",
      "  0.11558547 -0.38161121]\n",
      "New theta_0 : [-0.00768111 -0.05154022  0.05075047  0.09902632  0.08019972  0.108391\n",
      "  0.4337821   0.06111755  0.05846457  0.05288991 -0.176803   -0.13638107\n",
      "  0.11522173 -0.38293761]\n",
      "Training Error:  11.480334256615034\n",
      "====================================================================================================\n",
      "Iteration:  190\n",
      "Previous theta :  [-0.00768111 -0.05154022  0.05075047  0.09902632  0.08019972  0.108391\n",
      "  0.4337821   0.06111755  0.05846457  0.05288991 -0.176803   -0.13638107\n",
      "  0.11522173 -0.38293761]\n",
      "New theta_0 : [-0.00764828 -0.05184549  0.05105858  0.09800303  0.08008447  0.10659865\n",
      "  0.43200442  0.06050427  0.05528285  0.05399552 -0.17656317 -0.13714409\n",
      "  0.11486634 -0.38424482]\n",
      "Training Error:  11.461717108223553\n",
      "====================================================================================================\n",
      "Iteration:  191\n",
      "Previous theta :  [-0.00764828 -0.05184549  0.05105858  0.09800303  0.08008447  0.10659865\n",
      "  0.43200442  0.06050427  0.05528285  0.05399552 -0.17656317 -0.13714409\n",
      "  0.11486634 -0.38424482]\n",
      "New theta_0 : [-0.00761543 -0.05215046  0.05137206  0.09698821  0.07997066  0.10481721\n",
      "  0.43024664  0.05990404  0.0521282   0.05509373 -0.17632575 -0.13789647\n",
      "  0.1145191  -0.38553311]\n",
      "Training Error:  11.44341138931013\n",
      "====================================================================================================\n",
      "Iteration:  192\n",
      "Previous theta :  [-0.00761543 -0.05215046  0.05137206  0.09698821  0.07997066  0.10481721\n",
      "  0.43024664  0.05990404  0.0521282   0.05509373 -0.17632575 -0.13789647\n",
      "  0.1145191  -0.38553311]\n",
      "New theta_0 : [-0.00758258 -0.0524551   0.05169069  0.0959818   0.07985825  0.1030466\n",
      "  0.4285085   0.05931663  0.04900037  0.05618458 -0.17609074 -0.1386384\n",
      "  0.11417979 -0.38680277]\n",
      "Training Error:  11.425411426934437\n",
      "====================================================================================================\n",
      "Iteration:  193\n",
      "Previous theta :  [-0.00758258 -0.0524551   0.05169069  0.0959818   0.07985825  0.1030466\n",
      "  0.4285085   0.05931663  0.04900037  0.05618458 -0.17609074 -0.1386384\n",
      "  0.11417979 -0.38680277]\n",
      "New theta_0 : [-0.00754973 -0.05275939  0.05201428  0.09498373  0.07974719  0.10128677\n",
      "  0.42678978  0.05874179  0.04589909  0.05726811 -0.17585816 -0.13937003\n",
      "  0.11384821 -0.38805407]\n",
      "Training Error:  11.407711664612432\n",
      "====================================================================================================\n",
      "Iteration:  194\n",
      "Previous theta :  [-0.00754973 -0.05275939  0.05201428  0.09498373  0.07974719  0.10128677\n",
      "  0.42678978  0.05874179  0.04589909  0.05726811 -0.17585816 -0.13937003\n",
      "  0.11384821 -0.38805407]\n",
      "New theta_0 : [-0.0075169  -0.05306329  0.05234262  0.09399395  0.07963744  0.09953764\n",
      "  0.42509023  0.05817928  0.04282413  0.05834436 -0.17562801 -0.14009153\n",
      "  0.11352416 -0.38928728]\n",
      "Training Error:  11.390306659544782\n",
      "====================================================================================================\n",
      "Iteration:  195\n",
      "Previous theta :  [-0.0075169  -0.05306329  0.05234262  0.09399395  0.07963744  0.09953764\n",
      "  0.42509023  0.05817928  0.04282413  0.05834436 -0.17562801 -0.14009153\n",
      "  0.11352416 -0.38928728]\n",
      "New theta_0 : [-0.00748412 -0.05336679  0.05267554  0.09301239  0.07952896  0.09779915\n",
      "  0.42340964  0.05762888  0.03977522  0.05941335 -0.17540029 -0.14080308\n",
      "  0.11320745 -0.39050267]\n",
      "Training Error:  11.37319107992264\n",
      "====================================================================================================\n",
      "Iteration:  196\n",
      "Previous theta :  [-0.00748412 -0.05336679  0.05267554  0.09301239  0.07952896  0.09779915\n",
      "  0.42340964  0.05762888  0.03977522  0.05941335 -0.17540029 -0.14080308\n",
      "  0.11320745 -0.39050267]\n",
      "New theta_0 : [-0.00745139 -0.05366987  0.05301284  0.09203899  0.07942171  0.09607123\n",
      "  0.42174778  0.05709037  0.03675213  0.06047513 -0.17517502 -0.14150482\n",
      "  0.11289789 -0.3917005 ]\n",
      "Training Error:  11.356359702308273\n",
      "====================================================================================================\n",
      "Iteration:  197\n",
      "Previous theta :  [-0.00745139 -0.05366987  0.05301284  0.09203899  0.07942171  0.09607123\n",
      "  0.42174778  0.05709037  0.03675213  0.06047513 -0.17517502 -0.14150482\n",
      "  0.11289789 -0.3917005 ]\n",
      "New theta_0 : [-0.00741873 -0.05397249  0.05335433  0.09107369  0.07931565  0.09435383\n",
      "  0.42010441  0.05656351  0.03375461  0.06152974 -0.17495219 -0.14219693\n",
      "  0.11259529 -0.39288103]\n",
      "Training Error:  11.339807409088072\n",
      "====================================================================================================\n",
      "Iteration:  198\n",
      "Previous theta :  [-0.00741873 -0.05397249  0.05335433  0.09107369  0.07931565  0.09435383\n",
      "  0.42010441  0.05656351  0.03375461  0.06152974 -0.17495219 -0.14219693\n",
      "  0.11259529 -0.39288103]\n",
      "New theta_0 : [-0.00738615 -0.05427464  0.05369985  0.09011643  0.07921076  0.09264686\n",
      "  0.41847933  0.0560481   0.03078242  0.06257721 -0.1747318  -0.14287954\n",
      "  0.11229949 -0.3940445 ]\n",
      "Training Error:  11.323529185995609\n",
      "====================================================================================================\n",
      "Iteration:  199\n",
      "Previous theta :  [-0.00738615 -0.05427464  0.05369985  0.09011643  0.07921076  0.09264686\n",
      "  0.41847933  0.0560481   0.03078242  0.06257721 -0.1747318  -0.14287954\n",
      "  0.11229949 -0.3940445 ]\n",
      "New theta_0 : [-0.00735367 -0.05457629  0.05404922  0.08916715  0.07910699  0.09095028\n",
      "  0.4168723   0.05554391  0.02783533  0.06361758 -0.17451387 -0.14355283\n",
      "  0.1120103  -0.39519118]\n",
      "Training Error:  11.30752011970246\n",
      "====================================================================================================\n",
      "Iteration:  200\n",
      "Previous theta :  [-0.00735367 -0.05457629  0.05404922  0.08916715  0.07910699  0.09095028\n",
      "  0.4168723   0.05554391  0.02783533  0.06361758 -0.17451387 -0.14355283\n",
      "  0.1120103  -0.39519118]\n",
      "New theta_0 : [-0.00732129 -0.05487742  0.05440227  0.08822578  0.07900431  0.08926402\n",
      "  0.41528312  0.05505073  0.02491309  0.0646509  -0.17429838 -0.14421693\n",
      "  0.11172756 -0.39632131]\n",
      "Training Error:  11.291775395474643\n",
      "====================================================================================================\n",
      "Iteration:  201\n",
      "Previous theta :  [-0.00732129 -0.05487742  0.05440227  0.08822578  0.07900431  0.08926402\n",
      "  0.41528312  0.05505073  0.02491309  0.0646509  -0.17429838 -0.14421693\n",
      "  0.11172756 -0.39632131]\n",
      "New theta_0 : [-0.00728902 -0.05517801  0.05475885  0.08729228  0.0789027   0.08758802\n",
      "  0.41371157  0.05456836  0.02201549  0.0656772  -0.17408534 -0.14487199\n",
      "  0.11145112 -0.39743513]\n",
      "Training Error:  11.276290294892537\n",
      "====================================================================================================\n",
      "Iteration:  202\n",
      "Previous theta :  [-0.00728902 -0.05517801  0.05475885  0.08729228  0.0789027   0.08758802\n",
      "  0.41371157  0.05456836  0.02201549  0.0656772  -0.17408534 -0.14487199\n",
      "  0.11145112 -0.39743513]\n",
      "New theta_0 : [-0.00725688 -0.05547804  0.05511878  0.08636659  0.07880212  0.08592221\n",
      "  0.41215744  0.0540966   0.01914228  0.06669652 -0.17387475 -0.14551817\n",
      "  0.1111808  -0.39853288]\n",
      "Training Error:  11.261060193632321\n",
      "====================================================================================================\n",
      "Iteration:  203\n",
      "Previous theta :  [-0.00725688 -0.05547804  0.05511878  0.08636659  0.07880212  0.08592221\n",
      "  0.41215744  0.0540966   0.01914228  0.06669652 -0.17387475 -0.14551817\n",
      "  0.1111808  -0.39853288]\n",
      "New theta_0 : [-0.00722487 -0.05577749  0.05548192  0.08544864  0.07870254  0.08426653\n",
      "  0.41062052  0.05363524  0.01629324  0.06770891 -0.1736666  -0.1461556\n",
      "  0.11091645 -0.39961479]\n",
      "Training Error:  11.24608055930695\n",
      "====================================================================================================\n",
      "Iteration:  204\n",
      "Previous theta :  [-0.00722487 -0.05577749  0.05548192  0.08544864  0.07870254  0.08426653\n",
      "  0.41062052  0.05363524  0.01629324  0.06770891 -0.1736666  -0.1461556\n",
      "  0.11091645 -0.39961479]\n",
      "New theta_0 : [-0.007193   -0.05607633  0.05584811  0.08453838  0.07860394  0.08262093\n",
      "  0.4091006   0.05318409  0.01346815  0.0687144  -0.1734609  -0.14678442\n",
      "  0.11065793 -0.4006811 ]\n",
      "Training Error:  11.231346949364822\n",
      "====================================================================================================\n",
      "Iteration:  205\n",
      "Previous theta :  [-0.007193   -0.05607633  0.05584811  0.08453838  0.07860394  0.08262093\n",
      "  0.4091006   0.05318409  0.01346815  0.0687144  -0.1734609  -0.14678442\n",
      "  0.11065793 -0.4006811 ]\n",
      "New theta_0 : [-0.00716129 -0.05637455  0.05621721  0.08363575  0.07850629  0.08098533\n",
      "  0.40759749  0.05274294  0.01066678  0.06971304 -0.17325764 -0.14740477\n",
      "  0.11040509 -0.40173204]\n",
      "Training Error:  11.216855009044338\n",
      "====================================================================================================\n",
      "Iteration:  206\n",
      "Previous theta :  [-0.00716129 -0.05637455  0.05621721  0.08363575  0.07850629  0.08098533\n",
      "  0.40759749  0.05274294  0.01066678  0.06971304 -0.17325764 -0.14740477\n",
      "  0.11040509 -0.40173204]\n",
      "New theta_0 : [-0.00712973 -0.05667212  0.05658907  0.0827407   0.07840957  0.07935969\n",
      "  0.40611098  0.05231163  0.00788893  0.07070486 -0.17305681 -0.14801678\n",
      "  0.11015779 -0.40276783]\n",
      "Training Error:  11.202600469382613\n",
      "====================================================================================================\n",
      "Iteration:  207\n",
      "Previous theta :  [-0.00712973 -0.05667212  0.05658907  0.0827407   0.07840957  0.07935969\n",
      "  0.40611098  0.05231163  0.00788893  0.07070486 -0.17305681 -0.14801678\n",
      "  0.11015779 -0.40276783]\n",
      "New theta_0 : [-0.00709834 -0.05696903  0.05696356  0.08185317  0.07831374  0.07774395\n",
      "  0.40464088  0.05188995  0.00513436  0.07168991 -0.17285841 -0.1486206\n",
      "  0.10991589 -0.40378869]\n",
      "Training Error:  11.18857914527668\n",
      "====================================================================================================\n",
      "Iteration:  208\n",
      "Previous theta :  [-0.00709834 -0.05696903  0.05696356  0.08185317  0.07831374  0.07774395\n",
      "  0.40464088  0.05188995  0.00513436  0.07168991 -0.17285841 -0.1486206\n",
      "  0.10991589 -0.40378869]\n",
      "New theta_0 : [-0.00706712 -0.05726526  0.05734054  0.08097311  0.07821879  0.07613803\n",
      "  0.40318698  0.05147772  0.00240286  0.07266823 -0.17266245 -0.14921634\n",
      "  0.10967925 -0.40479483]\n",
      "Training Error:  11.174786933595573\n",
      "====================================================================================================\n",
      "Iteration:  209\n",
      "Previous theta :  [-0.00706712 -0.05726526  0.05734054  0.08097311  0.07821879  0.07613803\n",
      "  0.40318698  0.05147772  0.00240286  0.07266823 -0.17266245 -0.14921634\n",
      "  0.10967925 -0.40479483]\n",
      "New theta_0 : [-7.03607310e-03 -5.75607949e-02  5.77198736e-02  8.01004549e-02\n",
      "  7.81247005e-02  7.45418915e-02  4.01749102e-01  5.10747665e-02\n",
      " -3.05767338e-04  7.36398595e-02 -1.72468896e-01 -1.49804142e-01\n",
      "  1.09447749e-01 -4.05786488e-01]\n",
      "Training Error:  11.161219811341732\n",
      "====================================================================================================\n",
      "Iteration:  210\n",
      "Previous theta :  [-7.03607310e-03 -5.75607949e-02  5.77198736e-02  8.01004549e-02\n",
      "  7.81247005e-02  7.45418915e-02  4.01749102e-01  5.10747665e-02\n",
      " -3.05767338e-04  7.36398595e-02 -1.72468896e-01 -1.49804142e-01\n",
      "  1.09447749e-01 -4.05786488e-01]\n",
      "New theta_0 : [-0.00700521 -0.05785561  0.05810144  0.07923516  0.07803144  0.07295547\n",
      "  0.40032705  0.05068091 -0.00299175  0.07460485 -0.17227776 -0.15038413\n",
      "  0.10922125 -0.40676386]\n",
      "Training Error:  11.147873833860253\n",
      "====================================================================================================\n",
      "Iteration:  211\n",
      "Previous theta :  [-0.00700521 -0.05785561  0.05810144  0.07923516  0.07803144  0.07295547\n",
      "  0.40032705  0.05068091 -0.00299175  0.07460485 -0.17227776 -0.15038413\n",
      "  0.10922125 -0.40676386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00697454 -0.05814968  0.0584851   0.07837717  0.07793899  0.0713787\n",
      "  0.39892063  0.05029597 -0.00565528  0.07556323 -0.17208903 -0.15095642\n",
      "  0.10899964 -0.40772715]\n",
      "Training Error:  11.134745133094508\n",
      "====================================================================================================\n",
      "Iteration:  212\n",
      "Previous theta :  [-0.00697454 -0.05814968  0.0584851   0.07837717  0.07793899  0.0713787\n",
      "  0.39892063  0.05029597 -0.00565528  0.07556323 -0.17208903 -0.15095642\n",
      "  0.10899964 -0.40772715]\n",
      "New theta_0 : [-0.00694405 -0.05844301  0.05887074  0.07752643  0.07784734  0.06981154\n",
      "  0.39752966  0.04991979 -0.00829657  0.07651505 -0.1719027  -0.15152114\n",
      "  0.10878279 -0.40867657]\n",
      "Training Error:  11.12182991588679\n",
      "====================================================================================================\n",
      "Iteration:  213\n",
      "Previous theta :  [-0.00694405 -0.05844301  0.05887074  0.07752643  0.07784734  0.06981154\n",
      "  0.39752966  0.04991979 -0.00829657  0.07651505 -0.1719027  -0.15152114\n",
      "  0.10878279 -0.40867657]\n",
      "New theta_0 : [-0.00691377 -0.05873556  0.05925825  0.07668289  0.07775646  0.06825392\n",
      "  0.39615395  0.04955219 -0.01091582  0.07746035 -0.17171877 -0.15207841\n",
      "  0.10857059 -0.40961232]\n",
      "Training Error:  11.109124462322592\n",
      "====================================================================================================\n",
      "Iteration:  214\n",
      "Previous theta :  [-0.00691377 -0.05873556  0.05925825  0.07668289  0.07775646  0.06825392\n",
      "  0.39615395  0.04955219 -0.01091582  0.07746035 -0.17171877 -0.15207841\n",
      "  0.10857059 -0.40961232]\n",
      "New theta_0 : [-0.00688368 -0.05902733  0.0596475   0.07584649  0.07766633  0.06670579\n",
      "  0.39479333  0.04919301 -0.01351324  0.07839918 -0.17153721 -0.15262835\n",
      "  0.10836292 -0.41053461]\n",
      "Training Error:  11.096625124117237\n",
      "====================================================================================================\n",
      "Iteration:  215\n",
      "Previous theta :  [-0.00688368 -0.05902733  0.0596475   0.07584649  0.07766633  0.06670579\n",
      "  0.39479333  0.04919301 -0.01351324  0.07839918 -0.17153721 -0.15262835\n",
      "  0.10836292 -0.41053461]\n",
      "New theta_0 : [-0.0068538  -0.05931829  0.06003839  0.07501718  0.07757695  0.0651671\n",
      "  0.39344762  0.04884208 -0.01608902  0.07933157 -0.17135803 -0.15317106\n",
      "  0.10815968 -0.41144362]\n",
      "Training Error:  11.084328323043648\n",
      "====================================================================================================\n",
      "Iteration:  216\n",
      "Previous theta :  [-0.0068538  -0.05931829  0.06003839  0.07501718  0.07757695  0.0651671\n",
      "  0.39344762  0.04884208 -0.01608902  0.07933157 -0.17135803 -0.15317106\n",
      "  0.10815968 -0.41144362]\n",
      "New theta_0 : [-0.00682412 -0.05960844  0.0604308   0.07419492  0.07748829  0.06363777\n",
      "  0.39211663  0.04849926 -0.01864335  0.08025757 -0.17118121 -0.15370668\n",
      "  0.10796075 -0.41233954]\n",
      "Training Error:  11.07223054939998\n",
      "====================================================================================================\n",
      "Iteration:  217\n",
      "Previous theta :  [-0.00682412 -0.05960844  0.0604308   0.07419492  0.07748829  0.06363777\n",
      "  0.39211663  0.04849926 -0.01864335  0.08025757 -0.17118121 -0.15370668\n",
      "  0.10796075 -0.41233954]\n",
      "New theta_0 : [-0.00679466 -0.05989775  0.06082463  0.07337965  0.07740033  0.06211777\n",
      "  0.3908002   0.04816437 -0.02117644  0.08117722 -0.17100675 -0.1542353\n",
      "  0.10776602 -0.41322258]\n",
      "Training Error:  11.060328360515992\n",
      "====================================================================================================\n",
      "Iteration:  218\n",
      "Previous theta :  [-0.00679466 -0.05989775  0.06082463  0.07337965  0.07740033  0.06211777\n",
      "  0.3908002   0.04816437 -0.02117644  0.08117722 -0.17100675 -0.1542353\n",
      "  0.10776602 -0.41322258]\n",
      "New theta_0 : [-0.00676541 -0.06018622  0.06121977  0.07257131  0.07731306  0.06060704\n",
      "  0.38949815  0.04783728 -0.02368848  0.08209057 -0.17083463 -0.15475705\n",
      "  0.10757541 -0.41409292]\n",
      "Training Error:  11.048618379297027\n",
      "====================================================================================================\n",
      "Iteration:  219\n",
      "Previous theta :  [-0.00676541 -0.06018622  0.06121977  0.07257131  0.07731306  0.06060704\n",
      "  0.38949815  0.04783728 -0.02368848  0.08209057 -0.17083463 -0.15475705\n",
      "  0.10757541 -0.41409292]\n",
      "New theta_0 : [-0.00673637 -0.06047382  0.06161612  0.07176987  0.07722647  0.05910552\n",
      "  0.38821031  0.04751782 -0.02617965  0.08299766 -0.17066484 -0.15527202\n",
      "  0.1073888  -0.41495073]\n",
      "Training Error:  11.037097292804491\n",
      "====================================================================================================\n",
      "Iteration:  220\n",
      "Previous theta :  [-0.00673637 -0.06047382  0.06161612  0.07176987  0.07722647  0.05910552\n",
      "  0.38821031  0.04751782 -0.02617965  0.08299766 -0.17066484 -0.15527202\n",
      "  0.1073888  -0.41495073]\n",
      "New theta_0 : [-0.00670755 -0.06076055  0.06201359  0.07097526  0.07714054  0.05761316\n",
      "  0.38693651  0.04720584 -0.02865014  0.08389852 -0.17049738 -0.15578032\n",
      "  0.1072061  -0.41579621]\n",
      "Training Error:  11.0257618508718\n",
      "====================================================================================================\n",
      "Iteration:  221\n",
      "Previous theta :  [-0.00670755 -0.06076055  0.06201359  0.07097526  0.07714054  0.05761316\n",
      "  0.38693651  0.04720584 -0.02865014  0.08389852 -0.17049738 -0.15578032\n",
      "  0.1072061  -0.41579621]\n",
      "New theta_0 : [-0.00667895 -0.06104638  0.06241208  0.07018744  0.07705526  0.0561299\n",
      "  0.38567659  0.04690122 -0.03110014  0.08479321 -0.17033223 -0.15628206\n",
      "  0.10702722 -0.41662952]\n",
      "Training Error:  11.014608864754752\n",
      "====================================================================================================\n",
      "Iteration:  222\n",
      "Previous theta :  [-0.00667895 -0.06104638  0.06241208  0.07018744  0.07705526  0.0561299\n",
      "  0.38567659  0.04690122 -0.03110014  0.08479321 -0.17033223 -0.15628206\n",
      "  0.10702722 -0.41662952]\n",
      "New theta_0 : [-0.00665057 -0.06133131  0.0628115   0.06940636  0.07697061  0.05465569\n",
      "  0.38443038  0.04660379 -0.03352984  0.08568176 -0.17016937 -0.15677733\n",
      "  0.10685207 -0.41745086]\n",
      "Training Error:  11.003635205815351\n",
      "====================================================================================================\n",
      "Iteration:  223\n",
      "Previous theta :  [-0.00665057 -0.06133131  0.0628115   0.06940636  0.07697061  0.05465569\n",
      "  0.38443038  0.04660379 -0.03352984  0.08568176 -0.17016937 -0.15677733\n",
      "  0.10685207 -0.41745086]\n",
      "New theta_0 : [-0.00662241 -0.06161533  0.06321175  0.06863197  0.07688658  0.05319048\n",
      "  0.38319771  0.04631342 -0.03593941  0.08656422 -0.17000881 -0.15726625\n",
      "  0.10668055 -0.41826039]\n",
      "Training Error:  10.992837804238155\n",
      "====================================================================================================\n",
      "Iteration:  224\n",
      "Previous theta :  [-0.00662241 -0.06161533  0.06321175  0.06863197  0.07688658  0.05319048\n",
      "  0.38319771  0.04631342 -0.03593941  0.08656422 -0.17000881 -0.15726625\n",
      "  0.10668055 -0.41826039]\n",
      "New theta_0 : [-0.00659448 -0.06189841  0.06361275  0.06786422  0.07680317  0.05173421\n",
      "  0.38197844  0.04602998 -0.03832904  0.08744063 -0.16985052 -0.15774891\n",
      "  0.10651258 -0.41905827]\n",
      "Training Error:  10.982213647778153\n",
      "====================================================================================================\n",
      "Iteration:  225\n",
      "Previous theta :  [-0.00659448 -0.06189841  0.06361275  0.06786422  0.07680317  0.05173421\n",
      "  0.38197844  0.04602998 -0.03832904  0.08744063 -0.16985052 -0.15774891\n",
      "  0.10651258 -0.41905827]\n",
      "New theta_0 : [-0.00656677 -0.06218056  0.06401441  0.06710307  0.07672035  0.05028684\n",
      "  0.3807724   0.04575332 -0.0406989   0.08831104 -0.16969449 -0.1582254\n",
      "  0.10634808 -0.41984469]\n",
      "Training Error:  10.971759780539381\n",
      "====================================================================================================\n",
      "Iteration:  226\n",
      "Previous theta :  [-0.00656677 -0.06218056  0.06401441  0.06710307  0.07672035  0.05028684\n",
      "  0.3807724   0.04575332 -0.0406989   0.08831104 -0.16969449 -0.1582254\n",
      "  0.10634808 -0.41984469]\n",
      "New theta_0 : [-0.00653928 -0.06246175  0.06441666  0.06634846  0.07663812  0.0488483\n",
      "  0.37957943  0.04548332 -0.04304918  0.08917548 -0.16954072 -0.15869583\n",
      "  0.10618696 -0.42061981]\n",
      "Training Error:  10.96147330178333\n",
      "====================================================================================================\n",
      "Iteration:  227\n",
      "Previous theta :  [-0.00653928 -0.06246175  0.06441666  0.06634846  0.07663812  0.0488483\n",
      "  0.37957943  0.04548332 -0.04304918  0.08917548 -0.16954072 -0.15869583\n",
      "  0.10618696 -0.42061981]\n",
      "New theta_0 : [-0.00651202 -0.06274197  0.0648194   0.06560035  0.07655647  0.04741856\n",
      "  0.37839938  0.04521984 -0.04538004  0.090034   -0.16938918 -0.15916028\n",
      "  0.10602914 -0.42138378]\n",
      "Training Error:  10.951351364766342\n",
      "====================================================================================================\n",
      "Iteration:  228\n",
      "Previous theta :  [-0.00651202 -0.06274197  0.0648194   0.06560035  0.07655647  0.04741856\n",
      "  0.37839938  0.04521984 -0.04538004  0.090034   -0.16938918 -0.15916028\n",
      "  0.10602914 -0.42138378]\n",
      "New theta_0 : [-0.00648499 -0.06302122  0.06522257  0.06485869  0.07647538  0.04599755\n",
      "  0.37723211  0.04496276 -0.04769167  0.09088664 -0.16923987 -0.15961886\n",
      "  0.10587455 -0.42213678]\n",
      "Training Error:  10.941391175605194\n",
      "====================================================================================================\n",
      "Iteration:  229\n",
      "Previous theta :  [-0.00648499 -0.06302122  0.06522257  0.06485869  0.07647538  0.04599755\n",
      "  0.37723211  0.04496276 -0.04769167  0.09088664 -0.16923987 -0.15961886\n",
      "  0.10587455 -0.42213678]\n",
      "New theta_0 : [-0.00645818 -0.06329949  0.06562608  0.06412343  0.07639485  0.04458524\n",
      "  0.37607744  0.04471195 -0.04998422  0.09173344 -0.16909277 -0.16007164\n",
      "  0.1057231  -0.42287895]\n",
      "Training Error:  10.931589992170078\n",
      "====================================================================================================\n",
      "Iteration:  230\n",
      "Previous theta :  [-0.00645818 -0.06329949  0.06562608  0.06412343  0.07639485  0.04458524\n",
      "  0.37607744  0.04471195 -0.04998422  0.09173344 -0.16909277 -0.16007164\n",
      "  0.1057231  -0.42287895]\n",
      "New theta_0 : [-0.0064316  -0.06357675  0.06602986  0.06339453  0.07631487  0.04318155\n",
      "  0.37493525  0.04446728 -0.05225788  0.09257444 -0.16894786 -0.16051872\n",
      "  0.10557473 -0.42361046]\n",
      "Training Error:  10.92194512300422\n",
      "====================================================================================================\n",
      "Iteration:  231\n",
      "Previous theta :  [-0.0064316  -0.06357675  0.06602986  0.06339453  0.07631487  0.04318155\n",
      "  0.37493525  0.04446728 -0.05225788  0.09257444 -0.16894786 -0.16051872\n",
      "  0.10557473 -0.42361046]\n",
      "New theta_0 : [-0.00640525 -0.06385301  0.06643383  0.06267194  0.07623542  0.04178646\n",
      "  0.37380538  0.04422864 -0.0545128   0.09340969 -0.16880514 -0.1609602\n",
      "  0.10542937 -0.42433146]\n",
      "Training Error:  10.912453926269391\n",
      "====================================================================================================\n",
      "Iteration:  232\n",
      "Previous theta :  [-0.00640525 -0.06385301  0.06643383  0.06267194  0.07623542  0.04178646\n",
      "  0.37380538  0.04422864 -0.0545128   0.09340969 -0.16880514 -0.1609602\n",
      "  0.10542937 -0.42433146]\n",
      "New theta_0 : [-0.00637912 -0.06412825  0.06683794  0.06195561  0.07615651  0.0403999\n",
      "  0.37268769  0.0439959  -0.05674916  0.09423923 -0.16866459 -0.16139615\n",
      "  0.10528694 -0.4250421 ]\n",
      "Training Error:  10.903113808716629\n",
      "====================================================================================================\n",
      "Iteration:  233\n",
      "Previous theta :  [-0.00637912 -0.06412825  0.06683794  0.06195561  0.07615651  0.0403999\n",
      "  0.37268769  0.0439959  -0.05674916  0.09423923 -0.16866459 -0.16139615\n",
      "  0.10528694 -0.4250421 ]\n",
      "New theta_0 : [-0.00635322 -0.06440246  0.06724211  0.0612455   0.07607811  0.03902183\n",
      "  0.37158204  0.04376895 -0.05896712  0.0950631  -0.16852619 -0.16182665\n",
      "  0.10514737 -0.42574253]\n",
      "Training Error:  10.893922224681456\n",
      "====================================================================================================\n",
      "Iteration:  234\n",
      "Previous theta :  [-0.00635322 -0.06440246  0.06724211  0.0612455   0.07607811  0.03902183\n",
      "  0.37158204  0.04376895 -0.05896712  0.0950631  -0.16852619 -0.16182665\n",
      "  0.10514737 -0.42574253]\n",
      "New theta_0 : [-0.00632754 -0.06467564  0.06764627  0.06054157  0.07600023  0.03765219\n",
      "  0.37048828  0.04354768 -0.06116684  0.09588133 -0.16838994 -0.1622518\n",
      "  0.1050106  -0.42643289]\n",
      "Training Error:  10.884876675102923\n",
      "====================================================================================================\n",
      "Iteration:  235\n",
      "Previous theta :  [-0.00632754 -0.06467564  0.06764627  0.06054157  0.07600023  0.03765219\n",
      "  0.37048828  0.04354768 -0.06116684  0.09588133 -0.16838994 -0.1622518\n",
      "  0.1050106  -0.42643289]\n",
      "New theta_0 : [-0.00630209 -0.06494778  0.06805037  0.05984376  0.07592285  0.03629094\n",
      "  0.36940627  0.04333196 -0.06334848  0.09669398 -0.16825582 -0.16267168\n",
      "  0.10487656 -0.42711334]\n",
      "Training Error:  10.875974706565874\n",
      "====================================================================================================\n",
      "Iteration:  236\n",
      "Previous theta :  [-0.00630209 -0.06494778  0.06805037  0.05984376  0.07592285  0.03629094\n",
      "  0.36940627  0.04333196 -0.06334848  0.09669398 -0.16825582 -0.16267168\n",
      "  0.10487656 -0.42711334]\n",
      "New theta_0 : [-0.00627686 -0.06521886  0.06845433  0.05915204  0.07584596  0.03493803\n",
      "  0.36833588  0.0431217  -0.0655122   0.09750109 -0.1681238  -0.16308636\n",
      "  0.1047452  -0.42778401]\n",
      "Training Error:  10.867213910365734\n",
      "====================================================================================================\n",
      "Iteration:  237\n",
      "Previous theta :  [-0.00627686 -0.06521886  0.06845433  0.05915204  0.07584596  0.03493803\n",
      "  0.36833588  0.0431217  -0.0655122   0.09750109 -0.1681238  -0.16308636\n",
      "  0.1047452  -0.42778401]\n",
      "New theta_0 : [-0.00625186 -0.06548887  0.0688581   0.05846635  0.07576957  0.03359342\n",
      "  0.36727697  0.04291677 -0.06765817  0.09830268 -0.16799389 -0.16349593\n",
      "  0.10461644 -0.42844504]\n",
      "Training Error:  10.858591921595284\n",
      "====================================================================================================\n",
      "Iteration:  238\n",
      "Previous theta :  [-0.00625186 -0.06548887  0.0688581   0.05846635  0.07576957  0.03359342\n",
      "  0.36727697  0.04291677 -0.06765817  0.09830268 -0.16799389 -0.16349593\n",
      "  0.10461644 -0.42844504]\n",
      "New theta_0 : [-0.00622708 -0.06575782  0.06926161  0.05778666  0.07569366  0.03225704\n",
      "  0.3662294   0.04271708 -0.06978653  0.09909882 -0.16786605 -0.16390047\n",
      "  0.10449024 -0.42909658]\n",
      "Training Error:  10.850106418252777\n",
      "====================================================================================================\n",
      "Iteration:  239\n",
      "Previous theta :  [-0.00622708 -0.06575782  0.06926161  0.05778666  0.07569366  0.03225704\n",
      "  0.3662294   0.04271708 -0.06978653  0.09909882 -0.16786605 -0.16390047\n",
      "  0.10449024 -0.42909658]\n",
      "New theta_0 : [-0.00620253 -0.0660257   0.06966482  0.05711291  0.07561822  0.03092886\n",
      "  0.36519305  0.04252252 -0.07189744  0.09988952 -0.16774029 -0.16430004\n",
      "  0.10436652 -0.42973876]\n",
      "Training Error:  10.841755120370872\n",
      "====================================================================================================\n",
      "Iteration:  240\n",
      "Previous theta :  [-0.00620253 -0.0660257   0.06966482  0.05711291  0.07561822  0.03092886\n",
      "  0.36519305  0.04252252 -0.07189744  0.09988952 -0.16774029 -0.16430004\n",
      "  0.10436652 -0.42973876]\n",
      "New theta_0 : [-0.00617819 -0.06629249  0.07006767  0.05644508  0.07554326  0.02960883\n",
      "  0.36416778  0.04233298 -0.07399105  0.10067485 -0.16761658 -0.16469474\n",
      "  0.10424524 -0.43037171]\n",
      "Training Error:  10.833535789165792\n",
      "====================================================================================================\n",
      "Iteration:  241\n",
      "Previous theta :  [-0.00617819 -0.06629249  0.07006767  0.05644508  0.07554326  0.02960883\n",
      "  0.36416778  0.04233298 -0.07399105  0.10067485 -0.16761658 -0.16469474\n",
      "  0.10424524 -0.43037171]\n",
      "New theta_0 : [-0.00615408 -0.06655818  0.0704701   0.05578311  0.07546876  0.0282969\n",
      "  0.36315347  0.04214837 -0.07606752  0.10145483 -0.16749491 -0.16508462\n",
      "  0.10412634 -0.43099557]\n",
      "Training Error:  10.82544622620618\n",
      "====================================================================================================\n",
      "Iteration:  242\n",
      "Previous theta :  [-0.00615408 -0.06655818  0.0704701   0.05578311  0.07546876  0.0282969\n",
      "  0.36315347  0.04214837 -0.07606752  0.10145483 -0.16749491 -0.16508462\n",
      "  0.10412634 -0.43099557]\n",
      "New theta_0 : [-0.00613018 -0.06682278  0.07087206  0.05512695  0.07539471  0.02699302\n",
      "  0.36214998  0.04196858 -0.078127    0.1022295  -0.16737527 -0.16546977\n",
      "  0.10400977 -0.43161047]\n",
      "Training Error:  10.817484272601162\n",
      "====================================================================================================\n",
      "Iteration:  243\n",
      "Previous theta :  [-0.00613018 -0.06682278  0.07087206  0.05512695  0.07539471  0.02699302\n",
      "  0.36214998  0.04196858 -0.078127    0.1022295  -0.16737527 -0.16546977\n",
      "  0.10400977 -0.43161047]\n",
      "New theta_0 : [-0.0061065  -0.06708628  0.07127351  0.05447658  0.07532112  0.02569715\n",
      "  0.36115719  0.04179353 -0.08016963  0.10299891 -0.16725763 -0.16585025\n",
      "  0.10389546 -0.43221653]\n",
      "Training Error:  10.809647808207046\n",
      "====================================================================================================\n",
      "Iteration:  244\n",
      "Previous theta :  [-0.0061065  -0.06708628  0.07127351  0.05447658  0.07532112  0.02569715\n",
      "  0.36115719  0.04179353 -0.08016963  0.10299891 -0.16725763 -0.16585025\n",
      "  0.10389546 -0.43221653]\n",
      "New theta_0 : [-0.00608304 -0.06734866  0.07167438  0.05383194  0.07524797  0.02440924\n",
      "  0.36017498  0.0416231  -0.08219556  0.1037631  -0.16714199 -0.16622614\n",
      "  0.10378338 -0.43281389]\n",
      "Training Error:  10.801934750852245\n",
      "====================================================================================================\n",
      "Iteration:  245\n",
      "Previous theta :  [-0.00608304 -0.06734866  0.07167438  0.05383194  0.07524797  0.02440924\n",
      "  0.36017498  0.0416231  -0.08219556  0.1037631  -0.16714199 -0.16622614\n",
      "  0.10378338 -0.43281389]\n",
      "New theta_0 : [-0.0060598  -0.06760993  0.07207464  0.05319299  0.07517526  0.02312924\n",
      "  0.35920321  0.04145721 -0.08420494  0.1045221  -0.16702832 -0.1665975\n",
      "  0.10367348 -0.43340266]\n",
      "Training Error:  10.794343055579882\n",
      "====================================================================================================\n",
      "Iteration:  246\n",
      "Previous theta :  [-0.0060598  -0.06760993  0.07207464  0.05319299  0.07517526  0.02312924\n",
      "  0.35920321  0.04145721 -0.08420494  0.1045221  -0.16702832 -0.1665975\n",
      "  0.10367348 -0.43340266]\n",
      "New theta_0 : [-0.00603677 -0.06787008  0.07247424  0.05255969  0.07510299  0.02185712\n",
      "  0.35824178  0.04129577 -0.08619791  0.10527596 -0.16691662 -0.16696442\n",
      "  0.10356569 -0.43398297]\n",
      "Training Error:  10.786870713907646\n",
      "====================================================================================================\n",
      "Iteration:  247\n",
      "Previous theta :  [-0.00603677 -0.06787008  0.07247424  0.05255969  0.07510299  0.02185712\n",
      "  0.35824178  0.04129577 -0.08619791  0.10527596 -0.16691662 -0.16696442\n",
      "  0.10356569 -0.43398297]\n",
      "New theta_0 : [-0.00601395 -0.0681291   0.07287313  0.051932    0.07503114  0.02059281\n",
      "  0.35729056  0.04113869 -0.08817462  0.10602471 -0.16680687 -0.16732694\n",
      "  0.10345998 -0.43455494]\n",
      "Training Error:  10.779515753104457\n",
      "====================================================================================================\n",
      "Iteration:  248\n",
      "Previous theta :  [-0.00601395 -0.0681291   0.07287313  0.051932    0.07503114  0.02059281\n",
      "  0.35729056  0.04113869 -0.08817462  0.10602471 -0.16680687 -0.16732694\n",
      "  0.10345998 -0.43455494]\n",
      "New theta_0 : [-0.00599135 -0.06838699  0.07327127  0.05130988  0.07495972  0.01933628\n",
      "  0.35634943  0.04098587 -0.0901352   0.10676839 -0.16669905 -0.16768514\n",
      "  0.10335631 -0.43511869]\n",
      "Training Error:  10.772276235483478\n",
      "====================================================================================================\n",
      "Iteration:  249\n",
      "Previous theta :  [-0.00599135 -0.06838699  0.07327127  0.05130988  0.07495972  0.01933628\n",
      "  0.35634943  0.04098587 -0.0901352   0.10676839 -0.16669905 -0.16768514\n",
      "  0.10335631 -0.43511869]\n",
      "New theta_0 : [-0.00596895 -0.06864374  0.07366862  0.05069328  0.07488873  0.01808749\n",
      "  0.35541827  0.04083723 -0.09207979  0.10750704 -0.16659314 -0.16803908\n",
      "  0.10325461 -0.43567434]\n",
      "Training Error:  10.76515025771107\n",
      "====================================================================================================\n",
      "Iteration:  250\n",
      "Previous theta :  [-0.00596895 -0.06864374  0.07366862  0.05069328  0.07488873  0.01808749\n",
      "  0.35541827  0.04083723 -0.09207979  0.10750704 -0.16659314 -0.16803908\n",
      "  0.10325461 -0.43567434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00594677 -0.06889934  0.07406513  0.05008217  0.07481814  0.01684638\n",
      "  0.35449698  0.04069269 -0.09400854  0.1082407  -0.16648914 -0.16838883\n",
      "  0.10315486 -0.436222  ]\n",
      "Training Error:  10.758135950131283\n",
      "====================================================================================================\n",
      "Iteration:  251\n",
      "Previous theta :  [-0.00594677 -0.06889934  0.07406513  0.05008217  0.07481814  0.01684638\n",
      "  0.35449698  0.04069269 -0.09400854  0.1082407  -0.16648914 -0.16838883\n",
      "  0.10315486 -0.436222  ]\n",
      "New theta_0 : [-0.00592479 -0.06915381  0.07446078  0.0494765   0.07474797  0.01561291\n",
      "  0.35358543  0.04055215 -0.09592159  0.10896941 -0.16638703 -0.16873445\n",
      "  0.10305701 -0.43676179]\n",
      "Training Error:  10.751231476105469\n",
      "====================================================================================================\n",
      "Iteration:  252\n",
      "Previous theta :  [-0.00592479 -0.06915381  0.07446078  0.0494765   0.07474797  0.01561291\n",
      "  0.35358543  0.04055215 -0.09592159  0.10896941 -0.16638703 -0.16873445\n",
      "  0.10305701 -0.43676179]\n",
      "New theta_0 : [-0.00590302 -0.06940712  0.07485552  0.04887624  0.07467821  0.01438705\n",
      "  0.35268351  0.04041554 -0.09781906  0.1096932  -0.16628678 -0.169076\n",
      "  0.10296102 -0.43729382]\n",
      "Training Error:  10.744435031366631\n",
      "====================================================================================================\n",
      "Iteration:  253\n",
      "Previous theta :  [-0.00590302 -0.06940712  0.07485552  0.04887624  0.07467821  0.01438705\n",
      "  0.35268351  0.04041554 -0.09781906  0.1096932  -0.16628678 -0.169076\n",
      "  0.10296102 -0.43729382]\n",
      "New theta_0 : [-0.00588145 -0.06965928  0.07524931  0.04828134  0.07460884  0.01316874\n",
      "  0.35179112  0.04028278 -0.09970109  0.11041211 -0.1661884  -0.16941354\n",
      "  0.10286684 -0.4378182 ]\n",
      "Training Error:  10.737744843388162\n",
      "====================================================================================================\n",
      "Iteration:  254\n",
      "Previous theta :  [-0.00588145 -0.06965928  0.07524931  0.04828134  0.07460884  0.01316874\n",
      "  0.35179112  0.04028278 -0.09970109  0.11041211 -0.1661884  -0.16941354\n",
      "  0.10286684 -0.4378182 ]\n",
      "New theta_0 : [-0.00586008 -0.06991028  0.07564213  0.04769176  0.07453988  0.01195794\n",
      "  0.35090814  0.04015379 -0.10156781  0.11112619 -0.16609185 -0.16974713\n",
      "  0.10277444 -0.43833504]\n",
      "Training Error:  10.731159170766558\n",
      "====================================================================================================\n",
      "Iteration:  255\n",
      "Previous theta :  [-0.00586008 -0.06991028  0.07564213  0.04769176  0.07453988  0.01195794\n",
      "  0.35090814  0.04015379 -0.10156781  0.11112619 -0.16609185 -0.16974713\n",
      "  0.10277444 -0.43833504]\n",
      "New theta_0 : [-0.00583892 -0.07016012  0.07603392  0.04710746  0.07447131  0.01075461\n",
      "  0.35003446  0.04002848 -0.10341937  0.11183546 -0.16599713 -0.17007683\n",
      "  0.10268378 -0.43884444]\n",
      "Training Error:  10.724676302617798\n",
      "====================================================================================================\n",
      "Iteration:  256\n",
      "Previous theta :  [-0.00583892 -0.07016012  0.07603392  0.04710746  0.07447131  0.01075461\n",
      "  0.35003446  0.04002848 -0.10341937  0.11183546 -0.16599713 -0.17007683\n",
      "  0.10268378 -0.43884444]\n",
      "New theta_0 : [-0.00581796 -0.07040879  0.07642467  0.04652842  0.07440313  0.0095587\n",
      "  0.34916997  0.03990679 -0.10525588  0.11253997 -0.16590422 -0.17040271\n",
      "  0.10259482 -0.43934652]\n",
      "Training Error:  10.718294557987008\n",
      "====================================================================================================\n",
      "Iteration:  257\n",
      "Previous theta :  [-0.00581796 -0.07040879  0.07642467  0.04652842  0.07440313  0.0095587\n",
      "  0.34916997  0.03990679 -0.10525588  0.11253997 -0.16590422 -0.17040271\n",
      "  0.10259482 -0.43934652]\n",
      "New theta_0 : [-0.00579719 -0.0706563   0.07681434  0.04595457  0.07433534  0.00837017\n",
      "  0.34831458  0.03978864 -0.10707748  0.11323974 -0.16581311 -0.1707248\n",
      "  0.10250752 -0.43984138]\n",
      "Training Error:  10.712012285271115\n",
      "====================================================================================================\n",
      "Iteration:  258\n",
      "Previous theta :  [-0.00579719 -0.0706563   0.07681434  0.04595457  0.07433534  0.00837017\n",
      "  0.34831458  0.03978864 -0.10707748  0.11323974 -0.16581311 -0.1707248\n",
      "  0.10250752 -0.43984138]\n",
      "New theta_0 : [-0.00577662 -0.07090264  0.07720289  0.04538589  0.07426794  0.00718898\n",
      "  0.34746817  0.03967394 -0.1088843   0.11393483 -0.16572377 -0.17104318\n",
      "  0.10242186 -0.44032911]\n",
      "Training Error:  10.705827861654113\n",
      "====================================================================================================\n",
      "Iteration:  259\n",
      "Previous theta :  [-0.00577662 -0.07090264  0.07720289  0.04538589  0.07426794  0.00718898\n",
      "  0.34746817  0.03967394 -0.1088843   0.11393483 -0.16572377 -0.17104318\n",
      "  0.10242186 -0.44032911]\n",
      "New theta_0 : [-0.00575624 -0.0711478   0.0775903   0.04482234  0.07420091  0.00601509\n",
      "  0.34663065  0.03956264 -0.11067646  0.11462525 -0.1656362  -0.17135789\n",
      "  0.10233778 -0.44080983]\n",
      "Training Error:  10.699739692554685\n",
      "====================================================================================================\n",
      "Iteration:  260\n",
      "Previous theta :  [-0.00575624 -0.0711478   0.0775903   0.04482234  0.07420091  0.00601509\n",
      "  0.34663065  0.03956264 -0.11067646  0.11462525 -0.1656362  -0.17135789\n",
      "  0.10233778 -0.44080983]\n",
      "New theta_0 : [-0.00573606 -0.07139179  0.07797654  0.04426388  0.07413426  0.00484845\n",
      "  0.3458019   0.03945466 -0.11245409  0.11531106 -0.16555038 -0.171669\n",
      "  0.10225527 -0.44128363]\n",
      "Training Error:  10.693746211085818\n",
      "====================================================================================================\n",
      "Iteration:  261\n",
      "Previous theta :  [-0.00573606 -0.07139179  0.07797654  0.04426388  0.07413426  0.00484845\n",
      "  0.3458019   0.03945466 -0.11245409  0.11531106 -0.16555038 -0.171669\n",
      "  0.10225527 -0.44128363]\n",
      "New theta_0 : [-0.00571607 -0.07163461  0.07836159  0.04371047  0.07406798  0.00368903\n",
      "  0.34498184  0.03934993 -0.11421731  0.11599228 -0.1654663  -0.17197655\n",
      "  0.10217428 -0.44175061]\n",
      "Training Error:  10.687845877526154\n",
      "====================================================================================================\n",
      "Iteration:  262\n",
      "Previous theta :  [-0.00571607 -0.07163461  0.07836159  0.04371047  0.07406798  0.00368903\n",
      "  0.34498184  0.03934993 -0.11421731  0.11599228 -0.1654663  -0.17197655\n",
      "  0.10217428 -0.44175061]\n",
      "New theta_0 : [-0.00569626 -0.07187624  0.07874541  0.04316207  0.07400208  0.00253677\n",
      "  0.34417036  0.03924839 -0.11596625  0.11666895 -0.16538393 -0.17228059\n",
      "  0.10209479 -0.44221087]\n",
      "Training Error:  10.682037178802762\n",
      "====================================================================================================\n",
      "Iteration:  263\n",
      "Previous theta :  [-0.00569626 -0.07187624  0.07874541  0.04316207  0.07400208  0.00253677\n",
      "  0.34417036  0.03924839 -0.11596625  0.11666895 -0.16538393 -0.17228059\n",
      "  0.10209479 -0.44221087]\n",
      "New theta_0 : [-0.00567665 -0.0721167   0.07912797  0.04261864  0.07393654  0.00139164\n",
      "  0.34336735  0.03914995 -0.11770103  0.11734111 -0.16530327 -0.17258118\n",
      "  0.10201676 -0.4426645 ]\n",
      "Training Error:  10.676318627985045\n",
      "====================================================================================================\n",
      "Iteration:  264\n",
      "Previous theta :  [-0.00567665 -0.0721167   0.07912797  0.04261864  0.07393654  0.00139164\n",
      "  0.34336735  0.03914995 -0.11770103  0.11734111 -0.16530327 -0.17258118\n",
      "  0.10201676 -0.4426645 ]\n",
      "New theta_0 : [-5.65721969e-03 -7.23559682e-02  7.95092615e-02  4.20801528e-02\n",
      "  7.38713685e-02  2.53596154e-04  3.42572739e-01  3.90545682e-02\n",
      " -1.19421765e-01  1.18008793e-01 -1.65224292e-01 -1.72878363e-01\n",
      "  1.01940167e-01 -4.43111592e-01]\n",
      "Training Error:  10.670688763789556\n",
      "====================================================================================================\n",
      "Iteration:  265\n",
      "Previous theta :  [-5.65721969e-03 -7.23559682e-02  7.95092615e-02  4.20801528e-02\n",
      "  7.38713685e-02  2.53596154e-04  3.42572739e-01  3.90545682e-02\n",
      " -1.19421765e-01  1.18008793e-01 -1.65224292e-01 -1.72878363e-01\n",
      "  1.01940167e-01 -4.43111592e-01]\n",
      "New theta_0 : [-0.00563797 -0.07259406  0.07988925  0.04154657  0.07380656 -0.0008774\n",
      "  0.34178641  0.03896217 -0.12112858  0.11867203 -0.16514699 -0.1731722\n",
      "  0.10186497 -0.44355225]\n",
      "Training Error:  10.66514615009537\n",
      "====================================================================================================\n",
      "Iteration:  266\n",
      "Previous theta :  [-0.00563797 -0.07259406  0.07988925  0.04154657  0.07380656 -0.0008774\n",
      "  0.34178641  0.03896217 -0.12112858  0.11867203 -0.16514699 -0.1731722\n",
      "  0.10186497 -0.44355225]\n",
      "New theta_0 : [-0.00561891 -0.07283096  0.08026791  0.04101784  0.0737421  -0.00200139\n",
      "  0.34100828  0.03887269 -0.1228216   0.11933086 -0.16507135 -0.17346273\n",
      "  0.10179115 -0.44398655]\n",
      "Training Error:  10.659689375469837\n",
      "====================================================================================================\n",
      "Iteration:  267\n",
      "Previous theta :  [-0.00561891 -0.07283096  0.08026791  0.04101784  0.0737421  -0.00200139\n",
      "  0.34100828  0.03887269 -0.1228216   0.11933086 -0.16507135 -0.17346273\n",
      "  0.10179115 -0.44398655]\n",
      "New theta_0 : [-0.00560003 -0.07306668  0.08064523  0.04049394  0.07367801 -0.00311842\n",
      "  0.34023825  0.03878607 -0.12450094  0.11998531 -0.16499736 -0.17375\n",
      "  0.10171868 -0.4444146 ]\n",
      "Training Error:  10.654317052704418\n",
      "====================================================================================================\n",
      "Iteration:  268\n",
      "Previous theta :  [-0.00560003 -0.07306668  0.08064523  0.04049394  0.07367801 -0.00311842\n",
      "  0.34023825  0.03878607 -0.12450094  0.11998531 -0.16499736 -0.17375\n",
      "  0.10171868 -0.4444146 ]\n",
      "New theta_0 : [-0.00558133 -0.07330121  0.08102118  0.03997483  0.07361426 -0.00422853\n",
      "  0.33947624  0.03870225 -0.12616671  0.12063542 -0.16492499 -0.17403407\n",
      "  0.10164752 -0.44483647]\n",
      "Training Error:  10.649027818360361\n",
      "====================================================================================================\n",
      "Iteration:  269\n",
      "Previous theta :  [-0.00558133 -0.07330121  0.08102118  0.03997483  0.07361426 -0.00422853\n",
      "  0.33947624  0.03870225 -0.12616671  0.12063542 -0.16492499 -0.17403407\n",
      "  0.10164752 -0.44483647]\n",
      "New theta_0 : [-0.0055628  -0.07353456  0.08139575  0.03946047  0.07355087 -0.00533175\n",
      "  0.33872213  0.03862116 -0.12781903  0.12128122 -0.16485424 -0.17431497\n",
      "  0.10157765 -0.44525226]\n",
      "Training Error:  10.643820332324\n",
      "====================================================================================================\n",
      "Iteration:  270\n",
      "Previous theta :  [-0.0055628  -0.07353456  0.08139575  0.03946047  0.07355087 -0.00533175\n",
      "  0.33872213  0.03862116 -0.12781903  0.12128122 -0.16485424 -0.17431497\n",
      "  0.10157765 -0.44525226]\n",
      "New theta_0 : [-0.00554445 -0.07376672  0.0817689   0.03895083  0.07348783 -0.00642813\n",
      "  0.33797586  0.03854276 -0.12945801  0.12192275 -0.16478508 -0.17459276\n",
      "  0.10150904 -0.44566206]\n",
      "Training Error:  10.638693277371415\n",
      "====================================================================================================\n",
      "Iteration:  271\n",
      "Previous theta :  [-0.00554445 -0.07376672  0.0817689   0.03895083  0.07348783 -0.00642813\n",
      "  0.33797586  0.03854276 -0.12945801  0.12192275 -0.16478508 -0.17459276\n",
      "  0.10150904 -0.44566206]\n",
      "New theta_0 : [-0.00552628 -0.07399769  0.08214062  0.03844587  0.07342513 -0.0075177\n",
      "  0.33723733  0.03846698 -0.13108377  0.12256003 -0.16471752 -0.17486748\n",
      "  0.10144167 -0.44606594]\n",
      "Training Error:  10.633645358742262\n",
      "====================================================================================================\n",
      "Iteration:  272\n",
      "Previous theta :  [-0.00552628 -0.07399769  0.08214062  0.03844587  0.07342513 -0.0075177\n",
      "  0.33723733  0.03846698 -0.13108377  0.12256003 -0.16471752 -0.17486748\n",
      "  0.10144167 -0.44606594]\n",
      "New theta_0 : [-0.00550828 -0.07422747  0.0825109   0.03794556  0.07336277 -0.00860051\n",
      "  0.33650645  0.03839376 -0.13269641  0.12319311 -0.16465152 -0.17513917\n",
      "  0.10137551 -0.44646399]\n",
      "Training Error:  10.628675303722511\n",
      "====================================================================================================\n",
      "Iteration:  273\n",
      "Previous theta :  [-0.00550828 -0.07422747  0.0825109   0.03794556  0.07336277 -0.00860051\n",
      "  0.33650645  0.03839376 -0.13269641  0.12319311 -0.16465152 -0.17513917\n",
      "  0.10137551 -0.44646399]\n",
      "New theta_0 : [-0.00549044 -0.07445606  0.08287972  0.03744986  0.07330075 -0.0096766\n",
      "  0.33578313  0.03832305 -0.13429606  0.12382202 -0.16458708 -0.17540787\n",
      "  0.10131054 -0.4468563 ]\n",
      "Training Error:  10.623781861235923\n",
      "====================================================================================================\n",
      "Iteration:  274\n",
      "Previous theta :  [-0.00549044 -0.07445606  0.08287972  0.03744986  0.07330075 -0.0096766\n",
      "  0.33578313  0.03832305 -0.13429606  0.12382202 -0.16458708 -0.17540787\n",
      "  0.10131054 -0.4468563 ]\n",
      "New theta_0 : [-0.00547278 -0.07468347  0.08324706  0.03695873  0.07323908 -0.010746\n",
      "  0.3350673   0.03825479 -0.13588282  0.12444678 -0.16452419 -0.17567364\n",
      "  0.10124673 -0.44724295]\n",
      "Training Error:  10.618963801444021\n",
      "====================================================================================================\n",
      "Iteration:  275\n",
      "Previous theta :  [-0.00547278 -0.07468347  0.08324706  0.03695873  0.07323908 -0.010746\n",
      "  0.3350673   0.03825479 -0.13588282  0.12444678 -0.16452419 -0.17567364\n",
      "  0.10124673 -0.44724295]\n",
      "New theta_0 : [-0.00545528 -0.07490969  0.08361289  0.03647213  0.07317773 -0.01180875\n",
      "  0.33435885  0.03818894 -0.1374568   0.12506743 -0.16446282 -0.17593651\n",
      "  0.10118406 -0.44762401]\n",
      "Training Error:  10.614219915354376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  276\n",
      "Previous theta :  [-0.00545528 -0.07490969  0.08361289  0.03647213  0.07317773 -0.01180875\n",
      "  0.33435885  0.03818894 -0.1374568   0.12506743 -0.16446282 -0.17593651\n",
      "  0.10118406 -0.44762401]\n",
      "New theta_0 : [-0.00543795 -0.07513472  0.08397722  0.03599005  0.07311673 -0.0128649\n",
      "  0.33365772  0.03812543 -0.1390181   0.12568401 -0.16440296 -0.17619652\n",
      "  0.10112251 -0.44799956]\n",
      "Training Error:  10.609549014437002\n",
      "====================================================================================================\n",
      "Iteration:  277\n",
      "Previous theta :  [-0.00543795 -0.07513472  0.08397722  0.03599005  0.07311673 -0.0128649\n",
      "  0.33365772  0.03812543 -0.1390181   0.12568401 -0.16440296 -0.17619652\n",
      "  0.10112251 -0.44799956]\n",
      "New theta_0 : [-0.00542079 -0.07535856  0.08434002  0.03551243  0.07305605 -0.01391448\n",
      "  0.33296382  0.03806423 -0.14056685  0.12629654 -0.16434461 -0.17645372\n",
      "  0.10106205 -0.44836969]\n",
      "Training Error:  10.604949930248669\n",
      "====================================================================================================\n",
      "Iteration:  278\n",
      "Previous theta :  [-0.00542079 -0.07535856  0.08434002  0.03551243  0.07305605 -0.01391448\n",
      "  0.33296382  0.03806423 -0.14056685  0.12629654 -0.16434461 -0.17645372\n",
      "  0.10106205 -0.44836969]\n",
      "New theta_0 : [-0.00540378 -0.07558122  0.08470128  0.03503925  0.0729957  -0.01495753\n",
      "  0.33227707  0.03800527 -0.14210313  0.12690505 -0.16428773 -0.17670814\n",
      "  0.10100266 -0.44873446]\n",
      "Training Error:  10.60042151406493\n",
      "====================================================================================================\n",
      "Iteration:  279\n",
      "Previous theta :  [-0.00540378 -0.07558122  0.08470128  0.03503925  0.0729957  -0.01495753\n",
      "  0.33227707  0.03800527 -0.14210313  0.12690505 -0.16428773 -0.17670814\n",
      "  0.10100266 -0.44873446]\n",
      "New theta_0 : [-0.00538694 -0.0758027   0.08506099  0.03457047  0.07293568 -0.01599408\n",
      "  0.33159738  0.0379485  -0.14362706  0.12750959 -0.16423234 -0.17695983\n",
      "  0.10094432 -0.44909396]\n",
      "Training Error:  10.595962636519744\n",
      "====================================================================================================\n",
      "Iteration:  280\n",
      "Previous theta :  [-0.00538694 -0.0758027   0.08506099  0.03457047  0.07293568 -0.01599408\n",
      "  0.33159738  0.0379485  -0.14362706  0.12750959 -0.16423234 -0.17695983\n",
      "  0.10094432 -0.44909396]\n",
      "New theta_0 : [-0.00537025 -0.07602299  0.08541912  0.03410605  0.07287599 -0.01702419\n",
      "  0.33092468  0.03789389 -0.14513874  0.12811017 -0.16417839 -0.17720882\n",
      "  0.10088702 -0.44944826]\n",
      "Training Error:  10.591572187252412\n",
      "====================================================================================================\n",
      "Iteration:  281\n",
      "Previous theta :  [-0.00537025 -0.07602299  0.08541912  0.03410605  0.07287599 -0.01702419\n",
      "  0.33092468  0.03789389 -0.14513874  0.12811017 -0.16417839 -0.17720882\n",
      "  0.10088702 -0.44944826]\n",
      "New theta_0 : [-0.00535372 -0.0762421   0.08577568  0.03364597  0.07281661 -0.01804787\n",
      "  0.33025889  0.03784138 -0.14663827  0.12870683 -0.16412589 -0.17745515\n",
      "  0.10083072 -0.44979743]\n",
      "Training Error:  10.587249074561763\n",
      "====================================================================================================\n",
      "Iteration:  282\n",
      "Previous theta :  [-0.00535372 -0.0762421   0.08577568  0.03364597  0.07281661 -0.01804787\n",
      "  0.33025889  0.03784138 -0.14663827  0.12870683 -0.16412589 -0.17745515\n",
      "  0.10083072 -0.44979743]\n",
      "New theta_0 : [-0.00533735 -0.07646002  0.08613065  0.03319019  0.07275756 -0.01906517\n",
      "  0.32959993  0.03779092 -0.14812576  0.1292996  -0.16407482 -0.17769886\n",
      "  0.10077542 -0.45014155]\n",
      "Training Error:  10.582992225067343\n",
      "====================================================================================================\n",
      "Iteration:  283\n",
      "Previous theta :  [-0.00533735 -0.07646002  0.08613065  0.03319019  0.07275756 -0.01906517\n",
      "  0.32959993  0.03779092 -0.14812576  0.1292996  -0.16407482 -0.17769886\n",
      "  0.10077542 -0.45014155]\n",
      "New theta_0 : [-0.00532113 -0.07667677  0.08648402  0.03273868  0.07269883 -0.02007614\n",
      "  0.32894773  0.03774247 -0.1496013   0.12988851 -0.16402517 -0.17793998\n",
      "  0.10072108 -0.45048068]\n",
      "Training Error:  10.578800583377493\n",
      "====================================================================================================\n",
      "Iteration:  284\n",
      "Previous theta :  [-0.00532113 -0.07667677  0.08648402  0.03273868  0.07269883 -0.02007614\n",
      "  0.32894773  0.03774247 -0.1496013   0.12988851 -0.16402517 -0.17793998\n",
      "  0.10072108 -0.45048068]\n",
      "New theta_0 : [-0.00530506 -0.07689234  0.08683577  0.0322914   0.07264041 -0.02108079\n",
      "  0.3283022   0.03769599 -0.15106501  0.13047359 -0.16397692 -0.17817856\n",
      "  0.1006677  -0.4508149 ]\n",
      "Training Error:  10.574673111764119\n",
      "====================================================================================================\n",
      "Iteration:  285\n",
      "Previous theta :  [-0.00530506 -0.07689234  0.08683577  0.0322914   0.07264041 -0.02108079\n",
      "  0.3283022   0.03769599 -0.15106501  0.13047359 -0.16397692 -0.17817856\n",
      "  0.1006677  -0.4508149 ]\n",
      "New theta_0 : [-0.00528915 -0.07710673  0.0871859   0.03184832  0.07258231 -0.02207918\n",
      "  0.32766328  0.03765143 -0.15251697  0.13105487 -0.16393006 -0.17841462\n",
      "  0.10061524 -0.45114428]\n",
      "Training Error:  10.570608789844046\n",
      "====================================================================================================\n",
      "Iteration:  286\n",
      "Previous theta :  [-0.00528915 -0.07710673  0.0871859   0.03184832  0.07258231 -0.02207918\n",
      "  0.32766328  0.03765143 -0.15251697  0.13105487 -0.16393006 -0.17841462\n",
      "  0.10061524 -0.45114428]\n",
      "New theta_0 : [-0.00527338 -0.07731994  0.0875344   0.0314094   0.07252453 -0.02307134\n",
      "  0.32703089  0.03760874 -0.15395729  0.13163238 -0.16388457 -0.17864821\n",
      "  0.10056371 -0.45146887]\n",
      "Training Error:  10.566606614266746\n",
      "====================================================================================================\n",
      "Iteration:  287\n",
      "Previous theta :  [-0.00527338 -0.07731994  0.0875344   0.0314094   0.07252453 -0.02307134\n",
      "  0.32703089  0.03760874 -0.15395729  0.13163238 -0.16388457 -0.17864821\n",
      "  0.10056371 -0.45146887]\n",
      "New theta_0 : [-0.00525776 -0.07753199  0.08788125  0.03097463  0.07246705 -0.02405731\n",
      "  0.32640495  0.03756789 -0.15538606  0.13220615 -0.16384044 -0.17887936\n",
      "  0.10051307 -0.45178876]\n",
      "Training Error:  10.562665598408346\n",
      "====================================================================================================\n",
      "Iteration:  288\n",
      "Previous theta :  [-0.00525776 -0.07753199  0.08788125  0.03097463  0.07246705 -0.02405731\n",
      "  0.32640495  0.03756789 -0.15538606  0.13220615 -0.16384044 -0.17887936\n",
      "  0.10051307 -0.45178876]\n",
      "New theta_0 : [-0.00524228 -0.07774286  0.08822646  0.03054395  0.07240988 -0.02503711\n",
      "  0.3257854   0.03752883 -0.15680338  0.13277621 -0.16379767 -0.17910809\n",
      "  0.10046331 -0.45210401]\n",
      "Training Error:  10.558784772071746\n",
      "====================================================================================================\n",
      "Iteration:  289\n",
      "Previous theta :  [-0.00524228 -0.07774286  0.08822646  0.03054395  0.07240988 -0.02503711\n",
      "  0.3257854   0.03752883 -0.15680338  0.13277621 -0.16379767 -0.17910809\n",
      "  0.10046331 -0.45210401]\n",
      "New theta_0 : [-0.00522695 -0.07795256  0.08857001  0.03011735  0.07235302 -0.02601079\n",
      "  0.32517217  0.03749152 -0.15820935  0.13334259 -0.16375623 -0.17933446\n",
      "  0.10041441 -0.45241468]\n",
      "Training Error:  10.554963181192718\n",
      "====================================================================================================\n",
      "Iteration:  290\n",
      "Previous theta :  [-0.00522695 -0.07795256  0.08857001  0.03011735  0.07235302 -0.02601079\n",
      "  0.32517217  0.03749152 -0.15820935  0.13334259 -0.16375623 -0.17933446\n",
      "  0.10041441 -0.45241468]\n",
      "New theta_0 : [-0.00521177 -0.07816109  0.0889119   0.02969478  0.07229647 -0.02697839\n",
      "  0.32456518  0.03745593 -0.15960406  0.13390531 -0.16371611 -0.17955848\n",
      "  0.10036636 -0.45272084]\n",
      "Training Error:  10.55119988755183\n",
      "====================================================================================================\n",
      "Iteration:  291\n",
      "Previous theta :  [-0.00521177 -0.07816109  0.0889119   0.02969478  0.07229647 -0.02697839\n",
      "  0.32456518  0.03745593 -0.15960406  0.13390531 -0.16371611 -0.17955848\n",
      "  0.10036636 -0.45272084]\n",
      "New theta_0 : [-0.00519672 -0.07836846  0.08925211  0.02927622  0.07224022 -0.02793994\n",
      "  0.32396436  0.03742201 -0.1609876   0.13446441 -0.1636773  -0.17978019\n",
      "  0.10031914 -0.45302254]\n",
      "Training Error:  10.547493968492104\n",
      "====================================================================================================\n",
      "Iteration:  292\n",
      "Previous theta :  [-0.00519672 -0.07836846  0.08925211  0.02927622  0.07224022 -0.02793994\n",
      "  0.32396436  0.03742201 -0.1609876   0.13446441 -0.1636773  -0.17978019\n",
      "  0.10031914 -0.45302254]\n",
      "New theta_0 : [-0.00518182 -0.07857467  0.08959065  0.02886164  0.07218428 -0.02889547\n",
      "  0.32336965  0.03738972 -0.16236008  0.13501991 -0.16363979 -0.17999962\n",
      "  0.10027273 -0.45331986]\n",
      "Training Error:  10.543844516642231\n",
      "====================================================================================================\n",
      "Iteration:  293\n",
      "Previous theta :  [-0.00518182 -0.07857467  0.08959065  0.02886164  0.07218428 -0.02889547\n",
      "  0.32336965  0.03738972 -0.16236008  0.13501991 -0.16363979 -0.17999962\n",
      "  0.10027273 -0.45331986]\n",
      "New theta_0 : [-0.00516705 -0.07877971  0.0899275   0.028451    0.07212863 -0.02984502\n",
      "  0.32278097  0.03735903 -0.16372157  0.13557184 -0.16360356 -0.18021681\n",
      "  0.10022712 -0.45361286]\n",
      "Training Error:  10.540250639645256\n",
      "====================================================================================================\n",
      "Iteration:  294\n",
      "Previous theta :  [-0.00516705 -0.07877971  0.0899275   0.028451    0.07212863 -0.02984502\n",
      "  0.32278097  0.03735903 -0.16372157  0.13557184 -0.16360356 -0.18021681\n",
      "  0.10022712 -0.45361286]\n",
      "New theta_0 : [-0.00515242 -0.0789836   0.09026266  0.02804428  0.07207328 -0.03078863\n",
      "  0.32219827  0.0373299  -0.16507218  0.13612023 -0.1635686  -0.18043178\n",
      "  0.1001823  -0.45390159]\n",
      "Training Error:  10.536711459892583\n",
      "====================================================================================================\n",
      "Iteration:  295\n",
      "Previous theta :  [-0.00515242 -0.0789836   0.09026266  0.02804428  0.07207328 -0.03078863\n",
      "  0.32219827  0.0373299  -0.16507218  0.13612023 -0.1635686  -0.18043178\n",
      "  0.1001823  -0.45390159]\n",
      "New theta_0 : [-0.00513792 -0.07918634  0.09059613  0.02764143  0.07201823 -0.03172633\n",
      "  0.32162147  0.03730229 -0.166412    0.13666511 -0.1635349  -0.18064457\n",
      "  0.10013824 -0.45418612]\n",
      "Training Error:  10.533226114263208\n",
      "====================================================================================================\n",
      "Iteration:  296\n",
      "Previous theta :  [-0.00513792 -0.07918634  0.09059613  0.02764143  0.07201823 -0.03172633\n",
      "  0.32162147  0.03730229 -0.166412    0.13666511 -0.1635349  -0.18064457\n",
      "  0.10013824 -0.45418612]\n",
      "New theta_0 : [-0.00512356 -0.07938792  0.0909279   0.02724244  0.07196348 -0.03265815\n",
      "  0.32105051  0.03727617 -0.1677411   0.1372065  -0.16350245 -0.18085521\n",
      "  0.10009494 -0.4544665 ]\n",
      "Training Error:  10.529793753868036\n",
      "====================================================================================================\n",
      "Iteration:  297\n",
      "Previous theta :  [-0.00512356 -0.07938792  0.0909279   0.02724244  0.07196348 -0.03265815\n",
      "  0.32105051  0.03727617 -0.1677411   0.1372065  -0.16350245 -0.18085521\n",
      "  0.10009494 -0.4544665 ]\n",
      "New theta_0 : [-0.00510933 -0.07958835  0.09125796  0.02684727  0.07190902 -0.03358413\n",
      "  0.32048533  0.03725151 -0.16905959  0.13774444 -0.16347123 -0.18106372\n",
      "  0.10005238 -0.4547428 ]\n",
      "Training Error:  10.526413543799185\n",
      "====================================================================================================\n",
      "Iteration:  298\n",
      "Previous theta :  [-0.00510933 -0.07958835  0.09125796  0.02684727  0.07190902 -0.03358413\n",
      "  0.32048533  0.03725151 -0.16905959  0.13774444 -0.16347123 -0.18106372\n",
      "  0.10005238 -0.4547428 ]\n",
      "New theta_0 : [-0.00509524 -0.07978763  0.09158632  0.02645589  0.07185485 -0.03450431\n",
      "  0.31992586  0.03722826 -0.17036756  0.13827894 -0.16344123 -0.18127013\n",
      "  0.10001055 -0.45501506]\n",
      "Training Error:  10.523084662884171\n",
      "====================================================================================================\n",
      "Iteration:  299\n",
      "Previous theta :  [-0.00509524 -0.07978763  0.09158632  0.02645589  0.07185485 -0.03450431\n",
      "  0.31992586  0.03722826 -0.17036756  0.13827894 -0.16344123 -0.18127013\n",
      "  0.10001055 -0.45501506]\n",
      "New theta_0 : [-0.00508127 -0.07998578  0.09191297  0.02606827  0.07180097 -0.03541872\n",
      "  0.31937203  0.0372064  -0.17166508  0.13881003 -0.16341244 -0.18147448\n",
      "  0.09996943 -0.45528335]\n",
      "Training Error:  10.519806303444843\n",
      "====================================================================================================\n",
      "Iteration:  300\n",
      "Previous theta :  [-0.00508127 -0.07998578  0.09191297  0.02606827  0.07180097 -0.03541872\n",
      "  0.31937203  0.0372064  -0.17166508  0.13881003 -0.16341244 -0.18147448\n",
      "  0.09996943 -0.45528335]\n",
      "New theta_0 : [-0.00506743 -0.08018278  0.0922379   0.02568438  0.07174739 -0.03632739\n",
      "  0.3188238   0.0371859  -0.17295224  0.13933775 -0.16338484 -0.18167679\n",
      "  0.09992901 -0.45554773]\n",
      "Training Error:  10.516577671061\n",
      "====================================================================================================\n",
      "Iteration:  301\n",
      "Previous theta :  [-0.00506743 -0.08018278  0.0922379   0.02568438  0.07174739 -0.03632739\n",
      "  0.3188238   0.0371859  -0.17295224  0.13933775 -0.16338484 -0.18167679\n",
      "  0.09992901 -0.45554773]\n",
      "New theta_0 : [-0.00505372 -0.08037864  0.09256111  0.0253042   0.07169409 -0.03723036\n",
      "  0.31828108  0.03716671 -0.17422914  0.13986212 -0.16335843 -0.18187708\n",
      "  0.09988928 -0.45580824]\n",
      "Training Error:  10.51339798433855\n",
      "====================================================================================================\n",
      "Iteration:  302\n",
      "Previous theta :  [-0.00505372 -0.08037864  0.09256111  0.0253042   0.07169409 -0.03723036\n",
      "  0.31828108  0.03716671 -0.17422914  0.13986212 -0.16335843 -0.18187708\n",
      "  0.09988928 -0.45580824]\n",
      "New theta_0 : [-0.00504013 -0.08057337  0.09288261  0.02492768  0.07164107 -0.03812765\n",
      "  0.31774383  0.03714881 -0.17549586  0.14038316 -0.1633332  -0.18207539\n",
      "  0.09985023 -0.45606494]\n",
      "Training Error:  10.510266474682131\n",
      "====================================================================================================\n",
      "Iteration:  303\n",
      "Previous theta :  [-0.00504013 -0.08057337  0.09288261  0.02492768  0.07164107 -0.03812765\n",
      "  0.31774383  0.03714881 -0.17549586  0.14038316 -0.1633332  -0.18207539\n",
      "  0.09985023 -0.45606494]\n",
      "New theta_0 : [-0.00502667 -0.08076697  0.09320238  0.02455481  0.07158834 -0.03901932\n",
      "  0.31721198  0.03713218 -0.17675248  0.1409009  -0.16330912 -0.18227174\n",
      "  0.09981183 -0.45631789]\n",
      "Training Error:  10.507182386072113\n",
      "====================================================================================================\n",
      "Iteration:  304\n",
      "Previous theta :  [-0.00502667 -0.08076697  0.09320238  0.02455481  0.07158834 -0.03901932\n",
      "  0.31721198  0.03713218 -0.17675248  0.1409009  -0.16330912 -0.18227174\n",
      "  0.09981183 -0.45631789]\n",
      "New theta_0 : [-0.00501333 -0.08095944  0.09352042  0.02418555  0.07153589 -0.03990537\n",
      "  0.31668548  0.03711677 -0.17799908  0.14141536 -0.16328619 -0.18246617\n",
      "  0.09977409 -0.45656714]\n",
      "Training Error:  10.504144974845826\n",
      "====================================================================================================\n",
      "Iteration:  305\n",
      "Previous theta :  [-0.00501333 -0.08095944  0.09352042  0.02418555  0.07153589 -0.03990537\n",
      "  0.31668548  0.03711677 -0.17799908  0.14141536 -0.16328619 -0.18246617\n",
      "  0.09977409 -0.45656714]\n",
      "New theta_0 : [-0.00500011 -0.08115079  0.09383675  0.02381987  0.07148373 -0.04078586\n",
      "  0.31616426  0.03710255 -0.17923575  0.14192658 -0.1632644  -0.18265868\n",
      "  0.09973698 -0.45681273]\n",
      "Training Error:  10.501153509483007\n",
      "====================================================================================================\n",
      "Iteration:  306\n",
      "Previous theta :  [-0.00500011 -0.08115079  0.09383675  0.02381987  0.07148373 -0.04078586\n",
      "  0.31616426  0.03710255 -0.17923575  0.14192658 -0.1632644  -0.18265868\n",
      "  0.09973698 -0.45681273]\n",
      "New theta_0 : [-0.00498701 -0.08134101  0.09415134  0.02345775  0.07143184 -0.04166082\n",
      "  0.31564827  0.03708951 -0.18046258  0.14243457 -0.16324374 -0.18284932\n",
      "  0.09970051 -0.45705473]\n",
      "Training Error:  10.498207270395316\n",
      "====================================================================================================\n",
      "Iteration:  307\n",
      "Previous theta :  [-0.00498701 -0.08134101  0.09415134  0.02345775  0.07143184 -0.04166082\n",
      "  0.31564827  0.03708951 -0.18046258  0.14243457 -0.16324374 -0.18284932\n",
      "  0.09970051 -0.45705473]\n",
      "New theta_0 : [-0.00497403 -0.08153012  0.09446421  0.02309916  0.07138024 -0.04253027\n",
      "  0.31513746  0.03707761 -0.18167963  0.14293936 -0.16322418 -0.1830381\n",
      "  0.09966464 -0.45729318]\n",
      "Training Error:  10.495305549719825\n",
      "====================================================================================================\n",
      "Iteration:  308\n",
      "Previous theta :  [-0.00497403 -0.08153012  0.09446421  0.02309916  0.07138024 -0.04253027\n",
      "  0.31513746  0.03707761 -0.18167963  0.14293936 -0.16322418 -0.1830381\n",
      "  0.09966464 -0.45729318]\n",
      "New theta_0 : [-0.00496116 -0.08171811  0.09477535  0.02274406  0.07132891 -0.04339425\n",
      "  0.31463175  0.03706682 -0.182887    0.14344098 -0.16320574 -0.18322504\n",
      "  0.09962939 -0.45752813]\n",
      "Training Error:  10.492447651116459\n",
      "====================================================================================================\n",
      "Iteration:  309\n",
      "Previous theta :  [-0.00496116 -0.08171811  0.09477535  0.02274406  0.07132891 -0.04339425\n",
      "  0.31463175  0.03706682 -0.182887    0.14344098 -0.16320574 -0.18322504\n",
      "  0.09962939 -0.45752813]\n",
      "New theta_0 : [-0.00494842 -0.081905    0.09508476  0.02239243  0.07127785 -0.04425279\n",
      "  0.3141311   0.03705712 -0.18408476  0.14393945 -0.16318838 -0.18341019\n",
      "  0.09959472 -0.45775963]\n",
      "Training Error:  10.489632889569236\n",
      "====================================================================================================\n",
      "Iteration:  310\n",
      "Previous theta :  [-0.00494842 -0.081905    0.09508476  0.02239243  0.07127785 -0.04425279\n",
      "  0.3141311   0.03705712 -0.18408476  0.14393945 -0.16318838 -0.18341019\n",
      "  0.09959472 -0.45775963]\n",
      "New theta_0 : [-0.00493579 -0.08209078  0.09539245  0.02204425  0.07122707 -0.04510592\n",
      "  0.31363546  0.03704847 -0.185273    0.14443479 -0.1631721  -0.18359355\n",
      "  0.09956064 -0.45798772]\n",
      "Training Error:  10.486860591191261\n",
      "====================================================================================================\n",
      "Iteration:  311\n",
      "Previous theta :  [-0.00493579 -0.08209078  0.09539245  0.02204425  0.07122707 -0.04510592\n",
      "  0.31363546  0.03704847 -0.185273    0.14443479 -0.1631721  -0.18359355\n",
      "  0.09956064 -0.45798772]\n",
      "New theta_0 : [-0.00492327 -0.08227545  0.0956984   0.02169948  0.07117656 -0.04595369\n",
      "  0.31314476  0.03704086 -0.18645179  0.14492703 -0.16315689 -0.18377515\n",
      "  0.09952713 -0.45821247]\n",
      "Training Error:  10.484130093033384\n",
      "====================================================================================================\n",
      "Iteration:  312\n",
      "Previous theta :  [-0.00492327 -0.08227545  0.0956984   0.02169948  0.07117656 -0.04595369\n",
      "  0.31314476  0.03704086 -0.18645179  0.14492703 -0.16315689 -0.18377515\n",
      "  0.09952713 -0.45821247]\n",
      "New theta_0 : [-0.00491086 -0.08245903  0.09600263  0.0213581   0.07112632 -0.04679611\n",
      "  0.31265896  0.03703425 -0.1876212   0.14541619 -0.16314274 -0.18395502\n",
      "  0.09949419 -0.4584339 ]\n",
      "Training Error:  10.481440742896451\n",
      "====================================================================================================\n",
      "Iteration:  313\n",
      "Previous theta :  [-0.00491086 -0.08245903  0.09600263  0.0213581   0.07112632 -0.04679611\n",
      "  0.31265896  0.03703425 -0.1876212   0.14541619 -0.16314274 -0.18395502\n",
      "  0.09949419 -0.4584339 ]\n",
      "New theta_0 : [-0.00489857 -0.08264151  0.09630513  0.02102008  0.07107636 -0.04763322\n",
      "  0.312178    0.03702862 -0.18878132  0.1459023  -0.16312964 -0.18413317\n",
      "  0.0994618  -0.45865208]\n",
      "Training Error:  10.478791899147069\n",
      "====================================================================================================\n",
      "Iteration:  314\n",
      "Previous theta :  [-0.00489857 -0.08264151  0.09630513  0.02102008  0.07107636 -0.04763322\n",
      "  0.312178    0.03702862 -0.18878132  0.1459023  -0.16312964 -0.18413317\n",
      "  0.0994618  -0.45865208]\n",
      "New theta_0 : [-0.00488639 -0.08282291  0.09660591  0.02068539  0.07102666 -0.04846505\n",
      "  0.31170183  0.03702395 -0.18993223  0.14638539 -0.16311757 -0.18430963\n",
      "  0.09942995 -0.45886704]\n",
      "Training Error:  10.47618293053679\n",
      "====================================================================================================\n",
      "Iteration:  315\n",
      "Previous theta :  [-0.00488639 -0.08282291  0.09660591  0.02068539  0.07102666 -0.04846505\n",
      "  0.31170183  0.03702395 -0.18993223  0.14638539 -0.16311757 -0.18430963\n",
      "  0.09942995 -0.45886704]\n",
      "New theta_0 : [-0.00487431 -0.08300321  0.09690496  0.020354    0.07097722 -0.04929163\n",
      "  0.3112304   0.03702022 -0.19107399  0.14686546 -0.16310652 -0.18448443\n",
      "  0.09939863 -0.45907883]\n",
      "Training Error:  10.473613216024695\n",
      "====================================================================================================\n",
      "Iteration:  316\n",
      "Previous theta :  [-0.00487431 -0.08300321  0.09690496  0.020354    0.07097722 -0.04929163\n",
      "  0.3112304   0.03702022 -0.19107399  0.14686546 -0.16310652 -0.18448443\n",
      "  0.09939863 -0.45907883]\n",
      "New theta_0 : [-0.00486234 -0.08318243  0.09720229  0.02002589  0.07092806 -0.050113\n",
      "  0.31076365  0.03701739 -0.19220669  0.14734255 -0.16309649 -0.18465758\n",
      "  0.09936784 -0.45928749]\n",
      "Training Error:  10.471082144603246\n",
      "====================================================================================================\n",
      "Iteration:  317\n",
      "Previous theta :  [-0.00486234 -0.08318243  0.09720229  0.02002589  0.07092806 -0.050113\n",
      "  0.31076365  0.03701739 -0.19220669  0.14734255 -0.16309649 -0.18465758\n",
      "  0.09936784 -0.45928749]\n",
      "New theta_0 : [-0.00485048 -0.08336057  0.0974979   0.01970103  0.07087915 -0.05092919\n",
      "  0.31030154  0.03701544 -0.1933304   0.14781668 -0.16308747 -0.1848291\n",
      "  0.09933757 -0.45949307]\n",
      "Training Error:  10.46858911512737\n",
      "====================================================================================================\n",
      "Iteration:  318\n",
      "Previous theta :  [-0.00485048 -0.08336057  0.0974979   0.01970103  0.07087915 -0.05092919\n",
      "  0.31030154  0.03701544 -0.1933304   0.14781668 -0.16308747 -0.1848291\n",
      "  0.09933757 -0.45949307]\n",
      "New theta_0 : [-0.00483873 -0.08353764  0.09779179  0.0193794   0.07083051 -0.05174022\n",
      "  0.30984401  0.03701436 -0.19444519  0.14828787 -0.16307943 -0.18499902\n",
      "  0.0993078  -0.45969562]\n",
      "Training Error:  10.466133536146724\n",
      "====================================================================================================\n",
      "Iteration:  319\n",
      "Previous theta :  [-0.00483873 -0.08353764  0.09779179  0.0193794   0.07083051 -0.05174022\n",
      "  0.30984401  0.03701436 -0.19444519  0.14828787 -0.16307943 -0.18499902\n",
      "  0.0993078  -0.45969562]\n",
      "New theta_0 : [-0.00482708 -0.08371364  0.09808396  0.01906097  0.07078213 -0.05254613\n",
      "  0.30939101  0.03701412 -0.19555114  0.14875615 -0.16307238 -0.18516735\n",
      "  0.09927853 -0.45989516]\n",
      "Training Error:  10.463714825741015\n",
      "====================================================================================================\n",
      "Iteration:  320\n",
      "Previous theta :  [-0.00482708 -0.08371364  0.09808396  0.01906097  0.07078213 -0.05254613\n",
      "  0.30939101  0.03701412 -0.19555114  0.14875615 -0.16307238 -0.18516735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.09927853 -0.45989516]\n",
      "New theta_0 : [-0.00481553 -0.08388857  0.09837442  0.01874571  0.07073401 -0.05334695\n",
      "  0.3089425   0.03701469 -0.19664832  0.14922153 -0.16306631 -0.18533412\n",
      "  0.09924975 -0.46009175]\n",
      "Training Error:  10.461332411358391\n",
      "====================================================================================================\n",
      "Iteration:  321\n",
      "Previous theta :  [-0.00481553 -0.08388857  0.09837442  0.01874571  0.07073401 -0.05334695\n",
      "  0.3089425   0.03701469 -0.19664832  0.14922153 -0.16306631 -0.18533412\n",
      "  0.09924975 -0.46009175]\n",
      "New theta_0 : [-0.00480408 -0.08406244  0.09866316  0.01843359  0.07068615 -0.0541427\n",
      "  0.30849843  0.03701606 -0.19773679  0.14968405 -0.16306119 -0.18549935\n",
      "  0.09922144 -0.46028543]\n",
      "Training Error:  10.458985729656774\n",
      "====================================================================================================\n",
      "Iteration:  322\n",
      "Previous theta :  [-0.00480408 -0.08406244  0.09866316  0.01843359  0.07068615 -0.0541427\n",
      "  0.30849843  0.03701606 -0.19773679  0.14968405 -0.16306119 -0.18549935\n",
      "  0.09922144 -0.46028543]\n",
      "New theta_0 : [-0.00479274 -0.08423525  0.0989502   0.01812459  0.07063855 -0.05493343\n",
      "  0.30805875  0.03701821 -0.19881664  0.15014371 -0.16305703 -0.18566306\n",
      "  0.09919361 -0.46047623]\n",
      "Training Error:  10.456674226348113\n",
      "====================================================================================================\n",
      "Iteration:  323\n",
      "Previous theta :  [-0.00479274 -0.08423525  0.0989502   0.01812459  0.07063855 -0.05493343\n",
      "  0.30805875  0.03701821 -0.19881664  0.15014371 -0.16305703 -0.18566306\n",
      "  0.09919361 -0.46047623]\n",
      "New theta_0 : [-0.00478149 -0.084407    0.09923553  0.01781869  0.0705912  -0.05571915\n",
      "  0.30762342  0.03702111 -0.19988794  0.15060055 -0.16305381 -0.18582526\n",
      "  0.09916625 -0.4606642 ]\n",
      "Training Error:  10.454397356045469\n",
      "====================================================================================================\n",
      "Iteration:  324\n",
      "Previous theta :  [-0.00478149 -0.084407    0.09923553  0.01781869  0.0705912  -0.05571915\n",
      "  0.30762342  0.03702111 -0.19988794  0.15060055 -0.16305381 -0.18582526\n",
      "  0.09916625 -0.4606642 ]\n",
      "New theta_0 : [-0.00477035 -0.08457771  0.09951915  0.01751586  0.0705441  -0.0564999\n",
      "  0.30719237  0.03702475 -0.20095075  0.15105459 -0.16305152 -0.18598598\n",
      "  0.09913934 -0.46084938]\n",
      "Training Error:  10.452154582112904\n",
      "====================================================================================================\n",
      "Iteration:  325\n",
      "Previous theta :  [-0.00477035 -0.08457771  0.09951915  0.01751586  0.0705441  -0.0564999\n",
      "  0.30719237  0.03702475 -0.20095075  0.15105459 -0.16305152 -0.18598598\n",
      "  0.09913934 -0.46084938]\n",
      "New theta_0 : [-0.0047593  -0.08474737  0.09980108  0.01721607  0.07049726 -0.05727571\n",
      "  0.30676558  0.0370291  -0.20200513  0.15150584 -0.16305015 -0.18614523\n",
      "  0.09911288 -0.46103181]\n",
      "Training Error:  10.449945376518105\n",
      "====================================================================================================\n",
      "Iteration:  326\n",
      "Previous theta :  [-0.0047593  -0.08474737  0.09980108  0.01721607  0.07049726 -0.05727571\n",
      "  0.30676558  0.0370291  -0.20200513  0.15150584 -0.16305015 -0.18614523\n",
      "  0.09911288 -0.46103181]\n",
      "New theta_0 : [-0.00474834 -0.08491599  0.10008131  0.0169193   0.07045067 -0.05804661\n",
      "  0.30634299  0.03703414 -0.20305118  0.15195432 -0.16304969 -0.18630303\n",
      "  0.09908686 -0.46121152]\n",
      "Training Error:  10.447769219687665\n",
      "====================================================================================================\n",
      "Iteration:  327\n",
      "Previous theta :  [-0.00474834 -0.08491599  0.10008131  0.0169193   0.07045067 -0.05804661\n",
      "  0.30634299  0.03703414 -0.20305118  0.15195432 -0.16304969 -0.18630303\n",
      "  0.09908686 -0.46121152]\n",
      "New theta_0 : [-0.00473749 -0.08508358  0.10035985  0.01662553  0.07040433 -0.05881263\n",
      "  0.30592456  0.03703987 -0.20408894  0.15240007 -0.16305014 -0.18645941\n",
      "  0.09906127 -0.46138855]\n",
      "Training Error:  10.445625600364998\n",
      "====================================================================================================\n",
      "Iteration:  328\n",
      "Previous theta :  [-0.00473749 -0.08508358  0.10035985  0.01662553  0.07040433 -0.05881263\n",
      "  0.30592456  0.03703987 -0.20408894  0.15240007 -0.16305014 -0.18645941\n",
      "  0.09906127 -0.46138855]\n",
      "New theta_0 : [-0.00472673 -0.08525013  0.1006367   0.01633472  0.07035824 -0.0595738\n",
      "  0.30551025  0.03704625 -0.20511849  0.1528431  -0.16305148 -0.18661437\n",
      "  0.09903612 -0.46156294]\n",
      "Training Error:  10.44351401547084\n",
      "====================================================================================================\n",
      "Iteration:  329\n",
      "Previous theta :  [-0.00472673 -0.08525013  0.1006367   0.01633472  0.07035824 -0.0595738\n",
      "  0.30551025  0.03704625 -0.20511849  0.1528431  -0.16305148 -0.18661437\n",
      "  0.09903612 -0.46156294]\n",
      "New theta_0 : [-0.00471606 -0.08541566  0.10091187  0.01604686  0.0703124  -0.06033014\n",
      "  0.30510001  0.03705327 -0.20613989  0.15328342 -0.1630537  -0.18676794\n",
      "  0.09901138 -0.46173472]\n",
      "Training Error:  10.441433969966223\n",
      "====================================================================================================\n",
      "Iteration:  330\n",
      "Previous theta :  [-0.00471606 -0.08541566  0.10091187  0.01604686  0.0703124  -0.06033014\n",
      "  0.30510001  0.03705327 -0.20613989  0.15328342 -0.1630537  -0.18676794\n",
      "  0.09901138 -0.46173472]\n",
      "New theta_0 : [-0.00470548 -0.08558016  0.10118535  0.01576192  0.07026681 -0.06108169\n",
      "  0.30469379  0.03706091 -0.20715322  0.15372107 -0.1630568  -0.18692013\n",
      "  0.09898705 -0.46190394]\n",
      "Training Error:  10.43938497671797\n",
      "====================================================================================================\n",
      "Iteration:  331\n",
      "Previous theta :  [-0.00470548 -0.08558016  0.10118535  0.01576192  0.07026681 -0.06108169\n",
      "  0.30469379  0.03706091 -0.20715322  0.15372107 -0.1630568  -0.18692013\n",
      "  0.09898705 -0.46190394]\n",
      "New theta_0 : [-0.004695   -0.08574364  0.10145716  0.01547987  0.07022146 -0.06182847\n",
      "  0.30429156  0.03706915 -0.20815853  0.15415606 -0.16306076 -0.18707097\n",
      "  0.09896312 -0.46207063]\n",
      "Training Error:  10.437366556366573\n",
      "====================================================================================================\n",
      "Iteration:  332\n",
      "Previous theta :  [-0.004695   -0.08574364  0.10145716  0.01547987  0.07022146 -0.06182847\n",
      "  0.30429156  0.03706915 -0.20815853  0.15415606 -0.16306076 -0.18707097\n",
      "  0.09896312 -0.46207063]\n",
      "New theta_0 : [-0.0046846  -0.08590611  0.1017273   0.0152007   0.07017635 -0.06257052\n",
      "  0.30389326  0.03707799 -0.2091559   0.15458841 -0.16306557 -0.18722046\n",
      "  0.0989396  -0.46223483]\n",
      "Training Error:  10.435378237196442\n",
      "====================================================================================================\n",
      "Iteration:  333\n",
      "Previous theta :  [-0.0046846  -0.08590611  0.1017273   0.0152007   0.07017635 -0.06257052\n",
      "  0.30389326  0.03707799 -0.2091559   0.15458841 -0.16306557 -0.18722046\n",
      "  0.0989396  -0.46223483]\n",
      "New theta_0 : [-0.0046743  -0.08606757  0.10199577  0.01492437  0.07013149 -0.06330786\n",
      "  0.30349887  0.03708739 -0.21014539  0.15501814 -0.16307123 -0.18736863\n",
      "  0.09891647 -0.46239656]\n",
      "Training Error:  10.433419555008493\n",
      "====================================================================================================\n",
      "Iteration:  334\n",
      "Previous theta :  [-0.0046743  -0.08606757  0.10199577  0.01492437  0.07013149 -0.06330786\n",
      "  0.30349887  0.03708739 -0.21014539  0.15501814 -0.16307123 -0.18736863\n",
      "  0.09891647 -0.46239656]\n",
      "New theta_0 : [-0.00466408 -0.08622803  0.10226258  0.01465086  0.07008686 -0.06404052\n",
      "  0.30310834  0.03709735 -0.21112705  0.15544527 -0.16307773 -0.18751549\n",
      "  0.09889372 -0.46255586]\n",
      "Training Error:  10.431490052994999\n",
      "====================================================================================================\n",
      "Iteration:  335\n",
      "Previous theta :  [-0.00466408 -0.08622803  0.10226258  0.01465086  0.07008686 -0.06404052\n",
      "  0.30310834  0.03709735 -0.21112705  0.15544527 -0.16307773 -0.18751549\n",
      "  0.09889372 -0.46255586]\n",
      "New theta_0 : [-0.00465396 -0.08638748  0.10252773  0.01438016  0.07004248 -0.06476852\n",
      "  0.30272162  0.03710785 -0.21210097  0.15586983 -0.16308506 -0.18766106\n",
      "  0.09887136 -0.46271277]\n",
      "Training Error:  10.429589281616673\n",
      "====================================================================================================\n",
      "Iteration:  336\n",
      "Previous theta :  [-0.00465396 -0.08638748  0.10252773  0.01438016  0.07004248 -0.06476852\n",
      "  0.30272162  0.03710785 -0.21210097  0.15586983 -0.16308506 -0.18766106\n",
      "  0.09887136 -0.46271277]\n",
      "New theta_0 : [-0.00464392 -0.08654594  0.10279123  0.01411223  0.06999834 -0.06549191\n",
      "  0.30233868  0.03711886 -0.21306719  0.15629182 -0.1630932  -0.18780535\n",
      "  0.09884936 -0.46286733]\n",
      "Training Error:  10.42771679848195\n",
      "====================================================================================================\n",
      "Iteration:  337\n",
      "Previous theta :  [-0.00464392 -0.08654594  0.10279123  0.01411223  0.06999834 -0.06549191\n",
      "  0.30233868  0.03711886 -0.21306719  0.15629182 -0.1630932  -0.18780535\n",
      "  0.09884936 -0.46286733]\n",
      "New theta_0 : [-0.00463396 -0.08670341  0.10305308  0.01384706  0.06995443 -0.0662107\n",
      "  0.30195948  0.03713039 -0.21402579  0.15671128 -0.16310215 -0.18794838\n",
      "  0.09882773 -0.46301955]\n",
      "Training Error:  10.42587216822839\n",
      "====================================================================================================\n",
      "Iteration:  338\n",
      "Previous theta :  [-0.00463396 -0.08670341  0.10305308  0.01384706  0.06995443 -0.0662107\n",
      "  0.30195948  0.03713039 -0.21402579  0.15671128 -0.16310215 -0.18794838\n",
      "  0.09882773 -0.46301955]\n",
      "New theta_0 : [-0.00462409 -0.0868599   0.10331329  0.01358462  0.06991076 -0.06692492\n",
      "  0.30158397  0.03714241 -0.21497682  0.15712821 -0.16311191 -0.18809016\n",
      "  0.09880647 -0.46316948]\n",
      "Training Error:  10.424054962406208\n",
      "====================================================================================================\n",
      "Iteration:  339\n",
      "Previous theta :  [-0.00462409 -0.0868599   0.10331329  0.01358462  0.06991076 -0.06692492\n",
      "  0.30158397  0.03714241 -0.21497682  0.15712821 -0.16311191 -0.18809016\n",
      "  0.09880647 -0.46316948]\n",
      "New theta_0 : [-0.0046143  -0.0870154   0.10357187  0.01332488  0.06986733 -0.0676346\n",
      "  0.30121212  0.0371549  -0.21592034  0.15754264 -0.16312245 -0.18823071\n",
      "  0.09878556 -0.46331715]\n",
      "Training Error:  10.422264759363848\n",
      "====================================================================================================\n",
      "Iteration:  340\n",
      "Previous theta :  [-0.0046143  -0.0870154   0.10357187  0.01332488  0.06986733 -0.0676346\n",
      "  0.30121212  0.0371549  -0.21592034  0.15754264 -0.16312245 -0.18823071\n",
      "  0.09878556 -0.46331715]\n",
      "New theta_0 : [-0.0046046  -0.08716992  0.10382881  0.01306783  0.06982413 -0.06833977\n",
      "  0.30084389  0.03716786 -0.21685642  0.15795459 -0.16313378 -0.18837005\n",
      "  0.098765   -0.46346259]\n",
      "Training Error:  10.420501144135585\n",
      "====================================================================================================\n",
      "Iteration:  341\n",
      "Previous theta :  [-0.0046046  -0.08716992  0.10382881  0.01306783  0.06982413 -0.06833977\n",
      "  0.30084389  0.03716786 -0.21685642  0.15795459 -0.16313378 -0.18837005\n",
      "  0.098765   -0.46346259]\n",
      "New theta_0 : [-0.00459498 -0.08732347  0.10408412  0.01281344  0.06978116 -0.06904045\n",
      "  0.30047925  0.03718127 -0.21778512  0.15836408 -0.16314589 -0.18850818\n",
      "  0.09874478 -0.46360583]\n",
      "Training Error:  10.418763708331099\n",
      "====================================================================================================\n",
      "Iteration:  342\n",
      "Previous theta :  [-0.00459498 -0.08732347  0.10408412  0.01281344  0.06978116 -0.06904045\n",
      "  0.30047925  0.03718127 -0.21778512  0.15836408 -0.16314589 -0.18850818\n",
      "  0.09874478 -0.46360583]\n",
      "New theta_0 : [-0.00458544 -0.08747606  0.10433782  0.01256169  0.06973842 -0.06973668\n",
      "  0.30011814  0.03719511 -0.2187065   0.15877111 -0.16315876 -0.18864513\n",
      "  0.0987249  -0.4637469 ]\n",
      "Training Error:  10.417052050027008\n",
      "====================================================================================================\n",
      "Iteration:  343\n",
      "Previous theta :  [-0.00458544 -0.08747606  0.10433782  0.01256169  0.06973842 -0.06973668\n",
      "  0.30011814  0.03719511 -0.2187065   0.15877111 -0.16315876 -0.18864513\n",
      "  0.0987249  -0.4637469 ]\n",
      "New theta_0 : [-0.00457598 -0.08762768  0.1045899   0.01231256  0.06969592 -0.07042848\n",
      "  0.29976054  0.03720938 -0.21962061  0.15917573 -0.16317239 -0.18878091\n",
      "  0.09870535 -0.46388583]\n",
      "Training Error:  10.415365773660286\n",
      "====================================================================================================\n",
      "Iteration:  344\n",
      "Previous theta :  [-0.00457598 -0.08762768  0.1045899   0.01231256  0.06969592 -0.07042848\n",
      "  0.29976054  0.03720938 -0.21962061  0.15917573 -0.16317239 -0.18878091\n",
      "  0.09870535 -0.46388583]\n",
      "New theta_0 : [-0.0045666  -0.08777834  0.10484038  0.01206602  0.06965364 -0.07111587\n",
      "  0.29940641  0.03722405 -0.22052752  0.15957793 -0.16318677 -0.18891552\n",
      "  0.09868613 -0.46402266]\n",
      "Training Error:  10.413704489923568\n",
      "====================================================================================================\n",
      "Iteration:  345\n",
      "Previous theta :  [-0.0045666  -0.08777834  0.10484038  0.01206602  0.06965364 -0.07111587\n",
      "  0.29940641  0.03722405 -0.22052752  0.15957793 -0.16318677 -0.18891552\n",
      "  0.09868613 -0.46402266]\n",
      "New theta_0 : [-0.0045573  -0.08792805  0.10508925  0.01182205  0.06961159 -0.07179888\n",
      "  0.29905571  0.03723912 -0.22142728  0.15997774 -0.16320188 -0.18904899\n",
      "  0.09866723 -0.4641574 ]\n",
      "Training Error:  10.412067815662274\n",
      "====================================================================================================\n",
      "Iteration:  346\n",
      "Previous theta :  [-0.0045573  -0.08792805  0.10508925  0.01182205  0.06961159 -0.07179888\n",
      "  0.29905571  0.03723912 -0.22142728  0.15997774 -0.16320188 -0.18904899\n",
      "  0.09866723 -0.4641574 ]\n",
      "New theta_0 : [-0.00454808 -0.08807682  0.10533653  0.01158064  0.06956976 -0.07247755\n",
      "  0.2987084   0.03725457 -0.22231995  0.16037518 -0.16321774 -0.18918134\n",
      "  0.09864865 -0.46429009]\n",
      "Training Error:  10.410455373773535\n",
      "====================================================================================================\n",
      "Iteration:  347\n",
      "Previous theta :  [-0.00454808 -0.08807682  0.10533653  0.01158064  0.06956976 -0.07247755\n",
      "  0.2987084   0.03725457 -0.22231995  0.16037518 -0.16321774 -0.18918134\n",
      "  0.09864865 -0.46429009]\n",
      "New theta_0 : [-0.00453894 -0.08822463  0.10558221  0.01134175  0.06952816 -0.07315189\n",
      "  0.29836446  0.03727039 -0.2232056   0.16077026 -0.16323431 -0.18931256\n",
      "  0.09863038 -0.46442077]\n",
      "Training Error:  10.408866793106883\n",
      "====================================================================================================\n",
      "Iteration:  348\n",
      "Previous theta :  [-0.00453894 -0.08822463  0.10558221  0.01134175  0.06952816 -0.07315189\n",
      "  0.29836446  0.03727039 -0.2232056   0.16077026 -0.16323431 -0.18931256\n",
      "  0.09863038 -0.46442077]\n",
      "New theta_0 : [-0.00452987 -0.08837151  0.10582631  0.01110538  0.06948679 -0.07382194\n",
      "  0.29802384  0.03728657 -0.22408427  0.161163   -0.16325161 -0.18944268\n",
      "  0.09861242 -0.46454944]\n",
      "Training Error:  10.407301708366663\n",
      "====================================================================================================\n",
      "Iteration:  349\n",
      "Previous theta :  [-0.00452987 -0.08837151  0.10582631  0.01110538  0.06948679 -0.07382194\n",
      "  0.29802384  0.03728657 -0.22408427  0.161163   -0.16325161 -0.18944268\n",
      "  0.09861242 -0.46454944]\n",
      "New theta_0 : [-0.00452088 -0.08851746  0.10606884  0.01087149  0.06944564 -0.07448771\n",
      "  0.29768651  0.0373031  -0.22495602  0.16155343 -0.16326961 -0.18957171\n",
      "  0.09859476 -0.46467616]\n",
      "Training Error:  10.405759760016155\n",
      "====================================================================================================\n",
      "Iteration:  350\n",
      "Previous theta :  [-0.00452088 -0.08851746  0.10606884  0.01087149  0.06944564 -0.07448771\n",
      "  0.29768651  0.0373031  -0.22495602  0.16155343 -0.16326961 -0.18957171\n",
      "  0.09859476 -0.46467616]\n",
      "New theta_0 : [-0.00451196 -0.08866247  0.10630979  0.01064006  0.06940471 -0.07514924\n",
      "  0.29735244  0.03731996 -0.22582091  0.16194155 -0.16328831 -0.18969966\n",
      "  0.0985774  -0.46480093]\n",
      "Training Error:  10.404240594183335\n",
      "====================================================================================================\n",
      "Iteration:  351\n",
      "Previous theta :  [-0.00451196 -0.08866247  0.10630979  0.01064006  0.06940471 -0.07514924\n",
      "  0.29735244  0.03731996 -0.22582091  0.16194155 -0.16328831 -0.18969966\n",
      "  0.0985774  -0.46480093]\n",
      "New theta_0 : [-0.00450311 -0.08880656  0.10654918  0.01041108  0.069364   -0.07580654\n",
      "  0.29702159  0.03733715 -0.226679    0.16232738 -0.16330771 -0.18982654\n",
      "  0.09856033 -0.4649238 ]\n",
      "Training Error:  10.402743862568295\n",
      "====================================================================================================\n",
      "Iteration:  352\n",
      "Previous theta :  [-0.00450311 -0.08880656  0.10654918  0.01041108  0.069364   -0.07580654\n",
      "  0.29702159  0.03733715 -0.226679    0.16232738 -0.16330771 -0.18982654\n",
      "  0.09856033 -0.4649238 ]\n",
      "New theta_0 : [-0.00449434 -0.08894973  0.106787    0.01018452  0.06932351 -0.07645966\n",
      "  0.29669393  0.03735464 -0.22753034  0.16271095 -0.16332779 -0.18995237\n",
      "  0.09854355 -0.46504477]\n",
      "Training Error:  10.401269222352257\n",
      "====================================================================================================\n",
      "Iteration:  353\n",
      "Previous theta :  [-0.00449434 -0.08894973  0.106787    0.01018452  0.06932351 -0.07645966\n",
      "  0.29669393  0.03735464 -0.22753034  0.16271095 -0.16332779 -0.18995237\n",
      "  0.09854355 -0.46504477]\n",
      "New theta_0 : [-0.00448565 -0.08909199  0.10702328  0.00996037  0.06928323 -0.0771086\n",
      "  0.29636942  0.03737244 -0.22837498  0.16309226 -0.16334855 -0.19007716\n",
      "  0.09852705 -0.4651639 ]\n",
      "Training Error:  10.399816336108138\n",
      "====================================================================================================\n",
      "Iteration:  354\n",
      "Previous theta :  [-0.00448565 -0.08909199  0.10702328  0.00996037  0.06928323 -0.0771086\n",
      "  0.29636942  0.03737244 -0.22837498  0.16309226 -0.16334855 -0.19007716\n",
      "  0.09852705 -0.4651639 ]\n",
      "New theta_0 : [-0.00447702 -0.08923333  0.10725801  0.0097386   0.06924318 -0.07775341\n",
      "  0.29604804  0.03739053 -0.22921298  0.16347134 -0.16336998 -0.19020092\n",
      "  0.09851083 -0.46528118]\n",
      "Training Error:  10.39838487171268\n",
      "====================================================================================================\n",
      "Iteration:  355\n",
      "Previous theta :  [-0.00447702 -0.08923333  0.10725801  0.0097386   0.06924318 -0.07775341\n",
      "  0.29604804  0.03739053 -0.22921298  0.16347134 -0.16336998 -0.19020092\n",
      "  0.09851083 -0.46528118]\n",
      "New theta_0 : [-0.00446846 -0.08937377  0.10749121  0.00951919  0.06920334 -0.0783941\n",
      "  0.29572974  0.0374089  -0.23004439  0.1638482  -0.16339207 -0.19032366\n",
      "  0.09849489 -0.46539667]\n",
      "Training Error:  10.396974502260088\n",
      "====================================================================================================\n",
      "Iteration:  356\n",
      "Previous theta :  [-0.00446846 -0.08937377  0.10749121  0.00951919  0.06920334 -0.0783941\n",
      "  0.29572974  0.0374089  -0.23004439  0.1638482  -0.16339207 -0.19032366\n",
      "  0.09849489 -0.46539667]\n",
      "New theta_0 : [-0.00445998 -0.08951331  0.10772287  0.00930212  0.06916371 -0.07903069\n",
      "  0.2954145   0.03742754 -0.23086927  0.16422286 -0.16341482 -0.1904454\n",
      "  0.09847921 -0.46551037]\n",
      "Training Error:  10.395584905977142\n",
      "====================================================================================================\n",
      "Iteration:  357\n",
      "Previous theta :  [-0.00445998 -0.08951331  0.10772287  0.00930212  0.06916371 -0.07903069\n",
      "  0.2954145   0.03742754 -0.23086927  0.16422286 -0.16341482 -0.1904454\n",
      "  0.09847921 -0.46551037]\n",
      "New theta_0 : [-0.00445156 -0.08965195  0.107953    0.00908737  0.0691243  -0.07966322\n",
      "  0.29510229  0.03744645 -0.23168766  0.16459533 -0.16343822 -0.19056614\n",
      "  0.09846381 -0.46562231]\n",
      "Training Error:  10.394215766139771\n",
      "====================================================================================================\n",
      "Iteration:  358\n",
      "Previous theta :  [-0.00445156 -0.08965195  0.107953    0.00908737  0.0691243  -0.07966322\n",
      "  0.29510229  0.03744645 -0.23168766  0.16459533 -0.16343822 -0.19056614\n",
      "  0.09846381 -0.46562231]\n",
      "New theta_0 : [-0.00444322 -0.0897897   0.10818162  0.00887492  0.0690851  -0.08029171\n",
      "  0.29479306  0.0374656  -0.23249963  0.16496563 -0.16346225 -0.1906859\n",
      "  0.09844866 -0.46573252]\n",
      "Training Error:  10.392866770991061\n",
      "====================================================================================================\n",
      "Iteration:  359\n",
      "Previous theta :  [-0.00444322 -0.0897897   0.10818162  0.00887492  0.0690851  -0.08029171\n",
      "  0.29479306  0.0374656  -0.23249963  0.16496563 -0.16346225 -0.1906859\n",
      "  0.09844866 -0.46573252]\n",
      "New theta_0 : [-0.00443494 -0.08992656  0.10840873  0.00866476  0.06904611 -0.08091618\n",
      "  0.29448681  0.03748499 -0.23330522  0.16533378 -0.16348692 -0.19080469\n",
      "  0.09843378 -0.46584103]\n",
      "Training Error:  10.39153761366066\n",
      "====================================================================================================\n",
      "Iteration:  360\n",
      "Previous theta :  [-0.00443494 -0.08992656  0.10840873  0.00866476  0.06904611 -0.08091618\n",
      "  0.29448681  0.03748499 -0.23330522  0.16533378 -0.16348692 -0.19080469\n",
      "  0.09843378 -0.46584103]\n",
      "New theta_0 : [-0.00442673 -0.09006254  0.10863433  0.00845685  0.06900733 -0.08153665\n",
      "  0.29418348  0.03750462 -0.23410448  0.16569979 -0.16351221 -0.19092252\n",
      "  0.09841914 -0.46594785]\n",
      "Training Error:  10.39022799208556\n",
      "====================================================================================================\n",
      "Iteration:  361\n",
      "Previous theta :  [-0.00442673 -0.09006254  0.10863433  0.00845685  0.06900733 -0.08153665\n",
      "  0.29418348  0.03750462 -0.23410448  0.16569979 -0.16351221 -0.19092252\n",
      "  0.09841914 -0.46594785]\n",
      "New theta_0 : [-0.00441859 -0.09019765  0.10885844  0.00825119  0.06896876 -0.08215316\n",
      "  0.29388306  0.03752447 -0.23489747  0.16606368 -0.16353812 -0.19103939\n",
      "  0.09840476 -0.466053  ]\n",
      "Training Error:  10.388937608932228\n",
      "====================================================================================================\n",
      "Iteration:  362\n",
      "Previous theta :  [-0.00441859 -0.09019765  0.10885844  0.00825119  0.06896876 -0.08215316\n",
      "  0.29388306  0.03752447 -0.23489747  0.16606368 -0.16353812 -0.19103939\n",
      "  0.09840476 -0.466053  ]\n",
      "New theta_0 : [-0.00441051 -0.09033188  0.10908105  0.00804775  0.0689304  -0.08276573\n",
      "  0.29358551  0.03754453 -0.23568423  0.16642546 -0.16356465 -0.19115533\n",
      "  0.09839063 -0.46615653]\n",
      "Training Error:  10.387666171520065\n",
      "====================================================================================================\n",
      "Iteration:  363\n",
      "Previous theta :  [-0.00441051 -0.09033188  0.10908105  0.00804775  0.0689304  -0.08276573\n",
      "  0.29358551  0.03754453 -0.23568423  0.16642546 -0.16356465 -0.19115533\n",
      "  0.09839063 -0.46615653]\n",
      "New theta_0 : [-0.0044025  -0.09046524  0.10930218  0.00784651  0.06889224 -0.08337437\n",
      "  0.2932908   0.0375648  -0.23646482  0.16678515 -0.16359177 -0.19127034\n",
      "  0.09837673 -0.46625843]\n",
      "Training Error:  10.386413391746183\n",
      "====================================================================================================\n",
      "Iteration:  364\n",
      "Previous theta :  [-0.0044025  -0.09046524  0.10930218  0.00784651  0.06889224 -0.08337437\n",
      "  0.2932908   0.0375648  -0.23646482  0.16678515 -0.16359177 -0.19127034\n",
      "  0.09837673 -0.46625843]\n",
      "New theta_0 : [-0.00439455 -0.09059775  0.10952184  0.00764746  0.06885429 -0.08397912\n",
      "  0.2929989   0.03758526 -0.23723928  0.16714276 -0.1636195  -0.19138443\n",
      "  0.09836308 -0.46635875]\n",
      "Training Error:  10.38517898601142\n",
      "====================================================================================================\n",
      "Iteration:  365\n",
      "Previous theta :  [-0.00439455 -0.09059775  0.10952184  0.00764746  0.06885429 -0.08397912\n",
      "  0.2929989   0.03758526 -0.23723928  0.16714276 -0.1636195  -0.19138443\n",
      "  0.09836308 -0.46635875]\n",
      "New theta_0 : [-0.00438666 -0.09072939  0.10974002  0.00745058  0.06881654 -0.08458\n",
      "  0.29270978  0.03760592 -0.23800767  0.16749832 -0.16364782 -0.19149762\n",
      "  0.09834966 -0.4664575 ]\n",
      "Training Error:  10.38396267514765\n",
      "====================================================================================================\n",
      "Iteration:  366\n",
      "Previous theta :  [-0.00438666 -0.09072939  0.10974002  0.00745058  0.06881654 -0.08458\n",
      "  0.29270978  0.03760592 -0.23800767  0.16749832 -0.16364782 -0.19149762\n",
      "  0.09834966 -0.4664575 ]\n",
      "New theta_0 : [-0.00437884 -0.09086018  0.10995675  0.00725583  0.068779   -0.08517703\n",
      "  0.29242342  0.03762675 -0.23877003  0.16785182 -0.16367672 -0.1916099\n",
      "  0.09833647 -0.46655469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.382764184346305\n",
      "====================================================================================================\n",
      "Iteration:  367\n",
      "Previous theta :  [-0.00437884 -0.09086018  0.10995675  0.00725583  0.068779   -0.08517703\n",
      "  0.29242342  0.03762675 -0.23877003  0.16785182 -0.16367672 -0.1916099\n",
      "  0.09833647 -0.46655469]\n",
      "New theta_0 : [-0.00437109 -0.09099012  0.11017202  0.00706322  0.06874165 -0.08577024\n",
      "  0.29213979  0.03764776 -0.23952642  0.1682033  -0.16370619 -0.1917213\n",
      "  0.09832352 -0.46665037]\n",
      "Training Error:  10.3815832430881\n",
      "====================================================================================================\n",
      "Iteration:  368\n",
      "Previous theta :  [-0.00437109 -0.09099012  0.11017202  0.00706322  0.06874165 -0.08577024\n",
      "  0.29213979  0.03764776 -0.23952642  0.1682033  -0.16370619 -0.1917213\n",
      "  0.09832352 -0.46665037]\n",
      "New theta_0 : [-0.00436339 -0.09111922  0.11038584  0.00687272  0.06870451 -0.08635965\n",
      "  0.29185886  0.03766893 -0.24027687  0.16855276 -0.16373624 -0.19183182\n",
      "  0.09831078 -0.46674453]\n",
      "Training Error:  10.380419585073968\n",
      "====================================================================================================\n",
      "Iteration:  369\n",
      "Previous theta :  [-0.00436339 -0.09111922  0.11038584  0.00687272  0.06870451 -0.08635965\n",
      "  0.29185886  0.03766893 -0.24027687  0.16855276 -0.16373624 -0.19183182\n",
      "  0.09831078 -0.46674453]\n",
      "New theta_0 : [-0.00435576 -0.09124748  0.11059822  0.0066843   0.06866757 -0.08694528\n",
      "  0.29158059  0.03769026 -0.24102144  0.16890022 -0.16376685 -0.19194147\n",
      "  0.09829827 -0.46683722]\n",
      "Training Error:  10.379272948157134\n",
      "====================================================================================================\n",
      "Iteration:  370\n",
      "Previous theta :  [-0.00435576 -0.09124748  0.11059822  0.0066843   0.06866757 -0.08694528\n",
      "  0.29158059  0.03769026 -0.24102144  0.16890022 -0.16376685 -0.19194147\n",
      "  0.09829827 -0.46683722]\n",
      "New theta_0 : [-0.00434818 -0.09137491  0.11080917  0.00649796  0.06863083 -0.08752716\n",
      "  0.29130497  0.03771174 -0.24176018  0.1692457  -0.16379802 -0.19205026\n",
      "  0.09828597 -0.46692844]\n",
      "Training Error:  10.378143074276338\n",
      "====================================================================================================\n",
      "Iteration:  371\n",
      "Previous theta :  [-0.00434818 -0.09137491  0.11080917  0.00649796  0.06863083 -0.08752716\n",
      "  0.29130497  0.03771174 -0.24176018  0.1692457  -0.16379802 -0.19205026\n",
      "  0.09828597 -0.46692844]\n",
      "New theta_0 : [-0.00434067 -0.0915015   0.11101869  0.00631368  0.06859428 -0.0881053\n",
      "  0.29103197  0.03773337 -0.24249313  0.1695892  -0.16382974 -0.19215821\n",
      "  0.0982739  -0.46701822]\n",
      "Training Error:  10.377029709390218\n",
      "====================================================================================================\n",
      "Iteration:  372\n",
      "Previous theta :  [-0.00434067 -0.0915015   0.11101869  0.00631368  0.06859428 -0.0881053\n",
      "  0.29103197  0.03773337 -0.24249313  0.1695892  -0.16382974 -0.19215821\n",
      "  0.0982739  -0.46701822]\n",
      "New theta_0 : [-0.00433322 -0.09162728  0.1112268   0.00613142  0.06855794 -0.08867974\n",
      "  0.29076155  0.03775513 -0.24322034  0.16993074 -0.163862   -0.19226531\n",
      "  0.09826203 -0.46710657]\n",
      "Training Error:  10.375932603412727\n",
      "====================================================================================================\n",
      "Iteration:  373\n",
      "Previous theta :  [-0.00433322 -0.09162728  0.1112268   0.00613142  0.06855794 -0.08867974\n",
      "  0.29076155  0.03775513 -0.24322034  0.16993074 -0.163862   -0.19226531\n",
      "  0.09826203 -0.46710657]\n",
      "New theta_0 : [-0.00432583 -0.09175223  0.11143349  0.00595119  0.06852178 -0.0892505\n",
      "  0.2904937   0.03777702 -0.24394185  0.17027034 -0.16389481 -0.19237158\n",
      "  0.09825037 -0.46719352]\n",
      "Training Error:  10.374851510149695\n",
      "====================================================================================================\n",
      "Iteration:  374\n",
      "Previous theta :  [-0.00432583 -0.09175223  0.11143349  0.00595119  0.06852178 -0.0892505\n",
      "  0.2904937   0.03777702 -0.24394185  0.17027034 -0.16389481 -0.19237158\n",
      "  0.09825037 -0.46719352]\n",
      "New theta_0 : [-0.00431849 -0.09187636  0.11163878  0.00577296  0.06848582 -0.08981759\n",
      "  0.29022838  0.03779903 -0.24465771  0.17060801 -0.16392814 -0.19247703\n",
      "  0.09823891 -0.4672791 ]\n",
      "Training Error:  10.373786187236435\n",
      "====================================================================================================\n",
      "Iteration:  375\n",
      "Previous theta :  [-0.00431849 -0.09187636  0.11163878  0.00577296  0.06848582 -0.08981759\n",
      "  0.29022838  0.03779903 -0.24465771  0.17060801 -0.16392814 -0.19247703\n",
      "  0.09823891 -0.4672791 ]\n",
      "New theta_0 : [-0.00431121 -0.09199969  0.11184268  0.00559671  0.06845006 -0.09038105\n",
      "  0.28996557  0.03782115 -0.24536797  0.17094377 -0.163962   -0.19258166\n",
      "  0.09822766 -0.4673633 ]\n",
      "Training Error:  10.37273639607637\n",
      "====================================================================================================\n",
      "Iteration:  376\n",
      "Previous theta :  [-0.00431121 -0.09199969  0.11184268  0.00559671  0.06845006 -0.09038105\n",
      "  0.28996557  0.03782115 -0.24536797  0.17094377 -0.163962   -0.19258166\n",
      "  0.09822766 -0.4673633 ]\n",
      "New theta_0 : [-0.00430399 -0.09212221  0.11204518  0.00542243  0.06841448 -0.09094089\n",
      "  0.28970525  0.03784339 -0.24607267  0.17127762 -0.16399637 -0.1926855\n",
      "  0.09821661 -0.46744617]\n",
      "Training Error:  10.371701901780723\n",
      "====================================================================================================\n",
      "Iteration:  377\n",
      "Previous theta :  [-0.00430399 -0.09212221  0.11204518  0.00542243  0.06841448 -0.09094089\n",
      "  0.28970525  0.03784339 -0.24607267  0.17127762 -0.16399637 -0.1926855\n",
      "  0.09821661 -0.46744617]\n",
      "New theta_0 : [-0.00429683 -0.09224392  0.11224631  0.00525009  0.0683791  -0.09149713\n",
      "  0.28944739  0.03786573 -0.24677185  0.17160959 -0.16403127 -0.19278853\n",
      "  0.09820575 -0.4675277 ]\n",
      "Training Error:  10.37068247310919\n",
      "====================================================================================================\n",
      "Iteration:  378\n",
      "Previous theta :  [-0.00429683 -0.09224392  0.11224631  0.00525009  0.0683791  -0.09149713\n",
      "  0.28944739  0.03786573 -0.24677185  0.17160959 -0.16403127 -0.19278853\n",
      "  0.09820575 -0.4675277 ]\n",
      "New theta_0 : [-0.00428972 -0.09236484  0.11244606  0.00507968  0.06834391 -0.09204981\n",
      "  0.28919196  0.03788817 -0.24746556  0.17193968 -0.16406666 -0.19289078\n",
      "  0.09819508 -0.46760793]\n",
      "Training Error:  10.369677882411617\n",
      "====================================================================================================\n",
      "Iteration:  379\n",
      "Previous theta :  [-0.00428972 -0.09236484  0.11244606  0.00507968  0.06834391 -0.09204981\n",
      "  0.28919196  0.03788817 -0.24746556  0.17193968 -0.16406666 -0.19289078\n",
      "  0.09819508 -0.46760793]\n",
      "New theta_0 : [-0.00428267 -0.09248497  0.11264444  0.00491119  0.06830891 -0.09259893\n",
      "  0.28893895  0.03791069 -0.24815385  0.17226791 -0.16410256 -0.19299224\n",
      "  0.09818461 -0.46768688]\n",
      "Training Error:  10.368687905570624\n",
      "====================================================================================================\n",
      "Iteration:  380\n",
      "Previous theta :  [-0.00428267 -0.09248497  0.11264444  0.00491119  0.06830891 -0.09259893\n",
      "  0.28893895  0.03791069 -0.24815385  0.17226791 -0.16410256 -0.19299224\n",
      "  0.09818461 -0.46768688]\n",
      "New theta_0 : [-0.00427568 -0.09260431  0.11284146  0.0047446   0.06827409 -0.09314453\n",
      "  0.28868831  0.03793331 -0.24883675  0.1725943  -0.16413895 -0.19309294\n",
      "  0.09817432 -0.46776455]\n",
      "Training Error:  10.367712321945227\n",
      "====================================================================================================\n",
      "Iteration:  381\n",
      "Previous theta :  [-0.00427568 -0.09260431  0.11284146  0.0047446   0.06827409 -0.09314453\n",
      "  0.28868831  0.03793331 -0.24883675  0.1725943  -0.16413895 -0.19309294\n",
      "  0.09817432 -0.46776455]\n",
      "New theta_0 : [-0.00426873 -0.09272287  0.11303714  0.00457988  0.06823946 -0.09368662\n",
      "  0.28844004  0.037956   -0.24951431  0.17291885 -0.16417584 -0.19319287\n",
      "  0.09816422 -0.46784097]\n",
      "Training Error:  10.366750914315347\n",
      "====================================================================================================\n",
      "Iteration:  382\n",
      "Previous theta :  [-0.00426873 -0.09272287  0.11303714  0.00457988  0.06823946 -0.09368662\n",
      "  0.28844004  0.037956   -0.24951431  0.17291885 -0.16417584 -0.19319287\n",
      "  0.09816422 -0.46784097]\n",
      "New theta_0 : [-0.00426185 -0.09284065  0.11323147  0.00441703  0.06820502 -0.09422522\n",
      "  0.2881941   0.03797877 -0.25018658  0.17324158 -0.1642132  -0.19329205\n",
      "  0.0981543  -0.46791615]\n",
      "Training Error:  10.365803468827277\n",
      "====================================================================================================\n",
      "Iteration:  383\n",
      "Previous theta :  [-0.00426185 -0.09284065  0.11323147  0.00441703  0.06820502 -0.09422522\n",
      "  0.2881941   0.03797877 -0.25018658  0.17324158 -0.1642132  -0.19329205\n",
      "  0.0981543  -0.46791615]\n",
      "New theta_0 : [-0.00425501 -0.09295766  0.11342446  0.00425603  0.06817076 -0.09476037\n",
      "  0.28795048  0.0380016  -0.25085359  0.1735625  -0.16425104 -0.19339048\n",
      "  0.09814456 -0.46799012]\n",
      "Training Error:  10.36486977494004\n",
      "====================================================================================================\n",
      "Iteration:  384\n",
      "Previous theta :  [-0.00425501 -0.09295766  0.11342446  0.00425603  0.06817076 -0.09476037\n",
      "  0.28795048  0.0380016  -0.25085359  0.1735625  -0.16425104 -0.19339048\n",
      "  0.09814456 -0.46799012]\n",
      "New theta_0 : [-0.00424823 -0.09307389  0.11361612  0.00409685  0.06813669 -0.09529207\n",
      "  0.28770915  0.0380245  -0.25151538  0.17388163 -0.16428936 -0.19348817\n",
      "  0.098135   -0.46806288]\n",
      "Training Error:  10.363949625372637\n",
      "====================================================================================================\n",
      "Iteration:  385\n",
      "Previous theta :  [-0.00424823 -0.09307389  0.11361612  0.00409685  0.06813669 -0.09529207\n",
      "  0.28770915  0.0380245  -0.25151538  0.17388163 -0.16428936 -0.19348817\n",
      "  0.098135   -0.46806288]\n",
      "New theta_0 : [-0.0042415  -0.09318936  0.11380646  0.00393949  0.06810279 -0.09582036\n",
      "  0.28747008  0.03804746 -0.25217201  0.17419897 -0.16432814 -0.19358513\n",
      "  0.09812561 -0.46813446]\n",
      "Training Error:  10.363042816052168\n",
      "====================================================================================================\n",
      "Iteration:  386\n",
      "Previous theta :  [-0.0042415  -0.09318936  0.11380646  0.00393949  0.06810279 -0.09582036\n",
      "  0.28747008  0.03804746 -0.25217201  0.17419897 -0.16432814 -0.19358513\n",
      "  0.09812561 -0.46813446]\n",
      "New theta_0 : [-0.00423482 -0.09330408  0.11399549  0.00378393  0.06806909 -0.09634524\n",
      "  0.28723326  0.03807047 -0.2528235   0.17451455 -0.16436738 -0.19368136\n",
      "  0.09811639 -0.46820488]\n",
      "Training Error:  10.362149146062805\n",
      "====================================================================================================\n",
      "Iteration:  387\n",
      "Previous theta :  [-0.00423482 -0.09330408  0.11399549  0.00378393  0.06806909 -0.09634524\n",
      "  0.28723326  0.03807047 -0.2528235   0.17451455 -0.16436738 -0.19368136\n",
      "  0.09811639 -0.46820488]\n",
      "New theta_0 : [-0.0042282  -0.09341803  0.11418321  0.00363015  0.06803556 -0.09686675\n",
      "  0.28699866  0.03809353 -0.25346991  0.17482836 -0.16440707 -0.19377688\n",
      "  0.09810734 -0.46827414]\n",
      "Training Error:  10.361268417595621\n",
      "====================================================================================================\n",
      "Iteration:  388\n",
      "Previous theta :  [-0.0042282  -0.09341803  0.11418321  0.00363015  0.06803556 -0.09686675\n",
      "  0.28699866  0.03809353 -0.25346991  0.17482836 -0.16440707 -0.19377688\n",
      "  0.09810734 -0.46827414]\n",
      "New theta_0 : [-0.00422162 -0.09353124  0.11436964  0.00347813  0.06800221 -0.09738491\n",
      "  0.28676625  0.03811664 -0.25411126  0.17514044 -0.16444722 -0.19387169\n",
      "  0.09809846 -0.46834227]\n",
      "Training Error:  10.360400435899237\n",
      "====================================================================================================\n",
      "Iteration:  389\n",
      "Previous theta :  [-0.00422162 -0.09353124  0.11436964  0.00347813  0.06800221 -0.09738491\n",
      "  0.28676625  0.03811664 -0.25411126  0.17514044 -0.16444722 -0.19387169\n",
      "  0.09809846 -0.46834227]\n",
      "New theta_0 : [-0.0042151  -0.0936437   0.11455477  0.00332787  0.06796904 -0.09789973\n",
      "  0.28653602  0.03813978 -0.25474761  0.17545078 -0.16448781 -0.1939658\n",
      "  0.09808974 -0.46840928]\n",
      "Training Error:  10.35954500923128\n",
      "====================================================================================================\n",
      "Iteration:  390\n",
      "Previous theta :  [-0.0042151  -0.0936437   0.11455477  0.00332787  0.06796904 -0.09789973\n",
      "  0.28653602  0.03813978 -0.25474761  0.17545078 -0.16448781 -0.1939658\n",
      "  0.09808974 -0.46840928]\n",
      "New theta_0 : [-0.00420863 -0.09375542  0.11473861  0.00317934  0.06793604 -0.09841123\n",
      "  0.28630795  0.03816296 -0.25537899  0.1757594  -0.16452883 -0.19405921\n",
      "  0.09808119 -0.46847518]\n",
      "Training Error:  10.35870194881065\n",
      "====================================================================================================\n",
      "Iteration:  391\n",
      "Previous theta :  [-0.00420863 -0.09375542  0.11473861  0.00317934  0.06793604 -0.09841123\n",
      "  0.28630795  0.03816296 -0.25537899  0.1757594  -0.16452883 -0.19405921\n",
      "  0.09808119 -0.46847518]\n",
      "New theta_0 : [-0.0042022  -0.0938664   0.11492118  0.00303252  0.06790322 -0.09891944\n",
      "  0.28608201  0.03818617 -0.25600544  0.17606632 -0.16457029 -0.19415193\n",
      "  0.09807279 -0.46854   ]\n",
      "Training Error:  10.357871068770566\n",
      "====================================================================================================\n",
      "Iteration:  392\n",
      "Previous theta :  [-0.0042022  -0.0938664   0.11492118  0.00303252  0.06790322 -0.09891944\n",
      "  0.28608201  0.03818617 -0.25600544  0.17606632 -0.16457029 -0.19415193\n",
      "  0.09807279 -0.46854   ]\n",
      "New theta_0 : [-0.00419583 -0.09397664  0.11510248  0.00288742  0.06787058 -0.09942438\n",
      "  0.28585818  0.0382094  -0.25662701  0.17637154 -0.16461218 -0.19424397\n",
      "  0.09806455 -0.46860375]\n",
      "Training Error:  10.35705218611238\n",
      "====================================================================================================\n",
      "Iteration:  393\n",
      "Previous theta :  [-0.00419583 -0.09397664  0.11510248  0.00288742  0.06787058 -0.09942438\n",
      "  0.28585818  0.0382094  -0.25662701  0.17637154 -0.16461218 -0.19424397\n",
      "  0.09806455 -0.46860375]\n",
      "New theta_0 : [-0.0041895  -0.09408616  0.11528252  0.00274399  0.06783812 -0.09992607\n",
      "  0.28563643  0.03823266 -0.25724372  0.17667508 -0.16465449 -0.19433534\n",
      "  0.09805646 -0.46866644]\n",
      "Training Error:  10.35624512066016\n",
      "====================================================================================================\n",
      "Iteration:  394\n",
      "Previous theta :  [-0.0041895  -0.09408616  0.11528252  0.00274399  0.06783812 -0.09992607\n",
      "  0.28563643  0.03823266 -0.25724372  0.17667508 -0.16465449 -0.19433534\n",
      "  0.09805646 -0.46866644]\n",
      "New theta_0 : [-0.00418322 -0.09419496  0.1154613   0.00260225  0.06780582 -0.10042452\n",
      "  0.28541676  0.03825593 -0.25785562  0.17697695 -0.16469721 -0.19442604\n",
      "  0.09804853 -0.46872809]\n",
      "Training Error:  10.355449695016008\n",
      "====================================================================================================\n",
      "Iteration:  395\n",
      "Previous theta :  [-0.00418322 -0.09419496  0.1154613   0.00260225  0.06780582 -0.10042452\n",
      "  0.28541676  0.03825593 -0.25785562  0.17697695 -0.16469721 -0.19442604\n",
      "  0.09804853 -0.46872809]\n",
      "New theta_0 : [-0.00417699 -0.09430303  0.11563884  0.00246216  0.0677737  -0.10091977\n",
      "  0.28519914  0.03827922 -0.25846275  0.17727715 -0.16474035 -0.19451608\n",
      "  0.09804075 -0.46878871]\n",
      "Training Error:  10.354665734516109\n",
      "====================================================================================================\n",
      "Iteration:  396\n",
      "Previous theta :  [-0.00417699 -0.09430303  0.11563884  0.00246216  0.0677737  -0.10091977\n",
      "  0.28519914  0.03827922 -0.25846275  0.17727715 -0.16474035 -0.19451608\n",
      "  0.09804075 -0.46878871]\n",
      "New theta_0 : [-0.0041708  -0.09441039  0.11581513  0.00232371  0.06774176 -0.10141182\n",
      "  0.28498354  0.03830252 -0.25906514  0.17757571 -0.16478389 -0.19460547\n",
      "  0.09803311 -0.46884832]\n",
      "Training Error:  10.353893067187517\n",
      "====================================================================================================\n",
      "Iteration:  397\n",
      "Previous theta :  [-0.0041708  -0.09441039  0.11581513  0.00232371  0.06774176 -0.10141182\n",
      "  0.28498354  0.03830252 -0.25906514  0.17757571 -0.16478389 -0.19460547\n",
      "  0.09803311 -0.46884832]\n",
      "New theta_0 : [-0.00416466 -0.09451704  0.1159902   0.00218689  0.06770998 -0.1019007\n",
      "  0.28476995  0.03832582 -0.25966284  0.17787263 -0.16482784 -0.1946942\n",
      "  0.09802562 -0.46890693]\n",
      "Training Error:  10.35313152370562\n",
      "====================================================================================================\n",
      "Iteration:  398\n",
      "Previous theta :  [-0.00416466 -0.09451704  0.1159902   0.00218689  0.06770998 -0.1019007\n",
      "  0.28476995  0.03832582 -0.25966284  0.17787263 -0.16482784 -0.1946942\n",
      "  0.09802562 -0.46890693]\n",
      "New theta_0 : [-0.00415857 -0.09462298  0.11616404  0.00205168  0.06767837 -0.10238642\n",
      "  0.28455834  0.03834913 -0.26025587  0.17816793 -0.16487218 -0.1947823\n",
      "  0.09801828 -0.46896455]\n",
      "Training Error:  10.352380937352327\n",
      "====================================================================================================\n",
      "Iteration:  399\n",
      "Previous theta :  [-0.00415857 -0.09462298  0.11616404  0.00205168  0.06767837 -0.10238642\n",
      "  0.28455834  0.03834913 -0.26025587  0.17816793 -0.16487218 -0.1947823\n",
      "  0.09801828 -0.46896455]\n",
      "New theta_0 : [-0.00415252 -0.09472822  0.11633666  0.00191807  0.06764693 -0.10286902\n",
      "  0.28434871  0.03837243 -0.26084428  0.17846162 -0.16491691 -0.19486976\n",
      "  0.09801107 -0.46902121]\n",
      "Training Error:  10.351641143974916\n",
      "====================================================================================================\n",
      "Iteration:  400\n",
      "Previous theta :  [-0.00415252 -0.09472822  0.11633666  0.00191807  0.06764693 -0.10286902\n",
      "  0.28434871  0.03837243 -0.26084428  0.17846162 -0.16491691 -0.19486976\n",
      "  0.09801107 -0.46902121]\n",
      "New theta_0 : [-0.00414652 -0.09483276  0.11650807  0.00178605  0.06761566 -0.1033485\n",
      "  0.28414102  0.03839573 -0.26142811  0.1787537  -0.16496203 -0.19495659\n",
      "  0.09800401 -0.46907691]\n",
      "Training Error:  10.350911981945568\n",
      "====================================================================================================\n",
      "Iteration:  401\n",
      "Previous theta :  [-0.00414652 -0.09483276  0.11650807  0.00178605  0.06761566 -0.1033485\n",
      "  0.28414102  0.03839573 -0.26142811  0.1787537  -0.16496203 -0.19495659\n",
      "  0.09800401 -0.46907691]\n",
      "New theta_0 : [-0.00414057 -0.09493661  0.11667828  0.00165559  0.06758456 -0.10382489\n",
      "  0.28393525  0.03841902 -0.26200739  0.17904419 -0.16500753 -0.1950428\n",
      "  0.09799708 -0.46913166]\n",
      "Training Error:  10.350193292121556\n",
      "====================================================================================================\n",
      "Iteration:  402\n",
      "Previous theta :  [-0.00414057 -0.09493661  0.11667828  0.00165559  0.06758456 -0.10382489\n",
      "  0.28393525  0.03841902 -0.26200739  0.17904419 -0.16500753 -0.1950428\n",
      "  0.09799708 -0.46913166]\n",
      "New theta_0 : [-0.00413465 -0.09503977  0.11684729  0.00152669  0.06755362 -0.10429821\n",
      "  0.2837314   0.03844231 -0.26258215  0.17933311 -0.16505341 -0.19512839\n",
      "  0.09799029 -0.46918548]\n",
      "Training Error:  10.34948491780608\n",
      "====================================================================================================\n",
      "Iteration:  403\n",
      "Previous theta :  [-0.00413465 -0.09503977  0.11684729  0.00152669  0.06755362 -0.10429821\n",
      "  0.2837314   0.03844231 -0.26258215  0.17933311 -0.16505341 -0.19512839\n",
      "  0.09799029 -0.46918548]\n",
      "New theta_0 : [-0.00412879 -0.09514224  0.11701512  0.00139933  0.06752284 -0.10476847\n",
      "  0.28352944  0.03846557 -0.26315244  0.17962045 -0.16509966 -0.19521338\n",
      "  0.09798363 -0.46923839]\n",
      "Training Error:  10.348786704709738\n",
      "====================================================================================================\n",
      "Iteration:  404\n",
      "Previous theta :  [-0.00412879 -0.09514224  0.11701512  0.00139933  0.06752284 -0.10476847\n",
      "  0.28352944  0.03846557 -0.26315244  0.17962045 -0.16509966 -0.19521338\n",
      "  0.09798363 -0.46923839]\n",
      "New theta_0 : [-0.00412296 -0.09524404  0.11718176  0.0012735   0.06749223 -0.10523569\n",
      "  0.28332934  0.03848882 -0.26371828  0.17990624 -0.16514628 -0.19529775\n",
      "  0.09797711 -0.46929039]\n",
      "Training Error:  10.348098500912629\n",
      "====================================================================================================\n",
      "Iteration:  405\n",
      "Previous theta :  [-0.00412296 -0.09524404  0.11718176  0.0012735   0.06749223 -0.10523569\n",
      "  0.28332934  0.03848882 -0.26371828  0.17990624 -0.16514628 -0.19529775\n",
      "  0.09797711 -0.46929039]\n",
      "New theta_0 : [-0.00411718 -0.09534515  0.11734724  0.00114918  0.06746179 -0.1056999\n",
      "  0.2831311   0.03851205 -0.26427972  0.18019048 -0.16519326 -0.19538153\n",
      "  0.09797071 -0.46934151]\n",
      "Training Error:  10.347420156827074\n",
      "====================================================================================================\n",
      "Iteration:  406\n",
      "Previous theta :  [-0.00411718 -0.09534515  0.11734724  0.00114918  0.06746179 -0.1056999\n",
      "  0.2831311   0.03851205 -0.26427972  0.18019048 -0.16519326 -0.19538153\n",
      "  0.09797071 -0.46934151]\n",
      "New theta_0 : [-0.00411144 -0.0954456   0.11751154  0.00102636  0.0674315  -0.10616112\n",
      "  0.28293469  0.03853526 -0.26483678  0.18047318 -0.1652406  -0.19546472\n",
      "  0.09796444 -0.46939174]\n",
      "Training Error:  10.346751525160922\n",
      "====================================================================================================\n",
      "Iteration:  407\n",
      "Previous theta :  [-0.00411144 -0.0954456   0.11751154  0.00102636  0.0674315  -0.10616112\n",
      "  0.28293469  0.03853526 -0.26483678  0.18047318 -0.1652406  -0.19546472\n",
      "  0.09796444 -0.46939174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00410575 -0.09554538  0.11767469  0.00090503  0.06740138 -0.10661935\n",
      "  0.2827401   0.03855844 -0.26538951  0.18075436 -0.16528829 -0.19554731\n",
      "  0.0979583  -0.46944111]\n",
      "Training Error:  10.346092460881485\n",
      "====================================================================================================\n",
      "Iteration:  408\n",
      "Previous theta :  [-0.00410575 -0.09554538  0.11767469  0.00090503  0.06740138 -0.10661935\n",
      "  0.2827401   0.03855844 -0.26538951  0.18075436 -0.16528829 -0.19554731\n",
      "  0.0979583  -0.46944111]\n",
      "New theta_0 : [-0.00410009 -0.09564449  0.11783669  0.00078517  0.06737142 -0.10707463\n",
      "  0.2825473   0.03858159 -0.26593794  0.18103403 -0.16533633 -0.19562933\n",
      "  0.09795228 -0.46948962]\n",
      "Training Error:  10.345442821180015\n",
      "====================================================================================================\n",
      "Iteration:  409\n",
      "Previous theta :  [-0.00410009 -0.09564449  0.11783669  0.00078517  0.06737142 -0.10707463\n",
      "  0.2825473   0.03858159 -0.26593794  0.18103403 -0.16533633 -0.19562933\n",
      "  0.09795228 -0.46948962]\n",
      "New theta_0 : [-0.00409448 -0.09574294  0.11799754  0.00066677  0.06734161 -0.10752696\n",
      "  0.28235629  0.03860471 -0.2664821   0.18131219 -0.16538471 -0.19571077\n",
      "  0.09794639 -0.46953729]\n",
      "Training Error:  10.344802465436803\n",
      "====================================================================================================\n",
      "Iteration:  410\n",
      "Previous theta :  [-0.00409448 -0.09574294  0.11799754  0.00066677  0.06734161 -0.10752696\n",
      "  0.28235629  0.03860471 -0.2664821   0.18131219 -0.16538471 -0.19571077\n",
      "  0.09794639 -0.46953729]\n",
      "New theta_0 : [-0.00408891 -0.09584074  0.11815725  0.00054981  0.06731197 -0.10797637\n",
      "  0.28216703  0.03862779 -0.26702202  0.18158885 -0.16543344 -0.19579163\n",
      "  0.09794061 -0.46958413]\n",
      "Training Error:  10.344171255186808\n",
      "====================================================================================================\n",
      "Iteration:  411\n",
      "Previous theta :  [-0.00408891 -0.09584074  0.11815725  0.00054981  0.06731197 -0.10797637\n",
      "  0.28216703  0.03862779 -0.26702202  0.18158885 -0.16543344 -0.19579163\n",
      "  0.09794061 -0.46958413]\n",
      "New theta_0 : [-4.08337900e-03 -9.59378878e-02  1.18315836e-01  4.34281224e-04\n",
      "  6.72824818e-02 -1.08422879e-01  2.81979525e-01  3.86508381e-02\n",
      " -2.67557744e-01  1.81864037e-01 -1.65482495e-01 -1.95871933e-01\n",
      "  9.79349579e-02 -4.69630159e-01]\n",
      "Training Error:  10.343549054085843\n",
      "====================================================================================================\n",
      "Iteration:  412\n",
      "Previous theta :  [-4.08337900e-03 -9.59378878e-02  1.18315836e-01  4.34281224e-04\n",
      "  6.72824818e-02 -1.08422879e-01  2.81979525e-01  3.86508381e-02\n",
      " -2.67557744e-01  1.81864037e-01 -1.65482495e-01 -1.95871933e-01\n",
      "  9.79349579e-02 -4.69630159e-01]\n",
      "New theta_0 : [-4.07788884e-03 -9.60343874e-02  1.18473297e-01  3.20173889e-04\n",
      "  6.72531513e-02 -1.08866501e-01  2.81793742e-01  3.86738459e-02\n",
      " -2.68089300e-01  1.82137747e-01 -1.65531885e-01 -1.95951674e-01\n",
      "  9.79294195e-02 -4.69675378e-01]\n",
      "Training Error:  10.342935727877334\n",
      "====================================================================================================\n",
      "Iteration:  413\n",
      "Previous theta :  [-4.07788884e-03 -9.60343874e-02  1.18473297e-01  3.20173889e-04\n",
      "  6.72531513e-02 -1.08866501e-01  2.81793742e-01  3.86738459e-02\n",
      " -2.68089300e-01  1.82137747e-01 -1.65531885e-01 -1.95951674e-01\n",
      "  9.79294195e-02 -4.69675378e-01]\n",
      "New theta_0 : [-4.07243869e-03 -9.61302440e-02  1.18629644e-01  2.07472162e-04\n",
      "  6.72239765e-02 -1.09307255e-01  2.81609669e-01  3.86968118e-02\n",
      " -2.68616721e-01  1.82409994e-01 -1.65581601e-01 -1.96030859e-01\n",
      "  9.79239968e-02 -4.69719801e-01]\n",
      "Training Error:  10.34233114435959\n",
      "====================================================================================================\n",
      "Iteration:  414\n",
      "Previous theta :  [-4.07243869e-03 -9.61302440e-02  1.18629644e-01  2.07472162e-04\n",
      "  6.72239765e-02 -1.09307255e-01  2.81609669e-01  3.86968118e-02\n",
      " -2.68616721e-01  1.82409994e-01 -1.65581601e-01 -1.96030859e-01\n",
      "  9.79239968e-02 -4.69719801e-01]\n",
      "New theta_0 : [-4.06702818e-03 -9.62254617e-02  1.18784882e-01  9.61630807e-05\n",
      "  6.71949567e-02 -1.09745160e-01  2.81427289e-01  3.87197337e-02\n",
      " -2.69140041e-01  1.82680788e-01 -1.65631639e-01 -1.96109495e-01\n",
      "  9.79186879e-02 -4.69763441e-01]\n",
      "Training Error:  10.341735173353609\n",
      "====================================================================================================\n",
      "Iteration:  415\n",
      "Previous theta :  [-4.06702818e-03 -9.62254617e-02  1.18784882e-01  9.61630807e-05\n",
      "  6.71949567e-02 -1.09745160e-01  2.81427289e-01  3.87197337e-02\n",
      " -2.69140041e-01  1.82680788e-01 -1.65631639e-01 -1.96109495e-01\n",
      "  9.79186879e-02 -4.69763441e-01]\n",
      "New theta_0 : [-4.06165693e-03 -9.63200444e-02  1.18939018e-01 -1.37662141e-05\n",
      "  6.71660908e-02 -1.10180233e-01  2.81246585e-01  3.87426091e-02\n",
      " -2.69659291e-01  1.82950139e-01 -1.65681995e-01 -1.96187585e-01\n",
      "  9.79134913e-02 -4.69806309e-01]\n",
      "Training Error:  10.341147686671404\n",
      "====================================================================================================\n",
      "Iteration:  416\n",
      "Previous theta :  [-4.06165693e-03 -9.63200444e-02  1.18939018e-01 -1.37662141e-05\n",
      "  6.71660908e-02 -1.10180233e-01  2.81246585e-01  3.87426091e-02\n",
      " -2.69659291e-01  1.82950139e-01 -1.65681995e-01 -1.96187585e-01\n",
      "  9.79134913e-02 -4.69806309e-01]\n",
      "New theta_0 : [-4.05632458e-03 -9.64139963e-02  1.19092061e-01 -1.22328476e-04\n",
      "  6.71373781e-02 -1.10612493e-01  2.81067541e-01  3.87654359e-02\n",
      " -2.70174505e-01  1.83218057e-01 -1.65732664e-01 -1.96265135e-01\n",
      "  9.79084054e-02 -4.69848416e-01]\n",
      "Training Error:  10.340568558084838\n",
      "====================================================================================================\n",
      "Iteration:  417\n",
      "Previous theta :  [-4.05632458e-03 -9.64139963e-02  1.19092061e-01 -1.22328476e-04\n",
      "  6.71373781e-02 -1.10612493e-01  2.81067541e-01  3.87654359e-02\n",
      " -2.70174505e-01  1.83218057e-01 -1.65732664e-01 -1.96265135e-01\n",
      "  9.79084054e-02 -4.69848416e-01]\n",
      "New theta_0 : [-4.05103077e-03 -9.65073213e-02  1.19244016e-01 -2.29536357e-04\n",
      "  6.71088176e-02 -1.11041957e-01  2.80890140e-01  3.87882120e-02\n",
      " -2.70685714e-01  1.83484552e-01 -1.65783642e-01 -1.96342150e-01\n",
      "  9.79034285e-02 -4.69889772e-01]\n",
      "Training Error:  10.339997663294962\n",
      "====================================================================================================\n",
      "Iteration:  418\n",
      "Previous theta :  [-4.05103077e-03 -9.65073213e-02  1.19244016e-01 -2.29536357e-04\n",
      "  6.71088176e-02 -1.11041957e-01  2.80890140e-01  3.87882120e-02\n",
      " -2.70685714e-01  1.83484552e-01 -1.65783642e-01 -1.96342150e-01\n",
      "  9.79034285e-02 -4.69889772e-01]\n",
      "New theta_0 : [-4.04577513e-03 -9.66000235e-02  1.19394891e-01 -3.35402405e-04\n",
      "  6.70804084e-02 -1.11468642e-01  2.80714367e-01  3.88109353e-02\n",
      " -2.71192950e-01  1.83749633e-01 -1.65834926e-01 -1.96418635e-01\n",
      "  9.78985592e-02 -4.69930388e-01]\n",
      "Training Error:  10.33943487990185\n",
      "====================================================================================================\n",
      "Iteration:  419\n",
      "Previous theta :  [-4.04577513e-03 -9.66000235e-02  1.19394891e-01 -3.35402405e-04\n",
      "  6.70804084e-02 -1.11468642e-01  2.80714367e-01  3.88109353e-02\n",
      " -2.71192950e-01  1.83749633e-01 -1.65834926e-01 -1.96418635e-01\n",
      "  9.78985592e-02 -4.69930388e-01]\n",
      "New theta_0 : [-4.04055731e-03 -9.66921069e-02  1.19544693e-01 -4.39939067e-04\n",
      "  6.70521498e-02 -1.11892567e-01  2.80540205e-01  3.88336038e-02\n",
      " -2.71696245e-01  1.84013311e-01 -1.65886511e-01 -1.96494595e-01\n",
      "  9.78937958e-02 -4.69970276e-01]\n",
      "Training Error:  10.3388800873749\n",
      "====================================================================================================\n",
      "Iteration:  420\n",
      "Previous theta :  [-4.04055731e-03 -9.66921069e-02  1.19544693e-01 -4.39939067e-04\n",
      "  6.70521498e-02 -1.11892567e-01  2.80540205e-01  3.88336038e-02\n",
      " -2.71696245e-01  1.84013311e-01 -1.65886511e-01 -1.96494595e-01\n",
      "  9.78937958e-02 -4.69970276e-01]\n",
      "New theta_0 : [-0.00403538 -0.09678358  0.11969343 -0.00054316  0.06702404 -0.11231375\n",
      "  0.28036764  0.03885622 -0.27219563  0.18427559 -0.16593839 -0.19657003\n",
      "  0.09788914 -0.47000944]\n",
      "Training Error:  10.338333167023642\n",
      "====================================================================================================\n",
      "Iteration:  421\n",
      "Previous theta :  [-0.00403538 -0.09678358  0.11969343 -0.00054316  0.06702404 -0.11231375\n",
      "  0.28036764  0.03885622 -0.27219563  0.18427559 -0.16593839 -0.19657003\n",
      "  0.09788914 -0.47000944]\n",
      "New theta_0 : [-0.00403023 -0.09687443  0.1198411  -0.00064507  0.06699608 -0.11273221\n",
      "  0.28019665  0.03887877 -0.27269113  0.18453649 -0.16599057 -0.19664496\n",
      "  0.09788458 -0.4700479 ]\n",
      "Training Error:  10.337794001968991\n",
      "====================================================================================================\n",
      "Iteration:  422\n",
      "Previous theta :  [-0.00403023 -0.09687443  0.1198411  -0.00064507  0.06699608 -0.11273221\n",
      "  0.28019665  0.03887877 -0.27269113  0.18453649 -0.16599057 -0.19664496\n",
      "  0.09788458 -0.4700479 ]\n",
      "New theta_0 : [-0.00402513 -0.09696468  0.11998773 -0.0007457   0.06696827 -0.11314795\n",
      "  0.28002723  0.03890126 -0.27318279  0.18479602 -0.16604303 -0.19671937\n",
      "  0.09788013 -0.47008567]\n",
      "Training Error:  10.337262477114965\n",
      "====================================================================================================\n",
      "Iteration:  423\n",
      "Previous theta :  [-0.00402513 -0.09696468  0.11998773 -0.0007457   0.06696827 -0.11314795\n",
      "  0.28002723  0.03890126 -0.27318279  0.18479602 -0.16604303 -0.19671937\n",
      "  0.09788013 -0.47008567]\n",
      "New theta_0 : [-0.00402006 -0.09705433  0.12013331 -0.00084504  0.0669406  -0.11356101\n",
      "  0.27985935  0.03892369 -0.27367063  0.18505417 -0.16609578 -0.19679327\n",
      "  0.09787577 -0.47012274]\n",
      "Training Error:  10.336738479120875\n",
      "====================================================================================================\n",
      "Iteration:  424\n",
      "Previous theta :  [-0.00402006 -0.09705433  0.12013331 -0.00084504  0.0669406  -0.11356101\n",
      "  0.27985935  0.03892369 -0.27367063  0.18505417 -0.16609578 -0.19679327\n",
      "  0.09787577 -0.47012274]\n",
      "New theta_0 : [-0.00401502 -0.09714338  0.12027785 -0.00094311  0.06691308 -0.11397139\n",
      "  0.27969301  0.03894606 -0.27415467  0.18531098 -0.16614881 -0.19686668\n",
      "  0.09787152 -0.47015914]\n",
      "Training Error:  10.336221896373926\n",
      "====================================================================================================\n",
      "Iteration:  425\n",
      "Previous theta :  [-0.00401502 -0.09714338  0.12027785 -0.00094311  0.06691308 -0.11397139\n",
      "  0.27969301  0.03894606 -0.27415467  0.18531098 -0.16614881 -0.19686668\n",
      "  0.09787152 -0.47015914]\n",
      "New theta_0 : [-0.00401003 -0.09723183  0.12042136 -0.00103993  0.06688571 -0.11437911\n",
      "  0.27952819  0.03896836 -0.27463497  0.18556643 -0.16620211 -0.19693958\n",
      "  0.09786736 -0.47019486]\n",
      "Training Error:  10.33571261896229\n",
      "====================================================================================================\n",
      "Iteration:  426\n",
      "Previous theta :  [-0.00401003 -0.09723183  0.12042136 -0.00103993  0.06688571 -0.11437911\n",
      "  0.27952819  0.03896836 -0.27463497  0.18556643 -0.16620211 -0.19693958\n",
      "  0.09786736 -0.47019486]\n",
      "New theta_0 : [-0.00400506 -0.0973197   0.12056384 -0.0011355   0.06685848 -0.1147842\n",
      "  0.27936487  0.03899059 -0.27511153  0.18582054 -0.16625569 -0.197012\n",
      "  0.09786329 -0.47022993]\n",
      "Training Error:  10.335210538648596\n",
      "====================================================================================================\n",
      "Iteration:  427\n",
      "Previous theta :  [-0.00400506 -0.0973197   0.12056384 -0.0011355   0.06685848 -0.1147842\n",
      "  0.27936487  0.03899059 -0.27511153  0.18582054 -0.16625569 -0.197012\n",
      "  0.09786329 -0.47022993]\n",
      "New theta_0 : [-0.00400013 -0.09740697  0.12070531 -0.00122984  0.0668314  -0.11518666\n",
      "  0.27920304  0.03901276 -0.27558439  0.18607333 -0.16630954 -0.19708392\n",
      "  0.09785933 -0.47026435]\n",
      "Training Error:  10.334715548843837\n",
      "====================================================================================================\n",
      "Iteration:  428\n",
      "Previous theta :  [-0.00400013 -0.09740697  0.12070531 -0.00122984  0.0668314  -0.11518666\n",
      "  0.27920304  0.03901276 -0.27558439  0.18607333 -0.16630954 -0.19708392\n",
      "  0.09785933 -0.47026435]\n",
      "New theta_0 : [-0.00399524 -0.09749366  0.12084576 -0.00132295  0.06680445 -0.11558651\n",
      "  0.27904268  0.03903486 -0.27605358  0.1863248  -0.16636365 -0.19715536\n",
      "  0.09785545 -0.47029813]\n",
      "Training Error:  10.334227544581704\n",
      "====================================================================================================\n",
      "Iteration:  429\n",
      "Previous theta :  [-0.00399524 -0.09749366  0.12084576 -0.00132295  0.06680445 -0.11558651\n",
      "  0.27904268  0.03903486 -0.27605358  0.1863248  -0.16636365 -0.19715536\n",
      "  0.09785545 -0.47029813]\n",
      "New theta_0 : [-0.00399038 -0.09757977  0.12098521 -0.00141486  0.06677765 -0.11598377\n",
      "  0.27888378  0.03905688 -0.27651914  0.18657495 -0.16641803 -0.19722632\n",
      "  0.09785167 -0.47033127]\n",
      "Training Error:  10.333746422493332\n",
      "====================================================================================================\n",
      "Iteration:  430\n",
      "Previous theta :  [-0.00399038 -0.09757977  0.12098521 -0.00141486  0.06677765 -0.11598377\n",
      "  0.27888378  0.03905688 -0.27651914  0.18657495 -0.16641803 -0.19722632\n",
      "  0.09785167 -0.47033127]\n",
      "New theta_0 : [-0.00398556 -0.09766531  0.12112367 -0.00150556  0.06675099 -0.11637846\n",
      "  0.27872633  0.03907883 -0.27698108  0.1868238  -0.16647266 -0.1972968\n",
      "  0.09784797 -0.4703638 ]\n",
      "Training Error:  10.333272080782441\n",
      "====================================================================================================\n",
      "Iteration:  431\n",
      "Previous theta :  [-0.00398556 -0.09766531  0.12112367 -0.00150556  0.06675099 -0.11637846\n",
      "  0.27872633  0.03907883 -0.27698108  0.1868238  -0.16647266 -0.1972968\n",
      "  0.09784797 -0.4703638 ]\n",
      "New theta_0 : [-0.00398077 -0.09775027  0.12126113 -0.00159508  0.06672447 -0.11677059\n",
      "  0.27857031  0.03910071 -0.27743944  0.18707136 -0.16652755 -0.19736681\n",
      "  0.09784437 -0.47039571]\n",
      "Training Error:  10.332804419200869\n",
      "====================================================================================================\n",
      "Iteration:  432\n",
      "Previous theta :  [-0.00398077 -0.09775027  0.12126113 -0.00159508  0.06672447 -0.11677059\n",
      "  0.27857031  0.03910071 -0.27743944  0.18707136 -0.16652755 -0.19736681\n",
      "  0.09784437 -0.47039571]\n",
      "New theta_0 : [-0.00397601 -0.09783466  0.1213976  -0.00168342  0.06669809 -0.11716018\n",
      "  0.27841571  0.03912251 -0.27789424  0.18731764 -0.16658269 -0.19743635\n",
      "  0.09784085 -0.47042702]\n",
      "Training Error:  10.33234333902452\n",
      "====================================================================================================\n",
      "Iteration:  433\n",
      "Previous theta :  [-0.00397601 -0.09783466  0.1213976  -0.00168342  0.06669809 -0.11716018\n",
      "  0.27841571  0.03912251 -0.27789424  0.18731764 -0.16658269 -0.19743635\n",
      "  0.09784085 -0.47042702]\n",
      "New theta_0 : [-0.00397129 -0.09791849  0.1215331  -0.0017706   0.06667185 -0.11754724\n",
      "  0.27826252  0.03914423 -0.27834551  0.18756263 -0.16663808 -0.19750543\n",
      "  0.09783742 -0.47045773]\n",
      "Training Error:  10.33188874302966\n",
      "====================================================================================================\n",
      "Iteration:  434\n",
      "Previous theta :  [-0.00397129 -0.09791849  0.1215331  -0.0017706   0.06667185 -0.11754724\n",
      "  0.27826252  0.03914423 -0.27834551  0.18756263 -0.16663808 -0.19750543\n",
      "  0.09783742 -0.47045773]\n",
      "New theta_0 : [-0.0039666  -0.09800176  0.12166763 -0.00185662  0.06664575 -0.11793179\n",
      "  0.27811071  0.03916588 -0.27879329  0.18780636 -0.16669371 -0.19757405\n",
      "  0.09783408 -0.47048786]\n",
      "Training Error:  10.33144053546962\n",
      "====================================================================================================\n",
      "Iteration:  435\n",
      "Previous theta :  [-0.0039666  -0.09800176  0.12166763 -0.00185662  0.06664575 -0.11793179\n",
      "  0.27811071  0.03916588 -0.27879329  0.18780636 -0.16669371 -0.19757405\n",
      "  0.09783408 -0.47048786]\n",
      "New theta_0 : [-0.00396194 -0.09808447  0.1218012  -0.0019415   0.06661978 -0.11831385\n",
      "  0.27796028  0.03918745 -0.27923759  0.18804883 -0.16674958 -0.19764222\n",
      "  0.09783082 -0.47051741]\n",
      "Training Error:  10.330998622051853\n",
      "====================================================================================================\n",
      "Iteration:  436\n",
      "Previous theta :  [-0.00396194 -0.09808447  0.1218012  -0.0019415   0.06661978 -0.11831385\n",
      "  0.27796028  0.03918745 -0.27923759  0.18804883 -0.16674958 -0.19764222\n",
      "  0.09783082 -0.47051741]\n",
      "New theta_0 : [-0.00395731 -0.09816662  0.1219338  -0.00202525  0.06659396 -0.11869343\n",
      "  0.27781121  0.03920893 -0.27967845  0.18829005 -0.16680568 -0.19770993\n",
      "  0.09782764 -0.47054638]\n",
      "Training Error:  10.330562909915367\n",
      "====================================================================================================\n",
      "Iteration:  437\n",
      "Previous theta :  [-0.00395731 -0.09816662  0.1219338  -0.00202525  0.06659396 -0.11869343\n",
      "  0.27781121  0.03920893 -0.27967845  0.18829005 -0.16680568 -0.19770993\n",
      "  0.09782764 -0.47054638]\n",
      "New theta_0 : [-0.00395272 -0.09824823  0.12206546 -0.00210787  0.06656826 -0.11907056\n",
      "  0.27766349  0.03923034 -0.2801159   0.18853003 -0.16686202 -0.19777719\n",
      "  0.09782454 -0.4705748 ]\n",
      "Training Error:  10.3301333076085\n",
      "====================================================================================================\n",
      "Iteration:  438\n",
      "Previous theta :  [-0.00395272 -0.09824823  0.12206546 -0.00210787  0.06656826 -0.11907056\n",
      "  0.27766349  0.03923034 -0.2801159   0.18853003 -0.16686202 -0.19777719\n",
      "  0.09782454 -0.4705748 ]\n",
      "New theta_0 : [-0.00394816 -0.09832929  0.12219616 -0.00218939  0.0665427  -0.11944523\n",
      "  0.27751711  0.03925166 -0.28054995  0.18876877 -0.16691859 -0.19784401\n",
      "  0.09782153 -0.47060266]\n",
      "Training Error:  10.329709725067072\n",
      "====================================================================================================\n",
      "Iteration:  439\n",
      "Previous theta :  [-0.00394816 -0.09832929  0.12219616 -0.00218939  0.0665427  -0.11944523\n",
      "  0.27751711  0.03925166 -0.28054995  0.18876877 -0.16691859 -0.19784401\n",
      "  0.09782153 -0.47060266]\n",
      "New theta_0 : [-0.00394363 -0.0984098   0.12232593 -0.0022698   0.06651728 -0.11981747\n",
      "  0.27737205  0.0392729  -0.28098064  0.18900629 -0.16697538 -0.19791039\n",
      "  0.09781859 -0.47062998]\n",
      "Training Error:  10.329292073592866\n",
      "====================================================================================================\n",
      "Iteration:  440\n",
      "Previous theta :  [-0.00394363 -0.0984098   0.12232593 -0.0022698   0.06651728 -0.11981747\n",
      "  0.27737205  0.0392729  -0.28098064  0.18900629 -0.16697538 -0.19791039\n",
      "  0.09781859 -0.47062998]\n",
      "New theta_0 : [-0.00393913 -0.09848978  0.12245477 -0.00234912  0.06649199 -0.1201873\n",
      "  0.2772283   0.03929406 -0.28140799  0.18924259 -0.1670324  -0.19797633\n",
      "  0.09781573 -0.47065676]\n",
      "Training Error:  10.328880265832446\n",
      "====================================================================================================\n",
      "Iteration:  441\n",
      "Previous theta :  [-0.00393913 -0.09848978  0.12245477 -0.00234912  0.06649199 -0.1201873\n",
      "  0.2772283   0.03929406 -0.28140799  0.18924259 -0.1670324  -0.19797633\n",
      "  0.09781573 -0.47065676]\n",
      "New theta_0 : [-0.00393466 -0.09856922  0.12258269 -0.00242736  0.06646683 -0.12055473\n",
      "  0.27708586  0.03931513 -0.28183203  0.18947768 -0.16708964 -0.19804184\n",
      "  0.09781295 -0.47068301]\n",
      "Training Error:  10.328474215756339\n",
      "====================================================================================================\n",
      "Iteration:  442\n",
      "Previous theta :  [-0.00393466 -0.09856922  0.12258269 -0.00242736  0.06646683 -0.12055473\n",
      "  0.27708586  0.03931513 -0.28183203  0.18947768 -0.16708964 -0.19804184\n",
      "  0.09781295 -0.47068301]\n",
      "New theta_0 : [-0.00393022 -0.09864813  0.12270968 -0.00250453  0.0664418  -0.12091977\n",
      "  0.27694469  0.03933611 -0.28225279  0.18971157 -0.16714709 -0.19810692\n",
      "  0.09781024 -0.47070874]\n",
      "Training Error:  10.328073838638513\n",
      "====================================================================================================\n",
      "Iteration:  443\n",
      "Previous theta :  [-0.00393022 -0.09864813  0.12270968 -0.00250453  0.0664418  -0.12091977\n",
      "  0.27694469  0.03933611 -0.28225279  0.18971157 -0.16714709 -0.19810692\n",
      "  0.09781024 -0.47070874]\n",
      "New theta_0 : [-0.00392582 -0.09872651  0.12283576 -0.00258065  0.0664169  -0.12128245\n",
      "  0.2768048   0.03935701 -0.28267028  0.18994426 -0.16720475 -0.19817157\n",
      "  0.09780761 -0.47073395]\n",
      "Training Error:  10.327679051036206\n",
      "====================================================================================================\n",
      "Iteration:  444\n",
      "Previous theta :  [-0.00392582 -0.09872651  0.12283576 -0.00258065  0.0664169  -0.12128245\n",
      "  0.2768048   0.03935701 -0.28267028  0.18994426 -0.16720475 -0.19817157\n",
      "  0.09780761 -0.47073395]\n",
      "New theta_0 : [-0.00392144 -0.09880436  0.12296093 -0.00265571  0.06639214 -0.12164277\n",
      "  0.27666617  0.03937782 -0.28308455  0.19017577 -0.16726263 -0.1982358\n",
      "  0.09780506 -0.47075866]\n",
      "Training Error:  10.327289770770058\n",
      "====================================================================================================\n",
      "Iteration:  445\n",
      "Previous theta :  [-0.00392144 -0.09880436  0.12296093 -0.00265571  0.06639214 -0.12164277\n",
      "  0.27666617  0.03937782 -0.28308455  0.19017577 -0.16726263 -0.1982358\n",
      "  0.09780506 -0.47075866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00391709 -0.09888169  0.1230852  -0.00272973  0.0663675  -0.12200075\n",
      "  0.2765288   0.03939854 -0.28349561  0.1904061  -0.16732071 -0.19829962\n",
      "  0.09780257 -0.47078287]\n",
      "Training Error:  10.326905916904566\n",
      "====================================================================================================\n",
      "Iteration:  446\n",
      "Previous theta :  [-0.00391709 -0.09888169  0.1230852  -0.00272973  0.0663675  -0.12200075\n",
      "  0.2765288   0.03939854 -0.28349561  0.1904061  -0.16732071 -0.19829962\n",
      "  0.09780257 -0.47078287]\n",
      "New theta_0 : [-0.00391277 -0.09895851  0.12320858 -0.00280273  0.06634299 -0.12235641\n",
      "  0.27639265  0.03941918 -0.28390348  0.19063526 -0.16737899 -0.19836301\n",
      "  0.09780016 -0.47080658]\n",
      "Training Error:  10.326527409728849\n",
      "====================================================================================================\n",
      "Iteration:  447\n",
      "Previous theta :  [-0.00391277 -0.09895851  0.12320858 -0.00280273  0.06634299 -0.12235641\n",
      "  0.27639265  0.03941918 -0.28390348  0.19063526 -0.16737899 -0.19836301\n",
      "  0.09780016 -0.47080658]\n",
      "New theta_0 : [-0.00390849 -0.09903481  0.12333107 -0.0028747   0.06631861 -0.12270976\n",
      "  0.27625773  0.03943972 -0.2843082   0.19086326 -0.16743747 -0.198426\n",
      "  0.09779782 -0.47082981]\n",
      "Training Error:  10.32615417073771\n",
      "====================================================================================================\n",
      "Iteration:  448\n",
      "Previous theta :  [-0.00390849 -0.09903481  0.12333107 -0.0028747   0.06631861 -0.12270976\n",
      "  0.27625773  0.03943972 -0.2843082   0.19086326 -0.16743747 -0.198426\n",
      "  0.09779782 -0.47082981]\n",
      "New theta_0 : [-0.00390423 -0.0991106   0.12345268 -0.00294567  0.06629436 -0.12306081\n",
      "  0.27612403  0.03946017 -0.28470978  0.1910901  -0.16749615 -0.19848857\n",
      "  0.09779555 -0.47085257]\n",
      "Training Error:  10.325786122613001\n",
      "====================================================================================================\n",
      "Iteration:  449\n",
      "Previous theta :  [-0.00390423 -0.0991106   0.12345268 -0.00294567  0.06629436 -0.12306081\n",
      "  0.27612403  0.03946017 -0.28470978  0.1910901  -0.16749615 -0.19848857\n",
      "  0.09779555 -0.47085257]\n",
      "New theta_0 : [-0.0039     -0.09918588  0.12357341 -0.00301563  0.06627023 -0.12340959\n",
      "  0.27599153  0.03948054 -0.28510826  0.1913158  -0.16755503 -0.19855075\n",
      "  0.09779335 -0.47087485]\n",
      "Training Error:  10.325423189205292\n",
      "====================================================================================================\n",
      "Iteration:  450\n",
      "Previous theta :  [-0.0039     -0.09918588  0.12357341 -0.00301563  0.06627023 -0.12340959\n",
      "  0.27599153  0.03948054 -0.28510826  0.1913158  -0.16755503 -0.19855075\n",
      "  0.09779335 -0.47087485]\n",
      "New theta_0 : [-0.00389579 -0.09926065  0.12369327 -0.00308461  0.06624623 -0.1237561\n",
      "  0.27586021  0.03950081 -0.28550365  0.19154035 -0.16761409 -0.19861252\n",
      "  0.09779121 -0.47089667]\n",
      "Training Error:  10.325065295515813\n",
      "====================================================================================================\n",
      "Iteration:  451\n",
      "Previous theta :  [-0.00389579 -0.09926065  0.12369327 -0.00308461  0.06624623 -0.1237561\n",
      "  0.27586021  0.03950081 -0.28550365  0.19154035 -0.16761409 -0.19861252\n",
      "  0.09779121 -0.47089667]\n",
      "New theta_0 : [-0.00389162 -0.09933492  0.12381227 -0.0031526   0.06622235 -0.12410035\n",
      "  0.27573008  0.03952098 -0.28589599  0.19176378 -0.16767334 -0.19867389\n",
      "  0.09778914 -0.47091803]\n",
      "Training Error:  10.324712367678686\n",
      "====================================================================================================\n",
      "Iteration:  452\n",
      "Previous theta :  [-0.00389162 -0.09933492  0.12381227 -0.0031526   0.06622235 -0.12410035\n",
      "  0.27573008  0.03952098 -0.28589599  0.19176378 -0.16767334 -0.19867389\n",
      "  0.09778914 -0.47091803]\n",
      "New theta_0 : [-0.00388747 -0.0994087   0.12393041 -0.00321963  0.0661986  -0.12444238\n",
      "  0.27560111  0.03954107 -0.28628529  0.19198607 -0.16773278 -0.19873486\n",
      "  0.09778714 -0.47093894]\n",
      "Training Error:  10.324364332943448\n",
      "====================================================================================================\n",
      "Iteration:  453\n",
      "Previous theta :  [-0.00388747 -0.0994087   0.12393041 -0.00321963  0.0661986  -0.12444238\n",
      "  0.27560111  0.03954107 -0.28628529  0.19198607 -0.16773278 -0.19873486\n",
      "  0.09778714 -0.47093894]\n",
      "New theta_0 : [-0.00388336 -0.09948198  0.1240477  -0.00328569  0.06617497 -0.12478218\n",
      "  0.27547329  0.03956106 -0.28667157  0.19220726 -0.16779239 -0.19879544\n",
      "  0.0977852  -0.47095941]\n",
      "Training Error:  10.324021119657843\n",
      "====================================================================================================\n",
      "Iteration:  454\n",
      "Previous theta :  [-0.00388336 -0.09948198  0.1240477  -0.00328569  0.06617497 -0.12478218\n",
      "  0.27547329  0.03956106 -0.28667157  0.19220726 -0.16779239 -0.19879544\n",
      "  0.0977852  -0.47095941]\n",
      "New theta_0 : [-0.00387926 -0.09955477  0.12416415 -0.0033508   0.06615147 -0.12511977\n",
      "  0.27534663  0.03958096 -0.28705488  0.19242733 -0.16785219 -0.19885564\n",
      "  0.09778332 -0.47097944]\n",
      "Training Error:  10.323682657250867\n",
      "====================================================================================================\n",
      "Iteration:  455\n",
      "Previous theta :  [-0.00387926 -0.09955477  0.12416415 -0.0033508   0.06615147 -0.12511977\n",
      "  0.27534663  0.03958096 -0.28705488  0.19242733 -0.16785219 -0.19885564\n",
      "  0.09778332 -0.47097944]\n",
      "New theta_0 : [-0.0038752  -0.09962707  0.12427975 -0.00341496  0.06612808 -0.12545517\n",
      "  0.27522109  0.03960076 -0.28743521  0.1926463  -0.16791216 -0.19891544\n",
      "  0.09778151 -0.47099904]\n",
      "Training Error:  10.323348876216121\n",
      "====================================================================================================\n",
      "Iteration:  456\n",
      "Previous theta :  [-0.0038752  -0.09962707  0.12427975 -0.00341496  0.06612808 -0.12545517\n",
      "  0.27522109  0.03960076 -0.28743521  0.1926463  -0.16791216 -0.19891544\n",
      "  0.09778151 -0.47099904]\n",
      "New theta_0 : [-0.00387116 -0.09969889  0.12439452 -0.00347819  0.06610482 -0.12578838\n",
      "  0.27509668  0.03962047 -0.28781261  0.19286417 -0.1679723  -0.19897487\n",
      "  0.09777976 -0.47101822]\n",
      "Training Error:  10.323019708095387\n",
      "====================================================================================================\n",
      "Iteration:  457\n",
      "Previous theta :  [-0.00387116 -0.09969889  0.12439452 -0.00347819  0.06610482 -0.12578838\n",
      "  0.27509668  0.03962047 -0.28781261  0.19286417 -0.1679723  -0.19897487\n",
      "  0.09777976 -0.47101822]\n",
      "New theta_0 : [-0.00386716 -0.09977023  0.12450847 -0.0035405   0.06608168 -0.12611944\n",
      "  0.27497338  0.03964009 -0.28818708  0.19308095 -0.16803262 -0.19903391\n",
      "  0.09777807 -0.47103697]\n",
      "Training Error:  10.322695085462481\n",
      "====================================================================================================\n",
      "Iteration:  458\n",
      "Previous theta :  [-0.00386716 -0.09977023  0.12450847 -0.0035405   0.06608168 -0.12611944\n",
      "  0.27497338  0.03964009 -0.28818708  0.19308095 -0.16803262 -0.19903391\n",
      "  0.09777807 -0.47103697]\n",
      "New theta_0 : [-0.00386317 -0.09984109  0.12462159 -0.00360189  0.06605866 -0.12644834\n",
      "  0.27485118  0.03965961 -0.28855867  0.19329665 -0.1680931  -0.19909258\n",
      "  0.09777644 -0.47105532]\n",
      "Training Error:  10.322374941907357\n",
      "====================================================================================================\n",
      "Iteration:  459\n",
      "Previous theta :  [-0.00386317 -0.09984109  0.12462159 -0.00360189  0.06605866 -0.12644834\n",
      "  0.27485118  0.03965961 -0.28855867  0.19329665 -0.1680931  -0.19909258\n",
      "  0.09777644 -0.47105532]\n",
      "New theta_0 : [-0.00385922 -0.09991147  0.12473389 -0.00366237  0.06603576 -0.1267751\n",
      "  0.27473007  0.03967903 -0.28892738  0.19351128 -0.16815374 -0.19915088\n",
      "  0.09777487 -0.47107326]\n",
      "Training Error:  10.322059212020461\n",
      "====================================================================================================\n",
      "Iteration:  460\n",
      "Previous theta :  [-0.00385922 -0.09991147  0.12473389 -0.00366237  0.06603576 -0.1267751\n",
      "  0.27473007  0.03967903 -0.28892738  0.19351128 -0.16815374 -0.19915088\n",
      "  0.09777487 -0.47107326]\n",
      "New theta_0 : [-0.00385529 -0.09998138  0.12484539 -0.00372195  0.06601297 -0.12709974\n",
      "  0.27461005  0.03969836 -0.28929324  0.19372484 -0.16821455 -0.1992088\n",
      "  0.09777336 -0.4710908 ]\n",
      "Training Error:  10.321747831377335\n",
      "====================================================================================================\n",
      "Iteration:  461\n",
      "Previous theta :  [-0.00385529 -0.09998138  0.12484539 -0.00372195  0.06601297 -0.12709974\n",
      "  0.27461005  0.03969836 -0.28929324  0.19372484 -0.16821455 -0.1992088\n",
      "  0.09777336 -0.4710908 ]\n",
      "New theta_0 : [-0.00385138 -0.10005082  0.12495608 -0.00378064  0.06599031 -0.12742227\n",
      "  0.27449109  0.03971759 -0.28965627  0.19393734 -0.16827551 -0.19926635\n",
      "  0.09777191 -0.47110795]\n",
      "Training Error:  10.321440736523451\n",
      "====================================================================================================\n",
      "Iteration:  462\n",
      "Previous theta :  [-0.00385138 -0.10005082  0.12495608 -0.00378064  0.06599031 -0.12742227\n",
      "  0.27449109  0.03971759 -0.28965627  0.19393734 -0.16827551 -0.19926635\n",
      "  0.09777191 -0.47110795]\n",
      "New theta_0 : [-0.0038475  -0.1001198   0.12506597 -0.00383846  0.06596776 -0.1277427\n",
      "  0.27437319  0.03973672 -0.2900165   0.19414879 -0.16833663 -0.19932354\n",
      "  0.09777051 -0.47112471]\n",
      "Training Error:  10.321137864959297\n",
      "====================================================================================================\n",
      "Iteration:  463\n",
      "Previous theta :  [-0.0038475  -0.1001198   0.12506597 -0.00383846  0.06596776 -0.1277427\n",
      "  0.27437319  0.03973672 -0.2900165   0.19414879 -0.16833663 -0.19932354\n",
      "  0.09777051 -0.47112471]\n",
      "New theta_0 : [-0.00384365 -0.10018831  0.12517506 -0.0038954   0.06594533 -0.12806105\n",
      "  0.27425635  0.03975576 -0.29037395  0.19435919 -0.1683979  -0.19938037\n",
      "  0.09776917 -0.47114109]\n",
      "Training Error:  10.320839155125693\n",
      "====================================================================================================\n",
      "Iteration:  464\n",
      "Previous theta :  [-0.00384365 -0.10018831  0.12517506 -0.0038954   0.06594533 -0.12806105\n",
      "  0.27425635  0.03975576 -0.29037395  0.19435919 -0.1683979  -0.19938037\n",
      "  0.09776917 -0.47114109]\n",
      "New theta_0 : [-0.00383982 -0.10025637  0.12528337 -0.00395147  0.06592301 -0.12837732\n",
      "  0.27414054  0.0397747  -0.29072863  0.19456854 -0.16845932 -0.19943684\n",
      "  0.09776789 -0.47115709]\n",
      "Training Error:  10.320544546389327\n",
      "====================================================================================================\n",
      "Iteration:  465\n",
      "Previous theta :  [-0.00383982 -0.10025637  0.12528337 -0.00395147  0.06592301 -0.12837732\n",
      "  0.27414054  0.0397747  -0.29072863  0.19456854 -0.16845932 -0.19943684\n",
      "  0.09776789 -0.47115709]\n",
      "New theta_0 : [-0.00383602 -0.10032397  0.1253909  -0.00400669  0.06590081 -0.12869154\n",
      "  0.27402576  0.03979355 -0.29108058  0.19477687 -0.16852089 -0.19949295\n",
      "  0.09776665 -0.47117272]\n",
      "Training Error:  10.320253979028536\n",
      "====================================================================================================\n",
      "Iteration:  466\n",
      "Previous theta :  [-0.00383602 -0.10032397  0.1253909  -0.00400669  0.06590081 -0.12869154\n",
      "  0.27402576  0.03979355 -0.29108058  0.19477687 -0.16852089 -0.19949295\n",
      "  0.09776665 -0.47117272]\n",
      "New theta_0 : [-0.00383224 -0.10039111  0.12549765 -0.00406107  0.06587872 -0.12900372\n",
      "  0.273912    0.03981229 -0.2914298   0.19498417 -0.16858261 -0.19954871\n",
      "  0.09776547 -0.47118799]\n",
      "Training Error:  10.319967394219292\n",
      "====================================================================================================\n",
      "Iteration:  467\n",
      "Previous theta :  [-0.00383224 -0.10039111  0.12549765 -0.00406107  0.06587872 -0.12900372\n",
      "  0.273912    0.03981229 -0.2914298   0.19498417 -0.16858261 -0.19954871\n",
      "  0.09776547 -0.47118799]\n",
      "New theta_0 : [-0.00382848 -0.10045781  0.12560363 -0.0041146   0.06585675 -0.12931386\n",
      "  0.27379926  0.03983094 -0.29177633  0.19519045 -0.16864446 -0.19960411\n",
      "  0.09776435 -0.47120289]\n",
      "Training Error:  10.319684734021429\n",
      "====================================================================================================\n",
      "Iteration:  468\n",
      "Previous theta :  [-0.00382848 -0.10045781  0.12560363 -0.0041146   0.06585675 -0.12931386\n",
      "  0.27379926  0.03983094 -0.29177633  0.19519045 -0.16864446 -0.19960411\n",
      "  0.09776435 -0.47120289]\n",
      "New theta_0 : [-0.00382475 -0.10052406  0.12570885 -0.0041673   0.06583489 -0.12962199\n",
      "  0.27368751  0.03984949 -0.29212019  0.19539571 -0.16870646 -0.19965917\n",
      "  0.09776327 -0.47121745]\n",
      "Training Error:  10.31940594136506\n",
      "====================================================================================================\n",
      "Iteration:  469\n",
      "Previous theta :  [-0.00382475 -0.10052406  0.12570885 -0.0041673   0.06583489 -0.12962199\n",
      "  0.27368751  0.03984949 -0.29212019  0.19539571 -0.16870646 -0.19965917\n",
      "  0.09776327 -0.47121745]\n",
      "New theta_0 : [-0.00382105 -0.10058987  0.1258133  -0.00421919  0.06581314 -0.12992812\n",
      "  0.27357676  0.03986795 -0.29246139  0.19559997 -0.16876859 -0.19971388\n",
      "  0.09776225 -0.47123165]\n",
      "Training Error:  10.319130960037223\n",
      "====================================================================================================\n",
      "Iteration:  470\n",
      "Previous theta :  [-0.00382105 -0.10058987  0.1258133  -0.00421919  0.06581314 -0.12992812\n",
      "  0.27357676  0.03986795 -0.29246139  0.19559997 -0.16876859 -0.19971388\n",
      "  0.09776225 -0.47123165]\n",
      "New theta_0 : [-0.00381737 -0.10065523  0.125917   -0.00427025  0.06579151 -0.13023225\n",
      "  0.27346698  0.0398863  -0.29279995  0.19580322 -0.16883086 -0.19976825\n",
      "  0.09776128 -0.47124551]\n",
      "Training Error:  10.318859734668743\n",
      "====================================================================================================\n",
      "Iteration:  471\n",
      "Previous theta :  [-0.00381737 -0.10065523  0.125917   -0.00427025  0.06579151 -0.13023225\n",
      "  0.27346698  0.0398863  -0.29279995  0.19580322 -0.16883086 -0.19976825\n",
      "  0.09776128 -0.47124551]\n",
      "New theta_0 : [-0.00381371 -0.10072016  0.12601996 -0.00432051  0.06576998 -0.1305344\n",
      "  0.27335818  0.03990456 -0.29313591  0.19600548 -0.16889326 -0.19982228\n",
      "  0.09776036 -0.47125903]\n",
      "Training Error:  10.318592210721274\n",
      "====================================================================================================\n",
      "Iteration:  472\n",
      "Previous theta :  [-0.00381371 -0.10072016  0.12601996 -0.00432051  0.06576998 -0.1305344\n",
      "  0.27335818  0.03990456 -0.29313591  0.19600548 -0.16889326 -0.19982228\n",
      "  0.09776036 -0.47125903]\n",
      "New theta_0 : [-0.00381007 -0.10078465  0.12612216 -0.00436998  0.06574857 -0.13083459\n",
      "  0.27325034  0.03992272 -0.29346926  0.19620676 -0.16895579 -0.19987597\n",
      "  0.09775948 -0.47127222]\n",
      "Training Error:  10.318328334474574\n",
      "====================================================================================================\n",
      "Iteration:  473\n",
      "Previous theta :  [-0.00381007 -0.10078465  0.12612216 -0.00436998  0.06574857 -0.13083459\n",
      "  0.27325034  0.03992272 -0.29346926  0.19620676 -0.16895579 -0.19987597\n",
      "  0.09775948 -0.47127222]\n",
      "New theta_0 : [-0.00380646 -0.10084871  0.12622363 -0.00441865  0.06572727 -0.13113282\n",
      "  0.27314346  0.03994078 -0.29380005  0.19640705 -0.16901845 -0.19992932\n",
      "  0.09775866 -0.47128508]\n",
      "Training Error:  10.318068053013953\n",
      "====================================================================================================\n",
      "Iteration:  474\n",
      "Previous theta :  [-0.00380646 -0.10084871  0.12622363 -0.00441865  0.06572727 -0.13113282\n",
      "  0.27314346  0.03994078 -0.29380005  0.19640705 -0.16901845 -0.19992932\n",
      "  0.09775866 -0.47128508]\n",
      "New theta_0 : [-0.00380288 -0.10091234  0.12632437 -0.00446654  0.06570607 -0.13142911\n",
      "  0.27303752  0.03995874 -0.29412829  0.19660636 -0.16908123 -0.19998235\n",
      "  0.09775788 -0.47129762]\n",
      "Training Error:  10.317811314217932\n",
      "====================================================================================================\n",
      "Iteration:  475\n",
      "Previous theta :  [-0.00380288 -0.10091234  0.12632437 -0.00446654  0.06570607 -0.13142911\n",
      "  0.27303752  0.03995874 -0.29412829  0.19660636 -0.16908123 -0.19998235\n",
      "  0.09775788 -0.47129762]\n",
      "New theta_0 : [-0.00379931 -0.10097555  0.12642438 -0.00451366  0.06568499 -0.13172348\n",
      "  0.27293252  0.03997661 -0.29445399  0.19680471 -0.16914413 -0.20003504\n",
      "  0.09775715 -0.47130984]\n",
      "Training Error:  10.3175580667461\n",
      "====================================================================================================\n",
      "Iteration:  476\n",
      "Previous theta :  [-0.00379931 -0.10097555  0.12642438 -0.00451366  0.06568499 -0.13172348\n",
      "  0.27293252  0.03997661 -0.29445399  0.19680471 -0.16914413 -0.20003504\n",
      "  0.09775715 -0.47130984]\n",
      "New theta_0 : [-0.00379577 -0.10103833  0.12652367 -0.00456     0.06566401 -0.13201592\n",
      "  0.27282845  0.03999438 -0.29477718  0.19700209 -0.16920715 -0.2000874\n",
      "  0.09775646 -0.47132175]\n",
      "Training Error:  10.317308260027142\n",
      "====================================================================================================\n",
      "Iteration:  477\n",
      "Previous theta :  [-0.00379577 -0.10103833  0.12652367 -0.00456     0.06566401 -0.13201592\n",
      "  0.27282845  0.03999438 -0.29477718  0.19700209 -0.16920715 -0.2000874\n",
      "  0.09775646 -0.47132175]\n",
      "New theta_0 : [-0.00379225 -0.10110069  0.12662224 -0.00460559  0.06564314 -0.13230647\n",
      "  0.27272529  0.04001205 -0.29509788  0.19719852 -0.16927029 -0.20013944\n",
      "  0.09775582 -0.47133334]\n",
      "Training Error:  10.317061844247059\n",
      "====================================================================================================\n",
      "Iteration:  478\n",
      "Previous theta :  [-0.00379225 -0.10110069  0.12662224 -0.00460559  0.06564314 -0.13230647\n",
      "  0.27272529  0.04001205 -0.29509788  0.19719852 -0.16927029 -0.20013944\n",
      "  0.09775582 -0.47133334]\n",
      "New theta_0 : [-0.00378875 -0.10116264  0.1267201  -0.00465043  0.06562238 -0.13259512\n",
      "  0.27262304  0.04002962 -0.2954161   0.19739399 -0.16933355 -0.20019115\n",
      "  0.09775522 -0.47134464]\n",
      "Training Error:  10.316818770337596\n",
      "====================================================================================================\n",
      "Iteration:  479\n",
      "Previous theta :  [-0.00378875 -0.10116264  0.1267201  -0.00465043  0.06562238 -0.13259512\n",
      "  0.27262304  0.04002962 -0.2954161   0.19739399 -0.16933355 -0.20019115\n",
      "  0.09775522 -0.47134464]\n",
      "New theta_0 : [-0.00378528 -0.10122416  0.12681725 -0.00469452  0.06560172 -0.1328819\n",
      "  0.2725217   0.04004709 -0.29573187  0.19758852 -0.16939691 -0.20024255\n",
      "  0.09775467 -0.47135563]\n",
      "Training Error:  10.316578989964821\n",
      "====================================================================================================\n",
      "Iteration:  480\n",
      "Previous theta :  [-0.00378528 -0.10122416  0.12681725 -0.00469452  0.06560172 -0.1328819\n",
      "  0.2725217   0.04004709 -0.29573187  0.19758852 -0.16939691 -0.20024255\n",
      "  0.09775467 -0.47135563]\n",
      "New theta_0 : [-0.00378182 -0.10128528  0.1269137  -0.00473788  0.06558117 -0.1331668\n",
      "  0.27242125  0.04006447 -0.2960452   0.19778211 -0.16946039 -0.20029362\n",
      "  0.09775416 -0.47136633]\n",
      "Training Error:  10.316342455517884\n",
      "====================================================================================================\n",
      "Iteration:  481\n",
      "Previous theta :  [-0.00378182 -0.10128528  0.1269137  -0.00473788  0.06558117 -0.1331668\n",
      "  0.27242125  0.04006447 -0.2960452   0.19778211 -0.16946039 -0.20029362\n",
      "  0.09775416 -0.47136633]\n",
      "New theta_0 : [-0.00377839 -0.10134599  0.12700945 -0.0047805   0.06556072 -0.13344985\n",
      "  0.27232168  0.04008174 -0.29635612  0.19797477 -0.16952397 -0.20034438\n",
      "  0.09775369 -0.47137674]\n",
      "Training Error:  10.316109120097973\n",
      "====================================================================================================\n",
      "Iteration:  482\n",
      "Previous theta :  [-0.00377839 -0.10134599  0.12700945 -0.0047805   0.06556072 -0.13344985\n",
      "  0.27232168  0.04008174 -0.29635612  0.19797477 -0.16952397 -0.20034438\n",
      "  0.09775369 -0.47137674]\n",
      "New theta_0 : [-0.00377498 -0.1014063   0.12710452 -0.00482241  0.06554038 -0.13373106\n",
      "  0.27222299  0.04009892 -0.29666465  0.1981665  -0.16958767 -0.20039483\n",
      "  0.09775327 -0.47138687]\n",
      "Training Error:  10.315878937507428\n",
      "====================================================================================================\n",
      "Iteration:  483\n",
      "Previous theta :  [-0.00377498 -0.1014063   0.12710452 -0.00482241  0.06554038 -0.13373106\n",
      "  0.27222299  0.04009892 -0.29666465  0.1981665  -0.16958767 -0.20039483\n",
      "  0.09775327 -0.47138687]\n",
      "New theta_0 : [-0.00377159 -0.1014662   0.12719889 -0.0048636   0.06552014 -0.13401044\n",
      "  0.27212516  0.040116   -0.29697079  0.19835731 -0.16965146 -0.20044497\n",
      "  0.09775289 -0.47139671]\n",
      "Training Error:  10.315651862239017\n",
      "====================================================================================================\n",
      "Iteration:  484\n",
      "Previous theta :  [-0.00377159 -0.1014662   0.12719889 -0.0048636   0.06552014 -0.13401044\n",
      "  0.27212516  0.040116   -0.29697079  0.19835731 -0.16965146 -0.20044497\n",
      "  0.09775289 -0.47139671]\n",
      "New theta_0 : [-0.00376822 -0.10152569  0.12729259 -0.00490408  0.0655     -0.134288\n",
      "  0.2720282   0.04013299 -0.29727457  0.1985472  -0.16971536 -0.20049479\n",
      "  0.09775255 -0.47140628]\n",
      "Training Error:  10.315427849465395\n",
      "====================================================================================================\n",
      "Iteration:  485\n",
      "Previous theta :  [-0.00376822 -0.10152569  0.12729259 -0.00490408  0.0655     -0.134288\n",
      "  0.2720282   0.04013299 -0.29727457  0.1985472  -0.16971536 -0.20049479\n",
      "  0.09775255 -0.47140628]\n",
      "New theta_0 : [-0.00376488 -0.1015848   0.1273856  -0.00494386  0.06547997 -0.13456375\n",
      "  0.27193209  0.04014988 -0.29757602  0.19873618 -0.16977935 -0.20054431\n",
      "  0.09775224 -0.47141557]\n",
      "Training Error:  10.315206855028723\n",
      "====================================================================================================\n",
      "Iteration:  486\n",
      "Previous theta :  [-0.00376488 -0.1015848   0.1273856  -0.00494386  0.06547997 -0.13456375\n",
      "  0.27193209  0.04014988 -0.29757602  0.19873618 -0.16977935 -0.20054431\n",
      "  0.09775224 -0.47141557]\n",
      "New theta_0 : [-0.00376155 -0.1016435   0.12747795 -0.00498295  0.06546004 -0.13483771\n",
      "  0.27183682  0.04016667 -0.29787514  0.19892426 -0.16984344 -0.20059353\n",
      "  0.09775198 -0.4714246 ]\n",
      "Training Error:  10.314988835430437\n",
      "====================================================================================================\n",
      "Iteration:  487\n",
      "Previous theta :  [-0.00376155 -0.1016435   0.12747795 -0.00498295  0.06546004 -0.13483771\n",
      "  0.27183682  0.04016667 -0.29787514  0.19892426 -0.16984344 -0.20059353\n",
      "  0.09775198 -0.4714246 ]\n",
      "New theta_0 : [-0.00375825 -0.10170182  0.12756963 -0.00502135  0.06544021 -0.13510988\n",
      "  0.27174239  0.04018336 -0.29817195  0.19911144 -0.16990763 -0.20064244\n",
      "  0.09775176 -0.47143336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.314773747821189\n",
      "====================================================================================================\n",
      "Iteration:  488\n",
      "Previous theta :  [-0.00375825 -0.10170182  0.12756963 -0.00502135  0.06544021 -0.13510988\n",
      "  0.27174239  0.04018336 -0.29817195  0.19911144 -0.16990763 -0.20064244\n",
      "  0.09775176 -0.47143336]\n",
      "New theta_0 : [-0.00375496 -0.10175974  0.12766065 -0.00505907  0.06542048 -0.13538028\n",
      "  0.27164878  0.04019996 -0.29846648  0.19929773 -0.1699719  -0.20069105\n",
      "  0.09775157 -0.47144186]\n",
      "Training Error:  10.314561549990941\n",
      "====================================================================================================\n",
      "Iteration:  489\n",
      "Previous theta :  [-0.00375496 -0.10175974  0.12766065 -0.00505907  0.06542048 -0.13538028\n",
      "  0.27164878  0.04019996 -0.29846648  0.19929773 -0.1699719  -0.20069105\n",
      "  0.09775157 -0.47144186]\n",
      "New theta_0 : [-0.0037517  -0.10181728  0.12775101 -0.00509611  0.06540085 -0.13564891\n",
      "  0.27155599  0.04021645 -0.29875874  0.19948313 -0.17003627 -0.20073937\n",
      "  0.09775142 -0.47145011]\n",
      "Training Error:  10.314352200359211\n",
      "====================================================================================================\n",
      "Iteration:  490\n",
      "Previous theta :  [-0.0037517  -0.10181728  0.12775101 -0.00509611  0.06540085 -0.13564891\n",
      "  0.27155599  0.04021645 -0.29875874  0.19948313 -0.17003627 -0.20073937\n",
      "  0.09775142 -0.47145011]\n",
      "New theta_0 : [-0.00374846 -0.10187443  0.12784072 -0.00513249  0.06538132 -0.1359158\n",
      "  0.27146402  0.04023286 -0.29904875  0.19966764 -0.17010073 -0.20078738\n",
      "  0.09775131 -0.4714581 ]\n",
      "Training Error:  10.314145657965474\n",
      "====================================================================================================\n",
      "Iteration:  491\n",
      "Previous theta :  [-0.00374846 -0.10187443  0.12784072 -0.00513249  0.06538132 -0.1359158\n",
      "  0.27146402  0.04023286 -0.29904875  0.19966764 -0.17010073 -0.20078738\n",
      "  0.09775131 -0.4714581 ]\n",
      "New theta_0 : [-0.00374523 -0.1019312   0.12792979 -0.00516822  0.06536188 -0.13618095\n",
      "  0.27137285  0.04024916 -0.29933652  0.19985128 -0.17016527 -0.20083511\n",
      "  0.09775124 -0.47146585]\n",
      "Training Error:  10.313941882459705\n",
      "====================================================================================================\n",
      "Iteration:  492\n",
      "Previous theta :  [-0.00374523 -0.1019312   0.12792979 -0.00516822  0.06536188 -0.13618095\n",
      "  0.27137285  0.04024916 -0.29933652  0.19985128 -0.17016527 -0.20083511\n",
      "  0.09775124 -0.47146585]\n",
      "New theta_0 : [-0.00374203 -0.10198759  0.12801821 -0.00520329  0.06534255 -0.13644437\n",
      "  0.27128248  0.04026537 -0.29962208  0.20003405 -0.1702299  -0.20088254\n",
      "  0.0977512  -0.47147335]\n",
      "Training Error:  10.313740834093085\n",
      "====================================================================================================\n",
      "Iteration:  493\n",
      "Previous theta :  [-0.00374203 -0.10198759  0.12801821 -0.00520329  0.06534255 -0.13644437\n",
      "  0.27128248  0.04026537 -0.29962208  0.20003405 -0.1702299  -0.20088254\n",
      "  0.0977512  -0.47147335]\n",
      "New theta_0 : [-0.00373885 -0.10204361  0.12810599 -0.00523771  0.06532332 -0.13670608\n",
      "  0.2711929   0.04028149 -0.29990544  0.20021596 -0.17029461 -0.20092969\n",
      "  0.0977512  -0.47148062]\n",
      "Training Error:  10.313542473708825\n",
      "====================================================================================================\n",
      "Iteration:  494\n",
      "Previous theta :  [-0.00373885 -0.10204361  0.12810599 -0.00523771  0.06532332 -0.13670608\n",
      "  0.2711929   0.04028149 -0.29990544  0.20021596 -0.17029461 -0.20092969\n",
      "  0.0977512  -0.47148062]\n",
      "New theta_0 : [-0.00373568 -0.10209925  0.12819314 -0.00527149  0.06530418 -0.13696608\n",
      "  0.2711041   0.04029751 -0.30018662  0.200397   -0.17035939 -0.20097654\n",
      "  0.09775123 -0.47148764]\n",
      "Training Error:  10.31334676273316\n",
      "====================================================================================================\n",
      "Iteration:  495\n",
      "Previous theta :  [-0.00373568 -0.10209925  0.12819314 -0.00527149  0.06530418 -0.13696608\n",
      "  0.2711041   0.04029751 -0.30018662  0.200397   -0.17035939 -0.20097654\n",
      "  0.09775123 -0.47148764]\n",
      "New theta_0 : [-0.00373254 -0.10215452  0.12827966 -0.00530464  0.06528514 -0.13722438\n",
      "  0.27101607  0.04031343 -0.30046563  0.20057719 -0.17042426 -0.20102311\n",
      "  0.0977513  -0.47149443]\n",
      "Training Error:  10.313153663166462\n",
      "====================================================================================================\n",
      "Iteration:  496\n",
      "Previous theta :  [-0.00373254 -0.10215452  0.12827966 -0.00530464  0.06528514 -0.13722438\n",
      "  0.27101607  0.04031343 -0.30046563  0.20057719 -0.17042426 -0.20102311\n",
      "  0.0977513  -0.47149443]\n",
      "New theta_0 : [-0.00372941 -0.10220942  0.12836556 -0.00533717  0.06526619 -0.13748101\n",
      "  0.27092882  0.04032926 -0.3007425   0.20075653 -0.1704892  -0.2010694\n",
      "  0.0977514  -0.471501  ]\n",
      "Training Error:  10.312963137574513\n",
      "====================================================================================================\n",
      "Iteration:  497\n",
      "Previous theta :  [-0.00372941 -0.10220942  0.12836556 -0.00533717  0.06526619 -0.13748101\n",
      "  0.27092882  0.04032926 -0.3007425   0.20075653 -0.1704892  -0.2010694\n",
      "  0.0977514  -0.471501  ]\n",
      "New theta_0 : [-0.0037263  -0.10226396  0.12845084 -0.00536907  0.06524734 -0.13773596\n",
      "  0.27084232  0.04034499 -0.30101723  0.20093502 -0.17055422 -0.20111541\n",
      "  0.09775153 -0.47150734]\n",
      "Training Error:  10.31277514907988\n",
      "====================================================================================================\n",
      "Iteration:  498\n",
      "Previous theta :  [-0.0037263  -0.10226396  0.12845084 -0.00536907  0.06524734 -0.13773596\n",
      "  0.27084232  0.04034499 -0.30101723  0.20093502 -0.17055422 -0.20111541\n",
      "  0.09775153 -0.47150734]\n",
      "New theta_0 : [-0.00372321 -0.10231813  0.1285355  -0.00540036  0.06522859 -0.13798925\n",
      "  0.27075658  0.04036063 -0.30128985  0.20111268 -0.1706193  -0.20116113\n",
      "  0.0977517  -0.47151345]\n",
      "Training Error:  10.312589661353464\n",
      "====================================================================================================\n",
      "Iteration:  499\n",
      "Previous theta :  [-0.00372321 -0.10231813  0.1285355  -0.00540036  0.06522859 -0.13798925\n",
      "  0.27075658  0.04036063 -0.30128985  0.20111268 -0.1706193  -0.20116113\n",
      "  0.0977517  -0.47151345]\n",
      "New theta_0 : [-0.00372015 -0.10237194  0.12861956 -0.00543105  0.06520993 -0.13824089\n",
      "  0.27067158  0.04037617 -0.30156038  0.2012895  -0.17068446 -0.20120658\n",
      "  0.09775189 -0.47151935]\n",
      "Training Error:  10.312406638606138\n",
      "====================================================================================================\n",
      "Iteration:  500\n",
      "Previous theta :  [-0.00372015 -0.10237194  0.12861956 -0.00543105  0.06520993 -0.13824089\n",
      "  0.27067158  0.04037617 -0.30156038  0.2012895  -0.17068446 -0.20120658\n",
      "  0.09775189 -0.47151935]\n",
      "New theta_0 : [-0.00371709 -0.10242539  0.12870301 -0.00546113  0.06519136 -0.13849089\n",
      "  0.27058732  0.04039163 -0.30182882  0.20146549 -0.17074969 -0.20125176\n",
      "  0.09775212 -0.47152504]\n",
      "Training Error:  10.312226045580559\n",
      "====================================================================================================\n",
      "Iteration:  501\n",
      "Previous theta :  [-0.00371709 -0.10242539  0.12870301 -0.00546113  0.06519136 -0.13849089\n",
      "  0.27058732  0.04039163 -0.30182882  0.20146549 -0.17074969 -0.20125176\n",
      "  0.09775212 -0.47152504]\n",
      "New theta_0 : [-0.00371406 -0.10247849  0.12878586 -0.00549062  0.06517289 -0.13873926\n",
      "  0.2705038   0.04040698 -0.30209519  0.20164066 -0.17081498 -0.20129666\n",
      "  0.09775239 -0.47153051]\n",
      "Training Error:  10.312047847543067\n",
      "====================================================================================================\n",
      "Iteration:  502\n",
      "Previous theta :  [-0.00371406 -0.10247849  0.12878586 -0.00549062  0.06517289 -0.13873926\n",
      "  0.2705038   0.04040698 -0.30209519  0.20164066 -0.17081498 -0.20129666\n",
      "  0.09775239 -0.47153051]\n",
      "New theta_0 : [-0.00371105 -0.10253123  0.12886811 -0.00551952  0.06515451 -0.13898601\n",
      "  0.270421    0.04042224 -0.30235952  0.201815   -0.17088033 -0.20134129\n",
      "  0.09775268 -0.47153577]\n",
      "Training Error:  10.311872010275733\n",
      "====================================================================================================\n",
      "Iteration:  503\n",
      "Previous theta :  [-0.00371105 -0.10253123  0.12886811 -0.00551952  0.06515451 -0.13898601\n",
      "  0.270421    0.04042224 -0.30235952  0.201815   -0.17088033 -0.20134129\n",
      "  0.09775268 -0.47153577]\n",
      "New theta_0 : [-0.00370805 -0.10258362  0.12894977 -0.00554783  0.06513622 -0.13923115\n",
      "  0.27033892  0.04043741 -0.30262181  0.20198854 -0.17094575 -0.20138565\n",
      "  0.097753   -0.47154083]\n",
      "Training Error:  10.311698500068525\n",
      "====================================================================================================\n",
      "Iteration:  504\n",
      "Previous theta :  [-0.00370805 -0.10258362  0.12894977 -0.00554783  0.06513622 -0.13923115\n",
      "  0.27033892  0.04043741 -0.30262181  0.20198854 -0.17094575 -0.20138565\n",
      "  0.097753   -0.47154083]\n",
      "New theta_0 : [-0.00370507 -0.10263566  0.12903084 -0.00557557  0.06511803 -0.1394747\n",
      "  0.27025755  0.04045249 -0.30288208  0.20216126 -0.17101123 -0.20142974\n",
      "  0.09775335 -0.47154569]\n",
      "Training Error:  10.311527283711587\n",
      "====================================================================================================\n",
      "Iteration:  505\n",
      "Previous theta :  [-0.00370507 -0.10263566  0.12903084 -0.00557557  0.06511803 -0.1394747\n",
      "  0.27025755  0.04045249 -0.30288208  0.20216126 -0.17101123 -0.20142974\n",
      "  0.09775335 -0.47154569]\n",
      "New theta_0 : [-0.00370211 -0.10268736  0.12911133 -0.00560274  0.06509992 -0.13971666\n",
      "  0.27017689  0.04046747 -0.30314036  0.20233319 -0.17107677 -0.20147356\n",
      "  0.09775373 -0.47155035]\n",
      "Training Error:  10.311358328487653\n",
      "====================================================================================================\n",
      "Iteration:  506\n",
      "Previous theta :  [-0.00370211 -0.10268736  0.12911133 -0.00560274  0.06509992 -0.13971666\n",
      "  0.27017689  0.04046747 -0.30314036  0.20233319 -0.17107677 -0.20147356\n",
      "  0.09775373 -0.47155035]\n",
      "New theta_0 : [-0.00369917 -0.10273871  0.12919124 -0.00562934  0.06508191 -0.13995704\n",
      "  0.27009693  0.04048237 -0.30339664  0.20250431 -0.17114236 -0.20151712\n",
      "  0.09775414 -0.47155482]\n",
      "Training Error:  10.311191602164559\n",
      "====================================================================================================\n",
      "Iteration:  507\n",
      "Previous theta :  [-0.00369917 -0.10273871  0.12919124 -0.00562934  0.06508191 -0.13995704\n",
      "  0.27009693  0.04048237 -0.30339664  0.20250431 -0.17114236 -0.20151712\n",
      "  0.09775414 -0.47155482]\n",
      "New theta_0 : [-0.00369625 -0.10278972  0.12927057 -0.00565538  0.06506398 -0.14019586\n",
      "  0.27001766  0.04049717 -0.30365096  0.20267464 -0.17120801 -0.20156042\n",
      "  0.09775458 -0.4715591 ]\n",
      "Training Error:  10.31102707298789\n",
      "====================================================================================================\n",
      "Iteration:  508\n",
      "Previous theta :  [-0.00369625 -0.10278972  0.12927057 -0.00565538  0.06506398 -0.14019586\n",
      "  0.27001766  0.04049717 -0.30365096  0.20267464 -0.17120801 -0.20156042\n",
      "  0.09775458 -0.4715591 ]\n",
      "New theta_0 : [-0.00369334 -0.10284039  0.12934934 -0.00568087  0.06504615 -0.14043312\n",
      "  0.26993907  0.04051188 -0.30390332  0.20284418 -0.17127371 -0.20160346\n",
      "  0.09775505 -0.47156318]\n",
      "Training Error:  10.310864709673734\n",
      "====================================================================================================\n",
      "Iteration:  509\n",
      "Previous theta :  [-0.00369334 -0.10284039  0.12934934 -0.00568087  0.06504615 -0.14043312\n",
      "  0.26993907  0.04051188 -0.30390332  0.20284418 -0.17127371 -0.20160346\n",
      "  0.09775505 -0.47156318]\n",
      "New theta_0 : [-0.00369045 -0.10289072  0.12942754 -0.00570582  0.06502841 -0.14066883\n",
      "  0.26986117  0.04052649 -0.30415374  0.20301293 -0.17133947 -0.20164624\n",
      "  0.09775554 -0.47156708]\n",
      "Training Error:  10.310704481401535\n",
      "====================================================================================================\n",
      "Iteration:  510\n",
      "Previous theta :  [-0.00369045 -0.10289072  0.12942754 -0.00570582  0.06502841 -0.14066883\n",
      "  0.26986117  0.04052649 -0.30415374  0.20301293 -0.17133947 -0.20164624\n",
      "  0.09775554 -0.47156708]\n",
      "New theta_0 : [-0.00368758 -0.10294072  0.12950517 -0.00573022  0.06501075 -0.14090301\n",
      "  0.26978394  0.04054102 -0.30440224  0.20318091 -0.17140527 -0.20168876\n",
      "  0.09775606 -0.4715708 ]\n",
      "Training Error:  10.310546357807073\n",
      "====================================================================================================\n",
      "Iteration:  511\n",
      "Previous theta :  [-0.00368758 -0.10294072  0.12950517 -0.00573022  0.06501075 -0.14090301\n",
      "  0.26978394  0.04054102 -0.30440224  0.20318091 -0.17140527 -0.20168876\n",
      "  0.09775606 -0.4715708 ]\n",
      "New theta_0 : [-0.00368472 -0.10299038  0.12958225 -0.00575408  0.06499318 -0.14113566\n",
      "  0.26970738  0.04055545 -0.30464882  0.20334811 -0.17147112 -0.20173103\n",
      "  0.09775661 -0.47157434]\n",
      "Training Error:  10.310390308975549\n",
      "====================================================================================================\n",
      "Iteration:  512\n",
      "Previous theta :  [-0.00368472 -0.10299038  0.12958225 -0.00575408  0.06499318 -0.14113566\n",
      "  0.26970738  0.04055545 -0.30464882  0.20334811 -0.17147112 -0.20173103\n",
      "  0.09775661 -0.47157434]\n",
      "New theta_0 : [-0.00368188 -0.10303972  0.12965878 -0.00577742  0.0649757  -0.14136679\n",
      "  0.26963148  0.0405698  -0.30489351  0.20351453 -0.17153702 -0.20177304\n",
      "  0.09775718 -0.4715777 ]\n",
      "Training Error:  10.310236305434774\n",
      "====================================================================================================\n",
      "Iteration:  513\n",
      "Previous theta :  [-0.00368188 -0.10303972  0.12965878 -0.00577742  0.0649757  -0.14136679\n",
      "  0.26963148  0.0405698  -0.30489351  0.20351453 -0.17153702 -0.20177304\n",
      "  0.09775718 -0.4715777 ]\n",
      "New theta_0 : [-0.00367906 -0.10308873  0.12973475 -0.00580023  0.06495831 -0.14159642\n",
      "  0.26955623  0.04058406 -0.30513632  0.2036802  -0.17160297 -0.2018148\n",
      "  0.09775778 -0.47158089]\n",
      "Training Error:  10.310084318148458\n",
      "====================================================================================================\n",
      "Iteration:  514\n",
      "Previous theta :  [-0.00367906 -0.10308873  0.12973475 -0.00580023  0.06495831 -0.14159642\n",
      "  0.26955623  0.04058406 -0.30513632  0.2036802  -0.17160297 -0.2018148\n",
      "  0.09775778 -0.47158089]\n",
      "New theta_0 : [-0.00367625 -0.10313741  0.12981018 -0.00582252  0.064941   -0.14182455\n",
      "  0.26948163  0.04059822 -0.30537727  0.2038451  -0.17166895 -0.20185632\n",
      "  0.09775841 -0.47158391]\n",
      "Training Error:  10.309934318509615\n",
      "====================================================================================================\n",
      "Iteration:  515\n",
      "Previous theta :  [-0.00367625 -0.10313741  0.12981018 -0.00582252  0.064941   -0.14182455\n",
      "  0.26948163  0.04059822 -0.30537727  0.2038451  -0.17166895 -0.20185632\n",
      "  0.09775841 -0.47158391]\n",
      "New theta_0 : [-0.00367346 -0.10318577  0.12988507 -0.00584429  0.06492378 -0.14205119\n",
      "  0.26940768  0.0406123  -0.30561636  0.20400924 -0.17173498 -0.20189758\n",
      "  0.09775906 -0.47158676]\n",
      "Training Error:  10.309786278334057\n",
      "====================================================================================================\n",
      "Iteration:  516\n",
      "Previous theta :  [-0.00367346 -0.10318577  0.12988507 -0.00584429  0.06492378 -0.14205119\n",
      "  0.26940768  0.0406123  -0.30561636  0.20400924 -0.17173498 -0.20189758\n",
      "  0.09775906 -0.47158676]\n",
      "New theta_0 : [-0.00367069 -0.10323381  0.12995943 -0.00586556  0.06490664 -0.14227636\n",
      "  0.26933436  0.04062629 -0.30585362  0.20417264 -0.17180104 -0.2019386\n",
      "  0.09775973 -0.47158945]\n",
      "Training Error:  10.309640169854003\n",
      "====================================================================================================\n",
      "Iteration:  517\n",
      "Previous theta :  [-0.00367069 -0.10323381  0.12995943 -0.00586556  0.06490664 -0.14227636\n",
      "  0.26933436  0.04062629 -0.30585362  0.20417264 -0.17180104 -0.2019386\n",
      "  0.09775973 -0.47158945]\n",
      "New theta_0 : [-0.00366793 -0.10328153  0.13003325 -0.00588632  0.06488959 -0.14250005\n",
      "  0.26926167  0.04064019 -0.30608905  0.20433528 -0.17186715 -0.20197937\n",
      "  0.09776043 -0.47159197]\n",
      "Training Error:  10.309495965711761\n",
      "====================================================================================================\n",
      "Iteration:  518\n",
      "Previous theta :  [-0.00366793 -0.10328153  0.13003325 -0.00588632  0.06488959 -0.14250005\n",
      "  0.26926167  0.04064019 -0.30608905  0.20433528 -0.17186715 -0.20197937\n",
      "  0.09776043 -0.47159197]\n",
      "New theta_0 : [-0.00366519 -0.10332893  0.13010654 -0.00590659  0.06487263 -0.14272229\n",
      "  0.26918961  0.040654   -0.30632268  0.20449719 -0.17193329 -0.2020199\n",
      "  0.09776115 -0.47159434]\n",
      "Training Error:  10.309353638953548\n",
      "====================================================================================================\n",
      "Iteration:  519\n",
      "Previous theta :  [-0.00366519 -0.10332893  0.13010654 -0.00590659  0.06487263 -0.14272229\n",
      "  0.26918961  0.040654   -0.30632268  0.20449719 -0.17193329 -0.2020199\n",
      "  0.09776115 -0.47159434]\n",
      "New theta_0 : [-0.00366247 -0.10337602  0.1301793  -0.00592636  0.06485575 -0.14294309\n",
      "  0.26911817  0.04066773 -0.30655451  0.20465835 -0.17199947 -0.20206019\n",
      "  0.09776189 -0.47159655]\n",
      "Training Error:  10.309213163023356\n",
      "====================================================================================================\n",
      "Iteration:  520\n",
      "Previous theta :  [-0.00366247 -0.10337602  0.1301793  -0.00592636  0.06485575 -0.14294309\n",
      "  0.26911817  0.04066773 -0.30655451  0.20465835 -0.17199947 -0.20206019\n",
      "  0.09776189 -0.47159655]\n",
      "New theta_0 : [-0.00365976 -0.10342279  0.13025154 -0.00594564  0.06483895 -0.14316244\n",
      "  0.26904734  0.04068136 -0.30678456  0.20481878 -0.17206568 -0.20210023\n",
      "  0.09776266 -0.4715986 ]\n",
      "Training Error:  10.309074511756961\n",
      "====================================================================================================\n",
      "Iteration:  521\n",
      "Previous theta :  [-0.00365976 -0.10342279  0.13025154 -0.00594564  0.06483895 -0.14316244\n",
      "  0.26904734  0.04068136 -0.30678456  0.20481878 -0.17206568 -0.20210023\n",
      "  0.09776266 -0.4715986 ]\n",
      "New theta_0 : [-0.00365706 -0.10346926  0.13032327 -0.00596445  0.06482223 -0.14338036\n",
      "  0.26897712  0.04069492 -0.30701284  0.20497848 -0.17213192 -0.20214004\n",
      "  0.09776345 -0.4716005 ]\n",
      "Training Error:  10.30893765937598\n",
      "====================================================================================================\n",
      "Iteration:  522\n",
      "Previous theta :  [-0.00365706 -0.10346926  0.13032327 -0.00596445  0.06482223 -0.14338036\n",
      "  0.26897712  0.04069492 -0.30701284  0.20497848 -0.17213192 -0.20214004\n",
      "  0.09776345 -0.4716005 ]\n",
      "New theta_0 : [-0.00365438 -0.10351542  0.13039448 -0.00598277  0.0648056  -0.14359686\n",
      "  0.2689075   0.04070838 -0.30723937  0.20513745 -0.17219819 -0.20217961\n",
      "  0.09776426 -0.47160226]\n",
      "Training Error:  10.308802580482054\n",
      "====================================================================================================\n",
      "Iteration:  523\n",
      "Previous theta :  [-0.00365438 -0.10351542  0.13039448 -0.00598277  0.0648056  -0.14359686\n",
      "  0.2689075   0.04070838 -0.30723937  0.20513745 -0.17219819 -0.20217961\n",
      "  0.09776426 -0.47160226]\n",
      "New theta_0 : [-0.00365172 -0.10356127  0.13046519 -0.00600062  0.06478905 -0.14381195\n",
      "  0.26883848  0.04072176 -0.30746416  0.2052957  -0.17226449 -0.20221895\n",
      "  0.09776509 -0.47160386]\n",
      "Training Error:  10.308669250051103\n",
      "====================================================================================================\n",
      "Iteration:  524\n",
      "Previous theta :  [-0.00365172 -0.10356127  0.13046519 -0.00600062  0.06478905 -0.14381195\n",
      "  0.26883848  0.04072176 -0.30746416  0.2052957  -0.17226449 -0.20221895\n",
      "  0.09776509 -0.47160386]\n",
      "New theta_0 : [-0.00364907 -0.10360682  0.13053538 -0.00601801  0.06477258 -0.14402564\n",
      "  0.26877006  0.04073505 -0.30768723  0.20545324 -0.17233081 -0.20225805\n",
      "  0.09776595 -0.47160533]\n",
      "Training Error:  10.308537643427677\n",
      "====================================================================================================\n",
      "Iteration:  525\n",
      "Previous theta :  [-0.00364907 -0.10360682  0.13053538 -0.00601801  0.06477258 -0.14402564\n",
      "  0.26877006  0.04073505 -0.30768723  0.20545324 -0.17233081 -0.20225805\n",
      "  0.09776595 -0.47160533]\n",
      "New theta_0 : [-0.00364644 -0.10365207  0.13060508 -0.00603493  0.06475619 -0.14423793\n",
      "  0.26870221  0.04074826 -0.30790858  0.20561006 -0.17239716 -0.20229692\n",
      "  0.09776682 -0.47160665]\n",
      "Training Error:  10.308407736319385\n",
      "====================================================================================================\n",
      "Iteration:  526\n",
      "Previous theta :  [-0.00364644 -0.10365207  0.13060508 -0.00603493  0.06475619 -0.14423793\n",
      "  0.26870221  0.04074826 -0.30790858  0.20561006 -0.17239716 -0.20229692\n",
      "  0.09776682 -0.47160665]\n",
      "New theta_0 : [-0.00364382 -0.10369701  0.13067428 -0.0060514   0.06473989 -0.14444884\n",
      "  0.26863495  0.04076138 -0.30812823  0.20576618 -0.17246354 -0.20233556\n",
      "  0.09776772 -0.47160783]\n",
      "Training Error:  10.308279504791415\n",
      "====================================================================================================\n",
      "Iteration:  527\n",
      "Previous theta :  [-0.00364382 -0.10369701  0.13067428 -0.0060514   0.06473989 -0.14444884\n",
      "  0.26863495  0.04076138 -0.30812823  0.20576618 -0.17246354 -0.20233556\n",
      "  0.09776772 -0.47160783]\n",
      "New theta_0 : [-0.00364122 -0.10374167  0.13074298 -0.00606741  0.06472366 -0.14465838\n",
      "  0.26856826  0.04077442 -0.3083462   0.20592159 -0.17252994 -0.20237397\n",
      "  0.09776864 -0.47160888]\n",
      "Training Error:  10.308152925261137\n",
      "====================================================================================================\n",
      "Iteration:  528\n",
      "Previous theta :  [-0.00364122 -0.10374167  0.13074298 -0.00606741  0.06472366 -0.14465838\n",
      "  0.26856826  0.04077442 -0.3083462   0.20592159 -0.17252994 -0.20237397\n",
      "  0.09776864 -0.47160888]\n",
      "New theta_0 : [-0.00363863 -0.10378602  0.13081119 -0.00608298  0.06470752 -0.14486655\n",
      "  0.26850215  0.04078738 -0.3085625   0.2060763  -0.17259636 -0.20241216\n",
      "  0.09776957 -0.47160979]\n",
      "Training Error:  10.308027974492807\n",
      "====================================================================================================\n",
      "Iteration:  529\n",
      "Previous theta :  [-0.00363863 -0.10378602  0.13081119 -0.00608298  0.06470752 -0.14486655\n",
      "  0.26850215  0.04078738 -0.3085625   0.2060763  -0.17259636 -0.20241216\n",
      "  0.09776957 -0.47160979]\n",
      "New theta_0 : [-0.00363606 -0.10383008  0.13087892 -0.0060981   0.06469145 -0.14507336\n",
      "  0.2684366   0.04080025 -0.30877713  0.20623031 -0.17266279 -0.20245011\n",
      "  0.09777053 -0.47161057]\n",
      "Training Error:  10.307904629592306\n",
      "====================================================================================================\n",
      "Iteration:  530\n",
      "Previous theta :  [-0.00363606 -0.10383008  0.13087892 -0.0060981   0.06469145 -0.14507336\n",
      "  0.2684366   0.04080025 -0.30877713  0.20623031 -0.17266279 -0.20245011\n",
      "  0.09777053 -0.47161057]\n",
      "New theta_0 : [-0.0036335  -0.10387385  0.13094616 -0.00611279  0.06467546 -0.14527883\n",
      "  0.26837161  0.04081304 -0.30899012  0.20638363 -0.17272925 -0.20248784\n",
      "  0.0977715  -0.47161122]\n",
      "Training Error:  10.307782868002015\n",
      "====================================================================================================\n",
      "Iteration:  531\n",
      "Previous theta :  [-0.0036335  -0.10387385  0.13094616 -0.00611279  0.06467546 -0.14527883\n",
      "  0.26837161  0.04081304 -0.30899012  0.20638363 -0.17272925 -0.20248784\n",
      "  0.0977715  -0.47161122]\n",
      "New theta_0 : [-0.00363096 -0.10391734  0.13101292 -0.00612704  0.06465955 -0.14548295\n",
      "  0.26830717  0.04082575 -0.30920148  0.20653627 -0.17279572 -0.20252535\n",
      "  0.0977725  -0.47161174]\n",
      "Training Error:  10.307662667495727\n",
      "====================================================================================================\n",
      "Iteration:  532\n",
      "Previous theta :  [-0.00363096 -0.10391734  0.13101292 -0.00612704  0.06465955 -0.14548295\n",
      "  0.26830717  0.04082575 -0.30920148  0.20653627 -0.17279572 -0.20252535\n",
      "  0.0977725  -0.47161174]\n",
      "New theta_0 : [-0.00362843 -0.10396053  0.13107921 -0.00614086  0.06464372 -0.14568575\n",
      "  0.26824328  0.04083837 -0.30941121  0.20668822 -0.17286221 -0.20256264\n",
      "  0.09777351 -0.47161214]\n",
      "Training Error:  10.307544006173668\n",
      "====================================================================================================\n",
      "Iteration:  533\n",
      "Previous theta :  [-0.00362843 -0.10396053  0.13107921 -0.00614086  0.06464372 -0.14568575\n",
      "  0.26824328  0.04083837 -0.30941121  0.20668822 -0.17286221 -0.20256264\n",
      "  0.09777351 -0.47161214]\n",
      "New theta_0 : [-0.00362591 -0.10400344  0.13114502 -0.00615426  0.06462797 -0.14588722\n",
      "  0.26817994  0.04085091 -0.30961933  0.20683949 -0.17292871 -0.20259971\n",
      "  0.09777454 -0.47161242]\n",
      "Training Error:  10.307426862457556\n",
      "====================================================================================================\n",
      "Iteration:  534\n",
      "Previous theta :  [-0.00362591 -0.10400344  0.13114502 -0.00615426  0.06462797 -0.14588722\n",
      "  0.26817994  0.04085091 -0.30961933  0.20683949 -0.17292871 -0.20259971\n",
      "  0.09777454 -0.47161242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00362341 -0.10404607  0.13121036 -0.00616724  0.06461229 -0.14608738\n",
      "  0.26811713  0.04086337 -0.30982586  0.20699009 -0.17299523 -0.20263656\n",
      "  0.09777559 -0.47161257]\n",
      "Training Error:  10.30731121508579\n",
      "====================================================================================================\n",
      "Iteration:  535\n",
      "Previous theta :  [-0.00362341 -0.10404607  0.13121036 -0.00616724  0.06461229 -0.14608738\n",
      "  0.26811713  0.04086337 -0.30982586  0.20699009 -0.17299523 -0.20263656\n",
      "  0.09777559 -0.47161257]\n",
      "New theta_0 : [-0.00362093 -0.10408841  0.13127524 -0.00617981  0.06459669 -0.14628623\n",
      "  0.26805486  0.04087576 -0.3100308   0.20714001 -0.17306176 -0.20267319\n",
      "  0.09777665 -0.47161261]\n",
      "Training Error:  10.307197043108658\n",
      "====================================================================================================\n",
      "Iteration:  536\n",
      "Previous theta :  [-0.00362093 -0.10408841  0.13127524 -0.00617981  0.06459669 -0.14628623\n",
      "  0.26805486  0.04087576 -0.3100308   0.20714001 -0.17306176 -0.20267319\n",
      "  0.09777665 -0.47161261]\n",
      "New theta_0 : [-0.00361845 -0.10413048  0.13133966 -0.00619196  0.06458117 -0.14648379\n",
      "  0.26799313  0.04088805 -0.31023418  0.20728926 -0.17312829 -0.2027096\n",
      "  0.09777774 -0.47161253]\n",
      "Training Error:  10.307084325883654\n",
      "====================================================================================================\n",
      "Iteration:  537\n",
      "Previous theta :  [-0.00361845 -0.10413048  0.13133966 -0.00619196  0.06458117 -0.14648379\n",
      "  0.26799313  0.04088805 -0.31023418  0.20728926 -0.17312829 -0.2027096\n",
      "  0.09777774 -0.47161253]\n",
      "New theta_0 : [-0.00361599 -0.10417227  0.13140362 -0.00620371  0.06456572 -0.14668006\n",
      "  0.26793191  0.04090027 -0.31043599  0.20743786 -0.17319483 -0.2027458\n",
      "  0.09777884 -0.47161233]\n",
      "Training Error:  10.306973043070847\n",
      "====================================================================================================\n",
      "Iteration:  538\n",
      "Previous theta :  [-0.00361599 -0.10417227  0.13140362 -0.00620371  0.06456572 -0.14668006\n",
      "  0.26793191  0.04090027 -0.31043599  0.20743786 -0.17319483 -0.2027458\n",
      "  0.09777884 -0.47161233]\n",
      "New theta_0 : [-0.00361355 -0.10421378  0.13146712 -0.00621506  0.06455035 -0.14687505\n",
      "  0.26787122  0.04091242 -0.31063625  0.20758579 -0.17326139 -0.20278179\n",
      "  0.09777995 -0.47161203]\n",
      "Training Error:  10.306863174628342\n",
      "====================================================================================================\n",
      "Iteration:  539\n",
      "Previous theta :  [-0.00361355 -0.10421378  0.13146712 -0.00621506  0.06455035 -0.14687505\n",
      "  0.26787122  0.04091242 -0.31063625  0.20758579 -0.17326139 -0.20278179\n",
      "  0.09777995 -0.47161203]\n",
      "New theta_0 : [-0.00361112 -0.10425502  0.13153018 -0.00622601  0.06453505 -0.14706877\n",
      "  0.26781104  0.04092448 -0.31083498  0.20773306 -0.17332794 -0.20281757\n",
      "  0.09778109 -0.47161161]\n",
      "Training Error:  10.306754700807785\n",
      "====================================================================================================\n",
      "Iteration:  540\n",
      "Previous theta :  [-0.00361112 -0.10425502  0.13153018 -0.00622601  0.06453505 -0.14706877\n",
      "  0.26781104  0.04092448 -0.31083498  0.20773306 -0.17332794 -0.20281757\n",
      "  0.09778109 -0.47161161]\n",
      "New theta_0 : [-0.0036087  -0.10429599  0.13159278 -0.00623657  0.06451982 -0.14726123\n",
      "  0.26775137  0.04093646 -0.31103219  0.20787968 -0.1733945  -0.20285313\n",
      "  0.09778224 -0.47161108]\n",
      "Training Error:  10.306647602149962\n",
      "====================================================================================================\n",
      "Iteration:  541\n",
      "Previous theta :  [-0.0036087  -0.10429599  0.13159278 -0.00623657  0.06451982 -0.14726123\n",
      "  0.26775137  0.04093646 -0.31103219  0.20787968 -0.1733945  -0.20285313\n",
      "  0.09778224 -0.47161108]\n",
      "New theta_0 : [-0.00360629 -0.10433668  0.13165494 -0.00624673  0.06450468 -0.14745243\n",
      "  0.26769221  0.04094836 -0.31122789  0.20802566 -0.17346107 -0.20288849\n",
      "  0.0977834  -0.47161045]\n",
      "Training Error:  10.306541859480436\n",
      "====================================================================================================\n",
      "Iteration:  542\n",
      "Previous theta :  [-0.00360629 -0.10433668  0.13165494 -0.00624673  0.06450468 -0.14745243\n",
      "  0.26769221  0.04094836 -0.31122789  0.20802566 -0.17346107 -0.20288849\n",
      "  0.0977834  -0.47161045]\n",
      "New theta_0 : [-0.0036039  -0.10437712  0.13171666 -0.00625652  0.0644896  -0.14764239\n",
      "  0.26763354  0.04096019 -0.31142208  0.20817099 -0.17352763 -0.20292364\n",
      "  0.09778458 -0.47160972]\n",
      "Training Error:  10.306437453905291\n",
      "====================================================================================================\n",
      "Iteration:  543\n",
      "Previous theta :  [-0.0036039  -0.10437712  0.13171666 -0.00625652  0.0644896  -0.14764239\n",
      "  0.26763354  0.04096019 -0.31142208  0.20817099 -0.17352763 -0.20292364\n",
      "  0.09778458 -0.47160972]\n",
      "New theta_0 : [-0.00360152 -0.10441728  0.13177794 -0.00626592  0.0644746  -0.14783111\n",
      "  0.26757538  0.04097194 -0.31161479  0.20831567 -0.1735942  -0.20295858\n",
      "  0.09778578 -0.47160888]\n",
      "Training Error:  10.306334366806896\n",
      "====================================================================================================\n",
      "Iteration:  544\n",
      "Previous theta :  [-0.00360152 -0.10441728  0.13177794 -0.00626592  0.0644746  -0.14783111\n",
      "  0.26757538  0.04097194 -0.31161479  0.20831567 -0.1735942  -0.20295858\n",
      "  0.09778578 -0.47160888]\n",
      "New theta_0 : [-0.00359916 -0.10445718  0.13183878 -0.00627495  0.06445967 -0.14801859\n",
      "  0.26751771  0.04098361 -0.31180602  0.20845972 -0.17366077 -0.20299332\n",
      "  0.09778699 -0.47160794]\n",
      "Training Error:  10.306232579839774\n",
      "====================================================================================================\n",
      "Iteration:  545\n",
      "Previous theta :  [-0.00359916 -0.10445718  0.13183878 -0.00627495  0.06445967 -0.14801859\n",
      "  0.26751771  0.04098361 -0.31180602  0.20845972 -0.17366077 -0.20299332\n",
      "  0.09778699 -0.47160794]\n",
      "New theta_0 : [-0.0035968  -0.10449682  0.1318992  -0.00628361  0.06444481 -0.14820486\n",
      "  0.26746052  0.04099521 -0.31199578  0.20860314 -0.17372733 -0.20302785\n",
      "  0.09778821 -0.4716069 ]\n",
      "Training Error:  10.306132074926497\n",
      "====================================================================================================\n",
      "Iteration:  546\n",
      "Previous theta :  [-0.0035968  -0.10449682  0.1318992  -0.00628361  0.06444481 -0.14820486\n",
      "  0.26746052  0.04099521 -0.31199578  0.20860314 -0.17372733 -0.20302785\n",
      "  0.09778821 -0.4716069 ]\n",
      "New theta_0 : [-0.00359446 -0.1045362   0.13195918 -0.0062919   0.06443003 -0.14838991\n",
      "  0.26740382  0.04100673 -0.31218409  0.20874593 -0.17379389 -0.20306218\n",
      "  0.09778945 -0.47160577]\n",
      "Training Error:  10.306032834253688\n",
      "====================================================================================================\n",
      "Iteration:  547\n",
      "Previous theta :  [-0.00359446 -0.1045362   0.13195918 -0.0062919   0.06443003 -0.14838991\n",
      "  0.26740382  0.04100673 -0.31218409  0.20874593 -0.17379389 -0.20306218\n",
      "  0.09778945 -0.47160577]\n",
      "New theta_0 : [-0.00359214 -0.10457532  0.13201874 -0.00629982  0.06441531 -0.14857376\n",
      "  0.2673476   0.04101817 -0.31237096  0.20888808 -0.17386045 -0.20309631\n",
      "  0.0977907  -0.47160454]\n",
      "Training Error:  10.305934840268034\n",
      "====================================================================================================\n",
      "Iteration:  548\n",
      "Previous theta :  [-0.00359214 -0.10457532  0.13201874 -0.00629982  0.06441531 -0.14857376\n",
      "  0.2673476   0.04101817 -0.31237096  0.20888808 -0.17386045 -0.20309631\n",
      "  0.0977907  -0.47160454]\n",
      "New theta_0 : [-0.00358982 -0.10461418  0.13207788 -0.00630739  0.06440067 -0.14875641\n",
      "  0.26729185  0.04102954 -0.31255639  0.20902962 -0.173927   -0.20313024\n",
      "  0.09779197 -0.47160322]\n",
      "Training Error:  10.305838075672401\n",
      "====================================================================================================\n",
      "Iteration:  549\n",
      "Previous theta :  [-0.00358982 -0.10461418  0.13207788 -0.00630739  0.06440067 -0.14875641\n",
      "  0.26729185  0.04102954 -0.31255639  0.20902962 -0.173927   -0.20313024\n",
      "  0.09779197 -0.47160322]\n",
      "New theta_0 : [-0.00358752 -0.10465279  0.13213661 -0.0063146   0.0643861  -0.14893787\n",
      "  0.26723657  0.04104083 -0.31274041  0.20917054 -0.17399355 -0.20316397\n",
      "  0.09779325 -0.4716018 ]\n",
      "Training Error:  10.305742523421987\n",
      "====================================================================================================\n",
      "Iteration:  550\n",
      "Previous theta :  [-0.00358752 -0.10465279  0.13213661 -0.0063146   0.0643861  -0.14893787\n",
      "  0.26723657  0.04104083 -0.31274041  0.20917054 -0.17399355 -0.20316397\n",
      "  0.09779325 -0.4716018 ]\n",
      "New theta_0 : [-0.00358523 -0.10469114  0.13219491 -0.00632146  0.0643716  -0.14911814\n",
      "  0.26718176  0.04105205 -0.31292301  0.20931084 -0.17406008 -0.2031975\n",
      "  0.09779454 -0.4716003 ]\n",
      "Training Error:  10.305648166720534\n",
      "====================================================================================================\n",
      "Iteration:  551\n",
      "Previous theta :  [-0.00358523 -0.10469114  0.13219491 -0.00632146  0.0643716  -0.14911814\n",
      "  0.26718176  0.04105205 -0.31292301  0.20931084 -0.17406008 -0.2031975\n",
      "  0.09779454 -0.4716003 ]\n",
      "New theta_0 : [-0.00358295 -0.10472925  0.1322528  -0.00632797  0.06435717 -0.14929724\n",
      "  0.26712741  0.0410632  -0.31310422  0.20945053 -0.17412661 -0.20323084\n",
      "  0.09779585 -0.47159871]\n",
      "Training Error:  10.305554989016617\n",
      "====================================================================================================\n",
      "Iteration:  552\n",
      "Previous theta :  [-0.00358295 -0.10472925  0.1322528  -0.00632797  0.06435717 -0.14929724\n",
      "  0.26712741  0.0410632  -0.31310422  0.20945053 -0.17412661 -0.20323084\n",
      "  0.09779585 -0.47159871]\n",
      "New theta_0 : [-0.00358069 -0.1047671   0.13231029 -0.00633414  0.06434281 -0.14947518\n",
      "  0.26707352  0.04107427 -0.31328404  0.20958961 -0.17419313 -0.20326399\n",
      "  0.09779717 -0.47159703]\n",
      "Training Error:  10.305462973999965\n",
      "====================================================================================================\n",
      "Iteration:  553\n",
      "Previous theta :  [-0.00358069 -0.1047671   0.13231029 -0.00633414  0.06434281 -0.14947518\n",
      "  0.26707352  0.04107427 -0.31328404  0.20958961 -0.17419313 -0.20326399\n",
      "  0.09779717 -0.47159703]\n",
      "New theta_0 : [-0.00357844 -0.1048047   0.13236737 -0.00633997  0.06432851 -0.14965195\n",
      "  0.26702008  0.04108527 -0.31346248  0.20972808 -0.17425963 -0.20329694\n",
      "  0.0977985  -0.47159527]\n",
      "Training Error:  10.305372105597849\n",
      "====================================================================================================\n",
      "Iteration:  554\n",
      "Previous theta :  [-0.00357844 -0.1048047   0.13236737 -0.00633997  0.06432851 -0.14965195\n",
      "  0.26702008  0.04108527 -0.31346248  0.20972808 -0.17425963 -0.20329694\n",
      "  0.0977985  -0.47159527]\n",
      "New theta_0 : [-0.0035762  -0.10484206  0.13242404 -0.00634546  0.06431429 -0.14982757\n",
      "  0.26696709  0.0410962  -0.31363955  0.20986596 -0.17432613 -0.20332969\n",
      "  0.09779984 -0.47159342]\n",
      "Training Error:  10.305282367971524\n",
      "====================================================================================================\n",
      "Iteration:  555\n",
      "Previous theta :  [-0.0035762  -0.10484206  0.13242404 -0.00634546  0.06431429 -0.14982757\n",
      "  0.26696709  0.0410962  -0.31363955  0.20986596 -0.17432613 -0.20332969\n",
      "  0.09779984 -0.47159342]\n",
      "New theta_0 : [-0.00357397 -0.10487918  0.13248032 -0.00635062  0.06430014 -0.15000205\n",
      "  0.26691455  0.04110705 -0.31381527  0.21000323 -0.1743926  -0.20336226\n",
      "  0.09780119 -0.47159149]\n",
      "Training Error:  10.305193745512737\n",
      "====================================================================================================\n",
      "Iteration:  556\n",
      "Previous theta :  [-0.00357397 -0.10487918  0.13248032 -0.00635062  0.06430014 -0.15000205\n",
      "  0.26691455  0.04110705 -0.31381527  0.21000323 -0.1743926  -0.20336226\n",
      "  0.09780119 -0.47159149]\n",
      "New theta_0 : [-0.00357175 -0.10491605  0.1325362  -0.00635545  0.06428605 -0.15017539\n",
      "  0.26686244  0.04111784 -0.31398965  0.21013991 -0.17445907 -0.20339463\n",
      "  0.09780256 -0.47158949]\n",
      "Training Error:  10.305106222840264\n",
      "====================================================================================================\n",
      "Iteration:  557\n",
      "Previous theta :  [-0.00357175 -0.10491605  0.1325362  -0.00635545  0.06428605 -0.15017539\n",
      "  0.26686244  0.04111784 -0.31398965  0.21013991 -0.17445907 -0.20339463\n",
      "  0.09780256 -0.47158949]\n",
      "New theta_0 : [-0.00356955 -0.10495268  0.13259169 -0.00635996  0.06427203 -0.1503476\n",
      "  0.26681078  0.04112855 -0.31416269  0.210276   -0.17452552 -0.20342682\n",
      "  0.09780394 -0.4715874 ]\n",
      "Training Error:  10.305019784796524\n",
      "====================================================================================================\n",
      "Iteration:  558\n",
      "Previous theta :  [-0.00356955 -0.10495268  0.13259169 -0.00635996  0.06427203 -0.1503476\n",
      "  0.26681078  0.04112855 -0.31416269  0.210276   -0.17452552 -0.20342682\n",
      "  0.09780394 -0.4715874 ]\n",
      "New theta_0 : [-0.00356735 -0.10498907  0.13264678 -0.00636414  0.06425808 -0.15051869\n",
      "  0.26675955  0.04113919 -0.3143344   0.2104115  -0.17459195 -0.20345882\n",
      "  0.09780533 -0.47158524]\n",
      "Training Error:  10.304934416444226\n",
      "====================================================================================================\n",
      "Iteration:  559\n",
      "Previous theta :  [-0.00356735 -0.10498907  0.13264678 -0.00636414  0.06425808 -0.15051869\n",
      "  0.26675955  0.04113919 -0.3143344   0.2104115  -0.17459195 -0.20345882\n",
      "  0.09780533 -0.47158524]\n",
      "New theta_0 : [-0.00356517 -0.10502523  0.13270149 -0.00636801  0.06424419 -0.15068867\n",
      "  0.26670874  0.04114976 -0.3145048   0.21054641 -0.17465836 -0.20349064\n",
      "  0.09780673 -0.471583  ]\n",
      "Training Error:  10.304850103063076\n",
      "====================================================================================================\n",
      "Iteration:  560\n",
      "Previous theta :  [-0.00356517 -0.10502523  0.13270149 -0.00636801  0.06424419 -0.15068867\n",
      "  0.26670874  0.04114976 -0.3145048   0.21054641 -0.17465836 -0.20349064\n",
      "  0.09780673 -0.471583  ]\n",
      "New theta_0 : [-0.003563   -0.10506114  0.13275581 -0.00637157  0.06423037 -0.15085754\n",
      "  0.26665837  0.04116026 -0.3146739   0.21068075 -0.17472476 -0.20352226\n",
      "  0.09780814 -0.47158069]\n",
      "Training Error:  10.304766830146544\n",
      "====================================================================================================\n",
      "Iteration:  561\n",
      "Previous theta :  [-0.003563   -0.10506114  0.13275581 -0.00637157  0.06423037 -0.15085754\n",
      "  0.26665837  0.04116026 -0.3146739   0.21068075 -0.17472476 -0.20352226\n",
      "  0.09780814 -0.47158069]\n",
      "New theta_0 : [-0.00356085 -0.10509683  0.13280975 -0.00637481  0.06421662 -0.15102531\n",
      "  0.26660841  0.04117069 -0.3148417   0.2108145  -0.17479113 -0.20355371\n",
      "  0.09780956 -0.47157831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.304684583398652\n",
      "====================================================================================================\n",
      "Iteration:  562\n",
      "Previous theta :  [-0.00356085 -0.10509683  0.13280975 -0.00637481  0.06421662 -0.15102531\n",
      "  0.26660841  0.04117069 -0.3148417   0.2108145  -0.17479113 -0.20355371\n",
      "  0.09780956 -0.47157831]\n",
      "New theta_0 : [-0.0035587  -0.10513228  0.13286331 -0.00637775  0.06420293 -0.15119198\n",
      "  0.26655887  0.04118106 -0.31500822  0.21094768 -0.17485748 -0.20358497\n",
      "  0.097811   -0.47157586]\n",
      "Training Error:  10.304603348730845\n",
      "====================================================================================================\n",
      "Iteration:  563\n",
      "Previous theta :  [-0.0035587  -0.10513228  0.13286331 -0.00637775  0.06420293 -0.15119198\n",
      "  0.26655887  0.04118106 -0.31500822  0.21094768 -0.17485748 -0.20358497\n",
      "  0.097811   -0.47157586]\n",
      "New theta_0 : [-0.00355656 -0.1051675   0.1329165  -0.00638038  0.06418931 -0.15135757\n",
      "  0.26650975  0.04119135 -0.31517346  0.21108029 -0.17492381 -0.20361605\n",
      "  0.09781244 -0.47157333]\n",
      "Training Error:  10.304523112258877\n",
      "====================================================================================================\n",
      "Iteration:  564\n",
      "Previous theta :  [-0.00355656 -0.1051675   0.1329165  -0.00638038  0.06418931 -0.15135757\n",
      "  0.26650975  0.04119135 -0.31517346  0.21108029 -0.17492381 -0.20361605\n",
      "  0.09781244 -0.47157333]\n",
      "New theta_0 : [-0.00355444 -0.10520249  0.13296931 -0.00638271  0.06417575 -0.15152208\n",
      "  0.26646104  0.04120158 -0.31533744  0.21121233 -0.17499012 -0.20364695\n",
      "  0.09781389 -0.47157074]\n",
      "Training Error:  10.30444386029978\n",
      "====================================================================================================\n",
      "Iteration:  565\n",
      "Previous theta :  [-0.00355444 -0.10520249  0.13296931 -0.00638271  0.06417575 -0.15152208\n",
      "  0.26646104  0.04120158 -0.31533744  0.21121233 -0.17499012 -0.20364695\n",
      "  0.09781389 -0.47157074]\n",
      "New theta_0 : [-0.00355233 -0.10523725  0.13302175 -0.00638475  0.06416226 -0.15168552\n",
      "  0.26641273  0.04121174 -0.31550017  0.2113438  -0.1750564  -0.20367767\n",
      "  0.09781535 -0.47156809]\n",
      "Training Error:  10.304365579368842\n",
      "====================================================================================================\n",
      "Iteration:  566\n",
      "Previous theta :  [-0.00355233 -0.10523725  0.13302175 -0.00638475  0.06416226 -0.15168552\n",
      "  0.26641273  0.04121174 -0.31550017  0.2113438  -0.1750564  -0.20367767\n",
      "  0.09781535 -0.47156809]\n",
      "New theta_0 : [-0.00355022 -0.10527178  0.13307383 -0.00638649  0.06414883 -0.1518479\n",
      "  0.26636483  0.04122183 -0.31566165  0.21147471 -0.17512266 -0.20370821\n",
      "  0.09781682 -0.47156536]\n",
      "Training Error:  10.304288256176655\n",
      "====================================================================================================\n",
      "Iteration:  567\n",
      "Previous theta :  [-0.00355022 -0.10527178  0.13307383 -0.00638649  0.06414883 -0.1518479\n",
      "  0.26636483  0.04122183 -0.31566165  0.21147471 -0.17512266 -0.20370821\n",
      "  0.09781682 -0.47156536]\n",
      "New theta_0 : [-0.00354813 -0.10530609  0.13312554 -0.00638795  0.06413547 -0.15200921\n",
      "  0.26631732  0.04123185 -0.31582189  0.21160506 -0.17518889 -0.20373857\n",
      "  0.0978183  -0.47156258]\n",
      "Training Error:  10.304211877626203\n",
      "====================================================================================================\n",
      "Iteration:  568\n",
      "Previous theta :  [-0.00354813 -0.10530609  0.13312554 -0.00638795  0.06413547 -0.15200921\n",
      "  0.26631732  0.04123185 -0.31582189  0.21160506 -0.17518889 -0.20373857\n",
      "  0.0978183  -0.47156258]\n",
      "New theta_0 : [-0.00354605 -0.10534018  0.13317688 -0.00638912  0.06412217 -0.15216948\n",
      "  0.26627021  0.04124181 -0.31598091  0.21173486 -0.1752551  -0.20376876\n",
      "  0.09781979 -0.47155973]\n",
      "Training Error:  10.304136430809995\n",
      "====================================================================================================\n",
      "Iteration:  569\n",
      "Previous theta :  [-0.00354605 -0.10534018  0.13317688 -0.00638912  0.06412217 -0.15216948\n",
      "  0.26627021  0.04124181 -0.31598091  0.21173486 -0.1752551  -0.20376876\n",
      "  0.09781979 -0.47155973]\n",
      "New theta_0 : [-0.00354398 -0.10537405  0.13322787 -0.00639     0.06410893 -0.15232871\n",
      "  0.2662235   0.0412517  -0.31613872  0.2118641  -0.17532127 -0.20379877\n",
      "  0.09782129 -0.47155682]\n",
      "Training Error:  10.304061903007234\n",
      "====================================================================================================\n",
      "Iteration:  570\n",
      "Previous theta :  [-0.00354398 -0.10537405  0.13322787 -0.00639     0.06410893 -0.15232871\n",
      "  0.2662235   0.0412517  -0.31613872  0.2118641  -0.17532127 -0.20379877\n",
      "  0.09782129 -0.47155682]\n",
      "New theta_0 : [-0.00354193 -0.10540769  0.1332785  -0.00639061  0.06409576 -0.15248689\n",
      "  0.26617717  0.04126153 -0.31629531  0.21199279 -0.17538742 -0.20382861\n",
      "  0.0978228  -0.47155385]\n",
      "Training Error:  10.303988281681036\n",
      "====================================================================================================\n",
      "Iteration:  571\n",
      "Previous theta :  [-0.00354193 -0.10540769  0.1332785  -0.00639061  0.06409576 -0.15248689\n",
      "  0.26617717  0.04126153 -0.31629531  0.21199279 -0.17538742 -0.20382861\n",
      "  0.0978228  -0.47155385]\n",
      "New theta_0 : [-0.00353988 -0.10544112  0.13332878 -0.00639094  0.06408265 -0.15264405\n",
      "  0.26613123  0.04127129 -0.31645071  0.21212094 -0.17545353 -0.20385828\n",
      "  0.09782431 -0.47155083]\n",
      "Training Error:  10.303915554475692\n",
      "====================================================================================================\n",
      "Iteration:  572\n",
      "Previous theta :  [-0.00353988 -0.10544112  0.13332878 -0.00639094  0.06408265 -0.15264405\n",
      "  0.26613123  0.04127129 -0.31645071  0.21212094 -0.17545353 -0.20385828\n",
      "  0.09782431 -0.47155083]\n",
      "New theta_0 : [-0.00353784 -0.10547433  0.13337871 -0.00639099  0.0640696  -0.15280018\n",
      "  0.26608567  0.04128099 -0.31660492  0.21224854 -0.17551962 -0.20388777\n",
      "  0.09782584 -0.47154774]\n",
      "Training Error:  10.303843709213961\n",
      "====================================================================================================\n",
      "Iteration:  573\n",
      "Previous theta :  [-0.00353784 -0.10547433  0.13337871 -0.00639099  0.0640696  -0.15280018\n",
      "  0.26608567  0.04128099 -0.31660492  0.21224854 -0.17551962 -0.20388777\n",
      "  0.09782584 -0.47154774]\n",
      "New theta_0 : [-0.00353581 -0.10550732  0.13342829 -0.00639078  0.06405661 -0.1529553\n",
      "  0.26604048  0.04129062 -0.31675795  0.2123756  -0.17558567 -0.20391709\n",
      "  0.09782737 -0.4715446 ]\n",
      "Training Error:  10.303772733894428\n",
      "====================================================================================================\n",
      "Iteration:  574\n",
      "Previous theta :  [-0.00353581 -0.10550732  0.13342829 -0.00639078  0.06405661 -0.1529553\n",
      "  0.26604048  0.04129062 -0.31675795  0.2123756  -0.17558567 -0.20391709\n",
      "  0.09782737 -0.4715446 ]\n",
      "New theta_0 : [-0.0035338  -0.1055401   0.13347752 -0.0063903   0.06404368 -0.15310941\n",
      "  0.26599568  0.04130019 -0.31690982  0.21250213 -0.17565169 -0.20394625\n",
      "  0.09782891 -0.47154141]\n",
      "Training Error:  10.303702616688874\n",
      "====================================================================================================\n",
      "Iteration:  575\n",
      "Previous theta :  [-0.0035338  -0.1055401   0.13347752 -0.0063903   0.06404368 -0.15310941\n",
      "  0.26599568  0.04130019 -0.31690982  0.21250213 -0.17565169 -0.20394625\n",
      "  0.09782891 -0.47154141]\n",
      "New theta_0 : [-0.00353179 -0.10557267  0.13352641 -0.00638956  0.06403081 -0.15326251\n",
      "  0.26595124  0.04130969 -0.31706052  0.21262812 -0.17571768 -0.20397523\n",
      "  0.09783045 -0.47153816]\n",
      "Training Error:  10.3036333459397\n",
      "====================================================================================================\n",
      "Iteration:  576\n",
      "Previous theta :  [-0.00353179 -0.10557267  0.13352641 -0.00638956  0.06403081 -0.15326251\n",
      "  0.26595124  0.04130969 -0.31706052  0.21262812 -0.17571768 -0.20397523\n",
      "  0.09783045 -0.47153816]\n",
      "New theta_0 : [-0.0035298  -0.10560502  0.13357496 -0.00638855  0.06401801 -0.15341462\n",
      "  0.26590717  0.04131913 -0.31721006  0.21275357 -0.17578363 -0.20400405\n",
      "  0.09783201 -0.47153486]\n",
      "Training Error:  10.303564910157393\n",
      "====================================================================================================\n",
      "Iteration:  577\n",
      "Previous theta :  [-0.0035298  -0.10560502  0.13357496 -0.00638855  0.06401801 -0.15341462\n",
      "  0.26590717  0.04131913 -0.31721006  0.21275357 -0.17578363 -0.20400405\n",
      "  0.09783201 -0.47153486]\n",
      "New theta_0 : [-0.00352781 -0.10563717  0.13362317 -0.00638729  0.06400527 -0.15356573\n",
      "  0.26586347  0.04132851 -0.31735847  0.2128785  -0.17584954 -0.2040327\n",
      "  0.09783357 -0.4715315 ]\n",
      "Training Error:  10.303497298018021\n",
      "====================================================================================================\n",
      "Iteration:  578\n",
      "Previous theta :  [-0.00352781 -0.10563717  0.13362317 -0.00638729  0.06400527 -0.15356573\n",
      "  0.26586347  0.04132851 -0.31735847  0.2128785  -0.17584954 -0.2040327\n",
      "  0.09783357 -0.4715315 ]\n",
      "New theta_0 : [-0.00352583 -0.10566911  0.13367105 -0.00638577  0.06399258 -0.15371587\n",
      "  0.26582013  0.04133783 -0.31750574  0.21300291 -0.17591542 -0.20406118\n",
      "  0.09783514 -0.4715281 ]\n",
      "Training Error:  10.303430498360779\n",
      "====================================================================================================\n",
      "Iteration:  579\n",
      "Previous theta :  [-0.00352583 -0.10566911  0.13367105 -0.00638577  0.06399258 -0.15371587\n",
      "  0.26582013  0.04133783 -0.31750574  0.21300291 -0.17591542 -0.20406118\n",
      "  0.09783514 -0.4715281 ]\n",
      "New theta_0 : [-0.00352387 -0.10570084  0.13371859 -0.006384    0.06397996 -0.15386503\n",
      "  0.26577715  0.04134709 -0.31765189  0.21312679 -0.17598126 -0.2040895\n",
      "  0.09783671 -0.47152465]\n",
      "Training Error:  10.303364500185548\n",
      "====================================================================================================\n",
      "Iteration:  580\n",
      "Previous theta :  [-0.00352387 -0.10570084  0.13371859 -0.006384    0.06397996 -0.15386503\n",
      "  0.26577715  0.04134709 -0.31765189  0.21312679 -0.17598126 -0.2040895\n",
      "  0.09783671 -0.47152465]\n",
      "New theta_0 : [-0.00352191 -0.10573237  0.1337658  -0.00638199  0.06396739 -0.15401321\n",
      "  0.26573452  0.04135628 -0.31779692  0.21325014 -0.17604706 -0.20411766\n",
      "  0.0978383  -0.47152115]\n",
      "Training Error:  10.303299292650529\n",
      "====================================================================================================\n",
      "Iteration:  581\n",
      "Previous theta :  [-0.00352191 -0.10573237  0.1337658  -0.00638199  0.06396739 -0.15401321\n",
      "  0.26573452  0.04135628 -0.31779692  0.21325014 -0.17604706 -0.20411766\n",
      "  0.0978383  -0.47152115]\n",
      "New theta_0 : [-0.00351997 -0.10576369  0.13381269 -0.00637972  0.06395488 -0.15416043\n",
      "  0.26569224  0.04136542 -0.31794084  0.21337299 -0.17611283 -0.20414565\n",
      "  0.09783989 -0.4715176 ]\n",
      "Training Error:  10.303234865069873\n",
      "====================================================================================================\n",
      "Iteration:  582\n",
      "Previous theta :  [-0.00351997 -0.10576369  0.13381269 -0.00637972  0.06395488 -0.15416043\n",
      "  0.26569224  0.04136542 -0.31794084  0.21337299 -0.17611283 -0.20414565\n",
      "  0.09783989 -0.4715176 ]\n",
      "New theta_0 : [-0.00351803 -0.10579481  0.13385925 -0.00637722  0.06394244 -0.1543067\n",
      "  0.26565032  0.04137449 -0.31808366  0.21349531 -0.17617855 -0.20417349\n",
      "  0.09784148 -0.47151401]\n",
      "Training Error:  10.303171206911378\n",
      "====================================================================================================\n",
      "Iteration:  583\n",
      "Previous theta :  [-0.00351803 -0.10579481  0.13385925 -0.00637722  0.06394244 -0.1543067\n",
      "  0.26565032  0.04137449 -0.31808366  0.21349531 -0.17617855 -0.20417349\n",
      "  0.09784148 -0.47151401]\n",
      "New theta_0 : [-0.00351611 -0.10582573  0.13390549 -0.00637447  0.06393005 -0.15445201\n",
      "  0.26560874  0.0413835  -0.31822539  0.21361713 -0.17624423 -0.20420116\n",
      "  0.09784308 -0.47151038]\n",
      "Training Error:  10.303108307794192\n",
      "====================================================================================================\n",
      "Iteration:  584\n",
      "Previous theta :  [-0.00351611 -0.10582573  0.13390549 -0.00637447  0.06393005 -0.15445201\n",
      "  0.26560874  0.0413835  -0.31822539  0.21361713 -0.17624423 -0.20420116\n",
      "  0.09784308 -0.47151038]\n",
      "New theta_0 : [-0.00351419 -0.10585645  0.1339514  -0.00637149  0.06391771 -0.15459638\n",
      "  0.2655675   0.04139246 -0.31836604  0.21373844 -0.17630987 -0.20422867\n",
      "  0.09784469 -0.4715067 ]\n",
      "Training Error:  10.303046157486587\n",
      "====================================================================================================\n",
      "Iteration:  585\n",
      "Previous theta :  [-0.00351419 -0.10585645  0.1339514  -0.00637149  0.06391771 -0.15459638\n",
      "  0.2655675   0.04139246 -0.31836604  0.21373844 -0.17630987 -0.20422867\n",
      "  0.09784469 -0.4715067 ]\n",
      "New theta_0 : [-0.00351228 -0.10588697  0.133997   -0.00636828  0.06390544 -0.1547398\n",
      "  0.2655266   0.04140135 -0.31850561  0.21385924 -0.17637547 -0.20425602\n",
      "  0.0978463  -0.47150298]\n",
      "Training Error:  10.30298474590373\n",
      "====================================================================================================\n",
      "Iteration:  586\n",
      "Previous theta :  [-0.00351228 -0.10588697  0.133997   -0.00636828  0.06390544 -0.1547398\n",
      "  0.2655266   0.04140135 -0.31850561  0.21385924 -0.17637547 -0.20425602\n",
      "  0.0978463  -0.47150298]\n",
      "New theta_0 : [-0.00351039 -0.10591729  0.13404228 -0.00636483  0.06389322 -0.1548823\n",
      "  0.26548604  0.04141019 -0.31864412  0.21397954 -0.17644102 -0.20428322\n",
      "  0.09784792 -0.47149921]\n",
      "Training Error:  10.302924063105511\n",
      "====================================================================================================\n",
      "Iteration:  587\n",
      "Previous theta :  [-0.00351039 -0.10591729  0.13404228 -0.00636483  0.06389322 -0.1548823\n",
      "  0.26548604  0.04141019 -0.31864412  0.21397954 -0.17644102 -0.20428322\n",
      "  0.09784792 -0.47149921]\n",
      "New theta_0 : [-0.0035085  -0.10594742  0.13408725 -0.00636115  0.06388106 -0.15502386\n",
      "  0.26544581  0.04141896 -0.31878157  0.21409933 -0.17650653 -0.20431026\n",
      "  0.09784955 -0.47149541]\n",
      "Training Error:  10.302864099294396\n",
      "====================================================================================================\n",
      "Iteration:  588\n",
      "Previous theta :  [-0.0035085  -0.10594742  0.13408725 -0.00636115  0.06388106 -0.15502386\n",
      "  0.26544581  0.04141896 -0.31878157  0.21409933 -0.17650653 -0.20431026\n",
      "  0.09784955 -0.47149541]\n",
      "New theta_0 : [-0.00350662 -0.10597736  0.13413191 -0.00635725  0.06386896 -0.15516451\n",
      "  0.26540592  0.04142768 -0.31891796  0.21421863 -0.176572   -0.20433714\n",
      "  0.09785118 -0.47149157]\n",
      "Training Error:  10.302804844813316\n",
      "====================================================================================================\n",
      "Iteration:  589\n",
      "Previous theta :  [-0.00350662 -0.10597736  0.13413191 -0.00635725  0.06386896 -0.15516451\n",
      "  0.26540592  0.04142768 -0.31891796  0.21421863 -0.176572   -0.20433714\n",
      "  0.09785118 -0.47149157]\n",
      "New theta_0 : [-0.00350475 -0.1060071   0.13417627 -0.00635313  0.06385692 -0.15530424\n",
      "  0.26536635  0.04143634 -0.31905332  0.21433744 -0.17663741 -0.20436387\n",
      "  0.09785281 -0.47148769]\n",
      "Training Error:  10.30274629014358\n",
      "====================================================================================================\n",
      "Iteration:  590\n",
      "Previous theta :  [-0.00350475 -0.1060071   0.13417627 -0.00635313  0.06385692 -0.15530424\n",
      "  0.26536635  0.04143634 -0.31905332  0.21433744 -0.17663741 -0.20436387\n",
      "  0.09785281 -0.47148769]\n",
      "New theta_0 : [-0.00350289 -0.10603665  0.13422031 -0.00634879  0.06384493 -0.15544307\n",
      "  0.2653271   0.04144495 -0.31918765  0.21445575 -0.17670279 -0.20439045\n",
      "  0.09785446 -0.47148377]\n",
      "Training Error:  10.302688425902826\n",
      "====================================================================================================\n",
      "Iteration:  591\n",
      "Previous theta :  [-0.00350289 -0.10603665  0.13422031 -0.00634879  0.06384493 -0.15544307\n",
      "  0.2653271   0.04144495 -0.31918765  0.21445575 -0.17670279 -0.20439045\n",
      "  0.09785446 -0.47148377]\n",
      "New theta_0 : [-0.00350104 -0.10606601  0.13426405 -0.00634423  0.06383299 -0.15558099\n",
      "  0.26528818  0.04145349 -0.31932094  0.21457357 -0.17676811 -0.20441687\n",
      "  0.0978561  -0.47147982]\n",
      "Training Error:  10.30263124284301\n",
      "====================================================================================================\n",
      "Iteration:  592\n",
      "Previous theta :  [-0.00350104 -0.10606601  0.13426405 -0.00634423  0.06383299 -0.15558099\n",
      "  0.26528818  0.04145349 -0.31932094  0.21457357 -0.17676811 -0.20441687\n",
      "  0.0978561  -0.47147982]\n",
      "New theta_0 : [-0.0034992  -0.10609518  0.13430749 -0.00633945  0.06382111 -0.15571801\n",
      "  0.26524958  0.04146199 -0.31945323  0.21469091 -0.17683339 -0.20444314\n",
      "  0.09785775 -0.47147583]\n",
      "Training Error:  10.302574731848406\n",
      "====================================================================================================\n",
      "Iteration:  593\n",
      "Previous theta :  [-0.0034992  -0.10609518  0.13430749 -0.00633945  0.06382111 -0.15571801\n",
      "  0.26524958  0.04146199 -0.31945323  0.21469091 -0.17683339 -0.20444314\n",
      "  0.09785775 -0.47147583]\n",
      "New theta_0 : [-0.00349737 -0.10612417  0.13435063 -0.00633446  0.06380929 -0.15585414\n",
      "  0.26521129  0.04147042 -0.3195845   0.21480776 -0.17689862 -0.20446926\n",
      "  0.09785941 -0.4714718 ]\n",
      "Training Error:  10.302518883933656\n",
      "====================================================================================================\n",
      "Iteration:  594\n",
      "Previous theta :  [-0.00349737 -0.10612417  0.13435063 -0.00633446  0.06380929 -0.15585414\n",
      "  0.26521129  0.04147042 -0.3195845   0.21480776 -0.17689862 -0.20446926\n",
      "  0.09785941 -0.4714718 ]\n",
      "New theta_0 : [-0.00349554 -0.10615296  0.13439348 -0.00632926  0.06379752 -0.15598939\n",
      "  0.26517332  0.0414788  -0.31971476  0.21492412 -0.17696379 -0.20449523\n",
      "  0.09786107 -0.47146774]\n",
      "Training Error:  10.302463690241833\n",
      "====================================================================================================\n",
      "Iteration:  595\n",
      "Previous theta :  [-0.00349554 -0.10615296  0.13439348 -0.00632926  0.06379752 -0.15598939\n",
      "  0.26517332  0.0414788  -0.31971476  0.21492412 -0.17696379 -0.20449523\n",
      "  0.09786107 -0.47146774]\n",
      "New theta_0 : [-0.00349373 -0.10618158  0.13443603 -0.00632386  0.06378581 -0.15612376\n",
      "  0.26513565  0.04148712 -0.31984404  0.21504001 -0.17702892 -0.20452105\n",
      "  0.09786273 -0.47146365]\n",
      "Training Error:  10.302409142042558\n",
      "====================================================================================================\n",
      "Iteration:  596\n",
      "Previous theta :  [-0.00349373 -0.10618158  0.13443603 -0.00632386  0.06378581 -0.15612376\n",
      "  0.26513565  0.04148712 -0.31984404  0.21504001 -0.17702892 -0.20452105\n",
      "  0.09786273 -0.47146365]\n",
      "New theta_0 : [-0.00349193 -0.10621001  0.13447829 -0.00631825  0.06377415 -0.15625726\n",
      "  0.2650983   0.04149539 -0.31997233  0.21515543 -0.177094   -0.20454672\n",
      "  0.0978644  -0.47145953]\n",
      "Training Error:  10.3023552307301\n",
      "====================================================================================================\n",
      "Iteration:  597\n",
      "Previous theta :  [-0.00349193 -0.10621001  0.13447829 -0.00631825  0.06377415 -0.15625726\n",
      "  0.2650983   0.04149539 -0.31997233  0.21515543 -0.177094   -0.20454672\n",
      "  0.0978644  -0.47145953]\n",
      "New theta_0 : [-0.00349013 -0.10623826  0.13452026 -0.00631244  0.06376254 -0.15638988\n",
      "  0.26506125  0.04150361 -0.32009963  0.21527036 -0.17715902 -0.20457224\n",
      "  0.09786607 -0.47145537]\n",
      "Training Error:  10.302301947821563\n",
      "====================================================================================================\n",
      "Iteration:  598\n",
      "Previous theta :  [-0.00349013 -0.10623826  0.13452026 -0.00631244  0.06376254 -0.15638988\n",
      "  0.26506125  0.04150361 -0.32009963  0.21527036 -0.17715902 -0.20457224\n",
      "  0.09786607 -0.47145537]\n",
      "New theta_0 : [-0.00348834 -0.10626632  0.13456194 -0.00630643  0.06375099 -0.15652165\n",
      "  0.2650245   0.04151177 -0.32022597  0.21538483 -0.17722399 -0.20459762\n",
      "  0.09786775 -0.47145119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.302249284955058\n",
      "====================================================================================================\n",
      "Iteration:  599\n",
      "Previous theta :  [-0.00348834 -0.10626632  0.13456194 -0.00630643  0.06375099 -0.15652165\n",
      "  0.2650245   0.04151177 -0.32022597  0.21538483 -0.17722399 -0.20459762\n",
      "  0.09786775 -0.47145119]\n",
      "New theta_0 : [-0.00348656 -0.10629421  0.13460333 -0.00630022  0.06373949 -0.15665256\n",
      "  0.26498805  0.04151988 -0.32035134  0.21549883 -0.17728891 -0.20462285\n",
      "  0.09786943 -0.47144698]\n",
      "Training Error:  10.302197233887906\n",
      "====================================================================================================\n",
      "Iteration:  600\n",
      "Previous theta :  [-0.00348656 -0.10629421  0.13460333 -0.00630022  0.06373949 -0.15665256\n",
      "  0.26498805  0.04151988 -0.32035134  0.21549883 -0.17728891 -0.20462285\n",
      "  0.09786943 -0.47144698]\n",
      "New theta_0 : [-0.00348479 -0.10632192  0.13464444 -0.00629382  0.06372805 -0.15678262\n",
      "  0.2649519   0.04152793 -0.32047576  0.21561236 -0.17735378 -0.20464794\n",
      "  0.09787111 -0.47144274]\n",
      "Training Error:  10.302145786494897\n",
      "====================================================================================================\n",
      "Iteration:  601\n",
      "Previous theta :  [-0.00348479 -0.10632192  0.13464444 -0.00629382  0.06372805 -0.15678262\n",
      "  0.2649519   0.04152793 -0.32047576  0.21561236 -0.17735378 -0.20464794\n",
      "  0.09787111 -0.47144274]\n",
      "New theta_0 : [-0.00348303 -0.10634945  0.13468527 -0.00628723  0.06371665 -0.15691183\n",
      "  0.26491605  0.04153593 -0.32059923  0.21572543 -0.17741859 -0.20467288\n",
      "  0.0978728  -0.47143847]\n",
      "Training Error:  10.302094934766542\n",
      "====================================================================================================\n",
      "Iteration:  602\n",
      "Previous theta :  [-0.00348303 -0.10634945  0.13468527 -0.00628723  0.06371665 -0.15691183\n",
      "  0.26491605  0.04153593 -0.32059923  0.21572543 -0.17741859 -0.20467288\n",
      "  0.0978728  -0.47143847]\n",
      "New theta_0 : [-0.00348128 -0.1063768   0.13472582 -0.00628045  0.06370531 -0.1570402\n",
      "  0.26488048  0.04154388 -0.32072175  0.21583803 -0.17748334 -0.20469768\n",
      "  0.09787449 -0.47143417]\n",
      "Training Error:  10.302044670807367\n",
      "====================================================================================================\n",
      "Iteration:  603\n",
      "Previous theta :  [-0.00348128 -0.1063768   0.13472582 -0.00628045  0.06370531 -0.1570402\n",
      "  0.26488048  0.04154388 -0.32072175  0.21583803 -0.17748334 -0.20469768\n",
      "  0.09787449 -0.47143417]\n",
      "New theta_0 : [-0.00347953 -0.10640398  0.1347661  -0.00627348  0.06369402 -0.15716774\n",
      "  0.26484521  0.04155178 -0.32084334  0.21595018 -0.17754804 -0.20472234\n",
      "  0.09787619 -0.47142985]\n",
      "Training Error:  10.301994986834238\n",
      "====================================================================================================\n",
      "Iteration:  604\n",
      "Previous theta :  [-0.00347953 -0.10640398  0.1347661  -0.00627348  0.06369402 -0.15716774\n",
      "  0.26484521  0.04155178 -0.32084334  0.21595018 -0.17754804 -0.20472234\n",
      "  0.09787619 -0.47142985]\n",
      "New theta_0 : [-0.0034778  -0.10643099  0.13480609 -0.00626632  0.06368279 -0.15729445\n",
      "  0.26481022  0.04155962 -0.320964    0.21606187 -0.17761268 -0.20474685\n",
      "  0.09787788 -0.4714255 ]\n",
      "Training Error:  10.301945875174697\n",
      "====================================================================================================\n",
      "Iteration:  605\n",
      "Previous theta :  [-0.0034778  -0.10643099  0.13480609 -0.00626632  0.06368279 -0.15729445\n",
      "  0.26481022  0.04155962 -0.320964    0.21606187 -0.17761268 -0.20474685\n",
      "  0.09787788 -0.4714255 ]\n",
      "New theta_0 : [-0.00347607 -0.10645782  0.13484582 -0.00625898  0.0636716  -0.15742034\n",
      "  0.26477551  0.04156741 -0.32108375  0.2161731  -0.17767727 -0.20477123\n",
      "  0.09787958 -0.47142113]\n",
      "Training Error:  10.301897328265326\n",
      "====================================================================================================\n",
      "Iteration:  606\n",
      "Previous theta :  [-0.00347607 -0.10645782  0.13484582 -0.00625898  0.0636716  -0.15742034\n",
      "  0.26477551  0.04156741 -0.32108375  0.2161731  -0.17767727 -0.20477123\n",
      "  0.09787958 -0.47142113]\n",
      "New theta_0 : [-0.00347435 -0.10648449  0.13488528 -0.00625147  0.06366047 -0.15754541\n",
      "  0.26474109  0.04157516 -0.32120258  0.21628388 -0.17774179 -0.20479547\n",
      "  0.09788129 -0.47141673]\n",
      "Training Error:  10.301849338650152\n",
      "====================================================================================================\n",
      "Iteration:  607\n",
      "Previous theta :  [-0.00347435 -0.10648449  0.13488528 -0.00625147  0.06366047 -0.15754541\n",
      "  0.26474109  0.04157516 -0.32120258  0.21628388 -0.17774179 -0.20479547\n",
      "  0.09788129 -0.47141673]\n",
      "New theta_0 : [-0.00347264 -0.10651098  0.13492446 -0.00624377  0.06364939 -0.15766967\n",
      "  0.26470695  0.04158285 -0.3213205   0.21639422 -0.17780626 -0.20481956\n",
      "  0.09788299 -0.47141231]\n",
      "Training Error:  10.301801898979063\n",
      "====================================================================================================\n",
      "Iteration:  608\n",
      "Previous theta :  [-0.00347264 -0.10651098  0.13492446 -0.00624377  0.06364939 -0.15766967\n",
      "  0.26470695  0.04158285 -0.3213205   0.21639422 -0.17780626 -0.20481956\n",
      "  0.09788299 -0.47141231]\n",
      "New theta_0 : [-0.00347093 -0.1065373   0.13496338 -0.0062359   0.06363836 -0.15779312\n",
      "  0.26467308  0.04159049 -0.32143752  0.2165041  -0.17787067 -0.20484352\n",
      "  0.0978847  -0.47140787]\n",
      "Training Error:  10.301755002006228\n",
      "====================================================================================================\n",
      "Iteration:  609\n",
      "Previous theta :  [-0.00347093 -0.1065373   0.13496338 -0.0062359   0.06363836 -0.15779312\n",
      "  0.26467308  0.04159049 -0.32143752  0.2165041  -0.17787067 -0.20484352\n",
      "  0.0978847  -0.47140787]\n",
      "New theta_0 : [-0.00346924 -0.10656346  0.13500204 -0.00622786  0.06362737 -0.15791578\n",
      "  0.26463949  0.04159808 -0.32155365  0.21661355 -0.17793502 -0.20486734\n",
      "  0.09788641 -0.47140341]\n",
      "Training Error:  10.301708640588592\n",
      "====================================================================================================\n",
      "Iteration:  610\n",
      "Previous theta :  [-0.00346924 -0.10656346  0.13500204 -0.00622786  0.06362737 -0.15791578\n",
      "  0.26463949  0.04159808 -0.32155365  0.21661355 -0.17793502 -0.20486734\n",
      "  0.09788641 -0.47140341]\n",
      "New theta_0 : [-0.00346755 -0.10658945  0.13504043 -0.00621964  0.06361644 -0.15803763\n",
      "  0.26460617  0.04160562 -0.3216689   0.21672255 -0.1779993  -0.20489103\n",
      "  0.09788813 -0.47139892]\n",
      "Training Error:  10.301662807684336\n",
      "====================================================================================================\n",
      "Iteration:  611\n",
      "Previous theta :  [-0.00346755 -0.10658945  0.13504043 -0.00621964  0.06361644 -0.15803763\n",
      "  0.26460617  0.04160562 -0.3216689   0.21672255 -0.1779993  -0.20489103\n",
      "  0.09788813 -0.47139892]\n",
      "New theta_0 : [-0.00346587 -0.10661527  0.13507856 -0.00621126  0.06360556 -0.15815869\n",
      "  0.26457312  0.04161311 -0.32178326  0.2168311  -0.17806353 -0.20491458\n",
      "  0.09788985 -0.47139442]\n",
      "Training Error:  10.301617496351412\n",
      "====================================================================================================\n",
      "Iteration:  612\n",
      "Previous theta :  [-0.00346587 -0.10661527  0.13507856 -0.00621126  0.06360556 -0.15815869\n",
      "  0.26457312  0.04161311 -0.32178326  0.2168311  -0.17806353 -0.20491458\n",
      "  0.09788985 -0.47139442]\n",
      "New theta_0 : [-0.0034642  -0.10664093  0.13511644 -0.00620271  0.06359473 -0.15827897\n",
      "  0.26454033  0.04162056 -0.32189676  0.21693923 -0.17812769 -0.204938\n",
      "  0.09789156 -0.4713899 ]\n",
      "Training Error:  10.301572699746048\n",
      "====================================================================================================\n",
      "Iteration:  613\n",
      "Previous theta :  [-0.0034642  -0.10664093  0.13511644 -0.00620271  0.06359473 -0.15827897\n",
      "  0.26454033  0.04162056 -0.32189676  0.21693923 -0.17812769 -0.204938\n",
      "  0.09789156 -0.4713899 ]\n",
      "New theta_0 : [-0.00346254 -0.10666643  0.13515405 -0.006194    0.06358395 -0.15839847\n",
      "  0.26450781  0.04162795 -0.32200939  0.21704691 -0.1781918  -0.20496128\n",
      "  0.09789328 -0.47138535]\n",
      "Training Error:  10.301528411121327\n",
      "====================================================================================================\n",
      "Iteration:  614\n",
      "Previous theta :  [-0.00346254 -0.10666643  0.13515405 -0.006194    0.06358395 -0.15839847\n",
      "  0.26450781  0.04162795 -0.32200939  0.21704691 -0.1781918  -0.20496128\n",
      "  0.09789328 -0.47138535]\n",
      "New theta_0 : [-0.00346088 -0.10669177  0.13519142 -0.00618512  0.06357322 -0.15851719\n",
      "  0.26447555  0.0416353  -0.32212116  0.21715417 -0.17825584 -0.20498443\n",
      "  0.09789501 -0.47138079]\n",
      "Training Error:  10.301484623825752\n",
      "====================================================================================================\n",
      "Iteration:  615\n",
      "Previous theta :  [-0.00346088 -0.10669177  0.13519142 -0.00618512  0.06357322 -0.15851719\n",
      "  0.26447555  0.0416353  -0.32212116  0.21715417 -0.17825584 -0.20498443\n",
      "  0.09789501 -0.47138079]\n",
      "New theta_0 : [-0.00345923 -0.10671694  0.13522853 -0.00617608  0.06356253 -0.15863514\n",
      "  0.26444356  0.0416426  -0.32223208  0.21726099 -0.17831981 -0.20500744\n",
      "  0.09789673 -0.47137622]\n",
      "Training Error:  10.301441331301842\n",
      "====================================================================================================\n",
      "Iteration:  616\n",
      "Previous theta :  [-0.00345923 -0.10671694  0.13522853 -0.00617608  0.06356253 -0.15863514\n",
      "  0.26444356  0.0416426  -0.32223208  0.21726099 -0.17831981 -0.20500744\n",
      "  0.09789673 -0.47137622]\n",
      "New theta_0 : [-0.00345759 -0.10674196  0.13526538 -0.00616689  0.0635519  -0.15875232\n",
      "  0.26441182  0.04164985 -0.32234215  0.21736738 -0.17838372 -0.20503033\n",
      "  0.09789846 -0.47137162]\n",
      "Training Error:  10.301398527084755\n",
      "====================================================================================================\n",
      "Iteration:  617\n",
      "Previous theta :  [-0.00345759 -0.10674196  0.13526538 -0.00616689  0.0635519  -0.15875232\n",
      "  0.26441182  0.04164985 -0.32234215  0.21736738 -0.17838372 -0.20503033\n",
      "  0.09789846 -0.47137162]\n",
      "New theta_0 : [-0.00345596 -0.10676681  0.13530199 -0.00615754  0.06354131 -0.15886875\n",
      "  0.26438034  0.04165705 -0.32245139  0.21747335 -0.17844757 -0.20505308\n",
      "  0.09790019 -0.47136701]\n",
      "Training Error:  10.301356204800927\n",
      "====================================================================================================\n",
      "Iteration:  618\n",
      "Previous theta :  [-0.00345596 -0.10676681  0.13530199 -0.00615754  0.06354131 -0.15886875\n",
      "  0.26438034  0.04165705 -0.32245139  0.21747335 -0.17844757 -0.20505308\n",
      "  0.09790019 -0.47136701]\n",
      "New theta_0 : [-0.00345434 -0.10679151  0.13533836 -0.00614803  0.06353077 -0.15898442\n",
      "  0.26434911  0.04166421 -0.32255979  0.21757889 -0.17851135 -0.20507571\n",
      "  0.09790192 -0.47136238]\n",
      "Training Error:  10.301314358166731\n",
      "====================================================================================================\n",
      "Iteration:  619\n",
      "Previous theta :  [-0.00345434 -0.10679151  0.13533836 -0.00614803  0.06353077 -0.15898442\n",
      "  0.26434911  0.04166421 -0.32255979  0.21757889 -0.17851135 -0.20507571\n",
      "  0.09790192 -0.47136238]\n",
      "New theta_0 : [-0.00345272 -0.10681606  0.13537447 -0.00613838  0.06352028 -0.15909934\n",
      "  0.26431813  0.04167132 -0.32266736  0.21768401 -0.17857506 -0.2050982\n",
      "  0.09790365 -0.47135774]\n",
      "Training Error:  10.301272980987159\n",
      "====================================================================================================\n",
      "Iteration:  620\n",
      "Previous theta :  [-0.00345272 -0.10681606  0.13537447 -0.00613838  0.06352028 -0.15909934\n",
      "  0.26431813  0.04167132 -0.32266736  0.21768401 -0.17857506 -0.2050982\n",
      "  0.09790365 -0.47135774]\n",
      "New theta_0 : [-0.00345111 -0.10684044  0.13541035 -0.00612857  0.06350984 -0.15921351\n",
      "  0.2642874   0.04167839 -0.32277412  0.21778871 -0.17863871 -0.20512057\n",
      "  0.09790538 -0.47135309]\n",
      "Training Error:  10.301232067154515\n",
      "====================================================================================================\n",
      "Iteration:  621\n",
      "Previous theta :  [-0.00345111 -0.10684044  0.13541035 -0.00612857  0.06350984 -0.15921351\n",
      "  0.2642874   0.04167839 -0.32277412  0.21778871 -0.17863871 -0.20512057\n",
      "  0.09790538 -0.47135309]\n",
      "New theta_0 : [-0.00344951 -0.10686468  0.13544598 -0.00611862  0.06349944 -0.15932695\n",
      "  0.26425691  0.04168541 -0.32288006  0.217893   -0.1787023  -0.20514281\n",
      "  0.09790712 -0.47134842]\n",
      "Training Error:  10.301191610647146\n",
      "====================================================================================================\n",
      "Iteration:  622\n",
      "Previous theta :  [-0.00344951 -0.10686468  0.13544598 -0.00611862  0.06349944 -0.15932695\n",
      "  0.26425691  0.04168541 -0.32288006  0.217893   -0.1787023  -0.20514281\n",
      "  0.09790712 -0.47134842]\n",
      "New theta_0 : [-0.00344792 -0.10688876  0.13548137 -0.00610852  0.06348909 -0.15943965\n",
      "  0.26422667  0.04169238 -0.3229852   0.21799687 -0.17876581 -0.20516492\n",
      "  0.09790885 -0.47134374]\n",
      "Training Error:  10.30115160552817\n",
      "====================================================================================================\n",
      "Iteration:  623\n",
      "Previous theta :  [-0.00344792 -0.10688876  0.13548137 -0.00610852  0.06348909 -0.15943965\n",
      "  0.26422667  0.04169238 -0.3229852   0.21799687 -0.17876581 -0.20516492\n",
      "  0.09790885 -0.47134374]\n",
      "New theta_0 : [-0.00344633 -0.10691268  0.13551653 -0.00609827  0.06347879 -0.15955161\n",
      "  0.26419668  0.04169931 -0.32308953  0.21810032 -0.17882925 -0.2051869\n",
      "  0.09791059 -0.47133904]\n",
      "Training Error:  10.30111204594424\n",
      "====================================================================================================\n",
      "Iteration:  624\n",
      "Previous theta :  [-0.00344633 -0.10691268  0.13551653 -0.00609827  0.06347879 -0.15955161\n",
      "  0.26419668  0.04169931 -0.32308953  0.21810032 -0.17882925 -0.2051869\n",
      "  0.09791059 -0.47133904]\n",
      "New theta_0 : [-0.00344475 -0.10693646  0.13555145 -0.00608789  0.06346853 -0.15966285\n",
      "  0.26416692  0.0417062  -0.32319307  0.21820336 -0.17889263 -0.20520876\n",
      "  0.09791233 -0.47133434]\n",
      "Training Error:  10.301072926124315\n",
      "====================================================================================================\n",
      "Iteration:  625\n",
      "Previous theta :  [-0.00344475 -0.10693646  0.13555145 -0.00608789  0.06346853 -0.15966285\n",
      "  0.26416692  0.0417062  -0.32319307  0.21820336 -0.17889263 -0.20520876\n",
      "  0.09791233 -0.47133434]\n",
      "New theta_0 : [-0.00344318 -0.10696009  0.13558614 -0.00607736  0.06345832 -0.15977338\n",
      "  0.2641374   0.04171304 -0.32329582  0.218306   -0.17895594 -0.2052305\n",
      "  0.09791407 -0.47132962]\n",
      "Training Error:  10.30103424037846\n",
      "====================================================================================================\n",
      "Iteration:  626\n",
      "Previous theta :  [-0.00344318 -0.10696009  0.13558614 -0.00607736  0.06345832 -0.15977338\n",
      "  0.2641374   0.04171304 -0.32329582  0.218306   -0.17895594 -0.2052305\n",
      "  0.09791407 -0.47132962]\n",
      "New theta_0 : [-0.00344161 -0.10698357  0.13562059 -0.0060667   0.06344816 -0.15988318\n",
      "  0.26410812  0.04171983 -0.32339779  0.21840823 -0.17901918 -0.20525211\n",
      "  0.0979158  -0.47132489]\n",
      "Training Error:  10.300995983096655\n",
      "====================================================================================================\n",
      "Iteration:  627\n",
      "Previous theta :  [-0.00344161 -0.10698357  0.13562059 -0.0060667   0.06344816 -0.15988318\n",
      "  0.26410812  0.04171983 -0.32339779  0.21840823 -0.17901918 -0.20525211\n",
      "  0.0979158  -0.47132489]\n",
      "New theta_0 : [-0.00344005 -0.1070069   0.13565481 -0.0060559   0.06343804 -0.15999227\n",
      "  0.26407907  0.04172658 -0.32349898  0.21851005 -0.17908235 -0.2052736\n",
      "  0.09791754 -0.47132015]\n",
      "Training Error:  10.300958148747624\n",
      "====================================================================================================\n",
      "Iteration:  628\n",
      "Previous theta :  [-0.00344005 -0.1070069   0.13565481 -0.0060559   0.06343804 -0.15999227\n",
      "  0.26407907  0.04172658 -0.32349898  0.21851005 -0.17908235 -0.2052736\n",
      "  0.09791754 -0.47132015]\n",
      "New theta_0 : [-0.0034385  -0.10703008  0.1356888  -0.00604497  0.06342797 -0.16010066\n",
      "  0.26405026  0.04173329 -0.32359941  0.21861147 -0.17914544 -0.20529497\n",
      "  0.09791929 -0.4713154 ]\n",
      "Training Error:  10.30092073187769\n",
      "====================================================================================================\n",
      "Iteration:  629\n",
      "Previous theta :  [-0.0034385  -0.10703008  0.1356888  -0.00604497  0.06342797 -0.16010066\n",
      "  0.26405026  0.04173329 -0.32359941  0.21861147 -0.17914544 -0.20529497\n",
      "  0.09791929 -0.4713154 ]\n",
      "New theta_0 : [-0.00343696 -0.10705312  0.13572257 -0.0060339   0.06341794 -0.16020834\n",
      "  0.26402167  0.04173996 -0.32369906  0.21871249 -0.17920847 -0.20531621\n",
      "  0.09792103 -0.47131064]\n",
      "Training Error:  10.30088372710963\n",
      "====================================================================================================\n",
      "Iteration:  630\n",
      "Previous theta :  [-0.00343696 -0.10705312  0.13572257 -0.0060339   0.06341794 -0.16020834\n",
      "  0.26402167  0.04173996 -0.32369906  0.21871249 -0.17920847 -0.20531621\n",
      "  0.09792103 -0.47131064]\n",
      "New theta_0 : [-0.00343542 -0.10707601  0.13575611 -0.00602271  0.06340796 -0.16031533\n",
      "  0.26399331  0.04174658 -0.32379796  0.21881311 -0.17927142 -0.20533733\n",
      "  0.09792277 -0.47130587]\n",
      "Training Error:  10.300847129141564\n",
      "====================================================================================================\n",
      "Iteration:  631\n",
      "Previous theta :  [-0.00343542 -0.10707601  0.13575611 -0.00602271  0.06340796 -0.16031533\n",
      "  0.26399331  0.04174658 -0.32379796  0.21881311 -0.17927142 -0.20533733\n",
      "  0.09792277 -0.47130587]\n",
      "New theta_0 : [-0.00343389 -0.10709876  0.13578943 -0.00601138  0.06339802 -0.16042162\n",
      "  0.26396518  0.04175316 -0.3238961   0.21891334 -0.17933431 -0.20535834\n",
      "  0.09792451 -0.4713011 ]\n",
      "Training Error:  10.300810932745856\n",
      "====================================================================================================\n",
      "Iteration:  632\n",
      "Previous theta :  [-0.00343389 -0.10709876  0.13578943 -0.00601138  0.06339802 -0.16042162\n",
      "  0.26396518  0.04175316 -0.3238961   0.21891334 -0.17933431 -0.20535834\n",
      "  0.09792451 -0.4713011 ]\n",
      "New theta_0 : [-0.00343237 -0.10712136  0.13582252 -0.00599993  0.06338813 -0.16052723\n",
      "  0.26393727  0.0417597  -0.3239935   0.21901317 -0.17939712 -0.20537922\n",
      "  0.09792625 -0.47129632]\n",
      "Training Error:  10.30077513276802\n",
      "====================================================================================================\n",
      "Iteration:  633\n",
      "Previous theta :  [-0.00343237 -0.10712136  0.13582252 -0.00599993  0.06338813 -0.16052723\n",
      "  0.26393727  0.0417597  -0.3239935   0.21901317 -0.17939712 -0.20537922\n",
      "  0.09792625 -0.47129632]\n",
      "New theta_0 : [-0.00343085 -0.10714383  0.1358554  -0.00598835  0.06337828 -0.16063215\n",
      "  0.26390959  0.0417662  -0.32409016  0.21911261 -0.17945985 -0.20539999\n",
      "  0.097928   -0.47129153]\n",
      "Training Error:  10.30073972412566\n",
      "====================================================================================================\n",
      "Iteration:  634\n",
      "Previous theta :  [-0.00343085 -0.10714383  0.1358554  -0.00598835  0.06337828 -0.16063215\n",
      "  0.26390959  0.0417662  -0.32409016  0.21911261 -0.17945985 -0.20539999\n",
      "  0.097928   -0.47129153]\n",
      "New theta_0 : [-0.00342934 -0.10716615  0.13588805 -0.00597665  0.06336848 -0.16073639\n",
      "  0.26388212  0.04177265 -0.32418608  0.21921165 -0.17952252 -0.20542063\n",
      "  0.09792974 -0.47128673]\n",
      "Training Error:  10.300704701807415\n",
      "====================================================================================================\n",
      "Iteration:  635\n",
      "Previous theta :  [-0.00342934 -0.10716615  0.13588805 -0.00597665  0.06336848 -0.16073639\n",
      "  0.26388212  0.04177265 -0.32418608  0.21921165 -0.17952252 -0.20542063\n",
      "  0.09792974 -0.47128673]\n",
      "New theta_0 : [-0.00342784 -0.10718834  0.13592049 -0.00596483  0.06335871 -0.16083996\n",
      "  0.26385487  0.04177907 -0.32428127  0.21931031 -0.1795851  -0.20544116\n",
      "  0.09793148 -0.47128192]\n",
      "Training Error:  10.30067006087192\n",
      "====================================================================================================\n",
      "Iteration:  636\n",
      "Previous theta :  [-0.00342784 -0.10718834  0.13592049 -0.00596483  0.06335871 -0.16083996\n",
      "  0.26385487  0.04177907 -0.32428127  0.21931031 -0.1795851  -0.20544116\n",
      "  0.09793148 -0.47128192]\n",
      "New theta_0 : [-0.00342634 -0.10721038  0.13595271 -0.00595289  0.063349   -0.16094286\n",
      "  0.26382784  0.04178544 -0.32437573  0.21940858 -0.17964762 -0.20546157\n",
      "  0.09793323 -0.47127712]\n",
      "Training Error:  10.300635796446784\n",
      "====================================================================================================\n",
      "Iteration:  637\n",
      "Previous theta :  [-0.00342634 -0.10721038  0.13595271 -0.00595289  0.063349   -0.16094286\n",
      "  0.26382784  0.04178544 -0.32437573  0.21940858 -0.17964762 -0.20546157\n",
      "  0.09793323 -0.47127712]\n",
      "New theta_0 : [-0.00342485 -0.10723229  0.13598472 -0.00594083  0.06333932 -0.16104509\n",
      "  0.26380102  0.04179177 -0.32446948  0.21950647 -0.17971006 -0.20548187\n",
      "  0.09793497 -0.4712723 ]\n",
      "Training Error:  10.300601903727594\n",
      "====================================================================================================\n",
      "Iteration:  638\n",
      "Previous theta :  [-0.00342485 -0.10723229  0.13598472 -0.00594083  0.06333932 -0.16104509\n",
      "  0.26380102  0.04179177 -0.32446948  0.21950647 -0.17971006 -0.20548187\n",
      "  0.09793497 -0.4712723 ]\n",
      "New theta_0 : [-0.00342337 -0.10725405  0.13601652 -0.00592865  0.06332969 -0.16114665\n",
      "  0.26377442  0.04179806 -0.32456251  0.21960398 -0.17977242 -0.20550205\n",
      "  0.09793671 -0.47126748]\n",
      "Training Error:  10.300568377976917\n",
      "====================================================================================================\n",
      "Iteration:  639\n",
      "Previous theta :  [-0.00342337 -0.10725405  0.13601652 -0.00592865  0.06332969 -0.16114665\n",
      "  0.26377442  0.04179806 -0.32456251  0.21960398 -0.17977242 -0.20550205\n",
      "  0.09793671 -0.47126748]\n",
      "New theta_0 : [-0.0034219  -0.10727569  0.13604811 -0.00591636  0.0633201  -0.16124757\n",
      "  0.26374802  0.04180432 -0.32465483  0.2197011  -0.17983471 -0.20552212\n",
      "  0.09793846 -0.47126266]\n",
      "Training Error:  10.300535214523311\n",
      "====================================================================================================\n",
      "Iteration:  640\n",
      "Previous theta :  [-0.0034219  -0.10727569  0.13604811 -0.00591636  0.0633201  -0.16124757\n",
      "  0.26374802  0.04180432 -0.32465483  0.2197011  -0.17983471 -0.20552212\n",
      "  0.09793846 -0.47126266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00342043 -0.10729719  0.13607949 -0.00590395  0.06331056 -0.16134782\n",
      "  0.26372184  0.04181053 -0.32474646  0.21979785 -0.17989692 -0.20554207\n",
      "  0.0979402  -0.47125783]\n",
      "Training Error:  10.300502408760389\n",
      "====================================================================================================\n",
      "Iteration:  641\n",
      "Previous theta :  [-0.00342043 -0.10729719  0.13607949 -0.00590395  0.06331056 -0.16134782\n",
      "  0.26372184  0.04181053 -0.32474646  0.21979785 -0.17989692 -0.20554207\n",
      "  0.0979402  -0.47125783]\n",
      "New theta_0 : [-0.00341896 -0.10731855  0.13611066 -0.00589144  0.06330105 -0.16144744\n",
      "  0.26369586  0.0418167  -0.32483738  0.21989422 -0.17995905 -0.20556191\n",
      "  0.09794194 -0.471253  ]\n",
      "Training Error:  10.300469956145857\n",
      "====================================================================================================\n",
      "Iteration:  642\n",
      "Previous theta :  [-0.00341896 -0.10731855  0.13611066 -0.00589144  0.06330105 -0.16144744\n",
      "  0.26369586  0.0418167  -0.32483738  0.21989422 -0.17995905 -0.20556191\n",
      "  0.09794194 -0.471253  ]\n",
      "New theta_0 : [-0.00341751 -0.10733978  0.13614162 -0.00587881  0.06329159 -0.1615464\n",
      "  0.26367009  0.04182284 -0.32492761  0.21999021 -0.18002111 -0.20558163\n",
      "  0.09794368 -0.47124816]\n",
      "Training Error:  10.300437852200574\n",
      "====================================================================================================\n",
      "Iteration:  643\n",
      "Previous theta :  [-0.00341751 -0.10733978  0.13614162 -0.00587881  0.06329159 -0.1615464\n",
      "  0.26367009  0.04182284 -0.32492761  0.21999021 -0.18002111 -0.20558163\n",
      "  0.09794368 -0.47124816]\n",
      "New theta_0 : [-0.00341606 -0.10736088  0.13617238 -0.00586608  0.06328217 -0.16164473\n",
      "  0.26364452  0.04182893 -0.32501716  0.22008583 -0.18008309 -0.20560125\n",
      "  0.09794542 -0.47124332]\n",
      "Training Error:  10.300406092507655\n",
      "====================================================================================================\n",
      "Iteration:  644\n",
      "Previous theta :  [-0.00341606 -0.10736088  0.13617238 -0.00586608  0.06328217 -0.16164473\n",
      "  0.26364452  0.04182893 -0.32501716  0.22008583 -0.18008309 -0.20560125\n",
      "  0.09794542 -0.47124332]\n",
      "New theta_0 : [-0.00341462 -0.10738184  0.13620294 -0.00585324  0.0632728  -0.16174242\n",
      "  0.26361915  0.04183499 -0.32510603  0.22018108 -0.18014499 -0.20562075\n",
      "  0.09794716 -0.47123848]\n",
      "Training Error:  10.300374672711538\n",
      "====================================================================================================\n",
      "Iteration:  645\n",
      "Previous theta :  [-0.00341462 -0.10738184  0.13620294 -0.00585324  0.0632728  -0.16174242\n",
      "  0.26361915  0.04183499 -0.32510603  0.22018108 -0.18014499 -0.20562075\n",
      "  0.09794716 -0.47123848]\n",
      "New theta_0 : [-0.00341318 -0.10740268  0.1362333  -0.00584029  0.06326346 -0.16183948\n",
      "  0.26359398  0.04184101 -0.32519421  0.22027596 -0.18020682 -0.20564014\n",
      "  0.0979489  -0.47123364]\n",
      "Training Error:  10.300343588517123\n",
      "====================================================================================================\n",
      "Iteration:  646\n",
      "Previous theta :  [-0.00341318 -0.10740268  0.1362333  -0.00584029  0.06326346 -0.16183948\n",
      "  0.26359398  0.04184101 -0.32519421  0.22027596 -0.18020682 -0.20564014\n",
      "  0.0979489  -0.47123364]\n",
      "New theta_0 : [-0.00341175 -0.10742339  0.13626345 -0.00582724  0.06325417 -0.16193591\n",
      "  0.26356901  0.04184699 -0.32528173  0.22037047 -0.18026856 -0.20565942\n",
      "  0.09795064 -0.4712288 ]\n",
      "Training Error:  10.300312835688858\n",
      "====================================================================================================\n",
      "Iteration:  647\n",
      "Previous theta :  [-0.00341175 -0.10742339  0.13626345 -0.00582724  0.06325417 -0.16193591\n",
      "  0.26356901  0.04184699 -0.32528173  0.22037047 -0.18026856 -0.20565942\n",
      "  0.09795064 -0.4712288 ]\n",
      "New theta_0 : [-0.00341032 -0.10744397  0.13629341 -0.00581409  0.06324491 -0.16203171\n",
      "  0.26354424  0.04185293 -0.32536858  0.22046462 -0.18033023 -0.2056786\n",
      "  0.09795238 -0.47122395]\n",
      "Training Error:  10.300282410049908\n",
      "====================================================================================================\n",
      "Iteration:  648\n",
      "Previous theta :  [-0.00341032 -0.10744397  0.13629341 -0.00581409  0.06324491 -0.16203171\n",
      "  0.26354424  0.04185293 -0.32536858  0.22046462 -0.18033023 -0.2056786\n",
      "  0.09795238 -0.47122395]\n",
      "New theta_0 : [-0.00340891 -0.10746441  0.13632317 -0.00580084  0.0632357  -0.1621269\n",
      "  0.26351966  0.04185884 -0.32545478  0.22055841 -0.18039181 -0.20569766\n",
      "  0.09795412 -0.47121911]\n",
      "Training Error:  10.300252307481276\n",
      "====================================================================================================\n",
      "Iteration:  649\n",
      "Previous theta :  [-0.00340891 -0.10746441  0.13632317 -0.00580084  0.0632357  -0.1621269\n",
      "  0.26351966  0.04185884 -0.32545478  0.22055841 -0.18039181 -0.20569766\n",
      "  0.09795412 -0.47121911]\n",
      "New theta_0 : [-0.00340749 -0.10748474  0.13635274 -0.00578749  0.06322653 -0.16222148\n",
      "  0.26349527  0.04186471 -0.32554031  0.22065183 -0.18045332 -0.20571662\n",
      "  0.09795586 -0.47121426]\n",
      "Training Error:  10.300222523920981\n",
      "====================================================================================================\n",
      "Iteration:  650\n",
      "Previous theta :  [-0.00340749 -0.10748474  0.13635274 -0.00578749  0.06322653 -0.16222148\n",
      "  0.26349527  0.04186471 -0.32554031  0.22065183 -0.18045332 -0.20571662\n",
      "  0.09795586 -0.47121426]\n",
      "New theta_0 : [-0.00340609 -0.10750493  0.13638211 -0.00577404  0.06321739 -0.16231544\n",
      "  0.26347108  0.04187054 -0.3256252   0.22074489 -0.18051474 -0.20573546\n",
      "  0.09795759 -0.47120942]\n",
      "Training Error:  10.30019305536322\n",
      "====================================================================================================\n",
      "Iteration:  651\n",
      "Previous theta :  [-0.00340609 -0.10750493  0.13638211 -0.00577404  0.06321739 -0.16231544\n",
      "  0.26347108  0.04187054 -0.3256252   0.22074489 -0.18051474 -0.20573546\n",
      "  0.09795759 -0.47120942]\n",
      "New theta_0 : [-0.00340469 -0.10752501  0.1364113  -0.0057605   0.0632083  -0.16240879\n",
      "  0.26344707  0.04187634 -0.32570944  0.22083759 -0.18057609 -0.20575421\n",
      "  0.09795933 -0.47120457]\n",
      "Training Error:  10.300163897857551\n",
      "====================================================================================================\n",
      "Iteration:  652\n",
      "Previous theta :  [-0.00340469 -0.10752501  0.1364113  -0.0057605   0.0632083  -0.16240879\n",
      "  0.26344707  0.04187634 -0.32570944  0.22083759 -0.18057609 -0.20575421\n",
      "  0.09795933 -0.47120457]\n",
      "New theta_0 : [-0.0034033  -0.10754495  0.13644029 -0.00574686  0.06319925 -0.16250155\n",
      "  0.26342326  0.0418821  -0.32579304  0.22092994 -0.18063735 -0.20577284\n",
      "  0.09796106 -0.47119972]\n",
      "Training Error:  10.300135047508107\n",
      "====================================================================================================\n",
      "Iteration:  653\n",
      "Previous theta :  [-0.0034033  -0.10754495  0.13644029 -0.00574686  0.06319925 -0.16250155\n",
      "  0.26342326  0.0418821  -0.32579304  0.22092994 -0.18063735 -0.20577284\n",
      "  0.09796106 -0.47119972]\n",
      "New theta_0 : [-0.00340191 -0.10756478  0.13646909 -0.00573313  0.06319024 -0.1625937\n",
      "  0.26339963  0.04188782 -0.325876    0.22102193 -0.18069853 -0.20579137\n",
      "  0.09796279 -0.47119488]\n",
      "Training Error:  10.300106500472785\n",
      "====================================================================================================\n",
      "Iteration:  654\n",
      "Previous theta :  [-0.00340191 -0.10756478  0.13646909 -0.00573313  0.06319024 -0.1625937\n",
      "  0.26339963  0.04188782 -0.325876    0.22102193 -0.18069853 -0.20579137\n",
      "  0.09796279 -0.47119488]\n",
      "New theta_0 : [-0.00340053 -0.10758448  0.1364977  -0.00571931  0.06318127 -0.16268526\n",
      "  0.26337618  0.04189351 -0.32595833  0.22111357 -0.18075963 -0.20580979\n",
      "  0.09796453 -0.47119004]\n",
      "Training Error:  10.300078252962473\n",
      "====================================================================================================\n",
      "Iteration:  655\n",
      "Previous theta :  [-0.00340053 -0.10758448  0.1364977  -0.00571931  0.06318127 -0.16268526\n",
      "  0.26337618  0.04189351 -0.32595833  0.22111357 -0.18075963 -0.20580979\n",
      "  0.09796453 -0.47119004]\n",
      "New theta_0 : [-0.00339915 -0.10760406  0.13652613 -0.00570539  0.06317233 -0.16277622\n",
      "  0.26335292  0.04189916 -0.32604004  0.22120486 -0.18082065 -0.20582811\n",
      "  0.09796626 -0.4711852 ]\n",
      "Training Error:  10.30005030124029\n",
      "====================================================================================================\n",
      "Iteration:  656\n",
      "Previous theta :  [-0.00339915 -0.10760406  0.13652613 -0.00570539  0.06317233 -0.16277622\n",
      "  0.26335292  0.04189916 -0.32604004  0.22120486 -0.18082065 -0.20582811\n",
      "  0.09796626 -0.4711852 ]\n",
      "New theta_0 : [-0.00339778 -0.10762351  0.13655437 -0.00569139  0.06316344 -0.1628666\n",
      "  0.26332984  0.04190478 -0.32612113  0.2212958  -0.18088158 -0.20584633\n",
      "  0.09796799 -0.47118036]\n",
      "Training Error:  10.300022641620822\n",
      "====================================================================================================\n",
      "Iteration:  657\n",
      "Previous theta :  [-0.00339778 -0.10762351  0.13655437 -0.00569139  0.06316344 -0.1628666\n",
      "  0.26332984  0.04190478 -0.32612113  0.2212958  -0.18088158 -0.20584633\n",
      "  0.09796799 -0.47118036]\n",
      "New theta_0 : [-0.00339642 -0.10764285  0.13658242 -0.0056773   0.06315458 -0.1629564\n",
      "  0.26330694  0.04191036 -0.3262016   0.22138639 -0.18094243 -0.20586444\n",
      "  0.09796971 -0.47117552]\n",
      "Training Error:  10.299995270469381\n",
      "====================================================================================================\n",
      "Iteration:  658\n",
      "Previous theta :  [-0.00339642 -0.10764285  0.13658242 -0.0056773   0.06315458 -0.1629564\n",
      "  0.26330694  0.04191036 -0.3262016   0.22138639 -0.18094243 -0.20586444\n",
      "  0.09796971 -0.47117552]\n",
      "New theta_0 : [-0.00339506 -0.10766207  0.1366103  -0.00566313  0.06314577 -0.16304562\n",
      "  0.26328422  0.04191591 -0.32628146  0.22147663 -0.1810032  -0.20588245\n",
      "  0.09797144 -0.47117069]\n",
      "Training Error:  10.299968184201264\n",
      "====================================================================================================\n",
      "Iteration:  659\n",
      "Previous theta :  [-0.00339506 -0.10766207  0.1366103  -0.00566313  0.06314577 -0.16304562\n",
      "  0.26328422  0.04191591 -0.32628146  0.22147663 -0.1810032  -0.20588245\n",
      "  0.09797144 -0.47117069]\n",
      "New theta_0 : [-0.00339371 -0.10768117  0.13663799 -0.00564887  0.06313699 -0.16313426\n",
      "  0.26326167  0.04192142 -0.32636071  0.22156653 -0.18106389 -0.20590036\n",
      "  0.09797316 -0.47116585]\n",
      "Training Error:  10.299941379281039\n",
      "====================================================================================================\n",
      "Iteration:  660\n",
      "Previous theta :  [-0.00339371 -0.10768117  0.13663799 -0.00564887  0.06313699 -0.16313426\n",
      "  0.26326167  0.04192142 -0.32636071  0.22156653 -0.18106389 -0.20590036\n",
      "  0.09797316 -0.47116585]\n",
      "New theta_0 : [-0.00339236 -0.10770015  0.13666551 -0.00563453  0.06312825 -0.16322233\n",
      "  0.2632393   0.0419269  -0.32643935  0.22165609 -0.18112449 -0.20591817\n",
      "  0.09797489 -0.47116103]\n",
      "Training Error:  10.29991485222183\n",
      "====================================================================================================\n",
      "Iteration:  661\n",
      "Previous theta :  [-0.00339236 -0.10770015  0.13666551 -0.00563453  0.06312825 -0.16322233\n",
      "  0.2632393   0.0419269  -0.32643935  0.22165609 -0.18112449 -0.20591817\n",
      "  0.09797489 -0.47116103]\n",
      "New theta_0 : [-0.00339102 -0.10771902  0.13669285 -0.00562011  0.06311955 -0.16330983\n",
      "  0.26321711  0.04193235 -0.32651741  0.22174531 -0.18118501 -0.20593588\n",
      "  0.09797661 -0.4711562 ]\n",
      "Training Error:  10.29988859958461\n",
      "====================================================================================================\n",
      "Iteration:  662\n",
      "Previous theta :  [-0.00339102 -0.10771902  0.13669285 -0.00562011  0.06311955 -0.16330983\n",
      "  0.26321711  0.04193235 -0.32651741  0.22174531 -0.18118501 -0.20593588\n",
      "  0.09797661 -0.4711562 ]\n",
      "New theta_0 : [-0.00338969 -0.10773777  0.13672    -0.0056056   0.06311088 -0.16339677\n",
      "  0.26319509  0.04193776 -0.32659486  0.22183419 -0.18124544 -0.20595348\n",
      "  0.09797833 -0.47115138]\n",
      "Training Error:  10.299862617977517\n",
      "====================================================================================================\n",
      "Iteration:  663\n",
      "Previous theta :  [-0.00338969 -0.10773777  0.13672    -0.0056056   0.06311088 -0.16339677\n",
      "  0.26319509  0.04193776 -0.32659486  0.22183419 -0.18124544 -0.20595348\n",
      "  0.09797833 -0.47115138]\n",
      "New theta_0 : [-0.00338836 -0.1077564   0.13674699 -0.00559102  0.06310226 -0.16348314\n",
      "  0.26317323  0.04194314 -0.32667173  0.22192273 -0.18130578 -0.20597099\n",
      "  0.09798005 -0.47114656]\n",
      "Training Error:  10.299836904055171\n",
      "====================================================================================================\n",
      "Iteration:  664\n",
      "Previous theta :  [-0.00338836 -0.1077564   0.13674699 -0.00559102  0.06310226 -0.16348314\n",
      "  0.26317323  0.04194314 -0.32667173  0.22192273 -0.18130578 -0.20597099\n",
      "  0.09798005 -0.47114656]\n",
      "New theta_0 : [-0.00338704 -0.10777492  0.1367738  -0.00557636  0.06309367 -0.16356896\n",
      "  0.26315155  0.04194848 -0.32674802  0.22201093 -0.18136605 -0.2059884\n",
      "  0.09798176 -0.47114175]\n",
      "Training Error:  10.299811454517998\n",
      "====================================================================================================\n",
      "Iteration:  665\n",
      "Previous theta :  [-0.00338704 -0.10777492  0.1367738  -0.00557636  0.06309367 -0.16356896\n",
      "  0.26315155  0.04194848 -0.32674802  0.22201093 -0.18136605 -0.2059884\n",
      "  0.09798176 -0.47114175]\n",
      "New theta_0 : [-0.00338572 -0.10779333  0.13680043 -0.00556162  0.06308512 -0.16365423\n",
      "  0.26313004  0.0419538  -0.32682372  0.2220988  -0.18142622 -0.20600571\n",
      "  0.09798348 -0.47113695]\n",
      "Training Error:  10.299786266111578\n",
      "====================================================================================================\n",
      "Iteration:  666\n",
      "Previous theta :  [-0.00338572 -0.10779333  0.13680043 -0.00556162  0.06308512 -0.16365423\n",
      "  0.26313004  0.0419538  -0.32682372  0.2220988  -0.18142622 -0.20600571\n",
      "  0.09798348 -0.47113695]\n",
      "New theta_0 : [-0.00338441 -0.10781162  0.1368269  -0.00554681  0.0630766  -0.16373895\n",
      "  0.26310869  0.04195908 -0.32689885  0.22218634 -0.18148631 -0.20602292\n",
      "  0.09798519 -0.47113214]\n",
      "Training Error:  10.299761335625984\n",
      "====================================================================================================\n",
      "Iteration:  667\n",
      "Previous theta :  [-0.00338441 -0.10781162  0.1368269  -0.00554681  0.0630766  -0.16373895\n",
      "  0.26310869  0.04195908 -0.32689885  0.22218634 -0.18148631 -0.20602292\n",
      "  0.09798519 -0.47113214]\n",
      "New theta_0 : [-0.0033831  -0.1078298   0.13685319 -0.00553192  0.06306812 -0.16382312\n",
      "  0.26308751  0.04196433 -0.32697341  0.22227354 -0.18154632 -0.20604003\n",
      "  0.0979869  -0.47112735]\n",
      "Training Error:  10.29973665989515\n",
      "====================================================================================================\n",
      "Iteration:  668\n",
      "Previous theta :  [-0.0033831  -0.1078298   0.13685319 -0.00553192  0.06306812 -0.16382312\n",
      "  0.26308751  0.04196433 -0.32697341  0.22227354 -0.18154632 -0.20604003\n",
      "  0.0979869  -0.47112735]\n",
      "New theta_0 : [-0.0033818  -0.10784787  0.13687932 -0.00551696  0.06305968 -0.16390675\n",
      "  0.26306649  0.04196954 -0.3270474   0.22236042 -0.18160623 -0.20605705\n",
      "  0.09798861 -0.47112255]\n",
      "Training Error:  10.299712235796228\n",
      "====================================================================================================\n",
      "Iteration:  669\n",
      "Previous theta :  [-0.0033818  -0.10784787  0.13687932 -0.00551696  0.06305968 -0.16390675\n",
      "  0.26306649  0.04196954 -0.3270474   0.22236042 -0.18160623 -0.20605705\n",
      "  0.09798861 -0.47112255]\n",
      "New theta_0 : [-0.00338051 -0.10786583  0.13690528 -0.00550193  0.06305128 -0.16398984\n",
      "  0.26304563  0.04197473 -0.32712084  0.22244696 -0.18166607 -0.20607397\n",
      "  0.09799032 -0.47111777]\n",
      "Training Error:  10.29968806024898\n",
      "====================================================================================================\n",
      "Iteration:  670\n",
      "Previous theta :  [-0.00338051 -0.10786583  0.13690528 -0.00550193  0.06305128 -0.16398984\n",
      "  0.26304563  0.04197473 -0.32712084  0.22244696 -0.18166607 -0.20607397\n",
      "  0.09799032 -0.47111777]\n",
      "New theta_0 : [-0.00337922 -0.10788368  0.13693107 -0.00548683  0.06304291 -0.16407239\n",
      "  0.26302494  0.04197988 -0.32719371  0.22253319 -0.18172581 -0.2060908\n",
      "  0.09799202 -0.47111299]\n",
      "Training Error:  10.29966413021515\n",
      "====================================================================================================\n",
      "Iteration:  671\n",
      "Previous theta :  [-0.00337922 -0.10788368  0.13693107 -0.00548683  0.06304291 -0.16407239\n",
      "  0.26302494  0.04197988 -0.32719371  0.22253319 -0.18172581 -0.2060908\n",
      "  0.09799202 -0.47111299]\n",
      "New theta_0 : [-0.00337793 -0.10790142  0.13695669 -0.00547166  0.06303458 -0.16415442\n",
      "  0.2630044   0.041985   -0.32726603  0.22261908 -0.18178547 -0.20610753\n",
      "  0.09799373 -0.47110822]\n",
      "Training Error:  10.299640442697871\n",
      "====================================================================================================\n",
      "Iteration:  672\n",
      "Previous theta :  [-0.00337793 -0.10790142  0.13695669 -0.00547166  0.06303458 -0.16415442\n",
      "  0.2630044   0.041985   -0.32726603  0.22261908 -0.18178547 -0.20610753\n",
      "  0.09799373 -0.47110822]\n",
      "New theta_0 : [-0.00337665 -0.10791905  0.13698216 -0.00545642  0.06302628 -0.16423591\n",
      "  0.26298403  0.04199009 -0.3273378   0.22270466 -0.18184504 -0.20612416\n",
      "  0.09799543 -0.47110345]\n",
      "Training Error:  10.299616994741061\n",
      "====================================================================================================\n",
      "Iteration:  673\n",
      "Previous theta :  [-0.00337665 -0.10791905  0.13698216 -0.00545642  0.06302628 -0.16423591\n",
      "  0.26298403  0.04199009 -0.3273378   0.22270466 -0.18184504 -0.20612416\n",
      "  0.09799543 -0.47110345]\n",
      "New theta_0 : [-0.00337538 -0.10793657  0.13700745 -0.00544112  0.06301802 -0.16431688\n",
      "  0.26296381  0.04199515 -0.32740902  0.22278991 -0.18190452 -0.20614071\n",
      "  0.09799713 -0.47109869]\n",
      "Training Error:  10.299593783428842\n",
      "====================================================================================================\n",
      "Iteration:  674\n",
      "Previous theta :  [-0.00337538 -0.10793657  0.13700745 -0.00544112  0.06301802 -0.16431688\n",
      "  0.26296381  0.04199515 -0.32740902  0.22278991 -0.18190452 -0.20614071\n",
      "  0.09799713 -0.47109869]\n",
      "New theta_0 : [-0.00337411 -0.10795399  0.13703259 -0.00542574  0.0630098  -0.16439733\n",
      "  0.26294374  0.04200018 -0.32747971  0.22287484 -0.18196391 -0.20615715\n",
      "  0.09799882 -0.47109393]\n",
      "Training Error:  10.29957080588496\n",
      "====================================================================================================\n",
      "Iteration:  675\n",
      "Previous theta :  [-0.00337411 -0.10795399  0.13703259 -0.00542574  0.0630098  -0.16439733\n",
      "  0.26294374  0.04200018 -0.32747971  0.22287484 -0.18196391 -0.20615715\n",
      "  0.09799882 -0.47109393]\n",
      "New theta_0 : [-0.00337285 -0.1079713   0.13705757 -0.00541031  0.06300161 -0.16447726\n",
      "  0.26292383  0.04200518 -0.32754986  0.22295946 -0.18202321 -0.20617351\n",
      "  0.09800052 -0.47108919]\n",
      "Training Error:  10.299548059272212\n",
      "====================================================================================================\n",
      "Iteration:  676\n",
      "Previous theta :  [-0.00337285 -0.1079713   0.13705757 -0.00541031  0.06300161 -0.16447726\n",
      "  0.26292383  0.04200518 -0.32754986  0.22295946 -0.18202321 -0.20617351\n",
      "  0.09800052 -0.47108919]\n",
      "New theta_0 : [-0.00337159 -0.1079885   0.13708239 -0.00539481  0.06299345 -0.16455668\n",
      "  0.26290407  0.04201015 -0.32761947  0.22304375 -0.18208243 -0.20618977\n",
      "  0.09800221 -0.47108445]\n",
      "Training Error:  10.2995255407919\n",
      "====================================================================================================\n",
      "Iteration:  677\n",
      "Previous theta :  [-0.00337159 -0.1079885   0.13708239 -0.00539481  0.06299345 -0.16455668\n",
      "  0.26290407  0.04201015 -0.32761947  0.22304375 -0.18208243 -0.20618977\n",
      "  0.09800221 -0.47108445]\n",
      "New theta_0 : [-0.00337034 -0.1080056   0.13710704 -0.00537925  0.06298533 -0.16463558\n",
      "  0.26288447  0.04201509 -0.32768856  0.22312774 -0.18214156 -0.20620595\n",
      "  0.0980039  -0.47107972]\n",
      "Training Error:  10.299503247683253\n",
      "====================================================================================================\n",
      "Iteration:  678\n",
      "Previous theta :  [-0.00337034 -0.1080056   0.13710704 -0.00537925  0.06298533 -0.16463558\n",
      "  0.26288447  0.04201509 -0.32768856  0.22312774 -0.18214156 -0.20620595\n",
      "  0.0980039  -0.47107972]\n",
      "New theta_0 : [-0.00336909 -0.1080226   0.13713155 -0.00536363  0.06297725 -0.16471398\n",
      "  0.26286501  0.04202    -0.32775712  0.2232114  -0.18220059 -0.20622203\n",
      "  0.09800559 -0.471075  ]\n",
      "Training Error:  10.299481177222912\n",
      "====================================================================================================\n",
      "Iteration:  679\n",
      "Previous theta :  [-0.00336909 -0.1080226   0.13713155 -0.00536363  0.06297725 -0.16471398\n",
      "  0.26286501  0.04202    -0.32775712  0.2232114  -0.18220059 -0.20622203\n",
      "  0.09800559 -0.471075  ]\n",
      "New theta_0 : [-0.00336785 -0.10803949  0.13715589 -0.00534795  0.0629692  -0.16479188\n",
      "  0.2628457   0.04202488 -0.32782516  0.22329476 -0.18225954 -0.20623802\n",
      "  0.09800727 -0.47107028]\n",
      "Training Error:  10.299459326724365\n",
      "====================================================================================================\n",
      "Iteration:  680\n",
      "Previous theta :  [-0.00336785 -0.10803949  0.13715589 -0.00534795  0.0629692  -0.16479188\n",
      "  0.2628457   0.04202488 -0.32782516  0.22329476 -0.18225954 -0.20623802\n",
      "  0.09800727 -0.47107028]\n",
      "New theta_0 : [-0.00336661 -0.10805628  0.13718009 -0.00533221  0.06296118 -0.16486927\n",
      "  0.26282655  0.04202973 -0.32789268  0.2233778  -0.1823184  -0.20625392\n",
      "  0.09800896 -0.47106557]\n",
      "Training Error:  10.299437693537444\n",
      "====================================================================================================\n",
      "Iteration:  681\n",
      "Previous theta :  [-0.00336661 -0.10805628  0.13718009 -0.00533221  0.06296118 -0.16486927\n",
      "  0.26282655  0.04202973 -0.32789268  0.2233778  -0.1823184  -0.20625392\n",
      "  0.09800896 -0.47106557]\n",
      "New theta_0 : [-0.00336538 -0.10807297  0.13720412 -0.00531642  0.0629532  -0.16494617\n",
      "  0.26280753  0.04203455 -0.3279597   0.22346054 -0.18237717 -0.20626973\n",
      "  0.09801064 -0.47106088]\n",
      "Training Error:  10.299416275047781\n",
      "====================================================================================================\n",
      "Iteration:  682\n",
      "Previous theta :  [-0.00336538 -0.10807297  0.13720412 -0.00531642  0.0629532  -0.16494617\n",
      "  0.26280753  0.04203455 -0.3279597   0.22346054 -0.18237717 -0.20626973\n",
      "  0.09801064 -0.47106088]\n",
      "New theta_0 : [-0.00336415 -0.10808956  0.13722801 -0.00530056  0.06294525 -0.16502257\n",
      "  0.26278867  0.04203934 -0.3280262   0.22354297 -0.18243585 -0.20628545\n",
      "  0.09801231 -0.47105619]\n",
      "Training Error:  10.29939506867632\n",
      "====================================================================================================\n",
      "Iteration:  683\n",
      "Previous theta :  [-0.00336415 -0.10808956  0.13722801 -0.00530056  0.06294525 -0.16502257\n",
      "  0.26278867  0.04203934 -0.3280262   0.22354297 -0.18243585 -0.20628545\n",
      "  0.09801231 -0.47105619]\n",
      "New theta_0 : [-0.00336293 -0.10810605  0.13725175 -0.00528465  0.06293734 -0.16509848\n",
      "  0.26276994  0.04204411 -0.3280922   0.22362509 -0.18249443 -0.20630108\n",
      "  0.09801399 -0.47105151]\n",
      "Training Error:  10.299374071878784\n",
      "====================================================================================================\n",
      "Iteration:  684\n",
      "Previous theta :  [-0.00336293 -0.10810605  0.13725175 -0.00528465  0.06293734 -0.16509848\n",
      "  0.26276994  0.04204411 -0.3280922   0.22362509 -0.18249443 -0.20630108\n",
      "  0.09801399 -0.47105151]\n",
      "New theta_0 : [-0.00336171 -0.10812243  0.13727533 -0.00526869  0.06292946 -0.1651739\n",
      "  0.26275136  0.04204884 -0.3281577   0.2237069  -0.18255293 -0.20631663\n",
      "  0.09801566 -0.47104684]\n",
      "Training Error:  10.299353282145201\n",
      "====================================================================================================\n",
      "Iteration:  685\n",
      "Previous theta :  [-0.00336171 -0.10812243  0.13727533 -0.00526869  0.06292946 -0.1651739\n",
      "  0.26275136  0.04204884 -0.3281577   0.2237069  -0.18255293 -0.20631663\n",
      "  0.09801566 -0.47104684]\n",
      "New theta_0 : [-0.0033605  -0.10813872  0.13729877 -0.00525267  0.06292162 -0.16524884\n",
      "  0.26273292  0.04205355 -0.3282227   0.22378842 -0.18261134 -0.20633209\n",
      "  0.09801733 -0.47104217]\n",
      "Training Error:  10.299332696999402\n",
      "====================================================================================================\n",
      "Iteration:  686\n",
      "Previous theta :  [-0.0033605  -0.10813872  0.13729877 -0.00525267  0.06292162 -0.16524884\n",
      "  0.26273292  0.04205355 -0.3282227   0.22378842 -0.18261134 -0.20633209\n",
      "  0.09801733 -0.47104217]\n",
      "New theta_0 : [-0.00335929 -0.10815491  0.13732206 -0.00523661  0.0629138  -0.1653233\n",
      "  0.26271462  0.04205823 -0.3282872   0.22386963 -0.18266965 -0.20634746\n",
      "  0.098019   -0.47103752]\n",
      "Training Error:  10.299312313998536\n",
      "====================================================================================================\n",
      "Iteration:  687\n",
      "Previous theta :  [-0.00335929 -0.10815491  0.13732206 -0.00523661  0.0629138  -0.1653233\n",
      "  0.26271462  0.04205823 -0.3282872   0.22386963 -0.18266965 -0.20634746\n",
      "  0.098019   -0.47103752]\n",
      "New theta_0 : [-0.00335809 -0.108171    0.1373452  -0.00522049  0.06290602 -0.16539728\n",
      "  0.26269646  0.04206288 -0.32835122  0.22395054 -0.18272788 -0.20636274\n",
      "  0.09802066 -0.47103288]\n",
      "Training Error:  10.2992921307326\n",
      "====================================================================================================\n",
      "Iteration:  688\n",
      "Previous theta :  [-0.00335809 -0.108171    0.1373452  -0.00522049  0.06290602 -0.16539728\n",
      "  0.26269646  0.04206288 -0.32835122  0.22395054 -0.18272788 -0.20636274\n",
      "  0.09802066 -0.47103288]\n",
      "New theta_0 : [-0.00335689 -0.108187    0.1373682  -0.00520432  0.06289828 -0.16547078\n",
      "  0.26267844  0.04206751 -0.32841475  0.22403115 -0.18278601 -0.20637794\n",
      "  0.09802233 -0.47102824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.299272144823966\n",
      "====================================================================================================\n",
      "Iteration:  689\n",
      "Previous theta :  [-0.00335689 -0.108187    0.1373682  -0.00520432  0.06289828 -0.16547078\n",
      "  0.26267844  0.04206751 -0.32841475  0.22403115 -0.18278601 -0.20637794\n",
      "  0.09802233 -0.47102824]\n",
      "New theta_0 : [-0.0033557  -0.10820289  0.13739105 -0.0051881   0.06289056 -0.16554381\n",
      "  0.26266056  0.04207211 -0.3284778   0.22411146 -0.18284405 -0.20639305\n",
      "  0.09802399 -0.47102362]\n",
      "Training Error:  10.299252353926919\n",
      "====================================================================================================\n",
      "Iteration:  690\n",
      "Previous theta :  [-0.0033557  -0.10820289  0.13739105 -0.0051881   0.06289056 -0.16554381\n",
      "  0.26266056  0.04207211 -0.3284778   0.22411146 -0.18284405 -0.20639305\n",
      "  0.09802399 -0.47102362]\n",
      "New theta_0 : [-0.00335451 -0.1082187   0.13741376 -0.00517183  0.06288288 -0.16561638\n",
      "  0.26264281  0.04207668 -0.32854038  0.22419148 -0.182902   -0.20640808\n",
      "  0.09802564 -0.47101901]\n",
      "Training Error:  10.299232755727202\n",
      "====================================================================================================\n",
      "Iteration:  691\n",
      "Previous theta :  [-0.00335451 -0.1082187   0.13741376 -0.00517183  0.06288288 -0.16561638\n",
      "  0.26264281  0.04207668 -0.32854038  0.22419148 -0.182902   -0.20640808\n",
      "  0.09802564 -0.47101901]\n",
      "New theta_0 : [-0.00335333 -0.1082344   0.13743632 -0.00515551  0.06287523 -0.16568848\n",
      "  0.26262519  0.04208122 -0.32860247  0.2242712  -0.18295985 -0.20642302\n",
      "  0.0980273  -0.4710144 ]\n",
      "Training Error:  10.29921334794157\n",
      "====================================================================================================\n",
      "Iteration:  692\n",
      "Previous theta :  [-0.00335333 -0.1082344   0.13743632 -0.00515551  0.06287523 -0.16568848\n",
      "  0.26262519  0.04208122 -0.32860247  0.2242712  -0.18295985 -0.20642302\n",
      "  0.0980273  -0.4710144 ]\n",
      "New theta_0 : [-0.00335215 -0.10825001  0.13745875 -0.00513915  0.06286762 -0.16576011\n",
      "  0.26260771  0.04208574 -0.3286641   0.22435063 -0.18301762 -0.20643788\n",
      "  0.09802895 -0.47100981]\n",
      "Training Error:  10.299194128317344\n",
      "====================================================================================================\n",
      "Iteration:  693\n",
      "Previous theta :  [-0.00335215 -0.10825001  0.13745875 -0.00513915  0.06286762 -0.16576011\n",
      "  0.26260771  0.04208574 -0.3286641   0.22435063 -0.18301762 -0.20643788\n",
      "  0.09802895 -0.47100981]\n",
      "New theta_0 : [-0.00335097 -0.10826553  0.13748103 -0.00512275  0.06286003 -0.16583129\n",
      "  0.26259036  0.04209023 -0.32872526  0.22442976 -0.18307529 -0.20645265\n",
      "  0.0980306  -0.47100523]\n",
      "Training Error:  10.299175094631972\n",
      "====================================================================================================\n",
      "Iteration:  694\n",
      "Previous theta :  [-0.00335097 -0.10826553  0.13748103 -0.00512275  0.06286003 -0.16583129\n",
      "  0.26259036  0.04209023 -0.32872526  0.22442976 -0.18307529 -0.20645265\n",
      "  0.0980306  -0.47100523]\n",
      "New theta_0 : [-0.0033498  -0.10828096  0.13750318 -0.0051063   0.06285248 -0.16590201\n",
      "  0.26257315  0.04209469 -0.32878595  0.22450861 -0.18313287 -0.20646735\n",
      "  0.09803224 -0.47100066]\n",
      "Training Error:  10.299156244692607\n",
      "====================================================================================================\n",
      "Iteration:  695\n",
      "Previous theta :  [-0.0033498  -0.10828096  0.13750318 -0.0051063   0.06285248 -0.16590201\n",
      "  0.26257315  0.04209469 -0.32878595  0.22450861 -0.18313287 -0.20646735\n",
      "  0.09803224 -0.47100066]\n",
      "New theta_0 : [-0.00334864 -0.10829629  0.13752518 -0.0050898   0.06284496 -0.16597227\n",
      "  0.26255606  0.04209913 -0.32884619  0.22458716 -0.18319035 -0.20648196\n",
      "  0.09803388 -0.4709961 ]\n",
      "Training Error:  10.299137576335685\n",
      "====================================================================================================\n",
      "Iteration:  696\n",
      "Previous theta :  [-0.00334864 -0.10829629  0.13752518 -0.0050898   0.06284496 -0.16597227\n",
      "  0.26255606  0.04209913 -0.32884619  0.22458716 -0.18319035 -0.20648196\n",
      "  0.09803388 -0.4709961 ]\n",
      "New theta_0 : [-0.00334748 -0.10831153  0.13754705 -0.00507326  0.06283747 -0.16604209\n",
      "  0.2625391   0.04210354 -0.32890596  0.22466543 -0.18324775 -0.20649648\n",
      "  0.09803552 -0.47099155]\n",
      "Training Error:  10.2991190874265\n",
      "====================================================================================================\n",
      "Iteration:  697\n",
      "Previous theta :  [-0.00334748 -0.10831153  0.13754705 -0.00507326  0.06283747 -0.16604209\n",
      "  0.2625391   0.04210354 -0.32890596  0.22466543 -0.18324775 -0.20649648\n",
      "  0.09803552 -0.47099155]\n",
      "New theta_0 : [-0.00334633 -0.10832668  0.13756879 -0.00505669  0.06283001 -0.16611146\n",
      "  0.26252227  0.04210793 -0.32896529  0.22474341 -0.18330505 -0.20651093\n",
      "  0.09803716 -0.47098701]\n",
      "Training Error:  10.299100775858802\n",
      "====================================================================================================\n",
      "Iteration:  698\n",
      "Previous theta :  [-0.00334633 -0.10832668  0.13756879 -0.00505669  0.06283001 -0.16611146\n",
      "  0.26252227  0.04210793 -0.32896529  0.22474341 -0.18330505 -0.20651093\n",
      "  0.09803716 -0.47098701]\n",
      "New theta_0 : [-0.00334518 -0.10834174  0.13759038 -0.00504007  0.06282259 -0.16618038\n",
      "  0.26250556  0.04211229 -0.32902416  0.2248211  -0.18336225 -0.2065253\n",
      "  0.09803879 -0.47098249]\n",
      "Training Error:  10.299082639554381\n",
      "====================================================================================================\n",
      "Iteration:  699\n",
      "Previous theta :  [-0.00334518 -0.10834174  0.13759038 -0.00504007  0.06282259 -0.16618038\n",
      "  0.26250556  0.04211229 -0.32902416  0.2248211  -0.18336225 -0.2065253\n",
      "  0.09803879 -0.47098249]\n",
      "New theta_0 : [-0.00334403 -0.10835671  0.13761185 -0.00502341  0.06281519 -0.16624886\n",
      "  0.26248898  0.04211663 -0.32908259  0.22489851 -0.18341936 -0.20653958\n",
      "  0.09804042 -0.47097797]\n",
      "Training Error:  10.299064676462685\n",
      "====================================================================================================\n",
      "Iteration:  700\n",
      "Previous theta :  [-0.00334403 -0.10835671  0.13761185 -0.00502341  0.06281519 -0.16624886\n",
      "  0.26248898  0.04211663 -0.32908259  0.22489851 -0.18341936 -0.20653958\n",
      "  0.09804042 -0.47097797]\n",
      "New theta_0 : [-0.00334289 -0.10837159  0.13763318 -0.00500671  0.06280783 -0.1663169\n",
      "  0.26247253  0.04212094 -0.32914057  0.22497564 -0.18347638 -0.20655378\n",
      "  0.09804205 -0.47097347]\n",
      "Training Error:  10.299046884560411\n",
      "====================================================================================================\n",
      "Iteration:  701\n",
      "Previous theta :  [-0.00334289 -0.10837159  0.13763318 -0.00500671  0.06280783 -0.1663169\n",
      "  0.26247253  0.04212094 -0.32914057  0.22497564 -0.18347638 -0.20655378\n",
      "  0.09804205 -0.47097347]\n",
      "New theta_0 : [-0.00334175 -0.10838638  0.13765438 -0.00498998  0.0628005  -0.16638451\n",
      "  0.2624562   0.04212522 -0.32919812  0.22505249 -0.18353331 -0.20656791\n",
      "  0.09804368 -0.47096898]\n",
      "Training Error:  10.299029261851127\n",
      "====================================================================================================\n",
      "Iteration:  702\n",
      "Previous theta :  [-0.00334175 -0.10838638  0.13765438 -0.00498998  0.0628005  -0.16638451\n",
      "  0.2624562   0.04212522 -0.32919812  0.22505249 -0.18353331 -0.20656791\n",
      "  0.09804368 -0.47096898]\n",
      "New theta_0 : [-0.00334062 -0.10840108  0.13767545 -0.0049732   0.0627932  -0.16645169\n",
      "  0.26243999  0.04212948 -0.32925523  0.22512905 -0.18359014 -0.20658195\n",
      "  0.0980453  -0.4709645 ]\n",
      "Training Error:  10.299011806364893\n",
      "====================================================================================================\n",
      "Iteration:  703\n",
      "Previous theta :  [-0.00334062 -0.10840108  0.13767545 -0.0049732   0.0627932  -0.16645169\n",
      "  0.26243999  0.04212948 -0.32925523  0.22512905 -0.18359014 -0.20658195\n",
      "  0.0980453  -0.4709645 ]\n",
      "New theta_0 : [-0.00333949 -0.10841569  0.13769638 -0.0049564   0.06278592 -0.16651843\n",
      "  0.2624239   0.04213372 -0.3293119   0.22520534 -0.18364687 -0.20659592\n",
      "  0.09804692 -0.47096003]\n",
      "Training Error:  10.298994516157874\n",
      "====================================================================================================\n",
      "Iteration:  704\n",
      "Previous theta :  [-0.00333949 -0.10841569  0.13769638 -0.0049564   0.06278592 -0.16651843\n",
      "  0.2624239   0.04213372 -0.3293119   0.22520534 -0.18364687 -0.20659592\n",
      "  0.09804692 -0.47096003]\n",
      "New theta_0 : [-0.00333837 -0.10843022  0.13771719 -0.00493955  0.06277868 -0.16658475\n",
      "  0.26240793  0.04213793 -0.32936815  0.22528135 -0.18370351 -0.20660981\n",
      "  0.09804853 -0.47095558]\n",
      "Training Error:  10.298977389311984\n",
      "====================================================================================================\n",
      "Iteration:  705\n",
      "Previous theta :  [-0.00333837 -0.10843022  0.13771719 -0.00493955  0.06277868 -0.16658475\n",
      "  0.26240793  0.04213793 -0.32936815  0.22528135 -0.18370351 -0.20660981\n",
      "  0.09804853 -0.47095558]\n",
      "New theta_0 : [-0.00333725 -0.10844466  0.13773787 -0.00492267  0.06277147 -0.16665064\n",
      "  0.26239209  0.04214212 -0.32942397  0.22535709 -0.18376006 -0.20662362\n",
      "  0.09805014 -0.47095113]\n",
      "Training Error:  10.298960423934508\n",
      "====================================================================================================\n",
      "Iteration:  706\n",
      "Previous theta :  [-0.00333725 -0.10844466  0.13773787 -0.00492267  0.06277147 -0.16665064\n",
      "  0.26239209  0.04214212 -0.32942397  0.22535709 -0.18376006 -0.20662362\n",
      "  0.09805014 -0.47095113]\n",
      "New theta_0 : [-0.00333614 -0.10845901  0.13775843 -0.00490576  0.06276429 -0.16671611\n",
      "  0.26237636  0.04214629 -0.32947936  0.22543254 -0.18381651 -0.20663735\n",
      "  0.09805175 -0.4709467 ]\n",
      "Training Error:  10.298943618157749\n",
      "====================================================================================================\n",
      "Iteration:  707\n",
      "Previous theta :  [-0.00333614 -0.10845901  0.13775843 -0.00490576  0.06276429 -0.16671611\n",
      "  0.26237636  0.04214629 -0.32947936  0.22543254 -0.18381651 -0.20663735\n",
      "  0.09805175 -0.4709467 ]\n",
      "New theta_0 : [-0.00333503 -0.10847328  0.13777885 -0.00488882  0.06275714 -0.16678117\n",
      "  0.26236075  0.04215043 -0.32953434  0.22550773 -0.18387287 -0.20665101\n",
      "  0.09805336 -0.47094228]\n",
      "Training Error:  10.298926970138679\n",
      "====================================================================================================\n",
      "Iteration:  708\n",
      "Previous theta :  [-0.00333503 -0.10847328  0.13777885 -0.00488882  0.06275714 -0.16678117\n",
      "  0.26236075  0.04215043 -0.32953434  0.22550773 -0.18387287 -0.20665101\n",
      "  0.09805336 -0.47094228]\n",
      "New theta_0 : [-0.00333392 -0.10848747  0.13779915 -0.00487184  0.06275002 -0.1668458\n",
      "  0.26234525  0.04215454 -0.3295889   0.22558264 -0.18392913 -0.20666458\n",
      "  0.09805496 -0.47093788]\n",
      "Training Error:  10.298910478058579\n",
      "====================================================================================================\n",
      "Iteration:  709\n",
      "Previous theta :  [-0.00333392 -0.10848747  0.13779915 -0.00487184  0.06275002 -0.1668458\n",
      "  0.26234525  0.04215454 -0.3295889   0.22558264 -0.18392913 -0.20666458\n",
      "  0.09805496 -0.47093788]\n",
      "New theta_0 : [-0.00333282 -0.10850157  0.13781933 -0.00485483  0.06274293 -0.16691003\n",
      "  0.26232987  0.04215864 -0.32964305  0.22565728 -0.1839853  -0.20667809\n",
      "  0.09805656 -0.47093349]\n",
      "Training Error:  10.298894140122702\n",
      "====================================================================================================\n",
      "Iteration:  710\n",
      "Previous theta :  [-0.00333282 -0.10850157  0.13781933 -0.00485483  0.06274293 -0.16691003\n",
      "  0.26232987  0.04215864 -0.32964305  0.22565728 -0.1839853  -0.20667809\n",
      "  0.09805656 -0.47093349]\n",
      "New theta_0 : [-0.00333172 -0.10851558  0.13783938 -0.00483779  0.06273587 -0.16697384\n",
      "  0.26231461  0.04216271 -0.32969678  0.22573166 -0.18404137 -0.20669152\n",
      "  0.09805816 -0.47092911]\n",
      "Training Error:  10.298877954559936\n",
      "====================================================================================================\n",
      "Iteration:  711\n",
      "Previous theta :  [-0.00333172 -0.10851558  0.13783938 -0.00483779  0.06273587 -0.16697384\n",
      "  0.26231461  0.04216271 -0.32969678  0.22573166 -0.18404137 -0.20669152\n",
      "  0.09805816 -0.47092911]\n",
      "New theta_0 : [-0.00333063 -0.10852952  0.13785931 -0.00482073  0.06272883 -0.16703725\n",
      "  0.26229945  0.04216675 -0.32975011  0.22580576 -0.18409734 -0.20670487\n",
      "  0.09805975 -0.47092474]\n",
      "Training Error:  10.298861919622462\n",
      "====================================================================================================\n",
      "Iteration:  712\n",
      "Previous theta :  [-0.00333063 -0.10852952  0.13785931 -0.00482073  0.06272883 -0.16703725\n",
      "  0.26229945  0.04216675 -0.32975011  0.22580576 -0.18409734 -0.20670487\n",
      "  0.09805975 -0.47092474]\n",
      "New theta_0 : [-0.00332954 -0.10854337  0.13787912 -0.00480363  0.06272183 -0.16710025\n",
      "  0.26228441  0.04217078 -0.32980304  0.22587959 -0.18415322 -0.20671814\n",
      "  0.09806134 -0.47092038]\n",
      "Training Error:  10.298846033585436\n",
      "====================================================================================================\n",
      "Iteration:  713\n",
      "Previous theta :  [-0.00332954 -0.10854337  0.13787912 -0.00480363  0.06272183 -0.16710025\n",
      "  0.26228441  0.04217078 -0.32980304  0.22587959 -0.18415322 -0.20671814\n",
      "  0.09806134 -0.47092038]\n",
      "New theta_0 : [-0.00332846 -0.10855714  0.1378988  -0.0047865   0.06271485 -0.16716284\n",
      "  0.26226949  0.04217478 -0.32985556  0.22595316 -0.18420901 -0.20673135\n",
      "  0.09806293 -0.47091604]\n",
      "Training Error:  10.298830294746653\n",
      "====================================================================================================\n",
      "Iteration:  714\n",
      "Previous theta :  [-0.00332846 -0.10855714  0.1378988  -0.0047865   0.06271485 -0.16716284\n",
      "  0.26226949  0.04217478 -0.32985556  0.22595316 -0.18420901 -0.20673135\n",
      "  0.09806293 -0.47091604]\n",
      "New theta_0 : [-0.00332738 -0.10857082  0.13791837 -0.00476935  0.06270791 -0.16722504\n",
      "  0.26225467  0.04217876 -0.32990769  0.22602647 -0.18426469 -0.20674448\n",
      "  0.09806451 -0.47091172]\n",
      "Training Error:  10.298814701426236\n",
      "====================================================================================================\n",
      "Iteration:  715\n",
      "Previous theta :  [-0.00332738 -0.10857082  0.13791837 -0.00476935  0.06270791 -0.16722504\n",
      "  0.26225467  0.04217876 -0.32990769  0.22602647 -0.18426469 -0.20674448\n",
      "  0.09806451 -0.47091172]\n",
      "New theta_0 : [-0.0033263  -0.10858443  0.13793782 -0.00475217  0.06270099 -0.16728684\n",
      "  0.26223996  0.04218272 -0.32995942  0.22609951 -0.18432029 -0.20675753\n",
      "  0.09806609 -0.4709074 ]\n",
      "Training Error:  10.298799251966319\n",
      "====================================================================================================\n",
      "Iteration:  716\n",
      "Previous theta :  [-0.0033263  -0.10858443  0.13793782 -0.00475217  0.06270099 -0.16728684\n",
      "  0.26223996  0.04218272 -0.32995942  0.22609951 -0.18432029 -0.20675753\n",
      "  0.09806609 -0.4709074 ]\n",
      "New theta_0 : [-0.00332523 -0.10859796  0.13795715 -0.00473497  0.0626941  -0.16734825\n",
      "  0.26222536  0.04218665 -0.33001076  0.22617228 -0.18437578 -0.20677052\n",
      "  0.09806767 -0.4709031 ]\n",
      "Training Error:  10.298783944730737\n",
      "====================================================================================================\n",
      "Iteration:  717\n",
      "Previous theta :  [-0.00332523 -0.10859796  0.13795715 -0.00473497  0.0626941  -0.16734825\n",
      "  0.26222536  0.04218665 -0.33001076  0.22617228 -0.18437578 -0.20677052\n",
      "  0.09806767 -0.4709031 ]\n",
      "New theta_0 : [-0.00332416 -0.1086114   0.13797636 -0.00471774  0.06268724 -0.16740927\n",
      "  0.26221087  0.04219056 -0.33006171  0.2262448  -0.18443118 -0.20678343\n",
      "  0.09806924 -0.47089881]\n",
      "Training Error:  10.298768778104717\n",
      "====================================================================================================\n",
      "Iteration:  718\n",
      "Previous theta :  [-0.00332416 -0.1086114   0.13797636 -0.00471774  0.06268724 -0.16740927\n",
      "  0.26221087  0.04219056 -0.33006171  0.2262448  -0.18443118 -0.20678343\n",
      "  0.09806924 -0.47089881]\n",
      "New theta_0 : [-0.0033231  -0.10862477  0.13799545 -0.00470049  0.06268041 -0.16746989\n",
      "  0.26219649  0.04219445 -0.33011227  0.22631706 -0.18448648 -0.20679626\n",
      "  0.09807081 -0.47089454]\n",
      "Training Error:  10.298753750494583\n",
      "====================================================================================================\n",
      "Iteration:  719\n",
      "Previous theta :  [-0.0033231  -0.10862477  0.13799545 -0.00470049  0.06268041 -0.16746989\n",
      "  0.26219649  0.04219445 -0.33011227  0.22631706 -0.18448648 -0.20679626\n",
      "  0.09807081 -0.47089454]\n",
      "New theta_0 : [-0.00332204 -0.10863806  0.13801443 -0.00468321  0.06267361 -0.16753013\n",
      "  0.26218221  0.04219832 -0.33016245  0.22638905 -0.18454169 -0.20680903\n",
      "  0.09807237 -0.47089028]\n",
      "Training Error:  10.29873886032746\n",
      "====================================================================================================\n",
      "Iteration:  720\n",
      "Previous theta :  [-0.00332204 -0.10863806  0.13801443 -0.00468321  0.06267361 -0.16753013\n",
      "  0.26218221  0.04219832 -0.33016245  0.22638905 -0.18454169 -0.20680903\n",
      "  0.09807237 -0.47089028]\n",
      "New theta_0 : [-0.00332098 -0.10865127  0.1380333  -0.00466591  0.06266683 -0.16758998\n",
      "  0.26216804  0.04220217 -0.33021225  0.22646079 -0.1845968  -0.20682172\n",
      "  0.09807394 -0.47088603]\n",
      "Training Error:  10.298724106050965\n",
      "====================================================================================================\n",
      "Iteration:  721\n",
      "Previous theta :  [-0.00332098 -0.10865127  0.1380333  -0.00466591  0.06266683 -0.16758998\n",
      "  0.26216804  0.04220217 -0.33021225  0.22646079 -0.1845968  -0.20682172\n",
      "  0.09807394 -0.47088603]\n",
      "New theta_0 : [-0.00331993 -0.1086644   0.13805205 -0.00464859  0.06266008 -0.16764946\n",
      "  0.26215397  0.042206   -0.33026167  0.22653227 -0.18465181 -0.20683435\n",
      "  0.0980755  -0.4708818 ]\n",
      "Training Error:  10.298709486132944\n",
      "====================================================================================================\n",
      "Iteration:  722\n",
      "Previous theta :  [-0.00331993 -0.1086644   0.13805205 -0.00464859  0.06266008 -0.16764946\n",
      "  0.26215397  0.042206   -0.33026167  0.22653227 -0.18465181 -0.20683435\n",
      "  0.0980755  -0.4708818 ]\n",
      "New theta_0 : [-0.00331888 -0.10867746  0.13807068 -0.00463124  0.06265336 -0.16770855\n",
      "  0.26214001  0.0422098  -0.33031072  0.2266035  -0.18470673 -0.2068469\n",
      "  0.09807705 -0.47087758]\n",
      "Training Error:  10.298694999061171\n",
      "====================================================================================================\n",
      "Iteration:  723\n",
      "Previous theta :  [-0.00331888 -0.10867746  0.13807068 -0.00463124  0.06265336 -0.16770855\n",
      "  0.26214001  0.0422098  -0.33031072  0.2266035  -0.18470673 -0.2068469\n",
      "  0.09807705 -0.47087758]\n",
      "New theta_0 : [-0.00331784 -0.10869044  0.13808921 -0.00461388  0.06264667 -0.16776727\n",
      "  0.26212615  0.04221358 -0.3303594   0.22667447 -0.18476155 -0.20685939\n",
      "  0.0980786  -0.47087337]\n",
      "Training Error:  10.298680643343072\n",
      "====================================================================================================\n",
      "Iteration:  724\n",
      "Previous theta :  [-0.00331784 -0.10869044  0.13808921 -0.00461388  0.06264667 -0.16776727\n",
      "  0.26212615  0.04221358 -0.3303594   0.22667447 -0.18476155 -0.20685939\n",
      "  0.0980786  -0.47087337]\n",
      "New theta_0 : [-0.0033168  -0.10870334  0.13810762 -0.00459649  0.06264001 -0.16782561\n",
      "  0.26211238  0.04221735 -0.33040771  0.22674519 -0.18481627 -0.2068718\n",
      "  0.09808015 -0.47086918]\n",
      "Training Error:  10.298666417505448\n",
      "====================================================================================================\n",
      "Iteration:  725\n",
      "Previous theta :  [-0.0033168  -0.10870334  0.13810762 -0.00459649  0.06264001 -0.16782561\n",
      "  0.26211238  0.04221735 -0.33040771  0.22674519 -0.18481627 -0.2068718\n",
      "  0.09808015 -0.47086918]\n",
      "New theta_0 : [-0.00331576 -0.10871617  0.13812592 -0.00457909  0.06263337 -0.16788358\n",
      "  0.26209873  0.04222109 -0.33045565  0.22681566 -0.1848709  -0.20688414\n",
      "  0.0980817  -0.47086501]\n",
      "Training Error:  10.298652320094213\n",
      "====================================================================================================\n",
      "Iteration:  726\n",
      "Previous theta :  [-0.00331576 -0.10871617  0.13812592 -0.00457909  0.06263337 -0.16788358\n",
      "  0.26209873  0.04222109 -0.33045565  0.22681566 -0.1848709  -0.20688414\n",
      "  0.0980817  -0.47086501]\n",
      "New theta_0 : [-0.00331473 -0.10872892  0.13814411 -0.00456167  0.06262676 -0.16794118\n",
      "  0.26208517  0.04222481 -0.33050323  0.22688588 -0.18492542 -0.20689642\n",
      "  0.09808324 -0.47086084]\n",
      "Training Error:  10.298638349674112\n",
      "====================================================================================================\n",
      "Iteration:  727\n",
      "Previous theta :  [-0.00331473 -0.10872892  0.13814411 -0.00456167  0.06262676 -0.16794118\n",
      "  0.26208517  0.04222481 -0.33050323  0.22688588 -0.18492542 -0.20689642\n",
      "  0.09808324 -0.47086084]\n",
      "New theta_0 : [-0.0033137  -0.1087416   0.1381622  -0.00454423  0.06262018 -0.16799842\n",
      "  0.26207171  0.04222851 -0.33055045  0.22695584 -0.18497985 -0.20690863\n",
      "  0.09808478 -0.47085669]\n",
      "Training Error:  10.298624504828467\n",
      "====================================================================================================\n",
      "Iteration:  728\n",
      "Previous theta :  [-0.0033137  -0.1087416   0.1381622  -0.00454423  0.06262018 -0.16799842\n",
      "  0.26207171  0.04222851 -0.33055045  0.22695584 -0.18497985 -0.20690863\n",
      "  0.09808478 -0.47085669]\n",
      "New theta_0 : [-0.00331268 -0.1087542   0.13818017 -0.00452677  0.06261362 -0.16805529\n",
      "  0.26205834  0.04223219 -0.33059732  0.22702556 -0.18503419 -0.20692076\n",
      "  0.09808631 -0.47085256]\n",
      "Training Error:  10.298610784158909\n",
      "====================================================================================================\n",
      "Iteration:  729\n",
      "Previous theta :  [-0.00331268 -0.1087542   0.13818017 -0.00452677  0.06261362 -0.16805529\n",
      "  0.26205834  0.04223219 -0.33059732  0.22702556 -0.18503419 -0.20692076\n",
      "  0.09808631 -0.47085256]\n",
      "New theta_0 : [-0.00331166 -0.10876673  0.13819804 -0.0045093   0.06260709 -0.1681118\n",
      "  0.26204508  0.04223585 -0.33064382  0.22709503 -0.18508842 -0.20693284\n",
      "  0.09808784 -0.47084844]\n",
      "Training Error:  10.298597186285134\n",
      "====================================================================================================\n",
      "Iteration:  730\n",
      "Previous theta :  [-0.00331166 -0.10876673  0.13819804 -0.0045093   0.06260709 -0.1681118\n",
      "  0.26204508  0.04223585 -0.33064382  0.22709503 -0.18508842 -0.20693284\n",
      "  0.09808784 -0.47084844]\n",
      "New theta_0 : [-0.00331064 -0.10877919  0.1382158  -0.00449181  0.06260059 -0.16816795\n",
      "  0.26203191  0.04223949 -0.33068998  0.22716425 -0.18514256 -0.20694484\n",
      "  0.09808937 -0.47084433]\n",
      "Training Error:  10.298583709844635\n",
      "====================================================================================================\n",
      "Iteration:  731\n",
      "Previous theta :  [-0.00331064 -0.10877919  0.1382158  -0.00449181  0.06260059 -0.16816795\n",
      "  0.26203191  0.04223949 -0.33068998  0.22716425 -0.18514256 -0.20694484\n",
      "  0.09808937 -0.47084433]\n",
      "New theta_0 : [-0.00330963 -0.10879157  0.13823345 -0.0044743   0.06259411 -0.16822374\n",
      "  0.26201884  0.04224312 -0.33073579  0.22723323 -0.1851966  -0.20695678\n",
      "  0.0980909  -0.47084024]\n",
      "Training Error:  10.298570353492469\n",
      "====================================================================================================\n",
      "Iteration:  732\n",
      "Previous theta :  [-0.00330963 -0.10879157  0.13823345 -0.0044743   0.06259411 -0.16822374\n",
      "  0.26201884  0.04224312 -0.33073579  0.22723323 -0.1851966  -0.20695678\n",
      "  0.0980909  -0.47084024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00330862 -0.10880389  0.138251   -0.00445678  0.06258766 -0.16827918\n",
      "  0.26200587  0.04224672 -0.33078124  0.22730197 -0.18525054 -0.20696865\n",
      "  0.09809242 -0.47083616]\n",
      "Training Error:  10.298557115900998\n",
      "====================================================================================================\n",
      "Iteration:  733\n",
      "Previous theta :  [-0.00330862 -0.10880389  0.138251   -0.00445678  0.06258766 -0.16827918\n",
      "  0.26200587  0.04224672 -0.33078124  0.22730197 -0.18525054 -0.20696865\n",
      "  0.09809242 -0.47083616]\n",
      "New theta_0 : [-0.00330762 -0.10881613  0.13826844 -0.00443925  0.06258123 -0.16833426\n",
      "  0.26199298  0.0422503  -0.33082636  0.22737046 -0.18530439 -0.20698045\n",
      "  0.09809393 -0.4708321 ]\n",
      "Training Error:  10.298543995759653\n",
      "====================================================================================================\n",
      "Iteration:  734\n",
      "Previous theta :  [-0.00330762 -0.10881613  0.13826844 -0.00443925  0.06258123 -0.16833426\n",
      "  0.26199298  0.0422503  -0.33082636  0.22737046 -0.18530439 -0.20698045\n",
      "  0.09809393 -0.4708321 ]\n",
      "New theta_0 : [-0.00330662 -0.1088283   0.13828578 -0.0044217   0.06257484 -0.168389\n",
      "  0.26198019  0.04225386 -0.33087113  0.22743871 -0.18535813 -0.20699219\n",
      "  0.09809545 -0.47082805]\n",
      "Training Error:  10.29853099177471\n",
      "====================================================================================================\n",
      "Iteration:  735\n",
      "Previous theta :  [-0.00330662 -0.1088283   0.13828578 -0.0044217   0.06257484 -0.168389\n",
      "  0.26198019  0.04225386 -0.33087113  0.22743871 -0.18535813 -0.20699219\n",
      "  0.09809545 -0.47082805]\n",
      "New theta_0 : [-0.00330562 -0.10884039  0.13830302 -0.00440414  0.06256846 -0.16844338\n",
      "  0.2619675   0.0422574  -0.33091557  0.22750671 -0.18541178 -0.20700386\n",
      "  0.09809696 -0.47082402]\n",
      "Training Error:  10.298518102669018\n",
      "====================================================================================================\n",
      "Iteration:  736\n",
      "Previous theta :  [-0.00330562 -0.10884039  0.13830302 -0.00440414  0.06256846 -0.16844338\n",
      "  0.2619675   0.0422574  -0.33091557  0.22750671 -0.18541178 -0.20700386\n",
      "  0.09809696 -0.47082402]\n",
      "New theta_0 : [-0.00330463 -0.10885242  0.13832016 -0.00438656  0.06256212 -0.16849742\n",
      "  0.2619549   0.04226093 -0.33095967  0.22757448 -0.18546533 -0.20701547\n",
      "  0.09809846 -0.47082   ]\n",
      "Training Error:  10.298505327181811\n",
      "====================================================================================================\n",
      "Iteration:  737\n",
      "Previous theta :  [-0.00330463 -0.10885242  0.13832016 -0.00438656  0.06256212 -0.16849742\n",
      "  0.2619549   0.04226093 -0.33095967  0.22757448 -0.18546533 -0.20701547\n",
      "  0.09809846 -0.47082   ]\n",
      "New theta_0 : [-0.00330364 -0.10886438  0.13833719 -0.00436898  0.0625558  -0.16855112\n",
      "  0.26194238  0.04226443 -0.33100343  0.22764201 -0.18551878 -0.20702701\n",
      "  0.09809996 -0.470816  ]\n",
      "Training Error:  10.298492664068453\n",
      "====================================================================================================\n",
      "Iteration:  738\n",
      "Previous theta :  [-0.00330364 -0.10886438  0.13833719 -0.00436898  0.0625558  -0.16855112\n",
      "  0.26194238  0.04226443 -0.33100343  0.22764201 -0.18551878 -0.20702701\n",
      "  0.09809996 -0.470816  ]\n",
      "New theta_0 : [-0.00330265 -0.10887627  0.13835412 -0.00435138  0.0625495  -0.16860448\n",
      "  0.26192996  0.04226792 -0.33104687  0.2277093  -0.18557214 -0.20703849\n",
      "  0.09810146 -0.47081201]\n",
      "Training Error:  10.298480112100222\n",
      "====================================================================================================\n",
      "Iteration:  739\n",
      "Previous theta :  [-0.00330265 -0.10887627  0.13835412 -0.00435138  0.0625495  -0.16860448\n",
      "  0.26192996  0.04226792 -0.33104687  0.2277093  -0.18557214 -0.20703849\n",
      "  0.09810146 -0.47081201]\n",
      "New theta_0 : [-0.00330167 -0.10888809  0.13837095 -0.00433377  0.06254323 -0.1686575\n",
      "  0.26191763  0.04227139 -0.33108997  0.22777636 -0.18562539 -0.20704991\n",
      "  0.09810296 -0.47080803]\n",
      "Training Error:  10.298467670064086\n",
      "====================================================================================================\n",
      "Iteration:  740\n",
      "Previous theta :  [-0.00330167 -0.10888809  0.13837095 -0.00433377  0.06254323 -0.1686575\n",
      "  0.26191763  0.04227139 -0.33108997  0.22777636 -0.18562539 -0.20704991\n",
      "  0.09810296 -0.47080803]\n",
      "New theta_0 : [-0.00330069 -0.10889984  0.13838769 -0.00431616  0.06253699 -0.16871018\n",
      "  0.26190539  0.04227483 -0.33113275  0.22784317 -0.18567855 -0.20706126\n",
      "  0.09810445 -0.47080407]\n",
      "Training Error:  10.298455336762489\n",
      "====================================================================================================\n",
      "Iteration:  741\n",
      "Previous theta :  [-0.00330069 -0.10889984  0.13838769 -0.00431616  0.06253699 -0.16871018\n",
      "  0.26190539  0.04227483 -0.33113275  0.22784317 -0.18567855 -0.20706126\n",
      "  0.09810445 -0.47080407]\n",
      "New theta_0 : [-0.00329971 -0.10891153  0.13840432 -0.00429853  0.06253077 -0.16876253\n",
      "  0.26189323  0.04227827 -0.33117521  0.22790976 -0.18573161 -0.20707255\n",
      "  0.09810594 -0.47080013]\n",
      "Training Error:  10.29844311101313\n",
      "====================================================================================================\n",
      "Iteration:  742\n",
      "Previous theta :  [-0.00329971 -0.10891153  0.13840432 -0.00429853  0.06253077 -0.16876253\n",
      "  0.26189323  0.04227827 -0.33117521  0.22790976 -0.18573161 -0.20707255\n",
      "  0.09810594 -0.47080013]\n",
      "New theta_0 : [-0.00329874 -0.10892315  0.13842086 -0.0042809   0.06252457 -0.16881454\n",
      "  0.26188116  0.04228168 -0.33121734  0.22797611 -0.18578457 -0.20708377\n",
      "  0.09810742 -0.4707962 ]\n",
      "Training Error:  10.29843099164876\n",
      "====================================================================================================\n",
      "Iteration:  743\n",
      "Previous theta :  [-0.00329874 -0.10892315  0.13842086 -0.0042809   0.06252457 -0.16881454\n",
      "  0.26188116  0.04228168 -0.33121734  0.22797611 -0.18578457 -0.20708377\n",
      "  0.09810742 -0.4707962 ]\n",
      "New theta_0 : [-0.00329777 -0.1089347   0.1384373  -0.00426325  0.0625184  -0.16886623\n",
      "  0.26186918  0.04228507 -0.33125915  0.22804223 -0.18583743 -0.20709494\n",
      "  0.0981089  -0.47079228]\n",
      "Training Error:  10.298418977516963\n",
      "====================================================================================================\n",
      "Iteration:  744\n",
      "Previous theta :  [-0.00329777 -0.1089347   0.1384373  -0.00426325  0.0625184  -0.16886623\n",
      "  0.26186918  0.04228507 -0.33125915  0.22804223 -0.18583743 -0.20709494\n",
      "  0.0981089  -0.47079228]\n",
      "New theta_0 : [-0.00329681 -0.10894618  0.13845364 -0.0042456   0.06251226 -0.16891759\n",
      "  0.26185729  0.04228845 -0.33130065  0.22810811 -0.1858902  -0.20710604\n",
      "  0.09811038 -0.47078838]\n",
      "Training Error:  10.298407067479959\n",
      "====================================================================================================\n",
      "Iteration:  745\n",
      "Previous theta :  [-0.00329681 -0.10894618  0.13845364 -0.0042456   0.06251226 -0.16891759\n",
      "  0.26185729  0.04228845 -0.33130065  0.22810811 -0.1858902  -0.20710604\n",
      "  0.09811038 -0.47078838]\n",
      "New theta_0 : [-0.00329585 -0.1089576   0.13846989 -0.00422794  0.06250614 -0.16896862\n",
      "  0.26184548  0.04229181 -0.33134184  0.22817377 -0.18594286 -0.20711708\n",
      "  0.09811185 -0.4707845 ]\n",
      "Training Error:  10.298395260414393\n",
      "====================================================================================================\n",
      "Iteration:  746\n",
      "Previous theta :  [-0.00329585 -0.1089576   0.13846989 -0.00422794  0.06250614 -0.16896862\n",
      "  0.26184548  0.04229181 -0.33134184  0.22817377 -0.18594286 -0.20711708\n",
      "  0.09811185 -0.4707845 ]\n",
      "New theta_0 : [-0.00329489 -0.10896895  0.13848604 -0.00421028  0.06250004 -0.16901933\n",
      "  0.26183376  0.04229515 -0.33138271  0.22823919 -0.18599543 -0.20712806\n",
      "  0.09811332 -0.47078063]\n",
      "Training Error:  10.298383555211144\n",
      "====================================================================================================\n",
      "Iteration:  747\n",
      "Previous theta :  [-0.00329489 -0.10896895  0.13848604 -0.00421028  0.06250004 -0.16901933\n",
      "  0.26183376  0.04229515 -0.33138271  0.22823919 -0.18599543 -0.20712806\n",
      "  0.09811332 -0.47078063]\n",
      "New theta_0 : [-0.00329394 -0.10898023  0.1385021  -0.00419261  0.06249397 -0.16906972\n",
      "  0.26182212  0.04229847 -0.33142328  0.22830439 -0.1860479  -0.20713898\n",
      "  0.09811479 -0.47077677]\n",
      "Training Error:  10.298371950775122\n",
      "====================================================================================================\n",
      "Iteration:  748\n",
      "Previous theta :  [-0.00329394 -0.10898023  0.1385021  -0.00419261  0.06249397 -0.16906972\n",
      "  0.26182212  0.04229847 -0.33142328  0.22830439 -0.1860479  -0.20713898\n",
      "  0.09811479 -0.47077677]\n",
      "New theta_0 : [-0.00329299 -0.10899146  0.13851806 -0.00417493  0.06248793 -0.16911979\n",
      "  0.26181056  0.04230177 -0.33146353  0.22836936 -0.18610027 -0.20714983\n",
      "  0.09811625 -0.47077293]\n",
      "Training Error:  10.298360446025075\n",
      "====================================================================================================\n",
      "Iteration:  749\n",
      "Previous theta :  [-0.00329299 -0.10899146  0.13851806 -0.00417493  0.06248793 -0.16911979\n",
      "  0.26181056  0.04230177 -0.33146353  0.22836936 -0.18610027 -0.20714983\n",
      "  0.09811625 -0.47077293]\n",
      "New theta_0 : [-0.00329204 -0.10900261  0.13853393 -0.00415725  0.06248191 -0.16916954\n",
      "  0.26179909  0.04230506 -0.33150349  0.2284341  -0.18615254 -0.20716063\n",
      "  0.09811771 -0.47076911]\n",
      "Training Error:  10.298349039893397\n",
      "====================================================================================================\n",
      "Iteration:  750\n",
      "Previous theta :  [-0.00329204 -0.10900261  0.13853393 -0.00415725  0.06248191 -0.16916954\n",
      "  0.26179909  0.04230506 -0.33150349  0.2284341  -0.18615254 -0.20716063\n",
      "  0.09811771 -0.47076911]\n",
      "New theta_0 : [-0.0032911  -0.10901371  0.13854971 -0.00413956  0.06247591 -0.16921897\n",
      "  0.26178769  0.04230833 -0.33154314  0.22849862 -0.18620471 -0.20717137\n",
      "  0.09811916 -0.4707653 ]\n",
      "Training Error:  10.298337731325944\n",
      "====================================================================================================\n",
      "Iteration:  751\n",
      "Previous theta :  [-0.0032911  -0.10901371  0.13854971 -0.00413956  0.06247591 -0.16921897\n",
      "  0.26178769  0.04230833 -0.33154314  0.22849862 -0.18620471 -0.20717137\n",
      "  0.09811916 -0.4707653 ]\n",
      "New theta_0 : [-0.00329016 -0.10902474  0.1385654  -0.00412187  0.06246993 -0.1692681\n",
      "  0.26177638  0.04231159 -0.33158249  0.22856292 -0.18625678 -0.20718204\n",
      "  0.09812061 -0.47076151]\n",
      "Training Error:  10.298326519281842\n",
      "====================================================================================================\n",
      "Iteration:  752\n",
      "Previous theta :  [-0.00329016 -0.10902474  0.1385654  -0.00412187  0.06246993 -0.1692681\n",
      "  0.26177638  0.04231159 -0.33158249  0.22856292 -0.18625678 -0.20718204\n",
      "  0.09812061 -0.47076151]\n",
      "New theta_0 : [-0.00328922 -0.1090357   0.13858099 -0.00410418  0.06246398 -0.16931691\n",
      "  0.26176515  0.04231482 -0.33162154  0.22862698 -0.18630876 -0.20719266\n",
      "  0.09812206 -0.47075773]\n",
      "Training Error:  10.298315402733309\n",
      "====================================================================================================\n",
      "Iteration:  753\n",
      "Previous theta :  [-0.00328922 -0.1090357   0.13858099 -0.00410418  0.06246398 -0.16931691\n",
      "  0.26176515  0.04231482 -0.33162154  0.22862698 -0.18630876 -0.20719266\n",
      "  0.09812206 -0.47075773]\n",
      "New theta_0 : [-0.00328829 -0.10904661  0.1385965  -0.00408648  0.06245806 -0.16936542\n",
      "  0.261754    0.04231804 -0.3316603   0.22869083 -0.18636063 -0.20720322\n",
      "  0.0981235  -0.47075396]\n",
      "Training Error:  10.29830438066547\n",
      "====================================================================================================\n",
      "Iteration:  754\n",
      "Previous theta :  [-0.00328829 -0.10904661  0.1385965  -0.00408648  0.06245806 -0.16936542\n",
      "  0.261754    0.04231804 -0.3316603   0.22869083 -0.18636063 -0.20720322\n",
      "  0.0981235  -0.47075396]\n",
      "New theta_0 : [-0.00328736 -0.10905745  0.13861191 -0.00406878  0.06245215 -0.16941361\n",
      "  0.26174293  0.04232125 -0.33169876  0.22875446 -0.18641241 -0.20721372\n",
      "  0.09812494 -0.47075021]\n",
      "Training Error:  10.298293452076186\n",
      "====================================================================================================\n",
      "Iteration:  755\n",
      "Previous theta :  [-0.00328736 -0.10905745  0.13861191 -0.00406878  0.06245215 -0.16941361\n",
      "  0.26174293  0.04232125 -0.33169876  0.22875446 -0.18641241 -0.20721372\n",
      "  0.09812494 -0.47075021]\n",
      "New theta_0 : [-0.00328643 -0.10906823  0.13862724 -0.00405108  0.06244627 -0.16946151\n",
      "  0.26173194  0.04232443 -0.33173694  0.22881786 -0.18646408 -0.20722416\n",
      "  0.09812638 -0.47074648]\n",
      "Training Error:  10.29828261597587\n",
      "====================================================================================================\n",
      "Iteration:  756\n",
      "Previous theta :  [-0.00328643 -0.10906823  0.13862724 -0.00405108  0.06244627 -0.16946151\n",
      "  0.26173194  0.04232443 -0.33173694  0.22881786 -0.18646408 -0.20722416\n",
      "  0.09812638 -0.47074648]\n",
      "New theta_0 : [-0.00328551 -0.10907895  0.13864247 -0.00403337  0.06244042 -0.1695091\n",
      "  0.26172102  0.0423276  -0.33177482  0.22888105 -0.18651566 -0.20723455\n",
      "  0.09812781 -0.47074276]\n",
      "Training Error:  10.298271871387318\n",
      "====================================================================================================\n",
      "Iteration:  757\n",
      "Previous theta :  [-0.00328551 -0.10907895  0.13864247 -0.00403337  0.06244042 -0.1695091\n",
      "  0.26172102  0.0423276  -0.33177482  0.22888105 -0.18651566 -0.20723455\n",
      "  0.09812781 -0.47074276]\n",
      "New theta_0 : [-0.00328459 -0.1090896   0.13865762 -0.00401567  0.06243458 -0.16955639\n",
      "  0.26171018  0.04233076 -0.33181242  0.22894401 -0.18656714 -0.20724488\n",
      "  0.09812924 -0.47073906]\n",
      "Training Error:  10.298261217345539\n",
      "====================================================================================================\n",
      "Iteration:  758\n",
      "Previous theta :  [-0.00328459 -0.1090896   0.13865762 -0.00401567  0.06243458 -0.16955639\n",
      "  0.26171018  0.04233076 -0.33181242  0.22894401 -0.18656714 -0.20724488\n",
      "  0.09812924 -0.47073906]\n",
      "New theta_0 : [-0.00328367 -0.1091002   0.13867268 -0.00399796  0.06242878 -0.16960338\n",
      "  0.26169942  0.04233389 -0.33184974  0.22900676 -0.18661852 -0.20725515\n",
      "  0.09813066 -0.47073537]\n",
      "Training Error:  10.298250652897593\n",
      "====================================================================================================\n",
      "Iteration:  759\n",
      "Previous theta :  [-0.00328367 -0.1091002   0.13867268 -0.00399796  0.06242878 -0.16960338\n",
      "  0.26169942  0.04233389 -0.33184974  0.22900676 -0.18661852 -0.20725515\n",
      "  0.09813066 -0.47073537]\n",
      "New theta_0 : [-0.00328276 -0.10911074  0.13868766 -0.00398026  0.06242299 -0.16965007\n",
      "  0.26168874  0.04233702 -0.33188677  0.22906929 -0.1866698  -0.20726536\n",
      "  0.09813208 -0.47073169]\n",
      "Training Error:  10.298240177102414\n",
      "====================================================================================================\n",
      "Iteration:  760\n",
      "Previous theta :  [-0.00328276 -0.10911074  0.13868766 -0.00398026  0.06242299 -0.16965007\n",
      "  0.26168874  0.04233702 -0.33188677  0.22906929 -0.1866698  -0.20726536\n",
      "  0.09813208 -0.47073169]\n",
      "New theta_0 : [-0.00328185 -0.10912122  0.13870255 -0.00396255  0.06241722 -0.16969647\n",
      "  0.26167813  0.04234012 -0.33192352  0.22913161 -0.18672099 -0.20727552\n",
      "  0.0981335  -0.47072804]\n",
      "Training Error:  10.298229789030655\n",
      "====================================================================================================\n",
      "Iteration:  761\n",
      "Previous theta :  [-0.00328185 -0.10912122  0.13870255 -0.00396255  0.06241722 -0.16969647\n",
      "  0.26167813  0.04234012 -0.33192352  0.22913161 -0.18672099 -0.20727552\n",
      "  0.0981335  -0.47072804]\n",
      "New theta_0 : [-0.00328094 -0.10913163  0.13871735 -0.00394485  0.06241148 -0.16974258\n",
      "  0.2616676   0.04234321 -0.33196     0.22919371 -0.18677207 -0.20728562\n",
      "  0.09813491 -0.47072439]\n",
      "Training Error:  10.298219487764527\n",
      "====================================================================================================\n",
      "Iteration:  762\n",
      "Previous theta :  [-0.00328094 -0.10913163  0.13871735 -0.00394485  0.06241148 -0.16974258\n",
      "  0.2616676   0.04234321 -0.33196     0.22919371 -0.18677207 -0.20728562\n",
      "  0.09813491 -0.47072439]\n",
      "New theta_0 : [-0.00328004 -0.10914199  0.13873207 -0.00392714  0.06240577 -0.16978839\n",
      "  0.26165714  0.04234628 -0.3319962   0.22925559 -0.18682305 -0.20729566\n",
      "  0.09813632 -0.47072077]\n",
      "Training Error:  10.298209272397635\n",
      "====================================================================================================\n",
      "Iteration:  763\n",
      "Previous theta :  [-0.00328004 -0.10914199  0.13873207 -0.00392714  0.06240577 -0.16978839\n",
      "  0.26165714  0.04234628 -0.3319962   0.22925559 -0.18682305 -0.20729566\n",
      "  0.09813632 -0.47072077]\n",
      "New theta_0 : [-0.00327914 -0.10915229  0.13874671 -0.00390944  0.06240007 -0.16983392\n",
      "  0.26164675  0.04234934 -0.33203212  0.22931727 -0.18687394 -0.20730565\n",
      "  0.09813773 -0.47071715]\n",
      "Training Error:  10.298199142034823\n",
      "====================================================================================================\n",
      "Iteration:  764\n",
      "Previous theta :  [-0.00327914 -0.10915229  0.13874671 -0.00390944  0.06240007 -0.16983392\n",
      "  0.26164675  0.04234934 -0.33203212  0.22931727 -0.18687394 -0.20730565\n",
      "  0.09813773 -0.47071715]\n",
      "New theta_0 : [-0.00327824 -0.10916253  0.13876126 -0.00389174  0.0623944  -0.16987916\n",
      "  0.26163644  0.04235238 -0.33206778  0.22937873 -0.18692472 -0.20731558\n",
      "  0.09813913 -0.47071356]\n",
      "Training Error:  10.298189095792036\n",
      "====================================================================================================\n",
      "Iteration:  765\n",
      "Previous theta :  [-0.00327824 -0.10916253  0.13876126 -0.00389174  0.0623944  -0.16987916\n",
      "  0.26163644  0.04235238 -0.33206778  0.22937873 -0.18692472 -0.20731558\n",
      "  0.09813913 -0.47071356]\n",
      "New theta_0 : [-0.00327734 -0.10917271  0.13877572 -0.00387404  0.06238875 -0.16992411\n",
      "  0.26162619  0.04235541 -0.33210316  0.22943998 -0.18697541 -0.20732546\n",
      "  0.09814053 -0.47070998]\n",
      "Training Error:  10.298179132796143\n",
      "====================================================================================================\n",
      "Iteration:  766\n",
      "Previous theta :  [-0.00327734 -0.10917271  0.13877572 -0.00387404  0.06238875 -0.16992411\n",
      "  0.26162619  0.04235541 -0.33210316  0.22943998 -0.18697541 -0.20732546\n",
      "  0.09814053 -0.47070998]\n",
      "New theta_0 : [-0.00327645 -0.10918284  0.13879011 -0.00385635  0.06238312 -0.16996878\n",
      "  0.26161603  0.04235842 -0.33213828  0.22950102 -0.187026   -0.20733529\n",
      "  0.09814192 -0.47070641]\n",
      "Training Error:  10.298169252184803\n",
      "====================================================================================================\n",
      "Iteration:  767\n",
      "Previous theta :  [-0.00327645 -0.10918284  0.13879011 -0.00385635  0.06238312 -0.16996878\n",
      "  0.26161603  0.04235842 -0.33213828  0.22950102 -0.187026   -0.20733529\n",
      "  0.09814192 -0.47070641]\n",
      "New theta_0 : [-0.00327557 -0.10919291  0.13880441 -0.00383866  0.06237751 -0.17001317\n",
      "  0.26160593  0.04236142 -0.33217313  0.22956185 -0.18707649 -0.20734506\n",
      "  0.09814331 -0.47070286]\n",
      "Training Error:  10.298159453106315\n",
      "====================================================================================================\n",
      "Iteration:  768\n",
      "Previous theta :  [-0.00327557 -0.10919291  0.13880441 -0.00383866  0.06237751 -0.17001317\n",
      "  0.26160593  0.04236142 -0.33217313  0.22956185 -0.18707649 -0.20734506\n",
      "  0.09814331 -0.47070286]\n",
      "New theta_0 : [-0.00327468 -0.10920292  0.13881864 -0.00382097  0.06237193 -0.17005728\n",
      "  0.2615959   0.0423644  -0.33220772  0.22962247 -0.18712688 -0.20735477\n",
      "  0.0981447  -0.47069932]\n",
      "Training Error:  10.298149734719471\n",
      "====================================================================================================\n",
      "Iteration:  769\n",
      "Previous theta :  [-0.00327468 -0.10920292  0.13881864 -0.00382097  0.06237193 -0.17005728\n",
      "  0.2615959   0.0423644  -0.33220772  0.22962247 -0.18712688 -0.20735477\n",
      "  0.0981447  -0.47069932]\n",
      "New theta_0 : [-0.0032738  -0.10921288  0.13883278 -0.00380328  0.06236636 -0.17010111\n",
      "  0.26158594  0.04236737 -0.33224205  0.22968288 -0.18717717 -0.20736444\n",
      "  0.09814608 -0.4706958 ]\n",
      "Training Error:  10.29814009619342\n",
      "====================================================================================================\n",
      "Iteration:  770\n",
      "Previous theta :  [-0.0032738  -0.10921288  0.13883278 -0.00380328  0.06236636 -0.17010111\n",
      "  0.26158594  0.04236737 -0.33224205  0.22968288 -0.18717717 -0.20736444\n",
      "  0.09814608 -0.4706958 ]\n",
      "New theta_0 : [-0.00327292 -0.10922278  0.13884684 -0.00378561  0.06236082 -0.17014467\n",
      "  0.26157606  0.04237032 -0.33227612  0.22974309 -0.18722736 -0.20737404\n",
      "  0.09814746 -0.4706923 ]\n",
      "Training Error:  10.298130536707513\n",
      "====================================================================================================\n",
      "Iteration:  771\n",
      "Previous theta :  [-0.00327292 -0.10922278  0.13884684 -0.00378561  0.06236082 -0.17014467\n",
      "  0.26157606  0.04237032 -0.33227612  0.22974309 -0.18722736 -0.20737404\n",
      "  0.09814746 -0.4706923 ]\n",
      "New theta_0 : [-0.00327205 -0.10923262  0.13886082 -0.00376793  0.06235531 -0.17018795\n",
      "  0.26156624  0.04237325 -0.33230993  0.22980309 -0.18727745 -0.2073836\n",
      "  0.09814883 -0.47068881]\n",
      "Training Error:  10.298121055451176\n",
      "====================================================================================================\n",
      "Iteration:  772\n",
      "Previous theta :  [-0.00327205 -0.10923262  0.13886082 -0.00376793  0.06235531 -0.17018795\n",
      "  0.26156624  0.04237325 -0.33230993  0.22980309 -0.18727745 -0.2073836\n",
      "  0.09814883 -0.47068881]\n",
      "New theta_0 : [-0.00327118 -0.10924241  0.13887472 -0.00375026  0.06234981 -0.17023096\n",
      "  0.26155649  0.04237618 -0.33234348  0.22986288 -0.18732745 -0.2073931\n",
      "  0.0981502  -0.47068533]\n",
      "Training Error:  10.29811165162377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  773\n",
      "Previous theta :  [-0.00327118 -0.10924241  0.13887472 -0.00375026  0.06234981 -0.17023096\n",
      "  0.26155649  0.04237618 -0.33234348  0.22986288 -0.18732745 -0.2073931\n",
      "  0.0981502  -0.47068533]\n",
      "New theta_0 : [-0.00327031 -0.10925214  0.13888855 -0.0037326   0.06234433 -0.1702737\n",
      "  0.2615468   0.04237908 -0.33237678  0.22992247 -0.18737734 -0.20740256\n",
      "  0.09815157 -0.47068187]\n",
      "Training Error:  10.298102324434455\n",
      "====================================================================================================\n",
      "Iteration:  774\n",
      "Previous theta :  [-0.00327031 -0.10925214  0.13888855 -0.0037326   0.06234433 -0.1702737\n",
      "  0.2615468   0.04237908 -0.33237678  0.22992247 -0.18737734 -0.20740256\n",
      "  0.09815157 -0.47068187]\n",
      "New theta_0 : [-0.00326944 -0.10926182  0.13890229 -0.00371494  0.06233888 -0.17031617\n",
      "  0.26153719  0.04238198 -0.33240983  0.22998186 -0.18742714 -0.20741195\n",
      "  0.09815294 -0.47067843]\n",
      "Training Error:  10.298093073102054\n",
      "====================================================================================================\n",
      "Iteration:  775\n",
      "Previous theta :  [-0.00326944 -0.10926182  0.13890229 -0.00371494  0.06233888 -0.17031617\n",
      "  0.26153719  0.04238198 -0.33240983  0.22998186 -0.18742714 -0.20741195\n",
      "  0.09815294 -0.47067843]\n",
      "New theta_0 : [-0.00326858 -0.10927145  0.13891596 -0.00369729  0.06233345 -0.17035838\n",
      "  0.26152764  0.04238485 -0.33244263  0.23004104 -0.18747683 -0.2074213\n",
      "  0.0981543  -0.470675  ]\n",
      "Training Error:  10.298083896854928\n",
      "====================================================================================================\n",
      "Iteration:  776\n",
      "Previous theta :  [-0.00326858 -0.10927145  0.13891596 -0.00369729  0.06233345 -0.17035838\n",
      "  0.26152764  0.04238485 -0.33244263  0.23004104 -0.18747683 -0.2074213\n",
      "  0.0981543  -0.470675  ]\n",
      "New theta_0 : [-0.00326772 -0.10928102  0.13892956 -0.00367964  0.06232803 -0.17040032\n",
      "  0.26151816  0.04238772 -0.33247519  0.23010003 -0.18752643 -0.2074306\n",
      "  0.09815565 -0.47067158]\n",
      "Training Error:  10.298074794930837\n",
      "====================================================================================================\n",
      "Iteration:  777\n",
      "Previous theta :  [-0.00326772 -0.10928102  0.13892956 -0.00367964  0.06232803 -0.17040032\n",
      "  0.26151816  0.04238772 -0.33247519  0.23010003 -0.18752643 -0.2074306\n",
      "  0.09815565 -0.47067158]\n",
      "New theta_0 : [-0.00326686 -0.10929054  0.13894307 -0.00366201  0.06232264 -0.17044199\n",
      "  0.26150874  0.04239057 -0.33250749  0.23015881 -0.18757593 -0.20743984\n",
      "  0.098157   -0.47066819]\n",
      "Training Error:  10.298065766576832\n",
      "====================================================================================================\n",
      "Iteration:  778\n",
      "Previous theta :  [-0.00326686 -0.10929054  0.13894307 -0.00366201  0.06232264 -0.17044199\n",
      "  0.26150874  0.04239057 -0.33250749  0.23015881 -0.18757593 -0.20743984\n",
      "  0.098157   -0.47066819]\n",
      "New theta_0 : [-0.00326601 -0.1093      0.13895651 -0.00364438  0.06231727 -0.17048341\n",
      "  0.26149939  0.04239341 -0.33253956  0.23021739 -0.18762533 -0.20744904\n",
      "  0.09815835 -0.4706648 ]\n",
      "Training Error:  10.298056811049099\n",
      "====================================================================================================\n",
      "Iteration:  779\n",
      "Previous theta :  [-0.00326601 -0.1093      0.13895651 -0.00364438  0.06231727 -0.17048341\n",
      "  0.26149939  0.04239341 -0.33253956  0.23021739 -0.18762533 -0.20744904\n",
      "  0.09815835 -0.4706648 ]\n",
      "New theta_0 : [-0.00326516 -0.10930941  0.13896988 -0.00362676  0.06231193 -0.17052456\n",
      "  0.2614901   0.04239623 -0.33257138  0.23027577 -0.18767463 -0.20745818\n",
      "  0.0981597  -0.47066143]\n",
      "Training Error:  10.298047927612865\n",
      "====================================================================================================\n",
      "Iteration:  780\n",
      "Previous theta :  [-0.00326516 -0.10930941  0.13896988 -0.00362676  0.06231193 -0.17052456\n",
      "  0.2614901   0.04239623 -0.33257138  0.23027577 -0.18767463 -0.20745818\n",
      "  0.0981597  -0.47066143]\n",
      "New theta_0 : [-0.00326431 -0.10931877  0.13898317 -0.00360914  0.0623066  -0.17056545\n",
      "  0.26148088  0.04239904 -0.33260296  0.23033396 -0.18772383 -0.20746727\n",
      "  0.09816104 -0.47065808]\n",
      "Training Error:  10.29803911554226\n",
      "====================================================================================================\n",
      "Iteration:  781\n",
      "Previous theta :  [-0.00326431 -0.10931877  0.13898317 -0.00360914  0.0623066  -0.17056545\n",
      "  0.26148088  0.04239904 -0.33260296  0.23033396 -0.18772383 -0.20746727\n",
      "  0.09816104 -0.47065808]\n",
      "New theta_0 : [-0.00326346 -0.10932808  0.13899638 -0.00359154  0.06230129 -0.17060609\n",
      "  0.26147172  0.04240183 -0.3326343   0.23039194 -0.18777293 -0.20747631\n",
      "  0.09816238 -0.47065474]\n",
      "Training Error:  10.298030374120193\n",
      "====================================================================================================\n",
      "Iteration:  782\n",
      "Previous theta :  [-0.00326346 -0.10932808  0.13899638 -0.00359154  0.06230129 -0.17060609\n",
      "  0.26147172  0.04240183 -0.3326343   0.23039194 -0.18777293 -0.20747631\n",
      "  0.09816238 -0.47065474]\n",
      "New theta_0 : [-0.00326262 -0.10933733  0.13900952 -0.00357394  0.062296   -0.17064648\n",
      "  0.26146262  0.04240461 -0.33266541  0.23044973 -0.18782193 -0.20748531\n",
      "  0.09816371 -0.47065142]\n",
      "Training Error:  10.298021702638252\n",
      "====================================================================================================\n",
      "Iteration:  783\n",
      "Previous theta :  [-0.00326262 -0.10933733  0.13900952 -0.00357394  0.062296   -0.17064648\n",
      "  0.26146262  0.04240461 -0.33266541  0.23044973 -0.18782193 -0.20748531\n",
      "  0.09816371 -0.47065142]\n",
      "New theta_0 : [-0.00326178 -0.10934654  0.13902259 -0.00355636  0.06229074 -0.17068661\n",
      "  0.26145359  0.04240738 -0.33269628  0.23050733 -0.18787084 -0.20749425\n",
      "  0.09816504 -0.47064811]\n",
      "Training Error:  10.298013100396563\n",
      "====================================================================================================\n",
      "Iteration:  784\n",
      "Previous theta :  [-0.00326178 -0.10934654  0.13902259 -0.00355636  0.06229074 -0.17068661\n",
      "  0.26145359  0.04240738 -0.33269628  0.23050733 -0.18787084 -0.20749425\n",
      "  0.09816504 -0.47064811]\n",
      "New theta_0 : [-0.00326095 -0.10935569  0.13903559 -0.00353878  0.06228549 -0.17072649\n",
      "  0.26144462  0.04241013 -0.33272691  0.23056473 -0.18791964 -0.20750315\n",
      "  0.09816636 -0.47064482]\n",
      "Training Error:  10.298004566703696\n",
      "====================================================================================================\n",
      "Iteration:  785\n",
      "Previous theta :  [-0.00326095 -0.10935569  0.13903559 -0.00353878  0.06228549 -0.17072649\n",
      "  0.26144462  0.04241013 -0.33272691  0.23056473 -0.18791964 -0.20750315\n",
      "  0.09816636 -0.47064482]\n",
      "New theta_0 : [-0.00326011 -0.10936479  0.13904851 -0.00352121  0.06228027 -0.17076612\n",
      "  0.26143571  0.04241287 -0.33275732  0.23062193 -0.18796835 -0.20751199\n",
      "  0.09816769 -0.47064154]\n",
      "Training Error:  10.297996100876539\n",
      "====================================================================================================\n",
      "Iteration:  786\n",
      "Previous theta :  [-0.00326011 -0.10936479  0.13904851 -0.00352121  0.06228027 -0.17076612\n",
      "  0.26143571  0.04241287 -0.33275732  0.23062193 -0.18796835 -0.20751199\n",
      "  0.09816769 -0.47064154]\n",
      "New theta_0 : [-0.00325928 -0.10937384  0.13906137 -0.00350366  0.06227506 -0.1708055\n",
      "  0.26142686  0.0424156  -0.3327875   0.23067895 -0.18801696 -0.20752079\n",
      "  0.098169   -0.47063828]\n",
      "Training Error:  10.297987702240187\n",
      "====================================================================================================\n",
      "Iteration:  787\n",
      "Previous theta :  [-0.00325928 -0.10937384  0.13906137 -0.00350366  0.06227506 -0.1708055\n",
      "  0.26142686  0.0424156  -0.3327875   0.23067895 -0.18801696 -0.20752079\n",
      "  0.098169   -0.47063828]\n",
      "New theta_0 : [-0.00325846 -0.10938285  0.13907415 -0.00348611  0.06226988 -0.17084463\n",
      "  0.26141807  0.04241831 -0.33281744  0.23073577 -0.18806547 -0.20752954\n",
      "  0.09817032 -0.47063503]\n",
      "Training Error:  10.297979370127836\n",
      "====================================================================================================\n",
      "Iteration:  788\n",
      "Previous theta :  [-0.00325846 -0.10938285  0.13907415 -0.00348611  0.06226988 -0.17084463\n",
      "  0.26141807  0.04241831 -0.33281744  0.23073577 -0.18806547 -0.20752954\n",
      "  0.09817032 -0.47063503]\n",
      "New theta_0 : [-0.00325763 -0.1093918   0.13908686 -0.00346857  0.06226471 -0.17088352\n",
      "  0.26140934  0.04242101 -0.33284717  0.23079239 -0.18811388 -0.20753824\n",
      "  0.09817163 -0.4706318 ]\n",
      "Training Error:  10.297971103880668\n",
      "====================================================================================================\n",
      "Iteration:  789\n",
      "Previous theta :  [-0.00325763 -0.1093918   0.13908686 -0.00346857  0.06226471 -0.17088352\n",
      "  0.26140934  0.04242101 -0.33284717  0.23079239 -0.18811388 -0.20753824\n",
      "  0.09817163 -0.4706318 ]\n",
      "New theta_0 : [-0.00325681 -0.1094007   0.1390995  -0.00345105  0.06225957 -0.17092217\n",
      "  0.26140067  0.0424237  -0.33287666  0.23084883 -0.18816219 -0.20754689\n",
      "  0.09817294 -0.47062858]\n",
      "Training Error:  10.297962902847758\n",
      "====================================================================================================\n",
      "Iteration:  790\n",
      "Previous theta :  [-0.00325681 -0.1094007   0.1390995  -0.00345105  0.06225957 -0.17092217\n",
      "  0.26140067  0.0424237  -0.33287666  0.23084883 -0.18816219 -0.20754689\n",
      "  0.09817294 -0.47062858]\n",
      "New theta_0 : [-0.00325599 -0.10940955  0.13911207 -0.00343354  0.06225444 -0.17096057\n",
      "  0.26139206  0.04242637 -0.33290594  0.23090508 -0.1882104  -0.2075555\n",
      "  0.09817424 -0.47062538]\n",
      "Training Error:  10.297954766385942\n",
      "====================================================================================================\n",
      "Iteration:  791\n",
      "Previous theta :  [-0.00325599 -0.10940955  0.13911207 -0.00343354  0.06225444 -0.17096057\n",
      "  0.26139206  0.04242637 -0.33290594  0.23090508 -0.1882104  -0.2075555\n",
      "  0.09817424 -0.47062538]\n",
      "New theta_0 : [-0.00325517 -0.10941836  0.13912457 -0.00341604  0.06224934 -0.17099874\n",
      "  0.26138351  0.04242904 -0.33293499  0.23096113 -0.18825852 -0.20756405\n",
      "  0.09817554 -0.47062219]\n",
      "Training Error:  10.29794669385974\n",
      "====================================================================================================\n",
      "Iteration:  792\n",
      "Previous theta :  [-0.00325517 -0.10941836  0.13912457 -0.00341604  0.06224934 -0.17099874\n",
      "  0.26138351  0.04242904 -0.33293499  0.23096113 -0.18825852 -0.20756405\n",
      "  0.09817554 -0.47062219]\n",
      "New theta_0 : [-0.00325436 -0.10942711  0.13913701 -0.00339855  0.06224425 -0.17103666\n",
      "  0.26137502  0.04243169 -0.33296383  0.231017   -0.18830653 -0.20757257\n",
      "  0.09817683 -0.47061902]\n",
      "Training Error:  10.297938684641245\n",
      "====================================================================================================\n",
      "Iteration:  793\n",
      "Previous theta :  [-0.00325436 -0.10942711  0.13913701 -0.00339855  0.06224425 -0.17103666\n",
      "  0.26137502  0.04243169 -0.33296383  0.231017   -0.18830653 -0.20757257\n",
      "  0.09817683 -0.47061902]\n",
      "New theta_0 : [-0.00325355 -0.10943582  0.13914937 -0.00338107  0.06223918 -0.17107435\n",
      "  0.26136658  0.04243432 -0.33299245  0.23107268 -0.18835445 -0.20758103\n",
      "  0.09817813 -0.47061586]\n",
      "Training Error:  10.297930738110002\n",
      "====================================================================================================\n",
      "Iteration:  794\n",
      "Previous theta :  [-0.00325355 -0.10943582  0.13914937 -0.00338107  0.06223918 -0.17107435\n",
      "  0.26136658  0.04243432 -0.33299245  0.23107268 -0.18835445 -0.20758103\n",
      "  0.09817813 -0.47061586]\n",
      "New theta_0 : [-0.00325274 -0.10944448  0.13916167 -0.00336361  0.06223414 -0.1711118\n",
      "  0.26135821  0.04243695 -0.33302085  0.23112818 -0.18840227 -0.20758945\n",
      "  0.09817941 -0.47061272]\n",
      "Training Error:  10.297922853652942\n",
      "====================================================================================================\n",
      "Iteration:  795\n",
      "Previous theta :  [-0.00325274 -0.10944448  0.13916167 -0.00336361  0.06223414 -0.1711118\n",
      "  0.26135821  0.04243695 -0.33302085  0.23112818 -0.18840227 -0.20758945\n",
      "  0.09817941 -0.47061272]\n",
      "New theta_0 : [-0.00325194 -0.10945309  0.1391739  -0.00334616  0.06222911 -0.17114902\n",
      "  0.26134989  0.04243956 -0.33304904  0.23118348 -0.18844999 -0.20759782\n",
      "  0.0981807  -0.47060959]\n",
      "Training Error:  10.297915030664253\n",
      "====================================================================================================\n",
      "Iteration:  796\n",
      "Previous theta :  [-0.00325194 -0.10945309  0.1391739  -0.00334616  0.06222911 -0.17114902\n",
      "  0.26134989  0.04243956 -0.33304904  0.23118348 -0.18844999 -0.20759782\n",
      "  0.0981807  -0.47060959]\n",
      "New theta_0 : [-0.00325113 -0.10946166  0.13918606 -0.00332873  0.0622241  -0.17118601\n",
      "  0.26134162  0.04244216 -0.33307701  0.23123861 -0.18849761 -0.20760615\n",
      "  0.09818198 -0.47060648]\n",
      "Training Error:  10.297907268545305\n",
      "====================================================================================================\n",
      "Iteration:  797\n",
      "Previous theta :  [-0.00325113 -0.10946166  0.13918606 -0.00332873  0.0622241  -0.17118601\n",
      "  0.26134162  0.04244216 -0.33307701  0.23123861 -0.18849761 -0.20760615\n",
      "  0.09818198 -0.47060648]\n",
      "New theta_0 : [-0.00325034 -0.10947017  0.13919816 -0.0033113   0.06221911 -0.17122276\n",
      "  0.26133341  0.04244474 -0.33310477  0.23129354 -0.18854513 -0.20761443\n",
      "  0.09818325 -0.47060338]\n",
      "Training Error:  10.297899566704542\n",
      "====================================================================================================\n",
      "Iteration:  798\n",
      "Previous theta :  [-0.00325034 -0.10947017  0.13919816 -0.0033113   0.06221911 -0.17122276\n",
      "  0.26133341  0.04244474 -0.33310477  0.23129354 -0.18854513 -0.20761443\n",
      "  0.09818325 -0.47060338]\n",
      "New theta_0 : [-0.00324954 -0.10947865  0.13921019 -0.00329389  0.06221414 -0.17125929\n",
      "  0.26132526  0.04244732 -0.33313233  0.2313483  -0.18859256 -0.20762266\n",
      "  0.09818453 -0.47060029]\n",
      "Training Error:  10.297891924557385\n",
      "====================================================================================================\n",
      "Iteration:  799\n",
      "Previous theta :  [-0.00324954 -0.10947865  0.13921019 -0.00329389  0.06221414 -0.17125929\n",
      "  0.26132526  0.04244732 -0.33313233  0.2313483  -0.18859256 -0.20762266\n",
      "  0.09818453 -0.47060029]\n",
      "New theta_0 : [-0.00324874 -0.10948707  0.13922215 -0.0032765   0.06220919 -0.17129559\n",
      "  0.26131716  0.04244988 -0.33315967  0.23140287 -0.18863989 -0.20763086\n",
      "  0.0981858  -0.47059723]\n",
      "Training Error:  10.297884341526155\n",
      "====================================================================================================\n",
      "Iteration:  800\n",
      "Previous theta :  [-0.00324874 -0.10948707  0.13922215 -0.0032765   0.06220919 -0.17129559\n",
      "  0.26131716  0.04244988 -0.33315967  0.23140287 -0.18863989 -0.20763086\n",
      "  0.0981858  -0.47059723]\n",
      "New theta_0 : [-0.00324795 -0.10949545  0.13923406 -0.00325912  0.06220426 -0.17133166\n",
      "  0.26130911  0.04245243 -0.33318681  0.23145725 -0.18868712 -0.207639\n",
      "  0.09818706 -0.47059417]\n",
      "Training Error:  10.297876817039965\n",
      "====================================================================================================\n",
      "Iteration:  801\n",
      "Previous theta :  [-0.00324795 -0.10949545  0.13923406 -0.00325912  0.06220426 -0.17133166\n",
      "  0.26130911  0.04245243 -0.33318681  0.23145725 -0.18868712 -0.207639\n",
      "  0.09818706 -0.47059417]\n",
      "New theta_0 : [-0.00324716 -0.10950378  0.13924589 -0.00324175  0.06219934 -0.17136751\n",
      "  0.26130112  0.04245497 -0.33321375  0.23151146 -0.18873425 -0.2076471\n",
      "  0.09818832 -0.47059113]\n",
      "Training Error:  10.297869350534636\n",
      "====================================================================================================\n",
      "Iteration:  802\n",
      "Previous theta :  [-0.00324716 -0.10950378  0.13924589 -0.00324175  0.06219934 -0.17136751\n",
      "  0.26130112  0.04245497 -0.33321375  0.23151146 -0.18873425 -0.2076471\n",
      "  0.09818832 -0.47059113]\n",
      "New theta_0 : [-0.00324638 -0.10951207  0.13925766 -0.0032244   0.06219445 -0.17140313\n",
      "  0.26129319  0.04245749 -0.33324048  0.23156548 -0.18878128 -0.20765516\n",
      "  0.09818958 -0.47058811]\n",
      "Training Error:  10.297861941452611\n",
      "====================================================================================================\n",
      "Iteration:  803\n",
      "Previous theta :  [-0.00324638 -0.10951207  0.13925766 -0.0032244   0.06219445 -0.17140313\n",
      "  0.26129319  0.04245749 -0.33324048  0.23156548 -0.18878128 -0.20765516\n",
      "  0.09818958 -0.47058811]\n",
      "New theta_0 : [-0.00324559 -0.10952031  0.13926937 -0.00320707  0.06218957 -0.17143854\n",
      "  0.2612853   0.04246001 -0.33326701  0.23161933 -0.18882821 -0.20766317\n",
      "  0.09819084 -0.4705851 ]\n",
      "Training Error:  10.29785458924286\n",
      "====================================================================================================\n",
      "Iteration:  804\n",
      "Previous theta :  [-0.00324559 -0.10952031  0.13926937 -0.00320707  0.06218957 -0.17143854\n",
      "  0.2612853   0.04246001 -0.33326701  0.23161933 -0.18882821 -0.20766317\n",
      "  0.09819084 -0.4705851 ]\n",
      "New theta_0 : [-0.00324481 -0.10952851  0.13928102 -0.00318975  0.06218472 -0.17147372\n",
      "  0.26127747  0.04246251 -0.33329334  0.23167299 -0.18887505 -0.20767114\n",
      "  0.09819209 -0.4705821 ]\n",
      "Training Error:  10.297847293360798\n",
      "====================================================================================================\n",
      "Iteration:  805\n",
      "Previous theta :  [-0.00324481 -0.10952851  0.13928102 -0.00318975  0.06218472 -0.17147372\n",
      "  0.26127747  0.04246251 -0.33329334  0.23167299 -0.18887505 -0.20767114\n",
      "  0.09819209 -0.4705821 ]\n",
      "New theta_0 : [-0.00324404 -0.10953666  0.1392926  -0.00317245  0.06217988 -0.17150868\n",
      "  0.2612697   0.042465   -0.33331947  0.23172648 -0.18892179 -0.20767907\n",
      "  0.09819333 -0.47057912]\n",
      "Training Error:  10.297840053268201\n",
      "====================================================================================================\n",
      "Iteration:  806\n",
      "Previous theta :  [-0.00324404 -0.10953666  0.1392926  -0.00317245  0.06217988 -0.17150868\n",
      "  0.2612697   0.042465   -0.33331947  0.23172648 -0.18892179 -0.20767907\n",
      "  0.09819333 -0.47057912]\n",
      "New theta_0 : [-0.00324326 -0.10954477  0.13930412 -0.00315516  0.06217506 -0.17154343\n",
      "  0.26126197  0.04246748 -0.33334541  0.23177979 -0.18896843 -0.20768695\n",
      "  0.09819458 -0.47057615]\n",
      "Training Error:  10.297832868433115\n",
      "====================================================================================================\n",
      "Iteration:  807\n",
      "Previous theta :  [-0.00324326 -0.10954477  0.13930412 -0.00315516  0.06217506 -0.17154343\n",
      "  0.26126197  0.04246748 -0.33334541  0.23177979 -0.18896843 -0.20768695\n",
      "  0.09819458 -0.47057615]\n",
      "New theta_0 : [-0.00324249 -0.10955284  0.13931558 -0.00313789  0.06217026 -0.17157796\n",
      "  0.2612543   0.04246995 -0.33337115  0.23183292 -0.18901497 -0.20769479\n",
      "  0.09819581 -0.4705732 ]\n",
      "Training Error:  10.297825738329786\n",
      "====================================================================================================\n",
      "Iteration:  808\n",
      "Previous theta :  [-0.00324249 -0.10955284  0.13931558 -0.00313789  0.06217026 -0.17157796\n",
      "  0.2612543   0.04246995 -0.33337115  0.23183292 -0.18901497 -0.20769479\n",
      "  0.09819581 -0.4705732 ]\n",
      "New theta_0 : [-0.00324172 -0.10956086  0.13932697 -0.00312064  0.06216547 -0.17161227\n",
      "  0.26124667  0.04247241 -0.33339669  0.23188587 -0.18906141 -0.20770259\n",
      "  0.09819705 -0.47057027]\n",
      "Training Error:  10.29781866243856\n",
      "====================================================================================================\n",
      "Iteration:  809\n",
      "Previous theta :  [-0.00324172 -0.10956086  0.13932697 -0.00312064  0.06216547 -0.17161227\n",
      "  0.26124667  0.04247241 -0.33339669  0.23188587 -0.18906141 -0.20770259\n",
      "  0.09819705 -0.47057027]\n",
      "New theta_0 : [-0.00324095 -0.10956884  0.13933831 -0.0031034   0.06216071 -0.17164637\n",
      "  0.2612391   0.04247485 -0.33342204  0.23193865 -0.18910776 -0.20771034\n",
      "  0.09819828 -0.47056734]\n",
      "Training Error:  10.297811640245818\n",
      "====================================================================================================\n",
      "Iteration:  810\n",
      "Previous theta :  [-0.00324095 -0.10956884  0.13933831 -0.0031034   0.06216071 -0.17164637\n",
      "  0.2612391   0.04247485 -0.33342204  0.23193865 -0.18910776 -0.20771034\n",
      "  0.09819828 -0.47056734]\n",
      "New theta_0 : [-0.00324018 -0.10957677  0.13934958 -0.00308618  0.06215596 -0.17168026\n",
      "  0.26123158  0.04247728 -0.3334472   0.23199125 -0.18915401 -0.20771805\n",
      "  0.09819951 -0.47056443]\n",
      "Training Error:  10.297804671243894\n",
      "====================================================================================================\n",
      "Iteration:  811\n",
      "Previous theta :  [-0.00324018 -0.10957677  0.13934958 -0.00308618  0.06215596 -0.17168026\n",
      "  0.26123158  0.04247728 -0.3334472   0.23199125 -0.18915401 -0.20771805\n",
      "  0.09819951 -0.47056443]\n",
      "New theta_0 : [-0.00323942 -0.10958466  0.1393608  -0.00306897  0.06215123 -0.17171394\n",
      "  0.2612241   0.04247971 -0.33347217  0.23204368 -0.18920016 -0.20772572\n",
      "  0.09820073 -0.47056154]\n",
      "Training Error:  10.29779775493098\n",
      "====================================================================================================\n",
      "Iteration:  812\n",
      "Previous theta :  [-0.00323942 -0.10958466  0.1393608  -0.00306897  0.06215123 -0.17171394\n",
      "  0.2612241   0.04247971 -0.33347217  0.23204368 -0.18920016 -0.20772572\n",
      "  0.09820073 -0.47056154]\n",
      "New theta_0 : [-0.00323866 -0.10959251  0.13937195 -0.00305179  0.06214652 -0.17174741\n",
      "  0.26121668  0.04248212 -0.33349696  0.23209594 -0.18924622 -0.20773335\n",
      "  0.09820195 -0.47055866]\n",
      "Training Error:  10.297790890811074\n",
      "====================================================================================================\n",
      "Iteration:  813\n",
      "Previous theta :  [-0.00323866 -0.10959251  0.13937195 -0.00305179  0.06214652 -0.17174741\n",
      "  0.26121668  0.04248212 -0.33349696  0.23209594 -0.18924622 -0.20773335\n",
      "  0.09820195 -0.47055866]\n",
      "New theta_0 : [-0.0032379  -0.10960032  0.13938304 -0.00303462  0.06214182 -0.17178067\n",
      "  0.26120931  0.04248452 -0.33352155  0.23214802 -0.18929217 -0.20774094\n",
      "  0.09820317 -0.4705558 ]\n",
      "Training Error:  10.297784078393892\n",
      "====================================================================================================\n",
      "Iteration:  814\n",
      "Previous theta :  [-0.0032379  -0.10960032  0.13938304 -0.00303462  0.06214182 -0.17178067\n",
      "  0.26120931  0.04248452 -0.33352155  0.23214802 -0.18929217 -0.20774094\n",
      "  0.09820317 -0.4705558 ]\n",
      "New theta_0 : [-0.00323715 -0.10960808  0.13939408 -0.00301747  0.06213715 -0.17181373\n",
      "  0.26120198  0.04248691 -0.33354596  0.23219993 -0.18933803 -0.20774849\n",
      "  0.09820439 -0.47055294]\n",
      "Training Error:  10.297777317194782\n",
      "====================================================================================================\n",
      "Iteration:  815\n",
      "Previous theta :  [-0.00323715 -0.10960808  0.13939408 -0.00301747  0.06213715 -0.17181373\n",
      "  0.26120198  0.04248691 -0.33354596  0.23219993 -0.18933803 -0.20774849\n",
      "  0.09820439 -0.47055294]\n",
      "New theta_0 : [-0.0032364  -0.1096158   0.13940506 -0.00300034  0.06213249 -0.17184658\n",
      "  0.26119471  0.04248929 -0.33357019  0.23225166 -0.1893838  -0.20775599\n",
      "  0.09820559 -0.47055011]\n",
      "Training Error:  10.297770606734673\n",
      "====================================================================================================\n",
      "Iteration:  816\n",
      "Previous theta :  [-0.0032364  -0.1096158   0.13940506 -0.00300034  0.06213249 -0.17184658\n",
      "  0.26119471  0.04248929 -0.33357019  0.23225166 -0.1893838  -0.20775599\n",
      "  0.09820559 -0.47055011]\n",
      "New theta_0 : [-0.00323565 -0.10962349  0.13941598 -0.00298323  0.06212785 -0.17187923\n",
      "  0.26118748  0.04249165 -0.33359423  0.23230323 -0.18942946 -0.20776345\n",
      "  0.0982068  -0.47054728]\n",
      "Training Error:  10.297763946539979\n",
      "====================================================================================================\n",
      "Iteration:  817\n",
      "Previous theta :  [-0.00323565 -0.10962349  0.13941598 -0.00298323  0.06212785 -0.17187923\n",
      "  0.26118748  0.04249165 -0.33359423  0.23230323 -0.18942946 -0.20776345\n",
      "  0.0982068  -0.47054728]\n",
      "New theta_0 : [-0.0032349  -0.10963113  0.13942684 -0.00296613  0.06212322 -0.17191167\n",
      "  0.2611803   0.04249401 -0.33361809  0.23235463 -0.18947503 -0.20777088\n",
      "  0.098208   -0.47054448]\n",
      "Training Error:  10.297757336142547\n",
      "====================================================================================================\n",
      "Iteration:  818\n",
      "Previous theta :  [-0.0032349  -0.10963113  0.13942684 -0.00296613  0.06212322 -0.17191167\n",
      "  0.2611803   0.04249401 -0.33361809  0.23235463 -0.18947503 -0.20777088\n",
      "  0.098208   -0.47054448]\n",
      "New theta_0 : [-0.00323415 -0.10963872  0.13943764 -0.00294906  0.06211861 -0.17194391\n",
      "  0.26117316  0.04249636 -0.33364178  0.23240585 -0.1895205  -0.20777826\n",
      "  0.0982092  -0.47054168]\n",
      "Training Error:  10.297750775079567\n",
      "====================================================================================================\n",
      "Iteration:  819\n",
      "Previous theta :  [-0.00323415 -0.10963872  0.13943764 -0.00294906  0.06211861 -0.17194391\n",
      "  0.26117316  0.04249636 -0.33364178  0.23240585 -0.1895205  -0.20777826\n",
      "  0.0982092  -0.47054168]\n",
      "New theta_0 : [-0.00323341 -0.10964628  0.13944839 -0.002932    0.06211403 -0.17197596\n",
      "  0.26116608  0.04249869 -0.33366528  0.23245691 -0.18956587 -0.2077856\n",
      "  0.0982104  -0.4705389 ]\n",
      "Training Error:  10.29774426289352\n",
      "====================================================================================================\n",
      "Iteration:  820\n",
      "Previous theta :  [-0.00323341 -0.10964628  0.13944839 -0.002932    0.06211403 -0.17197596\n",
      "  0.26116608  0.04249869 -0.33366528  0.23245691 -0.18956587 -0.2077856\n",
      "  0.0982104  -0.4705389 ]\n",
      "New theta_0 : [-0.00323267 -0.1096538   0.13945908 -0.00291497  0.06210945 -0.1720078\n",
      "  0.26115904  0.04250102 -0.33368861  0.2325078  -0.18961115 -0.20779291\n",
      "  0.09821159 -0.47053614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.297737799132094\n",
      "====================================================================================================\n",
      "Iteration:  821\n",
      "Previous theta :  [-0.00323267 -0.1096538   0.13945908 -0.00291497  0.06210945 -0.1720078\n",
      "  0.26115904  0.04250102 -0.33368861  0.2325078  -0.18961115 -0.20779291\n",
      "  0.09821159 -0.47053614]\n",
      "New theta_0 : [-0.00323193 -0.10966128  0.13946971 -0.00289795  0.0621049  -0.17203945\n",
      "  0.26115204  0.04250333 -0.33371176  0.23255852 -0.18965633 -0.20780017\n",
      "  0.09821277 -0.47053338]\n",
      "Training Error:  10.297731383348124\n",
      "====================================================================================================\n",
      "Iteration:  822\n",
      "Previous theta :  [-0.00323193 -0.10966128  0.13946971 -0.00289795  0.0621049  -0.17203945\n",
      "  0.26115204  0.04250333 -0.33371176  0.23255852 -0.18965633 -0.20780017\n",
      "  0.09821277 -0.47053338]\n",
      "New theta_0 : [-0.0032312  -0.10966871  0.13948029 -0.00288095  0.06210036 -0.17207091\n",
      "  0.26114509  0.04250564 -0.33373474  0.23260908 -0.18970141 -0.20780739\n",
      "  0.09821396 -0.47053065]\n",
      "Training Error:  10.297725015099527\n",
      "====================================================================================================\n",
      "Iteration:  823\n",
      "Previous theta :  [-0.0032312  -0.10966871  0.13948029 -0.00288095  0.06210036 -0.17207091\n",
      "  0.26114509  0.04250564 -0.33373474  0.23260908 -0.18970141 -0.20780739\n",
      "  0.09821396 -0.47053065]\n",
      "New theta_0 : [-0.00323046 -0.10967611  0.13949081 -0.00286397  0.06209584 -0.17210216\n",
      "  0.26113819  0.04250793 -0.33375754  0.23265947 -0.1897464  -0.20781458\n",
      "  0.09821514 -0.47052792]\n",
      "Training Error:  10.297718693949223\n",
      "====================================================================================================\n",
      "Iteration:  824\n",
      "Previous theta :  [-0.00323046 -0.10967611  0.13949081 -0.00286397  0.06209584 -0.17210216\n",
      "  0.26113819  0.04250793 -0.33375754  0.23265947 -0.1897464  -0.20781458\n",
      "  0.09821514 -0.47052792]\n",
      "New theta_0 : [-0.00322973 -0.10968347  0.13950128 -0.00284701  0.06209134 -0.17213323\n",
      "  0.26113133  0.04251022 -0.33378017  0.23270969 -0.18979129 -0.20782172\n",
      "  0.09821632 -0.47052521]\n",
      "Training Error:  10.29771241946509\n",
      "====================================================================================================\n",
      "Iteration:  825\n",
      "Previous theta :  [-0.00322973 -0.10968347  0.13950128 -0.00284701  0.06209134 -0.17213323\n",
      "  0.26113133  0.04251022 -0.33378017  0.23270969 -0.18979129 -0.20782172\n",
      "  0.09821632 -0.47052521]\n",
      "New theta_0 : [-0.00322901 -0.10969079  0.13951169 -0.00283008  0.06208685 -0.1721641\n",
      "  0.26112452  0.04251249 -0.33380263  0.23275975 -0.18983608 -0.20782883\n",
      "  0.09821749 -0.47052252]\n",
      "Training Error:  10.297706191219882\n",
      "====================================================================================================\n",
      "Iteration:  826\n",
      "Previous theta :  [-0.00322901 -0.10969079  0.13951169 -0.00283008  0.06208685 -0.1721641\n",
      "  0.26112452  0.04251249 -0.33380263  0.23275975 -0.18983608 -0.20782883\n",
      "  0.09821749 -0.47052252]\n",
      "New theta_0 : [-0.00322828 -0.10969807  0.13952205 -0.00281316  0.06208238 -0.17219478\n",
      "  0.26111775  0.04251475 -0.33382492  0.23280964 -0.18988078 -0.2078359\n",
      "  0.09821866 -0.47051983]\n",
      "Training Error:  10.297700008791175\n",
      "====================================================================================================\n",
      "Iteration:  827\n",
      "Previous theta :  [-0.00322828 -0.10969807  0.13952205 -0.00281316  0.06208238 -0.17219478\n",
      "  0.26111775  0.04251475 -0.33382492  0.23280964 -0.18988078 -0.2078359\n",
      "  0.09821866 -0.47051983]\n",
      "New theta_0 : [-0.00322756 -0.10970531  0.13953235 -0.00279626  0.06207793 -0.17222528\n",
      "  0.26111103  0.04251701 -0.33384705  0.23285937 -0.18992538 -0.20784293\n",
      "  0.09821982 -0.47051716]\n",
      "Training Error:  10.297693871761295\n",
      "====================================================================================================\n",
      "Iteration:  828\n",
      "Previous theta :  [-0.00322756 -0.10970531  0.13953235 -0.00279626  0.06207793 -0.17222528\n",
      "  0.26111103  0.04251701 -0.33384705  0.23285937 -0.18992538 -0.20784293\n",
      "  0.09821982 -0.47051716]\n",
      "New theta_0 : [-0.00322684 -0.10971251  0.1395426  -0.00277939  0.06207349 -0.17225558\n",
      "  0.26110435  0.04251925 -0.333869    0.23290894 -0.18996988 -0.20784992\n",
      "  0.09822099 -0.47051451]\n",
      "Training Error:  10.297687779717272\n",
      "====================================================================================================\n",
      "Iteration:  829\n",
      "Previous theta :  [-0.00322684 -0.10971251  0.1395426  -0.00277939  0.06207349 -0.17225558\n",
      "  0.26110435  0.04251925 -0.333869    0.23290894 -0.18996988 -0.20784992\n",
      "  0.09822099 -0.47051451]\n",
      "New theta_0 : [-0.00322612 -0.10971968  0.1395528  -0.00276253  0.06206907 -0.1722857\n",
      "  0.26109771  0.04252148 -0.33389079  0.23295834 -0.19001429 -0.20785688\n",
      "  0.09822214 -0.47051187]\n",
      "Training Error:  10.297681732250764\n",
      "====================================================================================================\n",
      "Iteration:  830\n",
      "Previous theta :  [-0.00322612 -0.10971968  0.1395528  -0.00276253  0.06206907 -0.1722857\n",
      "  0.26109771  0.04252148 -0.33389079  0.23295834 -0.19001429 -0.20785688\n",
      "  0.09822214 -0.47051187]\n",
      "New theta_0 : [-0.0032254  -0.1097268   0.13956294 -0.0027457   0.06206466 -0.17231563\n",
      "  0.26109111  0.04252371 -0.33391242  0.23300759 -0.1900586  -0.20786379\n",
      "  0.0982233  -0.47050924]\n",
      "Training Error:  10.297675728958009\n",
      "====================================================================================================\n",
      "Iteration:  831\n",
      "Previous theta :  [-0.0032254  -0.1097268   0.13956294 -0.0027457   0.06206466 -0.17231563\n",
      "  0.26109111  0.04252371 -0.33391242  0.23300759 -0.1900586  -0.20786379\n",
      "  0.0982233  -0.47050924]\n",
      "New theta_0 : [-0.00322469 -0.10973389  0.13957303 -0.00272889  0.06206028 -0.17234538\n",
      "  0.26108456  0.04252592 -0.33393388  0.23305667 -0.19010281 -0.20787067\n",
      "  0.09822445 -0.47050663]\n",
      "Training Error:  10.29766976943975\n",
      "====================================================================================================\n",
      "Iteration:  832\n",
      "Previous theta :  [-0.00322469 -0.10973389  0.13957303 -0.00272889  0.06206028 -0.17234538\n",
      "  0.26108456  0.04252592 -0.33393388  0.23305667 -0.19010281 -0.20787067\n",
      "  0.09822445 -0.47050663]\n",
      "New theta_0 : [-0.00322398 -0.10974094  0.13958307 -0.0027121   0.06205591 -0.17237494\n",
      "  0.26107805  0.04252812 -0.33395519  0.23310559 -0.19014693 -0.20787752\n",
      "  0.0982256  -0.47050403]\n",
      "Training Error:  10.297663853301197\n",
      "====================================================================================================\n",
      "Iteration:  833\n",
      "Previous theta :  [-0.00322398 -0.10974094  0.13958307 -0.0027121   0.06205591 -0.17237494\n",
      "  0.26107805  0.04252812 -0.33395519  0.23310559 -0.19014693 -0.20787752\n",
      "  0.0982256  -0.47050403]\n",
      "New theta_0 : [-0.00322327 -0.10974796  0.13959305 -0.00269533  0.06205155 -0.17240432\n",
      "  0.26107158  0.04253032 -0.33397633  0.23315435 -0.19019095 -0.20788432\n",
      "  0.09822674 -0.47050144]\n",
      "Training Error:  10.297657980151955\n",
      "====================================================================================================\n",
      "Iteration:  834\n",
      "Previous theta :  [-0.00322327 -0.10974796  0.13959305 -0.00269533  0.06205155 -0.17240432\n",
      "  0.26107158  0.04253032 -0.33397633  0.23315435 -0.19019095 -0.20788432\n",
      "  0.09822674 -0.47050144]\n",
      "New theta_0 : [-0.00322256 -0.10975494  0.13960299 -0.00267859  0.06204721 -0.17243353\n",
      "  0.26106516  0.0425325  -0.33399731  0.23320296 -0.19023488 -0.20789109\n",
      "  0.09822788 -0.47049887]\n",
      "Training Error:  10.29765214960597\n",
      "====================================================================================================\n",
      "Iteration:  835\n",
      "Previous theta :  [-0.00322256 -0.10975494  0.13960299 -0.00267859  0.06204721 -0.17243353\n",
      "  0.26106516  0.0425325  -0.33399731  0.23320296 -0.19023488 -0.20789109\n",
      "  0.09822788 -0.47049887]\n",
      "New theta_0 : [-0.00322186 -0.10976188  0.13961287 -0.00266186  0.06204289 -0.17246255\n",
      "  0.26105877  0.04253468 -0.33401814  0.2332514  -0.19027871 -0.20789782\n",
      "  0.09822902 -0.47049631]\n",
      "Training Error:  10.297646361281478\n",
      "====================================================================================================\n",
      "Iteration:  836\n",
      "Previous theta :  [-0.00322186 -0.10976188  0.13961287 -0.00266186  0.06204289 -0.17246255\n",
      "  0.26105877  0.04253468 -0.33401814  0.2332514  -0.19027871 -0.20789782\n",
      "  0.09822902 -0.47049631]\n",
      "New theta_0 : [-0.00322115 -0.10976878  0.13962271 -0.00264516  0.06203858 -0.17249139\n",
      "  0.26105243  0.04253684 -0.3340388   0.23329969 -0.19032245 -0.20790452\n",
      "  0.09823015 -0.47049376]\n",
      "Training Error:  10.297640614800942\n",
      "====================================================================================================\n",
      "Iteration:  837\n",
      "Previous theta :  [-0.00322115 -0.10976878  0.13962271 -0.00264516  0.06203858 -0.17249139\n",
      "  0.26105243  0.04253684 -0.3340388   0.23329969 -0.19032245 -0.20790452\n",
      "  0.09823015 -0.47049376]\n",
      "New theta_0 : [-0.00322045 -0.10977565  0.13963249 -0.00262848  0.06203429 -0.17252005\n",
      "  0.26104612  0.042539   -0.33405932  0.23334782 -0.19036609 -0.20791118\n",
      "  0.09823128 -0.47049123]\n",
      "Training Error:  10.29763490979101\n",
      "====================================================================================================\n",
      "Iteration:  838\n",
      "Previous theta :  [-0.00322045 -0.10977565  0.13963249 -0.00262848  0.06203429 -0.17252005\n",
      "  0.26104612  0.042539   -0.33405932  0.23334782 -0.19036609 -0.20791118\n",
      "  0.09823128 -0.47049123]\n",
      "New theta_0 : [-0.00321976 -0.10978248  0.13964222 -0.00261182  0.06203001 -0.17254854\n",
      "  0.26103986  0.04254115 -0.33407967  0.23339579 -0.19040963 -0.2079178\n",
      "  0.09823241 -0.47048871]\n",
      "Training Error:  10.297629245882442\n",
      "====================================================================================================\n",
      "Iteration:  839\n",
      "Previous theta :  [-0.00321976 -0.10978248  0.13964222 -0.00261182  0.06203001 -0.17254854\n",
      "  0.26103986  0.04254115 -0.33407967  0.23339579 -0.19040963 -0.2079178\n",
      "  0.09823241 -0.47048871]\n",
      "New theta_0 : [-0.00321906 -0.10978927  0.1396519  -0.00259519  0.06202576 -0.17257686\n",
      "  0.26103364  0.04254328 -0.33409988  0.2334436  -0.19045308 -0.20792439\n",
      "  0.09823353 -0.4704862 ]\n",
      "Training Error:  10.29762362271008\n",
      "====================================================================================================\n",
      "Iteration:  840\n",
      "Previous theta :  [-0.00321906 -0.10978927  0.1396519  -0.00259519  0.06202576 -0.17257686\n",
      "  0.26103364  0.04254328 -0.33409988  0.2334436  -0.19045308 -0.20792439\n",
      "  0.09823353 -0.4704862 ]\n",
      "New theta_0 : [-0.00321837 -0.10979603  0.13966153 -0.00257858  0.06202151 -0.172605\n",
      "  0.26102746  0.04254541 -0.33411993  0.23349127 -0.19049644 -0.20793094\n",
      "  0.09823465 -0.47048371]\n",
      "Training Error:  10.297618039912784\n",
      "====================================================================================================\n",
      "Iteration:  841\n",
      "Previous theta :  [-0.00321837 -0.10979603  0.13966153 -0.00257858  0.06202151 -0.172605\n",
      "  0.26102746  0.04254541 -0.33411993  0.23349127 -0.19049644 -0.20793094\n",
      "  0.09823465 -0.47048371]\n",
      "New theta_0 : [-0.00321768 -0.10980276  0.13967112 -0.00256199  0.06201728 -0.17263296\n",
      "  0.26102131  0.04254753 -0.33413983  0.23353877 -0.1905397  -0.20793746\n",
      "  0.09823577 -0.47048123]\n",
      "Training Error:  10.29761249713337\n",
      "====================================================================================================\n",
      "Iteration:  842\n",
      "Previous theta :  [-0.00321768 -0.10980276  0.13967112 -0.00256199  0.06201728 -0.17263296\n",
      "  0.26102131  0.04254753 -0.33413983  0.23353877 -0.1905397  -0.20793746\n",
      "  0.09823577 -0.47048123]\n",
      "New theta_0 : [-0.00321699 -0.10980945  0.13968065 -0.00254543  0.06201307 -0.17266076\n",
      "  0.26101521  0.04254964 -0.33415958  0.23358612 -0.19058286 -0.20794394\n",
      "  0.09823688 -0.47047876]\n",
      "Training Error:  10.297606994018583\n",
      "====================================================================================================\n",
      "Iteration:  843\n",
      "Previous theta :  [-0.00321699 -0.10980945  0.13968065 -0.00254543  0.06201307 -0.17266076\n",
      "  0.26101521  0.04254964 -0.33415958  0.23358612 -0.19058286 -0.20794394\n",
      "  0.09823688 -0.47047876]\n",
      "New theta_0 : [-0.0032163  -0.1098161   0.13969014 -0.00252888  0.06200887 -0.17268838\n",
      "  0.26100914  0.04255174 -0.33417918  0.23363332 -0.19062593 -0.20795039\n",
      "  0.09823799 -0.47047631]\n",
      "Training Error:  10.29760153021903\n",
      "====================================================================================================\n",
      "Iteration:  844\n",
      "Previous theta :  [-0.0032163  -0.1098161   0.13969014 -0.00252888  0.06200887 -0.17268838\n",
      "  0.26100914  0.04255174 -0.33417918  0.23363332 -0.19062593 -0.20795039\n",
      "  0.09823799 -0.47047631]\n",
      "New theta_0 : [-0.00321562 -0.10982272  0.13969957 -0.00251237  0.06200469 -0.17271584\n",
      "  0.26100312  0.04255383 -0.33419864  0.23368037 -0.19066891 -0.2079568\n",
      "  0.09823909 -0.47047387]\n",
      "Training Error:  10.29759610538913\n",
      "====================================================================================================\n",
      "Iteration:  845\n",
      "Previous theta :  [-0.00321562 -0.10982272  0.13969957 -0.00251237  0.06200469 -0.17271584\n",
      "  0.26100312  0.04255383 -0.33419864  0.23368037 -0.19066891 -0.2079568\n",
      "  0.09823909 -0.47047387]\n",
      "New theta_0 : [-0.00321493 -0.10982931  0.13970896 -0.00249587  0.06200053 -0.17274313\n",
      "  0.26099713  0.04255591 -0.33421795  0.23372726 -0.19071178 -0.20796318\n",
      "  0.0982402  -0.47047144]\n",
      "Training Error:  10.297590719187083\n",
      "====================================================================================================\n",
      "Iteration:  846\n",
      "Previous theta :  [-0.00321493 -0.10982931  0.13970896 -0.00249587  0.06200053 -0.17274313\n",
      "  0.26099713  0.04255591 -0.33421795  0.23372726 -0.19071178 -0.20796318\n",
      "  0.0982402  -0.47047144]\n",
      "New theta_0 : [-0.00321425 -0.10983586  0.13971831 -0.0024794   0.06199638 -0.17277025\n",
      "  0.26099118  0.04255799 -0.33423711  0.233774   -0.19075457 -0.20796952\n",
      "  0.09824129 -0.47046902]\n",
      "Training Error:  10.297585371274797\n",
      "====================================================================================================\n",
      "Iteration:  847\n",
      "Previous theta :  [-0.00321425 -0.10983586  0.13971831 -0.0024794   0.06199638 -0.17277025\n",
      "  0.26099118  0.04255799 -0.33423711  0.233774   -0.19075457 -0.20796952\n",
      "  0.09824129 -0.47046902]\n",
      "New theta_0 : [-0.00321358 -0.10984237  0.1397276  -0.00246295  0.06199224 -0.1727972\n",
      "  0.26098526  0.04256005 -0.33425613  0.23382059 -0.19079726 -0.20797583\n",
      "  0.09824239 -0.47046662]\n",
      "Training Error:  10.297580061317863\n",
      "====================================================================================================\n",
      "Iteration:  848\n",
      "Previous theta :  [-0.00321358 -0.10984237  0.1397276  -0.00246295  0.06199224 -0.1727972\n",
      "  0.26098526  0.04256005 -0.33425613  0.23382059 -0.19079726 -0.20797583\n",
      "  0.09824239 -0.47046662]\n",
      "New theta_0 : [-0.0032129  -0.10984885  0.13973685 -0.00244653  0.06198812 -0.17282399\n",
      "  0.26097939  0.04256211 -0.334275    0.23386703 -0.19083986 -0.20798211\n",
      "  0.09824348 -0.47046423]\n",
      "Training Error:  10.297574788985495\n",
      "====================================================================================================\n",
      "Iteration:  849\n",
      "Previous theta :  [-0.0032129  -0.10984885  0.13973685 -0.00244653  0.06198812 -0.17282399\n",
      "  0.26097939  0.04256211 -0.334275    0.23386703 -0.19083986 -0.20798211\n",
      "  0.09824348 -0.47046423]\n",
      "New theta_0 : [-0.00321223 -0.1098553   0.13974605 -0.00243013  0.06198401 -0.17285061\n",
      "  0.26097355  0.04256416 -0.33429374  0.23391332 -0.19088236 -0.20798835\n",
      "  0.09824457 -0.47046186]\n",
      "Training Error:  10.297569553950487\n",
      "====================================================================================================\n",
      "Iteration:  850\n",
      "Previous theta :  [-0.00321223 -0.1098553   0.13974605 -0.00243013  0.06198401 -0.17285061\n",
      "  0.26097355  0.04256416 -0.33429374  0.23391332 -0.19088236 -0.20798835\n",
      "  0.09824457 -0.47046186]\n",
      "New theta_0 : [-0.00321156 -0.10986172  0.1397552  -0.00241376  0.06197992 -0.17287707\n",
      "  0.26096775  0.0425662  -0.33431233  0.23395946 -0.19092476 -0.20799456\n",
      "  0.09824565 -0.4704595 ]\n",
      "Training Error:  10.29756435588917\n",
      "====================================================================================================\n",
      "Iteration:  851\n",
      "Previous theta :  [-0.00321156 -0.10986172  0.1397552  -0.00241376  0.06197992 -0.17287707\n",
      "  0.26096775  0.0425662  -0.33431233  0.23395946 -0.19092476 -0.20799456\n",
      "  0.09824565 -0.4704595 ]\n",
      "New theta_0 : [-0.00321089 -0.1098681   0.13976431 -0.00239741  0.06197585 -0.17290337\n",
      "  0.26096198  0.04256823 -0.33433078  0.23400545 -0.19096708 -0.20800074\n",
      "  0.09824673 -0.47045715]\n",
      "Training Error:  10.297559194481368\n",
      "====================================================================================================\n",
      "Iteration:  852\n",
      "Previous theta :  [-0.00321089 -0.1098681   0.13976431 -0.00239741  0.06197585 -0.17290337\n",
      "  0.26096198  0.04256823 -0.33433078  0.23400545 -0.19096708 -0.20800074\n",
      "  0.09824673 -0.47045715]\n",
      "New theta_0 : [-0.00321022 -0.10987445  0.13977337 -0.00238108  0.06197179 -0.17292951\n",
      "  0.26095625  0.04257025 -0.3343491   0.23405129 -0.1910093  -0.20800688\n",
      "  0.09824781 -0.47045481]\n",
      "Training Error:  10.297554069410346\n",
      "====================================================================================================\n",
      "Iteration:  853\n",
      "Previous theta :  [-0.00321022 -0.10987445  0.13977337 -0.00238108  0.06197179 -0.17292951\n",
      "  0.26095625  0.04257025 -0.3343491   0.23405129 -0.1910093  -0.20800688\n",
      "  0.09824781 -0.47045481]\n",
      "New theta_0 : [-0.00320956 -0.10988077  0.13978239 -0.00236478  0.06196774 -0.17295549\n",
      "  0.26095056  0.04257226 -0.33436727  0.23409699 -0.19105142 -0.20801299\n",
      "  0.09824888 -0.47045248]\n",
      "Training Error:  10.297548980362778\n",
      "====================================================================================================\n",
      "Iteration:  854\n",
      "Previous theta :  [-0.00320956 -0.10988077  0.13978239 -0.00236478  0.06196774 -0.17295549\n",
      "  0.26095056  0.04257226 -0.33436727  0.23409699 -0.19105142 -0.20801299\n",
      "  0.09824888 -0.47045248]\n",
      "New theta_0 : [-0.00320889 -0.10988705  0.13979136 -0.00234851  0.06196371 -0.17298131\n",
      "  0.2609449   0.04257426 -0.33438531  0.23414253 -0.19109345 -0.20801907\n",
      "  0.09824996 -0.47045017]\n",
      "Training Error:  10.297543927028698\n",
      "====================================================================================================\n",
      "Iteration:  855\n",
      "Previous theta :  [-0.00320889 -0.10988705  0.13979136 -0.00234851  0.06196371 -0.17298131\n",
      "  0.2609449   0.04257426 -0.33438531  0.23414253 -0.19109345 -0.20801907\n",
      "  0.09824996 -0.47045017]\n",
      "New theta_0 : [-0.00320823 -0.1098933   0.13980029 -0.00233226  0.06195969 -0.17300698\n",
      "  0.26093928  0.04257626 -0.33440321  0.23418793 -0.19113539 -0.20802511\n",
      "  0.09825102 -0.47044787]\n",
      "Training Error:  10.297538909101458\n",
      "====================================================================================================\n",
      "Iteration:  856\n",
      "Previous theta :  [-0.00320823 -0.1098933   0.13980029 -0.00233226  0.06195969 -0.17300698\n",
      "  0.26093928  0.04257626 -0.33440321  0.23418793 -0.19113539 -0.20802511\n",
      "  0.09825102 -0.47044787]\n",
      "New theta_0 : [-0.00320757 -0.10989952  0.13980917 -0.00231603  0.06195569 -0.17303248\n",
      "  0.26093369  0.04257825 -0.33442098  0.23423319 -0.19117723 -0.20803112\n",
      "  0.09825209 -0.47044558]\n",
      "Training Error:  10.297533926277682\n",
      "====================================================================================================\n",
      "Iteration:  857\n",
      "Previous theta :  [-0.00320757 -0.10989952  0.13980917 -0.00231603  0.06195569 -0.17303248\n",
      "  0.26093369  0.04257825 -0.33442098  0.23423319 -0.19117723 -0.20803112\n",
      "  0.09825209 -0.47044558]\n",
      "New theta_0 : [-0.00320692 -0.10990571  0.13981801 -0.00229983  0.06195171 -0.17305783\n",
      "  0.26092814  0.04258023 -0.33443861  0.2342783  -0.19121898 -0.2080371\n",
      "  0.09825315 -0.47044331]\n",
      "Training Error:  10.297528978257233\n",
      "====================================================================================================\n",
      "Iteration:  858\n",
      "Previous theta :  [-0.00320692 -0.10990571  0.13981801 -0.00229983  0.06195171 -0.17305783\n",
      "  0.26092814  0.04258023 -0.33443861  0.2342783  -0.19121898 -0.2080371\n",
      "  0.09825315 -0.47044331]\n",
      "New theta_0 : [-0.00320626 -0.10991186  0.1398268  -0.00228366  0.06194773 -0.17308303\n",
      "  0.26092262  0.0425822  -0.33445612  0.23432326 -0.19126064 -0.20804305\n",
      "  0.0982542  -0.47044105]\n",
      "Training Error:  10.297524064743172\n",
      "====================================================================================================\n",
      "Iteration:  859\n",
      "Previous theta :  [-0.00320626 -0.10991186  0.1398268  -0.00228366  0.06194773 -0.17308303\n",
      "  0.26092262  0.0425822  -0.33445612  0.23432326 -0.19126064 -0.20804305\n",
      "  0.0982542  -0.47044105]\n",
      "New theta_0 : [-0.00320561 -0.10991798  0.13983555 -0.00226751  0.06194377 -0.17310807\n",
      "  0.26091714  0.04258416 -0.33447349  0.23436808 -0.1913022  -0.20804897\n",
      "  0.09825526 -0.4704388 ]\n",
      "Training Error:  10.297519185441708\n",
      "====================================================================================================\n",
      "Iteration:  860\n",
      "Previous theta :  [-0.00320561 -0.10991798  0.13983555 -0.00226751  0.06194377 -0.17310807\n",
      "  0.26091714  0.04258416 -0.33447349  0.23436808 -0.1913022  -0.20804897\n",
      "  0.09825526 -0.4704388 ]\n",
      "New theta_0 : [-0.00320496 -0.10992408  0.13984426 -0.00225138  0.06193983 -0.17313296\n",
      "  0.26091169  0.04258612 -0.33449073  0.23441276 -0.19134367 -0.20805485\n",
      "  0.09825631 -0.47043656]\n",
      "Training Error:  10.297514340062168\n",
      "====================================================================================================\n",
      "Iteration:  861\n",
      "Previous theta :  [-0.00320496 -0.10992408  0.13984426 -0.00225138  0.06193983 -0.17313296\n",
      "  0.26091169  0.04258612 -0.33449073  0.23441276 -0.19134367 -0.20805485\n",
      "  0.09825631 -0.47043656]\n",
      "New theta_0 : [-0.00320431 -0.10993014  0.13985292 -0.00223529  0.0619359  -0.1731577\n",
      "  0.26090627  0.04258806 -0.33450784  0.23445729 -0.19138505 -0.2080607\n",
      "  0.09825735 -0.47043433]\n",
      "Training Error:  10.29750952831696\n",
      "====================================================================================================\n",
      "Iteration:  862\n",
      "Previous theta :  [-0.00320431 -0.10993014  0.13985292 -0.00223529  0.0619359  -0.1731577\n",
      "  0.26090627  0.04258806 -0.33450784  0.23445729 -0.19138505 -0.2080607\n",
      "  0.09825735 -0.47043433]\n",
      "New theta_0 : [-0.00320367 -0.10993617  0.13986154 -0.00221921  0.06193199 -0.17318229\n",
      "  0.26090089  0.04259    -0.33452482  0.23450168 -0.19142633 -0.20806653\n",
      "  0.0982584  -0.47043212]\n",
      "Training Error:  10.297504749921519\n",
      "====================================================================================================\n",
      "Iteration:  863\n",
      "Previous theta :  [-0.00320367 -0.10993617  0.13986154 -0.00221921  0.06193199 -0.17318229\n",
      "  0.26090089  0.04259    -0.33452482  0.23450168 -0.19142633 -0.20806653\n",
      "  0.0982584  -0.47043212]\n",
      "New theta_0 : [-0.00320302 -0.10994216  0.13987012 -0.00220317  0.06192808 -0.17320673\n",
      "  0.26089554  0.04259193 -0.33454167  0.23454593 -0.19146752 -0.20807232\n",
      "  0.09825944 -0.47042992]\n",
      "Training Error:  10.297500004594292\n",
      "====================================================================================================\n",
      "Iteration:  864\n",
      "Previous theta :  [-0.00320302 -0.10994216  0.13987012 -0.00220317  0.06192808 -0.17320673\n",
      "  0.26089554  0.04259193 -0.33454167  0.23454593 -0.19146752 -0.20807232\n",
      "  0.09825944 -0.47042992]\n",
      "New theta_0 : [-0.00320238 -0.10994813  0.13987865 -0.00218715  0.0619242  -0.17323102\n",
      "  0.26089022  0.04259385 -0.33455839  0.23459003 -0.19150862 -0.20807808\n",
      "  0.09826047 -0.47042773]\n",
      "Training Error:  10.297495292056684\n",
      "====================================================================================================\n",
      "Iteration:  865\n",
      "Previous theta :  [-0.00320238 -0.10994813  0.13987865 -0.00218715  0.0619242  -0.17323102\n",
      "  0.26089022  0.04259385 -0.33455839  0.23459003 -0.19150862 -0.20807808\n",
      "  0.09826047 -0.47042773]\n",
      "New theta_0 : [-0.00320174 -0.10995407  0.13988715 -0.00217115  0.06192032 -0.17325516\n",
      "  0.26088494  0.04259577 -0.334575    0.234634   -0.19154963 -0.20808381\n",
      "  0.09826151 -0.47042556]\n",
      "Training Error:  10.297490612033023\n",
      "====================================================================================================\n",
      "Iteration:  866\n",
      "Previous theta :  [-0.00320174 -0.10995407  0.13988715 -0.00217115  0.06192032 -0.17325516\n",
      "  0.26088494  0.04259577 -0.334575    0.234634   -0.19154963 -0.20808381\n",
      "  0.09826151 -0.47042556]\n",
      "New theta_0 : [-0.0032011  -0.10995998  0.1398956  -0.00215518  0.06191646 -0.17327915\n",
      "  0.26087969  0.04259768 -0.33459147  0.23467782 -0.19159054 -0.20808951\n",
      "  0.09826254 -0.47042339]\n",
      "Training Error:  10.29748596425053\n",
      "====================================================================================================\n",
      "Iteration:  867\n",
      "Previous theta :  [-0.0032011  -0.10995998  0.1398956  -0.00215518  0.06191646 -0.17327915\n",
      "  0.26087969  0.04259768 -0.33459147  0.23467782 -0.19159054 -0.20808951\n",
      "  0.09826254 -0.47042339]\n",
      "New theta_0 : [-0.00320047 -0.10996585  0.13990401 -0.00213924  0.06191262 -0.173303\n",
      "  0.26087447  0.04259957 -0.33460782  0.23472151 -0.19163136 -0.20809517\n",
      "  0.09826356 -0.47042124]\n",
      "Training Error:  10.297481348439279\n",
      "====================================================================================================\n",
      "Iteration:  868\n",
      "Previous theta :  [-0.00320047 -0.10996585  0.13990401 -0.00213924  0.06191262 -0.173303\n",
      "  0.26087447  0.04259957 -0.33460782  0.23472151 -0.19163136 -0.20809517\n",
      "  0.09826356 -0.47042124]\n",
      "New theta_0 : [-0.00319983 -0.1099717   0.13991238 -0.00212332  0.06190879 -0.17332671\n",
      "  0.26086929  0.04260146 -0.33462405  0.23476505 -0.19167209 -0.20810081\n",
      "  0.09826459 -0.4704191 ]\n",
      "Training Error:  10.297476764332162\n",
      "====================================================================================================\n",
      "Iteration:  869\n",
      "Previous theta :  [-0.00319983 -0.1099717   0.13991238 -0.00212332  0.06190879 -0.17332671\n",
      "  0.26086929  0.04260146 -0.33462405  0.23476505 -0.19167209 -0.20810081\n",
      "  0.09826459 -0.4704191 ]\n",
      "New theta_0 : [-0.0031992  -0.10997752  0.1399207  -0.00210743  0.06190497 -0.17335027\n",
      "  0.26086413  0.04260335 -0.33464016  0.23480846 -0.19171273 -0.20810642\n",
      "  0.09826561 -0.47041697]\n",
      "Training Error:  10.297472211664855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  870\n",
      "Previous theta :  [-0.0031992  -0.10997752  0.1399207  -0.00210743  0.06190497 -0.17335027\n",
      "  0.26086413  0.04260335 -0.33464016  0.23480846 -0.19171273 -0.20810642\n",
      "  0.09826561 -0.47041697]\n",
      "New theta_0 : [-0.00319857 -0.10998331  0.13992899 -0.00209157  0.06190117 -0.17337368\n",
      "  0.26085901  0.04260522 -0.33465614  0.23485173 -0.19175327 -0.208112\n",
      "  0.09826663 -0.47041485]\n",
      "Training Error:  10.29746769017578\n",
      "====================================================================================================\n",
      "Iteration:  871\n",
      "Previous theta :  [-0.00319857 -0.10998331  0.13992899 -0.00209157  0.06190117 -0.17337368\n",
      "  0.26085901  0.04260522 -0.33465614  0.23485173 -0.19175327 -0.208112\n",
      "  0.09826663 -0.47041485]\n",
      "New theta_0 : [-0.00319794 -0.10998906  0.13993724 -0.00207573  0.06189738 -0.17339696\n",
      "  0.26085392  0.04260709 -0.33467201  0.23489486 -0.19179372 -0.20811755\n",
      "  0.09826764 -0.47041275]\n",
      "Training Error:  10.297463199606081\n",
      "====================================================================================================\n",
      "Iteration:  872\n",
      "Previous theta :  [-0.00319794 -0.10998906  0.13993724 -0.00207573  0.06189738 -0.17339696\n",
      "  0.26085392  0.04260709 -0.33467201  0.23489486 -0.19179372 -0.20811755\n",
      "  0.09826764 -0.47041275]\n",
      "New theta_0 : [-0.00319732 -0.10999479  0.13994544 -0.00205993  0.0618936  -0.17342009\n",
      "  0.26084886  0.04260895 -0.33468775  0.23493785 -0.19183408 -0.20812307\n",
      "  0.09826865 -0.47041066]\n",
      "Training Error:  10.297458739699579\n",
      "====================================================================================================\n",
      "Iteration:  873\n",
      "Previous theta :  [-0.00319732 -0.10999479  0.13994544 -0.00205993  0.0618936  -0.17342009\n",
      "  0.26084886  0.04260895 -0.33468775  0.23493785 -0.19183408 -0.20812307\n",
      "  0.09826865 -0.47041066]\n",
      "New theta_0 : [-0.00319669 -0.11000049  0.13995361 -0.00204414  0.06188984 -0.17344309\n",
      "  0.26084383  0.04261081 -0.33470338  0.2349807  -0.19187435 -0.20812856\n",
      "  0.09826966 -0.47040858]\n",
      "Training Error:  10.297454310202744\n",
      "====================================================================================================\n",
      "Iteration:  874\n",
      "Previous theta :  [-0.00319669 -0.11000049  0.13995361 -0.00204414  0.06188984 -0.17344309\n",
      "  0.26084383  0.04261081 -0.33470338  0.2349807  -0.19187435 -0.20812856\n",
      "  0.09826966 -0.47040858]\n",
      "New theta_0 : [-0.00319607 -0.11000616  0.13996173 -0.00202839  0.06188609 -0.17346594\n",
      "  0.26083883  0.04261265 -0.33471889  0.23502342 -0.19191453 -0.20813402\n",
      "  0.09827066 -0.47040651]\n",
      "Training Error:  10.29744991086466\n",
      "====================================================================================================\n",
      "Iteration:  875\n",
      "Previous theta :  [-0.00319607 -0.11000616  0.13996173 -0.00202839  0.06188609 -0.17346594\n",
      "  0.26083883  0.04261265 -0.33471889  0.23502342 -0.19191453 -0.20813402\n",
      "  0.09827066 -0.47040651]\n",
      "New theta_0 : [-0.00319545 -0.11001181  0.13996982 -0.00201266  0.06188235 -0.17348866\n",
      "  0.26083386  0.04261449 -0.33473428  0.235066   -0.19195461 -0.20813945\n",
      "  0.09827166 -0.47040445]\n",
      "Training Error:  10.297445541437\n",
      "====================================================================================================\n",
      "Iteration:  876\n",
      "Previous theta :  [-0.00319545 -0.11001181  0.13996982 -0.00201266  0.06188235 -0.17348866\n",
      "  0.26083386  0.04261449 -0.33473428  0.235066   -0.19195461 -0.20813945\n",
      "  0.09827166 -0.47040445]\n",
      "New theta_0 : [-0.00319483 -0.11001742  0.13997787 -0.00199696  0.06187863 -0.17351124\n",
      "  0.26082892  0.04261632 -0.33474956  0.23510845 -0.19199461 -0.20814485\n",
      "  0.09827266 -0.4704024 ]\n",
      "Training Error:  10.297441201673987\n",
      "====================================================================================================\n",
      "Iteration:  877\n",
      "Previous theta :  [-0.00319483 -0.11001742  0.13997787 -0.00199696  0.06187863 -0.17351124\n",
      "  0.26082892  0.04261632 -0.33474956  0.23510845 -0.19199461 -0.20814485\n",
      "  0.09827266 -0.4704024 ]\n",
      "New theta_0 : [-0.00319422 -0.11002301  0.13998588 -0.00198128  0.06187492 -0.17353368\n",
      "  0.26082401  0.04261814 -0.33476472  0.23515076 -0.19203451 -0.20815023\n",
      "  0.09827365 -0.47040037]\n",
      "Training Error:  10.297436891332362\n",
      "====================================================================================================\n",
      "Iteration:  878\n",
      "Previous theta :  [-0.00319422 -0.11002301  0.13998588 -0.00198128  0.06187492 -0.17353368\n",
      "  0.26082401  0.04261814 -0.33476472  0.23515076 -0.19203451 -0.20815023\n",
      "  0.09827365 -0.47040037]\n",
      "New theta_0 : [-0.0031936  -0.11002857  0.13999385 -0.00196563  0.06187122 -0.17355599\n",
      "  0.26081913  0.04261996 -0.33477977  0.23519294 -0.19207432 -0.20815557\n",
      "  0.09827464 -0.47039834]\n",
      "Training Error:  10.297432610171361\n",
      "====================================================================================================\n",
      "Iteration:  879\n",
      "Previous theta :  [-0.0031936  -0.11002857  0.13999385 -0.00196563  0.06187122 -0.17355599\n",
      "  0.26081913  0.04261996 -0.33477977  0.23519294 -0.19207432 -0.20815557\n",
      "  0.09827464 -0.47039834]\n",
      "New theta_0 : [-0.00319299 -0.1100341   0.14000178 -0.00195001  0.06186754 -0.17357816\n",
      "  0.26081428  0.04262177 -0.3347947   0.23523499 -0.19211404 -0.20816089\n",
      "  0.09827563 -0.47039633]\n",
      "Training Error:  10.29742835795268\n",
      "====================================================================================================\n",
      "Iteration:  880\n",
      "Previous theta :  [-0.00319299 -0.1100341   0.14000178 -0.00195001  0.06186754 -0.17357816\n",
      "  0.26081428  0.04262177 -0.3347947   0.23523499 -0.19211404 -0.20816089\n",
      "  0.09827563 -0.47039633]\n",
      "New theta_0 : [-0.00319238 -0.1100396   0.14000967 -0.00193442  0.06186387 -0.1736002\n",
      "  0.26080946  0.04262357 -0.33480953  0.2352769  -0.19215367 -0.20816618\n",
      "  0.09827661 -0.47039433]\n",
      "Training Error:  10.297424134440442\n",
      "====================================================================================================\n",
      "Iteration:  881\n",
      "Previous theta :  [-0.00319238 -0.1100396   0.14000967 -0.00193442  0.06186387 -0.1736002\n",
      "  0.26080946  0.04262357 -0.33480953  0.2352769  -0.19215367 -0.20816618\n",
      "  0.09827661 -0.47039433]\n",
      "New theta_0 : [-0.00319177 -0.11004507  0.14001753 -0.00191885  0.06186021 -0.17362211\n",
      "  0.26080467  0.04262536 -0.33482424  0.23531868 -0.19219321 -0.20817144\n",
      "  0.09827759 -0.47039234]\n",
      "Training Error:  10.29741993940117\n",
      "====================================================================================================\n",
      "Iteration:  882\n",
      "Previous theta :  [-0.00319177 -0.11004507  0.14001753 -0.00191885  0.06186021 -0.17362211\n",
      "  0.26080467  0.04262536 -0.33482424  0.23531868 -0.19219321 -0.20817144\n",
      "  0.09827759 -0.47039234]\n",
      "New theta_0 : [-0.00319116 -0.11005052  0.14002534 -0.00190332  0.06185657 -0.17364388\n",
      "  0.26079991  0.04262715 -0.33483884  0.23536032 -0.19223266 -0.20817668\n",
      "  0.09827857 -0.47039037]\n",
      "Training Error:  10.297415772603756\n",
      "====================================================================================================\n",
      "Iteration:  883\n",
      "Previous theta :  [-0.00319116 -0.11005052  0.14002534 -0.00190332  0.06185657 -0.17364388\n",
      "  0.26079991  0.04262715 -0.33483884  0.23536032 -0.19223266 -0.20817668\n",
      "  0.09827857 -0.47039037]\n",
      "New theta_0 : [-0.00319056 -0.11005594  0.14003312 -0.00188781  0.06185294 -0.17366552\n",
      "  0.26079518  0.04262893 -0.33485333  0.23540184 -0.19227202 -0.20818188\n",
      "  0.09827955 -0.4703884 ]\n",
      "Training Error:  10.297411633819443\n",
      "====================================================================================================\n",
      "Iteration:  884\n",
      "Previous theta :  [-0.00319056 -0.11005594  0.14003312 -0.00188781  0.06185294 -0.17366552\n",
      "  0.26079518  0.04262893 -0.33485333  0.23540184 -0.19227202 -0.20818188\n",
      "  0.09827955 -0.4703884 ]\n",
      "New theta_0 : [-0.00318996 -0.11006133  0.14004087 -0.00187232  0.06184932 -0.17368704\n",
      "  0.26079047  0.0426307  -0.33486771  0.23544322 -0.19231128 -0.20818706\n",
      "  0.09828052 -0.47038644]\n",
      "Training Error:  10.297407522821782\n",
      "====================================================================================================\n",
      "Iteration:  885\n",
      "Previous theta :  [-0.00318996 -0.11006133  0.14004087 -0.00187232  0.06184932 -0.17368704\n",
      "  0.26079047  0.0426307  -0.33486771  0.23544322 -0.19231128 -0.20818706\n",
      "  0.09828052 -0.47038644]\n",
      "New theta_0 : [-0.00318936 -0.1100667   0.14004857 -0.00185687  0.06184572 -0.17370842\n",
      "  0.26078579  0.04263247 -0.33488198  0.23548447 -0.19235046 -0.20819221\n",
      "  0.09828149 -0.4703845 ]\n",
      "Training Error:  10.297403439386605\n",
      "====================================================================================================\n",
      "Iteration:  886\n",
      "Previous theta :  [-0.00318936 -0.1100667   0.14004857 -0.00185687  0.06184572 -0.17370842\n",
      "  0.26078579  0.04263247 -0.33488198  0.23548447 -0.19235046 -0.20819221\n",
      "  0.09828149 -0.4703845 ]\n",
      "New theta_0 : [-0.00318876 -0.11007203  0.14005624 -0.00184144  0.06184213 -0.17372967\n",
      "  0.26078114  0.04263422 -0.33489615  0.23552559 -0.19238955 -0.20819734\n",
      "  0.09828245 -0.47038257]\n",
      "Training Error:  10.297399383292012\n",
      "====================================================================================================\n",
      "Iteration:  887\n",
      "Previous theta :  [-0.00318876 -0.11007203  0.14005624 -0.00184144  0.06184213 -0.17372967\n",
      "  0.26078114  0.04263422 -0.33489615  0.23552559 -0.19238955 -0.20819734\n",
      "  0.09828245 -0.47038257]\n",
      "New theta_0 : [-0.00318816 -0.11007735  0.14006387 -0.00182604  0.06183855 -0.1737508\n",
      "  0.26077652  0.04263598 -0.33491021  0.23556658 -0.19242855 -0.20820243\n",
      "  0.09828341 -0.47038064]\n",
      "Training Error:  10.297395354318327\n",
      "====================================================================================================\n",
      "Iteration:  888\n",
      "Previous theta :  [-0.00318816 -0.11007735  0.14006387 -0.00182604  0.06183855 -0.1737508\n",
      "  0.26077652  0.04263598 -0.33491021  0.23556658 -0.19242855 -0.20820243\n",
      "  0.09828341 -0.47038064]\n",
      "New theta_0 : [-0.00318756 -0.11008263  0.14007147 -0.00181067  0.06183498 -0.1737718\n",
      "  0.26077193  0.04263772 -0.33492417  0.23560745 -0.19246745 -0.2082075\n",
      "  0.09828437 -0.47037873]\n",
      "Training Error:  10.297391352248082\n",
      "====================================================================================================\n",
      "Iteration:  889\n",
      "Previous theta :  [-0.00318756 -0.11008263  0.14007147 -0.00181067  0.06183498 -0.1737718\n",
      "  0.26077193  0.04263772 -0.33492417  0.23560745 -0.19246745 -0.2082075\n",
      "  0.09828437 -0.47037873]\n",
      "New theta_0 : [-0.00318697 -0.11008789  0.14007903 -0.00179532  0.06183143 -0.17379267\n",
      "  0.26076736  0.04263946 -0.33493801  0.23564818 -0.19250627 -0.20821255\n",
      "  0.09828533 -0.47037683]\n",
      "Training Error:  10.29738737686598\n",
      "====================================================================================================\n",
      "Iteration:  890\n",
      "Previous theta :  [-0.00318697 -0.11008789  0.14007903 -0.00179532  0.06183143 -0.17379267\n",
      "  0.26076736  0.04263946 -0.33493801  0.23564818 -0.19250627 -0.20821255\n",
      "  0.09828533 -0.47037683]\n",
      "New theta_0 : [-0.00318638 -0.11009313  0.14008655 -0.00178001  0.06182788 -0.17381341\n",
      "  0.26076282  0.04264119 -0.33495176  0.23568878 -0.192545   -0.20821756\n",
      "  0.09828628 -0.47037495]\n",
      "Training Error:  10.297383427958886\n",
      "====================================================================================================\n",
      "Iteration:  891\n",
      "Previous theta :  [-0.00318638 -0.11009313  0.14008655 -0.00178001  0.06182788 -0.17381341\n",
      "  0.26076282  0.04264119 -0.33495176  0.23568878 -0.192545   -0.20821756\n",
      "  0.09828628 -0.47037495]\n",
      "New theta_0 : [-0.00318579 -0.11009833  0.14009404 -0.00176472  0.06182436 -0.17383404\n",
      "  0.26075831  0.04264291 -0.3349654   0.23572926 -0.19258364 -0.20822255\n",
      "  0.09828723 -0.47037307]\n",
      "Training Error:  10.29737950531578\n",
      "====================================================================================================\n",
      "Iteration:  892\n",
      "Previous theta :  [-0.00318579 -0.11009833  0.14009404 -0.00176472  0.06182436 -0.17383404\n",
      "  0.26075831  0.04264291 -0.3349654   0.23572926 -0.19258364 -0.20822255\n",
      "  0.09828723 -0.47037307]\n",
      "New theta_0 : [-0.0031852  -0.11010351  0.14010149 -0.00174946  0.06182084 -0.17385453\n",
      "  0.26075382  0.04264463 -0.33497894  0.23576961 -0.19262218 -0.20822752\n",
      "  0.09828818 -0.4703712 ]\n",
      "Training Error:  10.297375608727744\n",
      "====================================================================================================\n",
      "Iteration:  893\n",
      "Previous theta :  [-0.0031852  -0.11010351  0.14010149 -0.00174946  0.06182084 -0.17385453\n",
      "  0.26075382  0.04264463 -0.33497894  0.23576961 -0.19262218 -0.20822752\n",
      "  0.09828818 -0.4703712 ]\n",
      "New theta_0 : [-0.00318461 -0.11010867  0.14010891 -0.00173423  0.06181733 -0.17387491\n",
      "  0.26074937  0.04264634 -0.33499238  0.23580983 -0.19266064 -0.20823246\n",
      "  0.09828912 -0.47036934]\n",
      "Training Error:  10.297371737987943\n",
      "====================================================================================================\n",
      "Iteration:  894\n",
      "Previous theta :  [-0.00318461 -0.11010867  0.14010891 -0.00173423  0.06181733 -0.17387491\n",
      "  0.26074937  0.04264634 -0.33499238  0.23580983 -0.19266064 -0.20823246\n",
      "  0.09828912 -0.47036934]\n",
      "New theta_0 : [-0.00318403 -0.1101138   0.14011629 -0.00171903  0.06181384 -0.17389516\n",
      "  0.26074493  0.04264804 -0.33500571  0.23584993 -0.19269901 -0.20823737\n",
      "  0.09829006 -0.4703675 ]\n",
      "Training Error:  10.29736789289158\n",
      "====================================================================================================\n",
      "Iteration:  895\n",
      "Previous theta :  [-0.00318403 -0.1101138   0.14011629 -0.00171903  0.06181384 -0.17389516\n",
      "  0.26074493  0.04264804 -0.33500571  0.23584993 -0.19269901 -0.20823737\n",
      "  0.09829006 -0.4703675 ]\n",
      "New theta_0 : [-0.00318345 -0.1101189   0.14012364 -0.00170385  0.06181036 -0.17391529\n",
      "  0.26074053  0.04264974 -0.33501895  0.2358899  -0.1927373  -0.20824226\n",
      "  0.098291   -0.47036566]\n",
      "Training Error:  10.297364073235894\n",
      "====================================================================================================\n",
      "Iteration:  896\n",
      "Previous theta :  [-0.00318345 -0.1101189   0.14012364 -0.00170385  0.06181036 -0.17391529\n",
      "  0.26074053  0.04264974 -0.33501895  0.2358899  -0.1927373  -0.20824226\n",
      "  0.098291   -0.47036566]\n",
      "New theta_0 : [-0.00318287 -0.11012398  0.14013095 -0.00168871  0.0618069  -0.1739353\n",
      "  0.26073614  0.04265143 -0.33503209  0.23592974 -0.19277549 -0.20824712\n",
      "  0.09829193 -0.47036384]\n",
      "Training Error:  10.297360278820115\n",
      "====================================================================================================\n",
      "Iteration:  897\n",
      "Previous theta :  [-0.00318287 -0.11012398  0.14013095 -0.00168871  0.0618069  -0.1739353\n",
      "  0.26073614  0.04265143 -0.33503209  0.23592974 -0.19277549 -0.20824712\n",
      "  0.09829193 -0.47036384]\n",
      "New theta_0 : [-0.00318229 -0.11012904  0.14013823 -0.00167359  0.06180344 -0.1739552\n",
      "  0.26073179  0.04265312 -0.33504513  0.23596946 -0.19281359 -0.20825195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.09829286 -0.47036203]\n",
      "Training Error:  10.297356509445459\n",
      "====================================================================================================\n",
      "Iteration:  898\n",
      "Previous theta :  [-0.00318229 -0.11012904  0.14013823 -0.00167359  0.06180344 -0.1739552\n",
      "  0.26073179  0.04265312 -0.33504513  0.23596946 -0.19281359 -0.20825195\n",
      "  0.09829286 -0.47036203]\n",
      "New theta_0 : [-0.00318171 -0.11013407  0.14014548 -0.0016585   0.0618     -0.17397497\n",
      "  0.26072746  0.04265479 -0.33505807  0.23600905 -0.19285161 -0.20825676\n",
      "  0.09829379 -0.47036022]\n",
      "Training Error:  10.297352764915093\n",
      "====================================================================================================\n",
      "Iteration:  899\n",
      "Previous theta :  [-0.00318171 -0.11013407  0.14014548 -0.0016585   0.0618     -0.17397497\n",
      "  0.26072746  0.04265479 -0.33505807  0.23600905 -0.19285161 -0.20825676\n",
      "  0.09829379 -0.47036022]\n",
      "New theta_0 : [-0.00318113 -0.11013907  0.14015269 -0.00164344  0.06179657 -0.17399462\n",
      "  0.26072316  0.04265647 -0.33507091  0.23604852 -0.19288953 -0.20826155\n",
      "  0.09829472 -0.47035843]\n",
      "Training Error:  10.297349045034114\n",
      "====================================================================================================\n",
      "Iteration:  900\n",
      "Previous theta :  [-0.00318113 -0.11013907  0.14015269 -0.00164344  0.06179657 -0.17399462\n",
      "  0.26072316  0.04265647 -0.33507091  0.23604852 -0.19288953 -0.20826155\n",
      "  0.09829472 -0.47035843]\n",
      "New theta_0 : [-0.00318056 -0.11014405  0.14015986 -0.00162841  0.06179315 -0.17401416\n",
      "  0.26071888  0.04265813 -0.33508366  0.23608787 -0.19292737 -0.20826631\n",
      "  0.09829564 -0.47035665]\n",
      "Training Error:  10.297345349609525\n",
      "====================================================================================================\n",
      "Iteration:  901\n",
      "Previous theta :  [-0.00318056 -0.11014405  0.14015986 -0.00162841  0.06179315 -0.17401416\n",
      "  0.26071888  0.04265813 -0.33508366  0.23608787 -0.19292737 -0.20826631\n",
      "  0.09829564 -0.47035665]\n",
      "New theta_0 : [-0.00317999 -0.11014901  0.14016701 -0.0016134   0.06178974 -0.17403358\n",
      "  0.26071462  0.04265979 -0.33509631  0.23612709 -0.19296512 -0.20827104\n",
      "  0.09829656 -0.47035488]\n",
      "Training Error:  10.297341678450218\n",
      "====================================================================================================\n",
      "Iteration:  902\n",
      "Previous theta :  [-0.00317999 -0.11014901  0.14016701 -0.0016134   0.06178974 -0.17403358\n",
      "  0.26071462  0.04265979 -0.33509631  0.23612709 -0.19296512 -0.20827104\n",
      "  0.09829656 -0.47035488]\n",
      "New theta_0 : [-0.00317942 -0.11015394  0.14017412 -0.00159843  0.06178635 -0.17405288\n",
      "  0.26071039  0.04266144 -0.33510886  0.23616619 -0.19300279 -0.20827575\n",
      "  0.09829747 -0.47035311]\n",
      "Training Error:  10.297338031366946\n",
      "====================================================================================================\n",
      "Iteration:  903\n",
      "Previous theta :  [-0.00317942 -0.11015394  0.14017412 -0.00159843  0.06178635 -0.17405288\n",
      "  0.26071039  0.04266144 -0.33510886  0.23616619 -0.19300279 -0.20827575\n",
      "  0.09829747 -0.47035311]\n",
      "New theta_0 : [-0.00317885 -0.11015885  0.14018119 -0.00158348  0.06178297 -0.17407207\n",
      "  0.26070619  0.04266309 -0.33512132  0.23620517 -0.19304036 -0.20828044\n",
      "  0.09829838 -0.47035136]\n",
      "Training Error:  10.297334408172306\n",
      "====================================================================================================\n",
      "Iteration:  904\n",
      "Previous theta :  [-0.00317885 -0.11015885  0.14018119 -0.00158348  0.06178297 -0.17407207\n",
      "  0.26070619  0.04266309 -0.33512132  0.23620517 -0.19304036 -0.20828044\n",
      "  0.09829838 -0.47035136]\n",
      "New theta_0 : [-0.00317828 -0.11016373  0.14018824 -0.00156856  0.0617796  -0.17409114\n",
      "  0.26070201  0.04266472 -0.33513369  0.23624402 -0.19307785 -0.2082851\n",
      "  0.09829929 -0.47034962]\n",
      "Training Error:  10.29733080868071\n",
      "====================================================================================================\n",
      "Iteration:  905\n",
      "Previous theta :  [-0.00317828 -0.11016373  0.14018824 -0.00156856  0.0617796  -0.17409114\n",
      "  0.26070201  0.04266472 -0.33513369  0.23624402 -0.19307785 -0.2082851\n",
      "  0.09829929 -0.47034962]\n",
      "New theta_0 : [-0.00317772 -0.11016859  0.14019525 -0.00155367  0.06177624 -0.1741101\n",
      "  0.26069785  0.04266636 -0.33514596  0.23628276 -0.19311524 -0.20828973\n",
      "  0.0983002  -0.47034789]\n",
      "Training Error:  10.297327232708367\n",
      "====================================================================================================\n",
      "Iteration:  906\n",
      "Previous theta :  [-0.00317772 -0.11016859  0.14019525 -0.00155367  0.06177624 -0.1741101\n",
      "  0.26069785  0.04266636 -0.33514596  0.23628276 -0.19311524 -0.20828973\n",
      "  0.0983002  -0.47034789]\n",
      "New theta_0 : [-0.00317715 -0.11017343  0.14020223 -0.00153881  0.06177289 -0.17412895\n",
      "  0.26069372  0.04266798 -0.33515815  0.23632137 -0.19315256 -0.20829435\n",
      "  0.0983011  -0.47034617]\n",
      "Training Error:  10.297323680073271\n",
      "====================================================================================================\n",
      "Iteration:  907\n",
      "Previous theta :  [-0.00317715 -0.11017343  0.14020223 -0.00153881  0.06177289 -0.17412895\n",
      "  0.26069372  0.04266798 -0.33515815  0.23632137 -0.19315256 -0.20829435\n",
      "  0.0983011  -0.47034617]\n",
      "New theta_0 : [-0.00317659 -0.11017824  0.14020918 -0.00152398  0.06176955 -0.17414768\n",
      "  0.26068961  0.0426696  -0.33517024  0.23635986 -0.19318978 -0.20829893\n",
      "  0.098302   -0.47034446]\n",
      "Training Error:  10.29732015059516\n",
      "====================================================================================================\n",
      "Iteration:  908\n",
      "Previous theta :  [-0.00317659 -0.11017824  0.14020918 -0.00152398  0.06176955 -0.17414768\n",
      "  0.26068961  0.0426696  -0.33517024  0.23635986 -0.19318978 -0.20829893\n",
      "  0.098302   -0.47034446]\n",
      "New theta_0 : [-0.00317603 -0.11018303  0.14021609 -0.00150918  0.06176623 -0.1741663\n",
      "  0.26068553  0.04267122 -0.33518224  0.23639823 -0.19322692 -0.2083035\n",
      "  0.0983029  -0.47034276]\n",
      "Training Error:  10.297316644095515\n",
      "====================================================================================================\n",
      "Iteration:  909\n",
      "Previous theta :  [-0.00317603 -0.11018303  0.14021609 -0.00150918  0.06176623 -0.1741663\n",
      "  0.26068553  0.04267122 -0.33518224  0.23639823 -0.19322692 -0.2083035\n",
      "  0.0983029  -0.47034276]\n",
      "New theta_0 : [-0.00317547 -0.11018779  0.14022297 -0.0014944   0.06176292 -0.17418482\n",
      "  0.26068147  0.04267283 -0.33519415  0.23643649 -0.19326397 -0.20830804\n",
      "  0.0983038  -0.47034107]\n",
      "Training Error:  10.297313160397533\n",
      "====================================================================================================\n",
      "Iteration:  910\n",
      "Previous theta :  [-0.00317547 -0.11018779  0.14022297 -0.0014944   0.06176292 -0.17418482\n",
      "  0.26068147  0.04267283 -0.33519415  0.23643649 -0.19326397 -0.20830804\n",
      "  0.0983038  -0.47034107]\n",
      "New theta_0 : [-0.00317492 -0.11019254  0.14022982 -0.00147966  0.06175962 -0.17420322\n",
      "  0.26067743  0.04267443 -0.33520597  0.23647462 -0.19330093 -0.20831255\n",
      "  0.09830469 -0.47033939]\n",
      "Training Error:  10.297309699326101\n",
      "====================================================================================================\n",
      "Iteration:  911\n",
      "Previous theta :  [-0.00317492 -0.11019254  0.14022982 -0.00147966  0.06175962 -0.17420322\n",
      "  0.26067743  0.04267443 -0.33520597  0.23647462 -0.19330093 -0.20831255\n",
      "  0.09830469 -0.47033939]\n",
      "New theta_0 : [-0.00317436 -0.11019726  0.14023664 -0.00146494  0.06175633 -0.17422151\n",
      "  0.26067342  0.04267602 -0.3352177   0.23651263 -0.1933378  -0.20831705\n",
      "  0.09830558 -0.47033772]\n",
      "Training Error:  10.297306260707785\n",
      "====================================================================================================\n",
      "Iteration:  912\n",
      "Previous theta :  [-0.00317436 -0.11019726  0.14023664 -0.00146494  0.06175633 -0.17422151\n",
      "  0.26067342  0.04267602 -0.3352177   0.23651263 -0.1933378  -0.20831705\n",
      "  0.09830558 -0.47033772]\n",
      "New theta_0 : [-0.00317381 -0.11020195  0.14024343 -0.00145026  0.06175305 -0.17423969\n",
      "  0.26066943  0.04267761 -0.33522934  0.23655053 -0.19337459 -0.20832152\n",
      "  0.09830646 -0.47033606]\n",
      "Training Error:  10.297302844370803\n",
      "====================================================================================================\n",
      "Iteration:  913\n",
      "Previous theta :  [-0.00317381 -0.11020195  0.14024343 -0.00145026  0.06175305 -0.17423969\n",
      "  0.26066943  0.04267761 -0.33522934  0.23655053 -0.19337459 -0.20832152\n",
      "  0.09830646 -0.47033606]\n",
      "New theta_0 : [-0.00317326 -0.11020663  0.14025019 -0.0014356   0.06174978 -0.17425777\n",
      "  0.26066546  0.0426792  -0.3352409   0.2365883  -0.19341129 -0.20832596\n",
      "  0.09830735 -0.47033441]\n",
      "Training Error:  10.297299450145013\n",
      "====================================================================================================\n",
      "Iteration:  914\n",
      "Previous theta :  [-0.00317326 -0.11020663  0.14025019 -0.0014356   0.06174978 -0.17425777\n",
      "  0.26066546  0.0426792  -0.3352409   0.2365883  -0.19341129 -0.20832596\n",
      "  0.09830735 -0.47033441]\n",
      "New theta_0 : [-0.00317271 -0.11021128  0.14025691 -0.00142097  0.06174653 -0.17427574\n",
      "  0.26066152  0.04268078 -0.33525237  0.23662596 -0.19344791 -0.20833039\n",
      "  0.09830823 -0.47033277]\n",
      "Training Error:  10.297296077861892\n",
      "====================================================================================================\n",
      "Iteration:  915\n",
      "Previous theta :  [-0.00317271 -0.11021128  0.14025691 -0.00142097  0.06174653 -0.17427574\n",
      "  0.26066152  0.04268078 -0.33525237  0.23662596 -0.19344791 -0.20833039\n",
      "  0.09830823 -0.47033277]\n",
      "New theta_0 : [-0.00317216 -0.11021591  0.14026361 -0.00140637  0.06174329 -0.1742936\n",
      "  0.26065759  0.04268235 -0.33526375  0.23666351 -0.19348444 -0.20833479\n",
      "  0.0983091  -0.47033114]\n",
      "Training Error:  10.297292727354508\n",
      "====================================================================================================\n",
      "Iteration:  916\n",
      "Previous theta :  [-0.00317216 -0.11021591  0.14026361 -0.00140637  0.06174329 -0.1742936\n",
      "  0.26065759  0.04268235 -0.33526375  0.23666351 -0.19348444 -0.20833479\n",
      "  0.0983091  -0.47033114]\n",
      "New theta_0 : [-0.00317161 -0.11022051  0.14027027 -0.0013918   0.06174005 -0.17431135\n",
      "  0.26065369  0.04268391 -0.33527505  0.23670093 -0.19352088 -0.20833917\n",
      "  0.09830998 -0.47032952]\n",
      "Training Error:  10.297289398457515\n",
      "====================================================================================================\n",
      "Iteration:  917\n",
      "Previous theta :  [-0.00317161 -0.11022051  0.14027027 -0.0013918   0.06174005 -0.17431135\n",
      "  0.26065369  0.04268391 -0.33527505  0.23670093 -0.19352088 -0.20833917\n",
      "  0.09830998 -0.47032952]\n",
      "New theta_0 : [-0.00317107 -0.1102251   0.14027691 -0.00137726  0.06173683 -0.174329\n",
      "  0.26064982  0.04268547 -0.33528626  0.23673824 -0.19355724 -0.20834352\n",
      "  0.09831085 -0.4703279 ]\n",
      "Training Error:  10.297286091007132\n",
      "====================================================================================================\n",
      "Iteration:  918\n",
      "Previous theta :  [-0.00317107 -0.1102251   0.14027691 -0.00137726  0.06173683 -0.174329\n",
      "  0.26064982  0.04268547 -0.33528626  0.23673824 -0.19355724 -0.20834352\n",
      "  0.09831085 -0.4703279 ]\n",
      "New theta_0 : [-0.00317052 -0.11022966  0.14028351 -0.00136275  0.06173362 -0.17434655\n",
      "  0.26064596  0.04268703 -0.33529739  0.23677543 -0.19359351 -0.20834785\n",
      "  0.09831172 -0.4703263 ]\n",
      "Training Error:  10.297282804841114\n",
      "====================================================================================================\n",
      "Iteration:  919\n",
      "Previous theta :  [-0.00317052 -0.11022966  0.14028351 -0.00136275  0.06173362 -0.17434655\n",
      "  0.26064596  0.04268703 -0.33529739  0.23677543 -0.19359351 -0.20834785\n",
      "  0.09831172 -0.4703263 ]\n",
      "New theta_0 : [-0.00316998 -0.1102342   0.14029008 -0.00134826  0.06173042 -0.17436399\n",
      "  0.26064213  0.04268858 -0.33530844  0.23681251 -0.1936297  -0.20835216\n",
      "  0.09831258 -0.47032471]\n",
      "Training Error:  10.297279539798748\n",
      "====================================================================================================\n",
      "Iteration:  920\n",
      "Previous theta :  [-0.00316998 -0.1102342   0.14029008 -0.00134826  0.06173042 -0.17436399\n",
      "  0.26064213  0.04268858 -0.33530844  0.23681251 -0.1936297  -0.20835216\n",
      "  0.09831258 -0.47032471]\n",
      "New theta_0 : [-0.00316944 -0.11023872  0.14029663 -0.00133381  0.06172723 -0.17438133\n",
      "  0.26063831  0.04269012 -0.3353194   0.23684947 -0.1936658  -0.20835645\n",
      "  0.09831345 -0.47032313]\n",
      "Training Error:  10.297276295720824\n",
      "====================================================================================================\n",
      "Iteration:  921\n",
      "Previous theta :  [-0.00316944 -0.11023872  0.14029663 -0.00133381  0.06172723 -0.17438133\n",
      "  0.26063831  0.04269012 -0.3353194   0.23684947 -0.1936658  -0.20835645\n",
      "  0.09831345 -0.47032313]\n",
      "New theta_0 : [-0.0031689  -0.11024321  0.14030314 -0.00131938  0.06172406 -0.17439856\n",
      "  0.26063452  0.04269165 -0.33533028  0.23688632 -0.19370181 -0.20836071\n",
      "  0.09831431 -0.47032155]\n",
      "Training Error:  10.297273072449634\n",
      "====================================================================================================\n",
      "Iteration:  922\n",
      "Previous theta :  [-0.0031689  -0.11024321  0.14030314 -0.00131938  0.06172406 -0.17439856\n",
      "  0.26063452  0.04269165 -0.33533028  0.23688632 -0.19370181 -0.20836071\n",
      "  0.09831431 -0.47032155]\n",
      "New theta_0 : [-0.00316837 -0.11024769  0.14030963 -0.00130499  0.06172089 -0.1744157\n",
      "  0.26063075  0.04269319 -0.33534108  0.23692306 -0.19373774 -0.20836496\n",
      "  0.09831516 -0.47031999]\n",
      "Training Error:  10.29726986982893\n",
      "====================================================================================================\n",
      "Iteration:  923\n",
      "Previous theta :  [-0.00316837 -0.11024769  0.14030963 -0.00130499  0.06172089 -0.1744157\n",
      "  0.26063075  0.04269319 -0.33534108  0.23692306 -0.19373774 -0.20836496\n",
      "  0.09831516 -0.47031999]\n",
      "New theta_0 : [-0.00316783 -0.11025214  0.14031608 -0.00129062  0.06171774 -0.17443273\n",
      "  0.26062701  0.04269471 -0.33535179  0.23695968 -0.19377358 -0.20836918\n",
      "  0.09831602 -0.47031844]\n",
      "Training Error:  10.297266687703935\n",
      "====================================================================================================\n",
      "Iteration:  924\n",
      "Previous theta :  [-0.00316783 -0.11025214  0.14031608 -0.00129062  0.06171774 -0.17443273\n",
      "  0.26062701  0.04269471 -0.33535179  0.23695968 -0.19377358 -0.20836918\n",
      "  0.09831602 -0.47031844]\n",
      "New theta_0 : [-0.0031673  -0.11025657  0.14032251 -0.00127629  0.06171459 -0.17444966\n",
      "  0.26062328  0.04269623 -0.33536243  0.23699618 -0.19380934 -0.20837338\n",
      "  0.09831687 -0.47031689]\n",
      "Training Error:  10.297263525921299\n",
      "====================================================================================================\n",
      "Iteration:  925\n",
      "Previous theta :  [-0.0031673  -0.11025657  0.14032251 -0.00127629  0.06171459 -0.17444966\n",
      "  0.26062328  0.04269623 -0.33536243  0.23699618 -0.19380934 -0.20837338\n",
      "  0.09831687 -0.47031689]\n",
      "New theta_0 : [-0.00316677 -0.11026098  0.14032891 -0.00126198  0.06171146 -0.17446649\n",
      "  0.26061957  0.04269774 -0.33537299  0.23703258 -0.19384501 -0.20837756\n",
      "  0.09831772 -0.47031535]\n",
      "Training Error:  10.29726038432911\n",
      "====================================================================================================\n",
      "Iteration:  926\n",
      "Previous theta :  [-0.00316677 -0.11026098  0.14032891 -0.00126198  0.06171146 -0.17446649\n",
      "  0.26061957  0.04269774 -0.33537299  0.23703258 -0.19384501 -0.20837756\n",
      "  0.09831772 -0.47031535]\n",
      "New theta_0 : [-0.00316623 -0.11026537  0.14033528 -0.0012477   0.06170834 -0.17448323\n",
      "  0.26061589  0.04269925 -0.33538346  0.23706886 -0.1938806  -0.20838171\n",
      "  0.09831856 -0.47031383]\n",
      "Training Error:  10.297257262776855\n",
      "====================================================================================================\n",
      "Iteration:  927\n",
      "Previous theta :  [-0.00316623 -0.11026537  0.14033528 -0.0012477   0.06170834 -0.17448323\n",
      "  0.26061589  0.04269925 -0.33538346  0.23706886 -0.1938806  -0.20838171\n",
      "  0.09831856 -0.47031383]\n",
      "New theta_0 : [-0.00316571 -0.11026974  0.14034162 -0.00123345  0.06170523 -0.17449986\n",
      "  0.26061222  0.04270076 -0.33539386  0.23710502 -0.19391611 -0.20838585\n",
      "  0.0983194  -0.47031231]\n",
      "Training Error:  10.297254161115415\n",
      "====================================================================================================\n",
      "Iteration:  928\n",
      "Previous theta :  [-0.00316571 -0.11026974  0.14034162 -0.00123345  0.06170523 -0.17449986\n",
      "  0.26061222  0.04270076 -0.33539386  0.23710502 -0.19391611 -0.20838585\n",
      "  0.0983194  -0.47031231]\n",
      "New theta_0 : [-0.00316518 -0.11027409  0.14034793 -0.00121923  0.06170213 -0.1745164\n",
      "  0.26060858  0.04270225 -0.33540418  0.23714108 -0.19395153 -0.20838996\n",
      "  0.09832024 -0.4703108 ]\n",
      "Training Error:  10.297251079197048\n",
      "====================================================================================================\n",
      "Iteration:  929\n",
      "Previous theta :  [-0.00316518 -0.11027409  0.14034793 -0.00121923  0.06170213 -0.1745164\n",
      "  0.26060858  0.04270225 -0.33540418  0.23714108 -0.19395153 -0.20838996\n",
      "  0.09832024 -0.4703108 ]\n",
      "New theta_0 : [-0.00316465 -0.11027842  0.14035421 -0.00120504  0.06169904 -0.17453283\n",
      "  0.26060496  0.04270374 -0.33541442  0.23717703 -0.19398686 -0.20839405\n",
      "  0.09832108 -0.4703093 ]\n",
      "Training Error:  10.297248016875374\n",
      "====================================================================================================\n",
      "Iteration:  930\n",
      "Previous theta :  [-0.00316465 -0.11027842  0.14035421 -0.00120504  0.06169904 -0.17453283\n",
      "  0.26060496  0.04270374 -0.33541442  0.23717703 -0.19398686 -0.20839405\n",
      "  0.09832108 -0.4703093 ]\n",
      "New theta_0 : [-0.00316413 -0.11028272  0.14036047 -0.00119088  0.06169596 -0.17454918\n",
      "  0.26060135  0.04270523 -0.33542459  0.23721286 -0.19402211 -0.20839812\n",
      "  0.09832192 -0.47030781]\n",
      "Training Error:  10.297244974005352\n",
      "====================================================================================================\n",
      "Iteration:  931\n",
      "Previous theta :  [-0.00316413 -0.11028272  0.14036047 -0.00119088  0.06169596 -0.17454918\n",
      "  0.26060135  0.04270523 -0.33542459  0.23721286 -0.19402211 -0.20839812\n",
      "  0.09832192 -0.47030781]\n",
      "New theta_0 : [-0.00316361 -0.11028701  0.14036669 -0.00117675  0.06169289 -0.17456542\n",
      "  0.26059777  0.04270671 -0.33543468  0.23724858 -0.19405728 -0.20840217\n",
      "  0.09832275 -0.47030633]\n",
      "Training Error:  10.297241950443283\n",
      "====================================================================================================\n",
      "Iteration:  932\n",
      "Previous theta :  [-0.00316361 -0.11028701  0.14036669 -0.00117675  0.06169289 -0.17456542\n",
      "  0.26059777  0.04270671 -0.33543468  0.23724858 -0.19405728 -0.20840217\n",
      "  0.09832275 -0.47030633]\n",
      "New theta_0 : [-0.00316309 -0.11029128  0.14037289 -0.00116265  0.06168983 -0.17458157\n",
      "  0.26059421  0.04270819 -0.33544469  0.2372842  -0.19409236 -0.2084062\n",
      "  0.09832358 -0.47030486]\n",
      "Training Error:  10.29723894604677\n",
      "====================================================================================================\n",
      "Iteration:  933\n",
      "Previous theta :  [-0.00316309 -0.11029128  0.14037289 -0.00116265  0.06168983 -0.17458157\n",
      "  0.26059421  0.04270819 -0.33544469  0.2372842  -0.19409236 -0.2084062\n",
      "  0.09832358 -0.47030486]\n",
      "New theta_0 : [-0.00316257 -0.11029552  0.14037907 -0.00114857  0.06168678 -0.17459763\n",
      "  0.26059067  0.04270966 -0.33545463  0.2373197  -0.19412736 -0.20841021\n",
      "  0.0983244  -0.4703034 ]\n",
      "Training Error:  10.297235960674723\n",
      "====================================================================================================\n",
      "Iteration:  934\n",
      "Previous theta :  [-0.00316257 -0.11029552  0.14037907 -0.00114857  0.06168678 -0.17459763\n",
      "  0.26059067  0.04270966 -0.33545463  0.2373197  -0.19412736 -0.20841021\n",
      "  0.0983244  -0.4703034 ]\n",
      "New theta_0 : [-0.00316205 -0.11029975  0.14038521 -0.00113453  0.06168374 -0.17461359\n",
      "  0.26058714  0.04271112 -0.3354645   0.23735509 -0.19416228 -0.2084142\n",
      "  0.09832523 -0.47030194]\n",
      "Training Error:  10.29723299418734\n",
      "====================================================================================================\n",
      "Iteration:  935\n",
      "Previous theta :  [-0.00316205 -0.11029975  0.14038521 -0.00113453  0.06168374 -0.17461359\n",
      "  0.26058714  0.04271112 -0.3354645   0.23735509 -0.19416228 -0.2084142\n",
      "  0.09832523 -0.47030194]\n",
      "New theta_0 : [-0.00316153 -0.11030395  0.14039133 -0.00112052  0.06168072 -0.17462945\n",
      "  0.26058364  0.04271258 -0.33547429  0.23739038 -0.19419711 -0.20841816\n",
      "  0.09832605 -0.4703005 ]\n",
      "Training Error:  10.297230046446082\n",
      "====================================================================================================\n",
      "Iteration:  936\n",
      "Previous theta :  [-0.00316153 -0.11030395  0.14039133 -0.00112052  0.06168072 -0.17462945\n",
      "  0.26058364  0.04271258 -0.33547429  0.23739038 -0.19419711 -0.20841816\n",
      "  0.09832605 -0.4703005 ]\n",
      "New theta_0 : [-0.00316102 -0.11030814  0.14039742 -0.00110653  0.0616777  -0.17464523\n",
      "  0.26058015  0.04271403 -0.33548401  0.23742555 -0.19423186 -0.20842211\n",
      "  0.09832686 -0.47029906]\n",
      "Training Error:  10.297227117313676\n",
      "====================================================================================================\n",
      "Iteration:  937\n",
      "Previous theta :  [-0.00316102 -0.11030814  0.14039742 -0.00110653  0.0616777  -0.17464523\n",
      "  0.26058015  0.04271403 -0.33548401  0.23742555 -0.19423186 -0.20842211\n",
      "  0.09832686 -0.47029906]\n",
      "New theta_0 : [-0.00316051 -0.11031231  0.14040348 -0.00109258  0.06167469 -0.17466091\n",
      "  0.26057669  0.04271548 -0.33549365  0.23746062 -0.19426652 -0.20842604\n",
      "  0.09832768 -0.47029763]\n",
      "Training Error:  10.297224206654088\n",
      "====================================================================================================\n",
      "Iteration:  938\n",
      "Previous theta :  [-0.00316051 -0.11031231  0.14040348 -0.00109258  0.06167469 -0.17466091\n",
      "  0.26057669  0.04271548 -0.33549365  0.23746062 -0.19426652 -0.20842604\n",
      "  0.09832768 -0.47029763]\n",
      "New theta_0 : [-0.00315999 -0.11031645  0.14040952 -0.00107865  0.0616717  -0.1746765\n",
      "  0.26057324  0.04271693 -0.33550322  0.23749558 -0.1943011  -0.20842994\n",
      "  0.09832849 -0.47029622]\n",
      "Training Error:  10.297221314332509\n",
      "====================================================================================================\n",
      "Iteration:  939\n",
      "Previous theta :  [-0.00315999 -0.11031645  0.14040952 -0.00107865  0.0616717  -0.1746765\n",
      "  0.26057324  0.04271693 -0.33550322  0.23749558 -0.1943011  -0.20842994\n",
      "  0.09832849 -0.47029622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00315948 -0.11032058  0.14041553 -0.00106476  0.06166871 -0.174692\n",
      "  0.26056981  0.04271836 -0.33551272  0.23753043 -0.1943356  -0.20843383\n",
      "  0.0983293  -0.4702948 ]\n",
      "Training Error:  10.297218440215353\n",
      "====================================================================================================\n",
      "Iteration:  940\n",
      "Previous theta :  [-0.00315948 -0.11032058  0.14041553 -0.00106476  0.06166871 -0.174692\n",
      "  0.26056981  0.04271836 -0.33551272  0.23753043 -0.1943356  -0.20843383\n",
      "  0.0983293  -0.4702948 ]\n",
      "New theta_0 : [-0.00315897 -0.11032469  0.14042151 -0.00105089  0.06166573 -0.1747074\n",
      "  0.26056641  0.0427198  -0.33552215  0.23756518 -0.19437002 -0.2084377\n",
      "  0.09833011 -0.4702934 ]\n",
      "Training Error:  10.297215584170234\n",
      "====================================================================================================\n",
      "Iteration:  941\n",
      "Previous theta :  [-0.00315897 -0.11032469  0.14042151 -0.00105089  0.06166573 -0.1747074\n",
      "  0.26056641  0.0427198  -0.33552215  0.23756518 -0.19437002 -0.2084377\n",
      "  0.09833011 -0.4702934 ]\n",
      "New theta_0 : [-0.00315847 -0.11032878  0.14042747 -0.00103705  0.06166277 -0.17472272\n",
      "  0.26056302  0.04272122 -0.33553151  0.23759982 -0.19440435 -0.20844154\n",
      "  0.09833091 -0.47029201]\n",
      "Training Error:  10.297212746065949\n",
      "====================================================================================================\n",
      "Iteration:  942\n",
      "Previous theta :  [-0.00315847 -0.11032878  0.14042747 -0.00103705  0.06166277 -0.17472272\n",
      "  0.26056302  0.04272122 -0.33553151  0.23759982 -0.19440435 -0.20844154\n",
      "  0.09833091 -0.47029201]\n",
      "New theta_0 : [-0.00315796 -0.11033285  0.1404334  -0.00102325  0.06165981 -0.17473795\n",
      "  0.26055964  0.04272265 -0.33554079  0.23763435 -0.1944386  -0.20844537\n",
      "  0.09833171 -0.47029063]\n",
      "Training Error:  10.297209925772474\n",
      "====================================================================================================\n",
      "Iteration:  943\n",
      "Previous theta :  [-0.00315796 -0.11033285  0.1404334  -0.00102325  0.06165981 -0.17473795\n",
      "  0.26055964  0.04272265 -0.33554079  0.23763435 -0.1944386  -0.20844537\n",
      "  0.09833171 -0.47029063]\n",
      "New theta_0 : [-0.00315746 -0.1103369   0.1404393  -0.00100947  0.06165687 -0.17475309\n",
      "  0.26055629  0.04272406 -0.33555001  0.23766877 -0.19447277 -0.20844918\n",
      "  0.09833251 -0.47028925]\n",
      "Training Error:  10.29720712316095\n",
      "====================================================================================================\n",
      "Iteration:  944\n",
      "Previous theta :  [-0.00315746 -0.1103369   0.1404393  -0.00100947  0.06165687 -0.17475309\n",
      "  0.26055629  0.04272406 -0.33555001  0.23766877 -0.19447277 -0.20844918\n",
      "  0.09833251 -0.47028925]\n",
      "New theta_0 : [-0.00315696 -0.11034093  0.14044518 -0.00099572  0.06165393 -0.17476814\n",
      "  0.26055296  0.04272548 -0.33555916  0.23770309 -0.19450686 -0.20845296\n",
      "  0.09833331 -0.47028788]\n",
      "Training Error:  10.297204338103667\n",
      "====================================================================================================\n",
      "Iteration:  945\n",
      "Previous theta :  [-0.00315696 -0.11034093  0.14044518 -0.00099572  0.06165393 -0.17476814\n",
      "  0.26055296  0.04272548 -0.33555916  0.23770309 -0.19450686 -0.20845296\n",
      "  0.09833331 -0.47028788]\n",
      "New theta_0 : [-0.00315645 -0.11034494  0.14045103 -0.000982    0.06165101 -0.1747831\n",
      "  0.26054964  0.04272688 -0.33556824  0.23773731 -0.19454086 -0.20845673\n",
      "  0.0983341  -0.47028652]\n",
      "Training Error:  10.297201570474042\n",
      "====================================================================================================\n",
      "Iteration:  946\n",
      "Previous theta :  [-0.00315645 -0.11034494  0.14045103 -0.000982    0.06165101 -0.1747831\n",
      "  0.26054964  0.04272688 -0.33556824  0.23773731 -0.19454086 -0.20845673\n",
      "  0.0983341  -0.47028652]\n",
      "New theta_0 : [-0.00315596 -0.11034893  0.14045686 -0.00096831  0.06164809 -0.17479797\n",
      "  0.26054634  0.04272829 -0.33557725  0.23777142 -0.19457479 -0.20846048\n",
      "  0.09833489 -0.47028517]\n",
      "Training Error:  10.297198820146635\n",
      "====================================================================================================\n",
      "Iteration:  947\n",
      "Previous theta :  [-0.00315596 -0.11034893  0.14045686 -0.00096831  0.06164809 -0.17479797\n",
      "  0.26054634  0.04272829 -0.33557725  0.23777142 -0.19457479 -0.20846048\n",
      "  0.09833489 -0.47028517]\n",
      "New theta_0 : [-0.00315546 -0.11035291  0.14046266 -0.00095465  0.06164519 -0.17481276\n",
      "  0.26054306  0.04272968 -0.3355862   0.23780542 -0.19460863 -0.20846421\n",
      "  0.09833568 -0.47028383]\n",
      "Training Error:  10.297196086997099\n",
      "====================================================================================================\n",
      "Iteration:  948\n",
      "Previous theta :  [-0.00315546 -0.11035291  0.14046266 -0.00095465  0.06164519 -0.17481276\n",
      "  0.26054306  0.04272968 -0.3355862   0.23780542 -0.19460863 -0.20846421\n",
      "  0.09833568 -0.47028383]\n",
      "New theta_0 : [-0.00315496 -0.11035686  0.14046844 -0.00094102  0.06164229 -0.17482746\n",
      "  0.2605398   0.04273107 -0.33559507  0.23783932 -0.19464239 -0.20846792\n",
      "  0.09833647 -0.4702825 ]\n",
      "Training Error:  10.2971933709022\n",
      "====================================================================================================\n",
      "Iteration:  949\n",
      "Previous theta :  [-0.00315496 -0.11035686  0.14046844 -0.00094102  0.06164229 -0.17482746\n",
      "  0.2605398   0.04273107 -0.33559507  0.23783932 -0.19464239 -0.20846792\n",
      "  0.09833647 -0.4702825 ]\n",
      "New theta_0 : [-0.00315447 -0.1103608   0.14047419 -0.00092742  0.0616394  -0.17484208\n",
      "  0.26053656  0.04273246 -0.33560388  0.23787312 -0.19467606 -0.20847162\n",
      "  0.09833725 -0.47028117]\n",
      "Training Error:  10.297190671739784\n",
      "====================================================================================================\n",
      "Iteration:  950\n",
      "Previous theta :  [-0.00315447 -0.1103608   0.14047419 -0.00092742  0.0616394  -0.17484208\n",
      "  0.26053656  0.04273246 -0.33560388  0.23787312 -0.19467606 -0.20847162\n",
      "  0.09833725 -0.47028117]\n",
      "New theta_0 : [-0.00315397 -0.11036472  0.14047992 -0.00091385  0.06163653 -0.17485661\n",
      "  0.26053333  0.04273384 -0.33561263  0.23790681 -0.19470966 -0.20847529\n",
      "  0.09833803 -0.47027985]\n",
      "Training Error:  10.297187989388778\n",
      "====================================================================================================\n",
      "Iteration:  951\n",
      "Previous theta :  [-0.00315397 -0.11036472  0.14047992 -0.00091385  0.06163653 -0.17485661\n",
      "  0.26053333  0.04273384 -0.33561263  0.23790681 -0.19470966 -0.20847529\n",
      "  0.09833803 -0.47027985]\n",
      "New theta_0 : [-0.00315348 -0.11036862  0.14048562 -0.00090031  0.06163366 -0.17487106\n",
      "  0.26053012  0.04273522 -0.33562131  0.2379404  -0.19474317 -0.20847894\n",
      "  0.09833881 -0.47027854]\n",
      "Training Error:  10.29718532372917\n",
      "====================================================================================================\n",
      "Iteration:  952\n",
      "Previous theta :  [-0.00315348 -0.11036862  0.14048562 -0.00090031  0.06163366 -0.17487106\n",
      "  0.26053012  0.04273522 -0.33562131  0.2379404  -0.19474317 -0.20847894\n",
      "  0.09833881 -0.47027854]\n",
      "New theta_0 : [-0.00315299 -0.11037251  0.1404913  -0.00088679  0.0616308  -0.17488542\n",
      "  0.26052693  0.04273659 -0.33562992  0.23797389 -0.19477661 -0.20848258\n",
      "  0.09833959 -0.47027724]\n",
      "Training Error:  10.297182674642002\n",
      "====================================================================================================\n",
      "Iteration:  953\n",
      "Previous theta :  [-0.00315299 -0.11037251  0.1404913  -0.00088679  0.0616308  -0.17488542\n",
      "  0.26052693  0.04273659 -0.33562992  0.23797389 -0.19477661 -0.20848258\n",
      "  0.09833959 -0.47027724]\n",
      "New theta_0 : [-0.0031525  -0.11037637  0.14049695 -0.00087331  0.06162796 -0.1748997\n",
      "  0.26052375  0.04273796 -0.33563847  0.23800728 -0.19480996 -0.2084862\n",
      "  0.09834036 -0.47027595]\n",
      "Training Error:  10.297180042009359\n",
      "====================================================================================================\n",
      "Iteration:  954\n",
      "Previous theta :  [-0.0031525  -0.11037637  0.14049695 -0.00087331  0.06162796 -0.1748997\n",
      "  0.26052375  0.04273796 -0.33563847  0.23800728 -0.19480996 -0.2084862\n",
      "  0.09834036 -0.47027595]\n",
      "New theta_0 : [-0.00315201 -0.11038022  0.14050258 -0.00085986  0.06162512 -0.1749139\n",
      "  0.26052059  0.04273932 -0.33564695  0.23804056 -0.19484323 -0.2084898\n",
      "  0.09834113 -0.47027466]\n",
      "Training Error:  10.297177425714347\n",
      "====================================================================================================\n",
      "Iteration:  955\n",
      "Previous theta :  [-0.00315201 -0.11038022  0.14050258 -0.00085986  0.06162512 -0.1749139\n",
      "  0.26052059  0.04273932 -0.33564695  0.23804056 -0.19484323 -0.2084898\n",
      "  0.09834113 -0.47027466]\n",
      "New theta_0 : [-0.00315153 -0.11038405  0.14050818 -0.00084643  0.06162229 -0.17492801\n",
      "  0.26051745  0.04274068 -0.33565538  0.23807374 -0.19487642 -0.20849338\n",
      "  0.0983419  -0.47027339]\n",
      "Training Error:  10.297174825641106\n",
      "====================================================================================================\n",
      "Iteration:  956\n",
      "Previous theta :  [-0.00315153 -0.11038405  0.14050818 -0.00084643  0.06162229 -0.17492801\n",
      "  0.26051745  0.04274068 -0.33565538  0.23807374 -0.19487642 -0.20849338\n",
      "  0.0983419  -0.47027339]\n",
      "New theta_0 : [-0.00315104 -0.11038786  0.14051376 -0.00083304  0.06161947 -0.17494204\n",
      "  0.26051433  0.04274203 -0.33566373  0.23810682 -0.19490953 -0.20849694\n",
      "  0.09834266 -0.47027212]\n",
      "Training Error:  10.297172241674769\n",
      "====================================================================================================\n",
      "Iteration:  957\n",
      "Previous theta :  [-0.00315104 -0.11038786  0.14051376 -0.00083304  0.06161947 -0.17494204\n",
      "  0.26051433  0.04274203 -0.33566373  0.23810682 -0.19490953 -0.20849694\n",
      "  0.09834266 -0.47027212]\n",
      "New theta_0 : [-0.00315056 -0.11039166  0.14051932 -0.00081967  0.06161666 -0.17495599\n",
      "  0.26051122  0.04274338 -0.33567203  0.2381398  -0.19494256 -0.20850048\n",
      "  0.09834342 -0.47027085]\n",
      "Training Error:  10.297169673701472\n",
      "====================================================================================================\n",
      "Iteration:  958\n",
      "Previous theta :  [-0.00315056 -0.11039166  0.14051932 -0.00081967  0.06161666 -0.17495599\n",
      "  0.26051122  0.04274338 -0.33567203  0.2381398  -0.19494256 -0.20850048\n",
      "  0.09834342 -0.47027085]\n",
      "New theta_0 : [-0.00315007 -0.11039543  0.14052485 -0.00080634  0.06161387 -0.17496986\n",
      "  0.26050813  0.04274472 -0.33568026  0.23817268 -0.19497551 -0.20850401\n",
      "  0.09834418 -0.4702696 ]\n",
      "Training Error:  10.29716712160834\n",
      "====================================================================================================\n",
      "Iteration:  959\n",
      "Previous theta :  [-0.00315007 -0.11039543  0.14052485 -0.00080634  0.06161387 -0.17496986\n",
      "  0.26050813  0.04274472 -0.33568026  0.23817268 -0.19497551 -0.20850401\n",
      "  0.09834418 -0.4702696 ]\n",
      "New theta_0 : [-0.00314959 -0.11039919  0.14053036 -0.00079303  0.06161108 -0.17498365\n",
      "  0.26050505  0.04274606 -0.33568843  0.23820546 -0.19500838 -0.20850752\n",
      "  0.09834494 -0.47026836]\n",
      "Training Error:  10.297164585283468\n",
      "====================================================================================================\n",
      "Iteration:  960\n",
      "Previous theta :  [-0.00314959 -0.11039919  0.14053036 -0.00079303  0.06161108 -0.17498365\n",
      "  0.26050505  0.04274606 -0.33568843  0.23820546 -0.19500838 -0.20850752\n",
      "  0.09834494 -0.47026836]\n",
      "New theta_0 : [-0.00314911 -0.11040294  0.14053584 -0.00077975  0.06160829 -0.17499736\n",
      "  0.26050199  0.0427474  -0.33569654  0.23823814 -0.19504117 -0.20851101\n",
      "  0.0983457  -0.47026712]\n",
      "Training Error:  10.297162064615922\n",
      "====================================================================================================\n",
      "Iteration:  961\n",
      "Previous theta :  [-0.00314911 -0.11040294  0.14053584 -0.00077975  0.06160829 -0.17499736\n",
      "  0.26050199  0.0427474  -0.33569654  0.23823814 -0.19504117 -0.20851101\n",
      "  0.0983457  -0.47026712]\n",
      "New theta_0 : [-0.00314864 -0.11040666  0.14054131 -0.0007665   0.06160552 -0.17501099\n",
      "  0.26049895  0.04274873 -0.33570459  0.23827072 -0.19507388 -0.20851448\n",
      "  0.09834645 -0.47026589]\n",
      "Training Error:  10.297159559495713\n",
      "====================================================================================================\n",
      "Iteration:  962\n",
      "Previous theta :  [-0.00314864 -0.11040666  0.14054131 -0.0007665   0.06160552 -0.17501099\n",
      "  0.26049895  0.04274873 -0.33570459  0.23827072 -0.19507388 -0.20851448\n",
      "  0.09834645 -0.47026589]\n",
      "New theta_0 : [-0.00314816 -0.11041037  0.14054674 -0.00075328  0.06160276 -0.17502454\n",
      "  0.26049593  0.04275005 -0.33571258  0.2383032  -0.19510651 -0.20851794\n",
      "  0.0983472  -0.47026467]\n",
      "Training Error:  10.297157069813805\n",
      "====================================================================================================\n",
      "Iteration:  963\n",
      "Previous theta :  [-0.00314816 -0.11041037  0.14054674 -0.00075328  0.06160276 -0.17502454\n",
      "  0.26049593  0.04275005 -0.33571258  0.2383032  -0.19510651 -0.20851794\n",
      "  0.0983472  -0.47026467]\n",
      "New theta_0 : [-0.00314769 -0.11041406  0.14055216 -0.0007401   0.06160001 -0.17503801\n",
      "  0.26049292  0.04275137 -0.33572051  0.23833558 -0.19513907 -0.20852138\n",
      "  0.09834794 -0.47026345]\n",
      "Training Error:  10.297154595462098\n",
      "====================================================================================================\n",
      "Iteration:  964\n",
      "Previous theta :  [-0.00314769 -0.11041406  0.14055216 -0.0007401   0.06160001 -0.17503801\n",
      "  0.26049292  0.04275137 -0.33572051  0.23833558 -0.19513907 -0.20852138\n",
      "  0.09834794 -0.47026345]\n",
      "New theta_0 : [-0.00314721 -0.11041774  0.14055755 -0.00072694  0.06159727 -0.17505141\n",
      "  0.26048992  0.04275268 -0.33572838  0.23836786 -0.19517154 -0.2085248\n",
      "  0.09834869 -0.47026224]\n",
      "Training Error:  10.297152136333409\n",
      "====================================================================================================\n",
      "Iteration:  965\n",
      "Previous theta :  [-0.00314721 -0.11041774  0.14055755 -0.00072694  0.06159727 -0.17505141\n",
      "  0.26048992  0.04275268 -0.33572838  0.23836786 -0.19517154 -0.2085248\n",
      "  0.09834869 -0.47026224]\n",
      "New theta_0 : [-0.00314674 -0.11042139  0.14056292 -0.00071381  0.06159453 -0.17506473\n",
      "  0.26048694  0.042754   -0.33573619  0.23840005 -0.19520393 -0.2085282\n",
      "  0.09834943 -0.47026104]\n",
      "Training Error:  10.29714969232147\n",
      "====================================================================================================\n",
      "Iteration:  966\n",
      "Previous theta :  [-0.00314674 -0.11042139  0.14056292 -0.00071381  0.06159453 -0.17506473\n",
      "  0.26048694  0.042754   -0.33573619  0.23840005 -0.19520393 -0.2085282\n",
      "  0.09834943 -0.47026104]\n",
      "New theta_0 : [-0.00314627 -0.11042503  0.14056827 -0.0007007   0.06159181 -0.17507797\n",
      "  0.26048398  0.0427553  -0.33574394  0.23843213 -0.19523624 -0.20853159\n",
      "  0.09835017 -0.47025985]\n",
      "Training Error:  10.297147263320928\n",
      "====================================================================================================\n",
      "Iteration:  967\n",
      "Previous theta :  [-0.00314627 -0.11042503  0.14056827 -0.0007007   0.06159181 -0.17507797\n",
      "  0.26048398  0.0427553  -0.33574394  0.23843213 -0.19523624 -0.20853159\n",
      "  0.09835017 -0.47025985]\n",
      "New theta_0 : [-0.0031458  -0.11042866  0.14057359 -0.00068763  0.06158909 -0.17509113\n",
      "  0.26048103  0.0427566  -0.33575164  0.23846412 -0.19526848 -0.20853496\n",
      "  0.09835091 -0.47025867]\n",
      "Training Error:  10.297144849227314\n",
      "====================================================================================================\n",
      "Iteration:  968\n",
      "Previous theta :  [-0.0031458  -0.11042866  0.14057359 -0.00068763  0.06158909 -0.17509113\n",
      "  0.26048103  0.0427566  -0.33575164  0.23846412 -0.19526848 -0.20853496\n",
      "  0.09835091 -0.47025867]\n",
      "New theta_0 : [-0.00314533 -0.11043227  0.14057889 -0.00067459  0.06158638 -0.17510422\n",
      "  0.2604781   0.0427579  -0.33575927  0.23849601 -0.19530063 -0.20853831\n",
      "  0.09835164 -0.47025749]\n",
      "Training Error:  10.29714244993705\n",
      "====================================================================================================\n",
      "Iteration:  969\n",
      "Previous theta :  [-0.00314533 -0.11043227  0.14057889 -0.00067459  0.06158638 -0.17510422\n",
      "  0.2604781   0.0427579  -0.33575927  0.23849601 -0.19530063 -0.20853831\n",
      "  0.09835164 -0.47025749]\n",
      "New theta_0 : [-0.00314486 -0.11043586  0.14058417 -0.00066158  0.06158369 -0.17511724\n",
      "  0.26047519  0.04275919 -0.33576685  0.23852781 -0.19533271 -0.20854165\n",
      "  0.09835238 -0.47025632]\n",
      "Training Error:  10.297140065347435\n",
      "====================================================================================================\n",
      "Iteration:  970\n",
      "Previous theta :  [-0.00314486 -0.11043586  0.14058417 -0.00066158  0.06158369 -0.17511724\n",
      "  0.26047519  0.04275919 -0.33576685  0.23852781 -0.19533271 -0.20854165\n",
      "  0.09835238 -0.47025632]\n",
      "New theta_0 : [-0.0031444  -0.11043943  0.14058942 -0.00064859  0.061581   -0.17513018\n",
      "  0.26047229  0.04276048 -0.33577437  0.23855951 -0.19536471 -0.20854497\n",
      "  0.09835311 -0.47025516]\n",
      "Training Error:  10.297137695356632\n",
      "====================================================================================================\n",
      "Iteration:  971\n",
      "Previous theta :  [-0.0031444  -0.11043943  0.14058942 -0.00064859  0.061581   -0.17513018\n",
      "  0.26047229  0.04276048 -0.33577437  0.23855951 -0.19536471 -0.20854497\n",
      "  0.09835311 -0.47025516]\n",
      "New theta_0 : [-0.00314394 -0.11044299  0.14059466 -0.00063564  0.06157832 -0.17514304\n",
      "  0.2604694   0.04276176 -0.33578184  0.23859111 -0.19539663 -0.20854827\n",
      "  0.09835383 -0.470254  ]\n",
      "Training Error:  10.297135339863665\n",
      "====================================================================================================\n",
      "Iteration:  972\n",
      "Previous theta :  [-0.00314394 -0.11044299  0.14059466 -0.00063564  0.06157832 -0.17514304\n",
      "  0.2604694   0.04276176 -0.33578184  0.23859111 -0.19539663 -0.20854827\n",
      "  0.09835383 -0.470254  ]\n",
      "New theta_0 : [-0.00314347 -0.11044653  0.14059987 -0.00062271  0.06157565 -0.17515583\n",
      "  0.26046653  0.04276304 -0.33578925  0.23862261 -0.19542847 -0.20855155\n",
      "  0.09835456 -0.47025286]\n",
      "Training Error:  10.29713299876841\n",
      "====================================================================================================\n",
      "Iteration:  973\n",
      "Previous theta :  [-0.00314347 -0.11044653  0.14059987 -0.00062271  0.06157565 -0.17515583\n",
      "  0.26046653  0.04276304 -0.33578925  0.23862261 -0.19542847 -0.20855155\n",
      "  0.09835456 -0.47025286]\n",
      "New theta_0 : [-0.00314301 -0.11045006  0.14060506 -0.00060982  0.06157299 -0.17516855\n",
      "  0.26046368  0.04276432 -0.3357966   0.23865402 -0.19546024 -0.20855482\n",
      "  0.09835528 -0.47025172]\n",
      "Training Error:  10.297130671971573\n",
      "====================================================================================================\n",
      "Iteration:  974\n",
      "Previous theta :  [-0.00314301 -0.11045006  0.14060506 -0.00060982  0.06157299 -0.17516855\n",
      "  0.26046368  0.04276432 -0.3357966   0.23865402 -0.19546024 -0.20855482\n",
      "  0.09835528 -0.47025172]\n",
      "New theta_0 : [-0.00314255 -0.11045357  0.14061023 -0.00059695  0.06157033 -0.17518119\n",
      "  0.26046083  0.04276559 -0.3358039   0.23868534 -0.19549192 -0.20855807\n",
      "  0.098356   -0.47025058]\n",
      "Training Error:  10.297128359374705\n",
      "====================================================================================================\n",
      "Iteration:  975\n",
      "Previous theta :  [-0.00314255 -0.11045357  0.14061023 -0.00059695  0.06157033 -0.17518119\n",
      "  0.26046083  0.04276559 -0.3358039   0.23868534 -0.19549192 -0.20855807\n",
      "  0.098356   -0.47025058]\n",
      "New theta_0 : [-0.00314209 -0.11045707  0.14061538 -0.00058411  0.06156769 -0.17519376\n",
      "  0.26045801  0.04276685 -0.33581115  0.23871656 -0.19552353 -0.20856131\n",
      "  0.09835672 -0.47024946]\n",
      "Training Error:  10.297126060880169\n",
      "====================================================================================================\n",
      "Iteration:  976\n",
      "Previous theta :  [-0.00314209 -0.11045707  0.14061538 -0.00058411  0.06156769 -0.17519376\n",
      "  0.26045801  0.04276685 -0.33581115  0.23871656 -0.19552353 -0.20856131\n",
      "  0.09835672 -0.47024946]\n",
      "New theta_0 : [-0.00314164 -0.11046055  0.1406205  -0.0005713   0.06156505 -0.17520626\n",
      "  0.2604552   0.04276811 -0.33581834  0.23874769 -0.19555506 -0.20856453\n",
      "  0.09835743 -0.47024834]\n",
      "Training Error:  10.29712377639115\n",
      "====================================================================================================\n",
      "Iteration:  977\n",
      "Previous theta :  [-0.00314164 -0.11046055  0.1406205  -0.0005713   0.06156505 -0.17520626\n",
      "  0.2604552   0.04276811 -0.33581834  0.23874769 -0.19555506 -0.20856453\n",
      "  0.09835743 -0.47024834]\n",
      "New theta_0 : [-0.00314118 -0.11046401  0.1406256  -0.00055852  0.06156243 -0.17521869\n",
      "  0.2604524   0.04276937 -0.33582547  0.23877872 -0.19558652 -0.20856773\n",
      "  0.09835815 -0.47024723]\n",
      "Training Error:  10.297121505811631\n",
      "====================================================================================================\n",
      "Iteration:  978\n",
      "Previous theta :  [-0.00314118 -0.11046401  0.1406256  -0.00055852  0.06156243 -0.17521869\n",
      "  0.2604524   0.04276937 -0.33582547  0.23877872 -0.19558652 -0.20856773\n",
      "  0.09835815 -0.47024723]\n",
      "New theta_0 : [-0.00314072 -0.11046746  0.14063069 -0.00054577  0.06155981 -0.17523105\n",
      "  0.26044962  0.04277062 -0.33583256  0.23880966 -0.19561789 -0.20857092\n",
      "  0.09835886 -0.47024612]\n",
      "Training Error:  10.2971192490464\n",
      "====================================================================================================\n",
      "Iteration:  979\n",
      "Previous theta :  [-0.00314072 -0.11046746  0.14063069 -0.00054577  0.06155981 -0.17523105\n",
      "  0.26044962  0.04277062 -0.33583256  0.23880966 -0.19561789 -0.20857092\n",
      "  0.09835886 -0.47024612]\n",
      "New theta_0 : [-0.00314027 -0.11047089  0.14063575 -0.00053305  0.0615572  -0.17524333\n",
      "  0.26044685  0.04277187 -0.33583958  0.2388405  -0.19564919 -0.20857409\n",
      "  0.09835957 -0.47024503]\n",
      "Training Error:  10.29711700600103\n",
      "====================================================================================================\n",
      "Iteration:  980\n",
      "Previous theta :  [-0.00314027 -0.11047089  0.14063575 -0.00053305  0.0615572  -0.17524333\n",
      "  0.26044685  0.04277187 -0.33583958  0.2388405  -0.19564919 -0.20857409\n",
      "  0.09835957 -0.47024503]\n",
      "New theta_0 : [-0.00313982 -0.11047431  0.14064079 -0.00052036  0.0615546  -0.17525555\n",
      "  0.2604441   0.04277311 -0.33584656  0.23887125 -0.19568041 -0.20857725\n",
      "  0.09836027 -0.47024394]\n",
      "Training Error:  10.297114776581878\n",
      "====================================================================================================\n",
      "Iteration:  981\n",
      "Previous theta :  [-0.00313982 -0.11047431  0.14064079 -0.00052036  0.0615546  -0.17525555\n",
      "  0.2604441   0.04277311 -0.33584656  0.23887125 -0.19568041 -0.20857725\n",
      "  0.09836027 -0.47024394]\n",
      "New theta_0 : [-0.00313937 -0.11047771  0.14064581 -0.00050769  0.06155201 -0.1752677\n",
      "  0.26044136  0.04277435 -0.33585349  0.23890191 -0.19571156 -0.20858039\n",
      "  0.09836098 -0.47024285]\n",
      "Training Error:  10.297112560696071\n",
      "====================================================================================================\n",
      "Iteration:  982\n",
      "Previous theta :  [-0.00313937 -0.11047771  0.14064581 -0.00050769  0.06155201 -0.1752677\n",
      "  0.26044136  0.04277435 -0.33585349  0.23890191 -0.19571156 -0.20858039\n",
      "  0.09836098 -0.47024285]\n",
      "New theta_0 : [-0.00313892 -0.11048109  0.14065081 -0.00049506  0.06154942 -0.17527977\n",
      "  0.26043863  0.04277559 -0.33586036  0.23893248 -0.19574263 -0.20858351\n",
      "  0.09836168 -0.47024178]\n",
      "Training Error:  10.297110358251501\n",
      "====================================================================================================\n",
      "Iteration:  983\n",
      "Previous theta :  [-0.00313892 -0.11048109  0.14065081 -0.00049506  0.06154942 -0.17527977\n",
      "  0.26043863  0.04277559 -0.33586036  0.23893248 -0.19574263 -0.20858351\n",
      "  0.09836168 -0.47024178]\n",
      "New theta_0 : [-0.00313847 -0.11048447  0.14065578 -0.00048245  0.06154685 -0.17529178\n",
      "  0.26043592  0.04277682 -0.33586718  0.23896295 -0.19577362 -0.20858662\n",
      "  0.09836238 -0.47024071]\n",
      "Training Error:  10.29710816915682\n",
      "====================================================================================================\n",
      "Iteration:  984\n",
      "Previous theta :  [-0.00313847 -0.11048447  0.14065578 -0.00048245  0.06154685 -0.17529178\n",
      "  0.26043592  0.04277682 -0.33586718  0.23896295 -0.19577362 -0.20858662\n",
      "  0.09836238 -0.47024071]\n",
      "New theta_0 : [-3.13802503e-03 -1.10487822e-01  1.40660740e-01 -4.69878351e-04\n",
      "  6.15442842e-02 -1.75303719e-01  2.60433223e-01  4.27780462e-02\n",
      " -3.35873950e-01  2.38993330e-01 -1.95804537e-01 -2.08589717e-01\n",
      "  9.83630730e-02 -4.70239643e-01]\n",
      "Training Error:  10.297105993321429\n",
      "====================================================================================================\n",
      "Iteration:  985\n",
      "Previous theta :  [-3.13802503e-03 -1.10487822e-01  1.40660740e-01 -4.69878351e-04\n",
      "  6.15442842e-02 -1.75303719e-01  2.60433223e-01  4.27780462e-02\n",
      " -3.35873950e-01  2.38993330e-01 -1.95804537e-01 -2.08589717e-01\n",
      "  9.83630730e-02 -4.70239643e-01]\n",
      "New theta_0 : [-3.13757963e-03 -1.10491163e-01  1.40665677e-01 -4.57330983e-04\n",
      "  6.15417266e-02 -1.75315591e-01  2.60430539e-01  4.27792689e-02\n",
      " -3.35880669e-01  2.39023620e-01 -1.95835376e-01 -2.08592795e-01\n",
      "  9.83637672e-02 -4.70238587e-01]\n",
      "Training Error:  10.297103830655466\n",
      "====================================================================================================\n",
      "Iteration:  986\n",
      "Previous theta :  [-3.13757963e-03 -1.10491163e-01  1.40665677e-01 -4.57330983e-04\n",
      "  6.15417266e-02 -1.75315591e-01  2.60430539e-01  4.27792689e-02\n",
      " -3.35880669e-01  2.39023620e-01 -1.95835376e-01 -2.08592795e-01\n",
      "  9.83637672e-02 -4.70238587e-01]\n",
      "New theta_0 : [-3.13713553e-03 -1.10494489e-01  1.40670593e-01 -4.44812547e-04\n",
      "  6.15391775e-02 -1.75327394e-01  2.60427869e-01  4.27804874e-02\n",
      " -3.35887338e-01  2.39053818e-01 -1.95866139e-01 -2.08595858e-01\n",
      "  9.83644591e-02 -4.70237538e-01]\n",
      "Training Error:  10.29710168106981\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  987\n",
      "Previous theta :  [-3.13713553e-03 -1.10494489e-01  1.40670593e-01 -4.44812547e-04\n",
      "  6.15391775e-02 -1.75327394e-01  2.60427869e-01  4.27804874e-02\n",
      " -3.35887338e-01  2.39053818e-01 -1.95866139e-01 -2.08595858e-01\n",
      "  9.83644591e-02 -4.70237538e-01]\n",
      "New theta_0 : [-3.13669271e-03 -1.10497801e-01  1.40675489e-01 -4.32323021e-04\n",
      "  6.15366369e-02 -1.75339131e-01  2.60425213e-01  4.27817017e-02\n",
      " -3.35893956e-01  2.39083925e-01 -1.95896827e-01 -2.08598905e-01\n",
      "  9.83651487e-02 -4.70236496e-01]\n",
      "Training Error:  10.297099544476064\n",
      "====================================================================================================\n",
      "Iteration:  988\n",
      "Previous theta :  [-3.13669271e-03 -1.10497801e-01  1.40675489e-01 -4.32323021e-04\n",
      "  6.15366369e-02 -1.75339131e-01  2.60425213e-01  4.27817017e-02\n",
      " -3.35893956e-01  2.39083925e-01 -1.95896827e-01 -2.08598905e-01\n",
      "  9.83651487e-02 -4.70236496e-01]\n",
      "New theta_0 : [-3.13625119e-03 -1.10501097e-01  1.40680365e-01 -4.19862378e-04\n",
      "  6.15341046e-02 -1.75350800e-01  2.60422570e-01  4.27829119e-02\n",
      " -3.35900526e-01  2.39113942e-01 -1.95927438e-01 -2.08601937e-01\n",
      "  9.83658360e-02 -4.70235460e-01]\n",
      "Training Error:  10.297097420786548\n",
      "====================================================================================================\n",
      "Iteration:  989\n",
      "Previous theta :  [-3.13625119e-03 -1.10501097e-01  1.40680365e-01 -4.19862378e-04\n",
      "  6.15341046e-02 -1.75350800e-01  2.60422570e-01  4.27829119e-02\n",
      " -3.35900526e-01  2.39113942e-01 -1.95927438e-01 -2.08601937e-01\n",
      "  9.83658360e-02 -4.70235460e-01]\n",
      "New theta_0 : [-3.13581094e-03 -1.10504379e-01  1.40685221e-01 -4.07430592e-04\n",
      "  6.15315807e-02 -1.75362404e-01  2.60419940e-01  4.27841180e-02\n",
      " -3.35907046e-01  2.39143868e-01 -1.95957974e-01 -2.08604954e-01\n",
      "  9.83665210e-02 -4.70234431e-01]\n",
      "Training Error:  10.2970953099143\n",
      "====================================================================================================\n",
      "Iteration:  990\n",
      "Previous theta :  [-3.13581094e-03 -1.10504379e-01  1.40685221e-01 -4.07430592e-04\n",
      "  6.15315807e-02 -1.75362404e-01  2.60419940e-01  4.27841180e-02\n",
      " -3.35907046e-01  2.39143868e-01 -1.95957974e-01 -2.08604954e-01\n",
      "  9.83665210e-02 -4.70234431e-01]\n",
      "New theta_0 : [-3.13537198e-03 -1.10507647e-01  1.40690057e-01 -3.95027638e-04\n",
      "  6.15290652e-02 -1.75373941e-01  2.60417324e-01  4.27853199e-02\n",
      " -3.35913517e-01  2.39173703e-01 -1.95988435e-01 -2.08607957e-01\n",
      "  9.83672037e-02 -4.70233408e-01]\n",
      "Training Error:  10.297093211773054\n",
      "====================================================================================================\n",
      "Iteration:  991\n",
      "Previous theta :  [-3.13537198e-03 -1.10507647e-01  1.40690057e-01 -3.95027638e-04\n",
      "  6.15290652e-02 -1.75373941e-01  2.60417324e-01  4.27853199e-02\n",
      " -3.35913517e-01  2.39173703e-01 -1.95988435e-01 -2.08607957e-01\n",
      "  9.83672037e-02 -4.70233408e-01]\n",
      "New theta_0 : [-3.13493428e-03 -1.10510900e-01  1.40694873e-01 -3.82653489e-04\n",
      "  6.15265579e-02 -1.75385413e-01  2.60414721e-01  4.27865178e-02\n",
      " -3.35919939e-01  2.39203449e-01 -1.96018820e-01 -2.08610944e-01\n",
      "  9.83678841e-02 -4.70232392e-01]\n",
      "Training Error:  10.297091126277248\n",
      "====================================================================================================\n",
      "Iteration:  992\n",
      "Previous theta :  [-3.13493428e-03 -1.10510900e-01  1.40694873e-01 -3.82653489e-04\n",
      "  6.15265579e-02 -1.75385413e-01  2.60414721e-01  4.27865178e-02\n",
      " -3.35919939e-01  2.39203449e-01 -1.96018820e-01 -2.08610944e-01\n",
      "  9.83678841e-02 -4.70232392e-01]\n",
      "New theta_0 : [-3.13449786e-03 -1.10514138e-01  1.40699669e-01 -3.70308117e-04\n",
      "  6.15240589e-02 -1.75396820e-01  2.60412131e-01  4.27877117e-02\n",
      " -3.35926314e-01  2.39233106e-01 -1.96049129e-01 -2.08613916e-01\n",
      "  9.83685622e-02 -4.70231383e-01]\n",
      "Training Error:  10.297089053342015\n",
      "====================================================================================================\n",
      "Iteration:  993\n",
      "Previous theta :  [-3.13449786e-03 -1.10514138e-01  1.40699669e-01 -3.70308117e-04\n",
      "  6.15240589e-02 -1.75396820e-01  2.60412131e-01  4.27877117e-02\n",
      " -3.35926314e-01  2.39233106e-01 -1.96049129e-01 -2.08613916e-01\n",
      "  9.83685622e-02 -4.70231383e-01]\n",
      "New theta_0 : [-3.13406270e-03 -1.10517363e-01  1.40704446e-01 -3.57991497e-04\n",
      "  6.15215682e-02 -1.75408162e-01  2.60409554e-01  4.27889015e-02\n",
      " -3.35932641e-01  2.39262673e-01 -1.96079364e-01 -2.08616874e-01\n",
      "  9.83692381e-02 -4.70230380e-01]\n",
      "Training Error:  10.297086992883159\n",
      "====================================================================================================\n",
      "Iteration:  994\n",
      "Previous theta :  [-3.13406270e-03 -1.10517363e-01  1.40704446e-01 -3.57991497e-04\n",
      "  6.15215682e-02 -1.75408162e-01  2.60409554e-01  4.27889015e-02\n",
      " -3.35932641e-01  2.39262673e-01 -1.96079364e-01 -2.08616874e-01\n",
      "  9.83692381e-02 -4.70230380e-01]\n",
      "New theta_0 : [-3.13362881e-03 -1.10520573e-01  1.40709203e-01 -3.45703599e-04\n",
      "  6.15190856e-02 -1.75419440e-01  2.60406991e-01  4.27900872e-02\n",
      " -3.35938920e-01  2.39292151e-01 -1.96109524e-01 -2.08619817e-01\n",
      "  9.83699117e-02 -4.70229384e-01]\n",
      "Training Error:  10.297084944817174\n",
      "====================================================================================================\n",
      "Iteration:  995\n",
      "Previous theta :  [-3.13362881e-03 -1.10520573e-01  1.40709203e-01 -3.45703599e-04\n",
      "  6.15190856e-02 -1.75419440e-01  2.60406991e-01  4.27900872e-02\n",
      " -3.35938920e-01  2.39292151e-01 -1.96109524e-01 -2.08619817e-01\n",
      "  9.83699117e-02 -4.70229384e-01]\n",
      "New theta_0 : [-3.13319617e-03 -1.10523769e-01  1.40713941e-01 -3.33444397e-04\n",
      "  6.15166113e-02 -1.75430654e-01  2.60404440e-01  4.27912689e-02\n",
      " -3.35945152e-01  2.39321541e-01 -1.96139609e-01 -2.08622746e-01\n",
      "  9.83705830e-02 -4.70228394e-01]\n",
      "Training Error:  10.297082909061212\n",
      "====================================================================================================\n",
      "Iteration:  996\n",
      "Previous theta :  [-3.13319617e-03 -1.10523769e-01  1.40713941e-01 -3.33444397e-04\n",
      "  6.15166113e-02 -1.75430654e-01  2.60404440e-01  4.27912689e-02\n",
      " -3.35945152e-01  2.39321541e-01 -1.96139609e-01 -2.08622746e-01\n",
      "  9.83705830e-02 -4.70228394e-01]\n",
      "New theta_0 : [-3.13276478e-03 -1.10526950e-01  1.40718659e-01 -3.21213860e-04\n",
      "  6.15141450e-02 -1.75441804e-01  2.60401902e-01  4.27924467e-02\n",
      " -3.35951338e-01  2.39350842e-01 -1.96169619e-01 -2.08625660e-01\n",
      "  9.83712522e-02 -4.70227411e-01]\n",
      "Training Error:  10.297080885533097\n",
      "====================================================================================================\n",
      "Iteration:  997\n",
      "Previous theta :  [-3.13276478e-03 -1.10526950e-01  1.40718659e-01 -3.21213860e-04\n",
      "  6.15141450e-02 -1.75441804e-01  2.60401902e-01  4.27924467e-02\n",
      " -3.35951338e-01  2.39350842e-01 -1.96169619e-01 -2.08625660e-01\n",
      "  9.83712522e-02 -4.70227411e-01]\n",
      "New theta_0 : [-3.13233464e-03 -1.10530118e-01  1.40723359e-01 -3.09011960e-04\n",
      "  6.15116869e-02 -1.75452892e-01  2.60399376e-01  4.27936205e-02\n",
      " -3.35957477e-01  2.39380056e-01 -1.96199555e-01 -2.08628559e-01\n",
      "  9.83719191e-02 -4.70226434e-01]\n",
      "Training Error:  10.297078874151312\n",
      "====================================================================================================\n",
      "Iteration:  998\n",
      "Previous theta :  [-3.13233464e-03 -1.10530118e-01  1.40723359e-01 -3.09011960e-04\n",
      "  6.15116869e-02 -1.75452892e-01  2.60399376e-01  4.27936205e-02\n",
      " -3.35957477e-01  2.39380056e-01 -1.96199555e-01 -2.08628559e-01\n",
      "  9.83719191e-02 -4.70226434e-01]\n",
      "New theta_0 : [-3.13190575e-03 -1.10533272e-01  1.40728039e-01 -2.96838669e-04\n",
      "  6.15092369e-02 -1.75463917e-01  2.60396864e-01  4.27947903e-02\n",
      " -3.35963570e-01  2.39409181e-01 -1.96229417e-01 -2.08631445e-01\n",
      "  9.83725837e-02 -4.70225463e-01]\n",
      "Training Error:  10.297076874834978\n",
      "====================================================================================================\n",
      "Iteration:  999\n",
      "Previous theta :  [-3.13190575e-03 -1.10533272e-01  1.40728039e-01 -2.96838669e-04\n",
      "  6.15092369e-02 -1.75463917e-01  2.60396864e-01  4.27947903e-02\n",
      " -3.35963570e-01  2.39409181e-01 -1.96229417e-01 -2.08631445e-01\n",
      "  9.83725837e-02 -4.70225463e-01]\n",
      "New theta_0 : [-3.13147809e-03 -1.10536412e-01  1.40732700e-01 -2.84693955e-04\n",
      "  6.15067949e-02 -1.75474880e-01  2.60394364e-01  4.27959562e-02\n",
      " -3.35969618e-01  2.39438219e-01 -1.96259204e-01 -2.08634316e-01\n",
      "  9.83732461e-02 -4.70224499e-01]\n",
      "Training Error:  10.297074887503875\n",
      "====================================================================================================\n",
      "Iteration:  1000\n",
      "Previous theta :  [-3.13147809e-03 -1.10536412e-01  1.40732700e-01 -2.84693955e-04\n",
      "  6.15067949e-02 -1.75474880e-01  2.60394364e-01  4.27959562e-02\n",
      " -3.35969618e-01  2.39438219e-01 -1.96259204e-01 -2.08634316e-01\n",
      "  9.83732461e-02 -4.70224499e-01]\n",
      "New theta_0 : [-3.13105168e-03 -1.10539538e-01  1.40737343e-01 -2.72577789e-04\n",
      "  6.15043609e-02 -1.75485780e-01  2.60391876e-01  4.27971181e-02\n",
      " -3.35975620e-01  2.39467170e-01 -1.96288917e-01 -2.08637172e-01\n",
      "  9.83739064e-02 -4.70223540e-01]\n",
      "Training Error:  10.297072912078406\n",
      "====================================================================================================\n",
      "Iteration:  1001\n",
      "Previous theta :  [-3.13105168e-03 -1.10539538e-01  1.40737343e-01 -2.72577789e-04\n",
      "  6.15043609e-02 -1.75485780e-01  2.60391876e-01  4.27971181e-02\n",
      " -3.35975620e-01  2.39467170e-01 -1.96288917e-01 -2.08637172e-01\n",
      "  9.83739064e-02 -4.70223540e-01]\n",
      "New theta_0 : [-3.13062649e-03 -1.10542650e-01  1.40741967e-01 -2.60490140e-04\n",
      "  6.15019349e-02 -1.75496620e-01  2.60389401e-01  4.27982762e-02\n",
      " -3.35981577e-01  2.39496034e-01 -1.96318557e-01 -2.08640015e-01\n",
      "  9.83745644e-02 -4.70222588e-01]\n",
      "Training Error:  10.297070948479615\n",
      "====================================================================================================\n",
      "Iteration:  1002\n",
      "Previous theta :  [-3.13062649e-03 -1.10542650e-01  1.40741967e-01 -2.60490140e-04\n",
      "  6.15019349e-02 -1.75496620e-01  2.60389401e-01  4.27982762e-02\n",
      " -3.35981577e-01  2.39496034e-01 -1.96318557e-01 -2.08640015e-01\n",
      "  9.83745644e-02 -4.70222588e-01]\n",
      "New theta_0 : [-3.13020253e-03 -1.10545749e-01  1.40746572e-01 -2.48430977e-04\n",
      "  6.14995168e-02 -1.75507398e-01  2.60386938e-01  4.27994304e-02\n",
      " -3.35987490e-01  2.39524812e-01 -1.96348122e-01 -2.08642844e-01\n",
      "  9.83752202e-02 -4.70221643e-01]\n",
      "Training Error:  10.297068996629166\n",
      "====================================================================================================\n",
      "Iteration:  1003\n",
      "Previous theta :  [-3.13020253e-03 -1.10545749e-01  1.40746572e-01 -2.48430977e-04\n",
      "  6.14995168e-02 -1.75507398e-01  2.60386938e-01  4.27994304e-02\n",
      " -3.35987490e-01  2.39524812e-01 -1.96348122e-01 -2.08642844e-01\n",
      "  9.83752202e-02 -4.70221643e-01]\n",
      "New theta_0 : [-3.12977980e-03 -1.10548834e-01  1.40751158e-01 -2.36400270e-04\n",
      "  6.14971067e-02 -1.75518115e-01  2.60384487e-01  4.28005807e-02\n",
      " -3.35993358e-01  2.39553503e-01 -1.96377614e-01 -2.08645659e-01\n",
      "  9.83758739e-02 -4.70220703e-01]\n",
      "Training Error:  10.297067056449345\n",
      "====================================================================================================\n",
      "Iteration:  1004\n",
      "Previous theta :  [-3.12977980e-03 -1.10548834e-01  1.40751158e-01 -2.36400270e-04\n",
      "  6.14971067e-02 -1.75518115e-01  2.60384487e-01  4.28005807e-02\n",
      " -3.35993358e-01  2.39553503e-01 -1.96377614e-01 -2.08645659e-01\n",
      "  9.83758739e-02 -4.70220703e-01]\n",
      "New theta_0 : [-3.12935829e-03 -1.10551906e-01  1.40755726e-01 -2.24397986e-04\n",
      "  6.14947044e-02 -1.75528772e-01  2.60382048e-01  4.28017271e-02\n",
      " -3.35999183e-01  2.39582109e-01 -1.96407033e-01 -2.08648460e-01\n",
      "  9.83765253e-02 -4.70219770e-01]\n",
      "Training Error:  10.297065127863048\n",
      "====================================================================================================\n",
      "Iteration:  1005\n",
      "Previous theta :  [-3.12935829e-03 -1.10551906e-01  1.40755726e-01 -2.24397986e-04\n",
      "  6.14947044e-02 -1.75528772e-01  2.60382048e-01  4.28017271e-02\n",
      " -3.35999183e-01  2.39582109e-01 -1.96407033e-01 -2.08648460e-01\n",
      "  9.83765253e-02 -4.70219770e-01]\n",
      "New theta_0 : [-3.12893799e-03 -1.10554964e-01  1.40760276e-01 -2.12424094e-04\n",
      "  6.14923101e-02 -1.75539370e-01  2.60379622e-01  4.28028697e-02\n",
      " -3.36004963e-01  2.39610628e-01 -1.96436378e-01 -2.08651247e-01\n",
      "  9.83771746e-02 -4.70218842e-01]\n",
      "Training Error:  10.297063210793777\n",
      "====================================================================================================\n",
      "Iteration:  1006\n",
      "Previous theta :  [-3.12893799e-03 -1.10554964e-01  1.40760276e-01 -2.12424094e-04\n",
      "  6.14923101e-02 -1.75539370e-01  2.60379622e-01  4.28028697e-02\n",
      " -3.36004963e-01  2.39610628e-01 -1.96436378e-01 -2.08651247e-01\n",
      "  9.83771746e-02 -4.70218842e-01]\n",
      "New theta_0 : [-3.12851891e-03 -1.10558009e-01  1.40764807e-01 -2.00478561e-04\n",
      "  6.14899235e-02 -1.75549907e-01  2.60377207e-01  4.28040085e-02\n",
      " -3.36010701e-01  2.39639062e-01 -1.96465650e-01 -2.08654021e-01\n",
      "  9.83778217e-02 -4.70217921e-01]\n",
      "Training Error:  10.297061305165636\n",
      "====================================================================================================\n",
      "Iteration:  1007\n",
      "Previous theta :  [-3.12851891e-03 -1.10558009e-01  1.40764807e-01 -2.00478561e-04\n",
      "  6.14899235e-02 -1.75549907e-01  2.60377207e-01  4.28040085e-02\n",
      " -3.36010701e-01  2.39639062e-01 -1.96465650e-01 -2.08654021e-01\n",
      "  9.83778217e-02 -4.70217921e-01]\n",
      "New theta_0 : [-3.12810103e-03 -1.10561041e-01  1.40769320e-01 -1.88561354e-04\n",
      "  6.14875448e-02 -1.75560386e-01  2.60374804e-01  4.28051435e-02\n",
      " -3.36016395e-01  2.39667412e-01 -1.96494849e-01 -2.08656780e-01\n",
      "  9.83784667e-02 -4.70217006e-01]\n",
      "Training Error:  10.297059410903328\n",
      "====================================================================================================\n",
      "Iteration:  1008\n",
      "Previous theta :  [-3.12810103e-03 -1.10561041e-01  1.40769320e-01 -1.88561354e-04\n",
      "  6.14875448e-02 -1.75560386e-01  2.60374804e-01  4.28051435e-02\n",
      " -3.36016395e-01  2.39667412e-01 -1.96494849e-01 -2.08656780e-01\n",
      "  9.83784667e-02 -4.70217006e-01]\n",
      "New theta_0 : [-3.12768436e-03 -1.10564059e-01  1.40773815e-01 -1.76672441e-04\n",
      "  6.14851738e-02 -1.75570805e-01  2.60372414e-01  4.28062747e-02\n",
      " -3.36022047e-01  2.39695676e-01 -1.96523976e-01 -2.08659527e-01\n",
      "  9.83791095e-02 -4.70216097e-01]\n",
      "Training Error:  10.297057527932134\n",
      "====================================================================================================\n",
      "Iteration:  1009\n",
      "Previous theta :  [-3.12768436e-03 -1.10564059e-01  1.40773815e-01 -1.76672441e-04\n",
      "  6.14851738e-02 -1.75570805e-01  2.60372414e-01  4.28062747e-02\n",
      " -3.36022047e-01  2.39695676e-01 -1.96523976e-01 -2.08659527e-01\n",
      "  9.83791095e-02 -4.70216097e-01]\n",
      "New theta_0 : [-3.12726889e-03 -1.10567065e-01  1.40778292e-01 -1.64811788e-04\n",
      "  6.14828105e-02 -1.75581166e-01  2.60370034e-01  4.28074021e-02\n",
      " -3.36027657e-01  2.39723855e-01 -1.96553029e-01 -2.08662260e-01\n",
      "  9.83797501e-02 -4.70215193e-01]\n",
      "Training Error:  10.297055656177928\n",
      "====================================================================================================\n",
      "Iteration:  1010\n",
      "Previous theta :  [-3.12726889e-03 -1.10567065e-01  1.40778292e-01 -1.64811788e-04\n",
      "  6.14828105e-02 -1.75581166e-01  2.60370034e-01  4.28074021e-02\n",
      " -3.36027657e-01  2.39723855e-01 -1.96553029e-01 -2.08662260e-01\n",
      "  9.83797501e-02 -4.70215193e-01]\n",
      "New theta_0 : [-3.12685461e-03 -1.10570057e-01  1.40782752e-01 -1.52979361e-04\n",
      "  6.14804550e-02 -1.75591470e-01  2.60367667e-01  4.28085258e-02\n",
      " -3.36033224e-01  2.39751951e-01 -1.96582010e-01 -2.08664979e-01\n",
      "  9.83803886e-02 -4.70214296e-01]\n",
      "Training Error:  10.297053795567159\n",
      "====================================================================================================\n",
      "Iteration:  1011\n",
      "Previous theta :  [-3.12685461e-03 -1.10570057e-01  1.40782752e-01 -1.52979361e-04\n",
      "  6.14804550e-02 -1.75591470e-01  2.60367667e-01  4.28085258e-02\n",
      " -3.36033224e-01  2.39751951e-01 -1.96582010e-01 -2.08664979e-01\n",
      "  9.83803886e-02 -4.70214296e-01]\n",
      "New theta_0 : [-3.12644153e-03 -1.10573037e-01  1.40787193e-01 -1.41175127e-04\n",
      "  6.14781071e-02 -1.75601715e-01  2.60365311e-01  4.28096458e-02\n",
      " -3.36038750e-01  2.39779962e-01 -1.96610919e-01 -2.08667685e-01\n",
      "  9.83810250e-02 -4.70213404e-01]\n",
      "Training Error:  10.297051946026846\n",
      "====================================================================================================\n",
      "Iteration:  1012\n",
      "Previous theta :  [-3.12644153e-03 -1.10573037e-01  1.40787193e-01 -1.41175127e-04\n",
      "  6.14781071e-02 -1.75601715e-01  2.60365311e-01  4.28096458e-02\n",
      " -3.36038750e-01  2.39779962e-01 -1.96610919e-01 -2.08667685e-01\n",
      "  9.83810250e-02 -4.70213404e-01]\n",
      "New theta_0 : [-3.12602964e-03 -1.10576003e-01  1.40791617e-01 -1.29399051e-04\n",
      "  6.14757669e-02 -1.75611903e-01  2.60362967e-01  4.28107620e-02\n",
      " -3.36044234e-01  2.39807890e-01 -1.96639755e-01 -2.08670378e-01\n",
      "  9.83816593e-02 -4.70212519e-01]\n",
      "Training Error:  10.297050107484575\n",
      "====================================================================================================\n",
      "Iteration:  1013\n",
      "Previous theta :  [-3.12602964e-03 -1.10576003e-01  1.40791617e-01 -1.29399051e-04\n",
      "  6.14757669e-02 -1.75611903e-01  2.60362967e-01  4.28107620e-02\n",
      " -3.36044234e-01  2.39807890e-01 -1.96639755e-01 -2.08670378e-01\n",
      "  9.83816593e-02 -4.70212519e-01]\n",
      "New theta_0 : [-3.12561893e-03 -1.10578957e-01  1.40796023e-01 -1.17651098e-04\n",
      "  6.14734344e-02 -1.75622034e-01  2.60360634e-01  4.28118745e-02\n",
      " -3.36049677e-01  2.39835734e-01 -1.96668519e-01 -2.08673058e-01\n",
      "  9.83822915e-02 -4.70211639e-01]\n",
      "Training Error:  10.297048279868493\n",
      "====================================================================================================\n",
      "Iteration:  1014\n",
      "Previous theta :  [-3.12561893e-03 -1.10578957e-01  1.40796023e-01 -1.17651098e-04\n",
      "  6.14734344e-02 -1.75622034e-01  2.60360634e-01  4.28118745e-02\n",
      " -3.36049677e-01  2.39835734e-01 -1.96668519e-01 -2.08673058e-01\n",
      "  9.83822915e-02 -4.70211639e-01]\n",
      "New theta_0 : [-3.12520940e-03 -1.10581898e-01  1.40800412e-01 -1.05931234e-04\n",
      "  6.14711094e-02 -1.75632108e-01  2.60358313e-01  4.28129834e-02\n",
      " -3.36055080e-01  2.39863495e-01 -1.96697211e-01 -2.08675725e-01\n",
      "  9.83829215e-02 -4.70210765e-01]\n",
      "Training Error:  10.297046463107304\n",
      "====================================================================================================\n",
      "Iteration:  1015\n",
      "Previous theta :  [-3.12520940e-03 -1.10581898e-01  1.40800412e-01 -1.05931234e-04\n",
      "  6.14711094e-02 -1.75632108e-01  2.60358313e-01  4.28129834e-02\n",
      " -3.36055080e-01  2.39863495e-01 -1.96697211e-01 -2.08675725e-01\n",
      "  9.83829215e-02 -4.70210765e-01]\n",
      "New theta_0 : [-3.12480105e-03 -1.10584826e-01  1.40804783e-01 -9.42394228e-05\n",
      "  6.14687920e-02 -1.75642127e-01  2.60356002e-01  4.28140885e-02\n",
      " -3.36060442e-01  2.39891174e-01 -1.96725832e-01 -2.08678378e-01\n",
      "  9.83835495e-02 -4.70209897e-01]\n",
      "Training Error:  10.297044657130261\n",
      "====================================================================================================\n",
      "Iteration:  1016\n",
      "Previous theta :  [-3.12480105e-03 -1.10584826e-01  1.40804783e-01 -9.42394228e-05\n",
      "  6.14687920e-02 -1.75642127e-01  2.60356002e-01  4.28140885e-02\n",
      " -3.36060442e-01  2.39891174e-01 -1.96725832e-01 -2.08678378e-01\n",
      "  9.83835495e-02 -4.70209897e-01]\n",
      "New theta_0 : [-3.12439387e-03 -1.10587741e-01  1.40809137e-01 -8.25756295e-05\n",
      "  6.14664821e-02 -1.75652089e-01  2.60353703e-01  4.28151900e-02\n",
      " -3.36065764e-01  2.39918769e-01 -1.96754380e-01 -2.08681019e-01\n",
      "  9.83841753e-02 -4.70209034e-01]\n",
      "Training Error:  10.297042861867164\n",
      "====================================================================================================\n",
      "Iteration:  1017\n",
      "Previous theta :  [-3.12439387e-03 -1.10587741e-01  1.40809137e-01 -8.25756295e-05\n",
      "  6.14664821e-02 -1.75652089e-01  2.60353703e-01  4.28151900e-02\n",
      " -3.36065764e-01  2.39918769e-01 -1.96754380e-01 -2.08681019e-01\n",
      "  9.83841753e-02 -4.70209034e-01]\n",
      "New theta_0 : [-3.12398786e-03 -1.10590644e-01  1.40813474e-01 -7.09398180e-05\n",
      "  6.14641797e-02 -1.75661995e-01  2.60351416e-01  4.28162879e-02\n",
      " -3.36071046e-01  2.39946283e-01 -1.96782858e-01 -2.08683647e-01\n",
      "  9.83847991e-02 -4.70208177e-01]\n",
      "Training Error:  10.297041077248343\n",
      "====================================================================================================\n",
      "Iteration:  1018\n",
      "Previous theta :  [-3.12398786e-03 -1.10590644e-01  1.40813474e-01 -7.09398180e-05\n",
      "  6.14641797e-02 -1.75661995e-01  2.60351416e-01  4.28162879e-02\n",
      " -3.36071046e-01  2.39946283e-01 -1.96782858e-01 -2.08683647e-01\n",
      "  9.83847991e-02 -4.70208177e-01]\n",
      "New theta_0 : [-3.12358302e-03 -1.10593535e-01  1.40817793e-01 -5.93319522e-05\n",
      "  6.14618848e-02 -1.75671847e-01  2.60349139e-01  4.28173822e-02\n",
      " -3.36076288e-01  2.39973714e-01 -1.96811263e-01 -2.08686262e-01\n",
      "  9.83854208e-02 -4.70207326e-01]\n",
      "Training Error:  10.297039303204679\n",
      "====================================================================================================\n",
      "Iteration:  1019\n",
      "Previous theta :  [-3.12358302e-03 -1.10593535e-01  1.40817793e-01 -5.93319522e-05\n",
      "  6.14618848e-02 -1.75671847e-01  2.60349139e-01  4.28173822e-02\n",
      " -3.36076288e-01  2.39973714e-01 -1.96811263e-01 -2.08686262e-01\n",
      "  9.83854208e-02 -4.70207326e-01]\n",
      "New theta_0 : [-3.12317933e-03 -1.10596413e-01  1.40822096e-01 -4.77519956e-05\n",
      "  6.14595973e-02 -1.75681643e-01  2.60346873e-01  4.28184728e-02\n",
      " -3.36081492e-01  2.40001063e-01 -1.96839598e-01 -2.08688864e-01\n",
      "  9.83860404e-02 -4.70206480e-01]\n",
      "Training Error:  10.297037539667565\n",
      "====================================================================================================\n",
      "Iteration:  1020\n",
      "Previous theta :  [-3.12317933e-03 -1.10596413e-01  1.40822096e-01 -4.77519956e-05\n",
      "  6.14595973e-02 -1.75681643e-01  2.60346873e-01  4.28184728e-02\n",
      " -3.36081492e-01  2.40001063e-01 -1.96839598e-01 -2.08688864e-01\n",
      "  9.83860404e-02 -4.70206480e-01]\n",
      "New theta_0 : [-3.12277681e-03 -1.10599279e-01  1.40826381e-01 -3.61999115e-05\n",
      "  6.14573173e-02 -1.75691385e-01  2.60344618e-01  4.28195598e-02\n",
      " -3.36086656e-01  2.40028331e-01 -1.96867861e-01 -2.08691454e-01\n",
      "  9.83866579e-02 -4.70205641e-01]\n",
      "Training Error:  10.297035786568935\n",
      "====================================================================================================\n",
      "Iteration:  1021\n",
      "Previous theta :  [-3.12277681e-03 -1.10599279e-01  1.40826381e-01 -3.61999115e-05\n",
      "  6.14573173e-02 -1.75691385e-01  2.60344618e-01  4.28195598e-02\n",
      " -3.36086656e-01  2.40028331e-01 -1.96867861e-01 -2.08691454e-01\n",
      "  9.83866579e-02 -4.70205641e-01]\n",
      "New theta_0 : [-3.12237544e-03 -1.10602132e-01  1.40830650e-01 -2.46756628e-05\n",
      "  6.14550446e-02 -1.75701073e-01  2.60342375e-01  4.28206433e-02\n",
      " -3.36091781e-01  2.40055518e-01 -1.96896054e-01 -2.08694031e-01\n",
      "  9.83872734e-02 -4.70204806e-01]\n",
      "Training Error:  10.297034043841228\n",
      "====================================================================================================\n",
      "Iteration:  1022\n",
      "Previous theta :  [-3.12237544e-03 -1.10602132e-01  1.40830650e-01 -2.46756628e-05\n",
      "  6.14550446e-02 -1.75701073e-01  2.60342375e-01  4.28206433e-02\n",
      " -3.36091781e-01  2.40055518e-01 -1.96896054e-01 -2.08694031e-01\n",
      "  9.83872734e-02 -4.70204806e-01]\n",
      "New theta_0 : [-3.12197522e-03 -1.10604973e-01  1.40834902e-01 -1.31792123e-05\n",
      "  6.14527793e-02 -1.75710707e-01  2.60340141e-01  4.28217232e-02\n",
      " -3.36096868e-01  2.40082624e-01 -1.96924175e-01 -2.08696595e-01\n",
      "  9.83878869e-02 -4.70203977e-01]\n",
      "Training Error:  10.297032311417405\n",
      "====================================================================================================\n",
      "Iteration:  1023\n",
      "Previous theta :  [-3.12197522e-03 -1.10604973e-01  1.40834902e-01 -1.31792123e-05\n",
      "  6.14527793e-02 -1.75710707e-01  2.60340141e-01  4.28217232e-02\n",
      " -3.36096868e-01  2.40082624e-01 -1.96924175e-01 -2.08696595e-01\n",
      "  9.83878869e-02 -4.70203977e-01]\n",
      "New theta_0 : [-3.12157615e-03 -1.10607802e-01  1.40839137e-01 -1.71052245e-06\n",
      "  6.14505214e-02 -1.75720287e-01  2.60337919e-01  4.28227995e-02\n",
      " -3.36101918e-01  2.40109649e-01 -1.96952226e-01 -2.08699147e-01\n",
      "  9.83884983e-02 -4.70203154e-01]\n",
      "Training Error:  10.297030589230936\n",
      "====================================================================================================\n",
      "Iteration:  1024\n",
      "Previous theta :  [-3.12157615e-03 -1.10607802e-01  1.40839137e-01 -1.71052245e-06\n",
      "  6.14505214e-02 -1.75720287e-01  2.60337919e-01  4.28227995e-02\n",
      " -3.36101918e-01  2.40109649e-01 -1.96952226e-01 -2.08699147e-01\n",
      "  9.83884983e-02 -4.70203154e-01]\n",
      "New theta_0 : [-3.12117822e-03 -1.10610619e-01  1.40843355e-01  9.73044459e-06\n",
      "  6.14482707e-02 -1.75729815e-01  2.60335707e-01  4.28238724e-02\n",
      " -3.36106929e-01  2.40136594e-01 -1.96980207e-01 -2.08701687e-01\n",
      "  9.83891077e-02 -4.70202336e-01]\n",
      "Training Error:  10.297028877215794\n",
      "====================================================================================================\n",
      "Iteration:  1025\n",
      "Previous theta :  [-3.12117822e-03 -1.10610619e-01  1.40843355e-01  9.73044459e-06\n",
      "  6.14482707e-02 -1.75729815e-01  2.60335707e-01  4.28238724e-02\n",
      " -3.36106929e-01  2.40136594e-01 -1.96980207e-01 -2.08701687e-01\n",
      "  9.83891077e-02 -4.70202336e-01]\n",
      "New theta_0 : [-3.12078144e-03 -1.10613424e-01  1.40847557e-01  2.11437269e-05\n",
      "  6.14460273e-02 -1.75739289e-01  2.60333506e-01  4.28249416e-02\n",
      " -3.36111903e-01  2.40163458e-01 -1.97008117e-01 -2.08704214e-01\n",
      "  9.83897150e-02 -4.70201523e-01]\n",
      "Training Error:  10.297027175306452\n",
      "====================================================================================================\n",
      "Iteration:  1026\n",
      "Previous theta :  [-3.12078144e-03 -1.10613424e-01  1.40847557e-01  2.11437269e-05\n",
      "  6.14460273e-02 -1.75739289e-01  2.60333506e-01  4.28249416e-02\n",
      " -3.36111903e-01  2.40163458e-01 -1.97008117e-01 -2.08704214e-01\n",
      "  9.83897150e-02 -4.70201523e-01]\n",
      "New theta_0 : [-3.12038578e-03 -1.10616217e-01  1.40851743e-01  3.25293629e-05\n",
      "  6.14437912e-02 -1.75748711e-01  2.60331316e-01  4.28260074e-02\n",
      " -3.36116839e-01  2.40190242e-01 -1.97035957e-01 -2.08706729e-01\n",
      "  9.83903203e-02 -4.70200716e-01]\n",
      "Training Error:  10.29702548343788\n",
      "====================================================================================================\n",
      "Iteration:  1027\n",
      "Previous theta :  [-3.12038578e-03 -1.10616217e-01  1.40851743e-01  3.25293629e-05\n",
      "  6.14437912e-02 -1.75748711e-01  2.60331316e-01  4.28260074e-02\n",
      " -3.36116839e-01  2.40190242e-01 -1.97035957e-01 -2.08706729e-01\n",
      "  9.83903203e-02 -4.70200716e-01]\n",
      "New theta_0 : [-3.11999126e-03 -1.10618999e-01  1.40855912e-01  4.38873910e-05\n",
      "  6.14415623e-02 -1.75758081e-01  2.60329136e-01  4.28270697e-02\n",
      " -3.36121739e-01  2.40216947e-01 -1.97063726e-01 -2.08709232e-01\n",
      "  9.83909237e-02 -4.70199915e-01]\n",
      "Training Error:  10.297023801545535\n",
      "====================================================================================================\n",
      "Iteration:  1028\n",
      "Previous theta :  [-3.11999126e-03 -1.10618999e-01  1.40855912e-01  4.38873910e-05\n",
      "  6.14415623e-02 -1.75758081e-01  2.60329136e-01  4.28270697e-02\n",
      " -3.36121739e-01  2.40216947e-01 -1.97063726e-01 -2.08709232e-01\n",
      "  9.83909237e-02 -4.70199915e-01]\n",
      "New theta_0 : [-3.11959787e-03 -1.10621768e-01  1.40860065e-01  5.52178502e-05\n",
      "  6.14393406e-02 -1.75767398e-01  2.60326966e-01  4.28281286e-02\n",
      " -3.36126601e-01  2.40243573e-01 -1.97091426e-01 -2.08711723e-01\n",
      "  9.83915250e-02 -4.70199118e-01]\n",
      "Training Error:  10.297022129565365\n",
      "====================================================================================================\n",
      "Iteration:  1029\n",
      "Previous theta :  [-3.11959787e-03 -1.10621768e-01  1.40860065e-01  5.52178502e-05\n",
      "  6.14393406e-02 -1.75767398e-01  2.60326966e-01  4.28281286e-02\n",
      " -3.36126601e-01  2.40243573e-01 -1.97091426e-01 -2.08711723e-01\n",
      "  9.83915250e-02 -4.70199118e-01]\n",
      "New theta_0 : [-3.11920560e-03 -1.10624525e-01  1.40864202e-01  6.65207796e-05\n",
      "  6.14371261e-02 -1.75776665e-01  2.60324806e-01  4.28291840e-02\n",
      " -3.36131428e-01  2.40270119e-01 -1.97119056e-01 -2.08714202e-01\n",
      "  9.83921243e-02 -4.70198327e-01]\n",
      "Training Error:  10.297020467433798\n",
      "====================================================================================================\n",
      "Iteration:  1030\n",
      "Previous theta :  [-3.11920560e-03 -1.10624525e-01  1.40864202e-01  6.65207796e-05\n",
      "  6.14371261e-02 -1.75776665e-01  2.60324806e-01  4.28291840e-02\n",
      " -3.36131428e-01  2.40270119e-01 -1.97119056e-01 -2.08714202e-01\n",
      "  9.83921243e-02 -4.70198327e-01]\n",
      "New theta_0 : [-3.11881446e-03 -1.10627271e-01  1.40868323e-01  7.77962185e-05\n",
      "  6.14349187e-02 -1.75785880e-01  2.60322657e-01  4.28302359e-02\n",
      " -3.36136218e-01  2.40296587e-01 -1.97146617e-01 -2.08716668e-01\n",
      "  9.83927216e-02 -4.70197541e-01]\n",
      "Training Error:  10.297018815087737\n",
      "====================================================================================================\n",
      "Iteration:  1031\n",
      "Previous theta :  [-3.11881446e-03 -1.10627271e-01  1.40868323e-01  7.77962185e-05\n",
      "  6.14349187e-02 -1.75785880e-01  2.60322657e-01  4.28302359e-02\n",
      " -3.36136218e-01  2.40296587e-01 -1.97146617e-01 -2.08716668e-01\n",
      "  9.83927216e-02 -4.70197541e-01]\n",
      "New theta_0 : [-3.11842443e-03 -1.10630005e-01  1.40872427e-01  8.90442065e-05\n",
      "  6.14327185e-02 -1.75795044e-01  2.60320518e-01  4.28312844e-02\n",
      " -3.36140973e-01  2.40322975e-01 -1.97174108e-01 -2.08719123e-01\n",
      "  9.83933169e-02 -4.70196761e-01]\n",
      "Training Error:  10.29701717246456\n",
      "====================================================================================================\n",
      "Iteration:  1032\n",
      "Previous theta :  [-3.11842443e-03 -1.10630005e-01  1.40872427e-01  8.90442065e-05\n",
      "  6.14327185e-02 -1.75795044e-01  2.60320518e-01  4.28312844e-02\n",
      " -3.36140973e-01  2.40322975e-01 -1.97174108e-01 -2.08719123e-01\n",
      "  9.83933169e-02 -4.70196761e-01]\n",
      "New theta_0 : [-3.11803552e-03 -1.10632728e-01  1.40876516e-01  1.00264783e-04\n",
      "  6.14305253e-02 -1.75804157e-01  2.60318389e-01  4.28323295e-02\n",
      " -3.36145691e-01  2.40349286e-01 -1.97201530e-01 -2.08721566e-01\n",
      "  9.83939102e-02 -4.70195986e-01]\n",
      "Training Error:  10.297015539502109\n",
      "====================================================================================================\n",
      "Iteration:  1033\n",
      "Previous theta :  [-3.11803552e-03 -1.10632728e-01  1.40876516e-01  1.00264783e-04\n",
      "  6.14305253e-02 -1.75804157e-01  2.60318389e-01  4.28323295e-02\n",
      " -3.36145691e-01  2.40349286e-01 -1.97201530e-01 -2.08721566e-01\n",
      "  9.83939102e-02 -4.70195986e-01]\n",
      "New theta_0 : [-3.11764772e-03 -1.10635439e-01  1.40880589e-01  1.11457989e-04\n",
      "  6.14283392e-02 -1.75813221e-01  2.60316271e-01  4.28333711e-02\n",
      " -3.36150375e-01  2.40375518e-01 -1.97228882e-01 -2.08723997e-01\n",
      "  9.83945016e-02 -4.70195215e-01]\n",
      "Training Error:  10.297013916138694\n",
      "====================================================================================================\n",
      "Iteration:  1034\n",
      "Previous theta :  [-3.11764772e-03 -1.10635439e-01  1.40880589e-01  1.11457989e-04\n",
      "  6.14283392e-02 -1.75813221e-01  2.60316271e-01  4.28333711e-02\n",
      " -3.36150375e-01  2.40375518e-01 -1.97228882e-01 -2.08723997e-01\n",
      "  9.83945016e-02 -4.70195215e-01]\n",
      "New theta_0 : [-3.11726102e-03 -1.10638138e-01  1.40884646e-01  1.22623864e-04\n",
      "  6.14261601e-02 -1.75822234e-01  2.60314162e-01  4.28344094e-02\n",
      " -3.36155023e-01  2.40401673e-01 -1.97256165e-01 -2.08726417e-01\n",
      "  9.83950910e-02 -4.70194450e-01]\n",
      "Training Error:  10.297012302313084\n",
      "====================================================================================================\n",
      "Iteration:  1035\n",
      "Previous theta :  [-3.11726102e-03 -1.10638138e-01  1.40884646e-01  1.22623864e-04\n",
      "  6.14261601e-02 -1.75822234e-01  2.60314162e-01  4.28344094e-02\n",
      " -3.36155023e-01  2.40401673e-01 -1.97256165e-01 -2.08726417e-01\n",
      "  9.83950910e-02 -4.70194450e-01]\n",
      "New theta_0 : [-3.11687543e-03 -1.10640827e-01  1.40888688e-01  1.33762449e-04\n",
      "  6.14239880e-02 -1.75831198e-01  2.60312063e-01  4.28354443e-02\n",
      " -3.36159637e-01  2.40427750e-01 -1.97283380e-01 -2.08728825e-01\n",
      "  9.83956785e-02 -4.70193691e-01]\n",
      "Training Error:  10.2970106979645\n",
      "====================================================================================================\n",
      "Iteration:  1036\n",
      "Previous theta :  [-3.11687543e-03 -1.10640827e-01  1.40888688e-01  1.33762449e-04\n",
      "  6.14239880e-02 -1.75831198e-01  2.60312063e-01  4.28354443e-02\n",
      " -3.36159637e-01  2.40427750e-01 -1.97283380e-01 -2.08728825e-01\n",
      "  9.83956785e-02 -4.70193691e-01]\n",
      "New theta_0 : [-3.11649094e-03 -1.10643503e-01  1.40892714e-01  1.44873784e-04\n",
      "  6.14218229e-02 -1.75840112e-01  2.60309974e-01  4.28364759e-02\n",
      " -3.36164216e-01  2.40453750e-01 -1.97310526e-01 -2.08731221e-01\n",
      "  9.83962640e-02 -4.70192936e-01]\n",
      "Training Error:  10.297009103032622\n",
      "====================================================================================================\n",
      "Iteration:  1037\n",
      "Previous theta :  [-3.11649094e-03 -1.10643503e-01  1.40892714e-01  1.44873784e-04\n",
      "  6.14218229e-02 -1.75840112e-01  2.60309974e-01  4.28364759e-02\n",
      " -3.36164216e-01  2.40453750e-01 -1.97310526e-01 -2.08731221e-01\n",
      "  9.83962640e-02 -4.70192936e-01]\n",
      "New theta_0 : [-3.11610755e-03 -1.10646169e-01  1.40896724e-01  1.55957910e-04\n",
      "  6.14196648e-02 -1.75848977e-01  2.60307895e-01  4.28375041e-02\n",
      " -3.36168761e-01  2.40479672e-01 -1.97337603e-01 -2.08733606e-01\n",
      "  9.83968475e-02 -4.70192186e-01]\n",
      "Training Error:  10.297007517457565\n",
      "====================================================================================================\n",
      "Iteration:  1038\n",
      "Previous theta :  [-3.11610755e-03 -1.10646169e-01  1.40896724e-01  1.55957910e-04\n",
      "  6.14196648e-02 -1.75848977e-01  2.60307895e-01  4.28375041e-02\n",
      " -3.36168761e-01  2.40479672e-01 -1.97337603e-01 -2.08733606e-01\n",
      "  9.83968475e-02 -4.70192186e-01]\n",
      "New theta_0 : [-3.11572525e-03 -1.10648823e-01  1.40900719e-01  1.67014869e-04\n",
      "  6.14175136e-02 -1.75857794e-01  2.60305825e-01  4.28385290e-02\n",
      " -3.36173272e-01  2.40505518e-01 -1.97364611e-01 -2.08735979e-01\n",
      "  9.83974291e-02 -4.70191441e-01]\n",
      "Training Error:  10.297005941179899\n",
      "====================================================================================================\n",
      "Iteration:  1039\n",
      "Previous theta :  [-3.11572525e-03 -1.10648823e-01  1.40900719e-01  1.67014869e-04\n",
      "  6.14175136e-02 -1.75857794e-01  2.60305825e-01  4.28385290e-02\n",
      " -3.36173272e-01  2.40505518e-01 -1.97364611e-01 -2.08735979e-01\n",
      "  9.83974291e-02 -4.70191441e-01]\n",
      "New theta_0 : [-3.11534404e-03 -1.10651467e-01  1.40904698e-01  1.78044702e-04\n",
      "  6.14153693e-02 -1.75866562e-01  2.60303766e-01  4.28395505e-02\n",
      " -3.36177749e-01  2.40531287e-01 -1.97391552e-01 -2.08738341e-01\n",
      "  9.83980088e-02 -4.70190702e-01]\n",
      "Training Error:  10.297004374140625\n",
      "====================================================================================================\n",
      "Iteration:  1040\n",
      "Previous theta :  [-3.11534404e-03 -1.10651467e-01  1.40904698e-01  1.78044702e-04\n",
      "  6.14153693e-02 -1.75866562e-01  2.60303766e-01  4.28395505e-02\n",
      " -3.36177749e-01  2.40531287e-01 -1.97391552e-01 -2.08738341e-01\n",
      "  9.83980088e-02 -4.70190702e-01]\n",
      "New theta_0 : [-3.11496391e-03 -1.10654099e-01  1.40908662e-01  1.89047450e-04\n",
      "  6.14132319e-02 -1.75875282e-01  2.60301716e-01  4.28405688e-02\n",
      " -3.36182192e-01  2.40556980e-01 -1.97418424e-01 -2.08740692e-01\n",
      "  9.83985866e-02 -4.70189967e-01]\n",
      "Training Error:  10.29700281628118\n",
      "====================================================================================================\n",
      "Iteration:  1041\n",
      "Previous theta :  [-3.11496391e-03 -1.10654099e-01  1.40908662e-01  1.89047450e-04\n",
      "  6.14132319e-02 -1.75875282e-01  2.60301716e-01  4.28405688e-02\n",
      " -3.36182192e-01  2.40556980e-01 -1.97418424e-01 -2.08740692e-01\n",
      "  9.83985866e-02 -4.70189967e-01]\n",
      "New theta_0 : [-3.11458487e-03 -1.10656720e-01  1.40912611e-01  2.00023155e-04\n",
      "  6.14111013e-02 -1.75883954e-01  2.60299675e-01  4.28415837e-02\n",
      " -3.36186602e-01  2.40582597e-01 -1.97445228e-01 -2.08743031e-01\n",
      "  9.83991624e-02 -4.70189237e-01]\n",
      "Training Error:  10.297001267543434\n",
      "====================================================================================================\n",
      "Iteration:  1042\n",
      "Previous theta :  [-3.11458487e-03 -1.10656720e-01  1.40912611e-01  2.00023155e-04\n",
      "  6.14111013e-02 -1.75883954e-01  2.60299675e-01  4.28415837e-02\n",
      " -3.36186602e-01  2.40582597e-01 -1.97445228e-01 -2.08743031e-01\n",
      "  9.83991624e-02 -4.70189237e-01]\n",
      "New theta_0 : [-3.11420691e-03 -1.10659330e-01  1.40916545e-01  2.10971860e-04\n",
      "  6.14089776e-02 -1.75892579e-01  2.60297644e-01  4.28425954e-02\n",
      " -3.36190980e-01  2.40608138e-01 -1.97471964e-01 -2.08745359e-01\n",
      "  9.83997363e-02 -4.70188513e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.296999727869684\n",
      "====================================================================================================\n",
      "Iteration:  1043\n",
      "Previous theta :  [-3.11420691e-03 -1.10659330e-01  1.40916545e-01  2.10971860e-04\n",
      "  6.14089776e-02 -1.75892579e-01  2.60297644e-01  4.28425954e-02\n",
      " -3.36190980e-01  2.40608138e-01 -1.97471964e-01 -2.08745359e-01\n",
      "  9.83997363e-02 -4.70188513e-01]\n",
      "New theta_0 : [-3.11383003e-03 -1.10661929e-01  1.40920464e-01  2.21893605e-04\n",
      "  6.14068606e-02 -1.75901157e-01  2.60295622e-01  4.28436038e-02\n",
      " -3.36195324e-01  2.40633604e-01 -1.97498633e-01 -2.08747676e-01\n",
      "  9.84003084e-02 -4.70187793e-01]\n",
      "Training Error:  10.296998197202647\n",
      "====================================================================================================\n",
      "Iteration:  1044\n",
      "Previous theta :  [-3.11383003e-03 -1.10661929e-01  1.40920464e-01  2.21893605e-04\n",
      "  6.14068606e-02 -1.75901157e-01  2.60295622e-01  4.28436038e-02\n",
      " -3.36195324e-01  2.40633604e-01 -1.97498633e-01 -2.08747676e-01\n",
      "  9.84003084e-02 -4.70187793e-01]\n",
      "New theta_0 : [-3.11345421e-03 -1.10664517e-01  1.40924368e-01  2.32788435e-04\n",
      "  6.14047505e-02 -1.75909687e-01  2.60293610e-01  4.28446090e-02\n",
      " -3.36199636e-01  2.40658994e-01 -1.97525234e-01 -2.08749982e-01\n",
      "  9.84008785e-02 -4.70187078e-01]\n",
      "Training Error:  10.296996675485461\n",
      "====================================================================================================\n",
      "Iteration:  1045\n",
      "Previous theta :  [-3.11345421e-03 -1.10664517e-01  1.40924368e-01  2.32788435e-04\n",
      "  6.14047505e-02 -1.75909687e-01  2.60293610e-01  4.28446090e-02\n",
      " -3.36199636e-01  2.40658994e-01 -1.97525234e-01 -2.08749982e-01\n",
      "  9.84008785e-02 -4.70187078e-01]\n",
      "New theta_0 : [-3.11307947e-03 -1.10667095e-01  1.40928257e-01  2.43656390e-04\n",
      "  6.14026470e-02 -1.75918171e-01  2.60291607e-01  4.28456109e-02\n",
      " -3.36203916e-01  2.40684309e-01 -1.97551767e-01 -2.08752277e-01\n",
      "  9.84014467e-02 -4.70186367e-01]\n",
      "Training Error:  10.296995162661682\n",
      "====================================================================================================\n",
      "Iteration:  1046\n",
      "Previous theta :  [-3.11307947e-03 -1.10667095e-01  1.40928257e-01  2.43656390e-04\n",
      "  6.14026470e-02 -1.75918171e-01  2.60291607e-01  4.28456109e-02\n",
      " -3.36203916e-01  2.40684309e-01 -1.97551767e-01 -2.08752277e-01\n",
      "  9.84014467e-02 -4.70186367e-01]\n",
      "New theta_0 : [-3.11270579e-03 -1.10669662e-01  1.40932131e-01  2.54497514e-04\n",
      "  6.14005504e-02 -1.75926609e-01  2.60289614e-01  4.28466096e-02\n",
      " -3.36208163e-01  2.40709549e-01 -1.97578233e-01 -2.08754561e-01\n",
      "  9.84020131e-02 -4.70185662e-01]\n",
      "Training Error:  10.296993658675273\n",
      "====================================================================================================\n",
      "Iteration:  1047\n",
      "Previous theta :  [-3.11270579e-03 -1.10669662e-01  1.40932131e-01  2.54497514e-04\n",
      "  6.14005504e-02 -1.75926609e-01  2.60289614e-01  4.28466096e-02\n",
      " -3.36208163e-01  2.40709549e-01 -1.97578233e-01 -2.08754561e-01\n",
      "  9.84020131e-02 -4.70185662e-01]\n",
      "New theta_0 : [-3.11233318e-03 -1.10672218e-01  1.40935990e-01  2.65311850e-04\n",
      "  6.13984604e-02 -1.75935000e-01  2.60287629e-01  4.28476051e-02\n",
      " -3.36212379e-01  2.40734715e-01 -1.97604632e-01 -2.08756834e-01\n",
      "  9.84025776e-02 -4.70184961e-01]\n",
      "Training Error:  10.296992163470609\n",
      "====================================================================================================\n",
      "Iteration:  1048\n",
      "Previous theta :  [-3.11233318e-03 -1.10672218e-01  1.40935990e-01  2.65311850e-04\n",
      "  6.13984604e-02 -1.75935000e-01  2.60287629e-01  4.28476051e-02\n",
      " -3.36212379e-01  2.40734715e-01 -1.97604632e-01 -2.08756834e-01\n",
      "  9.84025776e-02 -4.70184961e-01]\n",
      "New theta_0 : [-3.11196162e-03 -1.10674763e-01  1.40939835e-01  2.76099440e-04\n",
      "  6.13963771e-02 -1.75943346e-01  2.60285654e-01  4.28485974e-02\n",
      " -3.36216563e-01  2.40759806e-01 -1.97630964e-01 -2.08759096e-01\n",
      "  9.84031402e-02 -4.70184265e-01]\n",
      "Training Error:  10.296990676992465\n",
      "====================================================================================================\n",
      "Iteration:  1049\n",
      "Previous theta :  [-3.11196162e-03 -1.10674763e-01  1.40939835e-01  2.76099440e-04\n",
      "  6.13963771e-02 -1.75943346e-01  2.60285654e-01  4.28485974e-02\n",
      " -3.36216563e-01  2.40759806e-01 -1.97630964e-01 -2.08759096e-01\n",
      "  9.84031402e-02 -4.70184265e-01]\n",
      "New theta_0 : [-3.11159113e-03 -1.10677298e-01  1.40943665e-01  2.86860329e-04\n",
      "  6.13943004e-02 -1.75951646e-01  2.60283688e-01  4.28495865e-02\n",
      " -3.36220716e-01  2.40784823e-01 -1.97657229e-01 -2.08761348e-01\n",
      "  9.84037009e-02 -4.70183574e-01]\n",
      "Training Error:  10.296989199186019\n",
      "====================================================================================================\n",
      "Iteration:  1050\n",
      "Previous theta :  [-3.11159113e-03 -1.10677298e-01  1.40943665e-01  2.86860329e-04\n",
      "  6.13943004e-02 -1.75951646e-01  2.60283688e-01  4.28495865e-02\n",
      " -3.36220716e-01  2.40784823e-01 -1.97657229e-01 -2.08761348e-01\n",
      "  9.84037009e-02 -4.70183574e-01]\n",
      "New theta_0 : [-3.11122168e-03 -1.10679822e-01  1.40947480e-01  2.97594559e-04\n",
      "  6.13922304e-02 -1.75959901e-01  2.60281731e-01  4.28505724e-02\n",
      " -3.36224838e-01  2.40809766e-01 -1.97683427e-01 -2.08763588e-01\n",
      "  9.84042598e-02 -4.70182888e-01]\n",
      "Training Error:  10.296987729996848\n",
      "====================================================================================================\n",
      "Iteration:  1051\n",
      "Previous theta :  [-3.11122168e-03 -1.10679822e-01  1.40947480e-01  2.97594559e-04\n",
      "  6.13922304e-02 -1.75959901e-01  2.60281731e-01  4.28505724e-02\n",
      " -3.36224838e-01  2.40809766e-01 -1.97683427e-01 -2.08763588e-01\n",
      "  9.84042598e-02 -4.70182888e-01]\n",
      "New theta_0 : [-3.11085328e-03 -1.10682336e-01  1.40951281e-01  3.08302174e-04\n",
      "  6.13901669e-02 -1.75968111e-01  2.60279783e-01  4.28515551e-02\n",
      " -3.36228929e-01  2.40834636e-01 -1.97709559e-01 -2.08765818e-01\n",
      "  9.84048169e-02 -4.70182206e-01]\n",
      "Training Error:  10.296986269370924\n",
      "====================================================================================================\n",
      "Iteration:  1052\n",
      "Previous theta :  [-3.11085328e-03 -1.10682336e-01  1.40951281e-01  3.08302174e-04\n",
      "  6.13901669e-02 -1.75968111e-01  2.60279783e-01  4.28515551e-02\n",
      " -3.36228929e-01  2.40834636e-01 -1.97709559e-01 -2.08765818e-01\n",
      "  9.84048169e-02 -4.70182206e-01]\n",
      "New theta_0 : [-3.11048593e-03 -1.10684839e-01  1.40955068e-01  3.18983218e-04\n",
      "  6.13881101e-02 -1.75976277e-01  2.60277844e-01  4.28525348e-02\n",
      " -3.36232990e-01  2.40859432e-01 -1.97735624e-01 -2.08768038e-01\n",
      "  9.84053720e-02 -4.70181529e-01]\n",
      "Training Error:  10.2969848172546\n",
      "====================================================================================================\n",
      "Iteration:  1053\n",
      "Previous theta :  [-3.11048593e-03 -1.10684839e-01  1.40955068e-01  3.18983218e-04\n",
      "  6.13881101e-02 -1.75976277e-01  2.60277844e-01  4.28525348e-02\n",
      " -3.36232990e-01  2.40859432e-01 -1.97735624e-01 -2.08768038e-01\n",
      "  9.84053720e-02 -4.70181529e-01]\n",
      "New theta_0 : [-3.11011962e-03 -1.10687332e-01  1.40958840e-01  3.29637735e-04\n",
      "  6.13860598e-02 -1.75984398e-01  2.60275914e-01  4.28535112e-02\n",
      " -3.36237020e-01  2.40884155e-01 -1.97761623e-01 -2.08770247e-01\n",
      "  9.84059254e-02 -4.70180856e-01]\n",
      "Training Error:  10.296983373594625\n",
      "====================================================================================================\n",
      "Iteration:  1054\n",
      "Previous theta :  [-3.11011962e-03 -1.10687332e-01  1.40958840e-01  3.29637735e-04\n",
      "  6.13860598e-02 -1.75984398e-01  2.60275914e-01  4.28535112e-02\n",
      " -3.36237020e-01  2.40884155e-01 -1.97761623e-01 -2.08770247e-01\n",
      "  9.84059254e-02 -4.70180856e-01]\n",
      "New theta_0 : [-3.10975436e-03 -1.10689815e-01  1.40962598e-01  3.40265768e-04\n",
      "  6.13840160e-02 -1.75992475e-01  2.60273992e-01  4.28544846e-02\n",
      " -3.36241020e-01  2.40908806e-01 -1.97787556e-01 -2.08772445e-01\n",
      "  9.84064769e-02 -4.70180188e-01]\n",
      "Training Error:  10.296981938338128\n",
      "====================================================================================================\n",
      "Iteration:  1055\n",
      "Previous theta :  [-3.10975436e-03 -1.10689815e-01  1.40962598e-01  3.40265768e-04\n",
      "  6.13840160e-02 -1.75992475e-01  2.60273992e-01  4.28544846e-02\n",
      " -3.36241020e-01  2.40908806e-01 -1.97787556e-01 -2.08772445e-01\n",
      "  9.84064769e-02 -4.70180188e-01]\n",
      "New theta_0 : [-3.10939013e-03 -1.10692288e-01  1.40966342e-01  3.50867362e-04\n",
      "  6.13819787e-02 -1.76000508e-01  2.60272079e-01  4.28554548e-02\n",
      " -3.36244989e-01  2.40933383e-01 -1.97813423e-01 -2.08774633e-01\n",
      "  9.84070266e-02 -4.70179524e-01]\n",
      "Training Error:  10.296980511432613\n",
      "====================================================================================================\n",
      "Iteration:  1056\n",
      "Previous theta :  [-3.10939013e-03 -1.10692288e-01  1.40966342e-01  3.50867362e-04\n",
      "  6.13819787e-02 -1.76000508e-01  2.60272079e-01  4.28554548e-02\n",
      " -3.36244989e-01  2.40933383e-01 -1.97813423e-01 -2.08774633e-01\n",
      "  9.84070266e-02 -4.70179524e-01]\n",
      "New theta_0 : [-3.10902693e-03 -1.10694750e-01  1.40970072e-01  3.61442562e-04\n",
      "  6.13799479e-02 -1.76008497e-01  2.60270175e-01  4.28564220e-02\n",
      " -3.36248930e-01  2.40957888e-01 -1.97839224e-01 -2.08776811e-01\n",
      "  9.84075745e-02 -4.70178866e-01]\n",
      "Training Error:  10.296979092825971\n",
      "====================================================================================================\n",
      "Iteration:  1057\n",
      "Previous theta :  [-3.10902693e-03 -1.10694750e-01  1.40970072e-01  3.61442562e-04\n",
      "  6.13799479e-02 -1.76008497e-01  2.60270175e-01  4.28564220e-02\n",
      " -3.36248930e-01  2.40957888e-01 -1.97839224e-01 -2.08776811e-01\n",
      "  9.84075745e-02 -4.70178866e-01]\n",
      "New theta_0 : [-3.10866476e-03 -1.10697202e-01  1.40973787e-01  3.71991412e-04\n",
      "  6.13779236e-02 -1.76016444e-01  2.60268280e-01  4.28573860e-02\n",
      " -3.36252840e-01  2.40982321e-01 -1.97864959e-01 -2.08778978e-01\n",
      "  9.84081206e-02 -4.70178211e-01]\n",
      "Training Error:  10.296977682466455\n",
      "====================================================================================================\n",
      "Iteration:  1058\n",
      "Previous theta :  [-3.10866476e-03 -1.10697202e-01  1.40973787e-01  3.71991412e-04\n",
      "  6.13779236e-02 -1.76016444e-01  2.60268280e-01  4.28573860e-02\n",
      " -3.36252840e-01  2.40982321e-01 -1.97864959e-01 -2.08778978e-01\n",
      "  9.84081206e-02 -4.70178211e-01]\n",
      "New theta_0 : [-3.10830362e-03 -1.10699644e-01  1.40977489e-01  3.82513956e-04\n",
      "  6.13759057e-02 -1.76024347e-01  2.60266393e-01  4.28583470e-02\n",
      " -3.36256722e-01  2.41006682e-01 -1.97890629e-01 -2.08781135e-01\n",
      "  9.84086648e-02 -4.70177561e-01]\n",
      "Training Error:  10.296976280302697\n",
      "====================================================================================================\n",
      "Iteration:  1059\n",
      "Previous theta :  [-3.10830362e-03 -1.10699644e-01  1.40977489e-01  3.82513956e-04\n",
      "  6.13759057e-02 -1.76024347e-01  2.60266393e-01  4.28583470e-02\n",
      " -3.36256722e-01  2.41006682e-01 -1.97890629e-01 -2.08781135e-01\n",
      "  9.84086648e-02 -4.70177561e-01]\n",
      "New theta_0 : [-3.10794350e-03 -1.10702076e-01  1.40981177e-01  3.93010239e-04\n",
      "  6.13738942e-02 -1.76032207e-01  2.60264515e-01  4.28593049e-02\n",
      " -3.36260574e-01  2.41030971e-01 -1.97916233e-01 -2.08783282e-01\n",
      "  9.84092073e-02 -4.70176916e-01]\n",
      "Training Error:  10.296974886283689\n",
      "====================================================================================================\n",
      "Iteration:  1060\n",
      "Previous theta :  [-3.10794350e-03 -1.10702076e-01  1.40981177e-01  3.93010239e-04\n",
      "  6.13738942e-02 -1.76032207e-01  2.60264515e-01  4.28593049e-02\n",
      " -3.36260574e-01  2.41030971e-01 -1.97916233e-01 -2.08783282e-01\n",
      "  9.84092073e-02 -4.70176916e-01]\n",
      "New theta_0 : [-3.10758440e-03 -1.10704498e-01  1.40984851e-01  4.03480307e-04\n",
      "  6.13718891e-02 -1.76040025e-01  2.60262646e-01  4.28602598e-02\n",
      " -3.36264398e-01  2.41055189e-01 -1.97941772e-01 -2.08785419e-01\n",
      "  9.84097480e-02 -4.70176274e-01]\n",
      "Training Error:  10.296973500358789\n",
      "====================================================================================================\n",
      "Iteration:  1061\n",
      "Previous theta :  [-3.10758440e-03 -1.10704498e-01  1.40984851e-01  4.03480307e-04\n",
      "  6.13718891e-02 -1.76040025e-01  2.60262646e-01  4.28602598e-02\n",
      " -3.36264398e-01  2.41055189e-01 -1.97941772e-01 -2.08785419e-01\n",
      "  9.84097480e-02 -4.70176274e-01]\n",
      "New theta_0 : [-3.10722632e-03 -1.10706910e-01  1.40988511e-01  4.13924205e-04\n",
      "  6.13698903e-02 -1.76047801e-01  2.60260785e-01  4.28612116e-02\n",
      " -3.36268193e-01  2.41079335e-01 -1.97967246e-01 -2.08787545e-01\n",
      "  9.84102869e-02 -4.70175638e-01]\n",
      "Training Error:  10.296972122477714\n",
      "====================================================================================================\n",
      "Iteration:  1062\n",
      "Previous theta :  [-3.10722632e-03 -1.10706910e-01  1.40988511e-01  4.13924205e-04\n",
      "  6.13698903e-02 -1.76047801e-01  2.60260785e-01  4.28612116e-02\n",
      " -3.36268193e-01  2.41079335e-01 -1.97967246e-01 -2.08787545e-01\n",
      "  9.84102869e-02 -4.70175638e-01]\n",
      "New theta_0 : [-3.10686926e-03 -1.10709313e-01  1.40992158e-01  4.24341977e-04\n",
      "  6.13678979e-02 -1.76055535e-01  2.60258932e-01  4.28621604e-02\n",
      " -3.36271959e-01  2.41103410e-01 -1.97992654e-01 -2.08789662e-01\n",
      "  9.84108240e-02 -4.70175005e-01]\n",
      "Training Error:  10.29697075259054\n",
      "====================================================================================================\n",
      "Iteration:  1063\n",
      "Previous theta :  [-3.10686926e-03 -1.10709313e-01  1.40992158e-01  4.24341977e-04\n",
      "  6.13678979e-02 -1.76055535e-01  2.60258932e-01  4.28621604e-02\n",
      " -3.36271959e-01  2.41103410e-01 -1.97992654e-01 -2.08789662e-01\n",
      "  9.84108240e-02 -4.70175005e-01]\n",
      "New theta_0 : [-3.10651320e-03 -1.10711705e-01  1.40995791e-01  4.34733669e-04\n",
      "  6.13659118e-02 -1.76063227e-01  2.60257087e-01  4.28631062e-02\n",
      " -3.36275698e-01  2.41127415e-01 -1.98017998e-01 -2.08791769e-01\n",
      "  9.84113593e-02 -4.70174377e-01]\n",
      "Training Error:  10.296969390647694\n",
      "====================================================================================================\n",
      "Iteration:  1064\n",
      "Previous theta :  [-3.10651320e-03 -1.10711705e-01  1.40995791e-01  4.34733669e-04\n",
      "  6.13659118e-02 -1.76063227e-01  2.60257087e-01  4.28631062e-02\n",
      " -3.36275698e-01  2.41127415e-01 -1.98017998e-01 -2.08791769e-01\n",
      "  9.84113593e-02 -4.70174377e-01]\n",
      "New theta_0 : [-3.10615815e-03 -1.10714088e-01  1.40999410e-01  4.45099327e-04\n",
      "  6.13639320e-02 -1.76070878e-01  2.60255251e-01  4.28640490e-02\n",
      " -3.36279408e-01  2.41151348e-01 -1.98043277e-01 -2.08793865e-01\n",
      "  9.84118929e-02 -4.70173753e-01]\n",
      "Training Error:  10.29696803659996\n",
      "====================================================================================================\n",
      "Iteration:  1065\n",
      "Previous theta :  [-3.10615815e-03 -1.10714088e-01  1.40999410e-01  4.45099327e-04\n",
      "  6.13639320e-02 -1.76070878e-01  2.60255251e-01  4.28640490e-02\n",
      " -3.36279408e-01  2.41151348e-01 -1.98043277e-01 -2.08793865e-01\n",
      "  9.84118929e-02 -4.70173753e-01]\n",
      "New theta_0 : [-3.10580411e-03 -1.10716460e-01  1.41003016e-01  4.55438996e-04\n",
      "  6.13619585e-02 -1.76078487e-01  2.60253423e-01  4.28649888e-02\n",
      " -3.36283091e-01  2.41175212e-01 -1.98068492e-01 -2.08795952e-01\n",
      "  9.84124247e-02 -4.70173134e-01]\n",
      "Training Error:  10.296966690398465\n",
      "====================================================================================================\n",
      "Iteration:  1066\n",
      "Previous theta :  [-3.10580411e-03 -1.10716460e-01  1.41003016e-01  4.55438996e-04\n",
      "  6.13619585e-02 -1.76078487e-01  2.60253423e-01  4.28649888e-02\n",
      " -3.36283091e-01  2.41175212e-01 -1.98068492e-01 -2.08795952e-01\n",
      "  9.84124247e-02 -4.70173134e-01]\n",
      "New theta_0 : [-3.10545107e-03 -1.10718824e-01  1.41006608e-01  4.65752721e-04\n",
      "  6.13599912e-02 -1.76086056e-01  2.60251604e-01  4.28659257e-02\n",
      " -3.36286746e-01  2.41199005e-01 -1.98093642e-01 -2.08798029e-01\n",
      "  9.84129547e-02 -4.70172519e-01]\n",
      "Training Error:  10.296965351994677\n",
      "====================================================================================================\n",
      "Iteration:  1067\n",
      "Previous theta :  [-3.10545107e-03 -1.10718824e-01  1.41006608e-01  4.65752721e-04\n",
      "  6.13599912e-02 -1.76086056e-01  2.60251604e-01  4.28659257e-02\n",
      " -3.36286746e-01  2.41199005e-01 -1.98093642e-01 -2.08798029e-01\n",
      "  9.84129547e-02 -4.70172519e-01]\n",
      "New theta_0 : [-0.0031051  -0.11072118  0.14101019  0.00047604  0.06135803 -0.17609358\n",
      "  0.26024979  0.04286686 -0.33629037  0.24122273 -0.19811873 -0.2088001\n",
      "  0.09841348 -0.47017191]\n",
      "Training Error:  10.296964021340413\n",
      "====================================================================================================\n",
      "Iteration:  1068\n",
      "Previous theta :  [-0.0031051  -0.11072118  0.14101019  0.00047604  0.06135803 -0.17609358\n",
      "  0.26024979  0.04286686 -0.33629037  0.24122273 -0.19811873 -0.2088001\n",
      "  0.09841348 -0.47017191]\n",
      "New theta_0 : [-0.00310475 -0.11072352  0.14101375  0.0004863   0.06135608 -0.17610107\n",
      "  0.26024799  0.04286779 -0.33629397  0.24124638 -0.19814375 -0.20880215\n",
      "  0.09841401 -0.4701713 ]\n",
      "Training Error:  10.296962698387826\n",
      "====================================================================================================\n",
      "Iteration:  1069\n",
      "Previous theta :  [-0.00310475 -0.11072352  0.14101375  0.0004863   0.06135608 -0.17610107\n",
      "  0.26024799  0.04286779 -0.33629397  0.24124638 -0.19814375 -0.20880215\n",
      "  0.09841401 -0.4701713 ]\n",
      "New theta_0 : [-0.0031044  -0.11072586  0.14101731  0.00049654  0.06135413 -0.17610852\n",
      "  0.26024619  0.04286872 -0.33629755  0.24126997 -0.19816871 -0.2088042\n",
      "  0.09841453 -0.4701707 ]\n",
      "Training Error:  10.296961383089407\n",
      "====================================================================================================\n",
      "Iteration:  1070\n",
      "Previous theta :  [-0.0031044  -0.11072586  0.14101731  0.00049654  0.06135413 -0.17610852\n",
      "  0.26024619  0.04286872 -0.33629755  0.24126997 -0.19816871 -0.2088042\n",
      "  0.09841453 -0.4701707 ]\n",
      "New theta_0 : [-0.00310405 -0.11072818  0.14102085  0.00050675  0.06135218 -0.17611593\n",
      "  0.26024441  0.04286964 -0.33630109  0.24129348 -0.1981936  -0.20880624\n",
      "  0.09841506 -0.4701701 ]\n",
      "Training Error:  10.296960075397976\n",
      "====================================================================================================\n",
      "Iteration:  1071\n",
      "Previous theta :  [-0.00310405 -0.11072818  0.14102085  0.00050675  0.06135218 -0.17611593\n",
      "  0.26024441  0.04286964 -0.33630109  0.24129348 -0.1981936  -0.20880624\n",
      "  0.09841506 -0.4701701 ]\n",
      "New theta_0 : [-0.0031037  -0.1107305   0.14102437  0.00051693  0.06135025 -0.17612329\n",
      "  0.26024263  0.04287057 -0.33630462  0.24131693 -0.19821843 -0.20880827\n",
      "  0.09841558 -0.47016951]\n",
      "Training Error:  10.296958775266686\n",
      "====================================================================================================\n",
      "Iteration:  1072\n",
      "Previous theta :  [-0.0031037  -0.1107305   0.14102437  0.00051693  0.06135025 -0.17612329\n",
      "  0.26024263  0.04287057 -0.33630462  0.24131693 -0.19821843 -0.20880827\n",
      "  0.09841558 -0.47016951]\n",
      "New theta_0 : [-0.00310335 -0.1107328   0.14102788  0.00052709  0.06134832 -0.17613062\n",
      "  0.26024085  0.04287148 -0.33630811  0.2413403  -0.1982432  -0.20881029\n",
      "  0.0984161  -0.47016892]\n",
      "Training Error:  10.296957482649017\n",
      "====================================================================================================\n",
      "Iteration:  1073\n",
      "Previous theta :  [-0.00310335 -0.1107328   0.14102788  0.00052709  0.06134832 -0.17613062\n",
      "  0.26024085  0.04287148 -0.33630811  0.2413403  -0.1982432  -0.20881029\n",
      "  0.0984161  -0.47016892]\n",
      "New theta_0 : [-0.00310301 -0.1107351   0.14103139  0.00053723  0.06134639 -0.17613791\n",
      "  0.26023909  0.0428724  -0.33631158  0.24136361 -0.1982679  -0.2088123\n",
      "  0.09841662 -0.47016833]\n",
      "Training Error:  10.296956197498774\n",
      "====================================================================================================\n",
      "Iteration:  1074\n",
      "Previous theta :  [-0.00310301 -0.1107351   0.14103139  0.00053723  0.06134639 -0.17613791\n",
      "  0.26023909  0.0428724  -0.33631158  0.24136361 -0.1982679  -0.2088123\n",
      "  0.09841662 -0.47016833]\n",
      "New theta_0 : [-0.00310266 -0.11073739  0.14103487  0.00054733  0.06134448 -0.17614516\n",
      "  0.26023734  0.04287331 -0.33631502  0.24138685 -0.19829254 -0.2088143\n",
      "  0.09841713 -0.47016775]\n",
      "Training Error:  10.296954919770082\n",
      "====================================================================================================\n",
      "Iteration:  1075\n",
      "Previous theta :  [-0.00310266 -0.11073739  0.14103487  0.00054733  0.06134448 -0.17614516\n",
      "  0.26023734  0.04287331 -0.33631502  0.24138685 -0.19829254 -0.2088143\n",
      "  0.09841713 -0.47016775]\n",
      "New theta_0 : [-0.00310232 -0.11073966  0.14103835  0.00055742  0.06134256 -0.17615237\n",
      "  0.26023559  0.04287422 -0.33631844  0.24141003 -0.19831712 -0.20881629\n",
      "  0.09841765 -0.47016717]\n",
      "Training Error:  10.29695364941739\n",
      "====================================================================================================\n",
      "Iteration:  1076\n",
      "Previous theta :  [-0.00310232 -0.11073966  0.14103835  0.00055742  0.06134256 -0.17615237\n",
      "  0.26023559  0.04287422 -0.33631844  0.24141003 -0.19831712 -0.20881629\n",
      "  0.09841765 -0.47016717]\n",
      "New theta_0 : [-0.00310198 -0.11074193  0.14104181  0.00056747  0.06134066 -0.17615954\n",
      "  0.26023385  0.04287513 -0.33632183  0.24143313 -0.19834163 -0.20881827\n",
      "  0.09841816 -0.4701666 ]\n",
      "Training Error:  10.296952386395457\n",
      "====================================================================================================\n",
      "Iteration:  1077\n",
      "Previous theta :  [-0.00310198 -0.11074193  0.14104181  0.00056747  0.06134066 -0.17615954\n",
      "  0.26023385  0.04287513 -0.33632183  0.24143313 -0.19834163 -0.20881827\n",
      "  0.09841816 -0.4701666 ]\n",
      "New theta_0 : [-0.00310163 -0.11074419  0.14104526  0.0005775   0.06133876 -0.17616668\n",
      "  0.26023211  0.04287604 -0.33632519  0.24145617 -0.19836608 -0.20882024\n",
      "  0.09841867 -0.47016603]\n",
      "Training Error:  10.296951130659359\n",
      "====================================================================================================\n",
      "Iteration:  1078\n",
      "Previous theta :  [-0.00310163 -0.11074419  0.14104526  0.0005775   0.06133876 -0.17616668\n",
      "  0.26023211  0.04287604 -0.33632519  0.24145617 -0.19836608 -0.20882024\n",
      "  0.09841867 -0.47016603]\n",
      "New theta_0 : [-0.00310129 -0.11074644  0.14104869  0.00058751  0.06133686 -0.17617377\n",
      "  0.26023039  0.04287694 -0.33632853  0.24147913 -0.19839047 -0.20882221\n",
      "  0.09841918 -0.47016546]\n",
      "Training Error:  10.296949882164485\n",
      "====================================================================================================\n",
      "Iteration:  1079\n",
      "Previous theta :  [-0.00310129 -0.11074644  0.14104869  0.00058751  0.06133686 -0.17617377\n",
      "  0.26023039  0.04287694 -0.33632853  0.24147913 -0.19839047 -0.20882221\n",
      "  0.09841918 -0.47016546]\n",
      "New theta_0 : [-0.00310095 -0.11074869  0.14105212  0.00059749  0.06133497 -0.17618083\n",
      "  0.26022867  0.04287784 -0.33633185  0.24150204 -0.19841479 -0.20882416\n",
      "  0.09841969 -0.4701649 ]\n",
      "Training Error:  10.29694864086653\n",
      "====================================================================================================\n",
      "Iteration:  1080\n",
      "Previous theta :  [-0.00310095 -0.11074869  0.14105212  0.00059749  0.06133497 -0.17618083\n",
      "  0.26022867  0.04287784 -0.33633185  0.24150204 -0.19841479 -0.20882416\n",
      "  0.09841969 -0.4701649 ]\n",
      "New theta_0 : [-0.00310061 -0.11075092  0.14105553  0.00060745  0.06133309 -0.17618785\n",
      "  0.26022696  0.04287873 -0.33633514  0.24152487 -0.19843906 -0.20882611\n",
      "  0.09842019 -0.47016434]\n",
      "Training Error:  10.296947406721495\n",
      "====================================================================================================\n",
      "Iteration:  1081\n",
      "Previous theta :  [-0.00310061 -0.11075092  0.14105553  0.00060745  0.06133309 -0.17618785\n",
      "  0.26022696  0.04287873 -0.33633514  0.24152487 -0.19843906 -0.20882611\n",
      "  0.09842019 -0.47016434]\n",
      "New theta_0 : [-0.00310027 -0.11075314  0.14105893  0.00061738  0.06133122 -0.17619484\n",
      "  0.26022526  0.04287963 -0.3363384   0.24154764 -0.19846326 -0.20882804\n",
      "  0.0984207  -0.47016378]\n",
      "Training Error:  10.296946179685683\n",
      "====================================================================================================\n",
      "Iteration:  1082\n",
      "Previous theta :  [-0.00310027 -0.11075314  0.14105893  0.00061738  0.06133122 -0.17619484\n",
      "  0.26022526  0.04287963 -0.3363384   0.24154764 -0.19846326 -0.20882804\n",
      "  0.0984207  -0.47016378]\n",
      "New theta_0 : [-0.00309994 -0.11075536  0.14106231  0.00062728  0.06132935 -0.17620178\n",
      "  0.26022356  0.04288052 -0.33634164  0.24157034 -0.19848739 -0.20882997\n",
      "  0.0984212  -0.47016323]\n",
      "Training Error:  10.296944959715702\n",
      "====================================================================================================\n",
      "Iteration:  1083\n",
      "Previous theta :  [-0.00309994 -0.11075536  0.14106231  0.00062728  0.06132935 -0.17620178\n",
      "  0.26022356  0.04288052 -0.33634164  0.24157034 -0.19848739 -0.20882997\n",
      "  0.0984212  -0.47016323]\n",
      "New theta_0 : [-0.0030996  -0.11075756  0.14106569  0.00063716  0.06132748 -0.17620869\n",
      "  0.26022188  0.04288141 -0.33634486  0.24159297 -0.19851147 -0.20883189\n",
      "  0.0984217  -0.47016269]\n",
      "Training Error:  10.296943746768456\n",
      "====================================================================================================\n",
      "Iteration:  1084\n",
      "Previous theta :  [-0.0030996  -0.11075756  0.14106569  0.00063716  0.06132748 -0.17620869\n",
      "  0.26022188  0.04288141 -0.33634486  0.24159297 -0.19851147 -0.20883189\n",
      "  0.0984217  -0.47016269]\n",
      "New theta_0 : [-0.00309926 -0.11075976  0.14106905  0.00064702  0.06132562 -0.17621557\n",
      "  0.2602202   0.04288229 -0.33634805  0.24161554 -0.19853548 -0.2088338\n",
      "  0.0984222  -0.47016214]\n",
      "Training Error:  10.296942540801144\n",
      "====================================================================================================\n",
      "Iteration:  1085\n",
      "Previous theta :  [-0.00309926 -0.11075976  0.14106905  0.00064702  0.06132562 -0.17621557\n",
      "  0.2602202   0.04288229 -0.33634805  0.24161554 -0.19853548 -0.2088338\n",
      "  0.0984222  -0.47016214]\n",
      "New theta_0 : [-0.00309893 -0.11076195  0.1410724   0.00065685  0.06132377 -0.1762224\n",
      "  0.26021852  0.04288317 -0.33635122  0.24163804 -0.19855944 -0.2088357\n",
      "  0.0984227  -0.47016161]\n",
      "Training Error:  10.29694134177126\n",
      "====================================================================================================\n",
      "Iteration:  1086\n",
      "Previous theta :  [-0.00309893 -0.11076195  0.1410724   0.00065685  0.06132377 -0.1762224\n",
      "  0.26021852  0.04288317 -0.33635122  0.24163804 -0.19855944 -0.2088357\n",
      "  0.0984227  -0.47016161]\n",
      "New theta_0 : [-0.0030986  -0.11076413  0.14107574  0.00066665  0.06132192 -0.1762292\n",
      "  0.26021686  0.04288405 -0.33635437  0.24166048 -0.19858333 -0.20883759\n",
      "  0.0984232  -0.47016107]\n",
      "Training Error:  10.296940149636587\n",
      "====================================================================================================\n",
      "Iteration:  1087\n",
      "Previous theta :  [-0.0030986  -0.11076413  0.14107574  0.00066665  0.06132192 -0.1762292\n",
      "  0.26021686  0.04288405 -0.33635437  0.24166048 -0.19858333 -0.20883759\n",
      "  0.0984232  -0.47016107]\n",
      "New theta_0 : [-0.00309826 -0.1107663   0.14107906  0.00067643  0.06132008 -0.17623597\n",
      "  0.2602152   0.04288493 -0.33635749  0.24168285 -0.19860716 -0.20883947\n",
      "  0.09842369 -0.47016054]\n",
      "Training Error:  10.296938964355197\n",
      "====================================================================================================\n",
      "Iteration:  1088\n",
      "Previous theta :  [-0.00309826 -0.1107663   0.14107906  0.00067643  0.06132008 -0.17623597\n",
      "  0.2602152   0.04288493 -0.33635749  0.24168285 -0.19860716 -0.20883947\n",
      "  0.09842369 -0.47016054]\n",
      "New theta_0 : [-0.00309793 -0.11076846  0.14108237  0.00068619  0.06131825 -0.1762427\n",
      "  0.26021355  0.0428858  -0.33636059  0.24170516 -0.19863092 -0.20884135\n",
      "  0.09842418 -0.47016001]\n",
      "Training Error:  10.29693778588545\n",
      "====================================================================================================\n",
      "Iteration:  1089\n",
      "Previous theta :  [-0.00309793 -0.11076846  0.14108237  0.00068619  0.06131825 -0.1762427\n",
      "  0.26021355  0.0428858  -0.33636059  0.24170516 -0.19863092 -0.20884135\n",
      "  0.09842418 -0.47016001]\n",
      "New theta_0 : [-0.0030976  -0.11077061  0.14108567  0.00069591  0.06131642 -0.17624939\n",
      "  0.2602119   0.04288668 -0.33636366  0.2417274  -0.19865463 -0.20884321\n",
      "  0.09842468 -0.47015949]\n",
      "Training Error:  10.29693661418599\n",
      "====================================================================================================\n",
      "Iteration:  1090\n",
      "Previous theta :  [-0.0030976  -0.11077061  0.14108567  0.00069591  0.06131642 -0.17624939\n",
      "  0.2602119   0.04288668 -0.33636366  0.2417274  -0.19865463 -0.20884321\n",
      "  0.09842468 -0.47015949]\n",
      "New theta_0 : [-0.00309727 -0.11077276  0.14108896  0.00070562  0.06131459 -0.17625605\n",
      "  0.26021027  0.04288754 -0.33636672  0.24174957 -0.19867828 -0.20884507\n",
      "  0.09842517 -0.47015897]\n",
      "Training Error:  10.296935449215738\n",
      "====================================================================================================\n",
      "Iteration:  1091\n",
      "Previous theta :  [-0.00309727 -0.11077276  0.14108896  0.00070562  0.06131459 -0.17625605\n",
      "  0.26021027  0.04288754 -0.33636672  0.24174957 -0.19867828 -0.20884507\n",
      "  0.09842517 -0.47015897]\n",
      "New theta_0 : [-0.00309694 -0.1107749   0.14109224  0.0007153   0.06131277 -0.17626267\n",
      "  0.26020864  0.04288841 -0.33636974  0.24177168 -0.19870186 -0.20884692\n",
      "  0.09842565 -0.47015845]\n",
      "Training Error:  10.296934290933896\n",
      "====================================================================================================\n",
      "Iteration:  1092\n",
      "Previous theta :  [-0.00309694 -0.1107749   0.14109224  0.0007153   0.06131277 -0.17626267\n",
      "  0.26020864  0.04288841 -0.33636974  0.24177168 -0.19870186 -0.20884692\n",
      "  0.09842565 -0.47015845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [-0.00309661 -0.11077702  0.14109551  0.00072496  0.06131096 -0.17626926\n",
      "  0.26020701  0.04288927 -0.33637275  0.24179373 -0.19872539 -0.20884876\n",
      "  0.09842614 -0.47015794]\n",
      "Training Error:  10.296933139299949\n",
      "====================================================================================================\n",
      "Iteration:  1093\n",
      "Previous theta :  [-0.00309661 -0.11077702  0.14109551  0.00072496  0.06131096 -0.17626926\n",
      "  0.26020701  0.04288927 -0.33637275  0.24179373 -0.19872539 -0.20884876\n",
      "  0.09842614 -0.47015794]\n",
      "New theta_0 : [-0.00309629 -0.11077914  0.14109876  0.00073459  0.06130915 -0.17627581\n",
      "  0.2602054   0.04289013 -0.33637574  0.24181571 -0.19874885 -0.20885059\n",
      "  0.09842662 -0.47015743]\n",
      "Training Error:  10.296931994273647\n",
      "====================================================================================================\n",
      "Iteration:  1094\n",
      "Previous theta :  [-0.00309629 -0.11077914  0.14109876  0.00073459  0.06130915 -0.17627581\n",
      "  0.2602054   0.04289013 -0.33637574  0.24181571 -0.19874885 -0.20885059\n",
      "  0.09842662 -0.47015743]\n",
      "New theta_0 : [-0.00309596 -0.11078126  0.141102    0.00074419  0.06130735 -0.17628233\n",
      "  0.26020379  0.04289099 -0.3363787   0.24183763 -0.19877225 -0.20885241\n",
      "  0.09842711 -0.47015692]\n",
      "Training Error:  10.296930855815019\n",
      "====================================================================================================\n",
      "Iteration:  1095\n",
      "Previous theta :  [-0.00309596 -0.11078126  0.141102    0.00074419  0.06130735 -0.17628233\n",
      "  0.26020379  0.04289099 -0.3363787   0.24183763 -0.19877225 -0.20885241\n",
      "  0.09842711 -0.47015692]\n",
      "New theta_0 : [-0.00309564 -0.11078336  0.14110523  0.00075378  0.06130556 -0.17628881\n",
      "  0.26020219  0.04289185 -0.33638164  0.24185948 -0.19879559 -0.20885423\n",
      "  0.09842759 -0.47015642]\n",
      "Training Error:  10.296929723884361\n",
      "====================================================================================================\n",
      "Iteration:  1096\n",
      "Previous theta :  [-0.00309564 -0.11078336  0.14110523  0.00075378  0.06130556 -0.17628881\n",
      "  0.26020219  0.04289185 -0.33638164  0.24185948 -0.19879559 -0.20885423\n",
      "  0.09842759 -0.47015642]\n",
      "New theta_0 : [-0.00309531 -0.11078545  0.14110845  0.00076333  0.06130377 -0.17629526\n",
      "  0.26020059  0.0428927  -0.33638456  0.24188127 -0.19881888 -0.20885603\n",
      "  0.09842807 -0.47015592]\n",
      "Training Error:  10.296928598442237\n",
      "====================================================================================================\n",
      "Iteration:  1097\n",
      "Previous theta :  [-0.00309531 -0.11078545  0.14110845  0.00076333  0.06130377 -0.17629526\n",
      "  0.26020059  0.0428927  -0.33638456  0.24188127 -0.19881888 -0.20885603\n",
      "  0.09842807 -0.47015592]\n",
      "New theta_0 : [-0.00309499 -0.11078754  0.14111166  0.00077287  0.06130198 -0.17630168\n",
      "  0.260199    0.04289355 -0.33638745  0.241903   -0.1988421  -0.20885783\n",
      "  0.09842855 -0.47015542]\n",
      "Training Error:  10.29692747944948\n",
      "====================================================================================================\n",
      "Iteration:  1098\n",
      "Previous theta :  [-0.00309499 -0.11078754  0.14111166  0.00077287  0.06130198 -0.17630168\n",
      "  0.260199    0.04289355 -0.33638745  0.241903   -0.1988421  -0.20885783\n",
      "  0.09842855 -0.47015542]\n",
      "New theta_0 : [-0.00309466 -0.11078962  0.14111485  0.00078237  0.0613002  -0.17630806\n",
      "  0.26019742  0.0428944  -0.33639033  0.24192466 -0.19886526 -0.20885962\n",
      "  0.09842903 -0.47015493]\n",
      "Training Error:  10.296926366867183\n",
      "====================================================================================================\n",
      "Iteration:  1099\n",
      "Previous theta :  [-0.00309466 -0.11078962  0.14111485  0.00078237  0.0613002  -0.17630806\n",
      "  0.26019742  0.0428944  -0.33639033  0.24192466 -0.19886526 -0.20885962\n",
      "  0.09842903 -0.47015493]\n",
      "New theta_0 : [-0.00309434 -0.11079169  0.14111804  0.00079186  0.06129843 -0.17631441\n",
      "  0.26019585  0.04289524 -0.33639318  0.24194626 -0.19888836 -0.2088614\n",
      "  0.0984295  -0.47015444]\n",
      "Training Error:  10.296925260656701\n",
      "====================================================================================================\n",
      "Iteration:  1100\n",
      "Previous theta :  [-0.00309434 -0.11079169  0.14111804  0.00079186  0.06129843 -0.17631441\n",
      "  0.26019585  0.04289524 -0.33639318  0.24194626 -0.19888836 -0.2088614\n",
      "  0.0984295  -0.47015444]\n",
      "New theta_0 : [-0.00309402 -0.11079375  0.14112121  0.00080132  0.06129666 -0.17632073\n",
      "  0.26019428  0.04289608 -0.33639601  0.2419678  -0.1989114  -0.20886317\n",
      "  0.09842998 -0.47015396]\n",
      "Training Error:  10.296924160779652\n",
      "====================================================================================================\n",
      "Iteration:  1101\n",
      "Previous theta :  [-0.00309402 -0.11079375  0.14112121  0.00080132  0.06129666 -0.17632073\n",
      "  0.26019428  0.04289608 -0.33639601  0.2419678  -0.1989114  -0.20886317\n",
      "  0.09842998 -0.47015396]\n",
      "New theta_0 : [-0.0030937  -0.1107958   0.14112437  0.00081075  0.0612949  -0.17632701\n",
      "  0.26019272  0.04289692 -0.33639882  0.24198927 -0.19893439 -0.20886494\n",
      "  0.09843045 -0.47015348]\n",
      "Training Error:  10.296923067197902\n",
      "====================================================================================================\n",
      "Iteration:  1102\n",
      "Previous theta :  [-0.0030937  -0.1107958   0.14112437  0.00081075  0.0612949  -0.17632701\n",
      "  0.26019272  0.04289692 -0.33639882  0.24198927 -0.19893439 -0.20886494\n",
      "  0.09843045 -0.47015348]\n",
      "New theta_0 : [-0.00309338 -0.11079785  0.14112752  0.00082016  0.06129314 -0.17633326\n",
      "  0.26019116  0.04289776 -0.33640161  0.24201068 -0.19895731 -0.2088667\n",
      "  0.09843092 -0.470153  ]\n",
      "Training Error:  10.296921979873588\n",
      "====================================================================================================\n",
      "Iteration:  1103\n",
      "Previous theta :  [-0.00309338 -0.11079785  0.14112752  0.00082016  0.06129314 -0.17633326\n",
      "  0.26019116  0.04289776 -0.33640161  0.24201068 -0.19895731 -0.2088667\n",
      "  0.09843092 -0.470153  ]\n",
      "New theta_0 : [-0.00309307 -0.11079988  0.14113066  0.00082955  0.06129139 -0.17633948\n",
      "  0.26018961  0.04289859 -0.33640438  0.24203203 -0.19898017 -0.20886844\n",
      "  0.09843139 -0.47015252]\n",
      "Training Error:  10.29692089876908\n",
      "====================================================================================================\n",
      "Iteration:  1104\n",
      "Previous theta :  [-0.00309307 -0.11079988  0.14113066  0.00082955  0.06129139 -0.17633948\n",
      "  0.26018961  0.04289859 -0.33640438  0.24203203 -0.19898017 -0.20886844\n",
      "  0.09843139 -0.47015252]\n",
      "New theta_0 : [-0.00309275 -0.11080191  0.14113378  0.00083891  0.06128965 -0.17634566\n",
      "  0.26018807  0.04289943 -0.33640713  0.24205332 -0.19900298 -0.20887019\n",
      "  0.09843186 -0.47015205]\n",
      "Training Error:  10.296919823847018\n",
      "====================================================================================================\n",
      "Iteration:  1105\n",
      "Previous theta :  [-0.00309275 -0.11080191  0.14113378  0.00083891  0.06128965 -0.17634566\n",
      "  0.26018807  0.04289943 -0.33640713  0.24205332 -0.19900298 -0.20887019\n",
      "  0.09843186 -0.47015205]\n",
      "New theta_0 : [-0.00309243 -0.11080394  0.1411369   0.00084825  0.0612879  -0.17635181\n",
      "  0.26018654  0.04290026 -0.33640985  0.24207455 -0.19902572 -0.20887192\n",
      "  0.09843232 -0.47015159]\n",
      "Training Error:  10.29691875507028\n",
      "====================================================================================================\n",
      "Iteration:  1106\n",
      "Previous theta :  [-0.00309243 -0.11080394  0.1411369   0.00084825  0.0612879  -0.17635181\n",
      "  0.26018654  0.04290026 -0.33640985  0.24207455 -0.19902572 -0.20887192\n",
      "  0.09843232 -0.47015159]\n",
      "New theta_0 : [-0.00309212 -0.11080595  0.14114001  0.00085757  0.06128617 -0.17635793\n",
      "  0.26018501  0.04290108 -0.33641256  0.24209571 -0.19904841 -0.20887364\n",
      "  0.09843279 -0.47015112]\n",
      "Training Error:  10.296917692401992\n",
      "====================================================================================================\n",
      "Iteration:  1107\n",
      "Previous theta :  [-0.00309212 -0.11080595  0.14114001  0.00085757  0.06128617 -0.17635793\n",
      "  0.26018501  0.04290108 -0.33641256  0.24209571 -0.19904841 -0.20887364\n",
      "  0.09843279 -0.47015112]\n",
      "New theta_0 : [-0.0030918  -0.11080796  0.1411431   0.00086686  0.06128444 -0.17636402\n",
      "  0.26018349  0.04290191 -0.33641525  0.24211681 -0.19907104 -0.20887536\n",
      "  0.09843325 -0.47015066]\n",
      "Training Error:  10.296916635805532\n",
      "====================================================================================================\n",
      "Iteration:  1108\n",
      "Previous theta :  [-0.0030918  -0.11080796  0.1411431   0.00086686  0.06128444 -0.17636402\n",
      "  0.26018349  0.04290191 -0.33641525  0.24211681 -0.19907104 -0.20887536\n",
      "  0.09843325 -0.47015066]\n",
      "New theta_0 : [-0.00309149 -0.11080995  0.14114618  0.00087612  0.06128272 -0.17637008\n",
      "  0.26018197  0.04290273 -0.33641791  0.24213785 -0.19909361 -0.20887707\n",
      "  0.09843371 -0.4701502 ]\n",
      "Training Error:  10.296915585244513\n",
      "====================================================================================================\n",
      "Iteration:  1109\n",
      "Previous theta :  [-0.00309149 -0.11080995  0.14114618  0.00087612  0.06128272 -0.17637008\n",
      "  0.26018197  0.04290273 -0.33641791  0.24213785 -0.19909361 -0.20887707\n",
      "  0.09843371 -0.4701502 ]\n",
      "New theta_0 : [-0.00309118 -0.11081194  0.14114925  0.00088537  0.061281   -0.17637611\n",
      "  0.26018046  0.04290355 -0.33642056  0.24215883 -0.19911612 -0.20887877\n",
      "  0.09843417 -0.47014975]\n",
      "Training Error:  10.296914540682794\n",
      "====================================================================================================\n",
      "Iteration:  1110\n",
      "Previous theta :  [-0.00309118 -0.11081194  0.14114925  0.00088537  0.061281   -0.17637611\n",
      "  0.26018046  0.04290355 -0.33642056  0.24215883 -0.19911612 -0.20887877\n",
      "  0.09843417 -0.47014975]\n",
      "New theta_0 : [-0.00309086 -0.11081393  0.14115232  0.00089459  0.06127928 -0.1763821\n",
      "  0.26017896  0.04290436 -0.33642319  0.24217975 -0.19913857 -0.20888047\n",
      "  0.09843463 -0.47014929]\n",
      "Training Error:  10.296913502084472\n",
      "====================================================================================================\n",
      "Iteration:  1111\n",
      "Previous theta :  [-0.00309086 -0.11081393  0.14115232  0.00089459  0.06127928 -0.1763821\n",
      "  0.26017896  0.04290436 -0.33642319  0.24217975 -0.19913857 -0.20888047\n",
      "  0.09843463 -0.47014929]\n",
      "New theta_0 : [-0.00309055 -0.1108159   0.14115537  0.00090378  0.06127757 -0.17638806\n",
      "  0.26017746  0.04290518 -0.33642579  0.24220061 -0.19916097 -0.20888215\n",
      "  0.09843509 -0.47014885]\n",
      "Training Error:  10.29691246941388\n",
      "====================================================================================================\n",
      "Iteration:  1112\n",
      "Previous theta :  [-0.00309055 -0.1108159   0.14115537  0.00090378  0.06127757 -0.17638806\n",
      "  0.26017746  0.04290518 -0.33642579  0.24220061 -0.19916097 -0.20888215\n",
      "  0.09843509 -0.47014885]\n",
      "New theta_0 : [-0.00309024 -0.11081787  0.1411584   0.00091295  0.06127587 -0.176394\n",
      "  0.26017597  0.04290599 -0.33642838  0.2422214  -0.1991833  -0.20888383\n",
      "  0.09843554 -0.4701484 ]\n",
      "Training Error:  10.29691144263559\n",
      "====================================================================================================\n",
      "Iteration:  1113\n",
      "Previous theta :  [-0.00309024 -0.11081787  0.1411584   0.00091295  0.06127587 -0.176394\n",
      "  0.26017597  0.04290599 -0.33642838  0.2422214  -0.1991833  -0.20888383\n",
      "  0.09843554 -0.4701484 ]\n",
      "New theta_0 : [-0.00308993 -0.11081983  0.14116143  0.0009221   0.06127417 -0.1763999\n",
      "  0.26017449  0.0429068  -0.33643095  0.24224214 -0.19920558 -0.2088855\n",
      "  0.098436   -0.47014796]\n",
      "Training Error:  10.296910421714408\n",
      "====================================================================================================\n",
      "Iteration:  1114\n",
      "Previous theta :  [-0.00308993 -0.11081983  0.14116143  0.0009221   0.06127417 -0.1763999\n",
      "  0.26017449  0.0429068  -0.33643095  0.24224214 -0.19920558 -0.2088855\n",
      "  0.098436   -0.47014796]\n",
      "New theta_0 : [-0.00308963 -0.11082178  0.14116445  0.00093122  0.06127248 -0.17640577\n",
      "  0.26017301  0.0429076  -0.3364335   0.24226281 -0.1992278  -0.20888717\n",
      "  0.09843645 -0.47014752]\n",
      "Training Error:  10.296909406615367\n",
      "====================================================================================================\n",
      "Iteration:  1115\n",
      "Previous theta :  [-0.00308963 -0.11082178  0.14116445  0.00093122  0.06127248 -0.17640577\n",
      "  0.26017301  0.0429076  -0.3364335   0.24226281 -0.1992278  -0.20888717\n",
      "  0.09843645 -0.47014752]\n",
      "New theta_0 : [-0.00308932 -0.11082372  0.14116746  0.00094032  0.06127079 -0.17641161\n",
      "  0.26017154  0.04290841 -0.33643603  0.24228343 -0.19924997 -0.20888882\n",
      "  0.0984369  -0.47014708]\n",
      "Training Error:  10.296908397303733\n",
      "====================================================================================================\n",
      "Iteration:  1116\n",
      "Previous theta :  [-0.00308932 -0.11082372  0.14116746  0.00094032  0.06127079 -0.17641161\n",
      "  0.26017154  0.04290841 -0.33643603  0.24228343 -0.19924997 -0.20888882\n",
      "  0.0984369  -0.47014708]\n",
      "New theta_0 : [-0.00308901 -0.11082566  0.14117046  0.0009494   0.06126911 -0.17641742\n",
      "  0.26017007  0.04290921 -0.33643854  0.24230399 -0.19927207 -0.20889047\n",
      "  0.09843735 -0.47014665]\n",
      "Training Error:  10.296907393745004\n",
      "====================================================================================================\n",
      "Iteration:  1117\n",
      "Previous theta :  [-0.00308901 -0.11082566  0.14117046  0.0009494   0.06126911 -0.17641742\n",
      "  0.26017007  0.04290921 -0.33643854  0.24230399 -0.19927207 -0.20889047\n",
      "  0.09843735 -0.47014665]\n",
      "New theta_0 : [-0.00308871 -0.11082759  0.14117344  0.00095845  0.06126743 -0.1764232\n",
      "  0.26016861  0.04291001 -0.33644103  0.24232448 -0.19929412 -0.20889211\n",
      "  0.0984378  -0.47014622]\n",
      "Training Error:  10.296906395904898\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = test_train_split(X, y, validation_sample3)\n",
    "learning_rate = 0.01\n",
    "train_error3, valid_error3, theta3 = linear_regression(X_train, y_train, X_test, y_test, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Second Sample')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(train_error3))], train_error3, label='Training error')\n",
    "plt.plot([i for i in range(len(valid_error3))], valid_error3, label='Validation error')\n",
    "plt.gca().legend(('Training error','Validation error'))\n",
    "plt.title('Second Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  0\n",
      "Previous theta :  [1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5]\n",
      "New theta_0 : [1.43909221 1.30157394 1.5803696  1.27931417 1.44299964 1.30284664\n",
      " 1.57698581 1.32674913 1.62733447 1.27295383 1.27188538 1.36276908\n",
      " 1.57455564 1.33341151]\n",
      "Training Error:  125.9250301096007\n",
      "====================================================================================================\n",
      "Iteration:  1\n",
      "Previous theta :  [1.43909221 1.30157394 1.5803696  1.27931417 1.44299964 1.30284664\n",
      " 1.57698581 1.32674913 1.62733447 1.27295383 1.27188538 1.36276908\n",
      " 1.57455564 1.33341151]\n",
      "New theta_0 : [1.38146456 1.14126159 1.62989009 1.10790993 1.38785484 1.15105545\n",
      " 1.62979965 1.1930882  1.71735221 1.08962111 1.08814105 1.25120538\n",
      " 1.62278174 1.20332276]\n",
      "Training Error:  107.94307821087563\n",
      "====================================================================================================\n",
      "Iteration:  2\n",
      "Previous theta :  [1.38146456 1.14126159 1.62989009 1.10790993 1.38785484 1.15105545\n",
      " 1.62979965 1.1930882  1.71735221 1.08962111 1.08814105 1.25120538\n",
      " 1.62278174 1.20332276]\n",
      "New theta_0 : [1.32678642 1.01071364 1.65601592 0.97455115 1.33459171 1.03423061\n",
      " 1.66420228 1.08986746 1.77877264 0.94045324 0.93900287 1.15960625\n",
      " 1.65086036 1.10133054]\n",
      "Training Error:  94.94594096043065\n",
      "====================================================================================================\n",
      "Iteration:  3\n",
      "Previous theta :  [1.32678642 1.01071364 1.65601592 0.97455115 1.33459171 1.03423061\n",
      " 1.66420228 1.08986746 1.77877264 0.94045324 0.93900287 1.15960625\n",
      " 1.65086036 1.10133054]\n",
      "New theta_0 : [1.27478576 0.90346612 1.66448715 0.87056137 1.28321223 0.94434559\n",
      " 1.68462908 1.01002835 1.81832213 0.81805621 0.81691427 1.08356392\n",
      " 1.66356547 1.02095194]\n",
      "Training Error:  85.56790411637115\n",
      "====================================================================================================\n",
      "Iteration:  4\n",
      "Previous theta :  [1.27478576 0.90346612 1.66448715 0.87056137 1.28321223 0.94434559\n",
      " 1.68462908 1.01002835 1.81832213 0.81805621 0.81691427 1.08356392\n",
      " 1.66356547 1.02095194]\n",
      "New theta_0 : [1.22523647 0.81451197 1.65972047 0.78924105 1.2337005  0.87520371\n",
      " 1.69449258 0.94812709 1.84118794 0.71670108 0.7160244  1.01967078\n",
      " 1.66458332 0.95718683]\n",
      "Training Error:  78.74127338100857\n",
      "====================================================================================================\n",
      "Iteration:  5\n",
      "Previous theta :  [1.22523647 0.81451197 1.65972047 0.78924105 1.2337005  0.87520371\n",
      " 1.69449258 0.94812709 1.84118794 0.71670108 0.7160244  1.01967078\n",
      " 1.66458332 0.95718683]\n",
      "New theta_0 : [1.17794856 0.73997009 1.64511119 0.72541743 1.18602749 0.82202151\n",
      " 1.69641602 0.89996666 1.85136898 0.63194579 0.63180055 0.96529174\n",
      " 1.65675972 0.90617993]\n",
      "Training Error:  73.66640853347056\n",
      "====================================================================================================\n",
      "Iteration:  6\n",
      "Previous theta :  [1.17794856 0.73997009 1.64511119 0.72541743 1.18602749 0.82202151\n",
      " 1.69641602 0.89996666 1.85136898 0.63194579 0.63180055 0.96529174\n",
      " 1.65675972 0.90617993]\n",
      "New theta_0 : [1.13276055 0.67682969 1.62326649 0.67509688 1.14015477 0.78110696\n",
      " 1.69241373 0.86231267 1.85194657 0.56034305 0.56072875 0.91838842\n",
      " 1.64229123 0.86495977]\n",
      "Training Error:  69.77129299893892\n",
      "====================================================================================================\n",
      "Iteration:  7\n",
      "Previous theta :  [1.13276055 0.67682969 1.62326649 0.67509688 1.14015477 0.78110696\n",
      " 1.69241373 0.86231267 1.85194657 0.56034305 0.56072875 0.91838842\n",
      " 1.64229123 0.86495977]\n",
      "New theta_0 : [1.08953361 0.62275282 1.59618552 0.63519638 1.0960373  0.74961096\n",
      " 1.68403046 0.83267379 1.84529363 0.4992147  0.50008246 0.87738332\n",
      " 1.62287272 0.8312372 ]\n",
      "Training Error:  66.66310715801744\n",
      "====================================================================================================\n",
      "Iteration:  8\n",
      "Previous theta :  [1.08953361 0.62275282 1.59618552 0.63519638 1.0960373  0.74961096\n",
      " 1.68403046 0.83267379 1.84529363 0.4992147  0.50008246 0.87738332\n",
      " 1.62287272 0.8312372 ]\n",
      "New theta_0 : [1.04814692 0.57592175 1.56539845 0.60333615 1.05362552 0.72533532\n",
      " 1.67244885 0.80913233 1.83323622 0.44647735 0.44774391 0.841055\n",
      " 1.59981143 0.80324967]\n",
      "Training Error:  64.0805704264783\n",
      "====================================================================================================\n",
      "Iteration:  9\n",
      "Previous theta :  [1.04814692 0.57592175 1.56539845 0.60333615 1.05362552 0.72533532\n",
      " 1.67244885 0.80913233 1.83323622 0.44647735 0.44774391 0.841055\n",
      " 1.59981143 0.80324967]\n",
      "New theta_0 : [1.00849419 0.53492119 1.53207384 0.57767946 1.01286704 0.70658458\n",
      " 1.65857253 0.79021331 1.8171783  0.40050772 0.40206606 0.80845705\n",
      " 1.57411503 0.77964107]\n",
      "Training Error:  61.853754839424475\n",
      "====================================================================================================\n",
      "Iteration:  10\n",
      "Previous theta :  [1.00849419 0.53492119 1.53207384 0.57767946 1.01286704 0.70658458\n",
      " 1.65857253 0.79021331 1.8171783  0.40050772 0.40206606 0.80845705\n",
      " 1.57411503 0.77964107]\n",
      "New theta_0 : [0.9704808  0.49864716 1.49710158 0.55680894 0.97370783 0.69205141\n",
      " 1.64309011 0.77478334 1.79819806 0.36003856 0.361766   0.7788555\n",
      " 1.54655973 0.75936888]\n",
      "Training Error:  59.87367079586778\n",
      "====================================================================================================\n",
      "Iteration:  11\n",
      "Previous theta :  [0.9704808  0.49864716 1.49710158 0.55680894 0.97370783 0.69205141\n",
      " 1.64309011 0.77478334 1.79819806 0.36003856 0.361766   0.7788555\n",
      " 1.54655973 0.75936888]\n",
      "New theta_0 : [0.93402174 0.46623667 1.46115687 0.53963105 0.93609317 0.68072824\n",
      " 1.62652476 0.76197259 1.77712236 0.32407827 0.32584253 0.75168055\n",
      " 1.51774281 0.74163249]\n",
      "Training Error:  58.07086444559285\n",
      "====================================================================================================\n",
      "Iteration:  12\n",
      "Previous theta :  [0.93402174 0.46623667 1.46115687 0.53963105 0.93609317 0.68072824\n",
      " 1.62652476 0.76197259 1.77712236 0.32407827 0.32584253 0.75168055\n",
      " 1.51774281 0.74163249]\n",
      "New theta_0 : [0.89903981 0.43701332 1.42474963 0.52530226 0.89996833 0.67183893\n",
      " 1.60927229 0.75111452 1.75458412 0.29184871 0.29351254 0.72648923\n",
      " 1.48812326 0.72581789]\n",
      "Training Error:  56.401063282701195\n",
      "====================================================================================================\n",
      "Iteration:  13\n",
      "Previous theta :  [0.89903981 0.43701332 1.42474963 0.52530226 0.89996833 0.67183893\n",
      " 1.60927229 0.75111452 1.75458412 0.29184871 0.29351254 0.72648923\n",
      " 1.48812326 0.72581789]\n",
      "New theta_0 : [0.86546439 0.41044531 1.38826265 0.51317206 0.86527907 0.66478602\n",
      " 1.59163067 0.74169931 1.73106677 0.26273724 0.26416178 0.70293658\n",
      " 1.45805316 0.71145488]\n",
      "Training Error:  54.83584617684163\n",
      "====================================================================================================\n",
      "Iteration:  14\n",
      "Previous theta :  [0.86546439 0.41044531 1.38826265 0.51317206 0.86527907 0.66478602\n",
      " 1.59163067 0.74169931 1.73106677 0.26273724 0.26416178 0.70293658\n",
      " 1.45805316 0.71145488]\n",
      "New theta_0 : [0.83323035 0.38611297 1.35198099 0.50273901 0.83197202 0.65910996\n",
      " 1.57382272 0.73333792 1.70693843 0.23625959 0.23730688 0.6807534\n",
      " 1.42780197 0.69818414]\n",
      "Training Error:  53.35670127932206\n",
      "====================================================================================================\n",
      "Iteration:  15\n",
      "Previous theta :  [0.83323035 0.38611297 1.35198099 0.50273901 0.83197202 0.65910996\n",
      " 1.57382272 0.73333792 1.70693843 0.23625959 0.23730688 0.6807534\n",
      " 1.42780197 0.69818414]\n",
      "New theta_0 : [0.80227721 0.36368363 1.31611473 0.49361666 0.79999498 0.65445768\n",
      " 1.55601367 0.7257344  1.68247843 0.21203113 0.21256595 0.65972903\n",
      " 1.39757522 0.68573172]\n",
      "Training Error:  51.95129107299167\n",
      "====================================================================================================\n",
      "Iteration:  16\n",
      "Previous theta :  [0.80227721 0.36368363 1.31611473 0.49361666 0.79999498 0.65445768\n",
      " 1.55601367 0.7257344  1.68247843 0.21203113 0.21256595 0.65972903\n",
      " 1.39757522 0.68573172]\n",
      "New theta_0 : [0.77254852 0.34289222 1.28081645 0.48550739 0.76929706 0.65055826\n",
      " 1.53832463 0.71866439 1.65789765 0.18974472 0.18963587 0.6396981\n",
      " 1.36752905 0.67388938]\n",
      "Training Error:  50.61112459967681\n",
      "====================================================================================================\n",
      "Iteration:  17\n",
      "Previous theta :  [0.77254852 0.34289222 1.28081645 0.48550739 0.76929706 0.65055826\n",
      " 1.53832463 0.71866439 1.65789765 0.18974472 0.18963587 0.6396981\n",
      " 1.36752905 0.67388938]\n",
      "New theta_0 : [0.74399135 0.3235263  1.24619476 0.47818207 0.73982883 0.64720419\n",
      " 1.52084303 0.71195868 1.63335439 0.16915352 0.16827475 0.62053028\n",
      " 1.33778136 0.66249947]\n",
      "Training Error:  49.330114587619214\n",
      "====================================================================================================\n",
      "Iteration:  18\n",
      "Previous theta :  [0.74399135 0.3235263  1.24619476 0.47818207 0.73982883 0.64720419\n",
      " 1.52084303 0.71195868 1.63335439 0.16915352 0.16827475 0.62053028\n",
      " 1.33778136 0.66249947]\n",
      "New theta_0 : [0.71655583 0.30541437 1.21232469 0.47146445 0.71154241 0.64423683\n",
      " 1.50363065 0.70549037 1.60896643 0.15005775 0.14828832 0.60212234\n",
      " 1.30842051 0.65144316]\n",
      "Training Error:  48.10368612822264\n",
      "====================================================================================================\n",
      "Iteration:  19\n",
      "Previous theta :  [0.71655583 0.30541437 1.21232469 0.47146445 0.71154241 0.64423683\n",
      " 1.50363065 0.70549037 1.60896643 0.15005775 0.14828832 0.60212234\n",
      " 1.30842051 0.65144316]\n",
      "New theta_0 : [0.69019481 0.28841695 1.17925573 0.46521907 0.6843915  0.64153527\n",
      " 1.48672976 0.69916511 1.58482049 0.13229436 0.12951946 0.58439205\n",
      " 1.27951201 0.64063147]\n",
      "Training Error:  46.9282271265958\n",
      "====================================================================================================\n",
      "Iteration:  20\n",
      "Previous theta :  [0.69019481 0.28841695 1.17925573 0.46521907 0.6843915  0.64153527\n",
      " 1.48672976 0.69916511 1.58482049 0.13229436 0.12951946 0.58439205\n",
      " 1.27951201 0.64063147]\n",
      "New theta_0 : [0.66486365 0.27241962 1.14701802 0.4593419  0.65833139 0.63900766\n",
      " 1.47016792 0.69291342 1.56097945 0.11572913 0.11184    0.56727343\n",
      " 1.25110366 0.62999824]\n",
      "Training Error:  45.800749702369764\n",
      "====================================================================================================\n",
      "Iteration:  21\n",
      "Previous theta :  [0.66486365 0.27241962 1.14701802 0.4593419  0.65833139 0.63900766\n",
      " 1.47016792 0.69291342 1.56097945 0.11572913 0.11184    0.56727343\n",
      " 1.25110366 0.62999824]\n",
      "New theta_0 : [0.64051991 0.25732758 1.11562706 0.45375317 0.63331897 0.63658454\n",
      " 1.45396158 0.68668493 1.53748792 0.10025043 0.09514453 0.55071315\n",
      " 1.22322961 0.61949482]\n",
      "Training Error:  44.71868143465414\n",
      "====================================================================================================\n",
      "Iteration:  22\n",
      "Previous theta :  [0.64051991 0.25732758 1.11562706 0.45375317 0.63331897 0.63658454\n",
      " 1.45396158 0.68668493 1.53748792 0.10025043 0.09514453 0.55071315\n",
      " 1.22322961 0.61949482]\n",
      "New theta_0 : [0.61712321 0.24306153 1.08508743 0.44839178 0.60931272 0.63421367\n",
      " 1.43811891 0.68044377 1.51437661 0.08576454 0.07934541 0.53466765\n",
      " 1.19591342 0.60908592]\n",
      "Training Error:  43.6797363681341\n",
      "====================================================================================================\n",
      "Iteration:  23\n",
      "Previous theta :  [0.61712321 0.24306153 1.08508743 0.44839178 0.60931272 0.63421367\n",
      " 1.43811891 0.68044377 1.51437661 0.08576454 0.07934541 0.53466765\n",
      " 1.19591342 0.60908592]\n",
      "New theta_0 : [0.59463506 0.22955439 1.05539554 0.44321102 0.58627268 0.6318561\n",
      " 1.42264195 0.67416519 1.49166557 0.07219182 0.06436909 0.51910101\n",
      " 1.1691705  0.59874639]\n",
      "Training Error:  42.6818349413134\n",
      "====================================================================================================\n",
      "Iteration:  24\n",
      "Previous theta :  [0.59463506 0.22955439 1.05539554 0.44321102 0.58627268 0.6318561\n",
      " 1.42264195 0.67416519 1.49166557 0.07219182 0.06436909 0.51910101\n",
      " 1.1691705  0.59874639]\n",
      "New theta_0 : [0.57301871 0.21674881 1.02654182 0.43817528 0.56416039 0.62948306\n",
      " 1.40752825 0.6678328  1.46936682 0.05946393 0.05015311 0.50398327\n",
      " 1.14300991 0.58845881]\n",
      "Training Error:  41.72305388808197\n",
      "====================================================================================================\n",
      "Iteration:  25\n",
      "Previous theta :  [0.57301871 0.21674881 1.02654182 0.43817528 0.56416039 0.62948306\n",
      " 1.40752825 0.6678328  1.46936682 0.05946393 0.05015311 0.50398327\n",
      " 1.14300991 0.58845881]\n",
      "New theta_0 : [0.55223906 0.2045952  0.99851237 0.43325743 0.54293889 0.62707358\n",
      " 1.3927721  0.66143656 1.44748628 0.04752152 0.03664383 0.48928909\n",
      " 1.11743586 0.57821155]\n",
      "Training Error:  40.801594489981426\n",
      "====================================================================================================\n",
      "Iteration:  26\n",
      "Previous theta :  [0.55223906 0.2045952  0.99851237 0.43325743 0.54293889 0.62707358\n",
      " 1.3927721  0.66143656 1.44748628 0.04752152 0.03664383 0.48928909\n",
      " 1.11743586 0.57821155]\n",
      "New theta_0 : [0.53226252 0.19305022 0.97129018 0.42843691 0.52257265 0.6246127\n",
      " 1.37836554 0.65497116 1.4260253  0.03631253 0.02379471 0.47499678\n",
      " 1.09244881 0.56799739]\n",
      "Training Error:  39.915762061276894\n",
      "====================================================================================================\n",
      "Iteration:  27\n",
      "Previous theta :  [0.53226252 0.19305022 0.97129018 0.42843691 0.52257265 0.6246127\n",
      " 1.37836554 0.65497116 1.4260253  0.03631253 0.02379471 0.47499678\n",
      " 1.09244881 0.56799739]\n",
      "New theta_0 : [0.51305697 0.18207557 0.94485614 0.42369818 0.50302753 0.62209005\n",
      " 1.36429904 0.64843486 1.40498184 0.02579079 0.01156486 0.46108751\n",
      " 1.06804632 0.55781235]\n",
      "Training Error:  39.06395231416654\n",
      "====================================================================================================\n",
      "Iteration:  28\n",
      "Previous theta :  [0.51305697 0.18207557 0.94485614 0.42369818 0.50302753 0.62209005\n",
      " 1.36429904 0.64843486 1.40498184 0.02579079 0.01156486 0.46108751\n",
      " 1.06804632 0.55781235]\n",
      "New theta_0 : [ 4.94591650e-01  1.71637080e-01  9.19189768e-01  4.19029552e-01\n",
      "  4.84270741e-01  6.19498734e-01  1.35056207e+00  6.41828477e-01\n",
      "  1.38435131e+00  1.59149514e-02 -8.19654841e-05  4.47544734e-01\n",
      "  1.04422373e+00  5.47654858e-01]\n",
      "Training Error:  38.244641946346164\n",
      "====================================================================================================\n",
      "Iteration:  29\n",
      "Previous theta :  [ 4.94591650e-01  1.71637080e-01  9.19189768e-01  4.19029552e-01\n",
      "  4.84270741e-01  6.19498734e-01  1.35056207e+00  6.41828477e-01\n",
      "  1.38435131e+00  1.59149514e-02 -8.19654841e-05  4.47544734e-01\n",
      "  1.04422373e+00  5.47654858e-01]\n",
      "New theta_0 : [ 0.47683708  0.16170397  0.89426971  0.41442227  0.46627078  0.61683452\n",
      "  1.33714348  0.63515474  1.36412735  0.00664769 -0.01117828  0.43435368\n",
      "  1.0209747   0.5375251 ]\n",
      "Training Error:  37.45638183048878\n",
      "====================================================================================================\n",
      "Iteration:  30\n",
      "Previous theta :  [ 0.47683708  0.16170397  0.89426971  0.41442227  0.46627078  0.61683452\n",
      "  1.33714348  0.63515474  1.36412735  0.00664769 -0.01117828  0.43435368\n",
      "  1.0209747   0.5375251 ]\n",
      "New theta_0 : [ 0.45976501  0.1522483   0.87007422  0.40986985  0.44899741  0.61409518\n",
      "  1.32403187  0.62841772  1.34430226 -0.00204501 -0.02175346  0.42150104\n",
      "  0.99829159  0.52742451]\n",
      "Training Error:  36.69779181914203\n",
      "====================================================================================================\n",
      "Iteration:  31\n",
      "Previous theta :  [ 0.45976501  0.1522483   0.87007422  0.40986985  0.44899741  0.61409518\n",
      "  1.32403187  0.62841772  1.34430226 -0.00204501 -0.02175346  0.42150104\n",
      "  0.99829159  0.52742451]\n",
      "New theta_0 : [ 0.44334836  0.14324449  0.84658143  0.4053675   0.43242158  0.61128\n",
      "  1.31121577  0.6216224   1.32486746 -0.01019431 -0.03183432  0.40897465\n",
      "  0.97616582  0.51735541]\n",
      "Training Error:  35.96755656533158\n",
      "====================================================================================================\n",
      "Iteration:  32\n",
      "Previous theta :  [ 0.44334836  0.14324449  0.84658143  0.4053675   0.43242158  0.61128\n",
      "  1.31121577  0.6216224   1.32486746 -0.01019431 -0.03183432  0.40897465\n",
      "  0.97616582  0.51735541]\n",
      "New theta_0 : [ 0.42756118  0.13466898  0.8237696   0.40091173  0.41651542  0.60838939\n",
      "  1.29868379  0.61477438  1.30581378 -0.017829   -0.04144545  0.39676332\n",
      "  0.95458807  0.50732071]\n",
      "Training Error:  35.26442199471559\n",
      "====================================================================================================\n",
      "Iteration:  33\n",
      "Previous theta :  [ 0.42756118  0.13466898  0.8237696   0.40091173  0.41651542  0.60838939\n",
      "  1.29868379  0.61477438  1.30581378 -0.017829   -0.04144545  0.39676332\n",
      "  0.95458807  0.50732071]\n",
      "New theta_0 : [ 0.41237855  0.12649993  0.80161726  0.39650005  0.40125214  0.6054246\n",
      "  1.2864248   0.60787961  1.28713169 -0.02497579 -0.05060964  0.38485663\n",
      "  0.93354848  0.49732369]\n",
      "Training Error:  34.58719220829629\n",
      "====================================================================================================\n",
      "Iteration:  34\n",
      "Previous theta :  [ 0.41237855  0.12649993  0.80161726  0.39650005  0.40125214  0.6054246\n",
      "  1.2864248   0.60787961  1.28713169 -0.02497579 -0.05060964  0.38485663\n",
      "  0.93354848  0.49732369]\n",
      "New theta_0 : [ 0.3977766   0.11871703  0.78010339  0.39213068  0.38660606  0.60238747\n",
      "  1.27442797  0.60094427  1.26881146 -0.03165958 -0.05934802  0.37324479\n",
      "  0.91303685  0.48736783]\n",
      "Training Error:  33.93472668149549\n",
      "====================================================================================================\n",
      "Iteration:  35\n",
      "Previous theta :  [ 0.3977766   0.11871703  0.78010339  0.39213068  0.38660606  0.60238747\n",
      "  1.27442797  0.60094427  1.26881146 -0.03165958 -0.05934802  0.37324479\n",
      "  0.91303685  0.48736783]\n",
      "New theta_0 : [ 0.3837324   0.11130127  0.75920742  0.38780241  0.3725525   0.5992803\n",
      "  1.26268283  0.59397455  1.25084333 -0.03790368 -0.06768039  0.36191859\n",
      "  0.8930427   0.47745671]\n",
      "Training Error:  33.305937677890746\n",
      "====================================================================================================\n",
      "Iteration:  36\n",
      "Previous theta :  [ 0.3837324   0.11130127  0.75920742  0.38780241  0.3725525   0.5992803\n",
      "  1.26268283  0.59397455  1.25084333 -0.03790368 -0.06768039  0.36191859\n",
      "  0.8930427   0.47745671]\n",
      "New theta_0 : [ 0.37022396  0.10423481  0.73890936  0.38351445  0.35906778  0.59610565\n",
      "  1.25117931  0.58697663  1.23321757 -0.04372997 -0.07562527  0.35086928\n",
      "  0.87355539  0.46759391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  32.6997878275548\n",
      "====================================================================================================\n",
      "Iteration:  37\n",
      "Previous theta :  [ 0.37022396  0.10423481  0.73890936  0.38351445  0.35906778  0.59610565\n",
      "  1.25117931  0.58697663  1.23321757 -0.04372997 -0.07562527  0.35086928\n",
      "  0.87355539  0.46759391]\n",
      "New theta_0 : [ 0.35723019  0.09750085  0.71918982  0.37926627  0.34612917  0.59286633\n",
      "  1.23990779  0.57995658  1.21592457 -0.04915907 -0.08320013  0.34008852\n",
      "  0.85456419  0.45778294]\n",
      "Training Error:  32.1152878389601\n",
      "====================================================================================================\n",
      "Iteration:  38\n",
      "Previous theta :  [ 0.35723019  0.09750085  0.71918982  0.37926627  0.34612917  0.59286633\n",
      "  1.23990779  0.57995658  1.21592457 -0.04915907 -0.08320013  0.34008852\n",
      "  0.85456419  0.45778294]\n",
      "New theta_0 : [ 0.34473083  0.09108356  0.70002999  0.37505759  0.33371483  0.58956524\n",
      "  1.22885904  0.57292026  1.19895488 -0.05421046 -0.09042144  0.32956832\n",
      "  0.83605834  0.4480272 ]\n",
      "Training Error:  31.551494324803134\n",
      "====================================================================================================\n",
      "Iteration:  39\n",
      "Previous theta :  [ 0.34473083  0.09108356  0.70002999  0.37505759  0.33371483  0.58956524\n",
      "  1.22885904  0.57292026  1.19895488 -0.05421046 -0.09042144  0.32956832\n",
      "  0.83605834  0.4480272 ]\n",
      "New theta_0 : [ 0.33270644  0.08496796  0.6814117   0.37088827  0.32180381  0.58620536\n",
      "  1.2180243   0.56587339  1.18229927 -0.05890253 -0.09730481  0.31930103\n",
      "  0.8180271   0.43832994]\n",
      "Training Error:  31.007507728908273\n",
      "====================================================================================================\n",
      "Iteration:  40\n",
      "Previous theta :  [ 0.33270644  0.08496796  0.6814117   0.37088827  0.32180381  0.58620536\n",
      "  1.2180243   0.56587339  1.18229927 -0.05890253 -0.09730481  0.31930103\n",
      "  0.8180271   0.43832994]\n",
      "New theta_0 : [ 0.32113837  0.07913985  0.6633174   0.36675826  0.31037601  0.58278966\n",
      "  1.20739522  0.55882141  1.16594873 -0.06325274 -0.10386502  0.30927928\n",
      "  0.80045977  0.42869424]\n",
      "Training Error:  30.482470345427075\n",
      "====================================================================================================\n",
      "Iteration:  41\n",
      "Previous theta :  [ 0.32113837  0.07913985  0.6633174   0.36675826  0.31037601  0.58278966\n",
      "  1.20739522  0.55882141  1.16594873 -0.06325274 -0.10386502  0.30927928\n",
      "  0.80045977  0.42869424]\n",
      "New theta_0 : [ 0.31000872  0.07358577  0.64573016  0.36266759  0.29941212  0.57932114\n",
      "  1.19696389  0.55176954  1.14989451 -0.06727762 -0.11011612  0.29949596\n",
      "  0.78334573  0.41912303]\n",
      "Training Error:  29.975564423969065\n",
      "====================================================================================================\n",
      "Iteration:  42\n",
      "Previous theta :  [ 0.31000872  0.07358577  0.64573016  0.36266759  0.29941212  0.57932114\n",
      "  1.19696389  0.55176954  1.14989451 -0.06727762 -0.11011612  0.29949596\n",
      "  0.78334573  0.41912303]\n",
      "New theta_0 : [ 0.29930029  0.06829293  0.62863364  0.35861634  0.2888936   0.57580274\n",
      "  1.18672278  0.54472276  1.1341281  -0.07099291 -0.11607147  0.28994422\n",
      "  0.76667447  0.40961901]\n",
      "Training Error:  29.486010355749727\n",
      "====================================================================================================\n",
      "Iteration:  43\n",
      "Previous theta :  [ 0.29930029  0.06829293  0.62863364  0.35861634  0.2888936   0.57580274\n",
      "  1.18672278  0.54472276  1.1341281  -0.07099291 -0.11607147  0.28994422\n",
      "  0.76667447  0.40961901]\n",
      "New theta_0 : [ 0.28899659  0.06324917  0.61201211  0.35460459  0.27880265  0.57223734\n",
      "  1.17666478  0.53768579  1.11864127 -0.07441353 -0.1217438   0.28061743\n",
      "  0.75043558  0.40018472]\n",
      "Training Error:  29.013064936721946\n",
      "====================================================================================================\n",
      "Iteration:  44\n",
      "Previous theta :  [ 0.28899659  0.06324917  0.61201211  0.35460459  0.27880265  0.57223734\n",
      "  1.17666478  0.53768579  1.11864127 -0.07441353 -0.1217438   0.28061743\n",
      "  0.75043558  0.40018472]\n",
      "New theta_0 : [ 0.27908177  0.05844294  0.59585039  0.35063244  0.2691222   0.56862777\n",
      "  1.16678314  0.53066308  1.10342604 -0.0775537  -0.12714523  0.27150917\n",
      "  0.73461879  0.3908225 ]\n",
      "Training Error:  28.556019704204918\n",
      "====================================================================================================\n",
      "Iteration:  45\n",
      "Previous theta :  [ 0.27908177  0.05844294  0.59585039  0.35063244  0.2691222   0.56862777\n",
      "  1.16678314  0.53066308  1.10342604 -0.0775537  -0.12714523  0.27150917\n",
      "  0.73461879  0.3908225 ]\n",
      "New theta_0 : [ 0.26954063  0.05386321  0.58013388  0.34669997  0.25983584  0.56497678\n",
      "  1.15707146  0.52365886  1.0884747  -0.08042695 -0.13228732  0.26261325\n",
      "  0.719214    0.38153451]\n",
      "Training Error:  28.114199343879775\n",
      "====================================================================================================\n",
      "Iteration:  46\n",
      "Previous theta :  [ 0.26954063  0.05386321  0.58013388  0.34669997  0.25983584  0.56497678\n",
      "  1.15707146  0.52365886  1.0884747  -0.08042695 -0.13228732  0.26261325\n",
      "  0.719214    0.38153451]\n",
      "New theta_0 : [ 0.26035857  0.0494995   0.56484852  0.34280726  0.25092783  0.56128702\n",
      "  1.14752371  0.51667709  1.07377981 -0.08304617 -0.13718114  0.25392364\n",
      "  0.70421124  0.37232272]\n",
      "Training Error:  27.68696016426615\n",
      "====================================================================================================\n",
      "Iteration:  47\n",
      "Previous theta :  [ 0.26035857  0.0494995   0.56484852  0.34280726  0.25092783  0.56128702\n",
      "  1.14752371  0.51667709  1.07377981 -0.08304617 -0.13718114  0.25392364\n",
      "  0.70421124  0.37232272]\n",
      "New theta_0 : [ 0.25152157  0.04534182  0.54998075  0.33895436  0.24238307  0.55756108\n",
      "  1.13813417  0.50972151  1.05933418 -0.08542363 -0.14183721  0.24543452\n",
      "  0.68960069  0.36318892]\n",
      "Training Error:  27.273688635974903\n",
      "====================================================================================================\n",
      "Iteration:  48\n",
      "Previous theta :  [ 0.25152157  0.04534182  0.54998075  0.33895436  0.24238307  0.55756108\n",
      "  1.13813417  0.50972151  1.05933418 -0.08542363 -0.14183721  0.24543452\n",
      "  0.68960069  0.36318892]\n",
      "New theta_0 : [ 0.24301617  0.04138063  0.53551752  0.33514131  0.23418702  0.55380144\n",
      "  1.12889742  0.50279562  1.04513084 -0.08757103 -0.14626563  0.23714024\n",
      "  0.67537273  0.35413476]\n",
      "Training Error:  26.8737999931767\n",
      "====================================================================================================\n",
      "Iteration:  49\n",
      "Previous theta :  [ 0.24301617  0.04138063  0.53551752  0.33514131  0.23418702  0.55380144\n",
      "  1.12889742  0.50279562  1.04513084 -0.08757103 -0.14626563  0.23714024\n",
      "  0.67537273  0.35413476]\n",
      "New theta_0 : [ 0.23482944  0.03760684  0.52144627  0.33136811  0.22632577  0.5500105\n",
      "  1.11980835  0.4959027   1.0311631  -0.08949953 -0.15047603  0.22903533\n",
      "  0.66151787  0.34516169]\n",
      "Training Error:  26.486736894849024\n",
      "====================================================================================================\n",
      "Iteration:  50\n",
      "Previous theta :  [ 0.23482944  0.03760684  0.52144627  0.33136811  0.22632577  0.5500105\n",
      "  1.11980835  0.4959027   1.0311631  -0.08949953 -0.15047603  0.22903533\n",
      "  0.66151787  0.34516169]\n",
      "New theta_0 : [ 0.22694899  0.03401179  0.5077549   0.32763477  0.21878593  0.54619057\n",
      "  1.11086211  0.48904583  1.01742449 -0.09121977 -0.15447762  0.22111448\n",
      "  0.64802683  0.33627104]\n",
      "Training Error:  26.1119681434729\n",
      "====================================================================================================\n",
      "Iteration:  51\n",
      "Previous theta :  [ 0.22694899  0.03401179  0.5077549   0.32763477  0.21878593  0.54619057\n",
      "  1.11086211  0.48904583  1.01742449 -0.09121977 -0.15447762  0.22111448\n",
      "  0.64802683  0.33627104]\n",
      "New theta_0 : [ 0.2193629   0.0305872   0.49443175  0.32394122  0.21155466  0.54234388\n",
      "  1.10205412  0.48222786  1.00390877 -0.0927419  -0.15827922  0.21337254\n",
      "  0.63489048  0.32746397]\n",
      "Training Error:  25.748987458950545\n",
      "====================================================================================================\n",
      "Iteration:  52\n",
      "Previous theta :  [ 0.2193629   0.0305872   0.49443175  0.32394122  0.21155466  0.54234388\n",
      "  1.10205412  0.48222786  1.00390877 -0.0927419  -0.15827922  0.21337254\n",
      "  0.63489048  0.32746397]\n",
      "New theta_0 : [ 0.21205972  0.02732517  0.48146558  0.32028741  0.20461963  0.53847256\n",
      "  1.09338005  0.47545146  0.9906099  -0.0940756  -0.16188927  0.20580452\n",
      "  0.62209989  0.3187415 ]\n",
      "Training Error:  25.397312305607706\n",
      "====================================================================================================\n",
      "Iteration:  53\n",
      "Previous theta :  [ 0.21205972  0.02732517  0.48146558  0.32028741  0.20461963  0.53847256\n",
      "  1.09338005  0.47545146  0.9906099  -0.0940756  -0.16188927  0.20580452\n",
      "  0.62209989  0.3187415 ]\n",
      "New theta_0 : [ 0.20502847  0.02421818  0.46884558  0.31667324  0.197969    0.53457867\n",
      "  1.0848358   0.46871912  0.97752209 -0.0952301  -0.16531582  0.19840556\n",
      "  0.60964628  0.31010454]\n",
      "Training Error:  25.056482770231042\n",
      "====================================================================================================\n",
      "Iteration:  54\n",
      "Previous theta :  [ 0.20502847  0.02421818  0.46884558  0.31667324  0.197969    0.53457867\n",
      "  1.0848358   0.46871912  0.97752209 -0.0952301  -0.16531582  0.19840556\n",
      "  0.60964628  0.31010454]\n",
      "New theta_0 : [ 0.1982586   0.02125904  0.4565613   0.31309861  0.19159141  0.53066417\n",
      "  1.07641747  0.46203315  0.96463972 -0.09621422 -0.16856662  0.19117099\n",
      "  0.59752107  0.30155387]\n",
      "Training Error:  24.72606048917239\n",
      "====================================================================================================\n",
      "Iteration:  55\n",
      "Previous theta :  [ 0.1982586   0.02125904  0.4565613   0.31309861  0.19159141  0.53066417\n",
      "  1.07641747  0.46203315  0.96463972 -0.09621422 -0.16856662  0.19117099\n",
      "  0.59752107  0.30155387]\n",
      "New theta_0 : [ 0.19173997  0.01844086  0.44460271  0.30956337  0.18547593  0.52673096\n",
      "  1.0681214   0.45539568  0.95195738 -0.09703637 -0.17164905  0.18409624\n",
      "  0.58571584  0.29309013]\n",
      "Training Error:  24.40562762262803\n",
      "====================================================================================================\n",
      "Iteration:  56\n",
      "Previous theta :  [ 0.19173997  0.01844086  0.44460271  0.30956337  0.18547593  0.52673096\n",
      "  1.0681214   0.45539568  0.95195738 -0.09703637 -0.17164905  0.18409624\n",
      "  0.58571584  0.29309013]\n",
      "New theta_0 : [ 0.18546287  0.01575711  0.4329601   0.30606736  0.17961209  0.52278084\n",
      "  1.05994409  0.44880867  0.93946985 -0.09770458 -0.1745702   0.17717689\n",
      "  0.57422238  0.28471389]\n",
      "Training Error:  24.094785874272983\n",
      "====================================================================================================\n",
      "Iteration:  57\n",
      "Previous theta :  [ 0.18546287  0.01575711  0.4329601   0.30606736  0.17961209  0.52278084\n",
      "  1.05994409  0.44880867  0.93946985 -0.09770458 -0.1745702   0.17717689\n",
      "  0.57422238  0.28471389]\n",
      "New theta_0 : [ 0.17941794  0.01320152  0.42162413  0.30261042  0.17398982  0.51881555\n",
      "  1.05188225  0.44227397  0.9271721  -0.09822652 -0.17733686  0.17040866\n",
      "  0.56303262  0.27642557]\n",
      "Training Error:  23.7931555544978\n",
      "====================================================================================================\n",
      "Iteration:  58\n",
      "Previous theta :  [ 0.17941794  0.01320152  0.42162413  0.30261042  0.17398982  0.51881555\n",
      "  1.05188225  0.44227397  0.9271721  -0.09822652 -0.17733686  0.17040866\n",
      "  0.56303262  0.27642557]\n",
      "New theta_0 : [ 0.17359622  0.01076812  0.41058579  0.29919233  0.16859946  0.51483675\n",
      "  1.04393274  0.43579323  0.91505925 -0.0986095  -0.17995552  0.1637874\n",
      "  0.55213867  0.26822554]\n",
      "Training Error:  23.500374685558587\n",
      "====================================================================================================\n",
      "Iteration:  59\n",
      "Previous theta :  [ 0.17359622  0.01076812  0.41058579  0.29919233  0.16859946  0.51483675\n",
      "  1.04393274  0.43579323  0.91505925 -0.0986095  -0.17995552  0.1637874\n",
      "  0.55213867  0.26822554]\n",
      "New theta_0 : [ 0.16798907  0.0084512   0.39983637  0.29581288  0.16343173  0.51084604\n",
      "  1.0360926   0.429368    0.90312663 -0.09886051 -0.18243241  0.15730907\n",
      "  0.54153285  0.26011404]\n",
      "Training Error:  23.216098147010815\n",
      "====================================================================================================\n",
      "Iteration:  60\n",
      "Previous theta :  [ 0.16798907  0.0084512   0.39983637  0.29581288  0.16343173  0.51084604\n",
      "  1.0360926   0.429368    0.90312663 -0.09886051 -0.18243241  0.15730907\n",
      "  0.54153285  0.26011404]\n",
      "New theta_0 : [ 0.16258823  0.00624531  0.3893675   0.29247184  0.15847772  0.50684494\n",
      "  1.02835899  0.42299967  0.89136968 -0.09898621 -0.18477348  0.15096978\n",
      "  0.5312076   0.25209125]\n",
      "Training Error:  22.939996859853764\n",
      "====================================================================================================\n",
      "Iteration:  61\n",
      "Previous theta :  [ 0.16258823  0.00624531  0.3893675   0.29247184  0.15847772  0.50684494\n",
      "  1.02835899  0.42299967  0.89136968 -0.09898621 -0.18477348  0.15096978\n",
      "  0.5312076   0.25209125]\n",
      "New theta_0 : [ 0.15738575  0.00414525  0.37917106  0.28916896  0.15372888  0.5028349\n",
      "  1.02072926  0.41668955  0.87978405 -0.09899296 -0.18698446  0.14476573\n",
      "  0.52115558  0.24415726]\n",
      "Training Error:  22.671757007865413\n",
      "====================================================================================================\n",
      "Iteration:  62\n",
      "Previous theta :  [ 0.15738575  0.00414525  0.37917106  0.28916896  0.15372888  0.5028349\n",
      "  1.02072926  0.41668955  0.87978405 -0.09899296 -0.18698446  0.14476573\n",
      "  0.52115558  0.24415726]\n",
      "New theta_0 : [ 0.15237398  0.00214604  0.36923925  0.28590399  0.14917699  0.49881733\n",
      "  1.01320086  0.41043877  0.8683655  -0.09888685 -0.18907083  0.13869326\n",
      "  0.51136958  0.23631208]\n",
      "Training Error:  22.411079294658574\n",
      "====================================================================================================\n",
      "Iteration:  63\n",
      "Previous theta :  [ 0.15237398  0.00214604  0.36923925  0.28590399  0.14917699  0.49881733\n",
      "  1.01320086  0.41043877  0.8683655  -0.09888685 -0.18907083  0.13869326\n",
      "  0.51136958  0.23631208]\n",
      "New theta_0 : [ 1.47545590e-01  2.42938155e-04  3.59564512e-01  2.82676639e-01\n",
      "  1.44814167e-01  4.94793556e-01  1.00577136e+00  4.04248407e-01\n",
      "  8.57109957e-01 -9.86736677e-02 -1.91037816e-01  1.32748793e-01\n",
      "  5.01842578e-01  2.28555673e-01]\n",
      "Training Error:  22.15767823503665\n",
      "====================================================================================================\n",
      "Iteration:  64\n",
      "Previous theta :  [ 1.47545590e-01  2.42938155e-04  3.59564512e-01  2.82676639e-01\n",
      "  1.44814167e-01  4.94793556e-01  1.00577136e+00  4.04248407e-01\n",
      "  8.57109957e-01 -9.86736677e-02 -1.91037816e-01  1.32748793e-01\n",
      "  5.01842578e-01  2.28555673e-01]\n",
      "New theta_0 : [ 0.14289354 -0.00156858  0.35013956  0.27948663  0.14063283  0.49076485\n",
      "  0.99843848  0.39811939  0.84601347 -0.09835897 -0.19289046  0.12692889\n",
      "  0.49256771  0.22088791]\n",
      "Training Error:  21.911281479273757\n",
      "====================================================================================================\n",
      "Iteration:  65\n",
      "Previous theta :  [ 0.14289354 -0.00156858  0.35013956  0.27948663  0.14063283  0.49076485\n",
      "  0.99843848  0.39811939  0.84601347 -0.09835897 -0.19289046  0.12692889\n",
      "  0.49256771  0.22088791]\n",
      "New theta_0 : [ 0.13841106 -0.00329286  0.34095735  0.27633367  0.1366257   0.48673244\n",
      "  0.99120003  0.39205257  0.83507224 -0.09794803 -0.19463359  0.12123019\n",
      "  0.48353828  0.21330862]\n",
      "Training Error:  21.671629168987913\n",
      "====================================================================================================\n",
      "Iteration:  66\n",
      "Previous theta :  [ 0.13841106 -0.00329286  0.34095735  0.27633367  0.1366257   0.48673244\n",
      "  0.99120003  0.39205257  0.83507224 -0.09794803 -0.19463359  0.12123019\n",
      "  0.48353828  0.21330862]\n",
      "New theta_0 : [ 0.13409164 -0.00493403  0.33201107  0.27321744  0.1327858   0.48269749\n",
      "  0.98405392  0.3860487   0.82428257 -0.09744591 -0.19627183  0.11564947\n",
      "  0.47474775  0.20581757]\n",
      "Training Error:  21.438473323318547\n",
      "====================================================================================================\n",
      "Iteration:  67\n",
      "Previous theta :  [ 0.13409164 -0.00493403  0.33201107  0.27321744  0.1327858   0.48269749\n",
      "  0.98405392  0.3860487   0.82428257 -0.09744591 -0.19627183  0.11564947\n",
      "  0.47474775  0.20581757]\n",
      "New theta_0 : [ 0.12992904 -0.00649603  0.32329417  0.27013764  0.12910643  0.47866111\n",
      "  0.97699817  0.38010844  0.81364092 -0.09685742 -0.19780959  0.11018356\n",
      "  0.46618973  0.19841446]\n",
      "Training Error:  21.21157725416075\n",
      "====================================================================================================\n",
      "Iteration:  68\n",
      "Previous theta :  [ 0.12992904 -0.00649603  0.32329417  0.27013764  0.12910643  0.47866111\n",
      "  0.97699817  0.38010844  0.81364092 -0.09685742 -0.19780959  0.11018356\n",
      "  0.46618973  0.19841446]\n",
      "New theta_0 : [ 0.12591726 -0.00798264  0.31480026  0.26709393  0.12558113  0.47462436\n",
      "  0.97003089  0.37423235  0.80314384 -0.09618718 -0.19925114  0.10482943\n",
      "  0.45785799  0.19109897]\n",
      "Training Error:  20.99071500924857\n",
      "====================================================================================================\n",
      "Iteration:  69\n",
      "Previous theta :  [ 0.12591726 -0.00798264  0.31480026  0.26709393  0.12558113  0.47462436\n",
      "  0.97003089  0.37423235  0.80314384 -0.09618718 -0.19925114  0.10482943\n",
      "  0.45785799  0.19109897]\n",
      "New theta_0 : [ 0.12205054 -0.00939747  0.30652322  0.264086    0.12220372  0.47058825\n",
      "  0.96315027  0.36842095  0.79278801 -0.09543958 -0.20060055  0.09958411\n",
      "  0.44974646  0.18387072]\n",
      "Training Error:  20.775670841918462\n",
      "====================================================================================================\n",
      "Iteration:  70\n",
      "Previous theta :  [ 0.12205054 -0.00939747  0.30652322  0.264086    0.12220372  0.47058825\n",
      "  0.96315027  0.36842095  0.79278801 -0.09543958 -0.20060055  0.09958411\n",
      "  0.44974646  0.18387072]\n",
      "New theta_0 : [ 0.11832333 -0.01074395  0.2984571   0.26111351  0.11896827  0.46655376\n",
      "  0.95635458  0.36267464  0.7825702  -0.09461881 -0.20186173  0.09444475\n",
      "  0.44184921  0.17672928]\n",
      "Training Error:  20.566238706421892\n",
      "====================================================================================================\n",
      "Iteration:  71\n",
      "Previous theta :  [ 0.11832333 -0.01074395  0.2984571   0.26111351  0.11896827  0.46655376\n",
      "  0.95635458  0.36267464  0.7825702  -0.09461881 -0.20186173  0.09444475\n",
      "  0.44184921  0.17672928]\n",
      "New theta_0 : [ 0.11473033 -0.01202538  0.29059615  0.2581761   0.11586907  0.4625218\n",
      "  0.94964218  0.35699377  0.77248732 -0.09372889 -0.20303842  0.08940856\n",
      "  0.43416047  0.16967418]\n",
      "Training Error:  20.36222177769326\n",
      "====================================================================================================\n",
      "Iteration:  72\n",
      "Previous theta :  [ 0.11473033 -0.01202538  0.29059615  0.2581761   0.11586907  0.4625218\n",
      "  0.94964218  0.35699377  0.77248732 -0.09372889 -0.20303842  0.08940856\n",
      "  0.43416047  0.16967418]\n",
      "New theta_0 : [ 0.1112664  -0.01324488  0.28293481  0.25527345  0.11290064  0.45849327\n",
      "  0.9430115   0.35137862  0.76253635 -0.09277364 -0.20413422  0.08447284\n",
      "  0.4266746   0.16270495]\n",
      "Training Error:  20.163431994515257\n",
      "====================================================================================================\n",
      "Iteration:  73\n",
      "Previous theta :  [ 0.1112664  -0.01324488  0.28293481  0.25527345  0.11290064  0.45849327\n",
      "  0.9430115   0.35137862  0.76253635 -0.09277364 -0.20413422  0.08447284\n",
      "  0.4266746   0.16270495]\n",
      "New theta_0 : [ 0.10792665 -0.01440546  0.27546769  0.2524052   0.11005772  0.45446899\n",
      "  0.93646101  0.34582942  0.75271438 -0.09175672 -0.20515258  0.079635\n",
      "  0.4193861   0.15582104]\n",
      "Training Error:  19.96968962505974\n",
      "====================================================================================================\n",
      "Iteration:  74\n",
      "Previous theta :  [ 0.10792665 -0.01440546  0.27546769  0.2524052   0.11005772  0.45446899\n",
      "  0.93646101  0.34582942  0.75271438 -0.09175672 -0.20515258  0.079635\n",
      "  0.4193861   0.15582104]\n",
      "New theta_0 : [ 0.10470635 -0.01550998  0.26818959  0.249571    0.10733526  0.45044977\n",
      "  0.92998928  0.34034631  0.74301858 -0.09068161 -0.2060968   0.07489249\n",
      "  0.41228962  0.14902189]\n",
      "Training Error:  19.78082285381671\n",
      "====================================================================================================\n",
      "Iteration:  75\n",
      "Previous theta :  [ 0.10470635 -0.01550998  0.26818959  0.249571    0.10733526  0.45044977\n",
      "  0.92998928  0.34034631  0.74301858 -0.09068161 -0.2060968   0.07489249\n",
      "  0.41228962  0.14902189]\n",
      "New theta_0 : [ 0.10160097 -0.01656117  0.26109546  0.24677048  0.10472841  0.44643637\n",
      "  0.92359492  0.3349294   0.73344624 -0.08955165 -0.20697006  0.07024287\n",
      "  0.40537995  0.14230692]\n",
      "Training Error:  19.596667388958437\n",
      "====================================================================================================\n",
      "Iteration:  76\n",
      "Previous theta :  [ 0.10160097 -0.01656117  0.26109546  0.24677048  0.10472841  0.44643637\n",
      "  0.92359492  0.3349294   0.73344624 -0.08955165 -0.20697006  0.07024287\n",
      "  0.40537995  0.14230692]\n",
      "New theta_0 : [ 0.09860616 -0.01756165  0.25418042  0.24400331  0.10223252  0.44242951\n",
      "  0.91727659  0.32957872  0.7239947  -0.08837002 -0.2077754   0.06568375\n",
      "  0.398652    0.13567552]\n",
      "Training Error:  19.417066089219297\n",
      "====================================================================================================\n",
      "Iteration:  77\n",
      "Previous theta :  [ 0.09860616 -0.01756165  0.25418042  0.24400331  0.10223252  0.44242951\n",
      "  0.91727659  0.32957872  0.7239947  -0.08837002 -0.2077754   0.06568375\n",
      "  0.398652    0.13567552]\n",
      "New theta_0 : [ 0.09571771 -0.01851391  0.24743974  0.24126911  0.0998431   0.43842989\n",
      "  0.91103301  0.32429429  0.71466142 -0.08713975 -0.20851575  0.06121283\n",
      "  0.39210082  0.12912705]\n",
      "Training Error:  19.241868609404936\n",
      "====================================================================================================\n",
      "Iteration:  78\n",
      "Previous theta :  [ 0.09571771 -0.01851391  0.24743974  0.24126911  0.0998431   0.43842989\n",
      "  0.91103301  0.32429429  0.71466142 -0.08713975 -0.20851575  0.06121283\n",
      "  0.39210082  0.12912705]\n",
      "New theta_0 : [ 0.09293162 -0.01942032  0.24086884  0.23856753  0.09755587  0.43443817\n",
      "  0.90486296  0.31907604  0.70544391 -0.08586374 -0.2091939   0.05682788\n",
      "  0.38572157  0.12266085]\n",
      "Training Error:  19.07093106367657\n",
      "====================================================================================================\n",
      "Iteration:  79\n",
      "Previous theta :  [ 0.09293162 -0.01942032  0.24086884  0.23856753  0.09755587  0.43443817\n",
      "  0.90486296  0.31907604  0.70544391 -0.08586374 -0.2091939   0.05682788\n",
      "  0.38572157  0.12266085]\n",
      "New theta_0 : [ 0.09024401 -0.02028317  0.23446327  0.2358982   0.0953667   0.43045496\n",
      "  0.89876525  0.31392389  0.69633978 -0.08454477 -0.20981255  0.05252672\n",
      "  0.37950957  0.11627624]\n",
      "Training Error:  18.90411570578823\n",
      "====================================================================================================\n",
      "Iteration:  80\n",
      "Previous theta :  [ 0.09024401 -0.02028317  0.23446327  0.2358982   0.0953667   0.43045496\n",
      "  0.89876525  0.31392389  0.69633978 -0.08454477 -0.20981255  0.05252672\n",
      "  0.37950957  0.11627624]\n",
      "New theta_0 : [ 0.08765117 -0.02110462  0.22821873  0.23326076  0.09327162  0.42648087\n",
      "  0.89273874  0.30883768  0.68734669 -0.08318546 -0.21037429  0.04830725\n",
      "  0.37346024  0.10997253]\n",
      "Training Error:  18.74129062548554\n",
      "====================================================================================================\n",
      "Iteration:  81\n",
      "Previous theta :  [ 0.08765117 -0.02110462  0.22821873  0.23326076  0.09327162  0.42648087\n",
      "  0.89273874  0.30883768  0.68734669 -0.08318546 -0.21037429  0.04830725\n",
      "  0.37346024  0.10997253]\n",
      "New theta_0 : [ 0.08514952 -0.02188674  0.22213106  0.23065486  0.09126684  0.42251645\n",
      "  0.88678233  0.30381726  0.67846239 -0.08178834 -0.21088157  0.04416744\n",
      "  0.36756912  0.10374901]\n",
      "Training Error:  18.582329460305377\n",
      "====================================================================================================\n",
      "Iteration:  82\n",
      "Previous theta :  [ 0.08514952 -0.02188674  0.22213106  0.23065486  0.09126684  0.42251645\n",
      "  0.88678233  0.30381726  0.67846239 -0.08178834 -0.21088157  0.04416744\n",
      "  0.36756912  0.10374901]\n",
      "New theta_0 : [ 0.08273564 -0.02263152  0.2161962   0.22808013  0.0893487   0.41856224\n",
      "  0.88089495  0.29886241  0.6696847  -0.08035583 -0.2113368   0.04010531\n",
      "  0.36183186  0.09760495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  18.427111122045176\n",
      "====================================================================================================\n",
      "Iteration:  83\n",
      "Previous theta :  [ 0.08273564 -0.02263152  0.2161962   0.22808013  0.0893487   0.41856224\n",
      "  0.88089495  0.29886241  0.6696847  -0.08035583 -0.2113368   0.04010531\n",
      "  0.36183186  0.09760495]\n",
      "New theta_0 : [ 0.08040622 -0.02334084  0.21041024  0.2255362   0.08751369  0.41461876\n",
      "  0.87507559  0.29397287  0.6610115  -0.07889021 -0.21174224  0.03611895\n",
      "  0.35624425  0.09153962]\n",
      "Training Error:  18.275519537200093\n",
      "====================================================================================================\n",
      "Iteration:  84\n",
      "Previous theta :  [ 0.08040622 -0.02334084  0.21041024  0.2255362   0.08751369  0.41461876\n",
      "  0.87507559  0.29397287  0.6610115  -0.07889021 -0.21174224  0.03611895\n",
      "  0.35624425  0.09153962]\n",
      "New theta_0 : [ 0.07815809 -0.02401651  0.20476937  0.22302274  0.08575844  0.41068648\n",
      "  0.86932325  0.28914838  0.65244073 -0.07739368 -0.2121001   0.03220648\n",
      "  0.35080217  0.08555227]\n",
      "Training Error:  18.127443400694247\n",
      "====================================================================================================\n",
      "Iteration:  85\n",
      "Previous theta :  [ 0.07815809 -0.02401651  0.20476937  0.22302274  0.08575844  0.41068648\n",
      "  0.86932325  0.28914838  0.65244073 -0.07739368 -0.2121001   0.03220648\n",
      "  0.35080217  0.08555227]\n",
      "New theta_0 : [ 0.07598821 -0.02466025  0.1992699   0.22053936  0.08407973  0.40676587\n",
      "  0.86363697  0.28438861  0.6439704  -0.07586833 -0.21241247  0.02836612\n",
      "  0.34550161  0.07964215]\n",
      "Training Error:  17.982775942260286\n",
      "====================================================================================================\n",
      "Iteration:  86\n",
      "Previous theta :  [ 0.07598821 -0.02466025  0.1992699   0.22053936  0.08407973  0.40676587\n",
      "  0.86363697  0.28438861  0.6439704  -0.07586833 -0.21241247  0.02836612\n",
      "  0.34550161  0.07964215]\n",
      "New theta_0 : [ 0.07389364 -0.0252737   0.19390826  0.21808572  0.08247444  0.40285735\n",
      "  0.85801582  0.27969324  0.63559857 -0.07431615 -0.21268137  0.02459612\n",
      "  0.34033869  0.07380847]\n",
      "Training Error:  17.841414704848145\n",
      "====================================================================================================\n",
      "Iteration:  87\n",
      "Previous theta :  [ 0.07389364 -0.0252737   0.19390826  0.21808572  0.08247444  0.40285735\n",
      "  0.85801582  0.27969324  0.63559857 -0.07431615 -0.21268137  0.02459612\n",
      "  0.34033869  0.07380847]\n",
      "New theta_0 : [ 0.07187157 -0.02585842  0.18868096  0.21566147  0.0809396   0.39896134\n",
      "  0.85245889  0.27506191  0.62732337 -0.07273906 -0.21290874  0.02089477\n",
      "  0.33530962  0.06805048]\n",
      "Training Error:  17.70326133447028\n",
      "====================================================================================================\n",
      "Iteration:  88\n",
      "Previous theta :  [ 0.07187157 -0.02585842  0.18868096  0.21566147  0.0809396   0.39896134\n",
      "  0.85245889  0.27506191  0.62732337 -0.07273906 -0.21290874  0.02089477\n",
      "  0.33530962  0.06805048]\n",
      "New theta_0 : [ 0.06991929 -0.02641592  0.18358463  0.21326624  0.07947233  0.39507822\n",
      "  0.84696532  0.27049422  0.61914297 -0.07113886 -0.21309644  0.01726044\n",
      "  0.33041069  0.06236739]\n",
      "Training Error:  17.568221380915983\n",
      "====================================================================================================\n",
      "Iteration:  89\n",
      "Previous theta :  [ 0.06991929 -0.02641592  0.18358463  0.21326624  0.07947233  0.39507822\n",
      "  0.84696532  0.27049422  0.61914297 -0.07113886 -0.21309644  0.01726044\n",
      "  0.33041069  0.06236739]\n",
      "New theta_0 : [ 0.06803421 -0.02694763  0.17861599  0.21089969  0.07806989  0.39120836\n",
      "  0.84153425  0.26598976  0.6110556  -0.06951729 -0.21324627  0.01369152\n",
      "  0.32563832  0.05675841]\n",
      "Training Error:  17.436204108792165\n",
      "====================================================================================================\n",
      "Iteration:  90\n",
      "Previous theta :  [ 0.06803421 -0.02694763  0.17861599  0.21089969  0.07806989  0.39120836\n",
      "  0.84153425  0.26598976  0.6110556  -0.06951729 -0.21324627  0.01369152\n",
      "  0.32563832  0.05675841]\n",
      "New theta_0 : [ 0.0662138  -0.0274549   0.17377188  0.20856148  0.07672964  0.38735212\n",
      "  0.83616485  0.26154811  0.60305955 -0.06787601 -0.21335994  0.01018648\n",
      "  0.32098903  0.05122276]\n",
      "Training Error:  17.307122318371782\n",
      "====================================================================================================\n",
      "Iteration:  91\n",
      "Previous theta :  [ 0.0662138  -0.0274549   0.17377188  0.20856148  0.07672964  0.38735212\n",
      "  0.83616485  0.26154811  0.60305955 -0.06787601 -0.21335994  0.01018648\n",
      "  0.32098903  0.05122276]\n",
      "New theta_0 : [ 0.06445568 -0.02793903  0.16904919  0.20625125  0.07544904  0.38350981\n",
      "  0.83085633  0.25716882  0.59515315 -0.06621659 -0.21343909  0.0067438\n",
      "  0.31645941  0.04575964]\n",
      "Training Error:  17.180892175754416\n",
      "====================================================================================================\n",
      "Iteration:  92\n",
      "Previous theta :  [ 0.06445568 -0.02793903  0.16904919  0.20625125  0.07544904  0.38350981\n",
      "  0.83085633  0.25716882  0.59515315 -0.06621659 -0.21343909  0.0067438\n",
      "  0.31645941  0.04575964]\n",
      "New theta_0 : [ 0.06275753 -0.02840127  0.16444493  0.20396866  0.07422566  0.37968174\n",
      "  0.82560789  0.25285141  0.58733477 -0.06454054 -0.21348531  0.00336203\n",
      "  0.31204615  0.04036825]\n",
      "Training Error:  17.057433051865832\n",
      "====================================================================================================\n",
      "Iteration:  93\n",
      "Previous theta :  [ 0.06275753 -0.02840127  0.16444493  0.20396866  0.07422566  0.37968174\n",
      "  0.82560789  0.25285141  0.58733477 -0.06454054 -0.21348531  0.00336203\n",
      "  0.31204615  0.04036825]\n",
      "New theta_0 : [ 6.11171215e-02 -2.88428001e-02  1.59956191e-01  2.01713380e-01\n",
      "  7.30571642e-02  3.75868213e-01  8.20418773e-01  2.48595409e-01\n",
      "  5.79602849e-01 -6.28492861e-02 -2.13500115e-01  3.97578314e-05\n",
      "  3.07746053e-01  3.50477997e-02]\n",
      "Training Error:  16.936667369844848\n",
      "====================================================================================================\n",
      "Iteration:  94\n",
      "Previous theta :  [ 6.11171215e-02 -2.88428001e-02  1.59956191e-01  2.01713380e-01\n",
      "  7.30571642e-02  3.75868213e-01  8.20418773e-01  2.48595409e-01\n",
      "  5.79602849e-01 -6.28492861e-02 -2.13500115e-01  3.97578314e-05\n",
      "  3.07746053e-01  3.50477997e-02]\n",
      "New theta_0 : [ 0.05953232 -0.02926474  0.15558013  0.19948506  0.0719413   0.37206949\n",
      "  0.81528823  0.24440031  0.57195584 -0.0611442  -0.21348497 -0.00322439\n",
      "  0.30355598  0.02979749]\n",
      "Training Error:  16.818520460387028\n",
      "====================================================================================================\n",
      "Iteration:  95\n",
      "Previous theta :  [ 0.05953232 -0.02926474  0.15558013  0.19948506  0.0719413   0.37206949\n",
      "  0.81528823  0.24440031  0.57195584 -0.0611442  -0.21348497 -0.00322439\n",
      "  0.30355598  0.02979749]\n",
      "New theta_0 : [ 0.05800107 -0.02966818  0.15131399  0.19728337  0.07087592  0.36828584\n",
      "  0.81021555  0.2402656   0.56439227 -0.05942658 -0.21344128 -0.00643175\n",
      "  0.29947289  0.02461652]\n",
      "Training Error:  16.702920424634524\n",
      "====================================================================================================\n",
      "Iteration:  96\n",
      "Previous theta :  [ 0.05800107 -0.02966818  0.15131399  0.19728337  0.07087592  0.36828584\n",
      "  0.81021555  0.2402656   0.56439227 -0.05942658 -0.21344128 -0.00643175\n",
      "  0.29947289  0.02461652]\n",
      "New theta_0 : [ 0.05652139 -0.03005414  0.14715511  0.19510798  0.06985894  0.3645175\n",
      "  0.8052      0.23619075  0.55691067 -0.05769767 -0.21337038 -0.00958362\n",
      "  0.29549383  0.01950409]\n",
      "Training Error:  16.589798004220928\n",
      "====================================================================================================\n",
      "Iteration:  97\n",
      "Previous theta :  [ 0.05652139 -0.03005414  0.14715511  0.19510798  0.06985894  0.3645175\n",
      "  0.8052      0.23619075  0.55691067 -0.05769767 -0.21337038 -0.00958362\n",
      "  0.29549383  0.01950409]\n",
      "New theta_0 : [ 0.05509139 -0.03042359  0.14310088  0.19295856  0.0688884   0.36076469\n",
      "  0.80024089  0.23217522  0.54950965 -0.05595866 -0.21327357 -0.01268124\n",
      "  0.29161592  0.01445941]\n",
      "Training Error:  16.47908645809867\n",
      "====================================================================================================\n",
      "Iteration:  98\n",
      "Previous theta :  [ 0.05509139 -0.03042359  0.14310088  0.19295856  0.0688884   0.36076469\n",
      "  0.80024089  0.23217522  0.54950965 -0.05595866 -0.21327357 -0.01268124\n",
      "  0.29161592  0.01445941]\n",
      "New theta_0 : [ 0.05370923 -0.03077747  0.13914877  0.19083479  0.06796237  0.35702763\n",
      "  0.79533754  0.22821848  0.54218784 -0.05421067 -0.21315209 -0.01572585\n",
      "  0.28783637  0.00948167]\n",
      "Training Error:  16.37072144579427\n",
      "====================================================================================================\n",
      "Iteration:  99\n",
      "Previous theta :  [ 0.05370923 -0.03077747  0.13914877  0.19083479  0.06796237  0.35702763\n",
      "  0.79533754  0.22821848  0.54218784 -0.05421067 -0.21315209 -0.01572585\n",
      "  0.28783637  0.00948167]\n",
      "New theta_0 : [ 0.05237316 -0.03111666  0.13529632  0.18873635  0.06707902  0.35330651\n",
      "  0.7904893   0.22431995  0.5349439  -0.05245477 -0.21300713 -0.01871862\n",
      "  0.28415246  0.00457009]\n",
      "Training Error:  16.26464091675409\n",
      "====================================================================================================\n",
      "Iteration:  100\n",
      "Previous theta :  [ 0.05237316 -0.03111666  0.13529632  0.18873635  0.06707902  0.35330651\n",
      "  0.7904893   0.22431995  0.5349439  -0.05245477 -0.21300713 -0.01871862\n",
      "  0.28415246  0.00457009]\n",
      "New theta_0 : [ 5.10814864e-02 -3.14420174e-02  1.31541135e-01  1.86662912e-01\n",
      "  6.62366028e-02  3.49601526e-01  7.85695491e-01  2.20479067e-01\n",
      "  5.27776530e-01 -5.06919955e-02 -2.12839848e-01 -2.16606966e-02\n",
      "  2.80561548e-01 -2.76129368e-04]\n",
      "Training Error:  16.160785005459754\n",
      "====================================================================================================\n",
      "Iteration:  101\n",
      "Previous theta :  [ 5.10814864e-02 -3.14420174e-02  1.31541135e-01  1.86662912e-01\n",
      "  6.62366028e-02  3.49601526e-01  7.85695491e-01  2.20479067e-01\n",
      "  5.27776530e-01 -5.06919955e-02 -2.12839848e-01 -2.16606966e-02\n",
      "  2.80561548e-01 -2.76129368e-04]\n",
      "New theta_0 : [ 0.04983258 -0.03175434  0.12788089  0.18461417  0.06543342  0.34591285\n",
      "  0.78095549  0.21669526  0.52068447 -0.04892331 -0.21265133 -0.02455321\n",
      "  0.27706106 -0.00505778]\n",
      "Training Error:  16.059095932008116\n",
      "====================================================================================================\n",
      "Iteration:  102\n",
      "Previous theta :  [ 0.04983258 -0.03175434  0.12788089  0.18461417  0.06543342  0.34591285\n",
      "  0.78095549  0.21669526  0.52068447 -0.04892331 -0.21265133 -0.02455321\n",
      "  0.27706106 -0.00505778]\n",
      "New theta_0 : [ 0.04862488 -0.03205441  0.12431332  0.18258981  0.06466786  0.34224063\n",
      "  0.77626866  0.21296796  0.5136665  -0.04714965 -0.21244264 -0.02739724\n",
      "  0.2736485  -0.00977563]\n",
      "Training Error:  15.9595179078659\n",
      "====================================================================================================\n",
      "Iteration:  103\n",
      "Previous theta :  [ 0.04862488 -0.03205441  0.12431332  0.18258981  0.06466786  0.34224063\n",
      "  0.77626866  0.21296796  0.5136665  -0.04714965 -0.21244264 -0.02739724\n",
      "  0.2736485  -0.00977563]\n",
      "New theta_0 : [ 0.04745688 -0.03234294  0.12083622  0.18058952  0.06393836  0.33858503\n",
      "  0.77163439  0.20929656  0.50672141 -0.04537188 -0.2122148  -0.03019384\n",
      "  0.27032144 -0.01443048]\n",
      "Training Error:  15.861997046523731\n",
      "====================================================================================================\n",
      "Iteration:  104\n",
      "Previous theta :  [ 0.04745688 -0.03234294  0.12083622  0.18058952  0.06393836  0.33858503\n",
      "  0.77163439  0.20929656  0.50672141 -0.04537188 -0.2122148  -0.03019384\n",
      "  0.27032144 -0.01443048]\n",
      "New theta_0 : [ 0.04632714 -0.03262064  0.11744744  0.178613    0.06324343  0.33494617\n",
      "  0.76705207  0.20568047  0.49984803 -0.04359086 -0.21196877 -0.03294403\n",
      "  0.26707751 -0.0190231 ]\n",
      "Training Error:  15.766481278787992\n",
      "====================================================================================================\n",
      "Iteration:  105\n",
      "Previous theta :  [ 0.04632714 -0.03262064  0.11744744  0.178613    0.06324343  0.33494617\n",
      "  0.76705207  0.20568047  0.49984803 -0.04359086 -0.21196877 -0.03294403\n",
      "  0.26707751 -0.0190231 ]\n",
      "New theta_0 : [ 0.04523426 -0.03288817  0.1141449   0.17665996  0.06258163  0.3313242\n",
      "  0.76252111  0.2021191   0.49304524 -0.04180738 -0.21170549 -0.03564881\n",
      "  0.26391444 -0.02355426]\n",
      "Training Error:  15.67292027246239\n",
      "====================================================================================================\n",
      "Iteration:  106\n",
      "Previous theta :  [ 0.04523426 -0.03288817  0.1141449   0.17665996  0.06258163  0.3313242\n",
      "  0.76252111  0.2021191   0.49304524 -0.04180738 -0.21170549 -0.03564881\n",
      "  0.26391444 -0.02355426]\n",
      "New theta_0 : [ 0.0441769  -0.03314616  0.11092655  0.17473009  0.06195159  0.32771922\n",
      "  0.75804092  0.19861185  0.48631192 -0.04002219 -0.21142587 -0.03830915\n",
      "  0.26082997 -0.02802473]\n",
      "Training Error:  15.581265356183675\n",
      "====================================================================================================\n",
      "Iteration:  107\n",
      "Previous theta :  [ 0.0441769  -0.03314616  0.11092655  0.17473009  0.06195159  0.32771922\n",
      "  0.75804092  0.19861185  0.48631192 -0.04002219 -0.21142587 -0.03830915\n",
      "  0.26082997 -0.02802473]\n",
      "New theta_0 : [ 0.04315378 -0.03339521  0.10779043  0.1728231   0.06135199  0.32413135\n",
      "  0.75361093  0.1951581   0.47964699 -0.03823603 -0.21113077 -0.04092599\n",
      "  0.25782195 -0.03243528]\n",
      "Training Error:  15.491469447188138\n",
      "====================================================================================================\n",
      "Iteration:  108\n",
      "Previous theta :  [ 0.04315378 -0.03339521  0.10779043  0.1728231   0.06135199  0.32413135\n",
      "  0.75361093  0.1951581   0.47964699 -0.03823603 -0.21113077 -0.04092599\n",
      "  0.25782195 -0.03243528]\n",
      "New theta_0 : [ 0.04216366 -0.03363589  0.1047346   0.1709387   0.06078155  0.32056067\n",
      "  0.74923056  0.19175726  0.4730494  -0.03644957 -0.21082101 -0.04350024\n",
      "  0.25488827 -0.03678666]\n",
      "Training Error:  15.403486982797073\n",
      "====================================================================================================\n",
      "Iteration:  109\n",
      "Previous theta :  [ 0.04216366 -0.03363589  0.1047346   0.1709387   0.06078155  0.32056067\n",
      "  0.74923056  0.19175726  0.4730494  -0.03644957 -0.21082101 -0.04350024\n",
      "  0.25488827 -0.03678666]\n",
      "New theta_0 : [ 0.04120534 -0.03386875  0.10175719  0.16907661  0.06023907  0.31700729\n",
      "  0.74489926  0.18840872  0.46651813 -0.03466347 -0.2104974  -0.0460328\n",
      "  0.25202689 -0.04107962]\n",
      "Training Error:  15.317273855420328\n",
      "====================================================================================================\n",
      "Iteration:  110\n",
      "Previous theta :  [ 0.04120534 -0.03386875  0.10175719  0.16907661  0.06023907  0.31700729\n",
      "  0.74489926  0.18840872  0.46651813 -0.03466347 -0.2104974  -0.0460328\n",
      "  0.25202689 -0.04107962]\n",
      "New theta_0 : [ 0.04027767 -0.0340943   0.09885636  0.16723654  0.05972336  0.31347128\n",
      "  0.74061648  0.18511185  0.46005216 -0.03287835 -0.2101607  -0.04852452\n",
      "  0.2492358  -0.04531491]\n",
      "Training Error:  15.232787350887683\n",
      "====================================================================================================\n",
      "Iteration:  111\n",
      "Previous theta :  [ 0.04027767 -0.0340943   0.09885636  0.16723654  0.05972336  0.31347128\n",
      "  0.74061648  0.18511185  0.46005216 -0.03287835 -0.2101607  -0.04852452\n",
      "  0.2492358  -0.04531491]\n",
      "New theta_0 : [ 0.03937956 -0.03431303  0.09603033  0.16541821  0.05923331  0.30995271\n",
      "  0.73638167  0.18186606  0.45365053 -0.03109479 -0.20981164 -0.05097625\n",
      "  0.24651309 -0.04949326]\n",
      "Training Error:  15.149986089927706\n",
      "====================================================================================================\n",
      "Iteration:  112\n",
      "Previous theta :  [ 0.03937956 -0.03431303  0.09603033  0.16541821  0.05923331  0.30995271\n",
      "  0.73638167  0.18186606  0.45365053 -0.03109479 -0.20981164 -0.05097625\n",
      "  0.24651309 -0.04949326]\n",
      "New theta_0 : [ 0.03850994 -0.03452542  0.09327737  0.16362136  0.05876784  0.30645165\n",
      "  0.73219431  0.17867073  0.44731228 -0.02931336 -0.20945094 -0.0533888\n",
      "  0.24385686 -0.05361542]\n",
      "Training Error:  15.068829972623295\n",
      "====================================================================================================\n",
      "Iteration:  113\n",
      "Previous theta :  [ 0.03850994 -0.03452542  0.09327737  0.16362136  0.05876784  0.30645165\n",
      "  0.73219431  0.17867073  0.44731228 -0.02931336 -0.20945094 -0.0533888\n",
      "  0.24385686 -0.05361542]\n",
      "New theta_0 : [ 0.03766778 -0.0347319   0.09059578  0.16184571  0.05832593  0.30296816\n",
      "  0.72805386  0.17552525  0.44103648 -0.02753457 -0.20907926 -0.05576298\n",
      "  0.2412653  -0.05768212]\n",
      "Training Error:  14.989280125682214\n",
      "====================================================================================================\n",
      "Iteration:  114\n",
      "Previous theta :  [ 0.03766778 -0.0347319   0.09059578  0.16184571  0.05832593  0.30296816\n",
      "  0.72805386  0.17552525  0.44103648 -0.02753457 -0.20907926 -0.05576298\n",
      "  0.2412653  -0.05768212]\n",
      "New theta_0 : [ 0.03685212 -0.0349329   0.08798392  0.16009098  0.05790656  0.29950229\n",
      "  0.7239598   0.172429    0.43482222 -0.02575894 -0.20869727 -0.05809956\n",
      "  0.23873662 -0.06169406]\n",
      "Training Error:  14.911298852369493\n",
      "====================================================================================================\n",
      "Iteration:  115\n",
      "Previous theta :  [ 0.03685212 -0.0349329   0.08798392  0.16009098  0.05790656  0.29950229\n",
      "  0.7239598   0.172429    0.43482222 -0.02575894 -0.20869727 -0.05809956\n",
      "  0.23873662 -0.06169406]\n",
      "New theta_0 : [ 0.03606199 -0.03512881  0.08544017  0.15835693  0.05750881  0.29605408\n",
      "  0.71991162  0.16938138  0.42866861 -0.02398693 -0.20830558 -0.06039928\n",
      "  0.23626911 -0.06565197]\n",
      "Training Error:  14.83484958495675\n",
      "====================================================================================================\n",
      "Iteration:  116\n",
      "Previous theta :  [ 0.03606199 -0.03512881  0.08544017  0.15835693  0.05750881  0.29605408\n",
      "  0.71991162  0.16938138  0.42866861 -0.02398693 -0.20830558 -0.06039928\n",
      "  0.23626911 -0.06565197]\n",
      "New theta_0 : [ 0.03529649 -0.03532001  0.08296296  0.15664328  0.05713174  0.29262358\n",
      "  0.71590882  0.16638177  0.42257478 -0.022219   -0.20790481 -0.06266289\n",
      "  0.23386108 -0.06955656]\n",
      "Training Error:  14.759896839551383\n",
      "====================================================================================================\n",
      "Iteration:  117\n",
      "Previous theta :  [ 0.03529649 -0.03532001  0.08296296  0.15664328  0.05713174  0.29262358\n",
      "  0.71590882  0.16638177  0.42257478 -0.022219   -0.20790481 -0.06266289\n",
      "  0.23386108 -0.06955656]\n",
      "New theta_0 : [ 0.03455474 -0.03550688  0.08055078  0.15494978  0.05677448  0.2892108\n",
      "  0.71195089  0.16342956  0.41653989 -0.02045557 -0.20749551 -0.0648911\n",
      "  0.23151092 -0.07340853]\n",
      "Training Error:  14.686406173175872\n",
      "====================================================================================================\n",
      "Iteration:  118\n",
      "Previous theta :  [ 0.03455474 -0.03550688  0.08055078  0.15494978  0.05677448  0.2892108\n",
      "  0.71195089  0.16342956  0.41653989 -0.02045557 -0.20749551 -0.0648911\n",
      "  0.23151092 -0.07340853]\n",
      "New theta_0 : [ 0.0338359  -0.03568973  0.07820212  0.15327617  0.0564362   0.28581578\n",
      "  0.70803733  0.16052416  0.41056312 -0.01869704 -0.20707826 -0.0670846\n",
      "  0.22921703 -0.07720856]\n",
      "Training Error:  14.61434414297448\n",
      "====================================================================================================\n",
      "Iteration:  119\n",
      "Previous theta :  [ 0.0338359  -0.03568973  0.07820212  0.15327617  0.0564362   0.28581578\n",
      "  0.70803733  0.16052416  0.41056312 -0.01869704 -0.20707826 -0.0670846\n",
      "  0.22921703 -0.07720856]\n",
      "New theta_0 : [ 0.03313916 -0.03586891  0.07591554  0.15162221  0.05611607  0.28243854\n",
      "  0.70416766  0.15766495  0.40464364 -0.0169438  -0.20665358 -0.06924407\n",
      "  0.22697789 -0.08095735]\n",
      "Training Error:  14.543678267431337\n",
      "====================================================================================================\n",
      "Iteration:  120\n",
      "Previous theta :  [ 0.03313916 -0.03586891  0.07591554  0.15162221  0.05611607  0.28243854\n",
      "  0.70416766  0.15766495  0.40464364 -0.0169438  -0.20665358 -0.06924407\n",
      "  0.22697789 -0.08095735]\n",
      "New theta_0 : [ 0.03246373 -0.03604471  0.07368962  0.14998765  0.05581334  0.2790791\n",
      "  0.7003414   0.15485133  0.39878067 -0.01519621 -0.20622197 -0.07137018\n",
      "  0.22479199 -0.08465559]\n",
      "Training Error:  14.47437698949027\n",
      "====================================================================================================\n",
      "Iteration:  121\n",
      "Previous theta :  [ 0.03246373 -0.03604471  0.07368962  0.14998765  0.05581334  0.2790791\n",
      "  0.7003414   0.15485133  0.39878067 -0.01519621 -0.20622197 -0.07137018\n",
      "  0.22479199 -0.08465559]\n",
      "New theta_0 : [ 0.03180886 -0.03621743  0.07152298  0.14837225  0.05552725  0.27573745\n",
      "  0.69655807  0.1520827   0.39297345 -0.0134546  -0.20578394 -0.07346356\n",
      "  0.2226579  -0.08830393]\n",
      "Training Error:  14.406409641472555\n",
      "====================================================================================================\n",
      "Iteration:  122\n",
      "Previous theta :  [ 0.03180886 -0.03621743  0.07152298  0.14837225  0.05552725  0.27573745\n",
      "  0.69655807  0.1520827   0.39297345 -0.0134546  -0.20578394 -0.07346356\n",
      "  0.2226579  -0.08830393]\n",
      "New theta_0 : [ 0.03117383 -0.03638734  0.06941426  0.14677576  0.05525709  0.27241361\n",
      "  0.69281719  0.14935848  0.3872212  -0.0117193  -0.20533994 -0.07552484\n",
      "  0.22057418 -0.09190305]\n",
      "Training Error:  14.339746411694717\n",
      "====================================================================================================\n",
      "Iteration:  123\n",
      "Previous theta :  [ 0.03117383 -0.03638734  0.06941426  0.14677576  0.05525709  0.27241361\n",
      "  0.69281719  0.14935848  0.3872212  -0.0117193  -0.20533994 -0.07552484\n",
      "  0.22057418 -0.09190305]\n",
      "New theta_0 : [ 0.03055793 -0.03655471  0.06736215  0.14519795  0.05500218  0.26910759\n",
      "  0.6891183   0.14667805  0.38152319 -0.0099906  -0.20489044 -0.07755463\n",
      "  0.21853949 -0.0954536 ]\n",
      "Training Error:  14.274358312693684\n",
      "====================================================================================================\n",
      "Iteration:  124\n",
      "Previous theta :  [ 0.03055793 -0.03655471  0.06736215  0.14519795  0.05500218  0.26910759\n",
      "  0.6891183   0.14667805  0.38152319 -0.0099906  -0.20489044 -0.07755463\n",
      "  0.21853949 -0.0954536 ]\n",
      "New theta_0 : [ 0.02996051 -0.03671977  0.06536537  0.14363858  0.05476186  0.26581936\n",
      "  0.68546094  0.14404084  0.3758787  -0.0082688  -0.20443586 -0.07955353\n",
      "  0.21655248 -0.09895625]\n",
      "Training Error:  14.210217150971838\n",
      "====================================================================================================\n",
      "Iteration:  125\n",
      "Previous theta :  [ 0.02996051 -0.03671977  0.06536537  0.14363858  0.05476186  0.26581936\n",
      "  0.68546094  0.14404084  0.3758787  -0.0082688  -0.20443586 -0.07955353\n",
      "  0.21655248 -0.09895625]\n",
      "New theta_0 : [ 0.02938091 -0.03688275  0.06342266  0.14209743  0.05453549  0.26254893\n",
      "  0.68184465  0.14144626  0.37028702 -0.00655415 -0.20397663 -0.08152211\n",
      "  0.21461187 -0.10241162]\n",
      "Training Error:  14.14729549817929\n",
      "====================================================================================================\n",
      "Iteration:  126\n",
      "Previous theta :  [ 0.02938091 -0.03688275  0.06342266  0.14209743  0.05453549  0.26254893\n",
      "  0.68184465  0.14144626  0.37028702 -0.00655415 -0.20397663 -0.08152211\n",
      "  0.21461187 -0.10241162]\n",
      "New theta_0 : [ 0.02881851 -0.03704389  0.0615328   0.14057427  0.05432248  0.25929629\n",
      "  0.67826898  0.13889373  0.36474745 -0.00484692 -0.20351313 -0.08346094\n",
      "  0.21271639 -0.10582037]\n",
      "Training Error:  14.085566663655328\n",
      "====================================================================================================\n",
      "Iteration:  127\n",
      "Previous theta :  [ 0.02881851 -0.03704389  0.0615328   0.14057427  0.05432248  0.25929629\n",
      "  0.67826898  0.13889373  0.36474745 -0.00484692 -0.20351313 -0.08346094\n",
      "  0.21271639 -0.10582037]\n",
      "New theta_0 : [ 0.0282727  -0.03720338  0.0596946   0.13906887  0.05412224  0.25606141\n",
      "  0.67473349  0.13638267  0.35925932 -0.00314733 -0.20304576 -0.08537058\n",
      "  0.21086483 -0.10918311]\n",
      "Training Error:  14.025004668255292\n",
      "====================================================================================================\n",
      "Iteration:  128\n",
      "Previous theta :  [ 0.0282727  -0.03720338  0.0596946   0.13906887  0.05412224  0.25606141\n",
      "  0.67473349  0.13638267  0.35925932 -0.00314733 -0.20304576 -0.08537058\n",
      "  0.21086483 -0.10918311]\n",
      "New theta_0 : [ 0.02774293 -0.03736142  0.05790689  0.13758102  0.05393422  0.25284429\n",
      "  0.67123772  0.1339125   0.35382197 -0.00145561 -0.20257487 -0.08725156\n",
      "  0.209056   -0.11250047]\n",
      "Training Error:  13.965584219393284\n",
      "====================================================================================================\n",
      "Iteration:  129\n",
      "Previous theta :  [ 0.02774293 -0.03736142  0.05790689  0.13758102  0.05393422  0.25284429\n",
      "  0.67123772  0.1339125   0.35382197 -0.00145561 -0.20257487 -0.08725156\n",
      "  0.209056   -0.11250047]\n",
      "New theta_0 : [ 2.72286138e-02 -3.75181972e-02  5.61685394e-02  1.36110493e-01\n",
      "  5.37578781e-02  2.49644885e-01  6.67781253e-01  1.31482652e-01\n",
      "  3.48434729e-01  2.28036566e-04 -2.02100831e-01 -8.91044055e-02\n",
      "  2.07288751e-01 -1.15773075e-01]\n",
      "Training Error:  13.907280687234984\n",
      "====================================================================================================\n",
      "Iteration:  130\n",
      "Previous theta :  [ 2.72286138e-02 -3.75181972e-02  5.61685394e-02  1.36110493e-01\n",
      "  5.37578781e-02  2.49644885e-01  6.67781253e-01  1.31482652e-01\n",
      "  3.48434729e-01  2.28036566e-04 -2.02100831e-01 -8.91044055e-02\n",
      "  2.07288751e-01 -1.15773075e-01]\n",
      "New theta_0 : [ 0.02672923 -0.03767388  0.05447843  0.13465708  0.05359271  0.24646318\n",
      "  0.66436364  0.12909257  0.34309698  0.00190341 -0.20162397 -0.09092963\n",
      "  0.20556196 -0.11900152]\n",
      "Training Error:  13.850070081978489\n",
      "====================================================================================================\n",
      "Iteration:  131\n",
      "Previous theta :  [ 0.02672923 -0.03767388  0.05447843  0.13465708  0.05359271  0.24646318\n",
      "  0.66436364  0.12909257  0.34309698  0.00190341 -0.20162397 -0.09092963\n",
      "  0.20556196 -0.11900152]\n",
      "New theta_0 : [ 0.02624427 -0.03782863  0.05283548  0.13322057  0.05343822  0.24329915\n",
      "  0.66098447  0.12674169  0.33780808  0.00357034 -0.20114461 -0.09272773\n",
      "  0.20387455 -0.12218641]\n",
      "Training Error:  13.79392903216469\n",
      "====================================================================================================\n",
      "Iteration:  132\n",
      "Previous theta :  [ 0.02624427 -0.03782863  0.05283548  0.13322057  0.05343822  0.24329915\n",
      "  0.66098447  0.12674169  0.33780808  0.00357034 -0.20114461 -0.09272773\n",
      "  0.20387455 -0.12218641]\n",
      "New theta_0 : [ 0.02577323 -0.03798261  0.05123863  0.13180075  0.05329394  0.24015276\n",
      "  0.6576433   0.12442945  0.33256743  0.00522865 -0.20066306 -0.09449919\n",
      "  0.20222545 -0.12532833]\n",
      "Training Error:  13.738834763961824\n",
      "====================================================================================================\n",
      "Iteration:  133\n",
      "Previous theta :  [ 0.02577323 -0.03798261  0.05123863  0.13180075  0.05329394  0.24015276\n",
      "  0.6576433   0.12442945  0.33256743  0.00522865 -0.20066306 -0.09449919\n",
      "  0.20222545 -0.12532833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.02531563 -0.03813596  0.04968685  0.13039742  0.05315941  0.23702397\n",
      "  0.65433972  0.12215531  0.32737443  0.00687818 -0.20017962 -0.09624449\n",
      "  0.20061364 -0.12842788]\n",
      "Training Error:  13.684765081372085\n",
      "====================================================================================================\n",
      "Iteration:  134\n",
      "Previous theta :  [ 0.02531563 -0.03813596  0.04968685  0.13039742  0.05315941  0.23702397\n",
      "  0.65433972  0.12215531  0.32737443  0.00687818 -0.20017962 -0.09624449\n",
      "  0.20061364 -0.12842788]\n",
      "New theta_0 : [ 0.02487101 -0.03828881  0.04817912  0.12901038  0.0530342   0.23391275\n",
      "  0.65107331  0.11991871  0.32222848  0.00851879 -0.19969458 -0.0979641\n",
      "  0.19903812 -0.13148564]\n",
      "Training Error:  13.631698347311087\n",
      "====================================================================================================\n",
      "Iteration:  135\n",
      "Previous theta :  [ 0.02487101 -0.03828881  0.04817912  0.12901038  0.0530342   0.23391275\n",
      "  0.65107331  0.11991871  0.32222848  0.00851879 -0.19969458 -0.0979641\n",
      "  0.19903812 -0.13148564]\n",
      "New theta_0 : [ 0.02443893 -0.03844128  0.04671447  0.12763942  0.0529179   0.23081905\n",
      "  0.64784367  0.11771913  0.31712902  0.01015034 -0.19920821 -0.09965847\n",
      "  0.19749793 -0.13450217]\n",
      "Training Error:  13.579613465513665\n",
      "====================================================================================================\n",
      "Iteration:  136\n",
      "Previous theta :  [ 0.02443893 -0.03844128  0.04671447  0.12763942  0.0529179   0.23081905\n",
      "  0.64784367  0.11771913  0.31712902  0.01015034 -0.19920821 -0.09965847\n",
      "  0.19749793 -0.13450217]\n",
      "New theta_0 : [ 0.02401896 -0.03859351  0.04529192  0.12628436  0.05281011  0.22774284\n",
      "  0.64465038  0.11555601  0.31207547  0.01177272 -0.19872077 -0.10132804\n",
      "  0.19599212 -0.13747803]\n",
      "Training Error:  13.52848986322228\n",
      "====================================================================================================\n",
      "Iteration:  137\n",
      "Previous theta :  [ 0.02401896 -0.03859351  0.04529192  0.12628436  0.05281011  0.22774284\n",
      "  0.64465038  0.11555601  0.31207547  0.01177272 -0.19872077 -0.10132804\n",
      "  0.19599212 -0.13747803]\n",
      "New theta_0 : [ 0.02361068 -0.03874559  0.04391054  0.12494499  0.05271045  0.22468407\n",
      "  0.64149305  0.11342884  0.30706728  0.01338579 -0.19823252 -0.10297324\n",
      "  0.19451978 -0.1404138 ]\n",
      "Training Error:  13.478307474616615\n",
      "====================================================================================================\n",
      "Iteration:  138\n",
      "Previous theta :  [ 0.02361068 -0.03874559  0.04391054  0.12494499  0.05271045  0.22468407\n",
      "  0.64149305  0.11342884  0.30706728  0.01338579 -0.19823252 -0.10297324\n",
      "  0.19451978 -0.1404138 ]\n",
      "New theta_0 : [ 0.02321371 -0.03889763  0.0425694   0.12362112  0.05261854  0.22164269\n",
      "  0.63837126  0.11133709  0.30210391  0.01498947 -0.19774368 -0.10459451\n",
      "  0.19308002 -0.14331001]\n",
      "Training Error:  13.429046724945394\n",
      "====================================================================================================\n",
      "Iteration:  139\n",
      "Previous theta :  [ 0.02321371 -0.03889763  0.0425694   0.12362112  0.05261854  0.22164269\n",
      "  0.63837126  0.11133709  0.30210391  0.01498947 -0.19774368 -0.10459451\n",
      "  0.19308002 -0.14331001]\n",
      "New theta_0 : [ 0.02282766 -0.03904974  0.04126762  0.12231257  0.05253404  0.21861865\n",
      "  0.63528463  0.10928023  0.29718481  0.01658364 -0.1972545  -0.10619224\n",
      "  0.19167197 -0.14616721]\n",
      "Training Error:  13.380688515323634\n",
      "====================================================================================================\n",
      "Iteration:  140\n",
      "Previous theta :  [ 0.02282766 -0.03904974  0.04126762  0.12231257  0.05253404  0.21861865\n",
      "  0.63528463  0.10928023  0.29718481  0.01658364 -0.1972545  -0.10619224\n",
      "  0.19167197 -0.14616721]\n",
      "New theta_0 : [ 0.02245216 -0.03920199  0.0400043   0.12101915  0.05245661  0.21561191\n",
      "  0.63223277  0.10725776  0.29230948  0.01816823 -0.19676519 -0.10776686\n",
      "  0.19029481 -0.14898594]\n",
      "Training Error:  13.333214208160609\n",
      "====================================================================================================\n",
      "Iteration:  141\n",
      "Previous theta :  [ 0.02245216 -0.03920199  0.0400043   0.12101915  0.05245661  0.21561191\n",
      "  0.63223277  0.10725776  0.29230948  0.01816823 -0.19676519 -0.10776686\n",
      "  0.19029481 -0.14898594]\n",
      "New theta_0 : [ 0.02208685 -0.03935447  0.0387786   0.11974068  0.05238592  0.2126224\n",
      "  0.62921529  0.10526916  0.28747738  0.01974315 -0.19627597 -0.10931874\n",
      "  0.18894771 -0.15176673]\n",
      "Training Error:  13.286605613185822\n",
      "====================================================================================================\n",
      "Iteration:  142\n",
      "Previous theta :  [ 0.02208685 -0.03935447  0.0387786   0.11974068  0.05238592  0.2126224\n",
      "  0.62921529  0.10526916  0.28747738  0.01974315 -0.19627597 -0.10931874\n",
      "  0.18894771 -0.15176673]\n",
      "New theta_0 : [ 0.0217314  -0.03950726  0.03758967  0.11847698  0.05232167  0.20965008\n",
      "  0.6262318   0.10331393  0.28268802  0.02130833 -0.19578703 -0.11084828\n",
      "  0.18762988 -0.1545101 ]\n",
      "Training Error:  13.240844974042044\n",
      "====================================================================================================\n",
      "Iteration:  143\n",
      "Previous theta :  [ 0.0217314  -0.03950726  0.03758967  0.11847698  0.05232167  0.20965008\n",
      "  0.6262318   0.10331393  0.28268802  0.02130833 -0.19578703 -0.11084828\n",
      "  0.18762988 -0.1545101 ]\n",
      "New theta_0 : [ 0.02138547 -0.03966042  0.03643669  0.11722786  0.05226357  0.2066949\n",
      "  0.62328193  0.10139158  0.27794091  0.02286371 -0.19529856 -0.11235585\n",
      "  0.18634055 -0.15721656]\n",
      "Training Error:  13.195914955416393\n",
      "====================================================================================================\n",
      "Iteration:  144\n",
      "Previous theta :  [ 0.02138547 -0.03966042  0.03643669  0.11722786  0.05226357  0.2066949\n",
      "  0.62328193  0.10139158  0.27794091  0.02286371 -0.19529856 -0.11235585\n",
      "  0.18634055 -0.15721656]\n",
      "New theta_0 : [ 0.02104875 -0.03981404  0.03531887  0.11599317  0.05221131  0.20375678\n",
      "  0.6203653   0.0995016   0.27323554  0.02440923 -0.19481076 -0.11384183\n",
      "  0.18507898 -0.15988663]\n",
      "Training Error:  13.15179863068188\n",
      "====================================================================================================\n",
      "Iteration:  145\n",
      "Previous theta :  [ 0.02104875 -0.03981404  0.03531887  0.11599317  0.05221131  0.20375678\n",
      "  0.6203653   0.0995016   0.27323554  0.02440923 -0.19481076 -0.11384183\n",
      "  0.18507898 -0.15988663]\n",
      "New theta_0 : [ 0.02072093 -0.03996816  0.03423542  0.11477271  0.05216464  0.20083568\n",
      "  0.61748154  0.09764352  0.26857145  0.02594483 -0.1943238  -0.11530658\n",
      "  0.18384444 -0.1625208 ]\n",
      "Training Error:  13.108479470023562\n",
      "====================================================================================================\n",
      "Iteration:  146\n",
      "Previous theta :  [ 0.02072093 -0.03996816  0.03423542  0.11477271  0.05216464  0.20083568\n",
      "  0.61748154  0.09764352  0.26857145  0.02594483 -0.1943238  -0.11530658\n",
      "  0.18384444 -0.1625208 ]\n",
      "New theta_0 : [ 0.02040172 -0.04012284  0.03318558  0.11356632  0.05212329  0.19793153\n",
      "  0.61463027  0.09581686  0.26394817  0.02747047 -0.19383784 -0.11675044\n",
      "  0.18263622 -0.16511958]\n",
      "Training Error:  13.065941329024882\n",
      "====================================================================================================\n",
      "Iteration:  147\n",
      "Previous theta :  [ 0.02040172 -0.04012284  0.03318558  0.11356632  0.05212329  0.19793153\n",
      "  0.61463027  0.09581686  0.26394817  0.02747047 -0.19383784 -0.11675044\n",
      "  0.18263622 -0.16511958]\n",
      "New theta_0 : [ 0.02009082 -0.04027814  0.03216859  0.11237384  0.05208701  0.19504428\n",
      "  0.61181114  0.09402113  0.25936522  0.02898612 -0.19335305 -0.11817377\n",
      "  0.18145364 -0.16768345]\n",
      "Training Error:  13.024168437691097\n",
      "====================================================================================================\n",
      "Iteration:  148\n",
      "Previous theta :  [ 0.02009082 -0.04027814  0.03216859  0.11237384  0.05208701  0.19504428\n",
      "  0.61181114  0.09402113  0.25936522  0.02898612 -0.19335305 -0.11817377\n",
      "  0.18145364 -0.16768345]\n",
      "New theta_0 : [ 0.01978797 -0.0404341   0.03118373  0.11119509  0.05205557  0.19217386\n",
      "  0.60902378  0.09225586  0.25482217  0.03049173 -0.19286958 -0.11957691\n",
      "  0.18029603 -0.1702129 ]\n",
      "Training Error:  12.983145389888035\n",
      "====================================================================================================\n",
      "Iteration:  149\n",
      "Previous theta :  [ 0.01978797 -0.0404341   0.03118373  0.11119509  0.05205557  0.19217386\n",
      "  0.60902378  0.09225586  0.25482217  0.03049173 -0.19286958 -0.11957691\n",
      "  0.18029603 -0.1702129 ]\n",
      "New theta_0 : [ 0.01949291 -0.04059076  0.03023028  0.11002992  0.05202872  0.1893202\n",
      "  0.60626783  0.0905206   0.25031855  0.03198729 -0.19238758 -0.12096018\n",
      "  0.17916275 -0.1727084 ]\n",
      "Training Error:  12.942857133175746\n",
      "====================================================================================================\n",
      "Iteration:  150\n",
      "Previous theta :  [ 0.01949291 -0.04059076  0.03023028  0.11002992  0.05202872  0.1893202\n",
      "  0.60626783  0.0905206   0.25031855  0.03198729 -0.19238758 -0.12096018\n",
      "  0.17916275 -0.1727084 ]\n",
      "New theta_0 : [ 0.01920537 -0.04074816  0.02930754  0.10887816  0.05200625  0.18648324\n",
      "  0.60354294  0.08881489  0.24585394  0.03347277 -0.19190718 -0.12232391\n",
      "  0.17805316 -0.17517042]\n",
      "Training Error:  12.903288959017571\n",
      "====================================================================================================\n",
      "Iteration:  151\n",
      "Previous theta :  [ 0.01920537 -0.04074816  0.02930754  0.10887816  0.05200625  0.18648324\n",
      "  0.60354294  0.08881489  0.24585394  0.03347277 -0.19190718 -0.12232391\n",
      "  0.17805316 -0.17517042]\n",
      "New theta_0 : [ 0.01892511 -0.04090633  0.02841484  0.10773965  0.05198794  0.18366292\n",
      "  0.60084877  0.08713826  0.2414279   0.03494815 -0.19142853 -0.12366841\n",
      "  0.17696665 -0.17759943]\n",
      "Training Error:  12.864426493346476\n",
      "====================================================================================================\n",
      "Iteration:  152\n",
      "Previous theta :  [ 0.01892511 -0.04090633  0.02841484  0.10773965  0.05198794  0.18366292\n",
      "  0.60084877  0.08713826  0.2414279   0.03494815 -0.19142853 -0.12366841\n",
      "  0.17696665 -0.17759943]\n",
      "New theta_0 : [ 0.0186519  -0.04106532  0.02755149  0.10661424  0.05197361  0.18085917\n",
      "  0.59818496  0.08549027  0.23704001  0.03641343 -0.19095174 -0.12499401\n",
      "  0.17590264 -0.17999588]\n",
      "Training Error:  12.826255687471365\n",
      "====================================================================================================\n",
      "Iteration:  153\n",
      "Previous theta :  [ 0.0186519  -0.04106532  0.02755149  0.10661424  0.05197361  0.18085917\n",
      "  0.59818496  0.08549027  0.23704001  0.03641343 -0.19095174 -0.12499401\n",
      "  0.17590264 -0.17999588]\n",
      "New theta_0 : [ 0.0183855  -0.04122513  0.02671685  0.10550178  0.05196304  0.17807192\n",
      "  0.59555116  0.08387049  0.23268985  0.03786859 -0.19047694 -0.12630099\n",
      "  0.17486054 -0.18236023]\n",
      "Training Error:  12.788762809307093\n",
      "====================================================================================================\n",
      "Iteration:  154\n",
      "Previous theta :  [ 0.0183855  -0.04122513  0.02671685  0.10550178  0.05196304  0.17807192\n",
      "  0.59555116  0.08387049  0.23268985  0.03786859 -0.19047694 -0.12630099\n",
      "  0.17486054 -0.18236023]\n",
      "New theta_0 : [ 0.0181257  -0.04138581  0.02591028  0.10440211  0.05195607  0.17530111\n",
      "  0.59294704  0.08227846  0.22837701  0.03931363 -0.19000425 -0.12758967\n",
      "  0.17383978 -0.18469291]\n",
      "Training Error:  12.751934434912876\n",
      "====================================================================================================\n",
      "Iteration:  155\n",
      "Previous theta :  [ 0.0181257  -0.04138581  0.02591028  0.10440211  0.05195607  0.17530111\n",
      "  0.59294704  0.08227846  0.22837701  0.03931363 -0.19000425 -0.12758967\n",
      "  0.17383978 -0.18469291]\n",
      "New theta_0 : [ 0.01787228 -0.04154736  0.02513114  0.10331508  0.0519525   0.17254666\n",
      "  0.59037227  0.08071377  0.22410108  0.04074855 -0.18953377 -0.12886034\n",
      "  0.17283984 -0.18699437]\n",
      "Training Error:  12.71575744032458\n",
      "====================================================================================================\n",
      "Iteration:  156\n",
      "Previous theta :  [ 0.01787228 -0.04154736  0.02513114  0.10331508  0.0519525   0.17254666\n",
      "  0.59037227  0.08071377  0.22410108  0.04074855 -0.18953377 -0.12886034\n",
      "  0.17283984 -0.18699437]\n",
      "New theta_0 : [ 0.01762503 -0.04170981  0.02437884  0.10224054  0.05195216  0.1698085\n",
      "  0.5878265   0.07917599  0.21986167  0.04217336 -0.18906561 -0.13011327\n",
      "  0.17186017 -0.18926504]\n",
      "Training Error:  12.68021899366723\n",
      "====================================================================================================\n",
      "Iteration:  157\n",
      "Previous theta :  [ 0.01762503 -0.04170981  0.02437884  0.10224054  0.05195216  0.1698085\n",
      "  0.5878265   0.07917599  0.21986167  0.04217336 -0.18906561 -0.13011327\n",
      "  0.17186017 -0.18926504]\n",
      "New theta_0 : [ 0.01738377 -0.04187317  0.02365277  0.10117834  0.0519549   0.16708657\n",
      "  0.58530942  0.07766469  0.21565839  0.04358807 -0.18859986 -0.13134876\n",
      "  0.17090027 -0.19150536]\n",
      "Training Error:  12.645306547534807\n",
      "====================================================================================================\n",
      "Iteration:  158\n",
      "Previous theta :  [ 0.01738377 -0.04187317  0.02365277  0.10117834  0.0519549   0.16708657\n",
      "  0.58530942  0.07766469  0.21565839  0.04358807 -0.18859986 -0.13134876\n",
      "  0.17090027 -0.19150536]\n",
      "New theta_0 : [ 0.0171483  -0.04203746  0.02295235  0.10012836  0.05196056  0.16438079\n",
      "  0.58282068  0.07617946  0.21149085  0.04499268 -0.18813663 -0.13256707\n",
      "  0.16995962 -0.19371573]\n",
      "Training Error:  12.611007831625137\n",
      "====================================================================================================\n",
      "Iteration:  159\n",
      "Previous theta :  [ 0.0171483  -0.04203746  0.02295235  0.10012836  0.05196056  0.16438079\n",
      "  0.58282068  0.07617946  0.21149085  0.04499268 -0.18813663 -0.13256707\n",
      "  0.16995962 -0.19371573]\n",
      "New theta_0 : [ 0.01691843 -0.04220268  0.022277    0.09909043  0.05196899  0.16169109\n",
      "  0.58035997  0.0747199   0.20735868  0.04638722 -0.187676   -0.13376848\n",
      "  0.16903775 -0.19589657]\n",
      "Training Error:  12.577310845618404\n",
      "====================================================================================================\n",
      "Iteration:  160\n",
      "Previous theta :  [ 0.01691843 -0.04220268  0.022277    0.09909043  0.05196899  0.16169109\n",
      "  0.58035997  0.0747199   0.20735868  0.04638722 -0.187676   -0.13376848\n",
      "  0.16903775 -0.19589657]\n",
      "New theta_0 : [ 0.01669399 -0.04236885  0.02162616  0.09806442  0.05198005  0.1590174\n",
      "  0.57792698  0.07328559  0.20326149  0.0477717  -0.18721805 -0.13495325\n",
      "  0.16813418 -0.19804831]\n",
      "Training Error:  12.544203852288307\n",
      "====================================================================================================\n",
      "Iteration:  161\n",
      "Previous theta :  [ 0.01669399 -0.04236885  0.02162616  0.09806442  0.05198005  0.1590174\n",
      "  0.57792698  0.07328559  0.20326149  0.0477717  -0.18721805 -0.13495325\n",
      "  0.16813418 -0.19804831]\n",
      "New theta_0 : [ 0.01647481 -0.04253596  0.02099929  0.0970502   0.05199359  0.15635965\n",
      "  0.57552137  0.07187615  0.19919893  0.04914615 -0.18676288 -0.13612164\n",
      "  0.16724846 -0.20017133]\n",
      "Training Error:  12.51167537083567\n",
      "====================================================================================================\n",
      "Iteration:  162\n",
      "Previous theta :  [ 0.01647481 -0.04253596  0.02099929  0.0970502   0.05199359  0.15635965\n",
      "  0.57552137  0.07187615  0.19919893  0.04914615 -0.18676288 -0.13612164\n",
      "  0.16724846 -0.20017133]\n",
      "New theta_0 : [ 0.01626071 -0.04270403  0.02039585  0.09604762  0.05200949  0.15371776\n",
      "  0.57314284  0.07049117  0.19517064  0.05051058 -0.18631054 -0.13727391\n",
      "  0.16638013 -0.20226603]\n",
      "Training Error:  12.479714170434745\n",
      "====================================================================================================\n",
      "Iteration:  163\n",
      "Previous theta :  [ 0.01626071 -0.04270403  0.02039585  0.09604762  0.05200949  0.15371776\n",
      "  0.57314284  0.07049117  0.19517064  0.05051058 -0.18631054 -0.13727391\n",
      "  0.16638013 -0.20226603]\n",
      "New theta_0 : [ 0.01605155 -0.04287304  0.01981532  0.09505656  0.05202762  0.15109166\n",
      "  0.57079108  0.06913027  0.19117624  0.05186503 -0.18586112 -0.13841031\n",
      "  0.16552876 -0.20433282]\n",
      "Training Error:  12.448309263983017\n",
      "====================================================================================================\n",
      "Iteration:  164\n",
      "Previous theta :  [ 0.01605155 -0.04287304  0.01981532  0.09505656  0.05202762  0.15109166\n",
      "  0.57079108  0.06913027  0.19117624  0.05186503 -0.18586112 -0.13841031\n",
      "  0.16552876 -0.20433282]\n",
      "New theta_0 : [ 0.01584717 -0.04304302  0.01925717  0.09407687  0.05204786  0.14848128\n",
      "  0.56846578  0.06779306  0.18721541  0.05320953 -0.18541469 -0.13953107\n",
      "  0.16469392 -0.20637208]\n",
      "Training Error:  12.417449902045814\n",
      "====================================================================================================\n",
      "Iteration:  165\n",
      "Previous theta :  [ 0.01584717 -0.04304302  0.01925717  0.09407687  0.05204786  0.14848128\n",
      "  0.56846578  0.06779306  0.18721541  0.05320953 -0.18541469 -0.13953107\n",
      "  0.16469392 -0.20637208]\n",
      "New theta_0 : [ 0.01564742 -0.04321394  0.01872092  0.09310844  0.0520701   0.14588655\n",
      "  0.56616664  0.06647918  0.18328778  0.05454411 -0.1849713  -0.14063644\n",
      "  0.16387522 -0.20838418]\n",
      "Training Error:  12.387125566987548\n",
      "====================================================================================================\n",
      "Iteration:  166\n",
      "Previous theta :  [ 0.01564742 -0.04321394  0.01872092  0.09310844  0.0520701   0.14588655\n",
      "  0.56616664  0.06647918  0.18328778  0.05454411 -0.1849713  -0.14063644\n",
      "  0.16387522 -0.20838418]\n",
      "New theta_0 : [ 0.01545215 -0.04338581  0.01820607  0.09215112  0.05209423  0.14330738\n",
      "  0.56389335  0.06518824  0.17939303  0.0558688  -0.18453102 -0.14172666\n",
      "  0.16307225 -0.21036951]\n",
      "Training Error:  12.35732596728175\n",
      "====================================================================================================\n",
      "Iteration:  167\n",
      "Previous theta :  [ 0.01545215 -0.04338581  0.01820607  0.09215112  0.05209423  0.14330738\n",
      "  0.56389335  0.06518824  0.17939303  0.0558688  -0.18453102 -0.14172666\n",
      "  0.16307225 -0.21036951]\n",
      "New theta_0 : [ 0.01526123 -0.04355862  0.01771213  0.0912048   0.05212013  0.1407437\n",
      "  0.56164563  0.06391988  0.1755308   0.05718364 -0.1840939  -0.14280196\n",
      "  0.16228462 -0.21232844]\n",
      "Training Error:  12.328041031992546\n",
      "====================================================================================================\n",
      "Iteration:  168\n",
      "Previous theta :  [ 0.01526123 -0.04355862  0.01771213  0.0912048   0.05212013  0.1407437\n",
      "  0.56164563  0.06391988  0.1755308   0.05718364 -0.1840939  -0.14280196\n",
      "  0.16228462 -0.21232844]\n",
      "New theta_0 : [ 0.01507452 -0.04373237  0.01723864  0.09026935  0.05214772  0.13819545\n",
      "  0.55942316  0.06267374  0.17170079  0.05848868 -0.18366    -0.14386257\n",
      "  0.16151195 -0.21426134]\n",
      "Training Error:  12.299260905420683\n",
      "====================================================================================================\n",
      "Iteration:  169\n",
      "Previous theta :  [ 0.01507452 -0.04373237  0.01723864  0.09026935  0.05214772  0.13819545\n",
      "  0.55942316  0.06267374  0.17170079  0.05848868 -0.18366    -0.14386257\n",
      "  0.16151195 -0.21426134]\n",
      "New theta_0 : [ 0.0148919  -0.04390704  0.01678514  0.08934464  0.05217689  0.13566254\n",
      "  0.55722568  0.06144945  0.16790264  0.05978394 -0.18322938 -0.1449087\n",
      "  0.16075388 -0.21616855]\n",
      "Training Error:  12.270975941907352\n",
      "====================================================================================================\n",
      "Iteration:  170\n",
      "Previous theta :  [ 0.0148919  -0.04390704  0.01678514  0.08934464  0.05217689  0.13566254\n",
      "  0.55722568  0.06144945  0.16790264  0.05978394 -0.18322938 -0.1449087\n",
      "  0.16075388 -0.21616855]\n",
      "New theta_0 : [ 0.01471324 -0.04408263  0.01635117  0.08843055  0.05220755  0.1331449\n",
      "  0.55505287  0.06024668  0.16413606  0.06106948 -0.18280207 -0.14594058\n",
      "  0.16001005 -0.21805045]\n",
      "Training Error:  12.243176700789725\n",
      "====================================================================================================\n",
      "Iteration:  171\n",
      "Previous theta :  [ 0.01471324 -0.04408263  0.01635117  0.08843055  0.05220755  0.1331449\n",
      "  0.55505287  0.06024668  0.16413606  0.06106948 -0.18280207 -0.14594058\n",
      "  0.16001005 -0.21805045]\n",
      "New theta_0 : [ 0.01453843 -0.04425913  0.0159363   0.08752696  0.05223961  0.13064245\n",
      "  0.55290447  0.05906507  0.16040072  0.06234534 -0.18237812 -0.14695842\n",
      "  0.15928012 -0.21990739]\n",
      "Training Error:  12.215853941502116\n",
      "====================================================================================================\n",
      "Iteration:  172\n",
      "Previous theta :  [ 0.01453843 -0.04425913  0.0159363   0.08752696  0.05223961  0.13064245\n",
      "  0.55290447  0.05906507  0.16040072  0.06234534 -0.18237812 -0.14695842\n",
      "  0.15928012 -0.21990739]\n",
      "New theta_0 : [ 0.01436733 -0.04443652  0.01554009  0.08663375  0.052273    0.12815512\n",
      "  0.55078018  0.05790428  0.1566963   0.06361156 -0.18195758 -0.14796243\n",
      "  0.15856375 -0.2217397 ]\n",
      "Training Error:  12.188998618817251\n",
      "====================================================================================================\n",
      "Iteration:  173\n",
      "Previous theta :  [ 0.01436733 -0.04443652  0.01554009  0.08663375  0.052273    0.12815512\n",
      "  0.55078018  0.05790428  0.1566963   0.06361156 -0.18195758 -0.14796243\n",
      "  0.15856375 -0.2217397 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.01419985 -0.0446148   0.01516212  0.08575081  0.05230762  0.12568284\n",
      "  0.54867974  0.05676397  0.15302251  0.0648682  -0.18154047 -0.14895282\n",
      "  0.1578606  -0.22354773]\n",
      "Training Error:  12.162601878222286\n",
      "====================================================================================================\n",
      "Iteration:  174\n",
      "Previous theta :  [ 0.01419985 -0.0446148   0.01516212  0.08575081  0.05230762  0.12568284\n",
      "  0.54867974  0.05676397  0.15302251  0.0648682  -0.18154047 -0.14895282\n",
      "  0.1578606  -0.22354773]\n",
      "New theta_0 : [ 0.01403588 -0.04479394  0.01480198  0.08487801  0.0523434   0.12322552\n",
      "  0.54660285  0.05564381  0.14937903  0.06611529 -0.18112685 -0.1499298\n",
      "  0.15717037 -0.22533182]\n",
      "Training Error:  12.13665505142445\n",
      "====================================================================================================\n",
      "Iteration:  175\n",
      "Previous theta :  [ 0.01403588 -0.04479394  0.01480198  0.08487801  0.0523434   0.12322552\n",
      "  0.54660285  0.05564381  0.14937903  0.06611529 -0.18112685 -0.1499298\n",
      "  0.15717037 -0.22533182]\n",
      "New theta_0 : [ 0.0138753  -0.04497394  0.01445926  0.08401525  0.05238028  0.12078309\n",
      "  0.54454926  0.05454347  0.14576557  0.0673529  -0.18071673 -0.15089356\n",
      "  0.15649273 -0.2270923 ]\n",
      "Training Error:  12.111149651981608\n",
      "====================================================================================================\n",
      "Iteration:  176\n",
      "Previous theta :  [ 0.0138753  -0.04497394  0.01445926  0.08401525  0.05238028  0.12078309\n",
      "  0.54454926  0.05454347  0.14576557  0.0673529  -0.18071673 -0.15089356\n",
      "  0.15649273 -0.2270923 ]\n",
      "New theta_0 : [ 0.01371802 -0.04515478  0.01413356  0.08316241  0.05241817  0.11835548\n",
      "  0.54251869  0.05346263  0.14218183  0.06858108 -0.18031016 -0.1518443\n",
      "  0.1558274  -0.22882949]\n",
      "Training Error:  12.086077371053067\n",
      "====================================================================================================\n",
      "Iteration:  177\n",
      "Previous theta :  [ 0.01371802 -0.04515478  0.01413356  0.08316241  0.05241817  0.11835548\n",
      "  0.54251869  0.05346263  0.14218183  0.06858108 -0.18031016 -0.1518443\n",
      "  0.1558274  -0.22882949]\n",
      "New theta_0 : [ 0.01356395 -0.04533644  0.0138245   0.08231938  0.05245701  0.11594262\n",
      "  0.54051086  0.05240098  0.13862752  0.06979987 -0.17990716 -0.15278222\n",
      "  0.15517408 -0.23054372]\n",
      "Training Error:  12.061430073266395\n",
      "====================================================================================================\n",
      "Iteration:  178\n",
      "Previous theta :  [ 0.01356395 -0.04533644  0.0138245   0.08231938  0.05245701  0.11594262\n",
      "  0.54051086  0.05240098  0.13862752  0.06979987 -0.17990716 -0.15278222\n",
      "  0.15517408 -0.23054372]\n",
      "New theta_0 : [ 0.01341298 -0.0455189   0.0135317   0.08148605  0.05249674  0.11354441\n",
      "  0.53852553  0.05135819  0.13510236  0.07100934 -0.17950775 -0.1537075\n",
      "  0.15453247 -0.23223531]\n",
      "Training Error:  12.037199792696\n",
      "====================================================================================================\n",
      "Iteration:  179\n",
      "Previous theta :  [ 0.01341298 -0.0455189   0.0135317   0.08148605  0.05249674  0.11354441\n",
      "  0.53852553  0.05135819  0.13510236  0.07100934 -0.17950775 -0.1537075\n",
      "  0.15453247 -0.23223531]\n",
      "New theta_0 : [ 0.01326504 -0.04570215  0.01325478  0.08066231  0.0525373   0.1111608\n",
      "  0.53656242  0.05033397  0.13160606  0.07220953 -0.17911196 -0.15462033\n",
      "  0.15390231 -0.23390456]\n",
      "Training Error:  12.01337872894964\n",
      "====================================================================================================\n",
      "Iteration:  180\n",
      "Previous theta :  [ 0.01326504 -0.04570215  0.01325478  0.08066231  0.0525373   0.1111608\n",
      "  0.53656242  0.05033397  0.13160606  0.07220953 -0.17911196 -0.15462033\n",
      "  0.15390231 -0.23390456]\n",
      "New theta_0 : [ 0.01312002 -0.04588617  0.01299339  0.07984805  0.05257862  0.1087917\n",
      "  0.53462128  0.049328    0.12813834  0.07340051 -0.17871982 -0.15552089\n",
      "  0.15328333 -0.23555179]\n",
      "Training Error:  11.989959243359097\n",
      "====================================================================================================\n",
      "Iteration:  181\n",
      "Previous theta :  [ 0.01312002 -0.04588617  0.01299339  0.07984805  0.05257862  0.1087917\n",
      "  0.53462128  0.049328    0.12813834  0.07340051 -0.17871982 -0.15552089\n",
      "  0.15328333 -0.23555179]\n",
      "New theta_0 : [ 0.01297784 -0.04607094  0.01274716  0.07904318  0.05262065  0.10643704\n",
      "  0.53270186  0.04833998  0.12469892  0.07458232 -0.17833134 -0.15640936\n",
      "  0.15267525 -0.23717731]\n",
      "Training Error:  11.966933855271428\n",
      "====================================================================================================\n",
      "Iteration:  182\n",
      "Previous theta :  [ 0.01297784 -0.04607094  0.01274716  0.07904318  0.05262065  0.10643704\n",
      "  0.53270186  0.04833998  0.12469892  0.07458232 -0.17833134 -0.15640936\n",
      "  0.15267525 -0.23717731]\n",
      "New theta_0 : [ 0.01283843 -0.04625644  0.01251575  0.07824757  0.05266334  0.10409674\n",
      "  0.53080389  0.04736963  0.12128754  0.07575504 -0.17794654 -0.15728593\n",
      "  0.15207783 -0.23878141]\n",
      "Training Error:  11.944295238437405\n",
      "====================================================================================================\n",
      "Iteration:  183\n",
      "Previous theta :  [ 0.01283843 -0.04625644  0.01251575  0.07824757  0.05266334  0.10409674\n",
      "  0.53080389  0.04736963  0.12128754  0.07575504 -0.17794654 -0.15728593\n",
      "  0.15207783 -0.23878141]\n",
      "New theta_0 : [ 0.0127017  -0.04644266  0.01229881  0.07746114  0.05270664  0.10177073\n",
      "  0.52892713  0.04641664  0.11790392  0.07691871 -0.17756543 -0.15815076\n",
      "  0.15149083 -0.24036439]\n",
      "Training Error:  11.922036217493954\n",
      "====================================================================================================\n",
      "Iteration:  184\n",
      "Previous theta :  [ 0.0127017  -0.04644266  0.01229881  0.07746114  0.05270664  0.10177073\n",
      "  0.52892713  0.04641664  0.11790392  0.07691871 -0.17756543 -0.15815076\n",
      "  0.15149083 -0.24036439]\n",
      "New theta_0 : [ 0.01256757 -0.04662956  0.01209601  0.07668378  0.0527505   0.09945893\n",
      "  0.52707134  0.04548074  0.1145478   0.07807339 -0.17718803 -0.15900402\n",
      "  0.15091398 -0.24192654]\n",
      "Training Error:  11.900149764537431\n",
      "====================================================================================================\n",
      "Iteration:  185\n",
      "Previous theta :  [ 0.01256757 -0.04662956  0.01209601  0.07668378  0.0527505   0.09945893\n",
      "  0.52707134  0.04548074  0.1145478   0.07807339 -0.17718803 -0.15900402\n",
      "  0.15091398 -0.24192654]\n",
      "New theta_0 : [ 0.01243598 -0.04681714  0.01190702  0.07591538  0.05279487  0.09716127\n",
      "  0.52523626  0.04456164  0.11121892  0.07921915 -0.17681436 -0.15984589\n",
      "  0.15034707 -0.24346815]\n",
      "Training Error:  11.878628995784846\n",
      "====================================================================================================\n",
      "Iteration:  186\n",
      "Previous theta :  [ 0.01243598 -0.04681714  0.01190702  0.07591538  0.05279487  0.09716127\n",
      "  0.52523626  0.04456164  0.11121892  0.07921915 -0.17681436 -0.15984589\n",
      "  0.15034707 -0.24346815]\n",
      "New theta_0 : [ 0.01230685 -0.04700537  0.01173153  0.07515585  0.05283971  0.09487767\n",
      "  0.52342165  0.04365906  0.10791702  0.08035605 -0.17644442 -0.16067653\n",
      "  0.14978986 -0.2449895 ]\n",
      "Training Error:  11.857467168320193\n",
      "====================================================================================================\n",
      "Iteration:  187\n",
      "Previous theta :  [ 0.01230685 -0.04700537  0.01173153  0.07515585  0.05283971  0.09487767\n",
      "  0.52342165  0.04365906  0.10791702  0.08035605 -0.17644442 -0.16067653\n",
      "  0.14978986 -0.2449895 ]\n",
      "New theta_0 : [ 0.01218011 -0.04719422  0.01156921  0.0744051   0.05288497  0.09260806\n",
      "  0.52162728  0.04277272  0.10464184  0.08148415 -0.17607822 -0.1614961\n",
      "  0.14924213 -0.24649087]\n",
      "Training Error:  11.83665767692319\n",
      "====================================================================================================\n",
      "Iteration:  188\n",
      "Previous theta :  [ 0.01218011 -0.04719422  0.01156921  0.0744051   0.05288497  0.09260806\n",
      "  0.52162728  0.04277272  0.10464184  0.08148415 -0.17607822 -0.1614961\n",
      "  0.14924213 -0.24649087]\n",
      "New theta_0 : [ 0.0120557  -0.04738368  0.01141977  0.07366302  0.05293062  0.09035237\n",
      "  0.51985291  0.04190237  0.10139313  0.0826035  -0.17571578 -0.16230476\n",
      "  0.14870367 -0.24797254]\n",
      "Training Error:  11.816194050977886\n",
      "====================================================================================================\n",
      "Iteration:  189\n",
      "Previous theta :  [ 0.0120557  -0.04738368  0.01141977  0.07366302  0.05293062  0.09035237\n",
      "  0.51985291  0.04190237  0.10139313  0.0826035  -0.17571578 -0.16230476\n",
      "  0.14870367 -0.24797254]\n",
      "New theta_0 : [ 0.01193355 -0.04757373  0.01128289  0.07292952  0.05297662  0.08811051\n",
      "  0.51809831  0.04104773  0.09817064  0.08371418 -0.17535709 -0.16310267\n",
      "  0.14817426 -0.24943478]\n",
      "Training Error:  11.796069951458618\n",
      "====================================================================================================\n",
      "Iteration:  190\n",
      "Previous theta :  [ 0.01193355 -0.04757373  0.01128289  0.07292952  0.05297662  0.08811051\n",
      "  0.51809831  0.04104773  0.09817064  0.08371418 -0.17535709 -0.16310267\n",
      "  0.14817426 -0.24943478]\n",
      "New theta_0 : [ 0.01181359 -0.04776435  0.01115829  0.0722045   0.05302293  0.08588241\n",
      "  0.51636324  0.04020854  0.09497413  0.08481624 -0.17500216 -0.16388999\n",
      "  0.14765369 -0.25087786]\n",
      "Training Error:  11.776279167991028\n",
      "====================================================================================================\n",
      "Iteration:  191\n",
      "Previous theta :  [ 0.01181359 -0.04776435  0.01115829  0.0722045   0.05302293  0.08588241\n",
      "  0.51636324  0.04020854  0.09497413  0.08481624 -0.17500216 -0.16388999\n",
      "  0.14765369 -0.25087786]\n",
      "New theta_0 : [ 0.01169577 -0.0479555   0.01104567  0.07148788  0.05306951  0.08366801\n",
      "  0.51464748  0.03938454  0.09180336  0.08590974 -0.17465099 -0.16466686\n",
      "  0.14714178 -0.25230204]\n",
      "Training Error:  11.756815615985808\n",
      "====================================================================================================\n",
      "Iteration:  192\n",
      "Previous theta :  [ 0.01169577 -0.0479555   0.01104567  0.07148788  0.05306951  0.08366801\n",
      "  0.51464748  0.03938454  0.09180336  0.08590974 -0.17465099 -0.16466686\n",
      "  0.14714178 -0.25230204]\n",
      "New theta_0 : [ 0.01158003 -0.04814718  0.01094476  0.07077955  0.05311634  0.08146722\n",
      "  0.5129508   0.03857548  0.08865808  0.08699475 -0.17430359 -0.16543344\n",
      "  0.14663831 -0.25370757]\n",
      "Training Error:  11.737673333843073\n",
      "====================================================================================================\n",
      "Iteration:  193\n",
      "Previous theta :  [ 0.01158003 -0.04814718  0.01094476  0.07077955  0.05311634  0.08146722\n",
      "  0.5129508   0.03857548  0.08865808  0.08699475 -0.17430359 -0.16543344\n",
      "  0.14663831 -0.25370757]\n",
      "New theta_0 : [ 0.01146632 -0.04833935  0.01085528  0.07007944  0.05316338  0.07927997\n",
      "  0.51127297  0.03778111  0.08553805  0.08807134 -0.17395996 -0.16618988\n",
      "  0.14614311 -0.25509473]\n",
      "Training Error:  11.718846480225237\n",
      "====================================================================================================\n",
      "Iteration:  194\n",
      "Previous theta :  [ 0.01146632 -0.04833935  0.01085528  0.07007944  0.05316338  0.07927997\n",
      "  0.51127297  0.03778111  0.08553805  0.08807134 -0.17395996 -0.16618988\n",
      "  0.14614311 -0.25509473]\n",
      "New theta_0 : [ 0.01135457 -0.048532    0.01077695  0.06938744  0.0532106   0.07710619\n",
      "  0.50961378  0.03700119  0.08244305  0.08913956 -0.17362009 -0.16693631\n",
      "  0.14565599 -0.25646376]\n",
      "Training Error:  11.700329331396407\n",
      "====================================================================================================\n",
      "Iteration:  195\n",
      "Previous theta :  [ 0.01135457 -0.048532    0.01077695  0.06938744  0.0532106   0.07710619\n",
      "  0.50961378  0.03700119  0.08244305  0.08913956 -0.17362009 -0.16693631\n",
      "  0.14565599 -0.25646376]\n",
      "New theta_0 : [ 0.01124474 -0.04872511  0.01070951  0.06870347  0.05325798  0.0749458\n",
      "  0.507973    0.03623547  0.07937285  0.09019948 -0.17328399 -0.16767289\n",
      "  0.14517678 -0.25781491]\n",
      "Training Error:  11.682116278626419\n",
      "====================================================================================================\n",
      "Iteration:  196\n",
      "Previous theta :  [ 0.01124474 -0.04872511  0.01070951  0.06870347  0.05325798  0.0749458\n",
      "  0.507973    0.03623547  0.07937285  0.09019948 -0.17328399 -0.16767289\n",
      "  0.14517678 -0.25781491]\n",
      "New theta_0 : [ 0.01113677 -0.04891864  0.0106527   0.06802745  0.05330548  0.07279873\n",
      "  0.50635043  0.03548371  0.0763272   0.09125116 -0.17295165 -0.16839975\n",
      "  0.14470529 -0.25914843]\n",
      "Training Error:  11.664201825657598\n",
      "====================================================================================================\n",
      "Iteration:  197\n",
      "Previous theta :  [ 0.01113677 -0.04891864  0.0106527   0.06802745  0.05330548  0.07279873\n",
      "  0.50635043  0.03548371  0.0763272   0.09125116 -0.17295165 -0.16839975\n",
      "  0.14470529 -0.25914843]\n",
      "New theta_0 : [ 0.01103061 -0.04911259  0.01060627  0.06735928  0.05335308  0.07066492\n",
      "  0.50474584  0.03474568  0.0733059   0.09229467 -0.17262307 -0.16911703\n",
      "  0.14424135 -0.26046455]\n",
      "Training Error:  11.646580586232535\n",
      "====================================================================================================\n",
      "Iteration:  198\n",
      "Previous theta :  [ 0.01103061 -0.04911259  0.01060627  0.06735928  0.05335308  0.07066492\n",
      "  0.50474584  0.03474568  0.0733059   0.09229467 -0.17262307 -0.16911703\n",
      "  0.14424135 -0.26046455]\n",
      "New theta_0 : [ 0.01092622 -0.04930692  0.01056996  0.06669888  0.05340076  0.06854428\n",
      "  0.50315903  0.03402114  0.07030871  0.09333007 -0.17229824 -0.16982487\n",
      "  0.14378481 -0.26176352]\n",
      "Training Error:  11.629247281681174\n",
      "====================================================================================================\n",
      "Iteration:  199\n",
      "Previous theta :  [ 0.01092622 -0.04930692  0.01056996  0.06669888  0.05340076  0.06854428\n",
      "  0.50315903  0.03402114  0.07030871  0.09333007 -0.17229824 -0.16982487\n",
      "  0.14378481 -0.26176352]\n",
      "New theta_0 : [ 0.01082355 -0.04950161  0.01054353  0.06604617  0.05344849  0.06643674\n",
      "  0.50158979  0.03330988  0.06733542  0.09435743 -0.17197716 -0.17052341\n",
      "  0.14333549 -0.26304558]\n",
      "Training Error:  11.612196738565528\n",
      "====================================================================================================\n",
      "Iteration:  200\n",
      "Previous theta :  [ 0.01082355 -0.04950161  0.01054353  0.06604617  0.05344849  0.06643674\n",
      "  0.50158979  0.03330988  0.06733542  0.09435743 -0.17197716 -0.17052341\n",
      "  0.14333549 -0.26304558]\n",
      "New theta_0 : [ 0.01072256 -0.04969665  0.01052675  0.06540107  0.05349625  0.06434223\n",
      "  0.50003791  0.03261166  0.0643858   0.0953768  -0.17165982 -0.17121276\n",
      "  0.14289325 -0.26431095]\n",
      "Training Error:  11.595423886380466\n",
      "====================================================================================================\n",
      "Iteration:  201\n",
      "Previous theta :  [ 0.01072256 -0.04969665  0.01052675  0.06540107  0.05349625  0.06434223\n",
      "  0.50003791  0.03261166  0.0643858   0.0953768  -0.17165982 -0.17121276\n",
      "  0.14289325 -0.26431095]\n",
      "New theta_0 : [ 0.0106232  -0.04989201  0.01051938  0.06476348  0.05354402  0.06226068\n",
      "  0.49850319  0.03192626  0.06145965  0.09638826 -0.17134622 -0.17189307\n",
      "  0.14245793 -0.26555986]\n",
      "Training Error:  11.578923755309072\n",
      "====================================================================================================\n",
      "Iteration:  202\n",
      "Previous theta :  [ 0.0106232  -0.04989201  0.01051938  0.06476348  0.05354402  0.06226068\n",
      "  0.49850319  0.03192626  0.06145965  0.09638826 -0.17134622 -0.17189307\n",
      "  0.14245793 -0.26555986]\n",
      "New theta_0 : [ 0.01052543 -0.05008767  0.01052119  0.06413333  0.05359178  0.06019202\n",
      "  0.49698542  0.03125347  0.05855674  0.09739187 -0.17103634 -0.17256446\n",
      "  0.14202938 -0.26679254]\n",
      "Training Error:  11.562691474031059\n",
      "====================================================================================================\n",
      "Iteration:  203\n",
      "Previous theta :  [ 0.01052543 -0.05008767  0.01052119  0.06413333  0.05359178  0.06019202\n",
      "  0.49698542  0.03125347  0.05855674  0.09739187 -0.17103634 -0.17256446\n",
      "  0.14202938 -0.26679254]\n",
      "New theta_0 : [ 0.01042921 -0.0502836   0.01053195  0.06351054  0.05363951  0.05813617\n",
      "  0.49548442  0.03059308  0.05567688  0.09838768 -0.17073018 -0.17322706\n",
      "  0.14160746 -0.26800922]\n",
      "Training Error:  11.546722267582881\n",
      "====================================================================================================\n",
      "Iteration:  204\n",
      "Previous theta :  [ 0.01042921 -0.0502836   0.01053195  0.06351054  0.05363951  0.05813617\n",
      "  0.49548442  0.03059308  0.05567688  0.09838768 -0.17073018 -0.17322706\n",
      "  0.14160746 -0.26800922]\n",
      "New theta_0 : [ 0.01033449 -0.05047979  0.01055145  0.06289503  0.05368719  0.05609307\n",
      "  0.49399997  0.02994487  0.05281985  0.09937577 -0.17042772 -0.17388099\n",
      "  0.14119203 -0.26921011]\n",
      "Training Error:  11.531011455268088\n",
      "====================================================================================================\n",
      "Iteration:  205\n",
      "Previous theta :  [ 0.01033449 -0.05047979  0.01055145  0.06289503  0.05368719  0.05609307\n",
      "  0.49399997  0.02994487  0.05281985  0.09937577 -0.17042772 -0.17388099\n",
      "  0.14119203 -0.26921011]\n",
      "New theta_0 : [ 0.01024125 -0.05067621  0.01057947  0.06228672  0.05373481  0.05406264\n",
      "  0.49253189  0.02930864  0.04998544  0.10035621 -0.17012896 -0.17452638\n",
      "  0.14078294 -0.27039542]\n",
      "Training Error:  11.515554448616705\n",
      "====================================================================================================\n",
      "Iteration:  206\n",
      "Previous theta :  [ 0.01024125 -0.05067621  0.01057947  0.06228672  0.05373481  0.05406264\n",
      "  0.49253189  0.02930864  0.04998544  0.10035621 -0.17012896 -0.17452638\n",
      "  0.14078294 -0.27039542]\n",
      "New theta_0 : [ 0.01014945 -0.05087285  0.01061579  0.06168554  0.05378235  0.05204481\n",
      "  0.49107998  0.02868418  0.04717346  0.10132904 -0.16983388 -0.17516334\n",
      "  0.14038007 -0.27156537]\n",
      "Training Error:  11.500346749392275\n",
      "====================================================================================================\n",
      "Iteration:  207\n",
      "Previous theta :  [ 0.01014945 -0.05087285  0.01061579  0.06168554  0.05378235  0.05204481\n",
      "  0.49107998  0.02868418  0.04717346  0.10132904 -0.16983388 -0.17516334\n",
      "  0.14038007 -0.27156537]\n",
      "New theta_0 : [ 0.01005904 -0.05106967  0.01066022  0.0610914   0.05382979  0.05003951\n",
      "  0.48964405  0.0280713   0.0443837   0.10229434 -0.16954247 -0.17579199\n",
      "  0.13998328 -0.27272018]\n",
      "Training Error:  11.485383947645376\n",
      "====================================================================================================\n",
      "Iteration:  208\n",
      "Previous theta :  [ 0.01005904 -0.05106967  0.01066022  0.0610914   0.05382979  0.05003951\n",
      "  0.48964405  0.0280713   0.0443837   0.10229434 -0.16954247 -0.17579199\n",
      "  0.13998328 -0.27272018]\n",
      "New theta_0 : [ 0.00997    -0.05126667  0.01071255  0.06050423  0.05387713  0.04804667\n",
      "  0.48822393  0.02746979  0.04161597  0.10325217 -0.16925473 -0.17641244\n",
      "  0.13959245 -0.27386004]\n",
      "Training Error:  11.470661719812377\n",
      "====================================================================================================\n",
      "Iteration:  209\n",
      "Previous theta :  [ 0.00997    -0.05126667  0.01071255  0.06050423  0.05387713  0.04804667\n",
      "  0.48822393  0.02746979  0.04161597  0.10325217 -0.16925473 -0.17641244\n",
      "  0.13959245 -0.27386004]\n",
      "New theta_0 : [ 0.00988229 -0.05146381  0.01077258  0.05992396  0.05392434  0.04606623\n",
      "  0.48681941  0.02687946  0.03887006  0.10420259 -0.16897062 -0.17702483\n",
      "  0.13920745 -0.27498516]\n",
      "Training Error:  11.456175826858349\n",
      "====================================================================================================\n",
      "Iteration:  210\n",
      "Previous theta :  [ 0.00988229 -0.05146381  0.01077258  0.05992396  0.05392434  0.04606623\n",
      "  0.48681941  0.02687946  0.03887006  0.10420259 -0.16897062 -0.17702483\n",
      "  0.13920745 -0.27498516]\n",
      "New theta_0 : [ 0.00979587 -0.05166108  0.01084012  0.05935051  0.05397141  0.0440981\n",
      "  0.48543032  0.02630012  0.03614579  0.10514566 -0.16869015 -0.17762925\n",
      "  0.13882816 -0.27609574]\n",
      "Training Error:  11.441922112462901\n",
      "====================================================================================================\n",
      "Iteration:  211\n",
      "Previous theta :  [ 0.00979587 -0.05166108  0.01084012  0.05935051  0.05397141  0.0440981\n",
      "  0.48543032  0.02630012  0.03614579  0.10514566 -0.16869015 -0.17762925\n",
      "  0.13882816 -0.27609574]\n",
      "New theta_0 : [ 0.00971073 -0.05185846  0.01091498  0.0587838   0.05401833  0.04214223\n",
      "  0.48405648  0.02573158  0.03344296  0.10608146 -0.1684133  -0.17822582\n",
      "  0.13845447 -0.27719199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  11.427896501247973\n",
      "====================================================================================================\n",
      "Iteration:  212\n",
      "Previous theta :  [ 0.00971073 -0.05185846  0.01091498  0.0587838   0.05401833  0.04214223\n",
      "  0.48405648  0.02573158  0.03344296  0.10608146 -0.1684133  -0.17822582\n",
      "  0.13845447 -0.27719199]\n",
      "New theta_0 : [ 0.00962682 -0.05205592  0.01099696  0.05822378  0.05406509  0.04019854\n",
      "  0.4826977   0.02517366  0.03076138  0.10701004 -0.16814005 -0.17881464\n",
      "  0.13808625 -0.27827409]\n",
      "Training Error:  11.414094997046426\n",
      "====================================================================================================\n",
      "Iteration:  213\n",
      "Previous theta :  [ 0.00962682 -0.05205592  0.01099696  0.05822378  0.05406509  0.04019854\n",
      "  0.4826977   0.02517366  0.03076138  0.10701004 -0.16814005 -0.17881464\n",
      "  0.13808625 -0.27827409]\n",
      "New theta_0 : [ 0.00954412 -0.05225345  0.0110859   0.05767035  0.05411168  0.03826697\n",
      "  0.48135381  0.02462618  0.02810087  0.10793146 -0.16787039 -0.17939583\n",
      "  0.13772341 -0.27934224]\n",
      "Training Error:  11.400513681210505\n",
      "====================================================================================================\n",
      "Iteration:  214\n",
      "Previous theta :  [ 0.00954412 -0.05225345  0.0110859   0.05767035  0.05411168  0.03826697\n",
      "  0.48135381  0.02462618  0.02810087  0.10793146 -0.16787039 -0.17939583\n",
      "  0.13772341 -0.27934224]\n",
      "New theta_0 : [ 0.00946259 -0.05245103  0.01118161  0.05712347  0.05415809  0.03634744\n",
      "  0.48002464  0.02408895  0.02546123  0.10884579 -0.16760429 -0.1799695\n",
      "  0.13736582 -0.28039663]\n",
      "Training Error:  11.387148710959105\n",
      "====================================================================================================\n",
      "Iteration:  215\n",
      "Previous theta :  [ 0.00946259 -0.05245103  0.01118161  0.05712347  0.05415809  0.03634744\n",
      "  0.48002464  0.02408895  0.02546123  0.10884579 -0.16760429 -0.1799695\n",
      "  0.13736582 -0.28039663]\n",
      "New theta_0 : [ 0.00938222 -0.05264863  0.01128391  0.05658304  0.05420431  0.03443988\n",
      "  0.47871001  0.0235618   0.02284229  0.10975308 -0.16734175 -0.18053574\n",
      "  0.13701339 -0.28143744]\n",
      "Training Error:  11.373996317762934\n",
      "====================================================================================================\n",
      "Iteration:  216\n",
      "Previous theta :  [ 0.00938222 -0.05264863  0.01128391  0.05658304  0.05420431  0.03443988\n",
      "  0.47871001  0.0235618   0.02284229  0.10975308 -0.16734175 -0.18053574\n",
      "  0.13701339 -0.28143744]\n",
      "New theta_0 : [ 0.00930297 -0.05284625  0.01139263  0.05604902  0.05425033  0.03254424\n",
      "  0.47740975  0.02304455  0.02024387  0.1106534  -0.16708275 -0.18109466\n",
      "  0.13666601 -0.28246487]\n",
      "Training Error:  11.361052805766608\n",
      "====================================================================================================\n",
      "Iteration:  217\n",
      "Previous theta :  [ 0.00930297 -0.05284625  0.01139263  0.05604902  0.05425033  0.03254424\n",
      "  0.47740975  0.02304455  0.02024387  0.1106534  -0.16708275 -0.18109466\n",
      "  0.13666601 -0.28246487]\n",
      "New theta_0 : [ 0.00922482 -0.05304385  0.01150762  0.05552131  0.05429614  0.03066044\n",
      "  0.47612369  0.02253705  0.01766578  0.11154682 -0.16682726 -0.18164637\n",
      "  0.13632358 -0.28347909]\n",
      "Training Error:  11.348314550246801\n",
      "====================================================================================================\n",
      "Iteration:  218\n",
      "Previous theta :  [ 0.00922482 -0.05304385  0.01150762  0.05552131  0.05429614  0.03066044\n",
      "  0.47612369  0.02253705  0.01766578  0.11154682 -0.16682726 -0.18164637\n",
      "  0.13632358 -0.28347909]\n",
      "New theta_0 : [ 0.00914774 -0.05324142  0.01162869  0.05499987  0.05434173  0.02878841\n",
      "  0.47485167  0.02203911  0.01510784  0.11243338 -0.16657528 -0.18219095\n",
      "  0.135986   -0.28448028]\n",
      "Training Error:  11.335777996105538\n",
      "====================================================================================================\n",
      "Iteration:  219\n",
      "Previous theta :  [ 0.00914774 -0.05324142  0.01162869  0.05499987  0.05434173  0.02878841\n",
      "  0.47485167  0.02203911  0.01510784  0.11243338 -0.16657528 -0.18219095\n",
      "  0.135986   -0.28448028]\n",
      "New theta_0 : [ 0.00907171 -0.05343894  0.0117557   0.05448462  0.0543871   0.02692808\n",
      "  0.47359352  0.02155057  0.01256989  0.11331316 -0.16632678 -0.18272852\n",
      "  0.13565317 -0.28546862]\n",
      "Training Error:  11.323439656397792\n",
      "====================================================================================================\n",
      "Iteration:  220\n",
      "Previous theta :  [ 0.00907171 -0.05343894  0.0117557   0.05448462  0.0543871   0.02692808\n",
      "  0.47359352  0.02155057  0.01256989  0.11331316 -0.16632678 -0.18272852\n",
      "  0.13565317 -0.28546862]\n",
      "New theta_0 : [ 0.0089967  -0.0536364   0.01188848  0.0539755   0.05443224  0.0250794\n",
      "  0.47234908  0.02107127  0.01005174  0.11418621 -0.16608175 -0.18325917\n",
      "  0.135325   -0.28644428]\n",
      "Training Error:  11.311296110892574\n",
      "====================================================================================================\n",
      "Iteration:  221\n",
      "Previous theta :  [ 0.0089967  -0.0536364   0.01188848  0.0539755   0.05443224  0.0250794\n",
      "  0.47234908  0.02107127  0.01005174  0.11418621 -0.16608175 -0.18325917\n",
      "  0.135325   -0.28644428]\n",
      "New theta_0 : [ 0.0089227  -0.05383377  0.01202688  0.05347244  0.05447714  0.02324229\n",
      "  0.47111819  0.02060105  0.00755323  0.11505259 -0.16584016 -0.18378299\n",
      "  0.13500141 -0.28740744]\n",
      "Training Error:  11.299344004666663\n",
      "====================================================================================================\n",
      "Iteration:  222\n",
      "Previous theta :  [ 0.0089227  -0.05383377  0.01202688  0.05347244  0.05447714  0.02324229\n",
      "  0.47111819  0.02060105  0.00755323  0.11505259 -0.16584016 -0.18378299\n",
      "  0.13500141 -0.28740744]\n",
      "New theta_0 : [ 0.00884967 -0.05403103  0.01217074  0.05297538  0.0545218   0.02141669\n",
      "  0.46990069  0.02013975  0.00507418  0.11591236 -0.165602   -0.18430009\n",
      "  0.13468229 -0.28835826]\n",
      "Training Error:  11.28758004673023\n",
      "====================================================================================================\n",
      "Iteration:  223\n",
      "Previous theta :  [ 0.00884967 -0.05403103  0.01217074  0.05297538  0.0545218   0.02141669\n",
      "  0.46990069  0.02013975  0.00507418  0.11591236 -0.165602   -0.18430009\n",
      "  0.13468229 -0.28835826]\n",
      "New theta_0 : [ 0.0087776  -0.05422818  0.01231993  0.05248425  0.0545662   0.01960252\n",
      "  0.46869641  0.01968722  0.00261443  0.11676559 -0.16536725 -0.18481054\n",
      "  0.13436757 -0.28929692]\n",
      "Training Error:  11.276001008683561\n",
      "====================================================================================================\n",
      "Iteration:  224\n",
      "Previous theta :  [ 0.0087776  -0.05422818  0.01231993  0.05248425  0.0545662   0.01960252\n",
      "  0.46869641  0.01968722  0.00261443  0.11676559 -0.16536725 -0.18481054\n",
      "  0.13436757 -0.28929692]\n",
      "New theta_0 : [ 8.70647037e-03 -5.44251880e-02  1.24742921e-02  5.19989896e-02\n",
      "  5.46103535e-02  1.77997355e-02  4.67505217e-01  1.92433108e-02\n",
      "  1.73806878e-04  1.17612325e-01 -1.65135887e-01 -1.85314448e-01\n",
      "  1.34057164e-01 -2.90223567e-01]\n",
      "Training Error:  11.264603723404178\n",
      "====================================================================================================\n",
      "Iteration:  225\n",
      "Previous theta :  [ 8.70647037e-03 -5.44251880e-02  1.24742921e-02  5.19989896e-02\n",
      "  5.46103535e-02  1.77997355e-02  4.67505217e-01  1.92433108e-02\n",
      "  1.73806878e-04  1.17612325e-01 -1.65135887e-01 -1.85314448e-01\n",
      "  1.34057164e-01 -2.90223567e-01]\n",
      "New theta_0 : [ 0.00863625 -0.05462204  0.01263369  0.05151954  0.05465425  0.01600826\n",
      "  0.46632694  0.01880786 -0.00224785  0.11845263 -0.16490789 -0.1858119\n",
      "  0.13375098 -0.29113838]\n",
      "Training Error:  11.253385083763565\n",
      "====================================================================================================\n",
      "Iteration:  226\n",
      "Previous theta :  [ 0.00863625 -0.05462204  0.01263369  0.05151954  0.05465425  0.01600826\n",
      "  0.46632694  0.01880786 -0.00224785  0.11845263 -0.16490789 -0.1858119\n",
      "  0.13375098 -0.29113838]\n",
      "New theta_0 : [ 0.00856693 -0.05481872  0.01279798  0.05104583  0.05469787  0.01422802\n",
      "  0.46516144  0.01838073 -0.00465071  0.11928656 -0.16468324 -0.18630299\n",
      "  0.13344894 -0.29204151]\n",
      "Training Error:  11.24234204137286\n",
      "====================================================================================================\n",
      "Iteration:  227\n",
      "Previous theta :  [ 0.00856693 -0.05481872  0.01279798  0.05104583  0.05469787  0.01422802\n",
      "  0.46516144  0.01838073 -0.00465071  0.11928656 -0.16468324 -0.18630299\n",
      "  0.13344894 -0.29204151]\n",
      "New theta_0 : [ 0.00849849 -0.05501522  0.01296702  0.05057782  0.05474123  0.01245897\n",
      "  0.46400856  0.01796178 -0.00703493  0.12011418 -0.16446192 -0.18678779\n",
      "  0.13315098 -0.29293312]\n",
      "Training Error:  11.231471605356791\n",
      "====================================================================================================\n",
      "Iteration:  228\n",
      "Previous theta :  [ 0.00849849 -0.05501522  0.01296702  0.05057782  0.05474123  0.01245897\n",
      "  0.46400856  0.01796178 -0.00703493  0.12011418 -0.16446192 -0.18678779\n",
      "  0.13315098 -0.29293312]\n",
      "New theta_0 : [ 0.0084309  -0.0552115   0.01314069  0.05011542  0.05478432  0.01070103\n",
      "  0.46286816  0.01755085 -0.00940066  0.12093553 -0.16424391 -0.18726641\n",
      "  0.132857   -0.29381336]\n",
      "Training Error:  11.220770841155204\n",
      "====================================================================================================\n",
      "Iteration:  229\n",
      "Previous theta :  [ 0.0084309  -0.0552115   0.01314069  0.05011542  0.05478432  0.01070103\n",
      "  0.46286816  0.01755085 -0.00940066  0.12093553 -0.16424391 -0.18726641\n",
      "  0.132857   -0.29381336]\n",
      "New theta_0 : [ 0.00836415 -0.05540757  0.01331886  0.04965859  0.05482713  0.00895415\n",
      "  0.46174008  0.01714782 -0.01174808  0.12175069 -0.16402918 -0.18773892\n",
      "  0.13256694 -0.29468238]\n",
      "Training Error:  11.21023686935149\n",
      "====================================================================================================\n",
      "Iteration:  230\n",
      "Previous theta :  [ 0.00836415 -0.05540757  0.01331886  0.04965859  0.05482713  0.00895415\n",
      "  0.46174008  0.01714782 -0.01174808  0.12175069 -0.16402918 -0.18773892\n",
      "  0.13256694 -0.29468238]\n",
      "New theta_0 : [ 0.00829823 -0.0556034   0.01350139  0.04920727  0.05486966  0.00721825\n",
      "  0.46062419  0.01675254 -0.01407733  0.12255971 -0.16381772 -0.18820541\n",
      "  0.13228072 -0.29554034]\n",
      "Training Error:  11.199866864527346\n",
      "====================================================================================================\n",
      "Iteration:  231\n",
      "Previous theta :  [ 0.00829823 -0.0556034   0.01350139  0.04920727  0.05486966  0.00721825\n",
      "  0.46062419  0.01675254 -0.01407733  0.12255971 -0.16381772 -0.18820541\n",
      "  0.13228072 -0.29554034]\n",
      "New theta_0 : [ 0.00823311 -0.05579898  0.01368816  0.0487614   0.0549119   0.00549327\n",
      "  0.45952033  0.01636487 -0.01638857  0.12336263 -0.16360951 -0.18866595\n",
      "  0.13199828 -0.29638739]\n",
      "Training Error:  11.189658054143182\n",
      "====================================================================================================\n",
      "Iteration:  232\n",
      "Previous theta :  [ 0.00823311 -0.05579898  0.01368816  0.0487614   0.0549119   0.00549327\n",
      "  0.45952033  0.01636487 -0.01638857  0.12336263 -0.16360951 -0.18866595\n",
      "  0.13199828 -0.29638739]\n",
      "New theta_0 : [ 0.00816878 -0.0559943   0.01387905  0.04832092  0.05495386  0.00377915\n",
      "  0.45842838  0.01598469 -0.01868196  0.12415952 -0.16340451 -0.18912064\n",
      "  0.13171954 -0.29722367]\n",
      "Training Error:  11.179607717443611\n",
      "====================================================================================================\n",
      "Iteration:  233\n",
      "Previous theta :  [ 0.00816878 -0.0559943   0.01387905  0.04832092  0.05495386  0.00377915\n",
      "  0.45842838  0.01598469 -0.01868196  0.12415952 -0.16340451 -0.18912064\n",
      "  0.13171954 -0.29722367]\n",
      "New theta_0 : [ 0.00810522 -0.05618933  0.01407394  0.04788577  0.05499554  0.00207583\n",
      "  0.45734819  0.01561186 -0.02095764  0.12495044 -0.16320272 -0.18956955\n",
      "  0.13144444 -0.29804934]\n",
      "Training Error:  11.169713184387428\n",
      "====================================================================================================\n",
      "Iteration:  234\n",
      "Previous theta :  [ 0.00810522 -0.05618933  0.01407394  0.04788577  0.05499554  0.00207583\n",
      "  0.45734819  0.01561186 -0.02095764  0.12495044 -0.16320272 -0.18956955\n",
      "  0.13144444 -0.29804934]\n",
      "New theta_0 : [ 8.04241754e-03 -5.63840689e-02  1.42727095e-02  4.74559049e-02\n",
      "  5.50369222e-02  3.83249862e-04  4.56279623e-01  1.52462573e-02\n",
      " -2.32157612e-02  1.25735438e-01 -1.63004105e-01 -1.90012766e-01\n",
      "  1.31172899e-01 -2.98864517e-01]\n",
      "Training Error:  11.159971834601475\n",
      "====================================================================================================\n",
      "Iteration:  235\n",
      "Previous theta :  [ 8.04241754e-03 -5.63840689e-02  1.42727095e-02  4.74559049e-02\n",
      "  5.50369222e-02  3.83249862e-04  4.56279623e-01  1.52462573e-02\n",
      " -2.32157612e-02  1.25735438e-01 -1.63004105e-01 -1.90012766e-01\n",
      "  1.31172899e-01 -2.98864517e-01]\n",
      "New theta_0 : [ 0.00798036 -0.0565785   0.01447524  0.04703126  0.05507801 -0.00129866\n",
      "  0.45522254  0.01488775 -0.02545648  0.12651457 -0.16280865 -0.19045036\n",
      "  0.13090487 -0.29966936]\n",
      "Training Error:  11.150381096357881\n",
      "====================================================================================================\n",
      "Iteration:  236\n",
      "Previous theta :  [ 0.00798036 -0.0565785   0.01447524  0.04703126  0.05507801 -0.00129866\n",
      "  0.45522254  0.01488775 -0.02545648  0.12651457 -0.16280865 -0.19045036\n",
      "  0.13090487 -0.29966936]\n",
      "New theta_0 : [ 0.00791903 -0.0567726   0.01468143  0.04661178  0.05511881 -0.00296996\n",
      "  0.45417682  0.01453621 -0.02767994  0.12728788 -0.16261633 -0.19088241\n",
      "  0.13064027 -0.300464  ]\n",
      "Training Error:  11.140938445574077\n",
      "====================================================================================================\n",
      "Iteration:  237\n",
      "Previous theta :  [ 0.00791903 -0.0567726   0.01468143  0.04661178  0.05511881 -0.00296996\n",
      "  0.45417682  0.01453621 -0.02767994  0.12728788 -0.16261633 -0.19088241\n",
      "  0.13064027 -0.300464  ]\n",
      "New theta_0 : [ 0.00785841 -0.05696637  0.01489116  0.04619741  0.05515931 -0.00463072\n",
      "  0.45314231  0.01419152 -0.02988629  0.12805544 -0.16242712 -0.19130899\n",
      "  0.13037906 -0.30124859]\n",
      "Training Error:  11.131641404835115\n",
      "====================================================================================================\n",
      "Iteration:  238\n",
      "Previous theta :  [ 0.00785841 -0.05696637  0.01489116  0.04619741  0.05515931 -0.00463072\n",
      "  0.45314231  0.01419152 -0.02988629  0.12805544 -0.16242712 -0.19130899\n",
      "  0.13037906 -0.30124859]\n",
      "New theta_0 : [ 0.00779848 -0.05715978  0.01510432  0.0457881   0.05519952 -0.00628099\n",
      "  0.4521189   0.01385356 -0.03207567  0.1288173  -0.16224101 -0.19173018\n",
      "  0.13012117 -0.30202324]\n",
      "Training Error:  11.122487542437693\n",
      "====================================================================================================\n",
      "Iteration:  239\n",
      "Previous theta :  [ 0.00779848 -0.05715978  0.01510432  0.0457881   0.05519952 -0.00628099\n",
      "  0.4521189   0.01385356 -0.03207567  0.1288173  -0.16224101 -0.19173018\n",
      "  0.13012117 -0.30202324]\n",
      "New theta_0 : [ 0.00773925 -0.05735283  0.01532081  0.04538379  0.05523943 -0.00792083\n",
      "  0.45110645  0.01352221 -0.03424822  0.1295735  -0.16205797 -0.19214605\n",
      "  0.12986653 -0.3027881 ]\n",
      "Training Error:  11.113474471455467\n",
      "====================================================================================================\n",
      "Iteration:  240\n",
      "Previous theta :  [ 0.00773925 -0.05735283  0.01532081  0.04538379  0.05523943 -0.00792083\n",
      "  0.45110645  0.01352221 -0.03424822  0.1295735  -0.16205797 -0.19214605\n",
      "  0.12986653 -0.3027881 ]\n",
      "New theta_0 : [ 0.00768068 -0.0575455   0.01554052  0.04498444  0.05527903 -0.00955031\n",
      "  0.45010483  0.01319735 -0.03640409  0.1303241  -0.16187797 -0.19255668\n",
      "  0.1296151  -0.3035433 ]\n",
      "Training Error:  11.104599848825082\n",
      "====================================================================================================\n",
      "Iteration:  241\n",
      "Previous theta :  [ 0.00768068 -0.0575455   0.01554052  0.04498444  0.05527903 -0.00955031\n",
      "  0.45010483  0.01319735 -0.03640409  0.1303241  -0.16187797 -0.19255668\n",
      "  0.1296151  -0.3035433 ]\n",
      "New theta_0 : [ 0.00762278 -0.05773779  0.01576336  0.04458999  0.05531834 -0.01116948\n",
      "  0.44911391  0.01287887 -0.03854341  0.13106915 -0.161701   -0.19296213\n",
      "  0.12936682 -0.30428896]\n",
      "Training Error:  11.095861374452475\n",
      "====================================================================================================\n",
      "Iteration:  242\n",
      "Previous theta :  [ 0.00762278 -0.05773779  0.01576336  0.04458999  0.05531834 -0.01116948\n",
      "  0.44911391  0.01287887 -0.03854341  0.13106915 -0.161701   -0.19296213\n",
      "  0.12936682 -0.30428896]\n",
      "New theta_0 : [ 0.00756552 -0.05792967  0.01598922  0.04420038  0.05535735 -0.01277841\n",
      "  0.44813358  0.01256666 -0.04066633  0.13180871 -0.16152704 -0.19336248\n",
      "  0.12912162 -0.30502522]\n",
      "Training Error:  11.087256790338982\n",
      "====================================================================================================\n",
      "Iteration:  243\n",
      "Previous theta :  [ 0.00756552 -0.05792967  0.01598922  0.04420038  0.05535735 -0.01277841\n",
      "  0.44813358  0.01256666 -0.04066633  0.13180871 -0.16152704 -0.19336248\n",
      "  0.12912162 -0.30502522]\n",
      "New theta_0 : [ 0.0075089  -0.05812114  0.01621801  0.04381557  0.05539605 -0.01437716\n",
      "  0.44716371  0.01226059 -0.04277299  0.13254282 -0.16135605 -0.19375779\n",
      "  0.12887947 -0.3057522 ]\n",
      "Training Error:  11.078783879726764\n",
      "====================================================================================================\n",
      "Iteration:  244\n",
      "Previous theta :  [ 0.0075089  -0.05812114  0.01621801  0.04381557  0.05539605 -0.01437716\n",
      "  0.44716371  0.01226059 -0.04277299  0.13254282 -0.16135605 -0.19375779\n",
      "  0.12887947 -0.3057522 ]\n",
      "New theta_0 : [ 0.0074529  -0.05831218  0.01644963  0.04343551  0.05543446 -0.01596578\n",
      "  0.44620417  0.01196058 -0.0448635   0.13327154 -0.16118803 -0.19414814\n",
      "  0.1286403  -0.30647002]\n",
      "Training Error:  11.070440466263133\n",
      "====================================================================================================\n",
      "Iteration:  245\n",
      "Previous theta :  [ 0.0074529  -0.05831218  0.01644963  0.04343551  0.05543446 -0.01596578\n",
      "  0.44620417  0.01196058 -0.0448635   0.13327154 -0.16118803 -0.19414814\n",
      "  0.1286403  -0.30647002]\n",
      "New theta_0 : [ 0.00739751 -0.05850279  0.01668399  0.04306015  0.05547256 -0.01754434\n",
      "  0.44525486  0.0116665  -0.04693803  0.13399492 -0.16102294 -0.19453359\n",
      "  0.12840406 -0.30717881]\n",
      "Training Error:  11.062224413183309\n",
      "====================================================================================================\n",
      "Iteration:  246\n",
      "Previous theta :  [ 0.00739751 -0.05850279  0.01668399  0.04306015  0.05547256 -0.01754434\n",
      "  0.44525486  0.0116665  -0.04693803  0.13399492 -0.16102294 -0.19453359\n",
      "  0.12840406 -0.30717881]\n",
      "New theta_0 : [ 0.00734272 -0.05869295  0.01692099  0.04268943  0.05551036 -0.01911289\n",
      "  0.44431564  0.01137825 -0.04899668  0.134713   -0.16086076 -0.19491421\n",
      "  0.12817071 -0.30787869]\n",
      "Training Error:  11.054133622511218\n",
      "====================================================================================================\n",
      "Iteration:  247\n",
      "Previous theta :  [ 0.00734272 -0.05869295  0.01692099  0.04268943  0.05551036 -0.01911289\n",
      "  0.44431564  0.01137825 -0.04899668  0.134713   -0.16086076 -0.19491421\n",
      "  0.12817071 -0.30787869]\n",
      "New theta_0 : [ 0.00728852 -0.05888265  0.01716055  0.04232331  0.05554785 -0.0206715\n",
      "  0.4433864   0.01109572 -0.05103961  0.13542584 -0.16070147 -0.19529007\n",
      "  0.1279402  -0.30856977]\n",
      "Training Error:  11.046166034277865\n",
      "====================================================================================================\n",
      "Iteration:  248\n",
      "Previous theta :  [ 0.00728852 -0.05888265  0.01716055  0.04232331  0.05554785 -0.0206715\n",
      "  0.4433864   0.01109572 -0.05103961  0.13542584 -0.16070147 -0.19529007\n",
      "  0.1279402  -0.30856977]\n",
      "New theta_0 : [ 0.0072349  -0.05907188  0.01740258  0.04196174  0.05558505 -0.02222022\n",
      "  0.44246702  0.01081883 -0.05306693  0.13613348 -0.16054506 -0.19566123\n",
      "  0.12771247 -0.30925217]\n",
      "Training Error:  11.038319625756934\n",
      "====================================================================================================\n",
      "Iteration:  249\n",
      "Previous theta :  [ 0.0072349  -0.05907188  0.01740258  0.04196174  0.05558505 -0.02222022\n",
      "  0.44246702  0.01081883 -0.05306693  0.13613348 -0.16054506 -0.19566123\n",
      "  0.12771247 -0.30925217]\n",
      "New theta_0 : [ 0.00718185 -0.05926062  0.017647    0.04160467  0.05562194 -0.02375911\n",
      "  0.4415574   0.01054746 -0.05507878  0.13683598 -0.16039149 -0.19602775\n",
      "  0.12748748 -0.30992601]\n",
      "Training Error:  11.03059241071715\n",
      "====================================================================================================\n",
      "Iteration:  250\n",
      "Previous theta :  [ 0.00718185 -0.05926062  0.017647    0.04160467  0.05562194 -0.02375911\n",
      "  0.4415574   0.01054746 -0.05507878  0.13683598 -0.16039149 -0.19602775\n",
      "  0.12748748 -0.30992601]\n",
      "New theta_0 : [ 0.00712936 -0.05944888  0.01789372  0.04125206  0.05565853 -0.02528823\n",
      "  0.44065741  0.01028151 -0.05707529  0.13753338 -0.16024074 -0.1963897\n",
      "  0.12726519 -0.31059141]\n",
      "Training Error:  11.022982438691074\n",
      "====================================================================================================\n",
      "Iteration:  251\n",
      "Previous theta :  [ 0.00712936 -0.05944888  0.01789372  0.04125206  0.05565853 -0.02528823\n",
      "  0.44065741  0.01028151 -0.05707529  0.13753338 -0.16024074 -0.1963897\n",
      "  0.12726519 -0.31059141]\n",
      "New theta_0 : [ 0.00707741 -0.05963664  0.01814265  0.04090385  0.05569482 -0.02680764\n",
      "  0.43976695  0.0100209  -0.05905658  0.13822573 -0.1600928  -0.19674713\n",
      "  0.12704555 -0.31124847]\n",
      "Training Error:  11.01548779425991\n",
      "====================================================================================================\n",
      "Iteration:  252\n",
      "Previous theta :  [ 0.00707741 -0.05963664  0.01814265  0.04090385  0.05569482 -0.02680764\n",
      "  0.43976695  0.0100209  -0.05905658  0.13822573 -0.1600928  -0.19674713\n",
      "  0.12704555 -0.31124847]\n",
      "New theta_0 : [ 0.00702601 -0.05982389  0.01839372  0.04056001  0.05573081 -0.02831739\n",
      "  0.43888591  0.00976552 -0.06102278  0.13891308 -0.15994764 -0.19710012\n",
      "  0.12682852 -0.3118973 ]\n",
      "Training Error:  11.008106596353985\n",
      "====================================================================================================\n",
      "Iteration:  253\n",
      "Previous theta :  [ 0.00702601 -0.05982389  0.01839372  0.04056001  0.05573081 -0.02831739\n",
      "  0.43888591  0.00976552 -0.06102278  0.13891308 -0.15994764 -0.19710012\n",
      "  0.12682852 -0.3118973 ]\n",
      "New theta_0 : [ 0.00697513 -0.06001062  0.01864685  0.04022048  0.0557665  -0.02981754\n",
      "  0.43801417  0.00951528 -0.06297402  0.13959548 -0.15980523 -0.19744872\n",
      "  0.12661405 -0.31253802]\n",
      "Training Error:  11.000836997568515\n",
      "====================================================================================================\n",
      "Iteration:  254\n",
      "Previous theta :  [ 0.00697513 -0.06001062  0.01864685  0.04022048  0.0557665  -0.02981754\n",
      "  0.43801417  0.00951528 -0.06297402  0.13959548 -0.15980523 -0.19744872\n",
      "  0.12661405 -0.31253802]\n",
      "New theta_0 : [ 0.00692478 -0.06019682  0.01890197  0.03988522  0.05580189 -0.03130815\n",
      "  0.43715163  0.00927008 -0.06491041  0.14027296 -0.15966555 -0.19779299\n",
      "  0.1264021  -0.31317074]\n",
      "Training Error:  10.993677183494304\n",
      "====================================================================================================\n",
      "Iteration:  255\n",
      "Previous theta :  [ 0.00692478 -0.06019682  0.01890197  0.03988522  0.05580189 -0.03130815\n",
      "  0.43715163  0.00927008 -0.06491041  0.14027296 -0.15966555 -0.19779299\n",
      "  0.1264021  -0.31317074]\n",
      "New theta_0 : [ 0.00687494 -0.06038248  0.01915899  0.03955419  0.05583698 -0.03278928\n",
      "  0.43629818  0.00902985 -0.06683208  0.14094559 -0.15952859 -0.19813299\n",
      "  0.12619264 -0.31379555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.986625372063072\n",
      "====================================================================================================\n",
      "Iteration:  256\n",
      "Previous theta :  [ 0.00687494 -0.06038248  0.01915899  0.03955419  0.05583698 -0.03278928\n",
      "  0.43629818  0.00902985 -0.06683208  0.14094559 -0.15952859 -0.19813299\n",
      "  0.12619264 -0.31379555]\n",
      "New theta_0 : [ 0.0068256  -0.0605676   0.01941785  0.03922733  0.05587178 -0.03426097\n",
      "  0.43545372  0.00879448 -0.06873915  0.1416134  -0.15939432 -0.19846878\n",
      "  0.12598561 -0.31441256]\n",
      "Training Error:  10.979679812907007\n",
      "====================================================================================================\n",
      "Iteration:  257\n",
      "Previous theta :  [ 0.0068256  -0.0605676   0.01941785  0.03922733  0.05587178 -0.03426097\n",
      "  0.43545372  0.00879448 -0.06873915  0.1416134  -0.15939432 -0.19846878\n",
      "  0.12598561 -0.31441256]\n",
      "New theta_0 : [ 0.00677676 -0.06075216  0.01967847  0.03890462  0.05590627 -0.03572329\n",
      "  0.43461814  0.0085639  -0.07063174  0.14227643 -0.15926272 -0.19880041\n",
      "  0.12578099 -0.31502188]\n",
      "Training Error:  10.972838786732272\n",
      "====================================================================================================\n",
      "Iteration:  258\n",
      "Previous theta :  [ 0.00677676 -0.06075216  0.01967847  0.03890462  0.05590627 -0.03572329\n",
      "  0.43461814  0.0085639  -0.07063174  0.14227643 -0.15926272 -0.19880041\n",
      "  0.12578099 -0.31502188]\n",
      "New theta_0 : [ 0.00672841 -0.06093616  0.01994078  0.03858599  0.05594048 -0.0371763\n",
      "  0.43379135  0.008338   -0.07250996  0.14293474 -0.15913376 -0.19912794\n",
      "  0.12557874 -0.31562361]\n",
      "Training Error:  10.96610060470612\n",
      "====================================================================================================\n",
      "Iteration:  259\n",
      "Previous theta :  [ 0.00672841 -0.06093616  0.01994078  0.03858599  0.05594048 -0.0371763\n",
      "  0.43379135  0.008338   -0.07250996  0.14293474 -0.15913376 -0.19912794\n",
      "  0.12557874 -0.31562361]\n",
      "New theta_0 : [ 0.00668053 -0.06111959  0.02020471  0.03827142  0.05597438 -0.03862004\n",
      "  0.43297323  0.00811672 -0.07437395  0.14358837 -0.15900743 -0.19945143\n",
      "  0.12537881 -0.31621785]\n",
      "Training Error:  10.959463607857302\n",
      "====================================================================================================\n",
      "Iteration:  260\n",
      "Previous theta :  [ 0.00668053 -0.06111959  0.02020471  0.03827142  0.05597438 -0.03862004\n",
      "  0.43297323  0.00811672 -0.07437395  0.14358837 -0.15900743 -0.19945143\n",
      "  0.12537881 -0.31621785]\n",
      "New theta_0 : [ 0.00663313 -0.06130244  0.0204702   0.03796085  0.05600799 -0.04005457\n",
      "  0.43216369  0.00789997 -0.07622381  0.14423736 -0.1588837  -0.19977093\n",
      "  0.12518117 -0.3168047 ]\n",
      "Training Error:  10.952926166489464\n",
      "====================================================================================================\n",
      "Iteration:  261\n",
      "Previous theta :  [ 0.00663313 -0.06130244  0.0204702   0.03796085  0.05600799 -0.04005457\n",
      "  0.43216369  0.00789997 -0.07622381  0.14423736 -0.1588837  -0.19977093\n",
      "  0.12518117 -0.3168047 ]\n",
      "New theta_0 : [ 0.00658619 -0.0614847   0.02073717  0.03765425  0.05604132 -0.04147996\n",
      "  0.43136264  0.00768766 -0.07805965  0.14488176 -0.15876254 -0.20008649\n",
      "  0.12498578 -0.31738425]\n",
      "Training Error:  10.94648667960724\n",
      "====================================================================================================\n",
      "Iteration:  262\n",
      "Previous theta :  [ 0.00658619 -0.0614847   0.02073717  0.03765425  0.05604132 -0.04147996\n",
      "  0.43136264  0.00768766 -0.07805965  0.14488176 -0.15876254 -0.20008649\n",
      "  0.12498578 -0.31738425]\n",
      "New theta_0 : [ 0.00653971 -0.06166638  0.02100557  0.03735157  0.05607434 -0.04289624\n",
      "  0.43056996  0.00747971 -0.0798816   0.1455216  -0.15864395 -0.20039817\n",
      "  0.12479262 -0.31795661]\n",
      "Training Error:  10.940143574354742\n",
      "====================================================================================================\n",
      "Iteration:  263\n",
      "Previous theta :  [ 0.00653971 -0.06166638  0.02100557  0.03735157  0.05607434 -0.04289624\n",
      "  0.43056996  0.00747971 -0.0798816   0.1455216  -0.15864395 -0.20039817\n",
      "  0.12479262 -0.31795661]\n",
      "New theta_0 : [ 0.00649368 -0.06184745  0.02127533  0.03705277  0.05610708 -0.04430348\n",
      "  0.42978558  0.00727605 -0.08168976  0.14615694 -0.15852789 -0.20070603\n",
      "  0.12460164 -0.31852186]\n",
      "Training Error:  10.93389530546617\n",
      "====================================================================================================\n",
      "Iteration:  264\n",
      "Previous theta :  [ 0.00649368 -0.06184745  0.02127533  0.03705277  0.05610708 -0.04430348\n",
      "  0.42978558  0.00727605 -0.08168976  0.14615694 -0.15852789 -0.20070603\n",
      "  0.12460164 -0.31852186]\n",
      "New theta_0 : [ 0.0064481  -0.06202791  0.02154639  0.03675781  0.05613953 -0.04570174\n",
      "  0.42900938  0.00707659 -0.08348426  0.14678781 -0.15841434 -0.2010101\n",
      "  0.12441281 -0.3190801 ]\n",
      "Training Error:  10.92774035472825\n",
      "====================================================================================================\n",
      "Iteration:  265\n",
      "Previous theta :  [ 0.0064481  -0.06202791  0.02154639  0.03675781  0.05613953 -0.04570174\n",
      "  0.42900938  0.00707659 -0.08348426  0.14678781 -0.15841434 -0.2010101\n",
      "  0.12441281 -0.3190801 ]\n",
      "New theta_0 : [ 0.00640294 -0.06220776  0.02181869  0.03646666  0.0561717  -0.04709105\n",
      "  0.42824128  0.00688127 -0.08526519  0.14741426 -0.15830329 -0.20131045\n",
      "  0.1242261  -0.31963143]\n",
      "Training Error:  10.921677230454238\n",
      "====================================================================================================\n",
      "Iteration:  266\n",
      "Previous theta :  [ 0.00640294 -0.06220776  0.02181869  0.03646666  0.0561717  -0.04709105\n",
      "  0.42824128  0.00688127 -0.08526519  0.14741426 -0.15830329 -0.20131045\n",
      "  0.1242261  -0.31963143]\n",
      "New theta_0 : [ 0.00635822 -0.06238699  0.02209216  0.03617926  0.05620357 -0.04847149\n",
      "  0.42748119  0.00669    -0.08703267  0.14803633 -0.15819471 -0.20160712\n",
      "  0.12404148 -0.32017593]\n",
      "Training Error:  10.915704466969226\n",
      "====================================================================================================\n",
      "Iteration:  267\n",
      "Previous theta :  [ 0.00635822 -0.06238699  0.02209216  0.03617926  0.05620357 -0.04847149\n",
      "  0.42748119  0.00669    -0.08703267  0.14803633 -0.15819471 -0.20160712\n",
      "  0.12404148 -0.32017593]\n",
      "New theta_0 : [ 0.00631392 -0.06256559  0.02236676  0.03589559  0.05623517 -0.0498431\n",
      "  0.42672901  0.00650271 -0.08878681  0.14865406 -0.15808857 -0.20190016\n",
      "  0.12385891 -0.32071369]\n",
      "Training Error:  10.909820624106482\n",
      "====================================================================================================\n",
      "Iteration:  268\n",
      "Previous theta :  [ 0.00631392 -0.06256559  0.02236676  0.03589559  0.05623517 -0.0498431\n",
      "  0.42672901  0.00650271 -0.08878681  0.14865406 -0.15808857 -0.20190016\n",
      "  0.12385891 -0.32071369]\n",
      "New theta_0 : [ 0.00627004 -0.06274356  0.02264242  0.0356156   0.05626648 -0.05120593\n",
      "  0.42598465  0.00631934 -0.09052772  0.14926749 -0.15798486 -0.20218963\n",
      "  0.12367836 -0.32124481]\n",
      "Training Error:  10.904024286714577\n",
      "====================================================================================================\n",
      "Iteration:  269\n",
      "Previous theta :  [ 0.00627004 -0.06274356  0.02264242  0.0356156   0.05626648 -0.05120593\n",
      "  0.42598465  0.00631934 -0.09052772  0.14926749 -0.15798486 -0.20218963\n",
      "  0.12367836 -0.32124481]\n",
      "New theta_0 : [ 0.00622657 -0.06292089  0.02291909  0.03533925  0.0562975  -0.05256004\n",
      "  0.42524802  0.0061398  -0.0922555   0.14987666 -0.15788356 -0.20247557\n",
      "  0.12349981 -0.32176937]\n",
      "Training Error:  10.898314064175048\n",
      "====================================================================================================\n",
      "Iteration:  270\n",
      "Previous theta :  [ 0.00622657 -0.06292089  0.02291909  0.03533925  0.0562975  -0.05256004\n",
      "  0.42524802  0.0061398  -0.0922555   0.14987666 -0.15788356 -0.20247557\n",
      "  0.12349981 -0.32176937]\n",
      "New theta_0 : [ 0.0061835  -0.06309758  0.02319672  0.0350665   0.05632825 -0.05390547\n",
      "  0.42451904  0.00596403 -0.09397026  0.15048161 -0.15778465 -0.20275802\n",
      "  0.12332322 -0.32228745]\n",
      "Training Error:  10.892688589930367\n",
      "====================================================================================================\n",
      "Iteration:  271\n",
      "Previous theta :  [ 0.0061835  -0.06309758  0.02319672  0.0350665   0.05632825 -0.05390547\n",
      "  0.42451904  0.00596403 -0.09397026  0.15048161 -0.15778465 -0.20275802\n",
      "  0.12332322 -0.32228745]\n",
      "New theta_0 : [ 0.00614084 -0.06327362  0.02347525  0.03479732  0.05635872 -0.05524229\n",
      "  0.42379761  0.00579195 -0.0956721   0.15108238 -0.15768809 -0.20303704\n",
      "  0.12314857 -0.32279914]\n",
      "Training Error:  10.887146521021956\n",
      "====================================================================================================\n",
      "Iteration:  272\n",
      "Previous theta :  [ 0.00614084 -0.06327362  0.02347525  0.03479732  0.05635872 -0.05524229\n",
      "  0.42379761  0.00579195 -0.0956721   0.15108238 -0.15768809 -0.20303704\n",
      "  0.12314857 -0.32279914]\n",
      "New theta_0 : [ 0.00609856 -0.063449    0.02375463  0.03453167  0.05638891 -0.05657054\n",
      "  0.42308366  0.00562351 -0.09736114  0.15167901 -0.15759388 -0.20331267\n",
      "  0.12297582 -0.32330453]\n",
      "Training Error:  10.881686537638027\n",
      "====================================================================================================\n",
      "Iteration:  273\n",
      "Previous theta :  [ 0.00609856 -0.063449    0.02375463  0.03453167  0.05638891 -0.05657054\n",
      "  0.42308366  0.00562351 -0.09736114  0.15167901 -0.15759388 -0.20331267\n",
      "  0.12297582 -0.32330453]\n",
      "New theta_0 : [ 0.00605668 -0.06362373  0.02403481  0.03426952  0.05641883 -0.05789028\n",
      "  0.42237708  0.00545864 -0.09903746  0.15227154 -0.15750199 -0.20358495\n",
      "  0.12280496 -0.3238037 ]\n",
      "Training Error:  10.87630734267107\n",
      "====================================================================================================\n",
      "Iteration:  274\n",
      "Previous theta :  [ 0.00605668 -0.06362373  0.02403481  0.03426952  0.05641883 -0.05789028\n",
      "  0.42237708  0.00545864 -0.09903746  0.15227154 -0.15750199 -0.20358495\n",
      "  0.12280496 -0.3238037 ]\n",
      "New theta_0 : [ 0.00601517 -0.06379779  0.02431574  0.03401081  0.05644847 -0.05920155\n",
      "  0.42167781  0.00529726 -0.10070119  0.15286001 -0.15741241 -0.20385394\n",
      "  0.12263594 -0.32429672]\n",
      "Training Error:  10.871007661284663\n",
      "====================================================================================================\n",
      "Iteration:  275\n",
      "Previous theta :  [ 0.00601517 -0.06379779  0.02431574  0.03401081  0.05644847 -0.05920155\n",
      "  0.42167781  0.00529726 -0.10070119  0.15286001 -0.15741241 -0.20385394\n",
      "  0.12263594 -0.32429672]\n",
      "New theta_0 : [ 0.00597404 -0.06397118  0.02459737  0.03375553  0.05647785 -0.06050441\n",
      "  0.42098576  0.00513931 -0.10235241  0.15344445 -0.1573251  -0.20411967\n",
      "  0.12246875 -0.32478368]\n",
      "Training Error:  10.8657862404895\n",
      "====================================================================================================\n",
      "Iteration:  276\n",
      "Previous theta :  [ 0.00597404 -0.06397118  0.02459737  0.03375553  0.05647785 -0.06050441\n",
      "  0.42098576  0.00513931 -0.10235241  0.15344445 -0.1573251  -0.20411967\n",
      "  0.12246875 -0.32478368]\n",
      "New theta_0 : [ 0.00593329 -0.06414389  0.02487965  0.03350363  0.05650695 -0.06179891\n",
      "  0.42030084  0.00498474 -0.10399122  0.15402491 -0.15724005 -0.20438219\n",
      "  0.12230335 -0.32526467]\n",
      "Training Error:  10.860641848728363\n",
      "====================================================================================================\n",
      "Iteration:  277\n",
      "Previous theta :  [ 0.00593329 -0.06414389  0.02487965  0.03350363  0.05650695 -0.06179891\n",
      "  0.42030084  0.00498474 -0.10399122  0.15402491 -0.15724005 -0.20438219\n",
      "  0.12230335 -0.32526467]\n",
      "New theta_0 : [ 0.00589289 -0.06431593  0.02516254  0.03325507  0.05653578 -0.06308509\n",
      "  0.41962297  0.00483348 -0.10561773  0.15460142 -0.15715724 -0.20464154\n",
      "  0.12213973 -0.32573974]\n",
      "Training Error:  10.855573275469846\n",
      "====================================================================================================\n",
      "Iteration:  278\n",
      "Previous theta :  [ 0.00589289 -0.06431593  0.02516254  0.03325507  0.05653578 -0.06308509\n",
      "  0.41962297  0.00483348 -0.10561773  0.15460142 -0.15715724 -0.20464154\n",
      "  0.12213973 -0.32573974]\n",
      "New theta_0 : [ 0.00585287 -0.06448729  0.025446    0.03300982  0.05656434 -0.06436302\n",
      "  0.41895208  0.00468546 -0.10723204  0.15517401 -0.15707664 -0.20489777\n",
      "  0.12197786 -0.326209  ]\n",
      "Training Error:  10.850579330810662\n",
      "====================================================================================================\n",
      "Iteration:  279\n",
      "Previous theta :  [ 0.00585287 -0.06448729  0.025446    0.03300982  0.05656434 -0.06436302\n",
      "  0.41895208  0.00468546 -0.10723204  0.15517401 -0.15707664 -0.20489777\n",
      "  0.12197786 -0.326209  ]\n",
      "New theta_0 : [ 0.00581319 -0.06465796  0.02572997  0.03276786  0.05659264 -0.06563273\n",
      "  0.41828808  0.00454064 -0.10883424  0.15574273 -0.15699825 -0.20515091\n",
      "  0.1218177  -0.3266725 ]\n",
      "Training Error:  10.845658845086263\n",
      "====================================================================================================\n",
      "Iteration:  280\n",
      "Previous theta :  [ 0.00581319 -0.06465796  0.02572997  0.03276786  0.05659264 -0.06563273\n",
      "  0.41828808  0.00454064 -0.10883424  0.15574273 -0.15699825 -0.20515091\n",
      "  0.1218177  -0.3266725 ]\n",
      "New theta_0 : [ 0.00577387 -0.06482794  0.02601442  0.03252913  0.05662068 -0.06689428\n",
      "  0.4176309   0.00439894 -0.11042443  0.15630761 -0.15692203 -0.20540101\n",
      "  0.12165925 -0.32713032]\n",
      "Training Error:  10.840810668489688\n",
      "====================================================================================================\n",
      "Iteration:  281\n",
      "Previous theta :  [ 0.00577387 -0.06482794  0.02601442  0.03252913  0.05662068 -0.06689428\n",
      "  0.4176309   0.00439894 -0.11042443  0.15630761 -0.15692203 -0.20540101\n",
      "  0.12165925 -0.32713032]\n",
      "New theta_0 : [ 0.0057349  -0.06499723  0.0262993   0.03229361  0.05664845 -0.06814772\n",
      "  0.41698045  0.00426032 -0.1120027   0.15686869 -0.15684796 -0.20564811\n",
      "  0.12150247 -0.32758255]\n",
      "Training Error:  10.836033670698356\n",
      "====================================================================================================\n",
      "Iteration:  282\n",
      "Previous theta :  [ 0.0057349  -0.06499723  0.0262993   0.03229361  0.05664845 -0.06814772\n",
      "  0.41698045  0.00426032 -0.1120027   0.15686869 -0.15684796 -0.20564811\n",
      "  0.12150247 -0.32758255]\n",
      "New theta_0 : [ 0.00569626 -0.06516582  0.02658457  0.03206126  0.05667596 -0.06939309\n",
      "  0.41633667  0.0041247  -0.11356916  0.157426   -0.15677604 -0.20589225\n",
      "  0.12134734 -0.32802924]\n",
      "Training Error:  10.831326740508679\n",
      "====================================================================================================\n",
      "Iteration:  283\n",
      "Previous theta :  [ 0.00569626 -0.06516582  0.02658457  0.03206126  0.05667596 -0.06939309\n",
      "  0.41633667  0.0041247  -0.11356916  0.157426   -0.15677604 -0.20589225\n",
      "  0.12134734 -0.32802924]\n",
      "New theta_0 : [ 0.00565797 -0.06533371  0.0268702   0.03183205  0.05670322 -0.07063045\n",
      "  0.41569947  0.00399205 -0.11512389  0.15797958 -0.15670623 -0.20613347\n",
      "  0.12119384 -0.32847048]\n",
      "Training Error:  10.826688785478302\n",
      "====================================================================================================\n",
      "Iteration:  284\n",
      "Previous theta :  [ 0.00565797 -0.06533371  0.0268702   0.03183205  0.05670322 -0.07063045\n",
      "  0.41569947  0.00399205 -0.11512389  0.15797958 -0.15670623 -0.20613347\n",
      "  0.12119384 -0.32847048]\n",
      "New theta_0 : [ 0.00562001 -0.0655009   0.02715614  0.03160595  0.05673021 -0.07185985\n",
      "  0.41506879  0.0038623  -0.11666699  0.15852946 -0.15663852 -0.2063718\n",
      "  0.12104195 -0.32890634]\n",
      "Training Error:  10.822118731575793\n",
      "====================================================================================================\n",
      "Iteration:  285\n",
      "Previous theta :  [ 0.00562001 -0.0655009   0.02715614  0.03160595  0.05673021 -0.07185985\n",
      "  0.41506879  0.0038623  -0.11666699  0.15852946 -0.15663852 -0.2063718\n",
      "  0.12104195 -0.32890634]\n",
      "New theta_0 : [ 0.00558238 -0.06566738  0.02744235  0.03138293  0.05675696 -0.07308133\n",
      "  0.41444454  0.0037354  -0.11819855  0.15907568 -0.15657289 -0.20660729\n",
      "  0.12089164 -0.32933688]\n",
      "Training Error:  10.817615522837622\n",
      "====================================================================================================\n",
      "Iteration:  286\n",
      "Previous theta :  [ 0.00558238 -0.06566738  0.02744235  0.03138293  0.05675696 -0.07308133\n",
      "  0.41444454  0.0037354  -0.11819855  0.15907568 -0.15657289 -0.20660729\n",
      "  0.12089164 -0.32933688]\n",
      "New theta_0 : [ 0.00554507 -0.06583315  0.02772879  0.03116294  0.05678345 -0.07429494\n",
      "  0.41382667  0.00361129 -0.11971866  0.15961826 -0.15650931 -0.20683997\n",
      "  0.12074289 -0.32976217]\n",
      "Training Error:  10.813178121032246\n",
      "====================================================================================================\n",
      "Iteration:  287\n",
      "Previous theta :  [ 0.00554507 -0.06583315  0.02772879  0.03116294  0.05678345 -0.07429494\n",
      "  0.41382667  0.00361129 -0.11971866  0.15961826 -0.15650931 -0.20683997\n",
      "  0.12074289 -0.32976217]\n",
      "New theta_0 : [ 0.00550809 -0.06599821  0.02801544  0.03094596  0.05680968 -0.07550072\n",
      "  0.41321508  0.00348993 -0.12122742  0.16015726 -0.15644777 -0.20706989\n",
      "  0.12059568 -0.33018228]\n",
      "Training Error:  10.808805505331177\n",
      "====================================================================================================\n",
      "Iteration:  288\n",
      "Previous theta :  [ 0.00550809 -0.06599821  0.02801544  0.03094596  0.05680968 -0.07550072\n",
      "  0.41321508  0.00348993 -0.12122742  0.16015726 -0.15644777 -0.20706989\n",
      "  0.12059568 -0.33018228]\n",
      "New theta_0 : [ 0.00547142 -0.06616256  0.02830224  0.03073196  0.05683567 -0.07669874\n",
      "  0.41260972  0.00337126 -0.12272491  0.16069269 -0.15638825 -0.20729707\n",
      "  0.12044999 -0.33059728]\n",
      "Training Error:  10.80449667198683\n",
      "====================================================================================================\n",
      "Iteration:  289\n",
      "Previous theta :  [ 0.00547142 -0.06616256  0.02830224  0.03073196  0.05683567 -0.07669874\n",
      "  0.41260972  0.00337126 -0.12272491  0.16069269 -0.15638825 -0.20729707\n",
      "  0.12044999 -0.33059728]\n",
      "New theta_0 : [ 0.00543506 -0.06632619  0.02858918  0.03052091  0.05686141 -0.07788902\n",
      "  0.41201051  0.00325524 -0.12421123  0.16122459 -0.15633074 -0.20752155\n",
      "  0.1203058  -0.33100724]\n",
      "Training Error:  10.80025063401702\n",
      "====================================================================================================\n",
      "Iteration:  290\n",
      "Previous theta :  [ 0.00543506 -0.06632619  0.02858918  0.03052091  0.05686141 -0.07788902\n",
      "  0.41201051  0.00325524 -0.12421123  0.16122459 -0.15633074 -0.20752155\n",
      "  0.1203058  -0.33100724]\n",
      "New theta_0 : [ 0.00539902 -0.0664891   0.02887621  0.03031277  0.0568869  -0.07907163\n",
      "  0.41141738  0.0031418  -0.12568645  0.161753   -0.1562752  -0.20774338\n",
      "  0.1201631  -0.33141221]\n",
      "Training Error:  10.796066420895974\n",
      "====================================================================================================\n",
      "Iteration:  291\n",
      "Previous theta :  [ 0.00539902 -0.0664891   0.02887621  0.03031277  0.0568869  -0.07907163\n",
      "  0.41141738  0.0031418  -0.12568645  0.161753   -0.1562752  -0.20774338\n",
      "  0.1201631  -0.33141221]\n",
      "New theta_0 : [ 0.00536328 -0.06665129  0.0291633   0.03010751  0.05691215 -0.08024661\n",
      "  0.41083027  0.00303091 -0.12715068  0.16227794 -0.15622162 -0.20796258\n",
      "  0.12002185 -0.33181228]\n",
      "Training Error:  10.791943078251672\n",
      "====================================================================================================\n",
      "Iteration:  292\n",
      "Previous theta :  [ 0.00536328 -0.06665129  0.0291633   0.03010751  0.05691215 -0.08024661\n",
      "  0.41083027  0.00303091 -0.12715068  0.16227794 -0.15622162 -0.20796258\n",
      "  0.12002185 -0.33181228]\n",
      "New theta_0 : [ 0.00532784 -0.06681275  0.02945042  0.0299051   0.05693716 -0.081414\n",
      "  0.4102491   0.00292252 -0.12860399  0.16279945 -0.15616999 -0.20817919\n",
      "  0.11988204 -0.33220748]\n",
      "Training Error:  10.787879667569412\n",
      "====================================================================================================\n",
      "Iteration:  293\n",
      "Previous theta :  [ 0.00532784 -0.06681275  0.02945042  0.0299051   0.05693716 -0.081414\n",
      "  0.4102491   0.00292252 -0.12860399  0.16279945 -0.15616999 -0.20817919\n",
      "  0.11988204 -0.33220748]\n",
      "New theta_0 : [ 0.0052927  -0.06697349  0.02973753  0.02970552  0.05696192 -0.08257385\n",
      "  0.40967382  0.00281658 -0.13004648  0.16331757 -0.15612028 -0.20839325\n",
      "  0.11974365 -0.3325979 ]\n",
      "Training Error:  10.78387526590143\n",
      "====================================================================================================\n",
      "Iteration:  294\n",
      "Previous theta :  [ 0.0052927  -0.06697349  0.02973753  0.02970552  0.05696192 -0.08257385\n",
      "  0.40967382  0.00281658 -0.13004648  0.16331757 -0.15612028 -0.20839325\n",
      "  0.11974365 -0.3325979 ]\n",
      "New theta_0 : [ 0.00525785 -0.06713351  0.03002461  0.02950873  0.05698645 -0.08372621\n",
      "  0.40910435  0.00271303 -0.13147822  0.16383231 -0.15607247 -0.20860478\n",
      "  0.11960667 -0.3329836 ]\n",
      "Training Error:  10.779928965582474\n",
      "====================================================================================================\n",
      "Iteration:  295\n",
      "Previous theta :  [ 0.00525785 -0.06713351  0.03002461  0.02950873  0.05698645 -0.08372621\n",
      "  0.40910435  0.00271303 -0.13147822  0.16383231 -0.15607247 -0.20860478\n",
      "  0.11960667 -0.3329836 ]\n",
      "New theta_0 : [ 0.0052233  -0.0672928   0.03031163  0.0293147   0.05701073 -0.08487112\n",
      "  0.40854063  0.00261185 -0.13289931  0.16434372 -0.15602656 -0.20881383\n",
      "  0.11947107 -0.33336462]\n",
      "Training Error:  10.776039873951142\n",
      "====================================================================================================\n",
      "Iteration:  296\n",
      "Previous theta :  [ 0.0052233  -0.0672928   0.03031163  0.0293147   0.05701073 -0.08487112\n",
      "  0.40854063  0.00261185 -0.13289931  0.16434372 -0.15602656 -0.20881383\n",
      "  0.11947107 -0.33336462]\n",
      "New theta_0 : [ 0.00518903 -0.06745135  0.03059855  0.0291234   0.05703479 -0.08600863\n",
      "  0.40798259  0.00251298 -0.13430983  0.16485182 -0.15598251 -0.20902042\n",
      "  0.11933684 -0.33374104]\n",
      "Training Error:  10.77220711307692\n",
      "====================================================================================================\n",
      "Iteration:  297\n",
      "Previous theta :  [ 0.00518903 -0.06745135  0.03059855  0.0291234   0.05703479 -0.08600863\n",
      "  0.40798259  0.00251298 -0.13430983  0.16485182 -0.15598251 -0.20902042\n",
      "  0.11933684 -0.33374104]\n",
      "New theta_0 : [ 0.00515504 -0.06760918  0.03088534  0.02893481  0.0570586  -0.08713878\n",
      "  0.40743018  0.00241638 -0.13570985  0.16535665 -0.15594031 -0.20922459\n",
      "  0.11920396 -0.33411291]\n",
      "Training Error:  10.768429819492761\n",
      "====================================================================================================\n",
      "Iteration:  298\n",
      "Previous theta :  [ 0.00515504 -0.06760918  0.03088534  0.02893481  0.0570586  -0.08713878\n",
      "  0.40743018  0.00241638 -0.13570985  0.16535665 -0.15594031 -0.20922459\n",
      "  0.11920396 -0.33411291]\n",
      "New theta_0 : [ 0.00512134 -0.06776627  0.03117198  0.02874889  0.05708219 -0.08826163\n",
      "  0.40688332  0.002322   -0.13709947  0.16585823 -0.15589994 -0.20942637\n",
      "  0.11907241 -0.3344803 ]\n",
      "Training Error:  10.764707143933055\n",
      "====================================================================================================\n",
      "Iteration:  299\n",
      "Previous theta :  [ 0.00512134 -0.06776627  0.03117198  0.02874889  0.05708219 -0.08826163\n",
      "  0.40688332  0.002322   -0.13709947  0.16585823 -0.15589994 -0.20942637\n",
      "  0.11907241 -0.3344803 ]\n",
      "New theta_0 : [ 0.00508792 -0.06792264  0.03145845  0.02856562  0.05710554 -0.0893772\n",
      "  0.40634196  0.00222981 -0.13847876  0.1663566  -0.15586139 -0.20962579\n",
      "  0.11894218 -0.33484325]\n",
      "Training Error:  10.761038251076922\n",
      "====================================================================================================\n",
      "Iteration:  300\n",
      "Previous theta :  [ 0.00508792 -0.06792264  0.03145845  0.02856562  0.05710554 -0.0893772\n",
      "  0.40634196  0.00222981 -0.13847876  0.1663566  -0.15586139 -0.20962579\n",
      "  0.11894218 -0.33484325]\n",
      "New theta_0 : [ 0.00505477 -0.06807826  0.0317447   0.02838496  0.05712867 -0.09048556\n",
      "  0.40580604  0.00213976 -0.13984782  0.16685177 -0.15582463 -0.20982289\n",
      "  0.11881324 -0.33520183]\n",
      "Training Error:  10.757422319296685\n",
      "====================================================================================================\n",
      "Iteration:  301\n",
      "Previous theta :  [ 0.00505477 -0.06807826  0.0317447   0.02838496  0.05712867 -0.09048556\n",
      "  0.40580604  0.00213976 -0.13984782  0.16685177 -0.15582463 -0.20982289\n",
      "  0.11881324 -0.33520183]\n",
      "New theta_0 : [ 0.00502189 -0.06823316  0.03203073  0.0282069   0.05715157 -0.09158673\n",
      "  0.40527549  0.00205181 -0.1412067   0.1673438  -0.15578965 -0.21001768\n",
      "  0.11868559 -0.33555609]\n",
      "Training Error:  10.753858540411379\n",
      "====================================================================================================\n",
      "Iteration:  302\n",
      "Previous theta :  [ 0.00502189 -0.06823316  0.03203073  0.0282069   0.05715157 -0.09158673\n",
      "  0.40527549  0.00205181 -0.1412067   0.1673438  -0.15578965 -0.21001768\n",
      "  0.11868559 -0.33555609]\n",
      "New theta_0 : [ 0.00498928 -0.06838731  0.03231649  0.0280314   0.05717424 -0.09268078\n",
      "  0.40475025  0.00196593 -0.1425555   0.16783269 -0.15575643 -0.21021021\n",
      "  0.1185592  -0.33590609]\n",
      "Training Error:  10.750346119445249\n",
      "====================================================================================================\n",
      "Iteration:  303\n",
      "Previous theta :  [ 0.00498928 -0.06838731  0.03231649  0.0280314   0.05717424 -0.09268078\n",
      "  0.40475025  0.00196593 -0.1425555   0.16783269 -0.15575643 -0.21021021\n",
      "  0.1185592  -0.33590609]\n",
      "New theta_0 : [ 0.00495693 -0.06854073  0.03260197  0.02785843  0.05719669 -0.09376773\n",
      "  0.40423027  0.00188206 -0.1438943   0.16831849 -0.15572496 -0.21040051\n",
      "  0.11843406 -0.33625188]\n",
      "Training Error:  10.746884274391062\n",
      "====================================================================================================\n",
      "Iteration:  304\n",
      "Previous theta :  [ 0.00495693 -0.06854073  0.03260197  0.02785843  0.05719669 -0.09376773\n",
      "  0.40423027  0.00188206 -0.1438943   0.16831849 -0.15572496 -0.21040051\n",
      "  0.11843406 -0.33625188]\n",
      "New theta_0 : [ 0.00492485 -0.06869341  0.03288715  0.02768798  0.05721891 -0.09484764\n",
      "  0.40371549  0.00180018 -0.14522318  0.16880121 -0.15569521 -0.21058859\n",
      "  0.11831016 -0.33659352]\n",
      "Training Error:  10.743472235978162\n",
      "====================================================================================================\n",
      "Iteration:  305\n",
      "Previous theta :  [ 0.00492485 -0.06869341  0.03288715  0.02768798  0.05721891 -0.09484764\n",
      "  0.40371549  0.00180018 -0.14522318  0.16880121 -0.15569521 -0.21058859\n",
      "  0.11831016 -0.33659352]\n",
      "New theta_0 : [ 0.00489303 -0.06884536  0.03317199  0.02752     0.05724092 -0.09592055\n",
      "  0.40320584  0.00172025 -0.1465422   0.16928089 -0.15566717 -0.2107745\n",
      "  0.11818747 -0.33693106]\n",
      "Training Error:  10.740109247445162\n",
      "====================================================================================================\n",
      "Iteration:  306\n",
      "Previous theta :  [ 0.00489303 -0.06884536  0.03317199  0.02752     0.05724092 -0.09592055\n",
      "  0.40320584  0.00172025 -0.1465422   0.16928089 -0.15566717 -0.2107745\n",
      "  0.11818747 -0.33693106]\n",
      "New theta_0 : [ 0.00486146 -0.06899657  0.03345648  0.02735448  0.05726271 -0.0969865\n",
      "  0.40270128  0.00164222 -0.14785145  0.16975756 -0.15564082 -0.21095826\n",
      "  0.11806599 -0.33726455]\n",
      "Training Error:  10.736794564317139\n",
      "====================================================================================================\n",
      "Iteration:  307\n",
      "Previous theta :  [ 0.00486146 -0.06899657  0.03345648  0.02735448  0.05726271 -0.0969865\n",
      "  0.40270128  0.00164222 -0.14785145  0.16975756 -0.15564082 -0.21095826\n",
      "  0.11806599 -0.33726455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00483015 -0.06914704  0.03374059  0.02719138  0.05728428 -0.09804553\n",
      "  0.40220174  0.00156606 -0.14915101  0.17023124 -0.15561615 -0.2111399\n",
      "  0.1179457  -0.33759404]\n",
      "Training Error:  10.733527454187298\n",
      "====================================================================================================\n",
      "Iteration:  308\n",
      "Previous theta :  [ 0.00483015 -0.06914704  0.03374059  0.02719138  0.05728428 -0.09804553\n",
      "  0.40220174  0.00156606 -0.14915101  0.17023124 -0.15561615 -0.2111399\n",
      "  0.1179457  -0.33759404]\n",
      "New theta_0 : [ 0.00479909 -0.06929677  0.0340243   0.02703069  0.05730563 -0.09909769\n",
      "  0.40170717  0.00149174 -0.15044094  0.17070196 -0.15559313 -0.21131944\n",
      "  0.11782658 -0.33791959]\n",
      "Training Error:  10.730307196502917\n",
      "====================================================================================================\n",
      "Iteration:  309\n",
      "Previous theta :  [ 0.00479909 -0.06929677  0.0340243   0.02703069  0.05730563 -0.09909769\n",
      "  0.40170717  0.00149174 -0.15044094  0.17070196 -0.15559313 -0.21131944\n",
      "  0.11782658 -0.33791959]\n",
      "New theta_0 : [ 0.00476828 -0.06944577  0.0343076   0.02687238  0.05732678 -0.10014302\n",
      "  0.40121752  0.00141922 -0.15172133  0.17116974 -0.15557175 -0.21149692\n",
      "  0.11770862 -0.33824125]\n",
      "Training Error:  10.727133082355557\n",
      "====================================================================================================\n",
      "Iteration:  310\n",
      "Previous theta :  [ 0.00476828 -0.06944577  0.0343076   0.02687238  0.05732678 -0.10014302\n",
      "  0.40121752  0.00141922 -0.15172133  0.17116974 -0.15557175 -0.21149692\n",
      "  0.11770862 -0.33824125]\n",
      "New theta_0 : [ 0.00473771 -0.06959402  0.03459045  0.02671641  0.0573477  -0.10118156\n",
      "  0.40073273  0.00134847 -0.15299226  0.17163462 -0.155552   -0.21167236\n",
      "  0.11759181 -0.33855906]\n",
      "Training Error:  10.724004414275411\n",
      "====================================================================================================\n",
      "Iteration:  311\n",
      "Previous theta :  [ 0.00473771 -0.06959402  0.03459045  0.02671641  0.0573477  -0.10118156\n",
      "  0.40073273  0.00134847 -0.15299226  0.17163462 -0.155552   -0.21167236\n",
      "  0.11759181 -0.33855906]\n",
      "New theta_0 : [ 0.00470739 -0.06974154  0.03487284  0.02656278  0.05736842 -0.10221335\n",
      "  0.40025274  0.00127945 -0.15425378  0.17209662 -0.15553386 -0.21184579\n",
      "  0.11747613 -0.33887307]\n",
      "Training Error:  10.720920506029698\n",
      "====================================================================================================\n",
      "Iteration:  312\n",
      "Previous theta :  [ 0.00470739 -0.06974154  0.03487284  0.02656278  0.05736842 -0.10221335\n",
      "  0.40025274  0.00127945 -0.15425378  0.17209662 -0.15553386 -0.21184579\n",
      "  0.11747613 -0.33887307]\n",
      "New theta_0 : [ 0.00467731 -0.06988832  0.03515475  0.02641144  0.05738893 -0.10323844\n",
      "  0.39977751  0.00121212 -0.15550598  0.17255576 -0.1555173  -0.21201723\n",
      "  0.11736157 -0.33918334]\n",
      "Training Error:  10.717880682425006\n",
      "====================================================================================================\n",
      "Iteration:  313\n",
      "Previous theta :  [ 0.00467731 -0.06988832  0.03515475  0.02641144  0.05738893 -0.10323844\n",
      "  0.39977751  0.00121212 -0.15550598  0.17255576 -0.1555173  -0.21201723\n",
      "  0.11736157 -0.33918334]\n",
      "New theta_0 : [ 0.00464747 -0.07003437  0.03543617  0.02626238  0.05740924 -0.10425687\n",
      "  0.39930698  0.00114646 -0.15674893  0.17301208 -0.15550232 -0.21218672\n",
      "  0.11724812 -0.3394899 ]\n",
      "Training Error:  10.714884279113543\n",
      "====================================================================================================\n",
      "Iteration:  314\n",
      "Previous theta :  [ 0.00464747 -0.07003437  0.03543617  0.02626238  0.05740924 -0.10425687\n",
      "  0.39930698  0.00114646 -0.15674893  0.17301208 -0.15550232 -0.21218672\n",
      "  0.11724812 -0.3394899 ]\n",
      "New theta_0 : [ 0.00461786 -0.07017967  0.03571706  0.02611556  0.05742933 -0.10526867\n",
      "  0.3988411   0.00108243 -0.1579827   0.17346559 -0.1554889  -0.21235427\n",
      "  0.11713575 -0.33979282]\n",
      "Training Error:  10.711930642403143\n",
      "====================================================================================================\n",
      "Iteration:  315\n",
      "Previous theta :  [ 0.00461786 -0.07017967  0.03571706  0.02611556  0.05742933 -0.10526867\n",
      "  0.3988411   0.00108243 -0.1579827   0.17346559 -0.1554889  -0.21235427\n",
      "  0.11713575 -0.33979282]\n",
      "New theta_0 : [ 0.00458849 -0.07032424  0.03599741  0.02597098  0.05744923 -0.1062739\n",
      "  0.39837982  0.00102    -0.15920737  0.17391633 -0.15547703 -0.21251991\n",
      "  0.11702447 -0.34009212]\n",
      "Training Error:  10.709019129071008\n",
      "====================================================================================================\n",
      "Iteration:  316\n",
      "Previous theta :  [ 0.00458849 -0.07032424  0.03599741  0.02597098  0.05744923 -0.1062739\n",
      "  0.39837982  0.00102    -0.15920737  0.17391633 -0.15547703 -0.21251991\n",
      "  0.11702447 -0.34009212]\n",
      "New theta_0 : [ 0.00455935 -0.07046808  0.03627722  0.0258286   0.05746892 -0.10727258\n",
      "  0.39792309  0.00095914 -0.16042299  0.17436431 -0.15546667 -0.21268366\n",
      "  0.11691425 -0.34038787]\n",
      "Training Error:  10.706149106181059\n",
      "====================================================================================================\n",
      "Iteration:  317\n",
      "Previous theta :  [ 0.00455935 -0.07046808  0.03627722  0.0258286   0.05746892 -0.10727258\n",
      "  0.39792309  0.00095914 -0.16042299  0.17436431 -0.15546667 -0.21268366\n",
      "  0.11691425 -0.34038787]\n",
      "New theta_0 : [ 0.00453043 -0.07061118  0.03655645  0.0256884   0.05748841 -0.10826477\n",
      "  0.39747085  0.00089982 -0.16162965  0.17480956 -0.15545783 -0.21284556\n",
      "  0.11680509 -0.3406801 ]\n",
      "Training Error:  10.703319950904842\n",
      "====================================================================================================\n",
      "Iteration:  318\n",
      "Previous theta :  [ 0.00453043 -0.07061118  0.03655645  0.0256884   0.05748841 -0.10826477\n",
      "  0.39747085  0.00089982 -0.16162965  0.17480956 -0.15545783 -0.21284556\n",
      "  0.11680509 -0.3406801 ]\n",
      "New theta_0 : [ 0.00450175 -0.07075354  0.03683509  0.02555035  0.0575077  -0.10925049\n",
      "  0.39702306  0.00084201 -0.16282742  0.17525211 -0.15545049 -0.21300563\n",
      "  0.11669697 -0.34096886]\n",
      "Training Error:  10.700531050345912\n",
      "====================================================================================================\n",
      "Iteration:  319\n",
      "Previous theta :  [ 0.00450175 -0.07075354  0.03683509  0.02555035  0.0575077  -0.10925049\n",
      "  0.39702306  0.00084201 -0.16282742  0.17525211 -0.15545049 -0.21300563\n",
      "  0.11669697 -0.34096886]\n",
      "New theta_0 : [ 0.00447328 -0.07089517  0.03711312  0.02541444  0.05752679 -0.1102298\n",
      "  0.39657967  0.00078568 -0.16401635  0.17569198 -0.15544462 -0.21316388\n",
      "  0.11658988 -0.3412542 ]\n",
      "Training Error:  10.697781801367613\n",
      "====================================================================================================\n",
      "Iteration:  320\n",
      "Previous theta :  [ 0.00447328 -0.07089517  0.03711312  0.02541444  0.05752679 -0.1102298\n",
      "  0.39657967  0.00078568 -0.16401635  0.17569198 -0.15544462 -0.21316388\n",
      "  0.11658988 -0.3412542 ]\n",
      "New theta_0 : [ 0.00444504 -0.07103607  0.03739054  0.02528064  0.05754569 -0.11120273\n",
      "  0.39614064  0.00073079 -0.16519652  0.17612919 -0.15544022 -0.21332034\n",
      "  0.11648381 -0.34153615]\n",
      "Training Error:  10.695071610424158\n",
      "====================================================================================================\n",
      "Iteration:  321\n",
      "Previous theta :  [ 0.00444504 -0.07103607  0.03739054  0.02528064  0.05754569 -0.11120273\n",
      "  0.39614064  0.00073079 -0.16519652  0.17612919 -0.15544022 -0.21332034\n",
      "  0.11648381 -0.34153615]\n",
      "New theta_0 : [ 0.00441702 -0.07117624  0.03766732  0.02514892  0.05756439 -0.11216933\n",
      "  0.3957059   0.00067733 -0.166368    0.17656377 -0.15543727 -0.21347504\n",
      "  0.11637874 -0.34181476]\n",
      "Training Error:  10.692399893395\n",
      "====================================================================================================\n",
      "Iteration:  322\n",
      "Previous theta :  [ 0.00441702 -0.07117624  0.03766732  0.02514892  0.05756439 -0.11216933\n",
      "  0.3957059   0.00067733 -0.166368    0.17656377 -0.15543727 -0.21347504\n",
      "  0.11637874 -0.34181476]\n",
      "New theta_0 : [ 0.00438922 -0.07131567  0.03794345  0.02501927  0.0575829  -0.11312962\n",
      "  0.39527543  0.00062527 -0.16753086  0.17699574 -0.15543575 -0.213628\n",
      "  0.11627466 -0.34209007]\n",
      "Training Error:  10.689766075422364\n",
      "====================================================================================================\n",
      "Iteration:  323\n",
      "Previous theta :  [ 0.00438922 -0.07131567  0.03794345  0.02501927  0.0575829  -0.11312962\n",
      "  0.39527543  0.00062527 -0.16753086  0.17699574 -0.15543575 -0.213628\n",
      "  0.11627466 -0.34209007]\n",
      "New theta_0 : [ 0.00436163 -0.07145438  0.03821891  0.02489166  0.05760122 -0.11408365\n",
      "  0.39484916  0.00057456 -0.16868515  0.17742513 -0.15543565 -0.21377924\n",
      "  0.11617157 -0.34236213]\n",
      "Training Error:  10.687169590751877\n",
      "====================================================================================================\n",
      "Iteration:  324\n",
      "Previous theta :  [ 0.00436163 -0.07145438  0.03821891  0.02489166  0.05760122 -0.11408365\n",
      "  0.39484916  0.00057456 -0.16868515  0.17742513 -0.15543565 -0.21377924\n",
      "  0.11617157 -0.34236213]\n",
      "New theta_0 : [ 0.00433426 -0.07159236  0.0384937   0.02476607  0.05761935 -0.11503146\n",
      "  0.39442706  0.0005252  -0.16983096  0.17785196 -0.15543696 -0.21392879\n",
      "  0.11606945 -0.34263097]\n",
      "Training Error:  10.68460988257628\n",
      "====================================================================================================\n",
      "Iteration:  325\n",
      "Previous theta :  [ 0.00433426 -0.07159236  0.0384937   0.02476607  0.05761935 -0.11503146\n",
      "  0.39442706  0.0005252  -0.16983096  0.17785196 -0.15543696 -0.21392879\n",
      "  0.11606945 -0.34263097]\n",
      "New theta_0 : [ 0.00430709 -0.07172961  0.03876779  0.02464247  0.05763729 -0.11597309\n",
      "  0.39400908  0.00047715 -0.17096833  0.17827624 -0.15543965 -0.21407666\n",
      "  0.11596829 -0.34289664]\n",
      "Training Error:  10.682086402882101\n",
      "====================================================================================================\n",
      "Iteration:  326\n",
      "Previous theta :  [ 0.00430709 -0.07172961  0.03876779  0.02464247  0.05763729 -0.11597309\n",
      "  0.39400908  0.00047715 -0.17096833  0.17827624 -0.15543965 -0.21407666\n",
      "  0.11596829 -0.34289664]\n",
      "New theta_0 : [ 0.00428014 -0.07186614  0.03904117  0.02452085  0.05765504 -0.11690858\n",
      "  0.39359517  0.00043038 -0.17209735  0.17869801 -0.15544372 -0.21422288\n",
      "  0.11586809 -0.34315917]\n",
      "Training Error:  10.679598612299243\n",
      "====================================================================================================\n",
      "Iteration:  327\n",
      "Previous theta :  [ 0.00428014 -0.07186614  0.03904117  0.02452085  0.05765504 -0.11690858\n",
      "  0.39359517  0.00043038 -0.17209735  0.17869801 -0.15544372 -0.21422288\n",
      "  0.11586809 -0.34315917]\n",
      "New theta_0 : [ 4.25339571e-03 -7.20019357e-02  3.93138403e-02  2.44011876e-02\n",
      "  5.76726117e-02 -1.17837965e-01  3.93185291e-01  3.84879400e-04\n",
      " -1.73218062e-01  1.79117285e-01 -1.55449147e-01 -2.14367463e-01\n",
      "  1.15768815e-01 -3.43418606e-01]\n",
      "Training Error:  10.677145979953439\n",
      "====================================================================================================\n",
      "Iteration:  328\n",
      "Previous theta :  [ 4.25339571e-03 -7.20019357e-02  3.93138403e-02  2.44011876e-02\n",
      "  5.76726117e-02 -1.17837965e-01  3.93185291e-01  3.84879400e-04\n",
      " -1.73218062e-01  1.79117285e-01 -1.55449147e-01 -2.14367463e-01\n",
      "  1.15768815e-01 -3.43418606e-01]\n",
      "New theta_0 : [ 4.22685518e-03 -7.21370127e-02  3.95857740e-02  2.42834561e-02\n",
      "  5.76899954e-02 -1.18761281e-01  3.92779399e-01  3.40610746e-04\n",
      " -1.74330543e-01  1.79534086e-01 -1.55455919e-01 -2.14510440e-01\n",
      "  1.15670473e-01 -3.43674986e-01]\n",
      "Training Error:  10.674727983321503\n",
      "====================================================================================================\n",
      "Iteration:  329\n",
      "Previous theta :  [ 4.22685518e-03 -7.21370127e-02  3.95857740e-02  2.42834561e-02\n",
      "  5.76899954e-02 -1.18761281e-01  3.92779399e-01  3.40610746e-04\n",
      " -1.74330543e-01  1.79534086e-01 -1.55455919e-01 -2.14510440e-01\n",
      "  1.15670473e-01 -3.43674986e-01]\n",
      "New theta_0 : [ 4.20051811e-03 -7.22713679e-02  3.98569636e-02  2.41676365e-02\n",
      "  5.77071965e-02 -1.19678568e-01  3.92377449e-01  2.97552958e-04\n",
      " -1.75434854e-01  1.79948435e-01 -1.55464023e-01 -2.14651826e-01\n",
      "  1.15573049e-01 -3.43928349e-01]\n",
      "Training Error:  10.6723441080893\n",
      "====================================================================================================\n",
      "Iteration:  330\n",
      "Previous theta :  [ 4.20051811e-03 -7.22713679e-02  3.98569636e-02  2.41676365e-02\n",
      "  5.77071965e-02 -1.19678568e-01  3.92377449e-01  2.97552958e-04\n",
      " -1.75434854e-01  1.79948435e-01 -1.55464023e-01 -2.14651826e-01\n",
      "  1.15573049e-01 -3.43928349e-01]\n",
      "New theta_0 : [ 4.17438261e-03 -7.24050029e-02  4.01273974e-02  2.40537080e-02\n",
      "  5.77242167e-02 -1.20589865e-01  3.91979400e-01  2.55681808e-04\n",
      " -1.76531056e-01  1.80360355e-01 -1.55473443e-01 -2.14791644e-01\n",
      "  1.15476533e-01 -3.44178732e-01]\n",
      "Training Error:  10.669993848012425\n",
      "====================================================================================================\n",
      "Iteration:  331\n",
      "Previous theta :  [ 4.17438261e-03 -7.24050029e-02  4.01273974e-02  2.40537080e-02\n",
      "  5.77242167e-02 -1.20589865e-01  3.91979400e-01  2.55681808e-04\n",
      " -1.76531056e-01  1.80360355e-01 -1.55473443e-01 -2.14791644e-01\n",
      "  1.15476533e-01 -3.44178732e-01]\n",
      "New theta_0 : [ 4.14844679e-03 -7.25379192e-02  4.03970640e-02  2.39416499e-02\n",
      "  5.77410572e-02 -1.21495209e-01  3.91585208e-01  2.14973503e-04\n",
      " -1.77619213e-01  1.80769867e-01 -1.55484166e-01 -2.14929913e-01\n",
      "  1.15380914e-01 -3.44426174e-01]\n",
      "Training Error:  10.667676704779469\n",
      "====================================================================================================\n",
      "Iteration:  332\n",
      "Previous theta :  [ 4.14844679e-03 -7.25379192e-02  4.03970640e-02  2.39416499e-02\n",
      "  5.77410572e-02 -1.21495209e-01  3.91585208e-01  2.14973503e-04\n",
      " -1.77619213e-01  1.80769867e-01 -1.55484166e-01 -2.14929913e-01\n",
      "  1.15380914e-01 -3.44426174e-01]\n",
      "New theta_0 : [ 4.12270880e-03 -7.26701185e-02  4.06659524e-02  2.38314417e-02\n",
      "  5.77577195e-02 -1.22394637e-01  3.91194832e-01  1.75404686e-04\n",
      " -1.78699385e-01  1.81176991e-01 -1.55496177e-01 -2.15066654e-01\n",
      "  1.15286183e-01 -3.44670709e-01]\n",
      "Training Error:  10.665392187877877\n",
      "====================================================================================================\n",
      "Iteration:  333\n",
      "Previous theta :  [ 4.12270880e-03 -7.26701185e-02  4.06659524e-02  2.38314417e-02\n",
      "  5.77577195e-02 -1.22394637e-01  3.91194832e-01  1.75404686e-04\n",
      " -1.78699385e-01  1.81176991e-01 -1.55496177e-01 -2.15066654e-01\n",
      "  1.15286183e-01 -3.44670709e-01]\n",
      "New theta_0 : [ 4.09716681e-03 -7.28016024e-02  4.09340517e-02  2.37230633e-02\n",
      "  5.77742051e-02 -1.23288186e-01  3.90808231e-01  1.36952418e-04\n",
      " -1.79771635e-01  1.81581750e-01 -1.55509463e-01 -2.15201885e-01\n",
      "  1.15192330e-01 -3.44912376e-01]\n",
      "Training Error:  10.663139814462317\n",
      "====================================================================================================\n",
      "Iteration:  334\n",
      "Previous theta :  [ 4.09716681e-03 -7.28016024e-02  4.09340517e-02  2.37230633e-02\n",
      "  5.77742051e-02 -1.23288186e-01  3.90808231e-01  1.36952418e-04\n",
      " -1.79771635e-01  1.81581750e-01 -1.55509463e-01 -2.15201885e-01\n",
      "  1.15192330e-01 -3.44912376e-01]\n",
      "New theta_0 : [ 4.07181901e-03 -7.29323727e-02  4.12013517e-02  2.36164947e-02\n",
      "  5.77905154e-02 -1.24175893e-01  3.90425364e-01  9.95941784e-05\n",
      " -1.80836022e-01  1.81984162e-01 -1.55524010e-01 -2.15335627e-01\n",
      "  1.15099346e-01 -3.45151211e-01]\n",
      "Training Error:  10.660919109225484\n",
      "====================================================================================================\n",
      "Iteration:  335\n",
      "Previous theta :  [ 4.07181901e-03 -7.29323727e-02  4.12013517e-02  2.36164947e-02\n",
      "  5.77905154e-02 -1.24175893e-01  3.90425364e-01  9.95941784e-05\n",
      " -1.80836022e-01  1.81984162e-01 -1.55524010e-01 -2.15335627e-01\n",
      "  1.15099346e-01 -3.45151211e-01]\n",
      "New theta_0 : [ 4.04666363e-03 -7.30624311e-02  4.14678424e-02  2.35117159e-02\n",
      "  5.78066517e-02 -1.25057796e-01  3.90046191e-01  6.33078548e-05\n",
      " -1.81892608e-01  1.82384249e-01 -1.55539804e-01 -2.15467898e-01\n",
      "  1.15007220e-01 -3.45387248e-01]\n",
      "Training Error:  10.658729604271347\n",
      "====================================================================================================\n",
      "Iteration:  336\n",
      "Previous theta :  [ 4.04666363e-03 -7.30624311e-02  4.14678424e-02  2.35117159e-02\n",
      "  5.78066517e-02 -1.25057796e-01  3.90046191e-01  6.33078548e-05\n",
      " -1.81892608e-01  1.82384249e-01 -1.55539804e-01 -2.15467898e-01\n",
      "  1.15007220e-01 -3.45387248e-01]\n",
      "New theta_0 : [ 4.02169893e-03 -7.31917795e-02  4.17335139e-02  2.34087074e-02\n",
      "  5.78226155e-02 -1.25933930e-01  3.89670671e-01  2.80717367e-05\n",
      " -1.82941451e-01  1.82782032e-01 -1.55556831e-01 -2.15598718e-01\n",
      "  1.14915943e-01 -3.45620522e-01]\n",
      "Training Error:  10.656570838990724\n",
      "====================================================================================================\n",
      "Iteration:  337\n",
      "Previous theta :  [ 4.02169893e-03 -7.31917795e-02  4.17335139e-02  2.34087074e-02\n",
      "  5.78226155e-02 -1.25933930e-01  3.89670671e-01  2.80717367e-05\n",
      " -1.82941451e-01  1.82782032e-01 -1.55556831e-01 -2.15598718e-01\n",
      "  1.14915943e-01 -3.45620522e-01]\n",
      "New theta_0 : [ 3.99692316e-03 -7.33204197e-02  4.19983570e-02  2.33074497e-02\n",
      "  5.78384082e-02 -1.26804332e-01  3.89298766e-01 -6.13549153e-06\n",
      " -1.83982612e-01  1.83177529e-01 -1.55575079e-01 -2.15728104e-01\n",
      "  1.14825507e-01 -3.45851069e-01]\n",
      "Training Error:  10.654442359939202\n",
      "====================================================================================================\n",
      "Iteration:  338\n",
      "Previous theta :  [ 3.99692316e-03 -7.33204197e-02  4.19983570e-02  2.33074497e-02\n",
      "  5.78384082e-02 -1.26804332e-01  3.89298766e-01 -6.13549153e-06\n",
      " -1.83982612e-01  1.83177529e-01 -1.55575079e-01 -2.15728104e-01\n",
      "  1.14825507e-01 -3.45851069e-01]\n",
      "New theta_0 : [ 3.97233463e-03 -7.34483537e-02  4.22623625e-02  2.32079236e-02\n",
      "  5.78540310e-02 -1.27669038e-01  3.88930436e-01 -3.93347575e-05\n",
      " -1.85016148e-01  1.83570761e-01 -1.55594534e-01 -2.15856075e-01\n",
      "  1.14735901e-01 -3.46078923e-01]\n",
      "Training Error:  10.65234372071726\n",
      "====================================================================================================\n",
      "Iteration:  339\n",
      "Previous theta :  [ 3.97233463e-03 -7.34483537e-02  4.22623625e-02  2.32079236e-02\n",
      "  5.78540310e-02 -1.27669038e-01  3.88930436e-01 -3.93347575e-05\n",
      " -1.85016148e-01  1.83570761e-01 -1.55594534e-01 -2.15856075e-01\n",
      "  1.14735901e-01 -3.46078923e-01]\n",
      "New theta_0 : [ 3.94793166e-03 -7.35755835e-02  4.25255218e-02  2.31101100e-02\n",
      "  5.78694855e-02 -1.28528084e-01  3.88565644e-01 -7.15466070e-05\n",
      " -1.86042118e-01  1.83961747e-01 -1.55615183e-01 -2.15982650e-01\n",
      "  1.14647118e-01 -3.46304117e-01]\n",
      "Training Error:  10.650274481852682\n",
      "====================================================================================================\n",
      "Iteration:  340\n",
      "Previous theta :  [ 3.94793166e-03 -7.35755835e-02  4.25255218e-02  2.31101100e-02\n",
      "  5.78694855e-02 -1.28528084e-01  3.88565644e-01 -7.15466070e-05\n",
      " -1.86042118e-01  1.83961747e-01 -1.55615183e-01 -2.15982650e-01\n",
      "  1.14647118e-01 -3.46304117e-01]\n",
      "New theta_0 : [ 3.92371258e-03 -7.37021110e-02  4.27878262e-02  2.30139902e-02\n",
      "  5.78847729e-02 -1.29381506e-01  3.88204350e-01 -1.02791211e-04\n",
      " -1.87060581e-01  1.84350507e-01 -1.55637012e-01 -2.16107846e-01\n",
      "  1.14559148e-01 -3.46526684e-01]\n",
      "Training Error:  10.648234210685061\n",
      "====================================================================================================\n",
      "Iteration:  341\n",
      "Previous theta :  [ 3.92371258e-03 -7.37021110e-02  4.27878262e-02  2.30139902e-02\n",
      "  5.78847729e-02 -1.29381506e-01  3.88204350e-01 -1.02791211e-04\n",
      " -1.87060581e-01  1.84350507e-01 -1.55637012e-01 -2.16107846e-01\n",
      "  1.14559148e-01 -3.46526684e-01]\n",
      "New theta_0 : [ 3.89967577e-03 -7.38279382e-02  4.30492678e-02  2.29195454e-02\n",
      "  5.78998945e-02 -1.30229338e-01  3.87846519e-01 -1.33088373e-04\n",
      " -1.88071592e-01  1.84737060e-01 -1.55660009e-01 -2.16231681e-01\n",
      "  1.14471982e-01 -3.46746657e-01]\n",
      "Training Error:  10.64622248125249\n",
      "====================================================================================================\n",
      "Iteration:  342\n",
      "Previous theta :  [ 3.89967577e-03 -7.38279382e-02  4.30492678e-02  2.29195454e-02\n",
      "  5.78998945e-02 -1.30229338e-01  3.87846519e-01 -1.33088373e-04\n",
      " -1.88071592e-01  1.84737060e-01 -1.55660009e-01 -2.16231681e-01\n",
      "  1.14471982e-01 -3.46746657e-01]\n",
      "New theta_0 : [ 3.87581960e-03 -7.39530674e-02  4.33098385e-02  2.28267571e-02\n",
      "  5.79148518e-02 -1.31071617e-01  3.87492112e-01 -1.62457532e-04\n",
      " -1.89075210e-01  1.85121425e-01 -1.55684160e-01 -2.16354172e-01\n",
      "  1.14385613e-01 -3.46964068e-01]\n",
      "Training Error:  10.644238874180287\n",
      "====================================================================================================\n",
      "Iteration:  343\n",
      "Previous theta :  [ 3.87581960e-03 -7.39530674e-02  4.33098385e-02  2.28267571e-02\n",
      "  5.79148518e-02 -1.31071617e-01  3.87492112e-01 -1.62457532e-04\n",
      " -1.89075210e-01  1.85121425e-01 -1.55684160e-01 -2.16354172e-01\n",
      "  1.14385613e-01 -3.46964068e-01]\n",
      "New theta_0 : [ 3.85214249e-03 -7.40775006e-02  4.35695307e-02  2.27356072e-02\n",
      "  5.79296460e-02 -1.31908378e-01  3.87141092e-01 -1.90917772e-04\n",
      " -1.90071489e-01  1.85503620e-01 -1.55709453e-01 -2.16475336e-01\n",
      "  1.14300030e-01 -3.47178950e-01]\n",
      "Training Error:  10.642282976571789\n",
      "====================================================================================================\n",
      "Iteration:  344\n",
      "Previous theta :  [ 3.85214249e-03 -7.40775006e-02  4.35695307e-02  2.27356072e-02\n",
      "  5.79296460e-02 -1.31908378e-01  3.87141092e-01 -1.90917772e-04\n",
      " -1.90071489e-01  1.85503620e-01 -1.55709453e-01 -2.16475336e-01\n",
      "  1.14300030e-01 -3.47178950e-01]\n",
      "New theta_0 : [ 3.82864286e-03 -7.42012399e-02  4.38283373e-02  2.26460774e-02\n",
      "  5.79442785e-02 -1.32739655e-01  3.86793425e-01 -2.18487829e-04\n",
      " -1.91060487e-01  1.85883665e-01 -1.55735876e-01 -2.16595191e-01\n",
      "  1.14215227e-01 -3.47391334e-01]\n",
      "Training Error:  10.640354381901119\n",
      "====================================================================================================\n",
      "Iteration:  345\n",
      "Previous theta :  [ 3.82864286e-03 -7.42012399e-02  4.38283373e-02  2.26460774e-02\n",
      "  5.79442785e-02 -1.32739655e-01  3.86793425e-01 -2.18487829e-04\n",
      " -1.91060487e-01  1.85883665e-01 -1.55735876e-01 -2.16595191e-01\n",
      "  1.14215227e-01 -3.47391334e-01]\n",
      "New theta_0 : [ 3.80531916e-03 -7.43242876e-02  4.40862510e-02  2.25581499e-02\n",
      "  5.79587505e-02 -1.33565483e-01  3.86449073e-01 -2.45186092e-04\n",
      " -1.92042259e-01  1.86261577e-01 -1.55763416e-01 -2.16713752e-01\n",
      "  1.14131195e-01 -3.47601251e-01]\n",
      "Training Error:  10.638452689907915\n",
      "====================================================================================================\n",
      "Iteration:  346\n",
      "Previous theta :  [ 3.80531916e-03 -7.43242876e-02  4.40862510e-02  2.25581499e-02\n",
      "  5.79587505e-02 -1.33565483e-01  3.86449073e-01 -2.45186092e-04\n",
      " -1.92042259e-01  1.86261577e-01 -1.55763416e-01 -2.16713752e-01\n",
      "  1.14131195e-01 -3.47601251e-01]\n",
      "New theta_0 : [ 3.78216986e-03 -7.44466459e-02  4.43432651e-02  2.24718069e-02\n",
      "  5.79730634e-02 -1.34385896e-01  3.86108002e-01 -2.71030616e-04\n",
      " -1.93016860e-01  1.86637375e-01 -1.55792059e-01 -2.16831036e-01\n",
      "  1.14047925e-01 -3.47808732e-01]\n",
      "Training Error:  10.636577506493978\n",
      "====================================================================================================\n",
      "Iteration:  347\n",
      "Previous theta :  [ 3.78216986e-03 -7.44466459e-02  4.43432651e-02  2.24718069e-02\n",
      "  5.79730634e-02 -1.34385896e-01  3.86108002e-01 -2.71030616e-04\n",
      " -1.93016860e-01  1.86637375e-01 -1.55792059e-01 -2.16831036e-01\n",
      "  1.14047925e-01 -3.47808732e-01]\n",
      "New theta_0 : [ 3.75919344e-03 -7.45683170e-02  4.45993732e-02  2.23870308e-02\n",
      "  5.79872184e-02 -1.35200929e-01  3.85770176e-01 -2.96039119e-04\n",
      " -1.93984343e-01  1.87011077e-01 -1.55821795e-01 -2.16947060e-01\n",
      "  1.13965410e-01 -3.48013806e-01]\n",
      "Training Error:  10.63472844362179\n",
      "====================================================================================================\n",
      "Iteration:  348\n",
      "Previous theta :  [ 3.75919344e-03 -7.45683170e-02  4.45993732e-02  2.23870308e-02\n",
      "  5.79872184e-02 -1.35200929e-01  3.85770176e-01 -2.96039119e-04\n",
      " -1.93984343e-01  1.87011077e-01 -1.55821795e-01 -2.16947060e-01\n",
      "  1.13965410e-01 -3.48013806e-01]\n",
      "New theta_0 : [ 3.73638842e-03 -7.46893034e-02  4.48545689e-02  2.23038043e-02\n",
      "  5.80012168e-02 -1.36010616e-01  3.85435562e-01 -3.20228996e-04\n",
      " -1.94944764e-01  1.87382700e-01 -1.55852610e-01 -2.17061838e-01\n",
      "  1.13883642e-01 -3.48216505e-01]\n",
      "Training Error:  10.632905119214872\n",
      "====================================================================================================\n",
      "Iteration:  349\n",
      "Previous theta :  [ 3.73638842e-03 -7.46893034e-02  4.48545689e-02  2.23038043e-02\n",
      "  5.80012168e-02 -1.36010616e-01  3.85435562e-01 -3.20228996e-04\n",
      " -1.94944764e-01  1.87382700e-01 -1.55852610e-01 -2.17061838e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.13883642e-01 -3.48216505e-01]\n",
      "New theta_0 : [ 3.71375331e-03 -7.48096072e-02  4.51088461e-02  2.22221101e-02\n",
      "  5.80150598e-02 -1.36814991e-01  3.85104124e-01 -3.43617322e-04\n",
      " -1.95898176e-01  1.87752263e-01 -1.55884493e-01 -2.17175388e-01\n",
      "  1.13802613e-01 -3.48416857e-01]\n",
      "Training Error:  10.63110715705993\n",
      "====================================================================================================\n",
      "Iteration:  350\n",
      "Previous theta :  [ 3.71375331e-03 -7.48096072e-02  4.51088461e-02  2.22221101e-02\n",
      "  5.80150598e-02 -1.36814991e-01  3.85104124e-01 -3.43617322e-04\n",
      " -1.95898176e-01  1.87752263e-01 -1.55884493e-01 -2.17175388e-01\n",
      "  1.13802613e-01 -3.48416857e-01]\n",
      "New theta_0 : [ 3.69128666e-03 -7.49292309e-02  4.53621992e-02  2.21419313e-02\n",
      "  5.80287488e-02 -1.37614087e-01  3.84775829e-01 -3.66220853e-04\n",
      " -1.96844633e-01  1.88119782e-01 -1.55917432e-01 -2.17287725e-01\n",
      "  1.13722315e-01 -3.48614891e-01]\n",
      "Training Error:  10.629334186710782\n",
      "====================================================================================================\n",
      "Iteration:  351\n",
      "Previous theta :  [ 3.69128666e-03 -7.49292309e-02  4.53621992e-02  2.21419313e-02\n",
      "  5.80287488e-02 -1.37614087e-01  3.84775829e-01 -3.66220853e-04\n",
      " -1.96844633e-01  1.88119782e-01 -1.55917432e-01 -2.17287725e-01\n",
      "  1.13722315e-01 -3.48614891e-01]\n",
      "New theta_0 : [ 0.00366899 -0.07504818  0.04561462  0.02206325  0.05804228 -0.13840794\n",
      "  0.38445064 -0.00038806 -0.19778419  0.18848528 -0.15595141 -0.21739886\n",
      "  0.11364274 -0.34881064]\n",
      "Training Error:  10.627585843394007\n",
      "====================================================================================================\n",
      "Iteration:  352\n",
      "Previous theta :  [ 0.00366899 -0.07504818  0.04561462  0.02206325  0.05804228 -0.13840794\n",
      "  0.38445064 -0.00038806 -0.19778419  0.18848528 -0.15595141 -0.21739886\n",
      "  0.11364274 -0.34881064]\n",
      "New theta_0 : [ 0.00364685 -0.07516645  0.04586611  0.02198605  0.05805567 -0.13919658\n",
      "  0.38412853 -0.00040914 -0.19871689  0.18884876 -0.15598643 -0.21750882\n",
      "  0.11356388 -0.34900412]\n",
      "Training Error:  10.62586176791628\n",
      "====================================================================================================\n",
      "Iteration:  353\n",
      "Previous theta :  [ 0.00364685 -0.07516645  0.04586611  0.02198605  0.05805567 -0.13919658\n",
      "  0.38412853 -0.00040914 -0.19871689  0.18884876 -0.15598643 -0.21750882\n",
      "  0.11356388 -0.34900412]\n",
      "New theta_0 : [ 0.00362488 -0.07528405  0.04611666  0.02191032  0.0580689  -0.13998004\n",
      "  0.38380947 -0.00042949 -0.19964279  0.18921025 -0.15602246 -0.21761761\n",
      "  0.11348573 -0.34919537]\n",
      "Training Error:  10.624161606573374\n",
      "====================================================================================================\n",
      "Iteration:  354\n",
      "Previous theta :  [ 0.00362488 -0.07528405  0.04611666  0.02191032  0.0580689  -0.13998004\n",
      "  0.38380947 -0.00042949 -0.19964279  0.18921025 -0.15602246 -0.21761761\n",
      "  0.11348573 -0.34919537]\n",
      "New theta_0 : [ 0.00360308 -0.07540097  0.04636626  0.02183603  0.05808199 -0.14075835\n",
      "  0.38349342 -0.00044911 -0.20056195  0.18956977 -0.1560595  -0.21772524\n",
      "  0.11340828 -0.34938442]\n",
      "Training Error:  10.622485011060782\n",
      "====================================================================================================\n",
      "Iteration:  355\n",
      "Previous theta :  [ 0.00360308 -0.07540097  0.04636626  0.02183603  0.05808199 -0.14075835\n",
      "  0.38349342 -0.00044911 -0.20056195  0.18956977 -0.1560595  -0.21772524\n",
      "  0.11340828 -0.34938442]\n",
      "New theta_0 : [ 0.00358143 -0.07551723  0.04661492  0.02176318  0.05809493 -0.14153156\n",
      "  0.38318034 -0.00046803 -0.20147441  0.18992733 -0.15609754 -0.21783174\n",
      "  0.11333153 -0.34957129]\n",
      "Training Error:  10.620831638385932\n",
      "====================================================================================================\n",
      "Iteration:  356\n",
      "Previous theta :  [ 0.00358143 -0.07551723  0.04661492  0.02176318  0.05809493 -0.14153156\n",
      "  0.38318034 -0.00046803 -0.20147441  0.18992733 -0.15609754 -0.21783174\n",
      "  0.11333153 -0.34957129]\n",
      "New theta_0 : [ 0.00355995 -0.07563283  0.04686262  0.02169175  0.05810772 -0.14229968\n",
      "  0.38287022 -0.00048626 -0.20238022  0.19028294 -0.15613657 -0.21793711\n",
      "  0.11325546 -0.34975601]\n",
      "Training Error:  10.61920115078198\n",
      "====================================================================================================\n",
      "Iteration:  357\n",
      "Previous theta :  [ 0.00355995 -0.07563283  0.04686262  0.02169175  0.05810772 -0.14229968\n",
      "  0.38287022 -0.00048626 -0.20238022  0.19028294 -0.15613657 -0.21793711\n",
      "  0.11325546 -0.34975601]\n",
      "New theta_0 : [ 0.00353862 -0.07574776  0.04710936  0.02162171  0.05812036 -0.14306275\n",
      "  0.38256301 -0.00050382 -0.20327944  0.19063663 -0.15617657 -0.21804137\n",
      "  0.11318008 -0.3499386 ]\n",
      "Training Error:  10.617593215623096\n",
      "====================================================================================================\n",
      "Iteration:  358\n",
      "Previous theta :  [ 0.00353862 -0.07574776  0.04710936  0.02162171  0.05812036 -0.14306275\n",
      "  0.38256301 -0.00050382 -0.20327944  0.19063663 -0.15617657 -0.21804137\n",
      "  0.11318008 -0.3499386 ]\n",
      "New theta_0 : [ 0.00351745 -0.07586203  0.04735514  0.02155306  0.05813286 -0.14382081\n",
      "  0.38225869 -0.00052071 -0.20417212  0.19098841 -0.15621753 -0.21814453\n",
      "  0.11310537 -0.3501191 ]\n",
      "Training Error:  10.616007505341303\n",
      "====================================================================================================\n",
      "Iteration:  359\n",
      "Previous theta :  [ 0.00351745 -0.07586203  0.04735514  0.02155306  0.05813286 -0.14382081\n",
      "  0.38225869 -0.00052071 -0.20417212  0.19098841 -0.15621753 -0.21814453\n",
      "  0.11310537 -0.3501191 ]\n",
      "New theta_0 : [ 0.00349644 -0.07597564  0.04759995  0.02148578  0.05814522 -0.14457388\n",
      "  0.38195723 -0.00053695 -0.2050583   0.19133829 -0.15625944 -0.21824661\n",
      "  0.11303132 -0.35029752]\n",
      "Training Error:  10.61444369734473\n",
      "====================================================================================================\n",
      "Iteration:  360\n",
      "Previous theta :  [ 0.00349644 -0.07597564  0.04759995  0.02148578  0.05814522 -0.14457388\n",
      "  0.38195723 -0.00053695 -0.2050583   0.19133829 -0.15625944 -0.21824661\n",
      "  0.11303132 -0.35029752]\n",
      "New theta_0 : [ 0.00347558 -0.0760886   0.04784379  0.02141986  0.05815743 -0.14532201\n",
      "  0.38165859 -0.00055256 -0.20593803  0.1916863  -0.1563023  -0.21834762\n",
      "  0.11295793 -0.3504739 ]\n",
      "Training Error:  10.612901473937342\n",
      "====================================================================================================\n",
      "Iteration:  361\n",
      "Previous theta :  [ 0.00347558 -0.0760886   0.04784379  0.02141986  0.05815743 -0.14532201\n",
      "  0.38165859 -0.00055256 -0.20593803  0.1916863  -0.1563023  -0.21834762\n",
      "  0.11295793 -0.3504739 ]\n",
      "New theta_0 : [ 0.00345487 -0.07620091  0.04808666  0.02135527  0.05816951 -0.14606521\n",
      "  0.38136275 -0.00056756 -0.20681136  0.19203244 -0.15634608 -0.21844757\n",
      "  0.1128852  -0.35064826]\n",
      "Training Error:  10.611380522240088\n",
      "====================================================================================================\n",
      "Iteration:  362\n",
      "Previous theta :  [ 0.00345487 -0.07620091  0.04808666  0.02135527  0.05816951 -0.14606521\n",
      "  0.38136275 -0.00056756 -0.20681136  0.19203244 -0.15634608 -0.21844757\n",
      "  0.1128852  -0.35064826]\n",
      "New theta_0 : [ 0.00343432 -0.07631256  0.04832856  0.02129201  0.05818144 -0.14680352\n",
      "  0.38106968 -0.00058194 -0.20767835  0.19237673 -0.15639079 -0.21854649\n",
      "  0.11281311 -0.35082062]\n",
      "Training Error:  10.609880534113389\n",
      "====================================================================================================\n",
      "Iteration:  363\n",
      "Previous theta :  [ 0.00343432 -0.07631256  0.04832856  0.02129201  0.05818144 -0.14680352\n",
      "  0.38106968 -0.00058194 -0.20767835  0.19237673 -0.15639079 -0.21854649\n",
      "  0.11281311 -0.35082062]\n",
      "New theta_0 : [ 0.00341392 -0.07642357  0.04856947  0.02123005  0.05819324 -0.14753697\n",
      "  0.38077934 -0.00059573 -0.20853903  0.19271919 -0.1564364  -0.21864437\n",
      "  0.11274166 -0.35099101]\n",
      "Training Error:  10.608401206081046\n",
      "====================================================================================================\n",
      "Iteration:  364\n",
      "Previous theta :  [ 0.00341392 -0.07642357  0.04856947  0.02123005  0.05819324 -0.14753697\n",
      "  0.38077934 -0.00059573 -0.20853903  0.19271919 -0.1564364  -0.21864437\n",
      "  0.11274166 -0.35099101]\n",
      "New theta_0 : [ 0.00339367 -0.07653394  0.04880941  0.02116939  0.0582049  -0.1482656\n",
      "  0.38049172 -0.00060895 -0.20939346  0.19305984 -0.15648291 -0.21874123\n",
      "  0.11267085 -0.35115944]\n",
      "Training Error:  10.60694223925543\n",
      "====================================================================================================\n",
      "Iteration:  365\n",
      "Previous theta :  [ 0.00339367 -0.07653394  0.04880941  0.02116939  0.0582049  -0.1482656\n",
      "  0.38049172 -0.00060895 -0.20939346  0.19305984 -0.15648291 -0.21874123\n",
      "  0.11267085 -0.35115944]\n",
      "New theta_0 : [ 0.00337356 -0.07664366  0.04904835  0.02111001  0.05821642 -0.14898943\n",
      "  0.38020677 -0.00062159 -0.21024168  0.19339868 -0.15653031 -0.21883709\n",
      "  0.11260066 -0.35132596]\n",
      "Training Error:  10.605503339263993\n",
      "====================================================================================================\n",
      "Iteration:  366\n",
      "Previous theta :  [ 0.00337356 -0.07664366  0.04904835  0.02111001  0.05821642 -0.14898943\n",
      "  0.38020677 -0.00062159 -0.21024168  0.19339868 -0.15653031 -0.21883709\n",
      "  0.11260066 -0.35132596]\n",
      "New theta_0 : [ 0.00335361 -0.07675274  0.04928632  0.0210519   0.05822781 -0.1497085\n",
      "  0.37992448 -0.00063368 -0.21108374  0.19373573 -0.15657858 -0.21893196\n",
      "  0.1125311  -0.35149058]\n",
      "Training Error:  10.604084216177073\n",
      "====================================================================================================\n",
      "Iteration:  367\n",
      "Previous theta :  [ 0.00335361 -0.07675274  0.04928632  0.0210519   0.05822781 -0.1497085\n",
      "  0.37992448 -0.00063368 -0.21108374  0.19373573 -0.15657858 -0.21893196\n",
      "  0.1125311  -0.35149058]\n",
      "New theta_0 : [ 0.0033338  -0.07686119  0.04952329  0.02099503  0.05823906 -0.15042283\n",
      "  0.37964481 -0.00064523 -0.21191968  0.19407101 -0.15662772 -0.21902585\n",
      "  0.11246215 -0.35165331]\n",
      "Training Error:  10.602684584436933\n",
      "====================================================================================================\n",
      "Iteration:  368\n",
      "Previous theta :  [ 0.0033338  -0.07686119  0.04952329  0.02099503  0.05823906 -0.15042283\n",
      "  0.37964481 -0.00064523 -0.21191968  0.19407101 -0.15662772 -0.21902585\n",
      "  0.11246215 -0.35165331]\n",
      "New theta_0 : [ 0.00331413 -0.07696901  0.04975927  0.0209394   0.05825018 -0.15113246\n",
      "  0.37936774 -0.00065624 -0.21274956  0.19440453 -0.15667772 -0.21911877\n",
      "  0.1123938  -0.3518142 ]\n",
      "Training Error:  10.601304162788034\n",
      "====================================================================================================\n",
      "Iteration:  369\n",
      "Previous theta :  [ 0.00331413 -0.07696901  0.04975927  0.0209394   0.05825018 -0.15113246\n",
      "  0.37936774 -0.00065624 -0.21274956  0.19440453 -0.15667772 -0.21911877\n",
      "  0.1123938  -0.3518142 ]\n",
      "New theta_0 : [ 0.00329461 -0.07707619  0.04999425  0.020885    0.05826117 -0.15183741\n",
      "  0.37909325 -0.00066673 -0.21357341  0.19473631 -0.15672856 -0.21921074\n",
      "  0.11232606 -0.35197325]\n",
      "Training Error:  10.599942674208537\n",
      "====================================================================================================\n",
      "Iteration:  370\n",
      "Previous theta :  [ 0.00329461 -0.07707619  0.04999425  0.020885    0.05826117 -0.15183741\n",
      "  0.37909325 -0.00066673 -0.21357341  0.19473631 -0.15672856 -0.21921074\n",
      "  0.11232606 -0.35197325]\n",
      "New theta_0 : [ 0.00327523 -0.07718275  0.05022824  0.0208318   0.05827202 -0.15253772\n",
      "  0.37882129 -0.00067672 -0.21439129  0.19506635 -0.15678024 -0.21930176\n",
      "  0.11225892 -0.35213049]\n",
      "Training Error:  10.598599845842953\n",
      "====================================================================================================\n",
      "Iteration:  371\n",
      "Previous theta :  [ 0.00327523 -0.07718275  0.05022824  0.0208318   0.05827202 -0.15253772\n",
      "  0.37882129 -0.00067672 -0.21439129  0.19506635 -0.15678024 -0.21930176\n",
      "  0.11225892 -0.35213049]\n",
      "New theta_0 : [ 0.003256   -0.07728868  0.05046123  0.02077979  0.05828275 -0.15323341\n",
      "  0.37855186 -0.00068621 -0.21520324  0.19539468 -0.15683274 -0.21939185\n",
      "  0.11219237 -0.35228595]\n",
      "Training Error:  10.597275408935984\n",
      "====================================================================================================\n",
      "Iteration:  372\n",
      "Previous theta :  [ 0.003256   -0.07728868  0.05046123  0.02077979  0.05828275 -0.15323341\n",
      "  0.37855186 -0.00068621 -0.21520324  0.19539468 -0.15683274 -0.21939185\n",
      "  0.11219237 -0.35228595]\n",
      "New theta_0 : [ 0.0032369  -0.07739399  0.05069323  0.02072897  0.05829335 -0.15392452\n",
      "  0.37828492 -0.00069522 -0.21600929  0.19572131 -0.15688606 -0.21948102\n",
      "  0.1121264  -0.35243964]\n",
      "Training Error:  10.595969098767487\n",
      "====================================================================================================\n",
      "Iteration:  373\n",
      "Previous theta :  [ 0.0032369  -0.07739399  0.05069323  0.02072897  0.05829335 -0.15392452\n",
      "  0.37828492 -0.00069522 -0.21600929  0.19572131 -0.15688606 -0.21948102\n",
      "  0.1121264  -0.35243964]\n",
      "New theta_0 : [ 0.00321794 -0.07749868  0.05092422  0.02067932  0.05830382 -0.15461107\n",
      "  0.37802044 -0.00070375 -0.21680951  0.19604625 -0.15694019 -0.21956928\n",
      "  0.11206102 -0.35259159]\n",
      "Training Error:  10.594680654588556\n",
      "====================================================================================================\n",
      "Iteration:  374\n",
      "Previous theta :  [ 0.00321794 -0.07749868  0.05092422  0.02067932  0.05830382 -0.15461107\n",
      "  0.37802044 -0.00070375 -0.21680951  0.19604625 -0.15694019 -0.21956928\n",
      "  0.11206102 -0.35259159]\n",
      "New theta_0 : [ 0.00319913 -0.07760275  0.05115421  0.02063082  0.05831416 -0.1552931\n",
      "  0.3777584  -0.00071181 -0.21760392  0.19636951 -0.15699511 -0.21965664\n",
      "  0.1119962  -0.35274181]\n",
      "Training Error:  10.593409819558705\n",
      "====================================================================================================\n",
      "Iteration:  375\n",
      "Previous theta :  [ 0.00319913 -0.07760275  0.05115421  0.02063082  0.05831416 -0.1552931\n",
      "  0.3777584  -0.00071181 -0.21760392  0.19636951 -0.15699511 -0.21965664\n",
      "  0.1119962  -0.35274181]\n",
      "New theta_0 : [ 0.00318044 -0.07770621  0.0513832   0.02058346  0.05832438 -0.15597063\n",
      "  0.37749878 -0.00071942 -0.21839258  0.19669111 -0.15705082 -0.21974311\n",
      "  0.11193196 -0.35289034]\n",
      "Training Error:  10.59215634068412\n",
      "====================================================================================================\n",
      "Iteration:  376\n",
      "Previous theta :  [ 0.00318044 -0.07770621  0.0513832   0.02058346  0.05832438 -0.15597063\n",
      "  0.37749878 -0.00071942 -0.21839258  0.19669111 -0.15705082 -0.21974311\n",
      "  0.11193196 -0.35289034]\n",
      "New theta_0 : [ 0.0031619  -0.07780905  0.05161118  0.02053723  0.05833447 -0.15664369\n",
      "  0.37724154 -0.00072659 -0.21917552  0.19701106 -0.1571073  -0.21982871\n",
      "  0.11186828 -0.35303718]\n",
      "Training Error:  10.590919968756976\n",
      "====================================================================================================\n",
      "Iteration:  377\n",
      "Previous theta :  [ 0.0031619  -0.07780905  0.05161118  0.02053723  0.05833447 -0.15664369\n",
      "  0.37724154 -0.00072659 -0.21917552  0.19701106 -0.1571073  -0.21982871\n",
      "  0.11186828 -0.35303718]\n",
      "New theta_0 : [ 0.00314349 -0.07791129  0.05183816  0.02049211  0.05834444 -0.15731231\n",
      "  0.37698668 -0.00073332 -0.21995279  0.19732937 -0.15716456 -0.21991344\n",
      "  0.11180515 -0.35318236]\n",
      "Training Error:  10.589700458295761\n",
      "====================================================================================================\n",
      "Iteration:  378\n",
      "Previous theta :  [ 0.00314349 -0.07791129  0.05183816  0.02049211  0.05834444 -0.15731231\n",
      "  0.37698668 -0.00073332 -0.21995279  0.19732937 -0.15716456 -0.21991344\n",
      "  0.11180515 -0.35318236]\n",
      "New theta_0 : [ 0.00312521 -0.07801293  0.05206414  0.0204481   0.05835429 -0.15797652\n",
      "  0.37673415 -0.00073963 -0.22072444  0.19764607 -0.15722257 -0.21999731\n",
      "  0.11174258 -0.35332591]\n",
      "Training Error:  10.58849756748665\n",
      "====================================================================================================\n",
      "Iteration:  379\n",
      "Previous theta :  [ 0.00312521 -0.07801293  0.05206414  0.0204481   0.05835429 -0.15797652\n",
      "  0.37673415 -0.00073963 -0.22072444  0.19764607 -0.15722257 -0.21999731\n",
      "  0.11174258 -0.35332591]\n",
      "New theta_0 : [ 0.00310707 -0.07811396  0.05228911  0.02040517  0.05836401 -0.15863635\n",
      "  0.37648394 -0.00074553 -0.2214905   0.19796115 -0.15728133 -0.22008034\n",
      "  0.11168055 -0.35346783]\n",
      "Training Error:  10.587311058125849\n",
      "====================================================================================================\n",
      "Iteration:  380\n",
      "Previous theta :  [ 0.00310707 -0.07811396  0.05228911  0.02040517  0.05836401 -0.15863635\n",
      "  0.37648394 -0.00074553 -0.2214905   0.19796115 -0.15728133 -0.22008034\n",
      "  0.11168055 -0.35346783]\n",
      "New theta_0 : [ 0.00308905 -0.07821439  0.05251307  0.02036332  0.05837362 -0.15929182\n",
      "  0.37623602 -0.00075102 -0.22225101  0.19827464 -0.15734083 -0.22016254\n",
      "  0.11161906 -0.35360815]\n",
      "Training Error:  10.586140695562927\n",
      "====================================================================================================\n",
      "Iteration:  381\n",
      "Previous theta :  [ 0.00308905 -0.07821439  0.05251307  0.02036332  0.05837362 -0.15929182\n",
      "  0.37623602 -0.00075102 -0.22225101  0.19827464 -0.15734083 -0.22016254\n",
      "  0.11161906 -0.35360815]\n",
      "New theta_0 : [ 0.00307117 -0.07831423  0.05273603  0.02032254  0.0583831  -0.15994297\n",
      "  0.37599038 -0.00075612 -0.22300602  0.19858654 -0.15740106 -0.22024391\n",
      "  0.11155811 -0.35374689]\n",
      "Training Error:  10.584986248645093\n",
      "====================================================================================================\n",
      "Iteration:  382\n",
      "Previous theta :  [ 0.00307117 -0.07831423  0.05273603  0.02032254  0.0583831  -0.15994297\n",
      "  0.37599038 -0.00075612 -0.22300602  0.19858654 -0.15740106 -0.22024391\n",
      "  0.11155811 -0.35374689]\n",
      "New theta_0 : [ 0.00305342 -0.07841347  0.05295797  0.02028281  0.05839247 -0.16058982\n",
      "  0.37574697 -0.00076083 -0.22375557  0.19889687 -0.15746201 -0.22032447\n",
      "  0.11149769 -0.35388407]\n",
      "Training Error:  10.58384748966245\n",
      "====================================================================================================\n",
      "Iteration:  383\n",
      "Previous theta :  [ 0.00305342 -0.07841347  0.05295797  0.02028281  0.05839247 -0.16058982\n",
      "  0.37574697 -0.00076083 -0.22375557  0.19889687 -0.15746201 -0.22032447\n",
      "  0.11149769 -0.35388407]\n",
      "New theta_0 : [ 0.0030358  -0.07851212  0.05317892  0.02024412  0.05840172 -0.16123239\n",
      "  0.3755058  -0.00076516 -0.2244997   0.19920564 -0.15752368 -0.22040422\n",
      "  0.1114378  -0.35401971]\n",
      "Training Error:  10.582724194294107\n",
      "====================================================================================================\n",
      "Iteration:  384\n",
      "Previous theta :  [ 0.0030358  -0.07851212  0.05317892  0.02024412  0.05840172 -0.16123239\n",
      "  0.3755058  -0.00076516 -0.2244997   0.19920564 -0.15752368 -0.22040422\n",
      "  0.1114378  -0.35401971]\n",
      "New theta_0 : [ 0.0030183  -0.07861018  0.05339885  0.02020645  0.05841085 -0.16187073\n",
      "  0.37526682 -0.00076913 -0.22523845  0.19951286 -0.15758604 -0.22048318\n",
      "  0.11137843 -0.35415382]\n",
      "Training Error:  10.581616141555262\n",
      "====================================================================================================\n",
      "Iteration:  385\n",
      "Previous theta :  [ 0.0030183  -0.07861018  0.05339885  0.02020645  0.05841085 -0.16187073\n",
      "  0.37526682 -0.00076913 -0.22523845  0.19951286 -0.15758604 -0.22048318\n",
      "  0.11137843 -0.35415382]\n",
      "New theta_0 : [ 0.00300093 -0.07870766  0.05361778  0.02016981  0.05841987 -0.16250485\n",
      "  0.37503002 -0.00077273 -0.22597186  0.19981855 -0.15764911 -0.22056135\n",
      "  0.11131957 -0.35428643]\n",
      "Training Error:  10.580523113745143\n",
      "====================================================================================================\n",
      "Iteration:  386\n",
      "Previous theta :  [ 0.00300093 -0.07870766  0.05361778  0.02016981  0.05841987 -0.16250485\n",
      "  0.37503002 -0.00077273 -0.22597186  0.19981855 -0.15764911 -0.22056135\n",
      "  0.11131957 -0.35428643]\n",
      "New theta_0 : [ 0.00298369 -0.07880456  0.0538357   0.02013416  0.05842877 -0.16313478\n",
      "  0.37479537 -0.00077599 -0.22669997  0.20012271 -0.15771286 -0.22063875\n",
      "  0.11126123 -0.35441755]\n",
      "Training Error:  10.57944489639581\n",
      "====================================================================================================\n",
      "Iteration:  387\n",
      "Previous theta :  [ 0.00298369 -0.07880456  0.0538357   0.02013416  0.05842877 -0.16313478\n",
      "  0.37479537 -0.00077599 -0.22669997  0.20012271 -0.15771286 -0.22063875\n",
      "  0.11126123 -0.35441755]\n",
      "New theta_0 : [ 0.00296657 -0.07890087  0.05405262  0.02009951  0.05843756 -0.16376055\n",
      "  0.37456286 -0.0007789  -0.22742282  0.20042536 -0.15777728 -0.22071538\n",
      "  0.11120339 -0.35454719]\n",
      "Training Error:  10.578381278221844\n",
      "====================================================================================================\n",
      "Iteration:  388\n",
      "Previous theta :  [ 0.00296657 -0.07890087  0.05405262  0.02009951  0.05843756 -0.16376055\n",
      "  0.37456286 -0.0007789  -0.22742282  0.20042536 -0.15777728 -0.22071538\n",
      "  0.11120339 -0.35454719]\n",
      "New theta_0 : [ 0.00294957 -0.07899661  0.05426853  0.02006584  0.05844623 -0.16438218\n",
      "  0.37433246 -0.00078147 -0.22814045  0.20072652 -0.15784238 -0.22079126\n",
      "  0.11114605 -0.35467539]\n",
      "Training Error:  10.57733205107085\n",
      "====================================================================================================\n",
      "Iteration:  389\n",
      "Previous theta :  [ 0.00294957 -0.07899661  0.05426853  0.02006584  0.05844623 -0.16438218\n",
      "  0.37433246 -0.00078147 -0.22814045  0.20072652 -0.15784238 -0.22079126\n",
      "  0.11114605 -0.35467539]\n",
      "New theta_0 : [ 0.0029327  -0.07909178  0.05448343  0.02003314  0.05845479 -0.16499971\n",
      "  0.37410414 -0.00078372 -0.2288529   0.20102618 -0.15790814 -0.22086638\n",
      "  0.11108921 -0.35480216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.576297009874798\n",
      "====================================================================================================\n",
      "Iteration:  390\n",
      "Previous theta :  [ 0.0029327  -0.07909178  0.05448343  0.02003314  0.05845479 -0.16499971\n",
      "  0.37410414 -0.00078372 -0.2288529   0.20102618 -0.15790814 -0.22086638\n",
      "  0.11108921 -0.35480216]\n",
      "New theta_0 : [ 0.00291595 -0.07918638  0.05469733  0.0200014   0.05846325 -0.16561315\n",
      "  0.3738779  -0.00078565 -0.2295602   0.20132437 -0.15797455 -0.22094077\n",
      "  0.11103286 -0.3549275 ]\n",
      "Training Error:  10.575275952602166\n",
      "====================================================================================================\n",
      "Iteration:  391\n",
      "Previous theta :  [ 0.00291595 -0.07918638  0.05469733  0.0200014   0.05846325 -0.16561315\n",
      "  0.3738779  -0.00078565 -0.2295602   0.20132437 -0.15797455 -0.22094077\n",
      "  0.11103286 -0.3549275 ]\n",
      "New theta_0 : [ 0.00289932 -0.0792804   0.05491022  0.01997061  0.05847159 -0.16622254\n",
      "  0.37365371 -0.00078727 -0.23026239  0.20162109 -0.1580416  -0.22101442\n",
      "  0.11097699 -0.35505145]\n",
      "Training Error:  10.574268680210883\n",
      "====================================================================================================\n",
      "Iteration:  392\n",
      "Previous theta :  [ 0.00289932 -0.0792804   0.05491022  0.01997061  0.05847159 -0.16622254\n",
      "  0.37365371 -0.00078727 -0.23026239  0.20162109 -0.1580416  -0.22101442\n",
      "  0.11097699 -0.35505145]\n",
      "New theta_0 : [ 0.00288281 -0.07937387  0.05512212  0.01994075  0.05847982 -0.16682791\n",
      "  0.37343154 -0.00078858 -0.23095952  0.20191636 -0.15810928 -0.22108736\n",
      "  0.11092161 -0.35517401]\n",
      "Training Error:  10.57327499660206\n",
      "====================================================================================================\n",
      "Iteration:  393\n",
      "Previous theta :  [ 0.00288281 -0.07937387  0.05512212  0.01994075  0.05847982 -0.16682791\n",
      "  0.37343154 -0.00078858 -0.23095952  0.20191636 -0.15810928 -0.22108736\n",
      "  0.11092161 -0.35517401]\n",
      "New theta_0 : [ 0.00286642 -0.07946677  0.05533301  0.01991181  0.05848794 -0.16742927\n",
      "  0.37321138 -0.0007896  -0.23165162  0.20221019 -0.1581776  -0.22115958\n",
      "  0.11086671 -0.35529521]\n",
      "Training Error:  10.572294708574455\n",
      "====================================================================================================\n",
      "Iteration:  394\n",
      "Previous theta :  [ 0.00286642 -0.07946677  0.05533301  0.01991181  0.05848794 -0.16742927\n",
      "  0.37321138 -0.0007896  -0.23165162  0.20221019 -0.1581776  -0.22115958\n",
      "  0.11086671 -0.35529521]\n",
      "New theta_0 : [ 0.00285015 -0.07955911  0.0555429   0.01988379  0.05849596 -0.16802665\n",
      "  0.3729932  -0.00079032 -0.23233872  0.20250258 -0.15824653 -0.2212311\n",
      "  0.11081228 -0.35541505]\n",
      "Training Error:  10.571327625779741\n",
      "====================================================================================================\n",
      "Iteration:  395\n",
      "Previous theta :  [ 0.00285015 -0.07955911  0.0555429   0.01988379  0.05849596 -0.16802665\n",
      "  0.3729932  -0.00079032 -0.23233872  0.20250258 -0.15824653 -0.2212311\n",
      "  0.11081228 -0.35541505]\n",
      "New theta_0 : [ 0.002834   -0.0796509   0.05575179  0.01985668  0.05850387 -0.16862008\n",
      "  0.37277699 -0.00079077 -0.23302087  0.20279356 -0.15831608 -0.22130192\n",
      "  0.11075832 -0.35553356]\n",
      "Training Error:  10.57037356067846\n",
      "====================================================================================================\n",
      "Iteration:  396\n",
      "Previous theta :  [ 0.002834   -0.0796509   0.05575179  0.01985668  0.05850387 -0.16862008\n",
      "  0.37277699 -0.00079077 -0.23302087  0.20279356 -0.15831608 -0.22130192\n",
      "  0.11075832 -0.35553356]\n",
      "New theta_0 : [ 0.00281796 -0.07974213  0.05595968  0.01983045  0.05851168 -0.16920959\n",
      "  0.37256272 -0.00079094 -0.23369811  0.20308312 -0.15838623 -0.22137205\n",
      "  0.11070483 -0.35565076]\n",
      "Training Error:  10.569432328496742\n",
      "====================================================================================================\n",
      "Iteration:  397\n",
      "Previous theta :  [ 0.00281796 -0.07974213  0.05595968  0.01983045  0.05851168 -0.16920959\n",
      "  0.37256272 -0.00079094 -0.23369811  0.20308312 -0.15838623 -0.22137205\n",
      "  0.11070483 -0.35565076]\n",
      "New theta_0 : [ 0.00280203 -0.07983282  0.05616657  0.01980511  0.05851938 -0.16979519\n",
      "  0.37235039 -0.00079084 -0.23437046  0.20337128 -0.15845697 -0.22144151\n",
      "  0.11065179 -0.35576665]\n",
      "Training Error:  10.568503747183707\n",
      "====================================================================================================\n",
      "Iteration:  398\n",
      "Previous theta :  [ 0.00280203 -0.07983282  0.05616657  0.01980511  0.05851938 -0.16979519\n",
      "  0.37235039 -0.00079084 -0.23437046  0.20337128 -0.15845697 -0.22144151\n",
      "  0.11065179 -0.35576665]\n",
      "New theta_0 : [ 0.00278623 -0.07992295  0.05637246  0.01978064  0.05852697 -0.17037693\n",
      "  0.37213995 -0.00079047 -0.23503796  0.20365806 -0.1585283  -0.22151029\n",
      "  0.11059922 -0.35588126]\n",
      "Training Error:  10.567587637369588\n",
      "====================================================================================================\n",
      "Iteration:  399\n",
      "Previous theta :  [ 0.00278623 -0.07992295  0.05637246  0.01978064  0.05852697 -0.17037693\n",
      "  0.37213995 -0.00079047 -0.23503796  0.20365806 -0.1585283  -0.22151029\n",
      "  0.11059922 -0.35588126]\n",
      "New theta_0 : [ 0.00277053 -0.08001255  0.05657737  0.01975703  0.05853446 -0.17095481\n",
      "  0.37193141 -0.00078985 -0.23570065  0.20394346 -0.15860021 -0.22157841\n",
      "  0.11054709 -0.35599459]\n",
      "Training Error:  10.56668382232453\n",
      "====================================================================================================\n",
      "Iteration:  400\n",
      "Previous theta :  [ 0.00277053 -0.08001255  0.05657737  0.01975703  0.05853446 -0.17095481\n",
      "  0.37193141 -0.00078985 -0.23570065  0.20394346 -0.15860021 -0.22157841\n",
      "  0.11054709 -0.35599459]\n",
      "New theta_0 : [ 0.00275495 -0.0801016   0.05678128  0.01973427  0.05854185 -0.17152887\n",
      "  0.37172473 -0.00078898 -0.23635857  0.20422748 -0.15867269 -0.22164587\n",
      "  0.11049541 -0.35610667]\n",
      "Training Error:  10.56579212791805\n",
      "====================================================================================================\n",
      "Iteration:  401\n",
      "Previous theta :  [ 0.00275495 -0.0801016   0.05678128  0.01973427  0.05854185 -0.17152887\n",
      "  0.37172473 -0.00078898 -0.23635857  0.20422748 -0.15867269 -0.22164587\n",
      "  0.11049541 -0.35610667]\n",
      "New theta_0 : [ 0.00273948 -0.08019011  0.05698419  0.01971235  0.05854914 -0.17209913\n",
      "  0.37151991 -0.00078787 -0.23701176  0.20451016 -0.15874574 -0.22171269\n",
      "  0.11044418 -0.35621751]\n",
      "Training Error:  10.5649123825792\n",
      "====================================================================================================\n",
      "Iteration:  402\n",
      "Previous theta :  [ 0.00273948 -0.08019011  0.05698419  0.01971235  0.05854914 -0.17209913\n",
      "  0.37151991 -0.00078787 -0.23701176  0.20451016 -0.15874574 -0.22171269\n",
      "  0.11044418 -0.35621751]\n",
      "New theta_0 : [ 0.00272412 -0.08027809  0.05718612  0.01969127  0.05855633 -0.17266562\n",
      "  0.37131691 -0.00078652 -0.23766023  0.20479148 -0.15881934 -0.22177886\n",
      "  0.11039338 -0.35632712]\n",
      "Training Error:  10.564044417257325\n",
      "====================================================================================================\n",
      "Iteration:  403\n",
      "Previous theta :  [ 0.00272412 -0.08027809  0.05718612  0.01969127  0.05855633 -0.17266562\n",
      "  0.37131691 -0.00078652 -0.23766023  0.20479148 -0.15881934 -0.22177886\n",
      "  0.11039338 -0.35632712]\n",
      "New theta_0 : [ 0.00270887 -0.08036553  0.05738706  0.019671    0.05856342 -0.17322835\n",
      "  0.37111573 -0.00078495 -0.23830404  0.20507147 -0.15889349 -0.2218444\n",
      "  0.11034302 -0.35643552]\n",
      "Training Error:  10.563188065383505\n",
      "====================================================================================================\n",
      "Iteration:  404\n",
      "Previous theta :  [ 0.00270887 -0.08036553  0.05738706  0.019671    0.05856342 -0.17322835\n",
      "  0.37111573 -0.00078495 -0.23830404  0.20507147 -0.15889349 -0.2218444\n",
      "  0.11034302 -0.35643552]\n",
      "New theta_0 : [ 0.00269373 -0.08045245  0.05758701  0.01965155  0.05857041 -0.17378736\n",
      "  0.37091634 -0.00078314 -0.23894322  0.20535013 -0.15896819 -0.22190932\n",
      "  0.11029309 -0.35654273]\n",
      "Training Error:  10.562343162832592\n",
      "====================================================================================================\n",
      "Iteration:  405\n",
      "Previous theta :  [ 0.00269373 -0.08045245  0.05758701  0.01965155  0.05857041 -0.17378736\n",
      "  0.37091634 -0.00078314 -0.23894322  0.20535013 -0.15896819 -0.22190932\n",
      "  0.11029309 -0.35654273]\n",
      "New theta_0 : [ 0.0026787  -0.08053883  0.05778598  0.01963289  0.0585773  -0.17434267\n",
      "  0.37071872 -0.00078112 -0.23957779  0.20562747 -0.15904341 -0.22197361\n",
      "  0.11024359 -0.35664875]\n",
      "Training Error:  10.561509547885901\n",
      "====================================================================================================\n",
      "Iteration:  406\n",
      "Previous theta :  [ 0.0026787  -0.08053883  0.05778598  0.01963289  0.0585773  -0.17434267\n",
      "  0.37071872 -0.00078112 -0.23957779  0.20562747 -0.15904341 -0.22197361\n",
      "  0.11024359 -0.35664875]\n",
      "New theta_0 : [ 0.00266378 -0.0806247   0.05798396  0.01961503  0.0585841  -0.1748943\n",
      "  0.37052287 -0.00077888 -0.2402078   0.2059035  -0.15911917 -0.2220373\n",
      "  0.11019452 -0.3567536 ]\n",
      "Training Error:  10.560687061194459\n",
      "====================================================================================================\n",
      "Iteration:  407\n",
      "Previous theta :  [ 0.00266378 -0.0806247   0.05798396  0.01961503  0.0585841  -0.1748943\n",
      "  0.37052287 -0.00077888 -0.2402078   0.2059035  -0.15911917 -0.2220373\n",
      "  0.11019452 -0.3567536 ]\n",
      "New theta_0 : [ 0.00264897 -0.08071004  0.05818097  0.01959795  0.05859079 -0.17544228\n",
      "  0.37032876 -0.00077643 -0.24083328  0.20617824 -0.15919545 -0.22210038\n",
      "  0.11014586 -0.3568573 ]\n",
      "Training Error:  10.559875545742877\n",
      "====================================================================================================\n",
      "Iteration:  408\n",
      "Previous theta :  [ 0.00264897 -0.08071004  0.05818097  0.01959795  0.05859079 -0.17544228\n",
      "  0.37032876 -0.00077643 -0.24083328  0.20617824 -0.15919545 -0.22210038\n",
      "  0.11014586 -0.3568573 ]\n",
      "New theta_0 : [ 0.00263426 -0.08079486  0.05837699  0.01958165  0.0585974  -0.17598663\n",
      "  0.37013637 -0.00077378 -0.24145426  0.20645169 -0.15927224 -0.22216287\n",
      "  0.11009762 -0.35695986]\n",
      "Training Error:  10.559074846813814\n",
      "====================================================================================================\n",
      "Iteration:  409\n",
      "Previous theta :  [ 0.00263426 -0.08079486  0.05837699  0.01958165  0.0585974  -0.17598663\n",
      "  0.37013637 -0.00077378 -0.24145426  0.20645169 -0.15927224 -0.22216287\n",
      "  0.11009762 -0.35695986]\n",
      "New theta_0 : [ 0.00261965 -0.08087917  0.05857204  0.0195661   0.0586039  -0.17652737\n",
      "  0.36994568 -0.00077094 -0.24207078  0.20672385 -0.15934953 -0.22222477\n",
      "  0.11004979 -0.35706129]\n",
      "Training Error:  10.558284811952987\n",
      "====================================================================================================\n",
      "Iteration:  410\n",
      "Previous theta :  [ 0.00261965 -0.08087917  0.05857204  0.0195661   0.0586039  -0.17652737\n",
      "  0.36994568 -0.00077094 -0.24207078  0.20672385 -0.15934953 -0.22222477\n",
      "  0.11004979 -0.35706129]\n",
      "New theta_0 : [ 0.00260515 -0.08096297  0.05876612  0.01955132  0.05861032 -0.17706453\n",
      "  0.36975669 -0.0007679  -0.24268286  0.20699475 -0.15942733 -0.22228608\n",
      "  0.11000237 -0.35716161]\n",
      "Training Error:  10.557505290934762\n",
      "====================================================================================================\n",
      "Iteration:  411\n",
      "Previous theta :  [ 0.00260515 -0.08096297  0.05876612  0.01955132  0.05861032 -0.17706453\n",
      "  0.36975669 -0.0007679  -0.24268286  0.20699475 -0.15942733 -0.22228608\n",
      "  0.11000237 -0.35716161]\n",
      "New theta_0 : [ 0.00259076 -0.08104625  0.05895922  0.01953727  0.05861664 -0.17759813\n",
      "  0.36956936 -0.00076467 -0.24329054  0.20726439 -0.15950561 -0.22234682\n",
      "  0.10995535 -0.35726083]\n",
      "Training Error:  10.556736135728299\n",
      "====================================================================================================\n",
      "Iteration:  412\n",
      "Previous theta :  [ 0.00259076 -0.08104625  0.05895922  0.01953727  0.05861664 -0.17759813\n",
      "  0.36956936 -0.00076467 -0.24329054  0.20726439 -0.15950561 -0.22234682\n",
      "  0.10995535 -0.35726083]\n",
      "New theta_0 : [ 0.00257647 -0.08112903  0.05915135  0.01952397  0.05862287 -0.17812819\n",
      "  0.3693837  -0.00076127 -0.24389386  0.20753278 -0.15958438 -0.22240699\n",
      "  0.10990874 -0.35735895]\n",
      "Training Error:  10.555977200464238\n",
      "====================================================================================================\n",
      "Iteration:  413\n",
      "Previous theta :  [ 0.00257647 -0.08112903  0.05915135  0.01952397  0.05862287 -0.17812819\n",
      "  0.3693837  -0.00076127 -0.24389386  0.20753278 -0.15958438 -0.22240699\n",
      "  0.10990874 -0.35735895]\n",
      "New theta_0 : [ 0.00256228 -0.08121131  0.05934252  0.01951139  0.058629   -0.17865475\n",
      "  0.36919967 -0.00075768 -0.24449284  0.20779992 -0.15966363 -0.22246659\n",
      "  0.10986252 -0.35745601]\n",
      "Training Error:  10.555228341401914\n",
      "====================================================================================================\n",
      "Iteration:  414\n",
      "Previous theta :  [ 0.00256228 -0.08121131  0.05934252  0.01951139  0.058629   -0.17865475\n",
      "  0.36919967 -0.00075768 -0.24449284  0.20779992 -0.15966363 -0.22246659\n",
      "  0.10986252 -0.35745601]\n",
      "New theta_0 : [ 0.00254819 -0.08129308  0.05953272  0.01949953  0.05863505 -0.17917781\n",
      "  0.36901727 -0.00075392 -0.24508752  0.20806584 -0.15974335 -0.22252564\n",
      "  0.10981669 -0.357552  ]\n",
      "Training Error:  10.554489416897104\n",
      "====================================================================================================\n",
      "Iteration:  415\n",
      "Previous theta :  [ 0.00254819 -0.08129308  0.05953272  0.01949953  0.05863505 -0.17917781\n",
      "  0.36901727 -0.00075392 -0.24508752  0.20806584 -0.15974335 -0.22252564\n",
      "  0.10981669 -0.357552  ]\n",
      "New theta_0 : [ 0.0025342  -0.08137436  0.05972196  0.01948837  0.058641   -0.1796974\n",
      "  0.36883647 -0.00075    -0.24567793  0.20833052 -0.15982354 -0.22258414\n",
      "  0.10977126 -0.35764695]\n",
      "Training Error:  10.553760287370288\n",
      "====================================================================================================\n",
      "Iteration:  416\n",
      "Previous theta :  [ 0.0025342  -0.08137436  0.05972196  0.01948837  0.058641   -0.1796974\n",
      "  0.36883647 -0.00075    -0.24567793  0.20833052 -0.15982354 -0.22258414\n",
      "  0.10977126 -0.35764695]\n",
      "New theta_0 : [ 0.00252032 -0.08145514  0.05991024  0.01947792  0.05864687 -0.18021356\n",
      "  0.36865726 -0.00074591 -0.2462641   0.208594   -0.15990419 -0.22264209\n",
      "  0.10972621 -0.35774085]\n",
      "Training Error:  10.553040815275414\n",
      "====================================================================================================\n",
      "Iteration:  417\n",
      "Previous theta :  [ 0.00252032 -0.08145514  0.05991024  0.01947792  0.05864687 -0.18021356\n",
      "  0.36865726 -0.00074591 -0.2462641   0.208594   -0.15990419 -0.22264209\n",
      "  0.10972621 -0.35774085]\n",
      "New theta_0 : [ 0.00250653 -0.08153542  0.06009756  0.01946817  0.05865265 -0.18072628\n",
      "  0.36847963 -0.00074167 -0.24684606  0.20885626 -0.15998528 -0.22269951\n",
      "  0.10968155 -0.35783373]\n",
      "Training Error:  10.55233086506918\n",
      "====================================================================================================\n",
      "Iteration:  418\n",
      "Previous theta :  [ 0.00250653 -0.08153542  0.06009756  0.01946817  0.05865265 -0.18072628\n",
      "  0.36847963 -0.00074167 -0.24684606  0.20885626 -0.15998528 -0.22269951\n",
      "  0.10968155 -0.35783373]\n",
      "New theta_0 : [ 0.00249284 -0.08161522  0.06028392  0.01945909  0.05865834 -0.18123561\n",
      "  0.36830356 -0.00073726 -0.24742384  0.20911733 -0.16006682 -0.2227564\n",
      "  0.10963726 -0.3579256 ]\n",
      "Training Error:  10.551630303180758\n",
      "====================================================================================================\n",
      "Iteration:  419\n",
      "Previous theta :  [ 0.00249284 -0.08161522  0.06028392  0.01945909  0.05865834 -0.18123561\n",
      "  0.36830356 -0.00073726 -0.24742384  0.20911733 -0.16006682 -0.2227564\n",
      "  0.10963726 -0.3579256 ]\n",
      "New theta_0 : [ 0.00247925 -0.08169453  0.06046933  0.01945069  0.05866394 -0.18174157\n",
      "  0.36812903 -0.00073271 -0.24799748  0.20937721 -0.1601488  -0.22281276\n",
      "  0.10959335 -0.35801647]\n",
      "Training Error:  10.55093899798206\n",
      "====================================================================================================\n",
      "Iteration:  420\n",
      "Previous theta :  [ 0.00247925 -0.08169453  0.06046933  0.01945069  0.05866394 -0.18174157\n",
      "  0.36812903 -0.00073271 -0.24799748  0.20937721 -0.1601488  -0.22281276\n",
      "  0.10959335 -0.35801647]\n",
      "New theta_0 : [ 0.00246575 -0.08177336  0.0606538   0.01944296  0.05866945 -0.18224417\n",
      "  0.36795603 -0.00072802 -0.248567    0.20963591 -0.16023122 -0.2228686\n",
      "  0.10954982 -0.35810635]\n",
      "Training Error:  10.550256819758438\n",
      "====================================================================================================\n",
      "Iteration:  421\n",
      "Previous theta :  [ 0.00246575 -0.08177336  0.0606538   0.01944296  0.05866945 -0.18224417\n",
      "  0.36795603 -0.00072802 -0.248567    0.20963591 -0.16023122 -0.2228686\n",
      "  0.10954982 -0.35810635]\n",
      "New theta_0 : [ 0.00245235 -0.0818517   0.06083731  0.01943589  0.05867488 -0.18274343\n",
      "  0.36778455 -0.00072318 -0.24913244  0.20989344 -0.16031406 -0.22292392\n",
      "  0.10950665 -0.35819526]\n",
      "Training Error:  10.549583640679854\n",
      "====================================================================================================\n",
      "Iteration:  422\n",
      "Previous theta :  [ 0.00245235 -0.0818517   0.06083731  0.01943589  0.05867488 -0.18274343\n",
      "  0.36778455 -0.00072318 -0.24913244  0.20989344 -0.16031406 -0.22292392\n",
      "  0.10950665 -0.35819526]\n",
      "New theta_0 : [ 0.00243905 -0.08192957  0.06101989  0.01942947  0.05868023 -0.18323938\n",
      "  0.36761456 -0.0007182  -0.24969382  0.2101498  -0.16039731 -0.22297875\n",
      "  0.10946385 -0.3582832 ]\n",
      "Training Error:  10.548919334772517\n",
      "====================================================================================================\n",
      "Iteration:  423\n",
      "Previous theta :  [ 0.00243905 -0.08192957  0.06101989  0.01942947  0.05868023 -0.18323938\n",
      "  0.36761456 -0.0007182  -0.24969382  0.2101498  -0.16039731 -0.22297875\n",
      "  0.10946385 -0.3582832 ]\n",
      "New theta_0 : [ 0.00242585 -0.08200696  0.06120152  0.01942369  0.05868549 -0.18373205\n",
      "  0.36744606 -0.0007131  -0.25025118  0.210405   -0.16048099 -0.22303306\n",
      "  0.10942142 -0.35837018]\n",
      "Training Error:  10.548263777890956\n",
      "====================================================================================================\n",
      "Iteration:  424\n",
      "Previous theta :  [ 0.00242585 -0.08200696  0.06120152  0.01942369  0.05868549 -0.18373205\n",
      "  0.36744606 -0.0007131  -0.25025118  0.210405   -0.16048099 -0.22303306\n",
      "  0.10942142 -0.35837018]\n",
      "New theta_0 : [ 0.00241273 -0.08208388  0.06138221  0.01941855  0.05869067 -0.18422144\n",
      "  0.36727903 -0.00070786 -0.25080454  0.21065906 -0.16056507 -0.22308689\n",
      "  0.10937934 -0.35845622]\n",
      "Training Error:  10.547616847690554\n",
      "====================================================================================================\n",
      "Iteration:  425\n",
      "Previous theta :  [ 0.00241273 -0.08208388  0.06138221  0.01941855  0.05869067 -0.18422144\n",
      "  0.36727903 -0.00070786 -0.25080454  0.21065906 -0.16056507 -0.22308689\n",
      "  0.10937934 -0.35845622]\n",
      "New theta_0 : [ 0.00239971 -0.08216033  0.06156197  0.01941403  0.05869576 -0.18470759\n",
      "  0.36711345 -0.00070249 -0.25135393  0.21091198 -0.16064955 -0.22314022\n",
      "  0.10933762 -0.35854133]\n",
      "Training Error:  10.546978423600493\n",
      "====================================================================================================\n",
      "Iteration:  426\n",
      "Previous theta :  [ 0.00239971 -0.08216033  0.06156197  0.01941403  0.05869576 -0.18470759\n",
      "  0.36711345 -0.00070249 -0.25135393  0.21091198 -0.16064955 -0.22314022\n",
      "  0.10933762 -0.35854133]\n",
      "New theta_0 : [ 0.00238679 -0.08223631  0.06174079  0.01941013  0.05870077 -0.18519052\n",
      "  0.36694932 -0.00069701 -0.25189939  0.21116377 -0.16073443 -0.22319307\n",
      "  0.10929625 -0.35862552]\n",
      "Training Error:  10.546348386797135\n",
      "====================================================================================================\n",
      "Iteration:  427\n",
      "Previous theta :  [ 0.00238679 -0.08223631  0.06174079  0.01941013  0.05870077 -0.18519052\n",
      "  0.36694932 -0.00069701 -0.25189939  0.21116377 -0.16073443 -0.22319307\n",
      "  0.10929625 -0.35862552]\n",
      "New theta_0 : [ 0.00237395 -0.08231182  0.06191869  0.01940685  0.0587057  -0.18567024\n",
      "  0.36678661 -0.0006914  -0.25244094  0.21141443 -0.16081969 -0.22324543\n",
      "  0.10925523 -0.3587088 ]\n",
      "Training Error:  10.545726620177835\n",
      "====================================================================================================\n",
      "Iteration:  428\n",
      "Previous theta :  [ 0.00237395 -0.08231182  0.06191869  0.01940685  0.0587057  -0.18567024\n",
      "  0.36678661 -0.0006914  -0.25244094  0.21141443 -0.16081969 -0.22324543\n",
      "  0.10925523 -0.3587088 ]\n",
      "New theta_0 : [ 0.00236121 -0.08238687  0.06209566  0.01940416  0.05871055 -0.18614678\n",
      "  0.36662531 -0.00068568 -0.25297861  0.21166398 -0.16090534 -0.22329733\n",
      "  0.10921456 -0.35879118]\n",
      "Training Error:  10.545113008335132\n",
      "====================================================================================================\n",
      "Iteration:  429\n",
      "Previous theta :  [ 0.00236121 -0.08238687  0.06209566  0.01940416  0.05871055 -0.18614678\n",
      "  0.36662531 -0.00068568 -0.25297861  0.21166398 -0.16090534 -0.22329733\n",
      "  0.10921456 -0.35879118]\n",
      "New theta_0 : [ 0.00234856 -0.08246147  0.0622717   0.01940208  0.05871532 -0.18662015\n",
      "  0.36646541 -0.00067985 -0.25351243  0.21191242 -0.16099137 -0.22334875\n",
      "  0.10917423 -0.35887267]\n",
      "Training Error:  10.544507437531395\n",
      "====================================================================================================\n",
      "Iteration:  430\n",
      "Previous theta :  [ 0.00234856 -0.08246147  0.0622717   0.01940208  0.05871532 -0.18662015\n",
      "  0.36646541 -0.00067985 -0.25351243  0.21191242 -0.16099137 -0.22334875\n",
      "  0.10917423 -0.35887267]\n",
      "New theta_0 : [ 0.002336   -0.0825356   0.06244683  0.01940058  0.05872001 -0.18709038\n",
      "  0.3663069  -0.00067391 -0.25404242  0.21215976 -0.16107777 -0.22339971\n",
      "  0.10913425 -0.35895328]\n",
      "Training Error:  10.543909795673814\n",
      "====================================================================================================\n",
      "Iteration:  431\n",
      "Previous theta :  [ 0.002336   -0.0825356   0.06244683  0.01940058  0.05872001 -0.18709038\n",
      "  0.3663069  -0.00067391 -0.25404242  0.21215976 -0.16107777 -0.22339971\n",
      "  0.10913425 -0.35895328]\n",
      "New theta_0 : [ 0.00232353 -0.08260928  0.06262103  0.01939966  0.05872463 -0.1875575\n",
      "  0.36614976 -0.00066787 -0.25456862  0.21240601 -0.16116454 -0.22345022\n",
      "  0.1090946  -0.35903303]\n",
      "Training Error:  10.54331997228982\n",
      "====================================================================================================\n",
      "Iteration:  432\n",
      "Previous theta :  [ 0.00232353 -0.08260928  0.06262103  0.01939966  0.05872463 -0.1875575\n",
      "  0.36614976 -0.00066787 -0.25456862  0.21240601 -0.16116454 -0.22345022\n",
      "  0.1090946  -0.35903303]\n",
      "New theta_0 : [ 0.00231114 -0.08268252  0.06279432  0.01939932  0.05872916 -0.18802151\n",
      "  0.36599398 -0.00066173 -0.25509106  0.21265117 -0.16125167 -0.22350027\n",
      "  0.10905529 -0.35911191]\n",
      "Training Error:  10.542737858502878\n",
      "====================================================================================================\n",
      "Iteration:  433\n",
      "Previous theta :  [ 0.00231114 -0.08268252  0.06279432  0.01939932  0.05872916 -0.18802151\n",
      "  0.36599398 -0.00066173 -0.25509106  0.21265117 -0.16125167 -0.22350027\n",
      "  0.10905529 -0.35911191]\n",
      "New theta_0 : [ 0.00229885 -0.0827553   0.06296671  0.01939955  0.05873362 -0.18848244\n",
      "  0.36583954 -0.00065548 -0.25560975  0.21289526 -0.16133915 -0.22354987\n",
      "  0.10901631 -0.35918995]\n",
      "Training Error:  10.542163347008657\n",
      "====================================================================================================\n",
      "Iteration:  434\n",
      "Previous theta :  [ 0.00229885 -0.0827553   0.06296671  0.01939955  0.05873362 -0.18848244\n",
      "  0.36583954 -0.00065548 -0.25560975  0.21289526 -0.16133915 -0.22354987\n",
      "  0.10901631 -0.35918995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00228664 -0.08282763  0.06313818  0.01940033  0.058738   -0.18894032\n",
      "  0.36568644 -0.00064915 -0.25612474  0.21313827 -0.16142698 -0.22359903\n",
      "  0.10897765 -0.35926715]\n",
      "Training Error:  10.541596332051563\n",
      "====================================================================================================\n",
      "Iteration:  435\n",
      "Previous theta :  [ 0.00228664 -0.08282763  0.06313818  0.01940033  0.058738   -0.18894032\n",
      "  0.36568644 -0.00064915 -0.25612474  0.21313827 -0.16142698 -0.22359903\n",
      "  0.10897765 -0.35926715]\n",
      "New theta_0 : [ 0.00227452 -0.08289953  0.06330875  0.01940167  0.0587423  -0.18939515\n",
      "  0.36553465 -0.00064272 -0.25663604  0.21338022 -0.16151515 -0.22364775\n",
      "  0.10893933 -0.35934353]\n",
      "Training Error:  10.541036709401666\n",
      "====================================================================================================\n",
      "Iteration:  436\n",
      "Previous theta :  [ 0.00227452 -0.08289953  0.06330875  0.01940167  0.0587423  -0.18939515\n",
      "  0.36553465 -0.00064272 -0.25663604  0.21338022 -0.16151515 -0.22364775\n",
      "  0.10893933 -0.35934353]\n",
      "New theta_0 : [ 0.00226249 -0.08297098  0.06347841  0.01940355  0.05874653 -0.18984696\n",
      "  0.36538417 -0.0006362  -0.25714368  0.21362112 -0.16160367 -0.22369604\n",
      "  0.10890133 -0.35941908]\n",
      "Training Error:  10.540484376331955\n",
      "====================================================================================================\n",
      "Iteration:  437\n",
      "Previous theta :  [ 0.00226249 -0.08297098  0.06347841  0.01940355  0.05874653 -0.18984696\n",
      "  0.36538417 -0.0006362  -0.25714368  0.21362112 -0.16160367 -0.22369604\n",
      "  0.10890133 -0.35941908]\n",
      "New theta_0 : [ 0.00225054 -0.08304199  0.06364718  0.01940597  0.05875068 -0.19029578\n",
      "  0.36523499 -0.00062959 -0.25764769  0.21386097 -0.16169251 -0.2237439\n",
      "  0.10886364 -0.35949383]\n",
      "Training Error:  10.53993923159597\n",
      "====================================================================================================\n",
      "Iteration:  438\n",
      "Previous theta :  [ 0.00225054 -0.08304199  0.06364718  0.01940597  0.05875068 -0.19029578\n",
      "  0.36523499 -0.00062959 -0.25764769  0.21386097 -0.16169251 -0.2237439\n",
      "  0.10886364 -0.35949383]\n",
      "New theta_0 : [ 0.00223867 -0.08311257  0.06381505  0.01940892  0.05875476 -0.19074161\n",
      "  0.36508708 -0.00062291 -0.2581481   0.21409977 -0.16178169 -0.22379133\n",
      "  0.10882628 -0.35956778]\n",
      "Training Error:  10.539401175405764\n",
      "====================================================================================================\n",
      "Iteration:  439\n",
      "Previous theta :  [ 0.00223867 -0.08311257  0.06381505  0.01940892  0.05875476 -0.19074161\n",
      "  0.36508708 -0.00062291 -0.2581481   0.21409977 -0.16178169 -0.22379133\n",
      "  0.10882628 -0.35956778]\n",
      "New theta_0 : [ 0.00222689 -0.08318272  0.06398203  0.0194124   0.05875877 -0.19118449\n",
      "  0.36494045 -0.00061614 -0.25864493  0.21433755 -0.16187118 -0.22383835\n",
      "  0.10878923 -0.35964093]\n",
      "Training Error:  10.538870109410215\n",
      "====================================================================================================\n",
      "Iteration:  440\n",
      "Previous theta :  [ 0.00222689 -0.08318272  0.06398203  0.0194124   0.05875877 -0.19118449\n",
      "  0.36494045 -0.00061614 -0.25864493  0.21433755 -0.16187118 -0.22383835\n",
      "  0.10878923 -0.35964093]\n",
      "New theta_0 : [ 0.0022152  -0.08325244  0.06414813  0.0194164   0.0587627  -0.19162442\n",
      "  0.36479507 -0.00060929 -0.2591382   0.21457429 -0.161961   -0.22388495\n",
      "  0.10875249 -0.35971331]\n",
      "Training Error:  10.53834593667369\n",
      "====================================================================================================\n",
      "Iteration:  441\n",
      "Previous theta :  [ 0.0022152  -0.08325244  0.06414813  0.0194164   0.0587627  -0.19162442\n",
      "  0.36479507 -0.00060929 -0.2591382   0.21457429 -0.161961   -0.22388495\n",
      "  0.10875249 -0.35971331]\n",
      "New theta_0 : [ 0.00220359 -0.08332173  0.06431333  0.0194209   0.05876656 -0.19206143\n",
      "  0.36465093 -0.00060238 -0.25962796  0.21481002 -0.16205112 -0.22393114\n",
      "  0.10871606 -0.35978491]\n",
      "Training Error:  10.537828561655003\n",
      "====================================================================================================\n",
      "Iteration:  442\n",
      "Previous theta :  [ 0.00220359 -0.08332173  0.06431333  0.0194209   0.05876656 -0.19206143\n",
      "  0.36465093 -0.00060238 -0.25962796  0.21481002 -0.16205112 -0.22393114\n",
      "  0.10871606 -0.35978491]\n",
      "New theta_0 : [ 0.00219206 -0.08339059  0.06447766  0.01942591  0.05877035 -0.19249554\n",
      "  0.36450803 -0.00059538 -0.26011421  0.21504473 -0.16214155 -0.22397693\n",
      "  0.10867994 -0.35985575]\n",
      "Training Error:  10.53731789018674\n",
      "====================================================================================================\n",
      "Iteration:  443\n",
      "Previous theta :  [ 0.00219206 -0.08339059  0.06447766  0.01942591  0.05877035 -0.19249554\n",
      "  0.36450803 -0.00059538 -0.26011421  0.21504473 -0.16214155 -0.22397693\n",
      "  0.10867994 -0.35985575]\n",
      "New theta_0 : [ 0.00218061 -0.08345903  0.06464111  0.01943142  0.05877407 -0.19292677\n",
      "  0.36436634 -0.00058832 -0.26059699  0.21527843 -0.16223229 -0.22402232\n",
      "  0.10864412 -0.35992584]\n",
      "Training Error:  10.536813829454875\n",
      "====================================================================================================\n",
      "Iteration:  444\n",
      "Previous theta :  [ 0.00218061 -0.08345903  0.06464111  0.01943142  0.05877407 -0.19292677\n",
      "  0.36436634 -0.00058832 -0.26059699  0.21527843 -0.16223229 -0.22402232\n",
      "  0.10864412 -0.35992584]\n",
      "New theta_0 : [ 0.00216925 -0.08352705  0.06480368  0.01943743  0.05877772 -0.19335513\n",
      "  0.36422587 -0.00058119 -0.26107632  0.21551114 -0.16232331 -0.22406731\n",
      "  0.1086086  -0.35999518]\n",
      "Training Error:  10.536316287978709\n",
      "====================================================================================================\n",
      "Iteration:  445\n",
      "Previous theta :  [ 0.00216925 -0.08352705  0.06480368  0.01943743  0.05877772 -0.19335513\n",
      "  0.36422587 -0.00058119 -0.26107632  0.21551114 -0.16232331 -0.22406731\n",
      "  0.1086086  -0.35999518]\n",
      "New theta_0 : [ 0.00215796 -0.08359466  0.06496538  0.01944391  0.0587813  -0.19378065\n",
      "  0.36408659 -0.000574   -0.26155223  0.21574285 -0.16241464 -0.2241119\n",
      "  0.10857338 -0.36006379]\n",
      "Training Error:  10.535825175591116\n",
      "====================================================================================================\n",
      "Iteration:  446\n",
      "Previous theta :  [ 0.00215796 -0.08359466  0.06496538  0.01944391  0.0587813  -0.19378065\n",
      "  0.36408659 -0.000574   -0.26155223  0.21574285 -0.16241464 -0.2241119\n",
      "  0.10857338 -0.36006379]\n",
      "New theta_0 : [ 0.00214676 -0.08366185  0.06512621  0.01945088  0.05878481 -0.19420334\n",
      "  0.3639485  -0.00056675 -0.26202473  0.21597358 -0.16250624 -0.22415611\n",
      "  0.10853846 -0.36013167]\n",
      "Training Error:  10.535340403419113\n",
      "====================================================================================================\n",
      "Iteration:  447\n",
      "Previous theta :  [ 0.00214676 -0.08366185  0.06512621  0.01945088  0.05878481 -0.19420334\n",
      "  0.3639485  -0.00056675 -0.26202473  0.21597358 -0.16250624 -0.22415611\n",
      "  0.10853846 -0.36013167]\n",
      "New theta_0 : [ 0.00213563 -0.08372863  0.06528618  0.01945832  0.05878825 -0.19462323\n",
      "  0.36381158 -0.00055943 -0.26249387  0.21620332 -0.16259813 -0.22419994\n",
      "  0.10850383 -0.36019883]\n",
      "Training Error:  10.534861883864696\n",
      "====================================================================================================\n",
      "Iteration:  448\n",
      "Previous theta :  [ 0.00213563 -0.08372863  0.06528618  0.01945832  0.05878825 -0.19462323\n",
      "  0.36381158 -0.00055943 -0.26249387  0.21620332 -0.16259813 -0.22419994\n",
      "  0.10850383 -0.36019883]\n",
      "New theta_0 : [ 0.00212458 -0.08379499  0.06544528  0.01946622  0.05879162 -0.19504032\n",
      "  0.36367583 -0.00055206 -0.26295966  0.21643209 -0.1626903  -0.22424338\n",
      "  0.10846949 -0.36026528]\n",
      "Training Error:  10.534389530586001\n",
      "====================================================================================================\n",
      "Iteration:  449\n",
      "Previous theta :  [ 0.00212458 -0.08379499  0.06544528  0.01946622  0.05879162 -0.19504032\n",
      "  0.36367583 -0.00055206 -0.26295966  0.21643209 -0.1626903  -0.22424338\n",
      "  0.10846949 -0.36026528]\n",
      "New theta_0 : [ 0.00211362 -0.08386096  0.06560353  0.01947459  0.05879492 -0.19545464\n",
      "  0.36354122 -0.00054463 -0.26342212  0.2166599  -0.16278273 -0.22428645\n",
      "  0.10843544 -0.36033102]\n",
      "Training Error:  10.533923258478726\n",
      "====================================================================================================\n",
      "Iteration:  450\n",
      "Previous theta :  [ 0.00211362 -0.08386096  0.06560353  0.01947459  0.05879492 -0.19545464\n",
      "  0.36354122 -0.00054463 -0.26342212  0.2166599  -0.16278273 -0.22428645\n",
      "  0.10843544 -0.36033102]\n",
      "New theta_0 : [ 0.00210273 -0.08392651  0.06576093  0.01948341  0.05879816 -0.19586622\n",
      "  0.36340776 -0.00053715 -0.26388128  0.21688674 -0.16287544 -0.22432915\n",
      "  0.10840167 -0.36039607]\n",
      "Training Error:  10.533462983657879\n",
      "====================================================================================================\n",
      "Iteration:  451\n",
      "Previous theta :  [ 0.00210273 -0.08392651  0.06576093  0.01948341  0.05879816 -0.19586622\n",
      "  0.36340776 -0.00053715 -0.26388128  0.21688674 -0.16287544 -0.22432915\n",
      "  0.10840167 -0.36039607]\n",
      "New theta_0 : [ 0.00209191 -0.08399167  0.06591747  0.01949268  0.05880134 -0.19627505\n",
      "  0.36327543 -0.00052962 -0.26433717  0.21711263 -0.1629684  -0.22437148\n",
      "  0.10836819 -0.36046043]\n",
      "Training Error:  10.533008623439754\n",
      "====================================================================================================\n",
      "Iteration:  452\n",
      "Previous theta :  [ 0.00209191 -0.08399167  0.06591747  0.01949268  0.05880134 -0.19627505\n",
      "  0.36327543 -0.00052962 -0.26433717  0.21711263 -0.1629684  -0.22437148\n",
      "  0.10836819 -0.36046043]\n",
      "New theta_0 : [ 0.00208118 -0.08405642  0.06607317  0.01950239  0.05880444 -0.19668118\n",
      "  0.36314421 -0.00052204 -0.2647898   0.21733757 -0.16306163 -0.22441345\n",
      "  0.10833499 -0.36052412]\n",
      "Training Error:  10.53256009632423\n",
      "====================================================================================================\n",
      "Iteration:  453\n",
      "Previous theta :  [ 0.00208118 -0.08405642  0.06607317  0.01950239  0.05880444 -0.19668118\n",
      "  0.36314421 -0.00052204 -0.2647898   0.21733757 -0.16306163 -0.22441345\n",
      "  0.10833499 -0.36052412]\n",
      "New theta_0 : [ 0.00207052 -0.08412078  0.06622802  0.01951254  0.05880748 -0.1970846\n",
      "  0.36301411 -0.00051441 -0.26523921  0.21756157 -0.1631551  -0.22445506\n",
      "  0.10830207 -0.36058713]\n",
      "Training Error:  10.532117321977312\n",
      "====================================================================================================\n",
      "Iteration:  454\n",
      "Previous theta :  [ 0.00207052 -0.08412078  0.06622802  0.01951254  0.05880748 -0.1970846\n",
      "  0.36301411 -0.00051441 -0.26523921  0.21756157 -0.1631551  -0.22445506\n",
      "  0.10830207 -0.36058713]\n",
      "New theta_0 : [ 0.00205993 -0.08418474  0.06638203  0.01952312  0.05881046 -0.19748534\n",
      "  0.3628851  -0.00050674 -0.26568541  0.21778464 -0.16324883 -0.22449631\n",
      "  0.10826942 -0.36064948]\n",
      "Training Error:  10.531680221213952\n",
      "====================================================================================================\n",
      "Iteration:  455\n",
      "Previous theta :  [ 0.00205993 -0.08418474  0.06638203  0.01952312  0.05881046 -0.19748534\n",
      "  0.3628851  -0.00050674 -0.26568541  0.21778464 -0.16324883 -0.22449631\n",
      "  0.10826942 -0.36064948]\n",
      "New theta_0 : [ 0.00204943 -0.08424831  0.06653521  0.01953413  0.05881338 -0.19788342\n",
      "  0.36275718 -0.00049903 -0.26612843  0.21800677 -0.16334279 -0.22453721\n",
      "  0.10823705 -0.36071118]\n",
      "Training Error:  10.531248715981125\n",
      "====================================================================================================\n",
      "Iteration:  456\n",
      "Previous theta :  [ 0.00204943 -0.08424831  0.06653521  0.01953413  0.05881338 -0.19788342\n",
      "  0.36275718 -0.00049903 -0.26612843  0.21800677 -0.16334279 -0.22453721\n",
      "  0.10823705 -0.36071118]\n",
      "New theta_0 : [ 0.00203899 -0.0843115   0.06668755  0.01954555  0.05881623 -0.19827886\n",
      "  0.36263034 -0.00049127 -0.26656829  0.21822798 -0.163437   -0.22457776\n",
      "  0.10820495 -0.36077223]\n",
      "Training Error:  10.530822729341171\n",
      "====================================================================================================\n",
      "Iteration:  457\n",
      "Previous theta :  [ 0.00203899 -0.0843115   0.06668755  0.01954555  0.05881623 -0.19827886\n",
      "  0.36263034 -0.00049127 -0.26656829  0.21822798 -0.163437   -0.22457776\n",
      "  0.10820495 -0.36077223]\n",
      "New theta_0 : [ 0.00202863 -0.08437429  0.06683906  0.01955739  0.05881901 -0.19867167\n",
      "  0.36250456 -0.00048348 -0.26700502  0.21844827 -0.16353144 -0.22461797\n",
      "  0.10817312 -0.36083263]\n",
      "Training Error:  10.530402185455394\n",
      "====================================================================================================\n",
      "Iteration:  458\n",
      "Previous theta :  [ 0.00202863 -0.08437429  0.06683906  0.01955739  0.05881901 -0.19867167\n",
      "  0.36250456 -0.00048348 -0.26700502  0.21844827 -0.16353144 -0.22461797\n",
      "  0.10817312 -0.36083263]\n",
      "New theta_0 : [ 0.00201835 -0.0844367   0.06698975  0.01956963  0.05882174 -0.19906186\n",
      "  0.36237984 -0.00047564 -0.26743863  0.21866765 -0.16362612 -0.22465783\n",
      "  0.10814155 -0.36089241]\n",
      "Training Error:  10.529987009567892\n",
      "====================================================================================================\n",
      "Iteration:  459\n",
      "Previous theta :  [ 0.00201835 -0.0844367   0.06698975  0.01956963  0.05882174 -0.19906186\n",
      "  0.36237984 -0.00047564 -0.26743863  0.21866765 -0.16362612 -0.22465783\n",
      "  0.10814155 -0.36089241]\n",
      "New theta_0 : [ 0.00200813 -0.08449873  0.06713961  0.01958228  0.0588244  -0.19944947\n",
      "  0.36225616 -0.00046778 -0.26786916  0.21888612 -0.16372102 -0.22469736\n",
      "  0.10811025 -0.36095155]\n",
      "Training Error:  10.529577127989652\n",
      "====================================================================================================\n",
      "Iteration:  460\n",
      "Previous theta :  [ 0.00200813 -0.08449873  0.06713961  0.01958228  0.0588244  -0.19944947\n",
      "  0.36225616 -0.00046778 -0.26786916  0.21888612 -0.16372102 -0.22469736\n",
      "  0.10811025 -0.36095155]\n",
      "New theta_0 : [ 0.00199799 -0.08456037  0.06728866  0.01959533  0.058827   -0.1998345\n",
      "  0.36213353 -0.00045988 -0.26829661  0.2191037  -0.16381614 -0.22473656\n",
      "  0.10807921 -0.36101008]\n",
      "Training Error:  10.529172468082882\n",
      "====================================================================================================\n",
      "Iteration:  461\n",
      "Previous theta :  [ 0.00199799 -0.08456037  0.06728866  0.01959533  0.058827   -0.1998345\n",
      "  0.36213353 -0.00045988 -0.26829661  0.2191037  -0.16381614 -0.22473656\n",
      "  0.10807921 -0.36101008]\n",
      "New theta_0 : [ 0.00198792 -0.08462164  0.06743689  0.01960877  0.05882955 -0.20021697\n",
      "  0.36201191 -0.00045194 -0.26872103  0.21932037 -0.16391147 -0.22477543\n",
      "  0.10804843 -0.361068  ]\n",
      "Training Error:  10.528772958245582\n",
      "====================================================================================================\n",
      "Iteration:  462\n",
      "Previous theta :  [ 0.00198792 -0.08462164  0.06743689  0.01960877  0.05882955 -0.20021697\n",
      "  0.36201191 -0.00045194 -0.26872103  0.21932037 -0.16391147 -0.22477543\n",
      "  0.10804843 -0.361068  ]\n",
      "New theta_0 : [ 0.00197792 -0.08468253  0.06758431  0.01962259  0.05883203 -0.2005969\n",
      "  0.36189132 -0.00044398 -0.26914242  0.21953616 -0.16400702 -0.22481396\n",
      "  0.10801791 -0.36112531]\n",
      "Training Error:  10.528378527896347\n",
      "====================================================================================================\n",
      "Iteration:  463\n",
      "Previous theta :  [ 0.00197792 -0.08468253  0.06758431  0.01962259  0.05883203 -0.2005969\n",
      "  0.36189132 -0.00044398 -0.26914242  0.21953616 -0.16400702 -0.22481396\n",
      "  0.10801791 -0.36112531]\n",
      "New theta_0 : [ 0.001968   -0.08474305  0.06773092  0.0196368   0.05883445 -0.20097431\n",
      "  0.36177173 -0.00043599 -0.26956081  0.21975107 -0.16410278 -0.22485218\n",
      "  0.10798764 -0.36118203]\n",
      "Training Error:  10.527989107459387\n",
      "====================================================================================================\n",
      "Iteration:  464\n",
      "Previous theta :  [ 0.001968   -0.08474305  0.06773092  0.0196368   0.05883445 -0.20097431\n",
      "  0.36177173 -0.00043599 -0.26956081  0.21975107 -0.16410278 -0.22485218\n",
      "  0.10798764 -0.36118203]\n",
      "New theta_0 : [ 0.00195814 -0.0848032   0.06787672  0.01965138  0.05883681 -0.2013492\n",
      "  0.36165315 -0.00042797 -0.26997622  0.2199651  -0.16419875 -0.22489008\n",
      "  0.10795762 -0.36123816]\n",
      "Training Error:  10.527604628349817\n",
      "====================================================================================================\n",
      "Iteration:  465\n",
      "Previous theta :  [ 0.00195814 -0.0848032   0.06787672  0.01965138  0.05883681 -0.2013492\n",
      "  0.36165315 -0.00042797 -0.26997622  0.2199651  -0.16419875 -0.22489008\n",
      "  0.10795762 -0.36123816]\n",
      "New theta_0 : [ 0.00194835 -0.08486298  0.06802173  0.01966633  0.05883912 -0.20172161\n",
      "  0.36153555 -0.00041993 -0.27038867  0.22017825 -0.16429491 -0.22492766\n",
      "  0.10792786 -0.3612937 ]\n",
      "Training Error:  10.527225022959115\n",
      "====================================================================================================\n",
      "Iteration:  466\n",
      "Previous theta :  [ 0.00194835 -0.08486298  0.06802173  0.01966633  0.05883912 -0.20172161\n",
      "  0.36153555 -0.00041993 -0.27038867  0.22017825 -0.16429491 -0.22492766\n",
      "  0.10792786 -0.3612937 ]\n",
      "New theta_0 : [ 0.00193864 -0.0849224   0.06816594  0.01968165  0.05884137 -0.20209154\n",
      "  0.36141893 -0.00041186 -0.27079819  0.22039054 -0.16439127 -0.22496492\n",
      "  0.10789835 -0.36134866]\n",
      "Training Error:  10.526850224640844\n",
      "====================================================================================================\n",
      "Iteration:  467\n",
      "Previous theta :  [ 0.00193864 -0.0849224   0.06816594  0.01968165  0.05884137 -0.20209154\n",
      "  0.36141893 -0.00041186 -0.27079819  0.22039054 -0.16439127 -0.22496492\n",
      "  0.10789835 -0.36134866]\n",
      "New theta_0 : [ 0.00192899 -0.08498145  0.06830936  0.01969733  0.05884355 -0.20245901\n",
      "  0.36130327 -0.00040377 -0.2712048   0.22060197 -0.16448782 -0.22500188\n",
      "  0.10786908 -0.36140306]\n",
      "Training Error:  10.526480167696558\n",
      "====================================================================================================\n",
      "Iteration:  468\n",
      "Previous theta :  [ 0.00192899 -0.08498145  0.06830936  0.01969733  0.05884355 -0.20245901\n",
      "  0.36130327 -0.00040377 -0.2712048   0.22060197 -0.16448782 -0.22500188\n",
      "  0.10786908 -0.36140306]\n",
      "New theta_0 : [ 0.00191941 -0.08504014  0.06845198  0.01971337  0.05884569 -0.20282404\n",
      "  0.36118858 -0.00039565 -0.27160851  0.22081254 -0.16458457 -0.22503853\n",
      "  0.10784006 -0.36145688]\n",
      "Training Error:  10.526114787361951\n",
      "====================================================================================================\n",
      "Iteration:  469\n",
      "Previous theta :  [ 0.00191941 -0.08504014  0.06845198  0.01971337  0.05884569 -0.20282404\n",
      "  0.36118858 -0.00039565 -0.27160851  0.22081254 -0.16458457 -0.22503853\n",
      "  0.10784006 -0.36145688]\n",
      "New theta_0 : [ 0.0019099  -0.08509847  0.06859382  0.01972975  0.05884776 -0.20318665\n",
      "  0.36107485 -0.00038752 -0.27200935  0.22102227 -0.16468149 -0.22507488\n",
      "  0.10781127 -0.36151016]\n",
      "Training Error:  10.52575401979319\n",
      "====================================================================================================\n",
      "Iteration:  470\n",
      "Previous theta :  [ 0.0019099  -0.08509847  0.06859382  0.01972975  0.05884776 -0.20318665\n",
      "  0.36107485 -0.00038752 -0.27200935  0.22102227 -0.16468149 -0.22507488\n",
      "  0.10781127 -0.36151016]\n",
      "New theta_0 : [ 0.00190045 -0.08515644  0.06873488  0.01974649  0.05884978 -0.20354684\n",
      "  0.36096205 -0.00037937 -0.27240734  0.22123114 -0.1647786  -0.22511092\n",
      "  0.10778273 -0.36156288]\n",
      "Training Error:  10.525397802053467\n",
      "====================================================================================================\n",
      "Iteration:  471\n",
      "Previous theta :  [ 0.00190045 -0.08515644  0.06873488  0.01974649  0.05884978 -0.20354684\n",
      "  0.36096205 -0.00037937 -0.27240734  0.22123114 -0.1647786  -0.22511092\n",
      "  0.10778273 -0.36156288]\n",
      "New theta_0 : [ 0.00189107 -0.08521406  0.06887516  0.01976356  0.05885175 -0.20390464\n",
      "  0.36085019 -0.0003712  -0.2728025   0.22143918 -0.16487588 -0.22514667\n",
      "  0.10775443 -0.36161505]\n",
      "Training Error:  10.525046072099748\n",
      "====================================================================================================\n",
      "Iteration:  472\n",
      "Previous theta :  [ 0.00189107 -0.08521406  0.06887516  0.01976356  0.05885175 -0.20390464\n",
      "  0.36085019 -0.0003712  -0.2728025   0.22143918 -0.16487588 -0.22514667\n",
      "  0.10775443 -0.36161505]\n",
      "New theta_0 : [ 0.00188176 -0.08527133  0.06901466  0.01978097  0.05885366 -0.20426006\n",
      "  0.36073926 -0.00036302 -0.27319485  0.22164638 -0.16497333 -0.22518213\n",
      "  0.10772636 -0.36166669]\n",
      "Training Error:  10.524698768769733\n",
      "====================================================================================================\n",
      "Iteration:  473\n",
      "Previous theta :  [ 0.00188176 -0.08527133  0.06901466  0.01978097  0.05885366 -0.20426006\n",
      "  0.36073926 -0.00036302 -0.27319485  0.22164638 -0.16497333 -0.22518213\n",
      "  0.10772636 -0.36166669]\n",
      "New theta_0 : [ 1.87251586e-03 -8.53282465e-02  6.91533905e-02  1.97987100e-02\n",
      "  5.88555138e-02 -2.04613124e-01  3.60629236e-01 -3.54824227e-04\n",
      " -2.73584405e-01  2.21852751e-01 -1.65070958e-01 -2.25217291e-01\n",
      "  1.07698533e-01 -3.61717796e-01]\n",
      "Training Error:  10.524355831768997\n",
      "====================================================================================================\n",
      "Iteration:  474\n",
      "Previous theta :  [ 1.87251586e-03 -8.53282465e-02  6.91533905e-02  1.97987100e-02\n",
      "  5.88555138e-02 -2.04613124e-01  3.60629236e-01 -3.54824227e-04\n",
      " -2.73584405e-01  2.21852751e-01 -1.65070958e-01 -2.25217291e-01\n",
      "  1.07698533e-01 -3.61717796e-01]\n",
      "New theta_0 : [ 1.86333578e-03 -8.53848151e-02  6.92913538e-02  1.98167782e-02\n",
      "  5.88573155e-02 -2.04963838e-01  3.60520125e-01 -3.46613501e-04\n",
      " -2.73971196e-01  2.22058298e-01 -1.65168747e-01 -2.25252168e-01\n",
      "  1.07670933e-01 -3.61768374e-01]\n",
      "Training Error:  10.524017201658332\n",
      "====================================================================================================\n",
      "Iteration:  475\n",
      "Previous theta :  [ 1.86333578e-03 -8.53848151e-02  6.92913538e-02  1.98167782e-02\n",
      "  5.88573155e-02 -2.04963838e-01  3.60520125e-01 -3.46613501e-04\n",
      " -2.73971196e-01  2.22058298e-01 -1.65168747e-01 -2.25252168e-01\n",
      "  1.07670933e-01 -3.61768374e-01]\n",
      "New theta_0 : [ 1.85422070e-03 -8.54410381e-02  6.94285529e-02  1.98351686e-02\n",
      "  5.88590637e-02 -2.05312222e-01  3.60411914e-01 -3.38390752e-04\n",
      " -2.74355237e-01  2.22263025e-01 -1.65266697e-01 -2.25286758e-01\n",
      "  1.07643564e-01 -3.61818432e-01]\n",
      "Training Error:  10.523682819841286\n",
      "====================================================================================================\n",
      "Iteration:  476\n",
      "Previous theta :  [ 1.85422070e-03 -8.54410381e-02  6.94285529e-02  1.98351686e-02\n",
      "  5.88590637e-02 -2.05312222e-01  3.60411914e-01 -3.38390752e-04\n",
      " -2.74355237e-01  2.22263025e-01 -1.65266697e-01 -2.25286758e-01\n",
      "  1.07643564e-01 -3.61818432e-01]\n",
      "New theta_0 : [ 1.84517014e-03 -8.54969175e-02  6.95649913e-02  1.98538767e-02\n",
      "  5.88607590e-02 -2.05658290e-01  3.60304594e-01 -3.30157155e-04\n",
      " -2.74736550e-01  2.22466937e-01 -1.65364805e-01 -2.25321067e-01\n",
      "  1.07616422e-01 -3.61867976e-01]\n",
      "Training Error:  10.523352628551867\n",
      "====================================================================================================\n",
      "Iteration:  477\n",
      "Previous theta :  [ 1.84517014e-03 -8.54969175e-02  6.95649913e-02  1.98538767e-02\n",
      "  5.88607590e-02 -2.05658290e-01  3.60304594e-01 -3.30157155e-04\n",
      " -2.74736550e-01  2.22466937e-01 -1.65364805e-01 -2.25321067e-01\n",
      "  1.07616422e-01 -3.61867976e-01]\n",
      "New theta_0 : [ 1.83618365e-03 -8.55524556e-02  6.97006726e-02  1.98728980e-02\n",
      "  5.88624018e-02 -2.06002059e-01  3.60198157e-01 -3.21913857e-04\n",
      " -2.75115153e-01  2.22670040e-01 -1.65463066e-01 -2.25355097e-01\n",
      "  1.07589508e-01 -3.61917011e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.523026570842475\n",
      "====================================================================================================\n",
      "Iteration:  478\n",
      "Previous theta :  [ 1.83618365e-03 -8.55524556e-02  6.97006726e-02  1.98728980e-02\n",
      "  5.88624018e-02 -2.06002059e-01  3.60198157e-01 -3.21913857e-04\n",
      " -2.75115153e-01  2.22670040e-01 -1.65463066e-01 -2.25355097e-01\n",
      "  1.07589508e-01 -3.61917011e-01]\n",
      "New theta_0 : [ 1.82726076e-03 -8.56076545e-02  6.98356006e-02  1.98922279e-02\n",
      "  5.88639926e-02 -2.06343542e-01  3.60092594e-01 -3.13661974e-04\n",
      " -2.75491067e-01  2.22872339e-01 -1.65561478e-01 -2.25388850e-01\n",
      "  1.07562817e-01 -3.61965542e-01]\n",
      "Training Error:  10.522704590571957\n",
      "====================================================================================================\n",
      "Iteration:  479\n",
      "Previous theta :  [ 1.82726076e-03 -8.56076545e-02  6.98356006e-02  1.98922279e-02\n",
      "  5.88639926e-02 -2.06343542e-01  3.60092594e-01 -3.13661974e-04\n",
      " -2.75491067e-01  2.22872339e-01 -1.65561478e-01 -2.25388850e-01\n",
      "  1.07562817e-01 -3.61965542e-01]\n",
      "New theta_0 : [ 1.81840102e-03 -8.56625164e-02  6.99697788e-02  1.99118621e-02\n",
      "  5.88655319e-02 -2.06682757e-01  3.59987899e-01 -3.05402594e-04\n",
      " -2.75864311e-01  2.23073837e-01 -1.65660037e-01 -2.25422329e-01\n",
      "  1.07536349e-01 -3.62013577e-01]\n",
      "Training Error:  10.522386632393884\n",
      "====================================================================================================\n",
      "Iteration:  480\n",
      "Previous theta :  [ 1.81840102e-03 -8.56625164e-02  6.99697788e-02  1.99118621e-02\n",
      "  5.88655319e-02 -2.06682757e-01  3.59987899e-01 -3.05402594e-04\n",
      " -2.75864311e-01  2.23073837e-01 -1.65660037e-01 -2.25422329e-01\n",
      "  1.07536349e-01 -3.62013577e-01]\n",
      "New theta_0 : [ 1.80960396e-03 -8.57170436e-02  7.01032109e-02  1.99317960e-02\n",
      "  5.88670202e-02 -2.07019717e-01  3.59884061e-01 -2.97136779e-04\n",
      " -2.76234904e-01  2.23274541e-01 -1.65758738e-01 -2.25455537e-01\n",
      "  1.07510102e-01 -3.62061120e-01]\n",
      "Training Error:  10.522072641744991\n",
      "====================================================================================================\n",
      "Iteration:  481\n",
      "Previous theta :  [ 1.80960396e-03 -8.57170436e-02  7.01032109e-02  1.99317960e-02\n",
      "  5.88670202e-02 -2.07019717e-01  3.59884061e-01 -2.97136779e-04\n",
      " -2.76234904e-01  2.23274541e-01 -1.65758738e-01 -2.25455537e-01\n",
      "  1.07510102e-01 -3.62061120e-01]\n",
      "New theta_0 : [ 1.80086915e-03 -8.57712380e-02  7.02359005e-02  1.99520255e-02\n",
      "  5.88684579e-02 -2.07354438e-01  3.59781075e-01 -2.88865559e-04\n",
      " -2.76602866e-01  2.23474454e-01 -1.65857579e-01 -2.25488478e-01\n",
      "  1.07484074e-01 -3.62108178e-01]\n",
      "Training Error:  10.5217625648338\n",
      "====================================================================================================\n",
      "Iteration:  482\n",
      "Previous theta :  [ 1.80086915e-03 -8.57712380e-02  7.02359005e-02  1.99520255e-02\n",
      "  5.88684579e-02 -2.07354438e-01  3.59781075e-01 -2.88865559e-04\n",
      " -2.76602866e-01  2.23474454e-01 -1.65857579e-01 -2.25488478e-01\n",
      "  1.07484074e-01 -3.62108178e-01]\n",
      "New theta_0 : [ 1.79219614e-03 -8.58251019e-02  7.03678512e-02  1.99725461e-02\n",
      "  5.88698455e-02 -2.07686935e-01  3.59678931e-01 -2.80589943e-04\n",
      " -2.76968215e-01  2.23673581e-01 -1.65956556e-01 -2.25521153e-01\n",
      "  1.07458262e-01 -3.62154755e-01]\n",
      "Training Error:  10.521456348629382\n",
      "====================================================================================================\n",
      "Iteration:  483\n",
      "Previous theta :  [ 1.79219614e-03 -8.58251019e-02  7.03678512e-02  1.99725461e-02\n",
      "  5.88698455e-02 -2.07686935e-01  3.59678931e-01 -2.80589943e-04\n",
      " -2.76968215e-01  2.23673581e-01 -1.65956556e-01 -2.25521153e-01\n",
      "  1.07458262e-01 -3.62154755e-01]\n",
      "New theta_0 : [ 1.78358447e-03 -8.58786373e-02  7.04990667e-02  1.99933536e-02\n",
      "  5.88711834e-02 -2.08017222e-01  3.59577621e-01 -2.72310909e-04\n",
      " -2.77330971e-01  2.23871928e-01 -1.66055666e-01 -2.25553565e-01\n",
      "  1.07432665e-01 -3.62200857e-01]\n",
      "Training Error:  10.521153940850326\n",
      "====================================================================================================\n",
      "Iteration:  484\n",
      "Previous theta :  [ 1.78358447e-03 -8.58786373e-02  7.04990667e-02  1.99933536e-02\n",
      "  5.88711834e-02 -2.08017222e-01  3.59577621e-01 -2.72310909e-04\n",
      " -2.77330971e-01  2.23871928e-01 -1.66055666e-01 -2.25553565e-01\n",
      "  1.07432665e-01 -3.62200857e-01]\n",
      "New theta_0 : [ 1.77503371e-03 -8.59318464e-02  7.06295506e-02  2.00144439e-02\n",
      "  5.88724722e-02 -2.08345314e-01  3.59477139e-01 -2.64029412e-04\n",
      " -2.77691152e-01  2.24069499e-01 -1.66154905e-01 -2.25585717e-01\n",
      "  1.07407282e-01 -3.62246489e-01]\n",
      "Training Error:  10.520855289953845\n",
      "====================================================================================================\n",
      "Iteration:  485\n",
      "Previous theta :  [ 1.77503371e-03 -8.59318464e-02  7.06295506e-02  2.00144439e-02\n",
      "  5.88724722e-02 -2.08345314e-01  3.59477139e-01 -2.64029412e-04\n",
      " -2.77691152e-01  2.24069499e-01 -1.66154905e-01 -2.25585717e-01\n",
      "  1.07407282e-01 -3.62246489e-01]\n",
      "New theta_0 : [ 1.76654343e-03 -8.59847312e-02  7.07593066e-02  2.00358128e-02\n",
      "  5.88737122e-02 -2.08671226e-01  3.59377477e-01 -2.55746380e-04\n",
      " -2.78048778e-01  2.24266298e-01 -1.66254269e-01 -2.25617612e-01\n",
      "  1.07382110e-01 -3.62291657e-01]\n",
      "Training Error:  10.520560345125064\n",
      "====================================================================================================\n",
      "Iteration:  486\n",
      "Previous theta :  [ 1.76654343e-03 -8.59847312e-02  7.07593066e-02  2.00358128e-02\n",
      "  5.88737122e-02 -2.08671226e-01  3.59377477e-01 -2.55746380e-04\n",
      " -2.78048778e-01  2.24266298e-01 -1.66254269e-01 -2.25617612e-01\n",
      "  1.07382110e-01 -3.62291657e-01]\n",
      "New theta_0 : [ 1.75811319e-03 -8.60372939e-02  7.08883382e-02  2.00574561e-02\n",
      "  5.88749039e-02 -2.08994972e-01  3.59278626e-01 -2.47462718e-04\n",
      " -2.78403866e-01  2.24462330e-01 -1.66353756e-01 -2.25649252e-01\n",
      "  1.07357148e-01 -3.62336366e-01]\n",
      "Training Error:  10.52026905626645\n",
      "====================================================================================================\n",
      "Iteration:  487\n",
      "Previous theta :  [ 1.75811319e-03 -8.60372939e-02  7.08883382e-02  2.00574561e-02\n",
      "  5.88749039e-02 -2.08994972e-01  3.59278626e-01 -2.47462718e-04\n",
      " -2.78403866e-01  2.24462330e-01 -1.66353756e-01 -2.25649252e-01\n",
      "  1.07357148e-01 -3.62336366e-01]\n",
      "New theta_0 : [ 1.74974255e-03 -8.60895365e-02  7.10166490e-02  2.00793698e-02\n",
      "  5.88760477e-02 -2.09316567e-01  3.59180580e-01 -2.39179306e-04\n",
      " -2.78756435e-01  2.24657600e-01 -1.66453362e-01 -2.25680640e-01\n",
      "  1.07332393e-01 -3.62380622e-01]\n",
      "Training Error:  10.519981373987417\n",
      "====================================================================================================\n",
      "Iteration:  488\n",
      "Previous theta :  [ 1.74974255e-03 -8.60895365e-02  7.10166490e-02  2.00793698e-02\n",
      "  5.88760477e-02 -2.09316567e-01  3.59180580e-01 -2.39179306e-04\n",
      " -2.78756435e-01  2.24657600e-01 -1.66453362e-01 -2.25680640e-01\n",
      "  1.07332393e-01 -3.62380622e-01]\n",
      "New theta_0 : [ 1.74143109e-03 -8.61414610e-02  7.11442427e-02  2.01015499e-02\n",
      "  5.88771441e-02 -2.09636025e-01  3.59083331e-01 -2.30897000e-04\n",
      " -2.79106503e-01  2.24852112e-01 -1.66553083e-01 -2.25711777e-01\n",
      "  1.07307845e-01 -3.62424428e-01]\n",
      "Training Error:  10.519697249594065\n",
      "====================================================================================================\n",
      "Iteration:  489\n",
      "Previous theta :  [ 1.74143109e-03 -8.61414610e-02  7.11442427e-02  2.01015499e-02\n",
      "  5.88771441e-02 -2.09636025e-01  3.59083331e-01 -2.30897000e-04\n",
      " -2.79106503e-01  2.24852112e-01 -1.66553083e-01 -2.25711777e-01\n",
      "  1.07307845e-01 -3.62424428e-01]\n",
      "New theta_0 : [ 1.73317839e-03 -8.61930696e-02  7.12711228e-02  2.01239923e-02\n",
      "  5.88781935e-02 -2.09953360e-01  3.58986871e-01 -2.22616632e-04\n",
      " -2.79454088e-01  2.25045870e-01 -1.66652917e-01 -2.25742668e-01\n",
      "  1.07283501e-01 -3.62467791e-01]\n",
      "Training Error:  10.519416635079105\n",
      "====================================================================================================\n",
      "Iteration:  490\n",
      "Previous theta :  [ 1.73317839e-03 -8.61930696e-02  7.12711228e-02  2.01239923e-02\n",
      "  5.88781935e-02 -2.09953360e-01  3.58986871e-01 -2.22616632e-04\n",
      " -2.79454088e-01  2.25045870e-01 -1.66652917e-01 -2.25742668e-01\n",
      "  1.07283501e-01 -3.62467791e-01]\n",
      "New theta_0 : [ 1.72498403e-03 -8.62443642e-02  7.13972930e-02  2.01466932e-02\n",
      "  5.88791964e-02 -2.10268587e-01  3.58891194e-01 -2.14339014e-04\n",
      " -2.79799209e-01  2.25238880e-01 -1.66752861e-01 -2.25773314e-01\n",
      "  1.07259360e-01 -3.62510716e-01]\n",
      "Training Error:  10.519139483111893\n",
      "====================================================================================================\n",
      "Iteration:  491\n",
      "Previous theta :  [ 1.72498403e-03 -8.62443642e-02  7.13972930e-02  2.01466932e-02\n",
      "  5.88791964e-02 -2.10268587e-01  3.58891194e-01 -2.14339014e-04\n",
      " -2.79799209e-01  2.25238880e-01 -1.66752861e-01 -2.25773314e-01\n",
      "  1.07259360e-01 -3.62510716e-01]\n",
      "New theta_0 : [ 1.71684758e-03 -8.62953469e-02  7.15227568e-02  2.01696487e-02\n",
      "  5.88801532e-02 -2.10581719e-01  3.58796292e-01 -2.06064933e-04\n",
      " -2.80141883e-01  2.25431144e-01 -1.66852910e-01 -2.25803717e-01\n",
      "  1.07235419e-01 -3.62553207e-01]\n",
      "Training Error:  10.51886574702864\n",
      "====================================================================================================\n",
      "Iteration:  492\n",
      "Previous theta :  [ 1.71684758e-03 -8.62953469e-02  7.15227568e-02  2.01696487e-02\n",
      "  5.88801532e-02 -2.10581719e-01  3.58796292e-01 -2.06064933e-04\n",
      " -2.80141883e-01  2.25431144e-01 -1.66852910e-01 -2.25803717e-01\n",
      "  1.07235419e-01 -3.62553207e-01]\n",
      "New theta_0 : [ 1.70876863e-03 -8.63460197e-02  7.16475179e-02  2.01928548e-02\n",
      "  5.88810644e-02 -2.10892771e-01  3.58702158e-01 -1.97795156e-04\n",
      " -2.80482128e-01  2.25622669e-01 -1.66953063e-01 -2.25833880e-01\n",
      "  1.07211678e-01 -3.62595269e-01]\n",
      "Training Error:  10.518595380822767\n",
      "====================================================================================================\n",
      "Iteration:  493\n",
      "Previous theta :  [ 1.70876863e-03 -8.63460197e-02  7.16475179e-02  2.01928548e-02\n",
      "  5.88810644e-02 -2.10892771e-01  3.58702158e-01 -1.97795156e-04\n",
      " -2.80482128e-01  2.25622669e-01 -1.66953063e-01 -2.25833880e-01\n",
      "  1.07211678e-01 -3.62595269e-01]\n",
      "New theta_0 : [ 1.70074677e-03 -8.63963845e-02  7.17715798e-02  2.02163079e-02\n",
      "  5.88819302e-02 -2.11201756e-01  3.58608785e-01 -1.89530428e-04\n",
      " -2.80819961e-01  2.25813457e-01 -1.67053315e-01 -2.25863806e-01\n",
      "  1.07188135e-01 -3.62636907e-01]\n",
      "Training Error:  10.518328339135385\n",
      "====================================================================================================\n",
      "Iteration:  494\n",
      "Previous theta :  [ 1.70074677e-03 -8.63963845e-02  7.17715798e-02  2.02163079e-02\n",
      "  5.88819302e-02 -2.11201756e-01  3.58608785e-01 -1.89530428e-04\n",
      " -2.80819961e-01  2.25813457e-01 -1.67053315e-01 -2.25863806e-01\n",
      "  1.07188135e-01 -3.62636907e-01]\n",
      "New theta_0 : [ 1.69278160e-03 -8.64464434e-02  7.18949461e-02  2.02400041e-02\n",
      "  5.88827512e-02 -2.11508688e-01  3.58516167e-01 -1.81271471e-04\n",
      " -2.81155400e-01  2.26003514e-01 -1.67153663e-01 -2.25893496e-01\n",
      "  1.07164787e-01 -3.62678126e-01]\n",
      "Training Error:  10.518064577245942\n",
      "====================================================================================================\n",
      "Iteration:  495\n",
      "Previous theta :  [ 1.69278160e-03 -8.64464434e-02  7.18949461e-02  2.02400041e-02\n",
      "  5.88827512e-02 -2.11508688e-01  3.58516167e-01 -1.81271471e-04\n",
      " -2.81155400e-01  2.26003514e-01 -1.67153663e-01 -2.25893496e-01\n",
      "  1.07164787e-01 -3.62678126e-01]\n",
      "New theta_0 : [ 1.68487269e-03 -8.64961984e-02  7.20176204e-02  2.02639397e-02\n",
      "  5.88835279e-02 -2.11813582e-01  3.58424295e-01 -1.73018991e-04\n",
      " -2.81488462e-01  2.26192843e-01 -1.67254106e-01 -2.25922954e-01\n",
      "  1.07141633e-01 -3.62718931e-01]\n",
      "Training Error:  10.51780405106298\n",
      "====================================================================================================\n",
      "Iteration:  496\n",
      "Previous theta :  [ 1.68487269e-03 -8.64961984e-02  7.20176204e-02  2.02639397e-02\n",
      "  5.88835279e-02 -2.11813582e-01  3.58424295e-01 -1.73018991e-04\n",
      " -2.81488462e-01  2.26192843e-01 -1.67254106e-01 -2.25922954e-01\n",
      "  1.07141633e-01 -3.62718931e-01]\n",
      "New theta_0 : [ 1.67701966e-03 -8.65456514e-02  7.21396061e-02  2.02881110e-02\n",
      "  5.88842605e-02 -2.12116449e-01  3.58333164e-01 -1.64773671e-04\n",
      " -2.81819164e-01  2.26381448e-01 -1.67354639e-01 -2.25952181e-01\n",
      "  1.07118672e-01 -3.62759325e-01]\n",
      "Training Error:  10.517546717115055\n",
      "====================================================================================================\n",
      "Iteration:  497\n",
      "Previous theta :  [ 1.67701966e-03 -8.65456514e-02  7.21396061e-02  2.02881110e-02\n",
      "  5.88842605e-02 -2.12116449e-01  3.58333164e-01 -1.64773671e-04\n",
      " -2.81819164e-01  2.26381448e-01 -1.67354639e-01 -2.25952181e-01\n",
      "  1.07118672e-01 -3.62759325e-01]\n",
      "New theta_0 : [ 1.66922209e-03 -8.65948043e-02  7.22609069e-02  2.03125143e-02\n",
      "  5.88849495e-02 -2.12417305e-01  3.58242766e-01 -1.56536174e-04\n",
      " -2.82147524e-01  2.26569335e-01 -1.67455259e-01 -2.25981179e-01\n",
      "  1.07095902e-01 -3.62799315e-01]\n",
      "Training Error:  10.517292532541774\n",
      "====================================================================================================\n",
      "Iteration:  498\n",
      "Previous theta :  [ 1.66922209e-03 -8.65948043e-02  7.22609069e-02  2.03125143e-02\n",
      "  5.88849495e-02 -2.12417305e-01  3.58242766e-01 -1.56536174e-04\n",
      " -2.82147524e-01  2.26569335e-01 -1.67455259e-01 -2.25981179e-01\n",
      "  1.07095902e-01 -3.62799315e-01]\n",
      "New theta_0 : [ 1.66147961e-03 -8.66436592e-02  7.23815264e-02  2.03371461e-02\n",
      "  5.88855954e-02 -2.12716162e-01  3.58153095e-01 -1.48307146e-04\n",
      " -2.82473558e-01  2.26756507e-01 -1.67555964e-01 -2.26009951e-01\n",
      "  1.07073322e-01 -3.62838904e-01]\n",
      "Training Error:  10.517041455084978\n",
      "====================================================================================================\n",
      "Iteration:  499\n",
      "Previous theta :  [ 1.66147961e-03 -8.66436592e-02  7.23815264e-02  2.03371461e-02\n",
      "  5.88855954e-02 -2.12716162e-01  3.58153095e-01 -1.48307146e-04\n",
      " -2.82473558e-01  2.26756507e-01 -1.67555964e-01 -2.26009951e-01\n",
      "  1.07073322e-01 -3.62838904e-01]\n",
      "New theta_0 : [ 1.65379180e-03 -8.66922179e-02  7.25014680e-02  2.03620028e-02\n",
      "  5.88861985e-02 -2.13013034e-01  3.58064145e-01 -1.40087212e-04\n",
      " -2.82797284e-01  2.26942967e-01 -1.67656751e-01 -2.26038500e-01\n",
      "  1.07050929e-01 -3.62878097e-01]\n",
      "Training Error:  10.516793443080045\n",
      "====================================================================================================\n",
      "Iteration:  500\n",
      "Previous theta :  [ 1.65379180e-03 -8.66922179e-02  7.25014680e-02  2.03620028e-02\n",
      "  5.88861985e-02 -2.13013034e-01  3.58064145e-01 -1.40087212e-04\n",
      " -2.82797284e-01  2.26942967e-01 -1.67656751e-01 -2.26038500e-01\n",
      "  1.07050929e-01 -3.62878097e-01]\n",
      "New theta_0 : [ 1.64615827e-03 -8.67404823e-02  7.26207353e-02  2.03870809e-02\n",
      "  5.88867592e-02 -2.13307934e-01  3.57975908e-01 -1.31876979e-04\n",
      " -2.83118717e-01  2.27128721e-01 -1.67757616e-01 -2.26066826e-01\n",
      "  1.07028722e-01 -3.62916899e-01]\n",
      "Training Error:  10.516548455447326\n",
      "====================================================================================================\n",
      "Iteration:  501\n",
      "Previous theta :  [ 1.64615827e-03 -8.67404823e-02  7.26207353e-02  2.03870809e-02\n",
      "  5.88867592e-02 -2.13307934e-01  3.57975908e-01 -1.31876979e-04\n",
      " -2.83118717e-01  2.27128721e-01 -1.67757616e-01 -2.26066826e-01\n",
      "  1.07028722e-01 -3.62916899e-01]\n",
      "New theta_0 : [ 1.63857865e-03 -8.67884544e-02  7.27393317e-02  2.04123769e-02\n",
      "  5.88872779e-02 -2.13600875e-01  3.57888378e-01 -1.23677038e-04\n",
      " -2.83437874e-01  2.27313772e-01 -1.67858557e-01 -2.26094933e-01\n",
      "  1.07006700e-01 -3.62955313e-01]\n",
      "Training Error:  10.516306451683711\n",
      "====================================================================================================\n",
      "Iteration:  502\n",
      "Previous theta :  [ 1.63857865e-03 -8.67884544e-02  7.27393317e-02  2.04123769e-02\n",
      "  5.88872779e-02 -2.13600875e-01  3.57888378e-01 -1.23677038e-04\n",
      " -2.83437874e-01  2.27313772e-01 -1.67858557e-01 -2.26094933e-01\n",
      "  1.07006700e-01 -3.62955313e-01]\n",
      "New theta_0 : [ 1.63105254e-03 -8.68361361e-02  7.28572610e-02  2.04378873e-02\n",
      "  5.88877551e-02 -2.13891871e-01  3.57801549e-01 -1.15487960e-04\n",
      " -2.83754772e-01  2.27498123e-01 -1.67959571e-01 -2.26122822e-01\n",
      "  1.06984861e-01 -3.62993344e-01]\n",
      "Training Error:  10.51606739185431\n",
      "====================================================================================================\n",
      "Iteration:  503\n",
      "Previous theta :  [ 1.63105254e-03 -8.68361361e-02  7.28572610e-02  2.04378873e-02\n",
      "  5.88877551e-02 -2.13891871e-01  3.57801549e-01 -1.15487960e-04\n",
      " -2.83754772e-01  2.27498123e-01 -1.67959571e-01 -2.26122822e-01\n",
      "  1.06984861e-01 -3.62993344e-01]\n",
      "New theta_0 : [ 1.62357956e-03 -8.68835292e-02  7.29745264e-02  2.04636087e-02\n",
      "  5.88881911e-02 -2.14180934e-01  3.57715415e-01 -1.07310300e-04\n",
      " -2.84069428e-01  2.27681780e-01 -1.68060655e-01 -2.26150496e-01\n",
      "  1.06963204e-01 -3.63030997e-01]\n",
      "Training Error:  10.51583123658427\n",
      "====================================================================================================\n",
      "Iteration:  504\n",
      "Previous theta :  [ 1.62357956e-03 -8.68835292e-02  7.29745264e-02  2.04636087e-02\n",
      "  5.88881911e-02 -2.14180934e-01  3.57715415e-01 -1.07310300e-04\n",
      " -2.84069428e-01  2.27681780e-01 -1.68060655e-01 -2.26150496e-01\n",
      "  1.06963204e-01 -3.63030997e-01]\n",
      "New theta_0 : [ 1.61615933e-03 -8.69306357e-02  7.30911315e-02  2.04895377e-02\n",
      "  5.88885864e-02 -2.14468077e-01  3.57629968e-01 -9.91445950e-05\n",
      " -2.84381857e-01  2.27864746e-01 -1.68161806e-01 -2.26177957e-01\n",
      "  1.06941727e-01 -3.63068275e-01]\n",
      "Training Error:  10.515597947050706\n",
      "====================================================================================================\n",
      "Iteration:  505\n",
      "Previous theta :  [ 1.61615933e-03 -8.69306357e-02  7.30911315e-02  2.04895377e-02\n",
      "  5.88885864e-02 -2.14468077e-01  3.57629968e-01 -9.91445950e-05\n",
      " -2.84381857e-01  2.27864746e-01 -1.68161806e-01 -2.26177957e-01\n",
      "  1.06941727e-01 -3.63068275e-01]\n",
      "New theta_0 : [ 1.60879148e-03 -8.69774573e-02  7.32070799e-02  2.05156711e-02\n",
      "  5.88889412e-02 -2.14753313e-01  3.57545204e-01 -9.09913674e-05\n",
      " -2.84692075e-01  2.28047025e-01 -1.68263022e-01 -2.26205207e-01\n",
      "  1.06920428e-01 -3.63105183e-01]\n",
      "Training Error:  10.51536748497474\n",
      "====================================================================================================\n",
      "Iteration:  506\n",
      "Previous theta :  [ 1.60879148e-03 -8.69774573e-02  7.32070799e-02  2.05156711e-02\n",
      "  5.88889412e-02 -2.14753313e-01  3.57545204e-01 -9.09913674e-05\n",
      " -2.84692075e-01  2.28047025e-01 -1.68263022e-01 -2.26205207e-01\n",
      "  1.06920428e-01 -3.63105183e-01]\n",
      "New theta_0 : [ 1.60147562e-03 -8.70239960e-02  7.33223750e-02  2.05420054e-02\n",
      "  5.88892560e-02 -2.15036655e-01  3.57461115e-01 -8.28511218e-05\n",
      " -2.85000098e-01  2.28228620e-01 -1.68364300e-01 -2.26232247e-01\n",
      "  1.06899306e-01 -3.63141725e-01]\n",
      "Training Error:  10.51513981261369\n",
      "====================================================================================================\n",
      "Iteration:  507\n",
      "Previous theta :  [ 1.60147562e-03 -8.70239960e-02  7.33223750e-02  2.05420054e-02\n",
      "  5.88892560e-02 -2.15036655e-01  3.57461115e-01 -8.28511218e-05\n",
      " -2.85000098e-01  2.28228620e-01 -1.68364300e-01 -2.26232247e-01\n",
      "  1.06899306e-01 -3.63141725e-01]\n",
      "New theta_0 : [ 1.59421139e-03 -8.70702535e-02  7.34370202e-02  2.05685375e-02\n",
      "  5.88895312e-02 -2.15318115e-01  3.57377695e-01 -7.47243476e-05\n",
      " -2.85305943e-01  2.28409536e-01 -1.68465636e-01 -2.26259080e-01\n",
      "  1.06878360e-01 -3.63177905e-01]\n",
      "Training Error:  10.514914892753332\n",
      "====================================================================================================\n",
      "Iteration:  508\n",
      "Previous theta :  [ 1.59421139e-03 -8.70702535e-02  7.34370202e-02  2.05685375e-02\n",
      "  5.88895312e-02 -2.15318115e-01  3.57377695e-01 -7.47243476e-05\n",
      " -2.85305943e-01  2.28409536e-01 -1.68465636e-01 -2.26259080e-01\n",
      "  1.06878360e-01 -3.63177905e-01]\n",
      "New theta_0 : [ 1.58699841e-03 -8.71162318e-02  7.35510190e-02  2.05952641e-02\n",
      "  5.88897672e-02 -2.15597707e-01  3.57294939e-01 -6.66115186e-05\n",
      " -2.85609625e-01  2.28589776e-01 -1.68567029e-01 -2.26285708e-01\n",
      "  1.06857588e-01 -3.63213727e-01]\n",
      "Training Error:  10.514692688700308\n",
      "====================================================================================================\n",
      "Iteration:  509\n",
      "Previous theta :  [ 1.58699841e-03 -8.71162318e-02  7.35510190e-02  2.05952641e-02\n",
      "  5.88897672e-02 -2.15597707e-01  3.57294939e-01 -6.66115186e-05\n",
      " -2.85609625e-01  2.28589776e-01 -1.68567029e-01 -2.26285708e-01\n",
      "  1.06857588e-01 -3.63213727e-01]\n",
      "New theta_0 : [ 1.57983633e-03 -8.71619326e-02  7.36643749e-02  2.06221820e-02\n",
      "  5.88899643e-02 -2.15875442e-01  3.57212841e-01 -5.85130935e-05\n",
      " -2.85911159e-01  2.28769345e-01 -1.68668476e-01 -2.26312133e-01\n",
      "  1.06836988e-01 -3.63249195e-01]\n",
      "Training Error:  10.514473164274632\n",
      "====================================================================================================\n",
      "Iteration:  510\n",
      "Previous theta :  [ 1.57983633e-03 -8.71619326e-02  7.36643749e-02  2.06221820e-02\n",
      "  5.88899643e-02 -2.15875442e-01  3.57212841e-01 -5.85130935e-05\n",
      " -2.85911159e-01  2.28769345e-01 -1.68668476e-01 -2.26312133e-01\n",
      "  1.06836988e-01 -3.63249195e-01]\n",
      "New theta_0 : [ 1.57272478e-03 -8.72073577e-02  7.37770913e-02  2.06492881e-02\n",
      "  5.88901229e-02 -2.16151333e-01  3.57131394e-01 -5.04295163e-05\n",
      " -2.86210561e-01  2.28948244e-01 -1.68769974e-01 -2.26338356e-01\n",
      "  1.06816560e-01 -3.63284314e-01]\n",
      "Training Error:  10.51425628380232\n",
      "====================================================================================================\n",
      "Iteration:  511\n",
      "Previous theta :  [ 1.57272478e-03 -8.72073577e-02  7.37770913e-02  2.06492881e-02\n",
      "  5.88901229e-02 -2.16151333e-01  3.57131394e-01 -5.04295163e-05\n",
      " -2.86210561e-01  2.28948244e-01 -1.68769974e-01 -2.26338356e-01\n",
      "  1.06816560e-01 -3.63284314e-01]\n",
      "New theta_0 : [ 1.56566339e-03 -8.72525089e-02  7.38891717e-02  2.06765792e-02\n",
      "  5.88902433e-02 -2.16425392e-01  3.57050593e-01 -4.23612163e-05\n",
      " -2.86507846e-01  2.29126480e-01 -1.68871520e-01 -2.26364380e-01\n",
      "  1.06796301e-01 -3.63319086e-01]\n",
      "Training Error:  10.514042012108092\n",
      "====================================================================================================\n",
      "Iteration:  512\n",
      "Previous theta :  [ 1.56566339e-03 -8.72525089e-02  7.38891717e-02  2.06765792e-02\n",
      "  5.88902433e-02 -2.16425392e-01  3.57050593e-01 -4.23612163e-05\n",
      " -2.86507846e-01  2.29126480e-01 -1.68871520e-01 -2.26364380e-01\n",
      "  1.06796301e-01 -3.63319086e-01]\n",
      "New theta_0 : [ 1.55865181e-03 -8.72973880e-02  7.40006194e-02  2.07040523e-02\n",
      "  5.88903260e-02 -2.16697632e-01  3.56970431e-01 -3.43086089e-05\n",
      " -2.86803031e-01  2.29304054e-01 -1.68973112e-01 -2.26390206e-01\n",
      "  1.06776211e-01 -3.63353516e-01]\n",
      "Training Error:  10.513830314508237\n",
      "====================================================================================================\n",
      "Iteration:  513\n",
      "Previous theta :  [ 1.55865181e-03 -8.72973880e-02  7.40006194e-02  2.07040523e-02\n",
      "  5.88903260e-02 -2.16697632e-01  3.56970431e-01 -3.43086089e-05\n",
      " -2.86803031e-01  2.29304054e-01 -1.68973112e-01 -2.26390206e-01\n",
      "  1.06776211e-01 -3.63353516e-01]\n",
      "New theta_0 : [ 1.55168968e-03 -8.73419968e-02  7.41114379e-02  2.07317042e-02\n",
      "  5.88903713e-02 -2.16968065e-01  3.56890904e-01 -2.62720954e-05\n",
      " -2.87096129e-01  2.29480972e-01 -1.69074747e-01 -2.26415837e-01\n",
      "  1.06756287e-01 -3.63387607e-01]\n",
      "Training Error:  10.513621156803534\n",
      "====================================================================================================\n",
      "Iteration:  514\n",
      "Previous theta :  [ 1.55168968e-03 -8.73419968e-02  7.41114379e-02  2.07317042e-02\n",
      "  5.88903713e-02 -2.16968065e-01  3.56890904e-01 -2.62720954e-05\n",
      " -2.87096129e-01  2.29480972e-01 -1.69074747e-01 -2.26415837e-01\n",
      "  1.06756287e-01 -3.63387607e-01]\n",
      "New theta_0 : [ 1.54477665e-03 -8.73863371e-02  7.42216306e-02  2.07595321e-02\n",
      "  5.88903796e-02 -2.17236703e-01  3.56812005e-01 -1.82520638e-05\n",
      " -2.87387155e-01  2.29657235e-01 -1.69176423e-01 -2.26441274e-01\n",
      "  1.06736529e-01 -3.63421364e-01]\n",
      "Training Error:  10.513414505272305\n",
      "====================================================================================================\n",
      "Iteration:  515\n",
      "Previous theta :  [ 1.54477665e-03 -8.73863371e-02  7.42216306e-02  2.07595321e-02\n",
      "  5.88903796e-02 -2.17236703e-01  3.56812005e-01 -1.82520638e-05\n",
      " -2.87387155e-01  2.29657235e-01 -1.69176423e-01 -2.26441274e-01\n",
      "  1.06736529e-01 -3.63421364e-01]\n",
      "New theta_0 : [ 1.53791236e-03 -8.74304105e-02  7.43312008e-02  2.07875328e-02\n",
      "  5.88903512e-02 -2.17503557e-01  3.56733729e-01 -1.02488887e-05\n",
      " -2.87676126e-01  2.29832849e-01 -1.69278138e-01 -2.26466519e-01\n",
      "  1.06716935e-01 -3.63454790e-01]\n",
      "Training Error:  10.513210326663554\n",
      "====================================================================================================\n",
      "Iteration:  516\n",
      "Previous theta :  [ 1.53791236e-03 -8.74304105e-02  7.43312008e-02  2.07875328e-02\n",
      "  5.88903512e-02 -2.17503557e-01  3.56733729e-01 -1.02488887e-05\n",
      " -2.87676126e-01  2.29832849e-01 -1.69278138e-01 -2.26466519e-01\n",
      "  1.06716935e-01 -3.63454790e-01]\n",
      "New theta_0 : [ 1.53109648e-03 -8.74742189e-02  7.44401520e-02  2.08157035e-02\n",
      "  5.88902865e-02 -2.17768641e-01  3.56656070e-01 -2.26293176e-06\n",
      " -2.87963055e-01  2.30007816e-01 -1.69379888e-01 -2.26491574e-01\n",
      "  1.06697504e-01 -3.63487889e-01]\n",
      "Training Error:  10.513008588190226\n",
      "====================================================================================================\n",
      "Iteration:  517\n",
      "Previous theta :  [ 1.53109648e-03 -8.74742189e-02  7.44401520e-02  2.08157035e-02\n",
      "  5.88902865e-02 -2.17768641e-01  3.56656070e-01 -2.26293176e-06\n",
      " -2.87963055e-01  2.30007816e-01 -1.69379888e-01 -2.26491574e-01\n",
      "  1.06697504e-01 -3.63487889e-01]\n",
      "New theta_0 : [ 1.52432865e-03 -8.75177640e-02  7.45484875e-02  2.08440412e-02\n",
      "  5.88901859e-02 -2.18031965e-01  3.56579023e-01  5.70545797e-06\n",
      " -2.88247957e-01  2.30182140e-01 -1.69481671e-01 -2.26516440e-01\n",
      "  1.06678235e-01 -3.63520664e-01]\n",
      "Training Error:  10.512809257522534\n",
      "====================================================================================================\n",
      "Iteration:  518\n",
      "Previous theta :  [ 1.52432865e-03 -8.75177640e-02  7.45484875e-02  2.08440412e-02\n",
      "  5.88901859e-02 -2.18031965e-01  3.56579023e-01  5.70545797e-06\n",
      " -2.88247957e-01  2.30182140e-01 -1.69481671e-01 -2.26516440e-01\n",
      "  1.06678235e-01 -3.63520664e-01]\n",
      "New theta_0 : [ 1.51760853e-03 -8.75610474e-02  7.46562107e-02  2.08725431e-02\n",
      "  5.88900496e-02 -2.18293541e-01  3.56502582e-01  1.36559438e-05\n",
      " -2.88530847e-01  2.30355824e-01 -1.69583486e-01 -2.26541120e-01\n",
      "  1.06659125e-01 -3.63553119e-01]\n",
      "Training Error:  10.512612302781429\n",
      "====================================================================================================\n",
      "Iteration:  519\n",
      "Previous theta :  [ 1.51760853e-03 -8.75610474e-02  7.46562107e-02  2.08725431e-02\n",
      "  5.88900496e-02 -2.18293541e-01  3.56502582e-01  1.36559438e-05\n",
      " -2.88530847e-01  2.30355824e-01 -1.69583486e-01 -2.26541120e-01\n",
      "  1.06659125e-01 -3.63553119e-01]\n",
      "New theta_0 : [ 1.51093578e-03 -8.76040710e-02  7.47633249e-02  2.09012062e-02\n",
      "  5.88898781e-02 -2.18553382e-01  3.56426741e-01  2.15882013e-05\n",
      " -2.88811740e-01  2.30528873e-01 -1.69685329e-01 -2.26565616e-01\n",
      "  1.06640174e-01 -3.63585258e-01]\n",
      "Training Error:  10.512417692532113\n",
      "====================================================================================================\n",
      "Iteration:  520\n",
      "Previous theta :  [ 1.51093578e-03 -8.76040710e-02  7.47633249e-02  2.09012062e-02\n",
      "  5.88898781e-02 -2.18553382e-01  3.56426741e-01  2.15882013e-05\n",
      " -2.88811740e-01  2.30528873e-01 -1.69685329e-01 -2.26565616e-01\n",
      "  1.06640174e-01 -3.63585258e-01]\n",
      "New theta_0 : [ 1.50431006e-03 -8.76468363e-02  7.48698335e-02  2.09300277e-02\n",
      "  5.88896716e-02 -2.18811498e-01  3.56351496e-01  2.95019177e-05\n",
      " -2.89090649e-01  2.30701288e-01 -1.69787198e-01 -2.26589928e-01\n",
      "  1.06621381e-01 -3.63617084e-01]\n",
      "Training Error:  10.512225395777694\n",
      "====================================================================================================\n",
      "Iteration:  521\n",
      "Previous theta :  [ 1.50431006e-03 -8.76468363e-02  7.48698335e-02  2.09300277e-02\n",
      "  5.88896716e-02 -2.18811498e-01  3.56351496e-01  2.95019177e-05\n",
      " -2.89090649e-01  2.30701288e-01 -1.69787198e-01 -2.26589928e-01\n",
      "  1.06621381e-01 -3.63617084e-01]\n",
      "New theta_0 : [ 1.49773103e-03 -8.76893451e-02  7.49757397e-02  2.09590050e-02\n",
      "  5.88894306e-02 -2.19067902e-01  3.56276841e-01  3.73967918e-05\n",
      " -2.89367590e-01  2.30873075e-01 -1.69889091e-01 -2.26614058e-01\n",
      "  1.06602743e-01 -3.63648600e-01]\n",
      "Training Error:  10.5120353819529\n",
      "====================================================================================================\n",
      "Iteration:  522\n",
      "Previous theta :  [ 1.49773103e-03 -8.76893451e-02  7.49757397e-02  2.09590050e-02\n",
      "  5.88894306e-02 -2.19067902e-01  3.56276841e-01  3.73967918e-05\n",
      " -2.89367590e-01  2.30873075e-01 -1.69889091e-01 -2.26614058e-01\n",
      "  1.06602743e-01 -3.63648600e-01]\n",
      "New theta_0 : [ 1.49119837e-03 -8.77315991e-02  7.50810470e-02  2.09881351e-02\n",
      "  5.88891554e-02 -2.19322605e-01  3.56202771e-01  4.52725339e-05\n",
      " -2.89642575e-01  2.31044235e-01 -1.69991005e-01 -2.26638009e-01\n",
      "  1.06584261e-01 -3.63679811e-01]\n",
      "Training Error:  10.51184762091791\n",
      "====================================================================================================\n",
      "Iteration:  523\n",
      "Previous theta :  [ 1.49119837e-03 -8.77315991e-02  7.50810470e-02  2.09881351e-02\n",
      "  5.88891554e-02 -2.19322605e-01  3.56202771e-01  4.52725339e-05\n",
      " -2.89642575e-01  2.31044235e-01 -1.69991005e-01 -2.26638009e-01\n",
      "  1.06584261e-01 -3.63679811e-01]\n",
      "New theta_0 : [ 1.48471174e-03 -8.77735999e-02  7.51857585e-02  2.10174154e-02\n",
      "  5.88888462e-02 -2.19575618e-01  3.56129280e-01  5.31288650e-05\n",
      " -2.89915620e-01  2.31214773e-01 -1.70092938e-01 -2.26661782e-01\n",
      "  1.06565932e-01 -3.63710718e-01]\n",
      "Training Error:  10.511662082952256\n",
      "====================================================================================================\n",
      "Iteration:  524\n",
      "Previous theta :  [ 1.48471174e-03 -8.77735999e-02  7.51857585e-02  2.10174154e-02\n",
      "  5.88888462e-02 -2.19575618e-01  3.56129280e-01  5.31288650e-05\n",
      " -2.89915620e-01  2.31214773e-01 -1.70092938e-01 -2.26661782e-01\n",
      "  1.06565932e-01 -3.63710718e-01]\n",
      "New theta_0 : [ 1.47827081e-03 -8.78153492e-02  7.52898776e-02  2.10468432e-02\n",
      "  5.88885035e-02 -2.19826953e-01  3.56056364e-01  6.09655172e-05\n",
      " -2.90186738e-01  2.31384692e-01 -1.70194888e-01 -2.26685378e-01\n",
      "  1.06547755e-01 -3.63741327e-01]\n",
      "Training Error:  10.511478738748828\n",
      "====================================================================================================\n",
      "Iteration:  525\n",
      "Previous theta :  [ 1.47827081e-03 -8.78153492e-02  7.52898776e-02  2.10468432e-02\n",
      "  5.88885035e-02 -2.19826953e-01  3.56056364e-01  6.09655172e-05\n",
      " -2.90186738e-01  2.31384692e-01 -1.70194888e-01 -2.26685378e-01\n",
      "  1.06547755e-01 -3.63741327e-01]\n",
      "New theta_0 : [ 1.47187526e-03 -8.78568486e-02  7.53934076e-02  2.10764159e-02\n",
      "  5.88881276e-02 -2.20076620e-01  3.55984017e-01  6.87822330e-05\n",
      " -2.90455943e-01  2.31553995e-01 -1.70296853e-01 -2.26708800e-01\n",
      "  1.06529729e-01 -3.63771639e-01]\n",
      "Training Error:  10.511297559407954\n",
      "====================================================================================================\n",
      "Iteration:  526\n",
      "Previous theta :  [ 1.47187526e-03 -8.78568486e-02  7.53934076e-02  2.10764159e-02\n",
      "  5.88881276e-02 -2.20076620e-01  3.55984017e-01  6.87822330e-05\n",
      " -2.90455943e-01  2.31553995e-01 -1.70296853e-01 -2.26708800e-01\n",
      "  1.06529729e-01 -3.63771639e-01]\n",
      "New theta_0 : [ 1.46552477e-03 -8.78980997e-02  7.54963517e-02  2.11061306e-02\n",
      "  5.88877188e-02 -2.20324632e-01  3.55912234e-01  7.65787653e-05\n",
      " -2.90723249e-01  2.31722685e-01 -1.70398830e-01 -2.26732049e-01\n",
      "  1.06511853e-01 -3.63801659e-01]\n",
      "Training Error:  10.511118516431585\n",
      "====================================================================================================\n",
      "Iteration:  527\n",
      "Previous theta :  [ 1.46552477e-03 -8.78980997e-02  7.54963517e-02  2.11061306e-02\n",
      "  5.88877188e-02 -2.20324632e-01  3.55912234e-01  7.65787653e-05\n",
      " -2.90723249e-01  2.31722685e-01 -1.70398830e-01 -2.26732049e-01\n",
      "  1.06511853e-01 -3.63801659e-01]\n",
      "New theta_0 : [ 1.45921900e-03 -8.79391043e-02  7.55987132e-02  2.11359850e-02\n",
      "  5.88872775e-02 -2.20570998e-01  3.55841011e-01  8.43548769e-05\n",
      " -2.90988670e-01  2.31890765e-01 -1.70500818e-01 -2.26755126e-01\n",
      "  1.06494125e-01 -3.63831389e-01]\n",
      "Training Error:  10.510941581717539\n",
      "====================================================================================================\n",
      "Iteration:  528\n",
      "Previous theta :  [ 1.45921900e-03 -8.79391043e-02  7.55987132e-02  2.11359850e-02\n",
      "  5.88872775e-02 -2.20570998e-01  3.55841011e-01  8.43548769e-05\n",
      " -2.90988670e-01  2.31890765e-01 -1.70500818e-01 -2.26755126e-01\n",
      "  1.06494125e-01 -3.63831389e-01]\n",
      "New theta_0 : [ 1.45295765e-03 -8.79798639e-02  7.57004954e-02  2.11659763e-02\n",
      "  5.88868039e-02 -2.20815731e-01  3.55770341e-01  9.21103407e-05\n",
      " -2.91252218e-01  2.32058240e-01 -1.70602813e-01 -2.26778033e-01\n",
      "  1.06476545e-01 -3.63860833e-01]\n",
      "Training Error:  10.510766727553861\n",
      "====================================================================================================\n",
      "Iteration:  529\n",
      "Previous theta :  [ 1.45295765e-03 -8.79798639e-02  7.57004954e-02  2.11659763e-02\n",
      "  5.88868039e-02 -2.20815731e-01  3.55770341e-01  9.21103407e-05\n",
      " -2.91252218e-01  2.32058240e-01 -1.70602813e-01 -2.26778033e-01\n",
      "  1.06476545e-01 -3.63860833e-01]\n",
      "New theta_0 : [ 1.44674039e-03 -8.80203800e-02  7.58017014e-02  2.11961021e-02\n",
      "  5.88862983e-02 -2.21058841e-01  3.55700222e-01  9.98449389e-05\n",
      " -2.91513908e-01  2.32225111e-01 -1.70704814e-01 -2.26800771e-01\n",
      "  1.06459111e-01 -3.63889994e-01]\n",
      "Training Error:  10.510593926613229\n",
      "====================================================================================================\n",
      "Iteration:  530\n",
      "Previous theta :  [ 1.44674039e-03 -8.80203800e-02  7.58017014e-02  2.11961021e-02\n",
      "  5.88862983e-02 -2.21058841e-01  3.55700222e-01  9.98449389e-05\n",
      " -2.91513908e-01  2.32225111e-01 -1.70704814e-01 -2.26800771e-01\n",
      "  1.06459111e-01 -3.63889994e-01]\n",
      "New theta_0 : [ 1.44056691e-03 -8.80606544e-02  7.59023344e-02  2.12263597e-02\n",
      "  5.88857612e-02 -2.21300339e-01  3.55630646e-01  1.07558463e-04\n",
      " -2.91773753e-01  2.32391382e-01 -1.70806819e-01 -2.26823343e-01\n",
      "  1.06441821e-01 -3.63918874e-01]\n",
      "Training Error:  10.510423151947478\n",
      "====================================================================================================\n",
      "Iteration:  531\n",
      "Previous theta :  [ 1.44056691e-03 -8.80606544e-02  7.59023344e-02  2.12263597e-02\n",
      "  5.88857612e-02 -2.21300339e-01  3.55630646e-01  1.07558463e-04\n",
      " -2.91773753e-01  2.32391382e-01 -1.70806819e-01 -2.26823343e-01\n",
      "  1.06441821e-01 -3.63918874e-01]\n",
      "New theta_0 : [ 1.43443690e-03 -8.81006885e-02  7.60023978e-02  2.12567468e-02\n",
      "  5.88851928e-02 -2.21540235e-01  3.55561610e-01  1.15250715e-04\n",
      " -2.92031766e-01  2.32557057e-01 -1.70908825e-01 -2.26845749e-01\n",
      "  1.06424675e-01 -3.63947478e-01]\n",
      "Training Error:  10.51025437698218\n",
      "====================================================================================================\n",
      "Iteration:  532\n",
      "Previous theta :  [ 1.43443690e-03 -8.81006885e-02  7.60023978e-02  2.12567468e-02\n",
      "  5.88851928e-02 -2.21540235e-01  3.55561610e-01  1.15250715e-04\n",
      " -2.92031766e-01  2.32557057e-01 -1.70908825e-01 -2.26845749e-01\n",
      "  1.06424675e-01 -3.63947478e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 1.42835005e-03 -8.81404840e-02  7.61018946e-02  2.12872609e-02\n",
      "  5.88845935e-02 -2.21778542e-01  3.55493109e-01  1.22921503e-04\n",
      " -2.92287961e-01  2.32722138e-01 -1.71010831e-01 -2.26867992e-01\n",
      "  1.06407671e-01 -3.63975808e-01]\n",
      "Training Error:  10.510087575511301\n",
      "====================================================================================================\n",
      "Iteration:  533\n",
      "Previous theta :  [ 1.42835005e-03 -8.81404840e-02  7.61018946e-02  2.12872609e-02\n",
      "  5.88845935e-02 -2.21778542e-01  3.55493109e-01  1.22921503e-04\n",
      " -2.92287961e-01  2.32722138e-01 -1.71010831e-01 -2.26867992e-01\n",
      "  1.06407671e-01 -3.63975808e-01]\n",
      "New theta_0 : [ 1.42230605e-03 -8.81800424e-02  7.62008281e-02  2.13178995e-02\n",
      "  5.88839635e-02 -2.22015268e-01  3.55425139e-01  1.30570647e-04\n",
      " -2.92542349e-01  2.32886628e-01 -1.71112834e-01 -2.26890072e-01\n",
      "  1.06390809e-01 -3.64003867e-01]\n",
      "Training Error:  10.509922721691964\n",
      "====================================================================================================\n",
      "Iteration:  534\n",
      "Previous theta :  [ 1.42230605e-03 -8.81800424e-02  7.62008281e-02  2.13178995e-02\n",
      "  5.88839635e-02 -2.22015268e-01  3.55425139e-01  1.30570647e-04\n",
      " -2.92542349e-01  2.32886628e-01 -1.71112834e-01 -2.26890072e-01\n",
      "  1.06390809e-01 -3.64003867e-01]\n",
      "New theta_0 : [ 1.41630459e-03 -8.82193652e-02  7.62992014e-02  2.13486601e-02\n",
      "  5.88833032e-02 -2.22250425e-01  3.55357693e-01  1.38197973e-04\n",
      " -2.92794945e-01  2.33050531e-01 -1.71214833e-01 -2.26911991e-01\n",
      "  1.06374087e-01 -3.64031658e-01]\n",
      "Training Error:  10.509759790039253\n",
      "====================================================================================================\n",
      "Iteration:  535\n",
      "Previous theta :  [ 1.41630459e-03 -8.82193652e-02  7.62992014e-02  2.13486601e-02\n",
      "  5.88833032e-02 -2.22250425e-01  3.55357693e-01  1.38197973e-04\n",
      " -2.92794945e-01  2.33050531e-01 -1.71214833e-01 -2.26911991e-01\n",
      "  1.06374087e-01 -3.64031658e-01]\n",
      "New theta_0 : [ 1.41034538e-03 -8.82584541e-02  7.63970177e-02  2.13795405e-02\n",
      "  5.88826128e-02 -2.22484024e-01  3.55290769e-01  1.45803317e-04\n",
      " -2.93045762e-01  2.33213849e-01 -1.71316824e-01 -2.26933750e-01\n",
      "  1.06357503e-01 -3.64059185e-01]\n",
      "Training Error:  10.509598755421106\n",
      "====================================================================================================\n",
      "Iteration:  536\n",
      "Previous theta :  [ 1.41034538e-03 -8.82584541e-02  7.63970177e-02  2.13795405e-02\n",
      "  5.88826128e-02 -2.22484024e-01  3.55290769e-01  1.45803317e-04\n",
      " -2.93045762e-01  2.33213849e-01 -1.71316824e-01 -2.26933750e-01\n",
      "  1.06357503e-01 -3.64059185e-01]\n",
      "New theta_0 : [ 1.40442811e-03 -8.82973106e-02  7.64942802e-02  2.14105383e-02\n",
      "  5.88818927e-02 -2.22716075e-01  3.55224361e-01  1.53386523e-04\n",
      " -2.93294811e-01  2.33376586e-01 -1.71418807e-01 -2.26955352e-01\n",
      "  1.06341058e-01 -3.64086449e-01]\n",
      "Training Error:  10.509439593053306\n",
      "====================================================================================================\n",
      "Iteration:  537\n",
      "Previous theta :  [ 1.40442811e-03 -8.82973106e-02  7.64942802e-02  2.14105383e-02\n",
      "  5.88818927e-02 -2.22716075e-01  3.55224361e-01  1.53386523e-04\n",
      " -2.93294811e-01  2.33376586e-01 -1.71418807e-01 -2.26955352e-01\n",
      "  1.06341058e-01 -3.64086449e-01]\n",
      "New theta_0 : [ 1.39855248e-03 -8.83359361e-02  7.65909919e-02  2.14416512e-02\n",
      "  5.88811432e-02 -2.22946588e-01  3.55158464e-01  1.60947442e-04\n",
      " -2.93542106e-01  2.33538745e-01 -1.71520780e-01 -2.26976797e-01\n",
      "  1.06324748e-01 -3.64113454e-01]\n",
      "Training Error:  10.509282278494508\n",
      "====================================================================================================\n",
      "Iteration:  538\n",
      "Previous theta :  [ 1.39855248e-03 -8.83359361e-02  7.65909919e-02  2.14416512e-02\n",
      "  5.88811432e-02 -2.22946588e-01  3.55158464e-01  1.60947442e-04\n",
      " -2.93542106e-01  2.33538745e-01 -1.71520780e-01 -2.26976797e-01\n",
      "  1.06324748e-01 -3.64113454e-01]\n",
      "New theta_0 : [ 1.39271819e-03 -8.83743322e-02  7.66871560e-02  2.14728767e-02\n",
      "  5.88803646e-02 -2.23175573e-01  3.55093075e-01  1.68485933e-04\n",
      " -2.93787660e-01  2.33700327e-01 -1.71622739e-01 -2.26998087e-01\n",
      "  1.06308575e-01 -3.64140202e-01]\n",
      "Training Error:  10.509126787641348\n",
      "====================================================================================================\n",
      "Iteration:  539\n",
      "Previous theta :  [ 1.39271819e-03 -8.83743322e-02  7.66871560e-02  2.14728767e-02\n",
      "  5.88803646e-02 -2.23175573e-01  3.55093075e-01  1.68485933e-04\n",
      " -2.93787660e-01  2.33700327e-01 -1.71622739e-01 -2.26998087e-01\n",
      "  1.06308575e-01 -3.64140202e-01]\n",
      "New theta_0 : [ 1.38692496e-03 -8.84125003e-02  7.67827756e-02  2.15042128e-02\n",
      "  5.88795571e-02 -2.23403041e-01  3.55028188e-01  1.76001863e-04\n",
      " -2.94031484e-01  2.33861338e-01 -1.71724684e-01 -2.27019223e-01\n",
      "  1.06292536e-01 -3.64166698e-01]\n",
      "Training Error:  10.508973096723649\n",
      "====================================================================================================\n",
      "Iteration:  540\n",
      "Previous theta :  [ 1.38692496e-03 -8.84125003e-02  7.67827756e-02  2.15042128e-02\n",
      "  5.88795571e-02 -2.23403041e-01  3.55028188e-01  1.76001863e-04\n",
      " -2.94031484e-01  2.33861338e-01 -1.71724684e-01 -2.27019223e-01\n",
      "  1.06292536e-01 -3.64166698e-01]\n",
      "New theta_0 : [ 1.38117248e-03 -8.84504421e-02  7.68778537e-02  2.15356570e-02\n",
      "  5.88787212e-02 -2.23629002e-01  3.54963800e-01  1.83495106e-04\n",
      " -2.94273591e-01  2.34021778e-01 -1.71826613e-01 -2.27040207e-01\n",
      "  1.06276630e-01 -3.64192942e-01]\n",
      "Training Error:  10.508821182299666\n",
      "====================================================================================================\n",
      "Iteration:  541\n",
      "Previous theta :  [ 1.38117248e-03 -8.84504421e-02  7.68778537e-02  2.15356570e-02\n",
      "  5.88787212e-02 -2.23629002e-01  3.54963800e-01  1.83495106e-04\n",
      " -2.94273591e-01  2.34021778e-01 -1.71826613e-01 -2.27040207e-01\n",
      "  1.06276630e-01 -3.64192942e-01]\n",
      "New theta_0 : [ 1.37546047e-03 -8.84881589e-02  7.69723935e-02  2.15672073e-02\n",
      "  5.88778570e-02 -2.23853467e-01  3.54899906e-01  1.90965543e-04\n",
      " -2.94513994e-01  2.34181652e-01 -1.71928523e-01 -2.27061040e-01\n",
      "  1.06260856e-01 -3.64218939e-01]\n",
      "Training Error:  10.508671021251406\n",
      "====================================================================================================\n",
      "Iteration:  542\n",
      "Previous theta :  [ 1.37546047e-03 -8.84881589e-02  7.69723935e-02  2.15672073e-02\n",
      "  5.88778570e-02 -2.23853467e-01  3.54899906e-01  1.90965543e-04\n",
      " -2.94513994e-01  2.34181652e-01 -1.71928523e-01 -2.27061040e-01\n",
      "  1.06260856e-01 -3.64218939e-01]\n",
      "New theta_0 : [ 1.36978864e-03 -8.85256523e-02  7.70663981e-02  2.15988614e-02\n",
      "  5.88769648e-02 -2.24076444e-01  3.54836501e-01  1.98413063e-04\n",
      " -2.94752705e-01  2.34340962e-01 -1.72030412e-01 -2.27081723e-01\n",
      "  1.06245213e-01 -3.64244690e-01]\n",
      "Training Error:  10.508522590780034\n",
      "====================================================================================================\n",
      "Iteration:  543\n",
      "Previous theta :  [ 1.36978864e-03 -8.85256523e-02  7.70663981e-02  2.15988614e-02\n",
      "  5.88769648e-02 -2.24076444e-01  3.54836501e-01  1.98413063e-04\n",
      " -2.94752705e-01  2.34340962e-01 -1.72030412e-01 -2.27081723e-01\n",
      "  1.06245213e-01 -3.64244690e-01]\n",
      "New theta_0 : [ 1.36415670e-03 -8.85629237e-02  7.71598704e-02  2.16306170e-02\n",
      "  5.88760450e-02 -2.24297945e-01  3.54773582e-01  2.05837561e-04\n",
      " -2.94989736e-01  2.34499711e-01 -1.72132280e-01 -2.27102257e-01\n",
      "  1.06229700e-01 -3.64270199e-01]\n",
      "Training Error:  10.508375868401329\n",
      "====================================================================================================\n",
      "Iteration:  544\n",
      "Previous theta :  [ 1.36415670e-03 -8.85629237e-02  7.71598704e-02  2.16306170e-02\n",
      "  5.88760450e-02 -2.24297945e-01  3.54773582e-01  2.05837561e-04\n",
      " -2.94989736e-01  2.34499711e-01 -1.72132280e-01 -2.27102257e-01\n",
      "  1.06229700e-01 -3.64270199e-01]\n",
      "New theta_0 : [ 1.35856436e-03 -8.85999745e-02  7.72528135e-02  2.16624722e-02\n",
      "  5.88750979e-02 -2.24517979e-01  3.54711144e-01  2.13238939e-04\n",
      " -2.95225098e-01  2.34657902e-01 -1.72234123e-01 -2.27122645e-01\n",
      "  1.06214316e-01 -3.64295467e-01]\n",
      "Training Error:  10.508230831941201\n",
      "====================================================================================================\n",
      "Iteration:  545\n",
      "Previous theta :  [ 1.35856436e-03 -8.85999745e-02  7.72528135e-02  2.16624722e-02\n",
      "  5.88750979e-02 -2.24517979e-01  3.54711144e-01  2.13238939e-04\n",
      " -2.95225098e-01  2.34657902e-01 -1.72234123e-01 -2.27122645e-01\n",
      "  1.06214316e-01 -3.64295467e-01]\n",
      "New theta_0 : [ 1.35301136e-03 -8.86368063e-02  7.73452305e-02  2.16944247e-02\n",
      "  5.88741237e-02 -2.24736556e-01  3.54649183e-01  2.20617105e-04\n",
      " -2.95458805e-01  2.34815537e-01 -1.72335941e-01 -2.27142887e-01\n",
      "  1.06199060e-01 -3.64320499e-01]\n",
      "Training Error:  10.508087459531296\n",
      "====================================================================================================\n",
      "Iteration:  546\n",
      "Previous theta :  [ 1.35301136e-03 -8.86368063e-02  7.73452305e-02  2.16944247e-02\n",
      "  5.88741237e-02 -2.24736556e-01  3.54649183e-01  2.20617105e-04\n",
      " -2.95458805e-01  2.34815537e-01 -1.72335941e-01 -2.27142887e-01\n",
      "  1.06199060e-01 -3.64320499e-01]\n",
      "New theta_0 : [ 1.34749740e-03 -8.86734203e-02  7.74371244e-02  2.17264725e-02\n",
      "  5.88731227e-02 -2.24953685e-01  3.54587694e-01  2.27971973e-04\n",
      " -2.95690867e-01  2.34972620e-01 -1.72437731e-01 -2.27162984e-01\n",
      "  1.06183930e-01 -3.64345296e-01]\n",
      "Training Error:  10.507945729604645\n",
      "====================================================================================================\n",
      "Iteration:  547\n",
      "Previous theta :  [ 1.34749740e-03 -8.86734203e-02  7.74371244e-02  2.17264725e-02\n",
      "  5.88731227e-02 -2.24953685e-01  3.54587694e-01  2.27971973e-04\n",
      " -2.95690867e-01  2.34972620e-01 -1.72437731e-01 -2.27162984e-01\n",
      "  1.06183930e-01 -3.64345296e-01]\n",
      "New theta_0 : [ 1.34202220e-03 -8.87098182e-02  7.75284981e-02  2.17586135e-02\n",
      "  5.88720951e-02 -2.25169378e-01  3.54526674e-01  2.35303465e-04\n",
      " -2.95921297e-01  2.35129153e-01 -1.72539491e-01 -2.27182938e-01\n",
      "  1.06168927e-01 -3.64369860e-01]\n",
      "Training Error:  10.507805620891373\n",
      "====================================================================================================\n",
      "Iteration:  548\n",
      "Previous theta :  [ 1.34202220e-03 -8.87098182e-02  7.75284981e-02  2.17586135e-02\n",
      "  5.88720951e-02 -2.25169378e-01  3.54526674e-01  2.35303465e-04\n",
      " -2.95921297e-01  2.35129153e-01 -1.72539491e-01 -2.27182938e-01\n",
      "  1.06168927e-01 -3.64369860e-01]\n",
      "New theta_0 : [ 1.33658550e-03 -8.87460013e-02  7.76193547e-02  2.17908455e-02\n",
      "  5.88710414e-02 -2.25383642e-01  3.54466119e-01  2.42611508e-04\n",
      " -2.96150106e-01  2.35285139e-01 -1.72641221e-01 -2.27202750e-01\n",
      "  1.06154048e-01 -3.64394195e-01]\n",
      "Training Error:  10.507667112414502\n",
      "====================================================================================================\n",
      "Iteration:  549\n",
      "Previous theta :  [ 1.33658550e-03 -8.87460013e-02  7.76193547e-02  2.17908455e-02\n",
      "  5.88710414e-02 -2.25383642e-01  3.54466119e-01  2.42611508e-04\n",
      " -2.96150106e-01  2.35285139e-01 -1.72641221e-01 -2.27202750e-01\n",
      "  1.06154048e-01 -3.64394195e-01]\n",
      "New theta_0 : [ 1.33118702e-03 -8.87819709e-02  7.77096972e-02  2.18231667e-02\n",
      "  5.88699617e-02 -2.25596488e-01  3.54406024e-01  2.49896034e-04\n",
      " -2.96377306e-01  2.35440580e-01 -1.72742917e-01 -2.27222422e-01\n",
      "  1.06139293e-01 -3.64418303e-01]\n",
      "Training Error:  10.507530183485768\n",
      "====================================================================================================\n",
      "Iteration:  550\n",
      "Previous theta :  [ 1.33118702e-03 -8.87819709e-02  7.77096972e-02  2.18231667e-02\n",
      "  5.88699617e-02 -2.25596488e-01  3.54406024e-01  2.49896034e-04\n",
      " -2.96377306e-01  2.35440580e-01 -1.72742917e-01 -2.27222422e-01\n",
      "  1.06139293e-01 -3.64418303e-01]\n",
      "New theta_0 : [ 1.32582648e-03 -8.88177286e-02  7.77995284e-02  2.18555750e-02\n",
      "  5.88688563e-02 -2.25807925e-01  3.54346386e-01  2.57156981e-04\n",
      " -2.96602909e-01  2.35595480e-01 -1.72844579e-01 -2.27241954e-01\n",
      "  1.06124660e-01 -3.64442186e-01]\n",
      "Training Error:  10.507394813701538\n",
      "====================================================================================================\n",
      "Iteration:  551\n",
      "Previous theta :  [ 1.32582648e-03 -8.88177286e-02  7.77995284e-02  2.18555750e-02\n",
      "  5.88688563e-02 -2.25807925e-01  3.54346386e-01  2.57156981e-04\n",
      " -2.96602909e-01  2.35595480e-01 -1.72844579e-01 -2.27241954e-01\n",
      "  1.06124660e-01 -3.64442186e-01]\n",
      "New theta_0 : [ 1.32050361e-03 -8.88532756e-02  7.78888513e-02  2.18880684e-02\n",
      "  5.88677254e-02 -2.26017963e-01  3.54287200e-01  2.64394295e-04\n",
      " -2.96826925e-01  2.35749840e-01 -1.72946204e-01 -2.27261348e-01\n",
      "  1.06110149e-01 -3.64465847e-01]\n",
      "Training Error:  10.507260982938762\n",
      "====================================================================================================\n",
      "Iteration:  552\n",
      "Previous theta :  [ 1.32050361e-03 -8.88532756e-02  7.78888513e-02  2.18880684e-02\n",
      "  5.88677254e-02 -2.26017963e-01  3.54287200e-01  2.64394295e-04\n",
      " -2.96826925e-01  2.35749840e-01 -1.72946204e-01 -2.27261348e-01\n",
      "  1.06110149e-01 -3.64465847e-01]\n",
      "New theta_0 : [ 1.31521816e-03 -8.88886134e-02  7.79776690e-02  2.19206450e-02\n",
      "  5.88665695e-02 -2.26226611e-01  3.54228463e-01  2.71607923e-04\n",
      " -2.97049367e-01  2.35903665e-01 -1.73047791e-01 -2.27280605e-01\n",
      "  1.06095758e-01 -3.64489288e-01]\n",
      "Training Error:  10.507128671351003\n",
      "====================================================================================================\n",
      "Iteration:  553\n",
      "Previous theta :  [ 1.31521816e-03 -8.88886134e-02  7.79776690e-02  2.19206450e-02\n",
      "  5.88665695e-02 -2.26226611e-01  3.54228463e-01  2.71607923e-04\n",
      " -2.97049367e-01  2.35903665e-01 -1.73047791e-01 -2.27280605e-01\n",
      "  1.06095758e-01 -3.64489288e-01]\n",
      "New theta_0 : [ 1.30996984e-03 -8.89237434e-02  7.80659843e-02  2.19533028e-02\n",
      "  5.88653887e-02 -2.26433879e-01  3.54170170e-01  2.78797822e-04\n",
      " -2.97270245e-01  2.36056955e-01 -1.73149338e-01 -2.27299726e-01\n",
      "  1.06081488e-01 -3.64512512e-01]\n",
      "Training Error:  10.506997859364505\n",
      "====================================================================================================\n",
      "Iteration:  554\n",
      "Previous theta :  [ 1.30996984e-03 -8.89237434e-02  7.80659843e-02  2.19533028e-02\n",
      "  5.88653887e-02 -2.26433879e-01  3.54170170e-01  2.78797822e-04\n",
      " -2.97270245e-01  2.36056955e-01 -1.73149338e-01 -2.27299726e-01\n",
      "  1.06081488e-01 -3.64512512e-01]\n",
      "New theta_0 : [ 1.30475840e-03 -8.89586669e-02  7.81538000e-02  2.19860399e-02\n",
      "  5.88641832e-02 -2.26639776e-01  3.54112318e-01  2.85963950e-04\n",
      " -2.97489571e-01  2.36209715e-01 -1.73250844e-01 -2.27318712e-01\n",
      "  1.06067335e-01 -3.64535521e-01]\n",
      "Training Error:  10.506868527674328\n",
      "====================================================================================================\n",
      "Iteration:  555\n",
      "Previous theta :  [ 1.30475840e-03 -8.89586669e-02  7.81538000e-02  2.19860399e-02\n",
      "  5.88641832e-02 -2.26639776e-01  3.54112318e-01  2.85963950e-04\n",
      " -2.97489571e-01  2.36209715e-01 -1.73250844e-01 -2.27318712e-01\n",
      "  1.06067335e-01 -3.64535521e-01]\n",
      "New theta_0 : [ 1.29958357e-03 -8.89933852e-02  7.82411192e-02  2.20188545e-02\n",
      "  5.88629534e-02 -2.26844310e-01  3.54054904e-01  2.93106273e-04\n",
      " -2.97707356e-01  2.36361946e-01 -1.73352307e-01 -2.27337565e-01\n",
      "  1.06053301e-01 -3.64558317e-01]\n",
      "Training Error:  10.506740657240545\n",
      "====================================================================================================\n",
      "Iteration:  556\n",
      "Previous theta :  [ 1.29958357e-03 -8.89933852e-02  7.82411192e-02  2.20188545e-02\n",
      "  5.88629534e-02 -2.26844310e-01  3.54054904e-01  2.93106273e-04\n",
      " -2.97707356e-01  2.36361946e-01 -1.73352307e-01 -2.27337565e-01\n",
      "  1.06053301e-01 -3.64558317e-01]\n",
      "New theta_0 : [ 1.29444509e-03 -8.90278997e-02  7.83279447e-02  2.20517446e-02\n",
      "  5.88616996e-02 -2.27047492e-01  3.53997922e-01  3.00224761e-04\n",
      " -2.97923611e-01  2.36513651e-01 -1.73453725e-01 -2.27356286e-01\n",
      "  1.06039383e-01 -3.64580903e-01]\n",
      "Training Error:  10.506614229284478\n",
      "====================================================================================================\n",
      "Iteration:  557\n",
      "Previous theta :  [ 1.29444509e-03 -8.90278997e-02  7.83279447e-02  2.20517446e-02\n",
      "  5.88616996e-02 -2.27047492e-01  3.53997922e-01  3.00224761e-04\n",
      " -2.97923611e-01  2.36513651e-01 -1.73453725e-01 -2.27356286e-01\n",
      "  1.06039383e-01 -3.64580903e-01]\n",
      "New theta_0 : [ 1.28934271e-03 -8.90622118e-02  7.84142793e-02  2.20847083e-02\n",
      "  5.88604219e-02 -2.27249330e-01  3.53941370e-01  3.07319388e-04\n",
      " -2.98138347e-01  2.36664833e-01 -1.73555097e-01 -2.27374876e-01\n",
      "  1.06025581e-01 -3.64603280e-01]\n",
      "Training Error:  10.506489225285003\n",
      "====================================================================================================\n",
      "Iteration:  558\n",
      "Previous theta :  [ 1.28934271e-03 -8.90622118e-02  7.84142793e-02  2.20847083e-02\n",
      "  5.88604219e-02 -2.27249330e-01  3.53941370e-01  3.07319388e-04\n",
      " -2.98138347e-01  2.36664833e-01 -1.73555097e-01 -2.27374876e-01\n",
      "  1.06025581e-01 -3.64603280e-01]\n",
      "New theta_0 : [ 1.28427616e-03 -8.90963227e-02  7.85001260e-02  2.21177440e-02\n",
      "  5.88591206e-02 -2.27449834e-01  3.53885244e-01  3.14390133e-04\n",
      " -2.98351574e-01  2.36815494e-01 -1.73656422e-01 -2.27393335e-01\n",
      "  1.06011894e-01 -3.64625452e-01]\n",
      "Training Error:  10.506365626974898\n",
      "====================================================================================================\n",
      "Iteration:  559\n",
      "Previous theta :  [ 1.28427616e-03 -8.90963227e-02  7.85001260e-02  2.21177440e-02\n",
      "  5.88591206e-02 -2.27449834e-01  3.53885244e-01  3.14390133e-04\n",
      " -2.98351574e-01  2.36815494e-01 -1.73656422e-01 -2.27393335e-01\n",
      "  1.06011894e-01 -3.64625452e-01]\n",
      "New theta_0 : [ 1.27924520e-03 -8.91302338e-02  7.85854875e-02  2.21508498e-02\n",
      "  5.88577960e-02 -2.27649011e-01  3.53829540e-01  3.21436980e-04\n",
      " -2.98563304e-01  2.36965636e-01 -1.73757696e-01 -2.27411666e-01\n",
      "  1.05998320e-01 -3.64647420e-01]\n",
      "Training Error:  10.506243416337258\n",
      "====================================================================================================\n",
      "Iteration:  560\n",
      "Previous theta :  [ 1.27924520e-03 -8.91302338e-02  7.85854875e-02  2.21508498e-02\n",
      "  5.88577960e-02 -2.27649011e-01  3.53829540e-01  3.21436980e-04\n",
      " -2.98563304e-01  2.36965636e-01 -1.73757696e-01 -2.27411666e-01\n",
      "  1.05998320e-01 -3.64647420e-01]\n",
      "New theta_0 : [ 1.27424956e-03 -8.91639464e-02  7.86703667e-02  2.21840239e-02\n",
      "  5.88564484e-02 -2.27846872e-01  3.53774255e-01  3.28459917e-04\n",
      " -2.98773547e-01  2.37115263e-01 -1.73858920e-01 -2.27429868e-01\n",
      "  1.05984860e-01 -3.64669187e-01]\n",
      "Training Error:  10.50612257560194\n",
      "====================================================================================================\n",
      "Iteration:  561\n",
      "Previous theta :  [ 1.27424956e-03 -8.91639464e-02  7.86703667e-02  2.21840239e-02\n",
      "  5.88564484e-02 -2.27846872e-01  3.53774255e-01  3.28459917e-04\n",
      " -2.98773547e-01  2.37115263e-01 -1.73858920e-01 -2.27429868e-01\n",
      "  1.05984860e-01 -3.64669187e-01]\n",
      "New theta_0 : [ 1.26928900e-03 -8.91974618e-02  7.87547664e-02  2.22172644e-02\n",
      "  5.88550780e-02 -2.28043425e-01  3.53719384e-01  3.35458936e-04\n",
      " -2.98982314e-01  2.37264377e-01 -1.73960091e-01 -2.27447944e-01\n",
      "  1.05971511e-01 -3.64690755e-01]\n",
      "Training Error:  10.506003087242084\n",
      "====================================================================================================\n",
      "Iteration:  562\n",
      "Previous theta :  [ 1.26928900e-03 -8.91974618e-02  7.87547664e-02  2.22172644e-02\n",
      "  5.88550780e-02 -2.28043425e-01  3.53719384e-01  3.35458936e-04\n",
      " -2.98982314e-01  2.37264377e-01 -1.73960091e-01 -2.27447944e-01\n",
      "  1.05971511e-01 -3.64690755e-01]\n",
      "New theta_0 : [ 1.26436327e-03 -8.92307813e-02  7.88386894e-02  2.22505698e-02\n",
      "  5.88536850e-02 -2.28238679e-01  3.53664925e-01  3.42434034e-04\n",
      " -2.99189616e-01  2.37412980e-01 -1.74061209e-01 -2.27465895e-01\n",
      "  1.05958274e-01 -3.64712125e-01]\n",
      "Training Error:  10.505884933970655\n",
      "====================================================================================================\n",
      "Iteration:  563\n",
      "Previous theta :  [ 1.26436327e-03 -8.92307813e-02  7.88386894e-02  2.22505698e-02\n",
      "  5.88536850e-02 -2.28238679e-01  3.53664925e-01  3.42434034e-04\n",
      " -2.99189616e-01  2.37412980e-01 -1.74061209e-01 -2.27465895e-01\n",
      "  1.05958274e-01 -3.64712125e-01]\n",
      "New theta_0 : [ 1.25947212e-03 -8.92639062e-02  7.89221385e-02  2.22839383e-02\n",
      "  5.88522697e-02 -2.28432643e-01  3.53610873e-01  3.49385211e-04\n",
      " -2.99395462e-01  2.37561074e-01 -1.74162271e-01 -2.27483720e-01\n",
      "  1.05945146e-01 -3.64733301e-01]\n",
      "Training Error:  10.505768098737077\n",
      "====================================================================================================\n",
      "Iteration:  564\n",
      "Previous theta :  [ 1.25947212e-03 -8.92639062e-02  7.89221385e-02  2.22839383e-02\n",
      "  5.88522697e-02 -2.28432643e-01  3.53610873e-01  3.49385211e-04\n",
      " -2.99395462e-01  2.37561074e-01 -1.74162271e-01 -2.27483720e-01\n",
      "  1.05945146e-01 -3.64733301e-01]\n",
      "New theta_0 : [ 1.25461530e-03 -8.92968377e-02  7.90051165e-02  2.23173681e-02\n",
      "  5.88508323e-02 -2.28625325e-01  3.53557226e-01  3.56312471e-04\n",
      " -2.99599864e-01  2.37708662e-01 -1.74263276e-01 -2.27501423e-01\n",
      "  1.05932128e-01 -3.64754283e-01]\n",
      "Training Error:  10.505652564723865\n",
      "====================================================================================================\n",
      "Iteration:  565\n",
      "Previous theta :  [ 1.25461530e-03 -8.92968377e-02  7.90051165e-02  2.23173681e-02\n",
      "  5.88508323e-02 -2.28625325e-01  3.53557226e-01  3.56312471e-04\n",
      " -2.99599864e-01  2.37708662e-01 -1.74263276e-01 -2.27501423e-01\n",
      "  1.05932128e-01 -3.64754283e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 1.24979257e-03 -8.93295772e-02  7.90876261e-02  2.23508577e-02\n",
      "  5.88493731e-02 -2.28816734e-01  3.53503979e-01  3.63215823e-04\n",
      " -2.99802832e-01  2.37855747e-01 -1.74364222e-01 -2.27519002e-01\n",
      "  1.05919218e-01 -3.64775075e-01]\n",
      "Training Error:  10.505538315343344\n",
      "====================================================================================================\n",
      "Iteration:  566\n",
      "Previous theta :  [ 1.24979257e-03 -8.93295772e-02  7.90876261e-02  2.23508577e-02\n",
      "  5.88493731e-02 -2.28816734e-01  3.53503979e-01  3.63215823e-04\n",
      " -2.99802832e-01  2.37855747e-01 -1.74364222e-01 -2.27519002e-01\n",
      "  1.05919218e-01 -3.64775075e-01]\n",
      "New theta_0 : [ 0.001245   -0.08936213  0.07916967  0.02238441  0.05884789 -0.22900688\n",
      "  0.35345113  0.0003701  -0.30000438  0.23800233 -0.17446511 -0.22753646\n",
      "  0.10590642 -0.36479568]\n",
      "Training Error:  10.505425334234406\n",
      "====================================================================================================\n",
      "Iteration:  567\n",
      "Previous theta :  [ 0.001245   -0.08936213  0.07916967  0.02238441  0.05884789 -0.22900688\n",
      "  0.35345113  0.0003701  -0.30000438  0.23800233 -0.17446511 -0.22753646\n",
      "  0.10590642 -0.36479568]\n",
      "New theta_0 : [ 0.00124025 -0.08939448  0.07925125  0.02241801  0.05884639 -0.22919577\n",
      "  0.35339868  0.00037695 -0.30020451  0.23814842 -0.17456593 -0.2275538\n",
      "  0.10589372 -0.36481609]\n",
      "Training Error:  10.505313605259296\n",
      "====================================================================================================\n",
      "Iteration:  568\n",
      "Previous theta :  [ 0.00124025 -0.08939448  0.07925125  0.02241801  0.05884639 -0.22919577\n",
      "  0.35339868  0.00037695 -0.30020451  0.23814842 -0.17456593 -0.2275538\n",
      "  0.10589372 -0.36481609]\n",
      "New theta_0 : [ 0.00123553 -0.08942666  0.07933237  0.02245167  0.05884487 -0.22938341\n",
      "  0.35334661  0.00038378 -0.30040323  0.238294   -0.1746667  -0.22757102\n",
      "  0.10588113 -0.36483633]\n",
      "Training Error:  10.505203112500473\n",
      "====================================================================================================\n",
      "Iteration:  569\n",
      "Previous theta :  [ 0.00123553 -0.08942666  0.07933237  0.02245167  0.05884487 -0.22938341\n",
      "  0.35334661  0.00038378 -0.30040323  0.238294   -0.1746667  -0.22757102\n",
      "  0.10588113 -0.36483633]\n",
      "New theta_0 : [ 0.00123084 -0.08945864  0.07941304  0.02248538  0.05884332 -0.22956981\n",
      "  0.35329493  0.00039059 -0.30060056  0.2384391  -0.1747674  -0.22758812\n",
      "  0.10586864 -0.36485638]\n",
      "Training Error:  10.50509384025749\n",
      "====================================================================================================\n",
      "Iteration:  570\n",
      "Previous theta :  [ 0.00123084 -0.08945864  0.07941304  0.02248538  0.05884332 -0.22956981\n",
      "  0.35329493  0.00039059 -0.30060056  0.2384391  -0.1747674  -0.22758812\n",
      "  0.10586864 -0.36485638]\n",
      "New theta_0 : [ 0.00122618 -0.08949044  0.07949324  0.02251914  0.05884176 -0.22975498\n",
      "  0.35324364  0.00039737 -0.30079651  0.2385837  -0.17486803 -0.2276051\n",
      "  0.10585626 -0.36487624]\n",
      "Training Error:  10.504985773043945\n",
      "====================================================================================================\n",
      "Iteration:  571\n",
      "Previous theta :  [ 0.00122618 -0.08949044  0.07949324  0.02251914  0.05884176 -0.22975498\n",
      "  0.35324364  0.00039737 -0.30079651  0.2385837  -0.17486803 -0.2276051\n",
      "  0.10585626 -0.36487624]\n",
      "New theta_0 : [ 0.00122156 -0.08952205  0.079573    0.02255296  0.05884017 -0.22993893\n",
      "  0.35319273  0.00040413 -0.30099109  0.23872782 -0.17496859 -0.22762197\n",
      "  0.10584399 -0.36489593]\n",
      "Training Error:  10.50487889558444\n",
      "====================================================================================================\n",
      "Iteration:  572\n",
      "Previous theta :  [ 0.00122156 -0.08952205  0.079573    0.02255296  0.05884017 -0.22993893\n",
      "  0.35319273  0.00040413 -0.30099109  0.23872782 -0.17496859 -0.22762197\n",
      "  0.10584399 -0.36489593]\n",
      "New theta_0 : [ 0.00121697 -0.08955348  0.07965231  0.02258682  0.05883857 -0.23012166\n",
      "  0.35314219  0.00041087 -0.3011843   0.23887144 -0.17506909 -0.22763872\n",
      "  0.10583181 -0.36491545]\n",
      "Training Error:  10.504773192811625\n",
      "====================================================================================================\n",
      "Iteration:  573\n",
      "Previous theta :  [ 0.00121697 -0.08955348  0.07965231  0.02258682  0.05883857 -0.23012166\n",
      "  0.35314219  0.00041087 -0.3011843   0.23887144 -0.17506909 -0.22763872\n",
      "  0.10583181 -0.36491545]\n",
      "New theta_0 : [ 0.00121241 -0.08958473  0.07973117  0.02262073  0.05883694 -0.23030319\n",
      "  0.35309203  0.00041758 -0.30137615  0.23901458 -0.17516952 -0.22765536\n",
      "  0.10581973 -0.36493478]\n",
      "Training Error:  10.504668649863255\n",
      "====================================================================================================\n",
      "Iteration:  574\n",
      "Previous theta :  [ 0.00121241 -0.08958473  0.07973117  0.02262073  0.05883694 -0.23030319\n",
      "  0.35309203  0.00041758 -0.30137615  0.23901458 -0.17516952 -0.22765536\n",
      "  0.10581973 -0.36493478]\n",
      "New theta_0 : [ 0.00120788 -0.08961579  0.07980959  0.02265468  0.0588353  -0.23048352\n",
      "  0.35304224  0.00042427 -0.30156666  0.23915724 -0.17526988 -0.22767188\n",
      "  0.10580776 -0.36495395]\n",
      "Training Error:  10.504565252079306\n",
      "====================================================================================================\n",
      "Iteration:  575\n",
      "Previous theta :  [ 0.00120788 -0.08961579  0.07980959  0.02265468  0.0588353  -0.23048352\n",
      "  0.35304224  0.00042427 -0.30156666  0.23915724 -0.17526988 -0.22767188\n",
      "  0.10580776 -0.36495395]\n",
      "New theta_0 : [ 0.00120339 -0.08964668  0.07988756  0.02268868  0.05883363 -0.23066266\n",
      "  0.35299282  0.00043094 -0.30175584  0.23929942 -0.17537016 -0.22768829\n",
      "  0.10579589 -0.36497294]\n",
      "Training Error:  10.504462984999114\n",
      "====================================================================================================\n",
      "Iteration:  576\n",
      "Previous theta :  [ 0.00120339 -0.08964668  0.07988756  0.02268868  0.05883363 -0.23066266\n",
      "  0.35299282  0.00043094 -0.30175584  0.23929942 -0.17537016 -0.22768829\n",
      "  0.10579589 -0.36497294]\n",
      "New theta_0 : [ 0.00119892 -0.08967739  0.0799651   0.02272272  0.05883195 -0.23084062\n",
      "  0.35294376  0.00043758 -0.30194369  0.23944112 -0.17547038 -0.22770459\n",
      "  0.10578411 -0.36499177]\n",
      "Training Error:  10.504361834358576\n",
      "====================================================================================================\n",
      "Iteration:  577\n",
      "Previous theta :  [ 0.00119892 -0.08967739  0.0799651   0.02272272  0.05883195 -0.23084062\n",
      "  0.35294376  0.00043758 -0.30194369  0.23944112 -0.17547038 -0.22770459\n",
      "  0.10578411 -0.36499177]\n",
      "New theta_0 : [ 0.00119449 -0.08970792  0.0800422   0.0227568   0.05883025 -0.23101741\n",
      "  0.35289506  0.0004442  -0.30213023  0.23958235 -0.17557051 -0.22772078\n",
      "  0.10577243 -0.36501042]\n",
      "Training Error:  10.504261786087383\n",
      "====================================================================================================\n",
      "Iteration:  578\n",
      "Previous theta :  [ 0.00119449 -0.08970792  0.0800422   0.0227568   0.05883025 -0.23101741\n",
      "  0.35289506  0.0004442  -0.30213023  0.23958235 -0.17557051 -0.22772078\n",
      "  0.10577243 -0.36501042]\n",
      "New theta_0 : [ 0.00119009 -0.08973827  0.08011886  0.02279092  0.05882853 -0.23119303\n",
      "  0.35284673  0.00045079 -0.30231546  0.2397231  -0.17567058 -0.22773686\n",
      "  0.10576085 -0.36502891]\n",
      "Training Error:  10.504162826306285\n",
      "====================================================================================================\n",
      "Iteration:  579\n",
      "Previous theta :  [ 0.00119009 -0.08973827  0.08011886  0.02279092  0.05882853 -0.23119303\n",
      "  0.35284673  0.00045079 -0.30231546  0.2397231  -0.17567058 -0.22773686\n",
      "  0.10576085 -0.36502891]\n",
      "New theta_0 : [ 0.00118572 -0.08976845  0.0801951   0.02282508  0.05882678 -0.23136749\n",
      "  0.35279875  0.00045737 -0.30249939  0.23986338 -0.17577056 -0.22775282\n",
      "  0.10574937 -0.36504724]\n",
      "Training Error:  10.504064941324405\n",
      "====================================================================================================\n",
      "Iteration:  580\n",
      "Previous theta :  [ 0.00118572 -0.08976845  0.0801951   0.02282508  0.05882678 -0.23136749\n",
      "  0.35279875  0.00045737 -0.30249939  0.23986338 -0.17577056 -0.22775282\n",
      "  0.10574937 -0.36504724]\n",
      "New theta_0 : [ 0.00118138 -0.08979845  0.0802709   0.02285928  0.05882503 -0.2315408\n",
      "  0.35275112  0.00046391 -0.30268203  0.24000319 -0.17587047 -0.22776869\n",
      "  0.10573798 -0.36506541]\n",
      "Training Error:  10.50396811763659\n",
      "====================================================================================================\n",
      "Iteration:  581\n",
      "Previous theta :  [ 0.00118138 -0.08979845  0.0802709   0.02285928  0.05882503 -0.2315408\n",
      "  0.35275112  0.00046391 -0.30268203  0.24000319 -0.17587047 -0.22776869\n",
      "  0.10573798 -0.36506541]\n",
      "New theta_0 : [ 0.00117707 -0.08982829  0.08034628  0.02289351  0.05882325 -0.23171297\n",
      "  0.35270384  0.00047044 -0.30286339  0.24014253 -0.17597029 -0.22778444\n",
      "  0.10572669 -0.36508341]\n",
      "Training Error:  10.503872341920799\n",
      "====================================================================================================\n",
      "Iteration:  582\n",
      "Previous theta :  [ 0.00117707 -0.08982829  0.08034628  0.02289351  0.05882325 -0.23171297\n",
      "  0.35270384  0.00047044 -0.30286339  0.24014253 -0.17597029 -0.22778444\n",
      "  0.10572669 -0.36508341]\n",
      "New theta_0 : [ 0.00117279 -0.08985795  0.08042124  0.02292778  0.05882145 -0.231884\n",
      "  0.3526569   0.00047694 -0.30304349  0.24028141 -0.17607004 -0.22780009\n",
      "  0.10571549 -0.36510126]\n",
      "Training Error:  10.503777601035527\n",
      "====================================================================================================\n",
      "Iteration:  583\n",
      "Previous theta :  [ 0.00117279 -0.08985795  0.08042124  0.02292778  0.05882145 -0.231884\n",
      "  0.3526569   0.00047694 -0.30304349  0.24028141 -0.17607004 -0.22780009\n",
      "  0.10571549 -0.36510126]\n",
      "New theta_0 : [ 0.00116854 -0.08988743  0.08049578  0.02296208  0.05881964 -0.23205391\n",
      "  0.35261031  0.00048342 -0.30322232  0.24041982 -0.1761697  -0.22781563\n",
      "  0.10570439 -0.36511894]\n",
      "Training Error:  10.503683882017267\n",
      "====================================================================================================\n",
      "Iteration:  584\n",
      "Previous theta :  [ 0.00116854 -0.08988743  0.08049578  0.02296208  0.05881964 -0.23205391\n",
      "  0.35261031  0.00048342 -0.30322232  0.24041982 -0.1761697  -0.22781563\n",
      "  0.10570439 -0.36511894]\n",
      "New theta_0 : [ 0.00116433 -0.08991675  0.08056989  0.0229964   0.05881781 -0.23222269\n",
      "  0.35256406  0.00048987 -0.30339991  0.24055778 -0.17626928 -0.22783107\n",
      "  0.10569338 -0.36513648]\n",
      "Training Error:  10.503591172078004\n",
      "====================================================================================================\n",
      "Iteration:  585\n",
      "Previous theta :  [ 0.00116433 -0.08991675  0.08056989  0.0229964   0.05881781 -0.23222269\n",
      "  0.35256406  0.00048987 -0.30339991  0.24055778 -0.17626928 -0.22783107\n",
      "  0.10569338 -0.36513648]\n",
      "New theta_0 : [ 0.00116014 -0.08994591  0.0806436   0.02303076  0.05881596 -0.23239037\n",
      "  0.35251815  0.0004963  -0.30357625  0.24069527 -0.17636878 -0.22784641\n",
      "  0.10568245 -0.36515386]\n",
      "Training Error:  10.503499458602754\n",
      "====================================================================================================\n",
      "Iteration:  586\n",
      "Previous theta :  [ 0.00116014 -0.08994591  0.0806436   0.02303076  0.05881596 -0.23239037\n",
      "  0.35251815  0.0004963  -0.30357625  0.24069527 -0.17636878 -0.22784641\n",
      "  0.10568245 -0.36515386]\n",
      "New theta_0 : [ 0.00115598 -0.08997489  0.08071688  0.02306515  0.0588141  -0.23255694\n",
      "  0.35247258  0.00050271 -0.30375135  0.24083231 -0.17646819 -0.22786164\n",
      "  0.10567163 -0.36517108]\n",
      "Training Error:  10.503408729147145\n",
      "====================================================================================================\n",
      "Iteration:  587\n",
      "Previous theta :  [ 0.00115598 -0.08997489  0.08071688  0.02306515  0.0588141  -0.23255694\n",
      "  0.35247258  0.00050271 -0.30375135  0.24083231 -0.17646819 -0.22786164\n",
      "  0.10567163 -0.36517108]\n",
      "New theta_0 : [ 0.00115184 -0.09000371  0.08078976  0.02309957  0.05881222 -0.23272241\n",
      "  0.35242733  0.0005091  -0.30392523  0.24096889 -0.17656751 -0.22787677\n",
      "  0.10566089 -0.36518816]\n",
      "Training Error:  10.503318971434998\n",
      "====================================================================================================\n",
      "Iteration:  588\n",
      "Previous theta :  [ 0.00115184 -0.09000371  0.08078976  0.02309957  0.05881222 -0.23272241\n",
      "  0.35242733  0.0005091  -0.30392523  0.24096889 -0.17656751 -0.22787677\n",
      "  0.10566089 -0.36518816]\n",
      "New theta_0 : [ 0.00114774 -0.09003236  0.08086223  0.02313401  0.05881032 -0.23288679\n",
      "  0.35238242  0.00051546 -0.3040979   0.24110503 -0.17666675 -0.2278918\n",
      "  0.10565024 -0.36520509]\n",
      "Training Error:  10.503230173355984\n",
      "====================================================================================================\n",
      "Iteration:  589\n",
      "Previous theta :  [ 0.00114774 -0.09003236  0.08086223  0.02313401  0.05881032 -0.23288679\n",
      "  0.35238242  0.00051546 -0.3040979   0.24110503 -0.17666675 -0.2278918\n",
      "  0.10565024 -0.36520509]\n",
      "New theta_0 : [ 0.00114367 -0.09006085  0.08093429  0.02316848  0.05880841 -0.23305009\n",
      "  0.35233783  0.0005218  -0.30426935  0.24124071 -0.17676589 -0.22790673\n",
      "  0.10563968 -0.36522187]\n",
      "Training Error:  10.503142322963289\n",
      "====================================================================================================\n",
      "Iteration:  590\n",
      "Previous theta :  [ 0.00114367 -0.09006085  0.08093429  0.02316848  0.05880841 -0.23305009\n",
      "  0.35233783  0.0005218  -0.30426935  0.24124071 -0.17676589 -0.22790673\n",
      "  0.10563968 -0.36522187]\n",
      "New theta_0 : [ 0.00113962 -0.09008917  0.08100595  0.02320297  0.05880647 -0.23321232\n",
      "  0.35229357  0.00052812 -0.30443961  0.24137594 -0.17686495 -0.22792156\n",
      "  0.1056292  -0.3652385 ]\n",
      "Training Error:  10.503055408471324\n",
      "====================================================================================================\n",
      "Iteration:  591\n",
      "Previous theta :  [ 0.00113962 -0.09008917  0.08100595  0.02320297  0.05880647 -0.23321232\n",
      "  0.35229357  0.00052812 -0.30443961  0.24137594 -0.17686495 -0.22792156\n",
      "  0.1056292  -0.3652385 ]\n",
      "New theta_0 : [ 0.00113561 -0.09011733  0.08107721  0.02323748  0.05880453 -0.23337348\n",
      "  0.35224963  0.00053441 -0.30460868  0.24151072 -0.17696392 -0.22793629\n",
      "  0.10561882 -0.36525499]\n",
      "Training Error:  10.50296941825346\n",
      "====================================================================================================\n",
      "Iteration:  592\n",
      "Previous theta :  [ 0.00113561 -0.09011733  0.08107721  0.02323748  0.05880453 -0.23337348\n",
      "  0.35224963  0.00053441 -0.30460868  0.24151072 -0.17696392 -0.22793629\n",
      "  0.10561882 -0.36525499]\n",
      "New theta_0 : [ 0.00113162 -0.09014534  0.08114807  0.02327201  0.05880256 -0.23353357\n",
      "  0.352206    0.00054069 -0.30477657  0.24164507 -0.17706279 -0.22795092\n",
      "  0.10560852 -0.36527134]\n",
      "Training Error:  10.502884340839808\n",
      "====================================================================================================\n",
      "Iteration:  593\n",
      "Previous theta :  [ 0.00113162 -0.09014534  0.08114807  0.02327201  0.05880256 -0.23353357\n",
      "  0.352206    0.00054069 -0.30477657  0.24164507 -0.17706279 -0.22795092\n",
      "  0.10560852 -0.36527134]\n",
      "New theta_0 : [ 0.00112766 -0.09017318  0.08121853  0.02330657  0.05880059 -0.23369262\n",
      "  0.35216269  0.00054694 -0.30494328  0.24177896 -0.17716157 -0.22796546\n",
      "  0.10559831 -0.36528755]\n",
      "Training Error:  10.502800164915007\n",
      "====================================================================================================\n",
      "Iteration:  594\n",
      "Previous theta :  [ 0.00112766 -0.09017318  0.08121853  0.02330657  0.05880059 -0.23369262\n",
      "  0.35216269  0.00054694 -0.30494328  0.24177896 -0.17716157 -0.22796546\n",
      "  0.10559831 -0.36528755]\n",
      "New theta_0 : [ 0.00112372 -0.09020086  0.0812886   0.02334114  0.05879859 -0.23385061\n",
      "  0.3521197   0.00055316 -0.30510882  0.24191242 -0.17726026 -0.2279799\n",
      "  0.10558818 -0.36530361]\n",
      "Training Error:  10.50271687931607\n",
      "====================================================================================================\n",
      "Iteration:  595\n",
      "Previous theta :  [ 0.00112372 -0.09020086  0.0812886   0.02334114  0.05879859 -0.23385061\n",
      "  0.3521197   0.00055316 -0.30510882  0.24191242 -0.17726026 -0.2279799\n",
      "  0.10558818 -0.36530361]\n",
      "New theta_0 : [ 0.00111982 -0.09022839  0.08135828  0.02337573  0.05879658 -0.23400757\n",
      "  0.35207701  0.00055937 -0.30527321  0.24204544 -0.17735885 -0.22799424\n",
      "  0.10557814 -0.36531954]\n",
      "Training Error:  10.502634473030254\n",
      "====================================================================================================\n",
      "Iteration:  596\n",
      "Previous theta :  [ 0.00111982 -0.09022839  0.08135828  0.02337573  0.05879658 -0.23400757\n",
      "  0.35207701  0.00055937 -0.30527321  0.24204544 -0.17735885 -0.22799424\n",
      "  0.10557814 -0.36531954]\n",
      "New theta_0 : [ 0.00111594 -0.09025576  0.08142756  0.02341033  0.05879456 -0.2341635\n",
      "  0.35203464  0.00056555 -0.30543646  0.24217803 -0.17745734 -0.22800849\n",
      "  0.10556818 -0.36533533]\n",
      "Training Error:  10.502552935192943\n",
      "====================================================================================================\n",
      "Iteration:  597\n",
      "Previous theta :  [ 0.00111594 -0.09025576  0.08142756  0.02341033  0.05879456 -0.2341635\n",
      "  0.35203464  0.00056555 -0.30543646  0.24217803 -0.17745734 -0.22800849\n",
      "  0.10556818 -0.36533533]\n",
      "New theta_0 : [ 0.00111209 -0.09028297  0.08149646  0.02344496  0.05879252 -0.2343184\n",
      "  0.35199257  0.00057171 -0.30559856  0.24231017 -0.17755574 -0.22802265\n",
      "  0.10555831 -0.36535099]\n",
      "Training Error:  10.502472255085582\n",
      "====================================================================================================\n",
      "Iteration:  598\n",
      "Previous theta :  [ 0.00111209 -0.09028297  0.08149646  0.02344496  0.05879252 -0.2343184\n",
      "  0.35199257  0.00057171 -0.30559856  0.24231017 -0.17755574 -0.22802265\n",
      "  0.10555831 -0.36535099]\n",
      "New theta_0 : [ 0.00110827 -0.09031003  0.08156498  0.02347959  0.05879046 -0.23447228\n",
      "  0.3519508   0.00057785 -0.30575952  0.24244189 -0.17765404 -0.22803671\n",
      "  0.10554852 -0.36536651]\n",
      "Training Error:  10.502392422133633\n",
      "====================================================================================================\n",
      "Iteration:  599\n",
      "Previous theta :  [ 0.00110827 -0.09031003  0.08156498  0.02347959  0.05879046 -0.23447228\n",
      "  0.3519508   0.00057785 -0.30575952  0.24244189 -0.17765404 -0.22803671\n",
      "  0.10554852 -0.36536651]\n",
      "New theta_0 : [ 0.00110447 -0.09033693  0.08163311  0.02351424  0.05878839 -0.23462515\n",
      "  0.35190933  0.00058397 -0.30591937  0.24257317 -0.17775224 -0.22805068\n",
      "  0.10553881 -0.3653819 ]\n",
      "Training Error:  10.502313425904559\n",
      "====================================================================================================\n",
      "Iteration:  600\n",
      "Previous theta :  [ 0.00110447 -0.09033693  0.08163311  0.02351424  0.05878839 -0.23462515\n",
      "  0.35190933  0.00058397 -0.30591937  0.24257317 -0.17775224 -0.22805068\n",
      "  0.10553881 -0.3653819 ]\n",
      "New theta_0 : [ 0.0011007  -0.09036369  0.08170087  0.0235489   0.05878631 -0.23477701\n",
      "  0.35186816  0.00059006 -0.3060781   0.24270403 -0.17785034 -0.22806456\n",
      "  0.10552918 -0.36539716]\n",
      "Training Error:  10.50223525610584\n",
      "====================================================================================================\n",
      "Iteration:  601\n",
      "Previous theta :  [ 0.0011007  -0.09036369  0.08170087  0.0235489   0.05878631 -0.23477701\n",
      "  0.35186816  0.00059006 -0.3060781   0.24270403 -0.17785034 -0.22806456\n",
      "  0.10552918 -0.36539716]\n",
      "New theta_0 : [ 0.00109695 -0.09039029  0.08176824  0.02358358  0.05878421 -0.23492788\n",
      "  0.35182729  0.00059613 -0.30623572  0.24283446 -0.17794834 -0.22807835\n",
      "  0.10551963 -0.36541229]\n",
      "Training Error:  10.502157902583006\n",
      "====================================================================================================\n",
      "Iteration:  602\n",
      "Previous theta :  [ 0.00109695 -0.09039029  0.08176824  0.02358358  0.05878421 -0.23492788\n",
      "  0.35182729  0.00059613 -0.30623572  0.24283446 -0.17794834 -0.22807835\n",
      "  0.10551963 -0.36541229]\n",
      "New theta_0 : [ 0.00109324 -0.09041673  0.08183524  0.02361826  0.0587821  -0.23507776\n",
      "  0.3517867   0.00060218 -0.30639224  0.24296446 -0.17804624 -0.22809204\n",
      "  0.10551016 -0.36542729]\n",
      "Training Error:  10.502081355317724\n",
      "====================================================================================================\n",
      "Iteration:  603\n",
      "Previous theta :  [ 0.00109324 -0.09041673  0.08183524  0.02361826  0.0587821  -0.23507776\n",
      "  0.3517867   0.00060218 -0.30639224  0.24296446 -0.17804624 -0.22809204\n",
      "  0.10551016 -0.36542729]\n",
      "New theta_0 : [ 0.00108954 -0.09044303  0.08190187  0.02365295  0.05877997 -0.23522665\n",
      "  0.35174641  0.00060821 -0.30654766  0.24309404 -0.17814403 -0.22810565\n",
      "  0.10550077 -0.36544217]\n",
      "Training Error:  10.502005604425884\n",
      "====================================================================================================\n",
      "Iteration:  604\n",
      "Previous theta :  [ 0.00108954 -0.09044303  0.08190187  0.02365295  0.05877997 -0.23522665\n",
      "  0.35174641  0.00060821 -0.30654766  0.24309404 -0.17814403 -0.22810565\n",
      "  0.10550077 -0.36544217]\n",
      "New theta_0 : [ 0.00108588 -0.09046919  0.08196812  0.02368765  0.05877783 -0.23537456\n",
      "  0.35170641  0.00061422 -0.30670201  0.2432232  -0.17824172 -0.22811917\n",
      "  0.10549146 -0.36545692]\n",
      "Training Error:  10.501930640155722\n",
      "====================================================================================================\n",
      "Iteration:  605\n",
      "Previous theta :  [ 0.00108588 -0.09046919  0.08196812  0.02368765  0.05877783 -0.23537456\n",
      "  0.35170641  0.00061422 -0.30670201  0.2432232  -0.17824172 -0.22811917\n",
      "  0.10549146 -0.36545692]\n",
      "New theta_0 : [ 0.00108224 -0.09049519  0.08203401  0.02372235  0.05877568 -0.23552151\n",
      "  0.35166669  0.0006202  -0.30685527  0.24335193 -0.17833931 -0.2281326\n",
      "  0.10548223 -0.36547154]\n",
      "Training Error:  10.501856452885983\n",
      "====================================================================================================\n",
      "Iteration:  606\n",
      "Previous theta :  [ 0.00108224 -0.09049519  0.08203401  0.02372235  0.05877568 -0.23552151\n",
      "  0.35166669  0.0006202  -0.30685527  0.24335193 -0.17833931 -0.2281326\n",
      "  0.10548223 -0.36547154]\n",
      "New theta_0 : [ 0.00107862 -0.09052104  0.08209953  0.02375706  0.05877351 -0.23566748\n",
      "  0.35162726  0.00062617 -0.30700747  0.24348025 -0.17843679 -0.22814594\n",
      "  0.10547307 -0.36548604]\n",
      "Training Error:  10.501783033124088\n",
      "====================================================================================================\n",
      "Iteration:  607\n",
      "Previous theta :  [ 0.00107862 -0.09052104  0.08209953  0.02375706  0.05877351 -0.23566748\n",
      "  0.35162726  0.00062617 -0.30700747  0.24348025 -0.17843679 -0.22814594\n",
      "  0.10547307 -0.36548604]\n",
      "New theta_0 : [ 0.00107503 -0.09054675  0.08216469  0.02379178  0.05877133 -0.2358125\n",
      "  0.3515881   0.00063211 -0.3071586   0.24360816 -0.17853416 -0.2281592\n",
      "  0.10546399 -0.36550042]\n",
      "Training Error:  10.501710371504345\n",
      "====================================================================================================\n",
      "Iteration:  608\n",
      "Previous theta :  [ 0.00107503 -0.09054675  0.08216469  0.02379178  0.05877133 -0.2358125\n",
      "  0.3515881   0.00063211 -0.3071586   0.24360816 -0.17853416 -0.2281592\n",
      "  0.10546399 -0.36550042]\n",
      "New theta_0 : [ 0.00107147 -0.09057232  0.08222948  0.0238265   0.05876914 -0.23595657\n",
      "  0.35154923  0.00063803 -0.30730868  0.24373565 -0.17863143 -0.22817237\n",
      "  0.10545499 -0.36551468]\n",
      "Training Error:  10.501638458786177\n",
      "====================================================================================================\n",
      "Iteration:  609\n",
      "Previous theta :  [ 0.00107147 -0.09057232  0.08222948  0.0238265   0.05876914 -0.23595657\n",
      "  0.35154923  0.00063803 -0.30730868  0.24373565 -0.17863143 -0.22817237\n",
      "  0.10545499 -0.36551468]\n",
      "New theta_0 : [ 0.00106793 -0.09059774  0.08229392  0.02386122  0.05876693 -0.23609969\n",
      "  0.35151063  0.00064394 -0.30745771  0.24386272 -0.17872859 -0.22818545\n",
      "  0.10544606 -0.36552882]\n",
      "Training Error:  10.501567285852376\n",
      "====================================================================================================\n",
      "Iteration:  610\n",
      "Previous theta :  [ 0.00106793 -0.09059774  0.08229392  0.02386122  0.05876693 -0.23609969\n",
      "  0.35151063  0.00064394 -0.30745771  0.24386272 -0.17872859 -0.22818545\n",
      "  0.10544606 -0.36552882]\n",
      "New theta_0 : [ 0.00106441 -0.09062302  0.08235799  0.02389594  0.05876471 -0.23624188\n",
      "  0.35147231  0.00064982 -0.30760571  0.24398939 -0.17882564 -0.22819845\n",
      "  0.10543721 -0.36554285]\n",
      "Training Error:  10.501496843707383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  611\n",
      "Previous theta :  [ 0.00106441 -0.09062302  0.08235799  0.02389594  0.05876471 -0.23624188\n",
      "  0.35147231  0.00064982 -0.30760571  0.24398939 -0.17882564 -0.22819845\n",
      "  0.10543721 -0.36554285]\n",
      "New theta_0 : [ 0.00106092 -0.09064815  0.08242171  0.02393067  0.05876248 -0.23638313\n",
      "  0.35143425  0.00065567 -0.30775267  0.24411565 -0.17892257 -0.22821137\n",
      "  0.10542843 -0.36555675]\n",
      "Training Error:  10.501427123475592\n",
      "====================================================================================================\n",
      "Iteration:  612\n",
      "Previous theta :  [ 0.00106092 -0.09064815  0.08242171  0.02393067  0.05876248 -0.23638313\n",
      "  0.35143425  0.00065567 -0.30775267  0.24411565 -0.17892257 -0.22821137\n",
      "  0.10542843 -0.36555675]\n",
      "New theta_0 : [ 0.00105745 -0.09067315  0.08248508  0.02396539  0.05876024 -0.23652345\n",
      "  0.35139647  0.00066151 -0.30789861  0.2442415  -0.1790194  -0.2282242\n",
      "  0.10541973 -0.36557054]\n",
      "Training Error:  10.501358116399683\n",
      "====================================================================================================\n",
      "Iteration:  613\n",
      "Previous theta :  [ 0.00105745 -0.09067315  0.08248508  0.02396539  0.05876024 -0.23652345\n",
      "  0.35139647  0.00066151 -0.30789861  0.2442415  -0.1790194  -0.2282242\n",
      "  0.10541973 -0.36557054]\n",
      "New theta_0 : [ 0.00105401 -0.090698    0.0825481   0.02400011  0.05875799 -0.23666286\n",
      "  0.35135896  0.00066733 -0.30804353  0.24436694 -0.17911612 -0.22823695\n",
      "  0.1054111  -0.36558422]\n",
      "Training Error:  10.50128981383897\n",
      "====================================================================================================\n",
      "Iteration:  614\n",
      "Previous theta :  [ 0.00105401 -0.090698    0.0825481   0.02400011  0.05875799 -0.23666286\n",
      "  0.35135896  0.00066733 -0.30804353  0.24436694 -0.17911612 -0.22823695\n",
      "  0.1054111  -0.36558422]\n",
      "New theta_0 : [ 0.00105059 -0.09072272  0.08261076  0.02403483  0.05875572 -0.23680135\n",
      "  0.35132171  0.00067313 -0.30818744  0.24449198 -0.17921272 -0.22824961\n",
      "  0.10540254 -0.36559778]\n",
      "Training Error:  10.501222207267775\n",
      "====================================================================================================\n",
      "Iteration:  615\n",
      "Previous theta :  [ 0.00105059 -0.09072272  0.08261076  0.02403483  0.05875572 -0.23680135\n",
      "  0.35132171  0.00067313 -0.30818744  0.24449198 -0.17921272 -0.22824961\n",
      "  0.10540254 -0.36559778]\n",
      "New theta_0 : [ 0.0010472  -0.09074729  0.08267308  0.02406955  0.05875344 -0.23693893\n",
      "  0.35128472  0.0006789  -0.30833034  0.24461662 -0.17930921 -0.2282622\n",
      "  0.10539405 -0.36561123]\n",
      "Training Error:  10.501155288273834\n",
      "====================================================================================================\n",
      "Iteration:  616\n",
      "Previous theta :  [ 0.0010472  -0.09074729  0.08267308  0.02406955  0.05875344 -0.23693893\n",
      "  0.35128472  0.0006789  -0.30833034  0.24461662 -0.17930921 -0.2282622\n",
      "  0.10539405 -0.36561123]\n",
      "New theta_0 : [ 0.00104383 -0.09077173  0.08273506  0.02410427  0.05875115 -0.23707561\n",
      "  0.35124799  0.00068466 -0.30847225  0.24474086 -0.17940559 -0.2282747\n",
      "  0.10538563 -0.36562457]\n",
      "Training Error:  10.501089048556713\n",
      "====================================================================================================\n",
      "Iteration:  617\n",
      "Previous theta :  [ 0.00104383 -0.09077173  0.08273506  0.02410427  0.05875115 -0.23707561\n",
      "  0.35124799  0.00068466 -0.30847225  0.24474086 -0.17940559 -0.2282747\n",
      "  0.10538563 -0.36562457]\n",
      "New theta_0 : [ 0.00104048 -0.09079603  0.08279669  0.02413898  0.05874885 -0.2372114\n",
      "  0.35121152  0.0006904  -0.30861318  0.24486469 -0.17950185 -0.22828713\n",
      "  0.10537729 -0.3656378 ]\n",
      "Training Error:  10.501023479926252\n",
      "====================================================================================================\n",
      "Iteration:  618\n",
      "Previous theta :  [ 0.00104048 -0.09079603  0.08279669  0.02413898  0.05874885 -0.2372114\n",
      "  0.35121152  0.0006904  -0.30861318  0.24486469 -0.17950185 -0.22828713\n",
      "  0.10537729 -0.3656378 ]\n",
      "New theta_0 : [ 0.00103716 -0.0908202   0.08285798  0.02417368  0.05874653 -0.23734629\n",
      "  0.35117531  0.00069611 -0.30875312  0.24498814 -0.179598   -0.22829947\n",
      "  0.10536901 -0.36565093]\n",
      "Training Error:  10.500958574301038\n",
      "====================================================================================================\n",
      "Iteration:  619\n",
      "Previous theta :  [ 0.00103716 -0.0908202   0.08285798  0.02417368  0.05874653 -0.23734629\n",
      "  0.35117531  0.00069611 -0.30875312  0.24498814 -0.179598   -0.22829947\n",
      "  0.10536901 -0.36565093]\n",
      "New theta_0 : [ 0.00103386 -0.09084423  0.08291893  0.02420838  0.05874421 -0.2374803\n",
      "  0.35113936  0.00070181 -0.30889209  0.24511118 -0.17969403 -0.22831174\n",
      "  0.10536081 -0.36566394]\n",
      "Training Error:  10.500894323706882\n",
      "====================================================================================================\n",
      "Iteration:  620\n",
      "Previous theta :  [ 0.00103386 -0.09084423  0.08291893  0.02420838  0.05874421 -0.2374803\n",
      "  0.35113936  0.00070181 -0.30889209  0.24511118 -0.17969403 -0.22831174\n",
      "  0.10536081 -0.36566394]\n",
      "New theta_0 : [ 0.00103058 -0.09086813  0.08297955  0.02424307  0.05874187 -0.23761344\n",
      "  0.35110365  0.00070748 -0.30903008  0.24523383 -0.17978994 -0.22832392\n",
      "  0.10535267 -0.36567685]\n",
      "Training Error:  10.500830720275344\n",
      "====================================================================================================\n",
      "Iteration:  621\n",
      "Previous theta :  [ 0.00103058 -0.09086813  0.08297955  0.02424307  0.05874187 -0.23761344\n",
      "  0.35110365  0.00070748 -0.30903008  0.24523383 -0.17978994 -0.22832392\n",
      "  0.10535267 -0.36567685]\n",
      "New theta_0 : [ 0.00102733 -0.09089189  0.08303983  0.02427775  0.05873952 -0.2377457\n",
      "  0.3510682   0.00071314 -0.30916712  0.24535609 -0.17988573 -0.22833603\n",
      "  0.1053446  -0.36568965]\n",
      "Training Error:  10.500767756242247\n",
      "====================================================================================================\n",
      "Iteration:  622\n",
      "Previous theta :  [ 0.00102733 -0.09089189  0.08303983  0.02427775  0.05873952 -0.2377457\n",
      "  0.3510682   0.00071314 -0.30916712  0.24535609 -0.17988573 -0.22833603\n",
      "  0.1053446  -0.36568965]\n",
      "New theta_0 : [ 0.00102409 -0.09091552  0.08309978  0.02431242  0.05873716 -0.2378771\n",
      "  0.35103299  0.00071877 -0.30930321  0.24547796 -0.17998141 -0.22834806\n",
      "  0.1053366  -0.36570235]\n",
      "Training Error:  10.500705423946242\n",
      "====================================================================================================\n",
      "Iteration:  623\n",
      "Previous theta :  [ 0.00102409 -0.09091552  0.08309978  0.02431242  0.05873716 -0.2378771\n",
      "  0.35103299  0.00071877 -0.30930321  0.24547796 -0.17998141 -0.22834806\n",
      "  0.1053366  -0.36570235]\n",
      "New theta_0 : [ 0.00102088 -0.09093902  0.0831594   0.02434709  0.0587348  -0.23800764\n",
      "  0.35099803  0.00072439 -0.30943834  0.24559944 -0.18007697 -0.22836002\n",
      "  0.10532867 -0.36571495]\n",
      "Training Error:  10.500643715827373\n",
      "====================================================================================================\n",
      "Iteration:  624\n",
      "Previous theta :  [ 0.00102088 -0.09093902  0.0831594   0.02434709  0.0587348  -0.23800764\n",
      "  0.35099803  0.00072439 -0.30943834  0.24559944 -0.18007697 -0.22836002\n",
      "  0.10532867 -0.36571495]\n",
      "New theta_0 : [ 0.0010177  -0.09096239  0.08321869  0.02438174  0.05873242 -0.23813732\n",
      "  0.35096332  0.00072998 -0.30957254  0.24572054 -0.18017241 -0.2283719\n",
      "  0.1053208  -0.36572745]\n",
      "Training Error:  10.500582624425672\n",
      "====================================================================================================\n",
      "Iteration:  625\n",
      "Previous theta :  [ 0.0010177  -0.09096239  0.08321869  0.02438174  0.05873242 -0.23813732\n",
      "  0.35096332  0.00072998 -0.30957254  0.24572054 -0.18017241 -0.2283719\n",
      "  0.1053208  -0.36572745]\n",
      "New theta_0 : [ 0.00101453 -0.09098563  0.08327765  0.02441638  0.05873003 -0.23826616\n",
      "  0.35092884  0.00073556 -0.3097058   0.24584124 -0.18026772 -0.2283837\n",
      "  0.105313   -0.36573984]\n",
      "Training Error:  10.500522142379777\n",
      "====================================================================================================\n",
      "Iteration:  626\n",
      "Previous theta :  [ 0.00101453 -0.09098563  0.08327765  0.02441638  0.05873003 -0.23826616\n",
      "  0.35092884  0.00073556 -0.3097058   0.24584124 -0.18026772 -0.2283837\n",
      "  0.105313   -0.36573984]\n",
      "New theta_0 : [ 0.00101139 -0.09100874  0.08333629  0.02445101  0.05872763 -0.23839415\n",
      "  0.35089461  0.00074112 -0.30983814  0.24596157 -0.18036292 -0.22839543\n",
      "  0.10530527 -0.36575214]\n",
      "Training Error:  10.500462262425554\n",
      "====================================================================================================\n",
      "Iteration:  627\n",
      "Previous theta :  [ 0.00101139 -0.09100874  0.08333629  0.02445101  0.05872763 -0.23839415\n",
      "  0.35089461  0.00074112 -0.30983814  0.24596157 -0.18036292 -0.22839543\n",
      "  0.10530527 -0.36575214]\n",
      "New theta_0 : [ 0.00100827 -0.09103172  0.0833946   0.02448563  0.05872522 -0.2385213\n",
      "  0.35086061  0.00074666 -0.30996955  0.24608151 -0.18045799 -0.22840708\n",
      "  0.1052976  -0.36576433]\n",
      "Training Error:  10.500402977394755\n",
      "====================================================================================================\n",
      "Iteration:  628\n",
      "Previous theta :  [ 0.00100827 -0.09103172  0.0833946   0.02448563  0.05872522 -0.2385213\n",
      "  0.35086061  0.00074666 -0.30996955  0.24608151 -0.18045799 -0.22840708\n",
      "  0.1052976  -0.36576433]\n",
      "New theta_0 : [ 0.00100517 -0.09105458  0.0834526   0.02452023  0.0587228  -0.23864763\n",
      "  0.35082686  0.00075217 -0.31010005  0.24620107 -0.18055294 -0.22841866\n",
      "  0.10528999 -0.36577643]\n",
      "Training Error:  10.500344280213685\n",
      "====================================================================================================\n",
      "Iteration:  629\n",
      "Previous theta :  [ 0.00100517 -0.09105458  0.0834526   0.02452023  0.0587228  -0.23864763\n",
      "  0.35082686  0.00075217 -0.31010005  0.24620107 -0.18055294 -0.22841866\n",
      "  0.10528999 -0.36577643]\n",
      "New theta_0 : [ 0.00100209 -0.0910773   0.08351028  0.02455482  0.05872037 -0.23877313\n",
      "  0.35079333  0.00075767 -0.31022965  0.24632025 -0.18064777 -0.22843017\n",
      "  0.10528245 -0.36578843]\n",
      "Training Error:  10.500286163901903\n",
      "====================================================================================================\n",
      "Iteration:  630\n",
      "Previous theta :  [ 0.00100209 -0.0910773   0.08351028  0.02455482  0.05872037 -0.23877313\n",
      "  0.35079333  0.00075767 -0.31022965  0.24632025 -0.18064777 -0.22843017\n",
      "  0.10528245 -0.36578843]\n",
      "New theta_0 : [ 0.00099904 -0.09109991  0.08356763  0.02458939  0.05871793 -0.23889781\n",
      "  0.35076004  0.00076315 -0.31035834  0.24643905 -0.18074247 -0.2284416\n",
      "  0.10527497 -0.36580034]\n",
      "Training Error:  10.500228621570916\n",
      "====================================================================================================\n",
      "Iteration:  631\n",
      "Previous theta :  [ 0.00099904 -0.09109991  0.08356763  0.02458939  0.05871793 -0.23889781\n",
      "  0.35076004  0.00076315 -0.31035834  0.24643905 -0.18074247 -0.2284416\n",
      "  0.10527497 -0.36580034]\n",
      "New theta_0 : [ 0.000996   -0.09112238  0.08362468  0.02462395  0.05871548 -0.23902167\n",
      "  0.35072698  0.00076862 -0.31048614  0.24655748 -0.18083705 -0.22845296\n",
      "  0.10526756 -0.36581215]\n",
      "Training Error:  10.50017164642291\n",
      "====================================================================================================\n",
      "Iteration:  632\n",
      "Previous theta :  [ 0.000996   -0.09112238  0.08362468  0.02462395  0.05871548 -0.23902167\n",
      "  0.35072698  0.00076862 -0.31048614  0.24655748 -0.18083705 -0.22845296\n",
      "  0.10526756 -0.36581215]\n",
      "New theta_0 : [ 0.00099299 -0.09114474  0.08368141  0.02465849  0.05871303 -0.23914473\n",
      "  0.35069415  0.00077406 -0.31061305  0.24667553 -0.18093151 -0.22846425\n",
      "  0.10526021 -0.36582387]\n",
      "Training Error:  10.500115231749504\n",
      "====================================================================================================\n",
      "Iteration:  633\n",
      "Previous theta :  [ 0.00099299 -0.09114474  0.08368141  0.02465849  0.05871303 -0.23914473\n",
      "  0.35069415  0.00077406 -0.31061305  0.24667553 -0.18093151 -0.22846425\n",
      "  0.10526021 -0.36582387]\n",
      "New theta_0 : [ 0.00099    -0.09116697  0.08373783  0.02469302  0.05871056 -0.23926698\n",
      "  0.35066154  0.00077948 -0.31073907  0.24679321 -0.18102584 -0.22847547\n",
      "  0.10525292 -0.3658355 ]\n",
      "Training Error:  10.500059370930499\n",
      "====================================================================================================\n",
      "Iteration:  634\n",
      "Previous theta :  [ 0.00099    -0.09116697  0.08373783  0.02469302  0.05871056 -0.23926698\n",
      "  0.35066154  0.00077948 -0.31073907  0.24679321 -0.18102584 -0.22847547\n",
      "  0.10525292 -0.3658355 ]\n",
      "New theta_0 : [ 0.00098703 -0.09118907  0.08379394  0.02472752  0.05870808 -0.23938843\n",
      "  0.35062916  0.00078489 -0.31086423  0.24691051 -0.18112004 -0.22848662\n",
      "  0.10524569 -0.36584703]\n",
      "Training Error:  10.500004057432669\n",
      "====================================================================================================\n",
      "Iteration:  635\n",
      "Previous theta :  [ 0.00098703 -0.09118907  0.08379394  0.02472752  0.05870808 -0.23938843\n",
      "  0.35062916  0.00078489 -0.31086423  0.24691051 -0.18112004 -0.22848662\n",
      "  0.10524569 -0.36584703]\n",
      "New theta_0 : [ 0.00098407 -0.09121106  0.08384975  0.02476201  0.0587056  -0.23950909\n",
      "  0.35059701  0.00079028 -0.31098851  0.24702745 -0.18121411 -0.2284977\n",
      "  0.10523852 -0.36585847]\n",
      "Training Error:  10.499949284808553\n",
      "====================================================================================================\n",
      "Iteration:  636\n",
      "Previous theta :  [ 0.00098407 -0.09121106  0.08384975  0.02476201  0.0587056  -0.23950909\n",
      "  0.35059701  0.00079028 -0.31098851  0.24702745 -0.18121411 -0.2284977\n",
      "  0.10523852 -0.36585847]\n",
      "New theta_0 : [ 0.00098114 -0.09123292  0.08390525  0.02479647  0.05870311 -0.23962896\n",
      "  0.35056507  0.00079564 -0.31111193  0.24714402 -0.18130806 -0.22850871\n",
      "  0.10523142 -0.36586983]\n",
      "Training Error:  10.499895046695267\n",
      "====================================================================================================\n",
      "Iteration:  637\n",
      "Previous theta :  [ 0.00098114 -0.09123292  0.08390525  0.02479647  0.05870311 -0.23962896\n",
      "  0.35056507  0.00079564 -0.31111193  0.24714402 -0.18130806 -0.22850871\n",
      "  0.10523142 -0.36586983]\n",
      "New theta_0 : [ 0.00097823 -0.09125467  0.08396044  0.02483092  0.0587006  -0.23974806\n",
      "  0.35053336  0.00080099 -0.31123449  0.24726022 -0.18140188 -0.22851965\n",
      "  0.10522437 -0.36588109]\n",
      "Training Error:  10.49984133681334\n",
      "====================================================================================================\n",
      "Iteration:  638\n",
      "Previous theta :  [ 0.00097823 -0.09125467  0.08396044  0.02483092  0.0587006  -0.23974806\n",
      "  0.35053336  0.00080099 -0.31123449  0.24726022 -0.18140188 -0.22851965\n",
      "  0.10522437 -0.36588109]\n",
      "New theta_0 : [ 0.00097534 -0.09127629  0.08401534  0.02486535  0.05869809 -0.23986637\n",
      "  0.35050186  0.00080633 -0.3113562   0.24737605 -0.18149557 -0.22853052\n",
      "  0.10521738 -0.36589227]\n",
      "Training Error:  10.499788148965566\n",
      "====================================================================================================\n",
      "Iteration:  639\n",
      "Previous theta :  [ 0.00097534 -0.09127629  0.08401534  0.02486535  0.05869809 -0.23986637\n",
      "  0.35050186  0.00080633 -0.3113562   0.24737605 -0.18149557 -0.22853052\n",
      "  0.10521738 -0.36589227]\n",
      "New theta_0 : [ 0.00097247 -0.0912978   0.08406993  0.02489975  0.05869558 -0.23998391\n",
      "  0.35047058  0.00081164 -0.31147706  0.24749152 -0.18158913 -0.22854133\n",
      "  0.10521045 -0.36590335]\n",
      "Training Error:  10.499735477035854\n",
      "====================================================================================================\n",
      "Iteration:  640\n",
      "Previous theta :  [ 0.00097247 -0.0912978   0.08406993  0.02489975  0.05869558 -0.23998391\n",
      "  0.35047058  0.00081164 -0.31147706  0.24749152 -0.18158913 -0.22854133\n",
      "  0.10521045 -0.36590335]\n",
      "New theta_0 : [ 0.00096962 -0.09131919  0.08412423  0.02493413  0.05869305 -0.24010069\n",
      "  0.35043951  0.00081694 -0.31159709  0.24760663 -0.18168256 -0.22855206\n",
      "  0.10520358 -0.36591436]\n",
      "Training Error:  10.499683314988122\n",
      "====================================================================================================\n",
      "Iteration:  641\n",
      "Previous theta :  [ 0.00096962 -0.09131919  0.08412423  0.02493413  0.05869305 -0.24010069\n",
      "  0.35043951  0.00081694 -0.31159709  0.24760663 -0.18168256 -0.22855206\n",
      "  0.10520358 -0.36591436]\n",
      "New theta_0 : [ 0.0009668  -0.09134046  0.08417823  0.02496849  0.05869051 -0.2402167\n",
      "  0.35040866  0.00082222 -0.31171628  0.24772138 -0.18177586 -0.22856273\n",
      "  0.10519677 -0.36592527]\n",
      "Training Error:  10.499631656865192\n",
      "====================================================================================================\n",
      "Iteration:  642\n",
      "Previous theta :  [ 0.0009668  -0.09134046  0.08417823  0.02496849  0.05869051 -0.2402167\n",
      "  0.35040866  0.00082222 -0.31171628  0.24772138 -0.18177586 -0.22856273\n",
      "  0.10519677 -0.36592527]\n",
      "New theta_0 : [ 0.00096399 -0.09136161  0.08423194  0.02500283  0.05868797 -0.24033196\n",
      "  0.35037802  0.00082748 -0.31183465  0.24783576 -0.18186903 -0.22857333\n",
      "  0.10519002 -0.36593611]\n",
      "Training Error:  10.49958049678769\n",
      "====================================================================================================\n",
      "Iteration:  643\n",
      "Previous theta :  [ 0.00096399 -0.09136161  0.08423194  0.02500283  0.05868797 -0.24033196\n",
      "  0.35037802  0.00082748 -0.31183465  0.24783576 -0.18186903 -0.22857333\n",
      "  0.10519002 -0.36593611]\n",
      "New theta_0 : [ 0.00096119 -0.09138265  0.08428535  0.02503714  0.05868542 -0.24044647\n",
      "  0.35034758  0.00083272 -0.31195219  0.24794979 -0.18196207 -0.22858387\n",
      "  0.10518332 -0.36594686]\n",
      "Training Error:  10.499529828952982\n",
      "====================================================================================================\n",
      "Iteration:  644\n",
      "Previous theta :  [ 0.00096119 -0.09138265  0.08428535  0.02503714  0.05868542 -0.24044647\n",
      "  0.35034758  0.00083272 -0.31195219  0.24794979 -0.18196207 -0.22858387\n",
      "  0.10518332 -0.36594686]\n",
      "New theta_0 : [ 0.00095842 -0.09140357  0.08433847  0.02507143  0.05868286 -0.24056023\n",
      "  0.35031736  0.00083794 -0.31206892  0.24806346 -0.18205497 -0.22859434\n",
      "  0.10517668 -0.36595752]\n",
      "Training Error:  10.499479647634123\n",
      "====================================================================================================\n",
      "Iteration:  645\n",
      "Previous theta :  [ 0.00095842 -0.09140357  0.08433847  0.02507143  0.05868286 -0.24056023\n",
      "  0.35031736  0.00083794 -0.31206892  0.24806346 -0.18205497 -0.22859434\n",
      "  0.10517668 -0.36595752]\n",
      "New theta_0 : [ 0.00095567 -0.09142438  0.0843913   0.02510569  0.05868029 -0.24067325\n",
      "  0.35028734  0.00084315 -0.31218484  0.24817678 -0.18214775 -0.22860475\n",
      "  0.1051701  -0.36596811]\n",
      "Training Error:  10.499429947178799\n",
      "====================================================================================================\n",
      "Iteration:  646\n",
      "Previous theta :  [ 0.00095567 -0.09142438  0.0843913   0.02510569  0.05868029 -0.24067325\n",
      "  0.35028734  0.00084315 -0.31218484  0.24817678 -0.18214775 -0.22860475\n",
      "  0.1051701  -0.36596811]\n",
      "New theta_0 : [ 0.00095294 -0.09144508  0.08444385  0.02513993  0.05867772 -0.24078554\n",
      "  0.35025752  0.00084834 -0.31229995  0.24828974 -0.18224039 -0.22861509\n",
      "  0.10516357 -0.36597861]\n",
      "Training Error:  10.499380722008306\n",
      "====================================================================================================\n",
      "Iteration:  647\n",
      "Previous theta :  [ 0.00095294 -0.09144508  0.08444385  0.02513993  0.05867772 -0.24078554\n",
      "  0.35025752  0.00084834 -0.31229995  0.24828974 -0.18224039 -0.22861509\n",
      "  0.10516357 -0.36597861]\n",
      "New theta_0 : [ 0.00095023 -0.09146566  0.08449611  0.02517414  0.05867514 -0.24089709\n",
      "  0.35022791  0.00085352 -0.31241427  0.24840235 -0.18233289 -0.22862537\n",
      "  0.10515709 -0.36598903]\n",
      "Training Error:  10.499331966616543\n",
      "====================================================================================================\n",
      "Iteration:  648\n",
      "Previous theta :  [ 0.00095023 -0.09146566  0.08449611  0.02517414  0.05867514 -0.24089709\n",
      "  0.35022791  0.00085352 -0.31241427  0.24840235 -0.18233289 -0.22862537\n",
      "  0.10515709 -0.36598903]\n",
      "New theta_0 : [ 0.00094753 -0.09148614  0.08454809  0.02520832  0.05867255 -0.24100792\n",
      "  0.3501985   0.00085867 -0.31252779  0.24851461 -0.18242527 -0.22863558\n",
      "  0.10515068 -0.36599938]\n",
      "Training Error:  10.499283675569004\n",
      "====================================================================================================\n",
      "Iteration:  649\n",
      "Previous theta :  [ 0.00094753 -0.09148614  0.08454809  0.02520832  0.05867255 -0.24100792\n",
      "  0.3501985   0.00085867 -0.31252779  0.24851461 -0.18242527 -0.22863558\n",
      "  0.10515068 -0.36599938]\n",
      "New theta_0 : [ 0.00094485 -0.0915065   0.08459978  0.02524248  0.05866996 -0.24111803\n",
      "  0.35016929  0.00086381 -0.31264053  0.24862651 -0.18251751 -0.22864573\n",
      "  0.10514431 -0.36600964]\n",
      "Training Error:  10.499235843501795\n",
      "====================================================================================================\n",
      "Iteration:  650\n",
      "Previous theta :  [ 0.00094485 -0.0915065   0.08459978  0.02524248  0.05866996 -0.24111803\n",
      "  0.35016929  0.00086381 -0.31264053  0.24862651 -0.18251751 -0.22864573\n",
      "  0.10514431 -0.36600964]\n",
      "New theta_0 : [ 0.0009422  -0.09152675  0.0846512   0.02527661  0.05866735 -0.24122742\n",
      "  0.35014027  0.00086893 -0.31275248  0.24873807 -0.18260961 -0.22865582\n",
      "  0.105138   -0.36601983]\n",
      "Training Error:  10.499188465120662\n",
      "====================================================================================================\n",
      "Iteration:  651\n",
      "Previous theta :  [ 0.0009422  -0.09152675  0.0846512   0.02527661  0.05866735 -0.24122742\n",
      "  0.35014027  0.00086893 -0.31275248  0.24873807 -0.18260961 -0.22865582\n",
      "  0.105138   -0.36601983]\n",
      "New theta_0 : [ 0.00093956 -0.09154689  0.08470233  0.02531071  0.05866475 -0.2413361\n",
      "  0.35011145  0.00087404 -0.31286366  0.24884928 -0.18270158 -0.22866585\n",
      "  0.10513175 -0.36602994]\n",
      "Training Error:  10.49914153520004\n",
      "====================================================================================================\n",
      "Iteration:  652\n",
      "Previous theta :  [ 0.00093956 -0.09154689  0.08470233  0.02531071  0.05866475 -0.2413361\n",
      "  0.35011145  0.00087404 -0.31286366  0.24884928 -0.18270158 -0.22866585\n",
      "  0.10513175 -0.36602994]\n",
      "New theta_0 : [ 0.00093694 -0.09156692  0.08475319  0.02534478  0.05866213 -0.24144407\n",
      "  0.35008283  0.00087913 -0.31297407  0.24896015 -0.18279341 -0.22867581\n",
      "  0.10512554 -0.36603997]\n",
      "Training Error:  10.499095048582106\n",
      "====================================================================================================\n",
      "Iteration:  653\n",
      "Previous theta :  [ 0.00093694 -0.09156692  0.08475319  0.02534478  0.05866213 -0.24144407\n",
      "  0.35008283  0.00087913 -0.31297407  0.24896015 -0.18279341 -0.22867581\n",
      "  0.10512554 -0.36603997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00093433 -0.09158684  0.08480378  0.02537882  0.05865951 -0.24155134\n",
      "  0.3500544   0.0008842  -0.31308371  0.24907067 -0.1828851  -0.22868572\n",
      "  0.10511939 -0.36604993]\n",
      "Training Error:  10.499049000175841\n",
      "====================================================================================================\n",
      "Iteration:  654\n",
      "Previous theta :  [ 0.00093433 -0.09158684  0.08480378  0.02537882  0.05865951 -0.24155134\n",
      "  0.3500544   0.0008842  -0.31308371  0.24907067 -0.1828851  -0.22868572\n",
      "  0.10511939 -0.36604993]\n",
      "New theta_0 : [ 0.00093175 -0.09160665  0.08485409  0.02541283  0.05865688 -0.24165791\n",
      "  0.35002616  0.00088925 -0.3131926   0.24918085 -0.18297666 -0.22869556\n",
      "  0.10511329 -0.36605981]\n",
      "Training Error:  10.499003384956117\n",
      "====================================================================================================\n",
      "Iteration:  655\n",
      "Previous theta :  [ 0.00093175 -0.09160665  0.08485409  0.02541283  0.05865688 -0.24165791\n",
      "  0.35002616  0.00088925 -0.3131926   0.24918085 -0.18297666 -0.22869556\n",
      "  0.10511329 -0.36605981]\n",
      "New theta_0 : [ 0.00092918 -0.09162636  0.08490413  0.02544681  0.05865424 -0.2417638\n",
      "  0.34999811  0.00089429 -0.31330073  0.24929068 -0.18306808 -0.22870534\n",
      "  0.10510725 -0.36606962]\n",
      "Training Error:  10.498958197962805\n",
      "====================================================================================================\n",
      "Iteration:  656\n",
      "Previous theta :  [ 0.00092918 -0.09162636  0.08490413  0.02544681  0.05865424 -0.2417638\n",
      "  0.34999811  0.00089429 -0.31330073  0.24929068 -0.18306808 -0.22870534\n",
      "  0.10510725 -0.36606962]\n",
      "New theta_0 : [ 0.00092664 -0.09164596  0.0849539   0.02548075  0.0586516  -0.24186899\n",
      "  0.34997025  0.00089931 -0.31340811  0.24940018 -0.18315936 -0.22871506\n",
      "  0.10510125 -0.36607936]\n",
      "Training Error:  10.498913434299864\n",
      "====================================================================================================\n",
      "Iteration:  657\n",
      "Previous theta :  [ 0.00092664 -0.09164596  0.0849539   0.02548075  0.0586516  -0.24186899\n",
      "  0.34997025  0.00089931 -0.31340811  0.24940018 -0.18315936 -0.22871506\n",
      "  0.10510125 -0.36607936]\n",
      "New theta_0 : [ 0.0009241  -0.09166545  0.0850034   0.02551467  0.05864895 -0.2419735\n",
      "  0.34994258  0.00090432 -0.31351475  0.24950933 -0.18325051 -0.22872473\n",
      "  0.10509531 -0.36608902]\n",
      "Training Error:  10.498869089134475\n",
      "====================================================================================================\n",
      "Iteration:  658\n",
      "Previous theta :  [ 0.0009241  -0.09166545  0.0850034   0.02551467  0.05864895 -0.2419735\n",
      "  0.34994258  0.00090432 -0.31351475  0.24950933 -0.18325051 -0.22872473\n",
      "  0.10509531 -0.36608902]\n",
      "New theta_0 : [ 0.00092159 -0.09168484  0.08505263  0.02554855  0.0586463  -0.24207733\n",
      "  0.34991509  0.00090931 -0.31362064  0.24961815 -0.18334152 -0.22873433\n",
      "  0.10508941 -0.36609862]\n",
      "Training Error:  10.498825157696164\n",
      "====================================================================================================\n",
      "Iteration:  659\n",
      "Previous theta :  [ 0.00092159 -0.09168484  0.08505263  0.02554855  0.0586463  -0.24207733\n",
      "  0.34991509  0.00090931 -0.31362064  0.24961815 -0.18334152 -0.22873433\n",
      "  0.10508941 -0.36609862]\n",
      "New theta_0 : [ 0.0009191  -0.09170413  0.0851016   0.0255824   0.05864364 -0.24218049\n",
      "  0.34988779  0.00091428 -0.31372581  0.24972663 -0.18343238 -0.22874387\n",
      "  0.10508357 -0.36610814]\n",
      "Training Error:  10.498781635275959\n",
      "====================================================================================================\n",
      "Iteration:  660\n",
      "Previous theta :  [ 0.0009191  -0.09170413  0.0851016   0.0255824   0.05864364 -0.24218049\n",
      "  0.34988779  0.00091428 -0.31372581  0.24972663 -0.18343238 -0.22874387\n",
      "  0.10508357 -0.36610814]\n",
      "New theta_0 : [ 0.00091662 -0.09172331  0.0851503   0.02561622  0.05864097 -0.24228298\n",
      "  0.34986067  0.00091924 -0.31383025  0.24983478 -0.18352311 -0.22875336\n",
      "  0.10507778 -0.36611759]\n",
      "Training Error:  10.498738517225538\n",
      "====================================================================================================\n",
      "Iteration:  661\n",
      "Previous theta :  [ 0.00091662 -0.09172331  0.0851503   0.02561622  0.05864097 -0.24228298\n",
      "  0.34986067  0.00091924 -0.31383025  0.24983478 -0.18352311 -0.22875336\n",
      "  0.10507778 -0.36611759]\n",
      "New theta_0 : [ 0.00091416 -0.09174239  0.08519874  0.02565     0.0586383  -0.2423848\n",
      "  0.34983373  0.00092418 -0.31393396  0.24994259 -0.1836137  -0.22876279\n",
      "  0.10507203 -0.36612697]\n",
      "Training Error:  10.49869579895641\n",
      "====================================================================================================\n",
      "Iteration:  662\n",
      "Previous theta :  [ 0.00091416 -0.09174239  0.08519874  0.02565     0.0586383  -0.2423848\n",
      "  0.34983373  0.00092418 -0.31393396  0.24994259 -0.1836137  -0.22876279\n",
      "  0.10507203 -0.36612697]\n",
      "New theta_0 : [ 0.00091171 -0.09176136  0.08524692  0.02568375  0.05863563 -0.24248597\n",
      "  0.34980697  0.00092911 -0.31403696  0.25005007 -0.18370415 -0.22877216\n",
      "  0.10506634 -0.36613628]\n",
      "Training Error:  10.498653475939076\n",
      "====================================================================================================\n",
      "Iteration:  663\n",
      "Previous theta :  [ 0.00091171 -0.09176136  0.08524692  0.02568375  0.05863563 -0.24248597\n",
      "  0.34980697  0.00092911 -0.31403696  0.25005007 -0.18370415 -0.22877216\n",
      "  0.10506634 -0.36613628]\n",
      "New theta_0 : [ 0.00090928 -0.09178024  0.08529485  0.02571746  0.05863294 -0.24258647\n",
      "  0.34978039  0.00093402 -0.31413924  0.25015722 -0.18379445 -0.22878147\n",
      "  0.10506069 -0.36614553]\n",
      "Training Error:  10.498611543702241\n",
      "====================================================================================================\n",
      "Iteration:  664\n",
      "Previous theta :  [ 0.00090928 -0.09178024  0.08529485  0.02571746  0.05863294 -0.24258647\n",
      "  0.34978039  0.00093402 -0.31413924  0.25015722 -0.18379445 -0.22878147\n",
      "  0.10506069 -0.36614553]\n",
      "New theta_0 : [ 0.00090687 -0.09179901  0.08534251  0.02575114  0.05863025 -0.24268633\n",
      "  0.34975399  0.00093891 -0.31424082  0.25026404 -0.18388462 -0.22879073\n",
      "  0.10505509 -0.3661547 ]\n",
      "Training Error:  10.498569997832016\n",
      "====================================================================================================\n",
      "Iteration:  665\n",
      "Previous theta :  [ 0.00090687 -0.09179901  0.08534251  0.02575114  0.05863025 -0.24268633\n",
      "  0.34975399  0.00093891 -0.31424082  0.25026404 -0.18388462 -0.22879073\n",
      "  0.10505509 -0.3661547 ]\n",
      "New theta_0 : [ 0.00090448 -0.09181768  0.08538992  0.02578479  0.05862756 -0.24278554\n",
      "  0.34972776  0.00094379 -0.3143417   0.25037053 -0.18397465 -0.22879993\n",
      "  0.10504954 -0.36616381]\n",
      "Training Error:  10.498528833971118\n",
      "====================================================================================================\n",
      "Iteration:  666\n",
      "Previous theta :  [ 0.00090448 -0.09181768  0.08538992  0.02578479  0.05862756 -0.24278554\n",
      "  0.34972776  0.00094379 -0.3143417   0.25037053 -0.18397465 -0.22879993\n",
      "  0.10504954 -0.36616381]\n",
      "New theta_0 : [ 0.0009021  -0.09183626  0.08543708  0.02581839  0.05862486 -0.2428841\n",
      "  0.34970171  0.00094865 -0.31444187  0.25047669 -0.18406453 -0.22880908\n",
      "  0.10504403 -0.36617286]\n",
      "Training Error:  10.498488047818114\n",
      "====================================================================================================\n",
      "Iteration:  667\n",
      "Previous theta :  [ 0.0009021  -0.09183626  0.08543708  0.02581839  0.05862486 -0.2428841\n",
      "  0.34970171  0.00094865 -0.31444187  0.25047669 -0.18406453 -0.22880908\n",
      "  0.10504403 -0.36617286]\n",
      "New theta_0 : [ 0.00089974 -0.09185473  0.08548398  0.02585196  0.05862216 -0.24298203\n",
      "  0.34967583  0.0009535  -0.31454136  0.25058252 -0.18415427 -0.22881817\n",
      "  0.10503858 -0.36618183]\n",
      "Training Error:  10.49844763512665\n",
      "====================================================================================================\n",
      "Iteration:  668\n",
      "Previous theta :  [ 0.00089974 -0.09185473  0.08548398  0.02585196  0.05862216 -0.24298203\n",
      "  0.34967583  0.0009535  -0.31454136  0.25058252 -0.18415427 -0.22881817\n",
      "  0.10503858 -0.36618183]\n",
      "New theta_0 : [ 0.0008974  -0.0918731   0.08553063  0.0258855   0.05861945 -0.24307932\n",
      "  0.34965012  0.00095834 -0.31464016  0.25068803 -0.18424387 -0.2288272\n",
      "  0.10503317 -0.36619075]\n",
      "Training Error:  10.498407591704696\n",
      "====================================================================================================\n",
      "Iteration:  669\n",
      "Previous theta :  [ 0.0008974  -0.0918731   0.08553063  0.0258855   0.05861945 -0.24307932\n",
      "  0.34965012  0.00095834 -0.31464016  0.25068803 -0.18424387 -0.2288272\n",
      "  0.10503317 -0.36619075]\n",
      "New theta_0 : [ 0.00089507 -0.09189138  0.08557703  0.02591899  0.05861674 -0.24317599\n",
      "  0.34962458  0.00096315 -0.31473827  0.25079322 -0.18433332 -0.22883619\n",
      "  0.1050278  -0.3661996 ]\n",
      "Training Error:  10.498367913413816\n",
      "====================================================================================================\n",
      "Iteration:  670\n",
      "Previous theta :  [ 0.00089507 -0.09189138  0.08557703  0.02591899  0.05861674 -0.24317599\n",
      "  0.34962458  0.00096315 -0.31473827  0.25079322 -0.18433332 -0.22883619\n",
      "  0.1050278  -0.3661996 ]\n",
      "New theta_0 : [ 0.00089276 -0.09190956  0.08562319  0.02595245  0.05861402 -0.24327203\n",
      "  0.34959921  0.00096796 -0.31483571  0.25089808 -0.18442264 -0.22884511\n",
      "  0.10502248 -0.36620838]\n",
      "Training Error:  10.49832859616842\n",
      "====================================================================================================\n",
      "Iteration:  671\n",
      "Previous theta :  [ 0.00089276 -0.09190956  0.08562319  0.02595245  0.05861402 -0.24327203\n",
      "  0.34959921  0.00096796 -0.31483571  0.25089808 -0.18442264 -0.22884511\n",
      "  0.10502248 -0.36620838]\n",
      "New theta_0 : [ 0.00089046 -0.09192764  0.0856691   0.02598587  0.0586113  -0.24336744\n",
      "  0.34957401  0.00097274 -0.31493247  0.25100262 -0.18451181 -0.22885398\n",
      "  0.10501721 -0.3662171 ]\n",
      "Training Error:  10.498289635935054\n",
      "====================================================================================================\n",
      "Iteration:  672\n",
      "Previous theta :  [ 0.00089046 -0.09192764  0.0856691   0.02598587  0.0586113  -0.24336744\n",
      "  0.34957401  0.00097274 -0.31493247  0.25100262 -0.18451181 -0.22885398\n",
      "  0.10501721 -0.3662171 ]\n",
      "New theta_0 : [ 0.00088818 -0.09194563  0.08571476  0.02601925  0.05860857 -0.24346224\n",
      "  0.34954897  0.00097752 -0.31502856  0.25110684 -0.18460083 -0.2288628\n",
      "  0.10501198 -0.36622576]\n",
      "Training Error:  10.4982510287317\n",
      "====================================================================================================\n",
      "Iteration:  673\n",
      "Previous theta :  [ 0.00088818 -0.09194563  0.08571476  0.02601925  0.05860857 -0.24346224\n",
      "  0.34954897  0.00097752 -0.31502856  0.25110684 -0.18460083 -0.2288628\n",
      "  0.10501198 -0.36622576]\n",
      "New theta_0 : [ 0.00088592 -0.09196352  0.08576018  0.02605259  0.05860584 -0.24355643\n",
      "  0.3495241   0.00098228 -0.31512399  0.25121075 -0.18468971 -0.22887157\n",
      "  0.1050068  -0.36623436]\n",
      "Training Error:  10.498212770627044\n",
      "====================================================================================================\n",
      "Iteration:  674\n",
      "Previous theta :  [ 0.00088592 -0.09196352  0.08576018  0.02605259  0.05860584 -0.24355643\n",
      "  0.3495241   0.00098228 -0.31512399  0.25121075 -0.18468971 -0.22887157\n",
      "  0.1050068  -0.36623436]\n",
      "New theta_0 : [ 0.00088367 -0.09198131  0.08580535  0.02608589  0.0586031  -0.24365001\n",
      "  0.3494994   0.00098702 -0.31521877  0.25131433 -0.18477845 -0.22888028\n",
      "  0.10500166 -0.3662429 ]\n",
      "Training Error:  10.498174857739821\n",
      "====================================================================================================\n",
      "Iteration:  675\n",
      "Previous theta :  [ 0.00088367 -0.09198131  0.08580535  0.02608589  0.0586031  -0.24365001\n",
      "  0.3494994   0.00098702 -0.31521877  0.25131433 -0.18477845 -0.22888028\n",
      "  0.10500166 -0.3662429 ]\n",
      "New theta_0 : [ 0.00088144 -0.09199901  0.08585029  0.02611916  0.05860036 -0.24374298\n",
      "  0.34947485  0.00099175 -0.31531288  0.2514176  -0.18486704 -0.22888894\n",
      "  0.10499657 -0.36625138]\n",
      "Training Error:  10.498137286238109\n",
      "====================================================================================================\n",
      "Iteration:  676\n",
      "Previous theta :  [ 0.00088144 -0.09199901  0.08585029  0.02611916  0.05860036 -0.24374298\n",
      "  0.34947485  0.00099175 -0.31531288  0.2514176  -0.18486704 -0.22888894\n",
      "  0.10499657 -0.36625138]\n",
      "New theta_0 : [ 0.00087922 -0.09201662  0.08589499  0.02615238  0.05859762 -0.24383535\n",
      "  0.34945047  0.00099646 -0.31540635  0.25152055 -0.18495549 -0.22889755\n",
      "  0.10499151 -0.36625979]\n",
      "Training Error:  10.498100052338664\n",
      "====================================================================================================\n",
      "Iteration:  677\n",
      "Previous theta :  [ 0.00087922 -0.09201662  0.08589499  0.02615238  0.05859762 -0.24383535\n",
      "  0.34945047  0.00099646 -0.31540635  0.25152055 -0.18495549 -0.22889755\n",
      "  0.10499151 -0.36625979]\n",
      "New theta_0 : [ 0.00087702 -0.09203413  0.08593945  0.02618556  0.05859487 -0.24392713\n",
      "  0.34942624  0.00100116 -0.31549917  0.25162319 -0.18504379 -0.22890611\n",
      "  0.10498651 -0.36626815]\n",
      "Training Error:  10.498063152306267\n",
      "====================================================================================================\n",
      "Iteration:  678\n",
      "Previous theta :  [ 0.00087702 -0.09203413  0.08593945  0.02618556  0.05859487 -0.24392713\n",
      "  0.34942624  0.00100116 -0.31549917  0.25162319 -0.18504379 -0.22890611\n",
      "  0.10498651 -0.36626815]\n",
      "New theta_0 : [ 0.00087483 -0.09205155  0.08598367  0.0262187   0.05859211 -0.24401831\n",
      "  0.34940218  0.00100585 -0.31559135  0.25172552 -0.18513195 -0.22891461\n",
      "  0.10498154 -0.36627645]\n",
      "Training Error:  10.498026582453056\n",
      "====================================================================================================\n",
      "Iteration:  679\n",
      "Previous theta :  [ 0.00087483 -0.09205155  0.08598367  0.0262187   0.05859211 -0.24401831\n",
      "  0.34940218  0.00100585 -0.31559135  0.25172552 -0.18513195 -0.22891461\n",
      "  0.10498154 -0.36627645]\n",
      "New theta_0 : [ 0.00087266 -0.09206888  0.08602766  0.0262518   0.05858936 -0.2441089\n",
      "  0.34937827  0.00101052 -0.3156829   0.25182753 -0.18521996 -0.22892307\n",
      "  0.10497662 -0.36628469]\n",
      "Training Error:  10.497990339137894\n",
      "====================================================================================================\n",
      "Iteration:  680\n",
      "Previous theta :  [ 0.00087266 -0.09206888  0.08602766  0.0262518   0.05858936 -0.2441089\n",
      "  0.34937827  0.00101052 -0.3156829   0.25182753 -0.18521996 -0.22892307\n",
      "  0.10497662 -0.36628469]\n",
      "New theta_0 : [ 0.0008705  -0.09208612  0.08607142  0.02628485  0.0585866  -0.24419891\n",
      "  0.34935452  0.00101518 -0.31577381  0.25192923 -0.18530783 -0.22893147\n",
      "  0.10497174 -0.36629288]\n",
      "Training Error:  10.497954418765733\n",
      "====================================================================================================\n",
      "Iteration:  681\n",
      "Previous theta :  [ 0.0008705  -0.09208612  0.08607142  0.02628485  0.0585866  -0.24419891\n",
      "  0.34935452  0.00101518 -0.31577381  0.25192923 -0.18530783 -0.22893147\n",
      "  0.10497174 -0.36629288]\n",
      "New theta_0 : [ 0.00086836 -0.09210327  0.08611494  0.02631787  0.05858383 -0.24428834\n",
      "  0.34933092  0.00101982 -0.3158641   0.25203063 -0.18539554 -0.22893983\n",
      "  0.1049669  -0.366301  ]\n",
      "Training Error:  10.497918817786982\n",
      "====================================================================================================\n",
      "Iteration:  682\n",
      "Previous theta :  [ 0.00086836 -0.09210327  0.08611494  0.02631787  0.05858383 -0.24428834\n",
      "  0.34933092  0.00101982 -0.3158641   0.25203063 -0.18539554 -0.22893983\n",
      "  0.1049669  -0.366301  ]\n",
      "New theta_0 : [ 0.00086623 -0.09212032  0.08615824  0.02635084  0.05858106 -0.24437719\n",
      "  0.34930748  0.00102445 -0.31595377  0.25213171 -0.18548312 -0.22894813\n",
      "  0.1049621  -0.36630907]\n",
      "Training Error:  10.497883532696891\n",
      "====================================================================================================\n",
      "Iteration:  683\n",
      "Previous theta :  [ 0.00086623 -0.09212032  0.08615824  0.02635084  0.05858106 -0.24437719\n",
      "  0.34930748  0.00102445 -0.31595377  0.25213171 -0.18548312 -0.22894813\n",
      "  0.1049621  -0.36630907]\n",
      "New theta_0 : [ 0.00086412 -0.09213729  0.0862013   0.02638377  0.05857829 -0.24446547\n",
      "  0.34928418  0.00102907 -0.31604281  0.25223249 -0.18557054 -0.22895639\n",
      "  0.10495735 -0.36631709]\n",
      "Training Error:  10.497848560034951\n",
      "====================================================================================================\n",
      "Iteration:  684\n",
      "Previous theta :  [ 0.00086412 -0.09213729  0.0862013   0.02638377  0.05857829 -0.24446547\n",
      "  0.34928418  0.00102907 -0.31604281  0.25223249 -0.18557054 -0.22895639\n",
      "  0.10495735 -0.36631709]\n",
      "New theta_0 : [ 0.00086203 -0.09215417  0.08624414  0.02641666  0.05857552 -0.24455318\n",
      "  0.34926104  0.00103367 -0.31613124  0.25233296 -0.18565782 -0.22896459\n",
      "  0.10495263 -0.36632505]\n",
      "Training Error:  10.497813896384288\n",
      "====================================================================================================\n",
      "Iteration:  685\n",
      "Previous theta :  [ 0.00086203 -0.09215417  0.08624414  0.02641666  0.05857552 -0.24455318\n",
      "  0.34926104  0.00103367 -0.31613124  0.25233296 -0.18565782 -0.22896459\n",
      "  0.10495263 -0.36632505]\n",
      "New theta_0 : [ 0.00085994 -0.09217096  0.08628675  0.0264495   0.05857274 -0.24464032\n",
      "  0.34923805  0.00103825 -0.31621907  0.25243313 -0.18574495 -0.22897275\n",
      "  0.10494796 -0.36633295]\n",
      "Training Error:  10.497779538371072\n",
      "====================================================================================================\n",
      "Iteration:  686\n",
      "Previous theta :  [ 0.00085994 -0.09217096  0.08628675  0.0264495   0.05857274 -0.24464032\n",
      "  0.34923805  0.00103825 -0.31621907  0.25243313 -0.18574495 -0.22897275\n",
      "  0.10494796 -0.36633295]\n",
      "New theta_0 : [ 0.00085787 -0.09218766  0.08632913  0.0264823   0.05856996 -0.24472691\n",
      "  0.34921521  0.00104283 -0.31630628  0.25253299 -0.18583193 -0.22898086\n",
      "  0.10494332 -0.3663408 ]\n",
      "Training Error:  10.497745482663928\n",
      "====================================================================================================\n",
      "Iteration:  687\n",
      "Previous theta :  [ 0.00085787 -0.09218766  0.08632913  0.0264823   0.05856996 -0.24472691\n",
      "  0.34921521  0.00104283 -0.31630628  0.25253299 -0.18583193 -0.22898086\n",
      "  0.10494332 -0.3663408 ]\n",
      "New theta_0 : [ 0.00085582 -0.09220427  0.08637129  0.02651506  0.05856717 -0.24481293\n",
      "  0.34919252  0.00104739 -0.3163929   0.25263255 -0.18591876 -0.22898892\n",
      "  0.10493873 -0.3663486 ]\n",
      "Training Error:  10.49771172597338\n",
      "====================================================================================================\n",
      "Iteration:  688\n",
      "Previous theta :  [ 0.00085582 -0.09220427  0.08637129  0.02651506  0.05856717 -0.24481293\n",
      "  0.34919252  0.00104739 -0.3163929   0.25263255 -0.18591876 -0.22898892\n",
      "  0.10493873 -0.3663486 ]\n",
      "New theta_0 : [ 0.00085378 -0.0922208   0.08641323  0.02654777  0.05856438 -0.2448984\n",
      "  0.34916998  0.00105194 -0.31647892  0.2527318  -0.18600545 -0.22899693\n",
      "  0.10493417 -0.36635634]\n",
      "Training Error:  10.49767826505126\n",
      "====================================================================================================\n",
      "Iteration:  689\n",
      "Previous theta :  [ 0.00085378 -0.0922208   0.08641323  0.02654777  0.05856438 -0.2448984\n",
      "  0.34916998  0.00105194 -0.31647892  0.2527318  -0.18600545 -0.22899693\n",
      "  0.10493417 -0.36635634]\n",
      "New theta_0 : [ 0.00085175 -0.09223724  0.08645495  0.02658043  0.05856159 -0.24498332\n",
      "  0.34914758  0.00105647 -0.31656435  0.25283076 -0.18609199 -0.2290049\n",
      "  0.10492966 -0.36636403]\n",
      "Training Error:  10.497645096690166\n",
      "====================================================================================================\n",
      "Iteration:  690\n",
      "Previous theta :  [ 0.00085175 -0.09223724  0.08645495  0.02658043  0.05856159 -0.24498332\n",
      "  0.34914758  0.00105647 -0.31656435  0.25283076 -0.18609199 -0.2290049\n",
      "  0.10492966 -0.36636403]\n",
      "New theta_0 : [ 0.00084974 -0.09225359  0.08649645  0.02661305  0.0585588  -0.2450677\n",
      "  0.34912532  0.00106099 -0.31664919  0.25292942 -0.18617838 -0.22901282\n",
      "  0.10492518 -0.36637167]\n",
      "Training Error:  10.497612217722905\n",
      "====================================================================================================\n",
      "Iteration:  691\n",
      "Previous theta :  [ 0.00084974 -0.09225359  0.08649645  0.02661305  0.0585588  -0.2450677\n",
      "  0.34912532  0.00106099 -0.31664919  0.25292942 -0.18617838 -0.22901282\n",
      "  0.10492518 -0.36637167]\n",
      "New theta_0 : [ 0.00084774 -0.09226986  0.08653773  0.02664563  0.058556   -0.24515153\n",
      "  0.34910321  0.0010655  -0.31673344  0.25302778 -0.18626462 -0.22902069\n",
      "  0.10492074 -0.36637926]\n",
      "Training Error:  10.497579625021947\n",
      "====================================================================================================\n",
      "Iteration:  692\n",
      "Previous theta :  [ 0.00084774 -0.09226986  0.08653773  0.02664563  0.058556   -0.24515153\n",
      "  0.34910321  0.0010655  -0.31673344  0.25302778 -0.18626462 -0.22902069\n",
      "  0.10492074 -0.36637926]\n",
      "New theta_0 : [ 0.00084576 -0.09228604  0.0865788   0.02667816  0.0585532  -0.24523482\n",
      "  0.34908124  0.00106999 -0.31681712  0.25312584 -0.18635071 -0.22902851\n",
      "  0.10491635 -0.36638679]\n",
      "Training Error:  10.497547315498899\n",
      "====================================================================================================\n",
      "Iteration:  693\n",
      "Previous theta :  [ 0.00084576 -0.09228604  0.0865788   0.02667816  0.0585532  -0.24523482\n",
      "  0.34908124  0.00106999 -0.31681712  0.25312584 -0.18635071 -0.22902851\n",
      "  0.10491635 -0.36638679]\n",
      "New theta_0 : [ 0.00084379 -0.09230214  0.08661965  0.02671064  0.0585504  -0.24531758\n",
      "  0.34905941  0.00107447 -0.31690021  0.25322361 -0.18643665 -0.22903629\n",
      "  0.10491198 -0.36639428]\n",
      "Training Error:  10.497515286103962\n",
      "====================================================================================================\n",
      "Iteration:  694\n",
      "Previous theta :  [ 0.00084379 -0.09230214  0.08661965  0.02671064  0.0585504  -0.24531758\n",
      "  0.34905941  0.00107447 -0.31690021  0.25322361 -0.18643665 -0.22903629\n",
      "  0.10491198 -0.36639428]\n",
      "New theta_0 : [ 0.00084183 -0.09231815  0.08666028  0.02674308  0.05854759 -0.2453998\n",
      "  0.34903772  0.00107894 -0.31698274  0.25332108 -0.18652244 -0.22904403\n",
      "  0.10490766 -0.36640171]\n",
      "Training Error:  10.497483533825424\n",
      "====================================================================================================\n",
      "Iteration:  695\n",
      "Previous theta :  [ 0.00084183 -0.09231815  0.08666028  0.02674308  0.05854759 -0.2453998\n",
      "  0.34903772  0.00107894 -0.31698274  0.25332108 -0.18652244 -0.22904403\n",
      "  0.10490766 -0.36640171]\n",
      "New theta_0 : [ 0.00083989 -0.09233409  0.0867007   0.02677547  0.05854479 -0.2454815\n",
      "  0.34901617  0.00108339 -0.3170647   0.25341826 -0.18660808 -0.22905171\n",
      "  0.10490337 -0.3664091 ]\n",
      "Training Error:  10.497452055689138\n",
      "====================================================================================================\n",
      "Iteration:  696\n",
      "Previous theta :  [ 0.00083989 -0.09233409  0.0867007   0.02677547  0.05854479 -0.2454815\n",
      "  0.34901617  0.00108339 -0.3170647   0.25341826 -0.18660808 -0.22905171\n",
      "  0.10490337 -0.3664091 ]\n",
      "New theta_0 : [ 0.00083796 -0.09234993  0.08674091  0.02680782  0.05854198 -0.24556267\n",
      "  0.34899476  0.00108784 -0.31714609  0.25351514 -0.18669358 -0.22905936\n",
      "  0.10489912 -0.36641644]\n",
      "Training Error:  10.49742084875802\n",
      "====================================================================================================\n",
      "Iteration:  697\n",
      "Previous theta :  [ 0.00083796 -0.09234993  0.08674091  0.02680782  0.05854198 -0.24556267\n",
      "  0.34899476  0.00108784 -0.31714609  0.25351514 -0.18669358 -0.22905936\n",
      "  0.10489912 -0.36641644]\n",
      "New theta_0 : [ 0.00083604 -0.0923657   0.08678091  0.02684011  0.05853916 -0.24564332\n",
      "  0.34897348  0.00109227 -0.31722693  0.25361173 -0.18677892 -0.22906695\n",
      "  0.10489491 -0.36642372]\n",
      "Training Error:  10.497389910131542\n",
      "====================================================================================================\n",
      "Iteration:  698\n",
      "Previous theta :  [ 0.00083604 -0.0923657   0.08678091  0.02684011  0.05853916 -0.24564332\n",
      "  0.34897348  0.00109227 -0.31722693  0.25361173 -0.18677892 -0.22906695\n",
      "  0.10489491 -0.36642372]\n",
      "New theta_0 : [ 0.00083414 -0.09238139  0.0868207   0.02687236  0.05853635 -0.24572345\n",
      "  0.34895234  0.00109668 -0.31730721  0.25370803 -0.18686411 -0.22907451\n",
      "  0.10489073 -0.36643096]\n",
      "Training Error:  10.497359236945258\n",
      "====================================================================================================\n",
      "Iteration:  699\n",
      "Previous theta :  [ 0.00083414 -0.09238139  0.0868207   0.02687236  0.05853635 -0.24572345\n",
      "  0.34895234  0.00109668 -0.31730721  0.25370803 -0.18686411 -0.22907451\n",
      "  0.10489073 -0.36643096]\n",
      "New theta_0 : [ 0.00083225 -0.09239699  0.08686029  0.02690457  0.05853353 -0.24580307\n",
      "  0.34893134  0.00110109 -0.31738693  0.25380404 -0.18694915 -0.22908201\n",
      "  0.10488659 -0.36643816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.497328826370286\n",
      "====================================================================================================\n",
      "Iteration:  700\n",
      "Previous theta :  [ 0.00083225 -0.09239699  0.08686029  0.02690457  0.05853353 -0.24580307\n",
      "  0.34893134  0.00110109 -0.31738693  0.25380404 -0.18694915 -0.22908201\n",
      "  0.10488659 -0.36643816]\n",
      "New theta_0 : [ 0.00083037 -0.09241251  0.08689966  0.02693672  0.05853071 -0.24588218\n",
      "  0.34891047  0.00110548 -0.31746611  0.25389977 -0.18703405 -0.22908948\n",
      "  0.10488249 -0.3664453 ]\n",
      "Training Error:  10.497298675612871\n",
      "====================================================================================================\n",
      "Iteration:  701\n",
      "Previous theta :  [ 0.00083037 -0.09241251  0.08689966  0.02693672  0.05853071 -0.24588218\n",
      "  0.34891047  0.00110548 -0.31746611  0.25389977 -0.18703405 -0.22908948\n",
      "  0.10488249 -0.3664453 ]\n",
      "New theta_0 : [ 0.00082851 -0.09242796  0.08693884  0.02696883  0.05852789 -0.24596078\n",
      "  0.34888973  0.00110986 -0.31754475  0.2539952  -0.18711879 -0.2290969\n",
      "  0.10487842 -0.3664524 ]\n",
      "Training Error:  10.497268781913876\n",
      "====================================================================================================\n",
      "Iteration:  702\n",
      "Previous theta :  [ 0.00082851 -0.09242796  0.08693884  0.02696883  0.05852789 -0.24596078\n",
      "  0.34888973  0.00110986 -0.31754475  0.2539952  -0.18711879 -0.2290969\n",
      "  0.10487842 -0.3664524 ]\n",
      "New theta_0 : [ 0.00082666 -0.09244332  0.0869778   0.02700088  0.05852507 -0.24603888\n",
      "  0.34886912  0.00111422 -0.31762284  0.25409035 -0.18720338 -0.22910428\n",
      "  0.10487439 -0.36645945]\n",
      "Training Error:  10.497239142548334\n",
      "====================================================================================================\n",
      "Iteration:  703\n",
      "Previous theta :  [ 0.00082666 -0.09244332  0.0869778   0.02700088  0.05852507 -0.24603888\n",
      "  0.34886912  0.00111422 -0.31762284  0.25409035 -0.18720338 -0.22910428\n",
      "  0.10487439 -0.36645945]\n",
      "New theta_0 : [ 0.00082482 -0.0924586   0.08701657  0.02703289  0.05852224 -0.24611647\n",
      "  0.34884865  0.00111858 -0.3177004   0.25418521 -0.18728782 -0.22911161\n",
      "  0.10487039 -0.36646646]\n",
      "Training Error:  10.497209754824993\n",
      "====================================================================================================\n",
      "Iteration:  704\n",
      "Previous theta :  [ 0.00082482 -0.0924586   0.08701657  0.02703289  0.05852224 -0.24611647\n",
      "  0.34884865  0.00111858 -0.3177004   0.25418521 -0.18728782 -0.22911161\n",
      "  0.10487039 -0.36646646]\n",
      "New theta_0 : [ 0.00082299 -0.09247381  0.08705513  0.02706485  0.05851942 -0.24619357\n",
      "  0.3488283   0.00112292 -0.31777742  0.25427979 -0.1873721  -0.2291189\n",
      "  0.10486642 -0.36647342]\n",
      "Training Error:  10.497180616085853\n",
      "====================================================================================================\n",
      "Iteration:  705\n",
      "Previous theta :  [ 0.00082299 -0.09247381  0.08705513  0.02706485  0.05851942 -0.24619357\n",
      "  0.3488283   0.00112292 -0.31777742  0.25427979 -0.1873721  -0.2291189\n",
      "  0.10486642 -0.36647342]\n",
      "New theta_0 : [ 0.00082118 -0.09248893  0.08709349  0.02709677  0.05851659 -0.24627018\n",
      "  0.34880809  0.00112725 -0.31785392  0.25437408 -0.18745624 -0.22912615\n",
      "  0.10486249 -0.36648033]\n",
      "Training Error:  10.49715172370572\n",
      "====================================================================================================\n",
      "Iteration:  706\n",
      "Previous theta :  [ 0.00082118 -0.09248893  0.08709349  0.02709677  0.05851659 -0.24627018\n",
      "  0.34880809  0.00112725 -0.31785392  0.25437408 -0.18745624 -0.22912615\n",
      "  0.10486249 -0.36648033]\n",
      "New theta_0 : [ 0.00081938 -0.09250398  0.08713166  0.02712863  0.05851376 -0.24634629\n",
      "  0.348788    0.00113157 -0.31792989  0.2544681  -0.18754023 -0.22913336\n",
      "  0.1048586  -0.3664872 ]\n",
      "Training Error:  10.497123075091777\n",
      "====================================================================================================\n",
      "Iteration:  707\n",
      "Previous theta :  [ 0.00081938 -0.09250398  0.08713166  0.02712863  0.05851376 -0.24634629\n",
      "  0.348788    0.00113157 -0.31792989  0.2544681  -0.18754023 -0.22913336\n",
      "  0.1048586  -0.3664872 ]\n",
      "New theta_0 : [ 0.00081759 -0.09251895  0.08716962  0.02716044  0.05851092 -0.24642192\n",
      "  0.34876803  0.00113587 -0.31800534  0.25456183 -0.18762406 -0.22914052\n",
      "  0.10485474 -0.36649403]\n",
      "Training Error:  10.497094667683134\n",
      "====================================================================================================\n",
      "Iteration:  708\n",
      "Previous theta :  [ 0.00081759 -0.09251895  0.08716962  0.02716044  0.05851092 -0.24642192\n",
      "  0.34876803  0.00113587 -0.31800534  0.25456183 -0.18762406 -0.22914052\n",
      "  0.10485474 -0.36649403]\n",
      "New theta_0 : [ 0.00081581 -0.09253385  0.08720739  0.0271922   0.05850809 -0.24649706\n",
      "  0.3487482   0.00114017 -0.31808027  0.25465528 -0.18770774 -0.22914765\n",
      "  0.10485091 -0.36650081]\n",
      "Training Error:  10.49706649895042\n",
      "====================================================================================================\n",
      "Iteration:  709\n",
      "Previous theta :  [ 0.00081581 -0.09253385  0.08720739  0.0271922   0.05850809 -0.24649706\n",
      "  0.3487482   0.00114017 -0.31808027  0.25465528 -0.18770774 -0.22914765\n",
      "  0.10485091 -0.36650081]\n",
      "New theta_0 : [ 0.00081405 -0.09254867  0.08724496  0.02722392  0.05850525 -0.24657172\n",
      "  0.34872849  0.00114445 -0.31815468  0.25474845 -0.18779127 -0.22915473\n",
      "  0.10484712 -0.36650755]\n",
      "Training Error:  10.497038566395343\n",
      "====================================================================================================\n",
      "Iteration:  710\n",
      "Previous theta :  [ 0.00081405 -0.09254867  0.08724496  0.02722392  0.05850525 -0.24657172\n",
      "  0.34872849  0.00114445 -0.31815468  0.25474845 -0.18779127 -0.22915473\n",
      "  0.10484712 -0.36650755]\n",
      "New theta_0 : [ 0.0008123  -0.09256341  0.08728234  0.02725558  0.05850242 -0.24664591\n",
      "  0.3487089   0.00114872 -0.31822859  0.25484134 -0.18787465 -0.22916177\n",
      "  0.10484335 -0.36651425]\n",
      "Training Error:  10.49701086755028\n",
      "====================================================================================================\n",
      "Iteration:  711\n",
      "Previous theta :  [ 0.0008123  -0.09256341  0.08728234  0.02725558  0.05850242 -0.24664591\n",
      "  0.3487089   0.00114872 -0.31822859  0.25484134 -0.18787465 -0.22916177\n",
      "  0.10484335 -0.36651425]\n",
      "New theta_0 : [ 0.00081056 -0.09257807  0.08731953  0.02728719  0.05849958 -0.24671962\n",
      "  0.34868943  0.00115298 -0.31830199  0.25493395 -0.18795787 -0.22916877\n",
      "  0.10483962 -0.3665209 ]\n",
      "Training Error:  10.496983399977873\n",
      "====================================================================================================\n",
      "Iteration:  712\n",
      "Previous theta :  [ 0.00081056 -0.09257807  0.08731953  0.02728719  0.05849958 -0.24671962\n",
      "  0.34868943  0.00115298 -0.31830199  0.25493395 -0.18795787 -0.22916877\n",
      "  0.10483962 -0.3665209 ]\n",
      "New theta_0 : [ 0.00080883 -0.09259267  0.08735652  0.02731875  0.05849674 -0.24679286\n",
      "  0.34867009  0.00115723 -0.31837488  0.25502629 -0.18804094 -0.22917573\n",
      "  0.10483593 -0.36652751]\n",
      "Training Error:  10.496956161270614\n",
      "====================================================================================================\n",
      "Iteration:  713\n",
      "Previous theta :  [ 0.00080883 -0.09259267  0.08735652  0.02731875  0.05849674 -0.24679286\n",
      "  0.34867009  0.00115723 -0.31837488  0.25502629 -0.18804094 -0.22917573\n",
      "  0.10483593 -0.36652751]\n",
      "New theta_0 : [ 0.00080712 -0.09260718  0.08739333  0.02735026  0.0584939  -0.24686563\n",
      "  0.34865087  0.00116146 -0.31844728  0.25511835 -0.18812387 -0.22918265\n",
      "  0.10483226 -0.36653408]\n",
      "Training Error:  10.496929149050459\n",
      "====================================================================================================\n",
      "Iteration:  714\n",
      "Previous theta :  [ 0.00080712 -0.09260718  0.08739333  0.02735026  0.0584939  -0.24686563\n",
      "  0.34865087  0.00116146 -0.31844728  0.25511835 -0.18812387 -0.22918265\n",
      "  0.10483226 -0.36653408]\n",
      "New theta_0 : [ 0.00080541 -0.09262163  0.08742994  0.02738172  0.05849106 -0.24693794\n",
      "  0.34863177  0.00116568 -0.31851917  0.25521014 -0.18820663 -0.22918952\n",
      "  0.10482863 -0.36654061]\n",
      "Training Error:  10.496902360968415\n",
      "====================================================================================================\n",
      "Iteration:  715\n",
      "Previous theta :  [ 0.00080541 -0.09262163  0.08742994  0.02738172  0.05849106 -0.24693794\n",
      "  0.34863177  0.00116568 -0.31851917  0.25521014 -0.18820663 -0.22918952\n",
      "  0.10482863 -0.36654061]\n",
      "New theta_0 : [ 0.00080372 -0.092636    0.08746636  0.02741313  0.05848822 -0.24700978\n",
      "  0.34861279  0.0011699  -0.31859058  0.25530165 -0.18828925 -0.22919636\n",
      "  0.10482503 -0.3665471 ]\n",
      "Training Error:  10.496875794704176\n",
      "====================================================================================================\n",
      "Iteration:  716\n",
      "Previous theta :  [ 0.00080372 -0.092636    0.08746636  0.02741313  0.05848822 -0.24700978\n",
      "  0.34861279  0.0011699  -0.31859058  0.25530165 -0.18828925 -0.22919636\n",
      "  0.10482503 -0.3665471 ]\n",
      "New theta_0 : [ 0.00080204 -0.09265029  0.0875026   0.02744449  0.05848537 -0.24708117\n",
      "  0.34859392  0.0011741  -0.31866149  0.25539289 -0.18837171 -0.22920316\n",
      "  0.10482146 -0.36655355]\n",
      "Training Error:  10.496849447965726\n",
      "====================================================================================================\n",
      "Iteration:  717\n",
      "Previous theta :  [ 0.00080204 -0.09265029  0.0875026   0.02744449  0.05848537 -0.24708117\n",
      "  0.34859392  0.0011741  -0.31866149  0.25539289 -0.18837171 -0.22920316\n",
      "  0.10482146 -0.36655355]\n",
      "New theta_0 : [ 0.00080037 -0.09266452  0.08753865  0.0274758   0.05848253 -0.2471521\n",
      "  0.34857518  0.00117829 -0.31873192  0.25548386 -0.18845402 -0.22920992\n",
      "  0.10481793 -0.36655995]\n",
      "Training Error:  10.49682331848896\n",
      "====================================================================================================\n",
      "Iteration:  718\n",
      "Previous theta :  [ 0.00080037 -0.09266452  0.08753865  0.0274758   0.05848253 -0.2471521\n",
      "  0.34857518  0.00117829 -0.31873192  0.25548386 -0.18845402 -0.22920992\n",
      "  0.10481793 -0.36655995]\n",
      "New theta_0 : [ 0.00079871 -0.09267867  0.08757452  0.02750705  0.05847968 -0.24722258\n",
      "  0.34855655  0.00118246 -0.31880187  0.25557456 -0.18853618 -0.22921665\n",
      "  0.10481442 -0.36656632]\n",
      "Training Error:  10.496797404037324\n",
      "====================================================================================================\n",
      "Iteration:  719\n",
      "Previous theta :  [ 0.00079871 -0.09267867  0.08757452  0.02750705  0.05847968 -0.24722258\n",
      "  0.34855655  0.00118246 -0.31880187  0.25557456 -0.18853618 -0.22921665\n",
      "  0.10481442 -0.36656632]\n",
      "New theta_0 : [ 0.00079707 -0.09269275  0.0876102   0.02753825  0.05847683 -0.24729261\n",
      "  0.34853803  0.00118663 -0.31887134  0.25566499 -0.18861818 -0.22922333\n",
      "  0.10481094 -0.36657265]\n",
      "Training Error:  10.496771702401427\n",
      "====================================================================================================\n",
      "Iteration:  720\n",
      "Previous theta :  [ 0.00079707 -0.09269275  0.0876102   0.02753825  0.05847683 -0.24729261\n",
      "  0.34853803  0.00118663 -0.31887134  0.25566499 -0.18861818 -0.22922333\n",
      "  0.10481094 -0.36657265]\n",
      "New theta_0 : [ 0.00079543 -0.09270675  0.0876457   0.0275694   0.05847399 -0.24736219\n",
      "  0.34851963  0.00119079 -0.31894033  0.25575515 -0.18870003 -0.22922997\n",
      "  0.1048075  -0.36657894]\n",
      "Training Error:  10.496746211398714\n",
      "====================================================================================================\n",
      "Iteration:  721\n",
      "Previous theta :  [ 0.00079543 -0.09270675  0.0876457   0.0275694   0.05847399 -0.24736219\n",
      "  0.34851963  0.00119079 -0.31894033  0.25575515 -0.18870003 -0.22922997\n",
      "  0.1048075  -0.36657894]\n",
      "New theta_0 : [ 0.00079381 -0.09272069  0.08768102  0.0276005   0.05847114 -0.24743133\n",
      "  0.34850135  0.00119493 -0.31900885  0.25584504 -0.18878173 -0.22923658\n",
      "  0.10480408 -0.36658519]\n",
      "Training Error:  10.49672092887307\n",
      "====================================================================================================\n",
      "Iteration:  722\n",
      "Previous theta :  [ 0.00079381 -0.09272069  0.08768102  0.0276005   0.05847114 -0.24743133\n",
      "  0.34850135  0.00119493 -0.31900885  0.25584504 -0.18878173 -0.22923658\n",
      "  0.10480408 -0.36658519]\n",
      "New theta_0 : [ 0.0007922  -0.09273456  0.08771616  0.02763154  0.05846829 -0.24750003\n",
      "  0.34848318  0.00119907 -0.3190769   0.25593467 -0.18886327 -0.22924315\n",
      "  0.1048007  -0.3665914 ]\n",
      "Training Error:  10.496695852694499\n",
      "====================================================================================================\n",
      "Iteration:  723\n",
      "Previous theta :  [ 0.0007922  -0.09273456  0.08771616  0.02763154  0.05846829 -0.24750003\n",
      "  0.34848318  0.00119907 -0.3190769   0.25593467 -0.18886327 -0.22924315\n",
      "  0.1048007  -0.3665914 ]\n",
      "New theta_0 : [ 0.00079059 -0.09274835  0.08775111  0.02766254  0.05846544 -0.24756829\n",
      "  0.34846512  0.00120319 -0.31914448  0.25602403 -0.18894467 -0.22924968\n",
      "  0.10479734 -0.36659758]\n",
      "Training Error:  10.496670980758758\n",
      "====================================================================================================\n",
      "Iteration:  724\n",
      "Previous theta :  [ 0.00079059 -0.09274835  0.08775111  0.02766254  0.05846544 -0.24756829\n",
      "  0.34846512  0.00120319 -0.31914448  0.25602403 -0.18894467 -0.22924968\n",
      "  0.10479734 -0.36659758]\n",
      "New theta_0 : [ 0.000789   -0.09276208  0.08778589  0.02769348  0.05846259 -0.24763612\n",
      "  0.34844717  0.0012073  -0.31921161  0.25611312 -0.1890259  -0.22925617\n",
      "  0.10479401 -0.36660371]\n",
      "Training Error:  10.496646310987026\n",
      "====================================================================================================\n",
      "Iteration:  725\n",
      "Previous theta :  [ 0.000789   -0.09276208  0.08778589  0.02769348  0.05846259 -0.24763612\n",
      "  0.34844717  0.0012073  -0.31921161  0.25611312 -0.1890259  -0.22925617\n",
      "  0.10479401 -0.36660371]\n",
      "New theta_0 : [ 0.00078743 -0.09277574  0.08782049  0.02772436  0.05845974 -0.24770351\n",
      "  0.34842934  0.0012114  -0.31927827  0.25620195 -0.18910699 -0.22926263\n",
      "  0.10479072 -0.36660981]\n",
      "Training Error:  10.496621841325565\n",
      "====================================================================================================\n",
      "Iteration:  726\n",
      "Previous theta :  [ 0.00078743 -0.09277574  0.08782049  0.02772436  0.05845974 -0.24770351\n",
      "  0.34842934  0.0012114  -0.31927827  0.25620195 -0.18910699 -0.22926263\n",
      "  0.10479072 -0.36660981]\n",
      "New theta_0 : [ 0.00078586 -0.09278933  0.08785492  0.0277552   0.05845689 -0.24777048\n",
      "  0.34841161  0.00121549 -0.31934448  0.25629052 -0.18918792 -0.22926905\n",
      "  0.10478745 -0.36661588]\n",
      "Training Error:  10.496597569745376\n",
      "====================================================================================================\n",
      "Iteration:  727\n",
      "Previous theta :  [ 0.00078586 -0.09278933  0.08785492  0.0277552   0.05845689 -0.24777048\n",
      "  0.34841161  0.00121549 -0.31934448  0.25629052 -0.18918792 -0.22926905\n",
      "  0.10478745 -0.36661588]\n",
      "New theta_0 : [ 0.0007843  -0.09280285  0.08788917  0.02778598  0.05845404 -0.24783702\n",
      "  0.34839399  0.00121957 -0.31941023  0.25637882 -0.1892687  -0.22927543\n",
      "  0.10478421 -0.3666219 ]\n",
      "Training Error:  10.49657349424189\n",
      "====================================================================================================\n",
      "Iteration:  728\n",
      "Previous theta :  [ 0.0007843  -0.09280285  0.08788917  0.02778598  0.05845404 -0.24783702\n",
      "  0.34839399  0.00121957 -0.31941023  0.25637882 -0.1892687  -0.22927543\n",
      "  0.10478421 -0.3666219 ]\n",
      "New theta_0 : [ 0.00078275 -0.0928163   0.08792324  0.0278167   0.05845119 -0.24790314\n",
      "  0.34837648  0.00122364 -0.31947553  0.25646686 -0.18934932 -0.22928178\n",
      "  0.104781   -0.36662789]\n",
      "Training Error:  10.496549612834633\n",
      "====================================================================================================\n",
      "Iteration:  729\n",
      "Previous theta :  [ 0.00078275 -0.0928163   0.08792324  0.0278167   0.05845119 -0.24790314\n",
      "  0.34837648  0.00122364 -0.31947553  0.25646686 -0.18934932 -0.22928178\n",
      "  0.104781   -0.36662789]\n",
      "New theta_0 : [ 0.00078122 -0.09282968  0.08795714  0.02784738  0.05844834 -0.24796884\n",
      "  0.34835908  0.0012277  -0.31954039  0.25655464 -0.18942979 -0.22928809\n",
      "  0.10477782 -0.36663385]\n",
      "Training Error:  10.496525923566905\n",
      "====================================================================================================\n",
      "Iteration:  730\n",
      "Previous theta :  [ 0.00078122 -0.09282968  0.08795714  0.02784738  0.05844834 -0.24796884\n",
      "  0.34835908  0.0012277  -0.31954039  0.25655464 -0.18942979 -0.22928809\n",
      "  0.10477782 -0.36663385]\n",
      "New theta_0 : [ 0.00077969 -0.092843    0.08799087  0.027878    0.05844549 -0.24803412\n",
      "  0.34834178  0.00123175 -0.3196048   0.25664217 -0.18951011 -0.22929436\n",
      "  0.10477466 -0.36663977]\n",
      "Training Error:  10.496502424505472\n",
      "====================================================================================================\n",
      "Iteration:  731\n",
      "Previous theta :  [ 0.00077969 -0.092843    0.08799087  0.027878    0.05844549 -0.24803412\n",
      "  0.34834178  0.00123175 -0.3196048   0.25664217 -0.18951011 -0.22929436\n",
      "  0.10477466 -0.36663977]\n",
      "New theta_0 : [ 0.00077818 -0.09285625  0.08802443  0.02790856  0.05844263 -0.24809898\n",
      "  0.34832459  0.00123579 -0.31966878  0.25672943 -0.18959027 -0.2293006\n",
      "  0.10477153 -0.36664565]\n",
      "Training Error:  10.496479113740254\n",
      "====================================================================================================\n",
      "Iteration:  732\n",
      "Previous theta :  [ 0.00077818 -0.09285625  0.08802443  0.02790856  0.05844263 -0.24809898\n",
      "  0.34832459  0.00123579 -0.31966878  0.25672943 -0.18959027 -0.2293006\n",
      "  0.10477153 -0.36664565]\n",
      "New theta_0 : [ 0.00077667 -0.09286943  0.08805782  0.02793908  0.05843978 -0.24816344\n",
      "  0.34830751  0.00123981 -0.31973231  0.25681643 -0.18967028 -0.2293068\n",
      "  0.10476843 -0.3666515 ]\n",
      "Training Error:  10.496455989384021\n",
      "====================================================================================================\n",
      "Iteration:  733\n",
      "Previous theta :  [ 0.00077667 -0.09286943  0.08805782  0.02793908  0.05843978 -0.24816344\n",
      "  0.34830751  0.00123981 -0.31973231  0.25681643 -0.18967028 -0.2293068\n",
      "  0.10476843 -0.3666515 ]\n",
      "New theta_0 : [ 0.00077518 -0.09288255  0.08809104  0.02796953  0.05843693 -0.24822748\n",
      "  0.34829053  0.00124383 -0.31979541  0.25690318 -0.18975013 -0.22931297\n",
      "  0.10476536 -0.36665731]\n",
      "Training Error:  10.49643304957208\n",
      "====================================================================================================\n",
      "Iteration:  734\n",
      "Previous theta :  [ 0.00077518 -0.09288255  0.08809104  0.02796953  0.05843693 -0.24822748\n",
      "  0.34829053  0.00124383 -0.31979541  0.25690318 -0.18975013 -0.22931297\n",
      "  0.10476536 -0.36665731]\n",
      "New theta_0 : [ 0.00077369 -0.09289561  0.08812409  0.02799994  0.05843408 -0.24829112\n",
      "  0.34827365  0.00124784 -0.31985808  0.25698967 -0.18982983 -0.2293191\n",
      "  0.10476232 -0.36666309]\n",
      "Training Error:  10.496410292461993\n",
      "====================================================================================================\n",
      "Iteration:  735\n",
      "Previous theta :  [ 0.00077369 -0.09289561  0.08812409  0.02799994  0.05843408 -0.24829112\n",
      "  0.34827365  0.00124784 -0.31985808  0.25698967 -0.18982983 -0.2293191\n",
      "  0.10476232 -0.36666309]\n",
      "New theta_0 : [ 0.00077222 -0.09290859  0.08815697  0.02803029  0.05843123 -0.24835436\n",
      "  0.34825687  0.00125183 -0.31992033  0.25707591 -0.18990938 -0.2293252\n",
      "  0.1047593  -0.36666884]\n",
      "Training Error:  10.49638771623328\n",
      "====================================================================================================\n",
      "Iteration:  736\n",
      "Previous theta :  [ 0.00077222 -0.09290859  0.08815697  0.02803029  0.05843123 -0.24835436\n",
      "  0.34825687  0.00125183 -0.31992033  0.25707591 -0.18990938 -0.2293252\n",
      "  0.1047593  -0.36666884]\n",
      "New theta_0 : [ 0.00077075 -0.09292151  0.08818969  0.02806058  0.05842838 -0.2484172\n",
      "  0.3482402   0.00125582 -0.31998214  0.25716189 -0.18998877 -0.22933126\n",
      "  0.10475631 -0.36667455]\n",
      "Training Error:  10.49636531908712\n",
      "====================================================================================================\n",
      "Iteration:  737\n",
      "Previous theta :  [ 0.00077075 -0.09292151  0.08818969  0.02806058  0.05842838 -0.2484172\n",
      "  0.3482402   0.00125582 -0.31998214  0.25716189 -0.18998877 -0.22933126\n",
      "  0.10475631 -0.36667455]\n",
      "New theta_0 : [ 0.0007693  -0.09293437  0.08822224  0.02809082  0.05842552 -0.24847963\n",
      "  0.34822363  0.00125979 -0.32004354  0.25724762 -0.19006801 -0.22933729\n",
      "  0.10475334 -0.36668023]\n",
      "Training Error:  10.496343099246074\n",
      "====================================================================================================\n",
      "Iteration:  738\n",
      "Previous theta :  [ 0.0007693  -0.09293437  0.08822224  0.02809082  0.05842552 -0.24847963\n",
      "  0.34822363  0.00125979 -0.32004354  0.25724762 -0.19006801 -0.22933729\n",
      "  0.10475334 -0.36668023]\n",
      "New theta_0 : [ 0.00076786 -0.09294717  0.08825463  0.02812101  0.05842267 -0.24854168\n",
      "  0.34820716  0.00126376 -0.32010452  0.2573331  -0.19014709 -0.22934329\n",
      "  0.10475041 -0.36668588]\n",
      "Training Error:  10.496321054953802\n",
      "====================================================================================================\n",
      "Iteration:  739\n",
      "Previous theta :  [ 0.00076786 -0.09294717  0.08825463  0.02812101  0.05842267 -0.24854168\n",
      "  0.34820716  0.00126376 -0.32010452  0.2573331  -0.19014709 -0.22934329\n",
      "  0.10475041 -0.36668588]\n",
      "New theta_0 : [ 0.00076642 -0.0929599   0.08828686  0.02815114  0.05841982 -0.24860332\n",
      "  0.34819079  0.00126772 -0.32016508  0.25741833 -0.19022602 -0.22934925\n",
      "  0.10474749 -0.36669149]\n",
      "Training Error:  10.49629918447479\n",
      "====================================================================================================\n",
      "Iteration:  740\n",
      "Previous theta :  [ 0.00076642 -0.0929599   0.08828686  0.02815114  0.05841982 -0.24860332\n",
      "  0.34819079  0.00126772 -0.32016508  0.25741833 -0.19022602 -0.22934925\n",
      "  0.10474749 -0.36669149]\n",
      "New theta_0 : [ 0.000765   -0.09297256  0.08831892  0.02818121  0.05841697 -0.24866458\n",
      "  0.34817452  0.00127166 -0.32022522  0.2575033  -0.1903048  -0.22935518\n",
      "  0.10474461 -0.36669708]\n",
      "Training Error:  10.496277486094066\n",
      "====================================================================================================\n",
      "Iteration:  741\n",
      "Previous theta :  [ 0.000765   -0.09297256  0.08831892  0.02818121  0.05841697 -0.24866458\n",
      "  0.34817452  0.00127166 -0.32022522  0.2575033  -0.1903048  -0.22935518\n",
      "  0.10474461 -0.36669708]\n",
      "New theta_0 : [ 0.00076358 -0.09298517  0.08835082  0.02821124  0.05841412 -0.24872545\n",
      "  0.34815834  0.0012756  -0.32028496  0.25758802 -0.19038342 -0.22936107\n",
      "  0.10474175 -0.36670263]\n",
      "Training Error:  10.496255958116937\n",
      "====================================================================================================\n",
      "Iteration:  742\n",
      "Previous theta :  [ 0.00076358 -0.09298517  0.08835082  0.02821124  0.05841412 -0.24872545\n",
      "  0.34815834  0.0012756  -0.32028496  0.25758802 -0.19038342 -0.22936107\n",
      "  0.10474175 -0.36670263]\n",
      "New theta_0 : [ 0.00076218 -0.09299771  0.08838257  0.0282412   0.05841127 -0.24878594\n",
      "  0.34814227  0.00127953 -0.32034429  0.2576725  -0.19046189 -0.22936693\n",
      "  0.10473891 -0.36670814]\n",
      "Training Error:  10.496234598868723\n",
      "====================================================================================================\n",
      "Iteration:  743\n",
      "Previous theta :  [ 0.00076218 -0.09299771  0.08838257  0.0282412   0.05841127 -0.24878594\n",
      "  0.34814227  0.00127953 -0.32034429  0.2576725  -0.19046189 -0.22936693\n",
      "  0.10473891 -0.36670814]\n",
      "New theta_0 : [ 0.00076078 -0.09301019  0.08841415  0.02827111  0.05840843 -0.24884605\n",
      "  0.34812629  0.00128344 -0.32040321  0.25775673 -0.19054021 -0.22937276\n",
      "  0.1047361  -0.36671363]\n",
      "Training Error:  10.496213406694498\n",
      "====================================================================================================\n",
      "Iteration:  744\n",
      "Previous theta :  [ 0.00076078 -0.09301019  0.08841415  0.02827111  0.05840843 -0.24884605\n",
      "  0.34812629  0.00128344 -0.32040321  0.25775673 -0.19054021 -0.22937276\n",
      "  0.1047361  -0.36671363]\n",
      "New theta_0 : [ 0.0007594  -0.09302261  0.08844557  0.02830097  0.05840558 -0.24890577\n",
      "  0.3481104   0.00128735 -0.32046174  0.2578407  -0.19061837 -0.22937855\n",
      "  0.10473332 -0.36671908]\n",
      "Training Error:  10.496192379958813\n",
      "====================================================================================================\n",
      "Iteration:  745\n",
      "Previous theta :  [ 0.0007594  -0.09302261  0.08844557  0.02830097  0.05840558 -0.24890577\n",
      "  0.3481104   0.00128735 -0.32046174  0.2578407  -0.19061837 -0.22937855\n",
      "  0.10473332 -0.36671908]\n",
      "New theta_0 : [ 0.00075802 -0.09303497  0.08847684  0.02833077  0.05840273 -0.24896512\n",
      "  0.34809462  0.00129125 -0.32051986  0.25792444 -0.19069637 -0.22938432\n",
      "  0.10473056 -0.36672451]\n",
      "Training Error:  10.49617151704547\n",
      "====================================================================================================\n",
      "Iteration:  746\n",
      "Previous theta :  [ 0.00075802 -0.09303497  0.08847684  0.02833077  0.05840273 -0.24896512\n",
      "  0.34809462  0.00129125 -0.32051986  0.25792444 -0.19069637 -0.22938432\n",
      "  0.10473056 -0.36672451]\n",
      "New theta_0 : [ 0.00075666 -0.09304726  0.08850795  0.02836051  0.05839988 -0.24902409\n",
      "  0.34807892  0.00129513 -0.32057759  0.25800792 -0.19077423 -0.22939005\n",
      "  0.10472782 -0.3667299 ]\n",
      "Training Error:  10.496150816357243\n",
      "====================================================================================================\n",
      "Iteration:  747\n",
      "Previous theta :  [ 0.00075666 -0.09304726  0.08850795  0.02836051  0.05839988 -0.24902409\n",
      "  0.34807892  0.00129513 -0.32057759  0.25800792 -0.19077423 -0.22939005\n",
      "  0.10472782 -0.3667299 ]\n",
      "New theta_0 : [ 0.0007553  -0.0930595   0.08853891  0.0283902   0.05839704 -0.24908269\n",
      "  0.34806332  0.00129901 -0.32063492  0.25809117 -0.19085193 -0.22939574\n",
      "  0.10472511 -0.36673527]\n",
      "Training Error:  10.49613027631565\n",
      "====================================================================================================\n",
      "Iteration:  748\n",
      "Previous theta :  [ 0.0007553  -0.0930595   0.08853891  0.0283902   0.05839704 -0.24908269\n",
      "  0.34806332  0.00129901 -0.32063492  0.25809117 -0.19085193 -0.22939574\n",
      "  0.10472511 -0.36673527]\n",
      "New theta_0 : [ 0.00075395 -0.09307167  0.08856971  0.02841983  0.05839419 -0.24914092\n",
      "  0.34804782  0.00130288 -0.32069187  0.25817416 -0.19092947 -0.22940141\n",
      "  0.10472242 -0.3667406 ]\n",
      "Training Error:  10.496109895360693\n",
      "====================================================================================================\n",
      "Iteration:  749\n",
      "Previous theta :  [ 0.00075395 -0.09307167  0.08856971  0.02841983  0.05839419 -0.24914092\n",
      "  0.34804782  0.00130288 -0.32069187  0.25817416 -0.19092947 -0.22940141\n",
      "  0.10472242 -0.3667406 ]\n",
      "New theta_0 : [ 0.00075261 -0.09308379  0.08860036  0.02844941  0.05839135 -0.24919878\n",
      "  0.3480324   0.00130674 -0.32074842  0.25825692 -0.19100686 -0.22940704\n",
      "  0.10471976 -0.3667459 ]\n",
      "Training Error:  10.496089671950621\n",
      "====================================================================================================\n",
      "Iteration:  750\n",
      "Previous theta :  [ 0.00075261 -0.09308379  0.08860036  0.02844941  0.05839135 -0.24919878\n",
      "  0.3480324   0.00130674 -0.32074842  0.25825692 -0.19100686 -0.22940704\n",
      "  0.10471976 -0.3667459 ]\n",
      "New theta_0 : [ 0.00075128 -0.09309584  0.08863085  0.02847893  0.0583885  -0.24925628\n",
      "  0.34801708  0.00131059 -0.32080459  0.25833943 -0.1910841  -0.22941265\n",
      "  0.10471712 -0.36675118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.496069604561697\n",
      "====================================================================================================\n",
      "Iteration:  751\n",
      "Previous theta :  [ 0.00075128 -0.09309584  0.08863085  0.02847893  0.0583885  -0.24925628\n",
      "  0.34801708  0.00131059 -0.32080459  0.25833943 -0.1910841  -0.22941265\n",
      "  0.10471712 -0.36675118]\n",
      "New theta_0 : [ 0.00074996 -0.09310784  0.08866119  0.0285084   0.05838566 -0.24931342\n",
      "  0.34800185  0.00131443 -0.32086038  0.2584217  -0.19116118 -0.22941822\n",
      "  0.1047145  -0.36675642]\n",
      "Training Error:  10.496049691687961\n",
      "====================================================================================================\n",
      "Iteration:  752\n",
      "Previous theta :  [ 0.00074996 -0.09310784  0.08866119  0.0285084   0.05838566 -0.24931342\n",
      "  0.34800185  0.00131443 -0.32086038  0.2584217  -0.19116118 -0.22941822\n",
      "  0.1047145  -0.36675642]\n",
      "New theta_0 : [ 0.00074865 -0.09311977  0.08869138  0.0285378   0.05838282 -0.24937019\n",
      "  0.34798671  0.00131826 -0.32091579  0.25850373 -0.19123811 -0.22942376\n",
      "  0.10471191 -0.36676164]\n",
      "Training Error:  10.496029931840997\n",
      "====================================================================================================\n",
      "Iteration:  753\n",
      "Previous theta :  [ 0.00074865 -0.09311977  0.08869138  0.0285378   0.05838282 -0.24937019\n",
      "  0.34798671  0.00131826 -0.32091579  0.25850373 -0.19123811 -0.22942376\n",
      "  0.10471191 -0.36676164]\n",
      "New theta_0 : [ 0.00074735 -0.09313165  0.08872143  0.02856716  0.05837998 -0.24942661\n",
      "  0.34797166  0.00132208 -0.32097082  0.25858552 -0.19131488 -0.22942927\n",
      "  0.10470934 -0.36676683]\n",
      "Training Error:  10.4960103235497\n",
      "====================================================================================================\n",
      "Iteration:  754\n",
      "Previous theta :  [ 0.00074735 -0.09313165  0.08872143  0.02856716  0.05837998 -0.24942661\n",
      "  0.34797166  0.00132208 -0.32097082  0.25858552 -0.19131488 -0.22942927\n",
      "  0.10470934 -0.36676683]\n",
      "New theta_0 : [ 0.00074605 -0.09314347  0.08875132  0.02859646  0.05837714 -0.24948268\n",
      "  0.3479567   0.00132589 -0.32102548  0.25866707 -0.1913915  -0.22943475\n",
      "  0.1047068  -0.36677198]\n",
      "Training Error:  10.495990865360058\n",
      "====================================================================================================\n",
      "Iteration:  755\n",
      "Previous theta :  [ 0.00074605 -0.09314347  0.08875132  0.02859646  0.05837714 -0.24948268\n",
      "  0.3479567   0.00132589 -0.32102548  0.25866707 -0.1913915  -0.22943475\n",
      "  0.1047068  -0.36677198]\n",
      "New theta_0 : [ 0.00074477 -0.09315524  0.08878106  0.0286257   0.0583743  -0.24953839\n",
      "  0.34794183  0.0013297  -0.32107976  0.25874838 -0.19146797 -0.2294402\n",
      "  0.10470427 -0.36677711]\n",
      "Training Error:  10.49597155583493\n",
      "====================================================================================================\n",
      "Iteration:  756\n",
      "Previous theta :  [ 0.00074477 -0.09315524  0.08878106  0.0286257   0.0583743  -0.24953839\n",
      "  0.34794183  0.0013297  -0.32107976  0.25874838 -0.19146797 -0.2294402\n",
      "  0.10470427 -0.36677711]\n",
      "New theta_0 : [ 0.00074349 -0.09316694  0.08881066  0.02865488  0.05837146 -0.24959375\n",
      "  0.34792705  0.00133349 -0.32113368  0.25882945 -0.19154428 -0.22944561\n",
      "  0.10470177 -0.36678222]\n",
      "Training Error:  10.495952393553809\n",
      "====================================================================================================\n",
      "Iteration:  757\n",
      "Previous theta :  [ 0.00074349 -0.09316694  0.08881066  0.02865488  0.05837146 -0.24959375\n",
      "  0.34792705  0.00133349 -0.32113368  0.25882945 -0.19154428 -0.22944561\n",
      "  0.10470177 -0.36678222]\n",
      "New theta_0 : [ 0.00074223 -0.09317859  0.08884011  0.02868401  0.05836862 -0.24964876\n",
      "  0.34791235  0.00133728 -0.32118723  0.25891029 -0.19162044 -0.229451\n",
      "  0.10469929 -0.36678729]\n",
      "Training Error:  10.495933377112642\n",
      "====================================================================================================\n",
      "Iteration:  758\n",
      "Previous theta :  [ 0.00074223 -0.09317859  0.08884011  0.02868401  0.05836862 -0.24964876\n",
      "  0.34791235  0.00133728 -0.32118723  0.25891029 -0.19162044 -0.229451\n",
      "  0.10469929 -0.36678729]\n",
      "New theta_0 : [ 0.00074097 -0.09319018  0.08886942  0.02871308  0.05836579 -0.24970343\n",
      "  0.34789774  0.00134105 -0.32124042  0.25899089 -0.19169644 -0.22945636\n",
      "  0.10469684 -0.36679234]\n",
      "Training Error:  10.495914505123581\n",
      "====================================================================================================\n",
      "Iteration:  759\n",
      "Previous theta :  [ 0.00074097 -0.09319018  0.08886942  0.02871308  0.05836579 -0.24970343\n",
      "  0.34789774  0.00134105 -0.32124042  0.25899089 -0.19169644 -0.22945636\n",
      "  0.10469684 -0.36679234]\n",
      "New theta_0 : [ 0.00073972 -0.09320172  0.08889858  0.02874209  0.05836296 -0.24975775\n",
      "  0.34788322  0.00134482 -0.32129324  0.25907126 -0.1917723  -0.22946169\n",
      "  0.1046944  -0.36679736]\n",
      "Training Error:  10.495895776214791\n",
      "====================================================================================================\n",
      "Iteration:  760\n",
      "Previous theta :  [ 0.00073972 -0.09320172  0.08889858  0.02874209  0.05836296 -0.24975775\n",
      "  0.34788322  0.00134482 -0.32129324  0.25907126 -0.1917723  -0.22946169\n",
      "  0.1046944  -0.36679736]\n",
      "New theta_0 : [ 0.00073848 -0.09321319  0.08892759  0.02877105  0.05836012 -0.24981173\n",
      "  0.34786878  0.00134858 -0.3213457   0.25915139 -0.19184799 -0.22946698\n",
      "  0.10469199 -0.36680235]\n",
      "Training Error:  10.495877189030233\n",
      "====================================================================================================\n",
      "Iteration:  761\n",
      "Previous theta :  [ 0.00073848 -0.09321319  0.08892759  0.02877105  0.05836012 -0.24981173\n",
      "  0.34786878  0.00134858 -0.3213457   0.25915139 -0.19184799 -0.22946698\n",
      "  0.10469199 -0.36680235]\n",
      "New theta_0 : [ 0.00073724 -0.09322462  0.08895647  0.02879996  0.05835729 -0.24986538\n",
      "  0.34785442  0.00135233 -0.32139781  0.25923129 -0.19192354 -0.22947225\n",
      "  0.1046896  -0.36680732]\n",
      "Training Error:  10.495858742229473\n",
      "====================================================================================================\n",
      "Iteration:  762\n",
      "Previous theta :  [ 0.00073724 -0.09322462  0.08895647  0.02879996  0.05835729 -0.24986538\n",
      "  0.34785442  0.00135233 -0.32139781  0.25923129 -0.19192354 -0.22947225\n",
      "  0.1046896  -0.36680732]\n",
      "New theta_0 : [ 0.00073602 -0.09323598  0.0889852   0.0288288   0.05835446 -0.24991869\n",
      "  0.34784016  0.00135607 -0.32144957  0.25931095 -0.19199893 -0.22947749\n",
      "  0.10468723 -0.36681226]\n",
      "Training Error:  10.49584043448747\n",
      "====================================================================================================\n",
      "Iteration:  763\n",
      "Previous theta :  [ 0.00073602 -0.09323598  0.0889852   0.0288288   0.05835446 -0.24991869\n",
      "  0.34784016  0.00135607 -0.32144957  0.25931095 -0.19199893 -0.22947749\n",
      "  0.10468723 -0.36681226]\n",
      "New theta_0 : [ 0.0007348  -0.0932473   0.08901379  0.02885759  0.05835163 -0.24997166\n",
      "  0.34782597  0.0013598  -0.32150097  0.25939039 -0.19207416 -0.2294827\n",
      "  0.10468489 -0.36681717]\n",
      "Training Error:  10.495822264494372\n",
      "====================================================================================================\n",
      "Iteration:  764\n",
      "Previous theta :  [ 0.0007348  -0.0932473   0.08901379  0.02885759  0.05835163 -0.24997166\n",
      "  0.34782597  0.0013598  -0.32150097  0.25939039 -0.19207416 -0.2294827\n",
      "  0.10468489 -0.36681717]\n",
      "New theta_0 : [ 0.00073359 -0.09325855  0.08904224  0.02888632  0.05834881 -0.2500243\n",
      "  0.34781187  0.00136352 -0.32155203  0.25946959 -0.19214925 -0.22948789\n",
      "  0.10468256 -0.36682206]\n",
      "Training Error:  10.495804230955333\n",
      "====================================================================================================\n",
      "Iteration:  765\n",
      "Previous theta :  [ 0.00073359 -0.09325855  0.08904224  0.02888632  0.05834881 -0.2500243\n",
      "  0.34781187  0.00136352 -0.32155203  0.25946959 -0.19214925 -0.22948789\n",
      "  0.10468256 -0.36682206]\n",
      "New theta_0 : [ 0.0007324  -0.09326976  0.08907055  0.028915    0.05834598 -0.25007661\n",
      "  0.34779785  0.00136723 -0.32160273  0.25954856 -0.19222418 -0.22949304\n",
      "  0.10468026 -0.36682692]\n",
      "Training Error:  10.495786332590313\n",
      "====================================================================================================\n",
      "Iteration:  766\n",
      "Previous theta :  [ 0.0007324  -0.09326976  0.08907055  0.028915    0.05834598 -0.25007661\n",
      "  0.34779785  0.00136723 -0.32160273  0.25954856 -0.19222418 -0.22949304\n",
      "  0.10468026 -0.36682692]\n",
      "New theta_0 : [ 0.0007312  -0.09328091  0.08909872  0.02894361  0.05834316 -0.25012859\n",
      "  0.34778391  0.00137094 -0.3216531   0.2596273  -0.19229895 -0.22949816\n",
      "  0.10467797 -0.36683176]\n",
      "Training Error:  10.495768568133887\n",
      "====================================================================================================\n",
      "Iteration:  767\n",
      "Previous theta :  [ 0.0007312  -0.09328091  0.08909872  0.02894361  0.05834316 -0.25012859\n",
      "  0.34778391  0.00137094 -0.3216531   0.2596273  -0.19229895 -0.22949816\n",
      "  0.10467797 -0.36683176]\n",
      "New theta_0 : [ 0.00073002 -0.093292    0.08912675  0.02897217  0.05834034 -0.25018025\n",
      "  0.34777005  0.00137464 -0.32170312  0.25970581 -0.19237358 -0.22950326\n",
      "  0.10467571 -0.36683657]\n",
      "Training Error:  10.495750936335055\n",
      "====================================================================================================\n",
      "Iteration:  768\n",
      "Previous theta :  [ 0.00073002 -0.093292    0.08912675  0.02897217  0.05834034 -0.25018025\n",
      "  0.34777005  0.00137464 -0.32170312  0.25970581 -0.19237358 -0.22950326\n",
      "  0.10467571 -0.36683657]\n",
      "New theta_0 : [ 0.00072885 -0.09330304  0.08915465  0.02900068  0.05833752 -0.25023158\n",
      "  0.34775628  0.00137832 -0.3217528   0.25978409 -0.19244805 -0.22950833\n",
      "  0.10467347 -0.36684136]\n",
      "Training Error:  10.495733435957057\n",
      "====================================================================================================\n",
      "Iteration:  769\n",
      "Previous theta :  [ 0.00072885 -0.09330304  0.08915465  0.02900068  0.05833752 -0.25023158\n",
      "  0.34775628  0.00137832 -0.3217528   0.25978409 -0.19244805 -0.22950833\n",
      "  0.10467347 -0.36684136]\n",
      "New theta_0 : [ 0.00072768 -0.09331403  0.0891824   0.02902912  0.0583347  -0.2502826\n",
      "  0.34774258  0.001382   -0.32180215  0.25986215 -0.19252236 -0.22951337\n",
      "  0.10467124 -0.36684612]\n",
      "Training Error:  10.495716065777193\n",
      "====================================================================================================\n",
      "Iteration:  770\n",
      "Previous theta :  [ 0.00072768 -0.09331403  0.0891824   0.02902912  0.0583347  -0.2502826\n",
      "  0.34774258  0.001382   -0.32180215  0.25986215 -0.19252236 -0.22951337\n",
      "  0.10467124 -0.36684612]\n",
      "New theta_0 : [ 0.00072652 -0.09332497  0.08921003  0.02905751  0.05833188 -0.25033329\n",
      "  0.34772897  0.00138567 -0.32185116  0.25993998 -0.19259653 -0.22951838\n",
      "  0.10466904 -0.36685085]\n",
      "Training Error:  10.495698824586642\n",
      "====================================================================================================\n",
      "Iteration:  771\n",
      "Previous theta :  [ 0.00072652 -0.09332497  0.08921003  0.02905751  0.05833188 -0.25033329\n",
      "  0.34772897  0.00138567 -0.32185116  0.25993998 -0.19259653 -0.22951838\n",
      "  0.10466904 -0.36685085]\n",
      "New theta_0 : [ 0.00072537 -0.09333585  0.08923752  0.02908585  0.05832906 -0.25038367\n",
      "  0.34771543  0.00138934 -0.32189984  0.26001758 -0.19267054 -0.22952337\n",
      "  0.10466686 -0.36685556]\n",
      "Training Error:  10.495681711190276\n",
      "====================================================================================================\n",
      "Iteration:  772\n",
      "Previous theta :  [ 0.00072537 -0.09333585  0.08923752  0.02908585  0.05832906 -0.25038367\n",
      "  0.34771543  0.00138934 -0.32189984  0.26001758 -0.19267054 -0.22952337\n",
      "  0.10466686 -0.36685556]\n",
      "New theta_0 : [ 0.00072422 -0.09334668  0.08926487  0.02911412  0.05832625 -0.25043373\n",
      "  0.34770197  0.00139299 -0.32194819  0.26009496 -0.1927444  -0.22952833\n",
      "  0.1046647  -0.36686025]\n",
      "Training Error:  10.495664724406494\n",
      "====================================================================================================\n",
      "Iteration:  773\n",
      "Previous theta :  [ 0.00072422 -0.09334668  0.08926487  0.02911412  0.05832625 -0.25043373\n",
      "  0.34770197  0.00139299 -0.32194819  0.26009496 -0.1927444  -0.22952833\n",
      "  0.1046647  -0.36686025]\n",
      "New theta_0 : [ 0.00072309 -0.09335746  0.08929209  0.02914234  0.05832344 -0.25048348\n",
      "  0.34768859  0.00139664 -0.32199621  0.26017211 -0.1928181  -0.22953326\n",
      "  0.10466255 -0.36686492]\n",
      "Training Error:  10.495647863067045\n",
      "====================================================================================================\n",
      "Iteration:  774\n",
      "Previous theta :  [ 0.00072309 -0.09335746  0.08929209  0.02914234  0.05832344 -0.25048348\n",
      "  0.34768859  0.00139664 -0.32199621  0.26017211 -0.1928181  -0.22953326\n",
      "  0.10466255 -0.36686492]\n",
      "New theta_0 : [ 0.00072196 -0.09336818  0.08931918  0.0291705   0.05832063 -0.25053292\n",
      "  0.34767528  0.00140027 -0.3220439   0.26024904 -0.19289165 -0.22953816\n",
      "  0.10466043 -0.36686955]\n",
      "Training Error:  10.495631126016853\n",
      "====================================================================================================\n",
      "Iteration:  775\n",
      "Previous theta :  [ 0.00072196 -0.09336818  0.08931918  0.0291705   0.05832063 -0.25053292\n",
      "  0.34767528  0.00140027 -0.3220439   0.26024904 -0.19289165 -0.22953816\n",
      "  0.10466043 -0.36686955]\n",
      "New theta_0 : [ 0.00072084 -0.09337886  0.08934614  0.02919861  0.05831782 -0.25058205\n",
      "  0.34766206  0.0014039  -0.32209128  0.26032575 -0.19296505 -0.22954304\n",
      "  0.10465833 -0.36687417]\n",
      "Training Error:  10.495614512113855\n",
      "====================================================================================================\n",
      "Iteration:  776\n",
      "Previous theta :  [ 0.00072084 -0.09337886  0.08934614  0.02919861  0.05831782 -0.25058205\n",
      "  0.34766206  0.0014039  -0.32209128  0.26032575 -0.19296505 -0.22954304\n",
      "  0.10465833 -0.36687417]\n",
      "New theta_0 : [ 0.00071973 -0.09338948  0.08937297  0.02922666  0.05831501 -0.25063088\n",
      "  0.3476489   0.00140752 -0.32213833  0.26040223 -0.1930383  -0.22954789\n",
      "  0.10465624 -0.36687876]\n",
      "Training Error:  10.495598020228831\n",
      "====================================================================================================\n",
      "Iteration:  777\n",
      "Previous theta :  [ 0.00071973 -0.09338948  0.08937297  0.02922666  0.05831501 -0.25063088\n",
      "  0.3476489   0.00140752 -0.32213833  0.26040223 -0.1930383  -0.22954789\n",
      "  0.10465624 -0.36687876]\n",
      "New theta_0 : [ 0.00071862 -0.09340006  0.08939966  0.02925464  0.05831221 -0.2506794\n",
      "  0.34763583  0.00141114 -0.32218506  0.2604785  -0.19311139 -0.22955271\n",
      "  0.10465418 -0.36688333]\n",
      "Training Error:  10.49558164924524\n",
      "====================================================================================================\n",
      "Iteration:  778\n",
      "Previous theta :  [ 0.00071862 -0.09340006  0.08939966  0.02925464  0.05831221 -0.2506794\n",
      "  0.34763583  0.00141114 -0.32218506  0.2604785  -0.19311139 -0.22955271\n",
      "  0.10465418 -0.36688333]\n",
      "New theta_0 : [ 0.00071752 -0.09341058  0.08942623  0.02928258  0.05830941 -0.25072762\n",
      "  0.34762283  0.00141474 -0.32223148  0.26055454 -0.19318433 -0.22955751\n",
      "  0.10465213 -0.36688788]\n",
      "Training Error:  10.495565398059059\n",
      "====================================================================================================\n",
      "Iteration:  779\n",
      "Previous theta :  [ 0.00071752 -0.09341058  0.08942623  0.02928258  0.05830941 -0.25072762\n",
      "  0.34762283  0.00141474 -0.32223148  0.26055454 -0.19318433 -0.22955751\n",
      "  0.10465213 -0.36688788]\n",
      "New theta_0 : [ 0.00071643 -0.09342105  0.08945267  0.02931045  0.05830661 -0.25077553\n",
      "  0.3476099   0.00141834 -0.32227758  0.26063036 -0.19325712 -0.22956228\n",
      "  0.1046501  -0.3668924 ]\n",
      "Training Error:  10.495549265578616\n",
      "====================================================================================================\n",
      "Iteration:  780\n",
      "Previous theta :  [ 0.00071643 -0.09342105  0.08945267  0.02931045  0.05830661 -0.25077553\n",
      "  0.3476099   0.00141834 -0.32227758  0.26063036 -0.19325712 -0.22956228\n",
      "  0.1046501  -0.3668924 ]\n",
      "New theta_0 : [ 0.00071535 -0.09343148  0.08947898  0.02933827  0.05830381 -0.25082315\n",
      "  0.34759705  0.00142193 -0.32232337  0.26070596 -0.19332976 -0.22956703\n",
      "  0.10464809 -0.3668969 ]\n",
      "Training Error:  10.495533250724446\n",
      "====================================================================================================\n",
      "Iteration:  781\n",
      "Previous theta :  [ 0.00071535 -0.09343148  0.08947898  0.02933827  0.05830381 -0.25082315\n",
      "  0.34759705  0.00142193 -0.32232337  0.26070596 -0.19332976 -0.22956703\n",
      "  0.10464809 -0.3668969 ]\n",
      "New theta_0 : [ 0.00071428 -0.09344185  0.08950516  0.02936603  0.05830101 -0.25087048\n",
      "  0.34758427  0.00142551 -0.32236886  0.26078134 -0.19340224 -0.22957175\n",
      "  0.1046461  -0.36690138]\n",
      "Training Error:  10.495517352429129\n",
      "====================================================================================================\n",
      "Iteration:  782\n",
      "Previous theta :  [ 0.00071428 -0.09344185  0.08950516  0.02936603  0.05830101 -0.25087048\n",
      "  0.34758427  0.00142551 -0.32236886  0.26078134 -0.19340224 -0.22957175\n",
      "  0.1046461  -0.36690138]\n",
      "New theta_0 : [ 0.00071321 -0.09345218  0.08953122  0.02939373  0.05829822 -0.2509175\n",
      "  0.34757157  0.00142908 -0.32241403  0.26085651 -0.19347458 -0.22957644\n",
      "  0.10464413 -0.36690584]\n",
      "Training Error:  10.495501569637131\n",
      "====================================================================================================\n",
      "Iteration:  783\n",
      "Previous theta :  [ 0.00071321 -0.09345218  0.08953122  0.02939373  0.05829822 -0.2509175\n",
      "  0.34757157  0.00142908 -0.32241403  0.26085651 -0.19347458 -0.22957644\n",
      "  0.10464413 -0.36690584]\n",
      "New theta_0 : [ 0.00071215 -0.09346245  0.08955715  0.02942138  0.05829543 -0.25096424\n",
      "  0.34755893  0.00143264 -0.3224589   0.26093146 -0.19354676 -0.22958111\n",
      "  0.10464217 -0.36691027]\n",
      "Training Error:  10.495485901304662\n",
      "====================================================================================================\n",
      "Iteration:  784\n",
      "Previous theta :  [ 0.00071215 -0.09346245  0.08955715  0.02942138  0.05829543 -0.25096424\n",
      "  0.34755893  0.00143264 -0.3224589   0.26093146 -0.19354676 -0.22958111\n",
      "  0.10464217 -0.36691027]\n",
      "New theta_0 : [ 0.00071109 -0.09347268  0.08958296  0.02944897  0.05829264 -0.25101069\n",
      "  0.34754637  0.0014362  -0.32250346  0.26100619 -0.19361878 -0.22958575\n",
      "  0.10464024 -0.36691468]\n",
      "Training Error:  10.495470346399522\n",
      "====================================================================================================\n",
      "Iteration:  785\n",
      "Previous theta :  [ 0.00071109 -0.09347268  0.08958296  0.02944897  0.05829264 -0.25101069\n",
      "  0.34754637  0.0014362  -0.32250346  0.26100619 -0.19361878 -0.22958575\n",
      "  0.10464024 -0.36691468]\n",
      "New theta_0 : [ 0.00071005 -0.09348285  0.08960864  0.0294765   0.05828985 -0.25105684\n",
      "  0.34753388  0.00143974 -0.32254773  0.2610807  -0.19369066 -0.22959037\n",
      "  0.10463832 -0.36691907]\n",
      "Training Error:  10.495454903900958\n",
      "====================================================================================================\n",
      "Iteration:  786\n",
      "Previous theta :  [ 0.00071005 -0.09348285  0.08960864  0.0294765   0.05828985 -0.25105684\n",
      "  0.34753388  0.00143974 -0.32254773  0.2610807  -0.19369066 -0.22959037\n",
      "  0.10463832 -0.36691907]\n",
      "New theta_0 : [ 0.00070901 -0.09349298  0.0896342   0.02950397  0.05828707 -0.25110271\n",
      "  0.34752147  0.00144329 -0.32259169  0.261155   -0.19376239 -0.22959496\n",
      "  0.10463642 -0.36692344]\n",
      "Training Error:  10.495439572799507\n",
      "====================================================================================================\n",
      "Iteration:  787\n",
      "Previous theta :  [ 0.00070901 -0.09349298  0.0896342   0.02950397  0.05828707 -0.25110271\n",
      "  0.34752147  0.00144329 -0.32259169  0.261155   -0.19376239 -0.22959496\n",
      "  0.10463642 -0.36692344]\n",
      "New theta_0 : [ 0.00070798 -0.09350307  0.08965964  0.02953139  0.05828429 -0.2511483\n",
      "  0.34750912  0.00144682 -0.32263536  0.26122909 -0.19383396 -0.22959953\n",
      "  0.10463454 -0.36692779]\n",
      "Training Error:  10.49542435209687\n",
      "====================================================================================================\n",
      "Iteration:  788\n",
      "Previous theta :  [ 0.00070798 -0.09350307  0.08965964  0.02953139  0.05828429 -0.2511483\n",
      "  0.34750912  0.00144682 -0.32263536  0.26122909 -0.19383396 -0.22959953\n",
      "  0.10463454 -0.36692779]\n",
      "New theta_0 : [ 0.00070695 -0.0935131   0.08968495  0.02955875  0.05828151 -0.2511936\n",
      "  0.34749684  0.00145034 -0.32267873  0.26130296 -0.19390538 -0.22960407\n",
      "  0.10463267 -0.36693212]\n",
      "Training Error:  10.49540924080576\n",
      "====================================================================================================\n",
      "Iteration:  789\n",
      "Previous theta :  [ 0.00070695 -0.0935131   0.08968495  0.02955875  0.05828151 -0.2511936\n",
      "  0.34749684  0.00145034 -0.32267873  0.26130296 -0.19390538 -0.22960407\n",
      "  0.10463267 -0.36693212]\n",
      "New theta_0 : [ 0.00070593 -0.09352309  0.08971015  0.02958605  0.05827873 -0.25123862\n",
      "  0.34748463  0.00145386 -0.32272182  0.26137662 -0.19397665 -0.22960859\n",
      "  0.10463082 -0.36693642]\n",
      "Training Error:  10.495394237949759\n",
      "====================================================================================================\n",
      "Iteration:  790\n",
      "Previous theta :  [ 0.00070593 -0.09352309  0.08971015  0.02958605  0.05827873 -0.25123862\n",
      "  0.34748463  0.00145386 -0.32272182  0.26137662 -0.19397665 -0.22960859\n",
      "  0.10463082 -0.36693642]\n",
      "New theta_0 : [ 0.00070492 -0.09353303  0.08973522  0.02961329  0.05827595 -0.25128337\n",
      "  0.34747249  0.00145737 -0.32276461  0.26145006 -0.19404777 -0.22961308\n",
      "  0.10462899 -0.36694071]\n",
      "Training Error:  10.495379342563197\n",
      "====================================================================================================\n",
      "Iteration:  791\n",
      "Previous theta :  [ 0.00070492 -0.09353303  0.08973522  0.02961329  0.05827595 -0.25128337\n",
      "  0.34747249  0.00145737 -0.32276461  0.26145006 -0.19404777 -0.22961308\n",
      "  0.10462899 -0.36694071]\n",
      "New theta_0 : [ 0.00070392 -0.09354292  0.08976017  0.02964048  0.05827318 -0.25132783\n",
      "  0.34746042  0.00146087 -0.32280711  0.2615233  -0.19411874 -0.22961755\n",
      "  0.10462717 -0.36694497]\n",
      "Training Error:  10.495364553691\n",
      "====================================================================================================\n",
      "Iteration:  792\n",
      "Previous theta :  [ 0.00070392 -0.09354292  0.08976017  0.02964048  0.05827318 -0.25132783\n",
      "  0.34746042  0.00146087 -0.32280711  0.2615233  -0.19411874 -0.22961755\n",
      "  0.10462717 -0.36694497]\n",
      "New theta_0 : [ 0.00070292 -0.09355277  0.08978501  0.02966761  0.05827041 -0.25137202\n",
      "  0.34744842  0.00146436 -0.32284932  0.26159632 -0.19418955 -0.229622\n",
      "  0.10462538 -0.36694922]\n",
      "Training Error:  10.49534987038856\n",
      "====================================================================================================\n",
      "Iteration:  793\n",
      "Previous theta :  [ 0.00070292 -0.09355277  0.08978501  0.02966761  0.05827041 -0.25137202\n",
      "  0.34744842  0.00146436 -0.32284932  0.26159632 -0.19418955 -0.229622\n",
      "  0.10462538 -0.36694922]\n",
      "New theta_0 : [ 0.00070193 -0.09356257  0.08980972  0.02969468  0.05826764 -0.25141594\n",
      "  0.34743648  0.00146785 -0.32289125  0.26166913 -0.19426022 -0.22962642\n",
      "  0.1046236  -0.36695344]\n",
      "Training Error:  10.495335291721611\n",
      "====================================================================================================\n",
      "Iteration:  794\n",
      "Previous theta :  [ 0.00070193 -0.09356257  0.08980972  0.02969468  0.05826764 -0.25141594\n",
      "  0.34743648  0.00146785 -0.32289125  0.26166913 -0.19426022 -0.22962642\n",
      "  0.1046236  -0.36695344]\n",
      "New theta_0 : [ 0.00070095 -0.09357232  0.08983432  0.0297217   0.05826487 -0.25145959\n",
      "  0.34742461  0.00147133 -0.3229329   0.26174173 -0.19433073 -0.22963082\n",
      "  0.10462183 -0.36695764]\n",
      "Training Error:  10.49532081676609\n",
      "====================================================================================================\n",
      "Iteration:  795\n",
      "Previous theta :  [ 0.00070095 -0.09357232  0.08983432  0.0297217   0.05826487 -0.25145959\n",
      "  0.34742461  0.00147133 -0.3229329   0.26174173 -0.19433073 -0.22963082\n",
      "  0.10462183 -0.36695764]\n",
      "New theta_0 : [ 0.00069997 -0.09358203  0.0898588   0.02974865  0.05826211 -0.25150296\n",
      "  0.34741281  0.0014748  -0.32297426  0.26181413 -0.1944011  -0.22963519\n",
      "  0.10462008 -0.36696183]\n",
      "Training Error:  10.495306444608012\n",
      "====================================================================================================\n",
      "Iteration:  796\n",
      "Previous theta :  [ 0.00069997 -0.09358203  0.0898588   0.02974865  0.05826211 -0.25150296\n",
      "  0.34741281  0.0014748  -0.32297426  0.26181413 -0.1944011  -0.22963519\n",
      "  0.10462008 -0.36696183]\n",
      "New theta_0 : [ 0.000699   -0.09359169  0.08988316  0.02977555  0.05825935 -0.25154607\n",
      "  0.34740107  0.00147826 -0.32301535  0.26188631 -0.19447131 -0.22963954\n",
      "  0.10461835 -0.36696599]\n",
      "Training Error:  10.495292174343346\n",
      "====================================================================================================\n",
      "Iteration:  797\n",
      "Previous theta :  [ 0.000699   -0.09359169  0.08988316  0.02977555  0.05825935 -0.25154607\n",
      "  0.34740107  0.00147826 -0.32301535  0.26188631 -0.19447131 -0.22963954\n",
      "  0.10461835 -0.36696599]\n",
      "New theta_0 : [ 0.00069803 -0.09360131  0.08990741  0.0298024   0.05825659 -0.25158891\n",
      "  0.3473894   0.00148171 -0.32305616  0.26195829 -0.19454138 -0.22964387\n",
      "  0.10461664 -0.36697013]\n",
      "Training Error:  10.49527800507788\n",
      "====================================================================================================\n",
      "Iteration:  798\n",
      "Previous theta :  [ 0.00069803 -0.09360131  0.08990741  0.0298024   0.05825659 -0.25158891\n",
      "  0.3473894   0.00148171 -0.32305616  0.26195829 -0.19454138 -0.22964387\n",
      "  0.10461664 -0.36697013]\n",
      "New theta_0 : [ 0.00069708 -0.09361088  0.08993155  0.02982918  0.05825384 -0.25163149\n",
      "  0.3473778   0.00148516 -0.3230967   0.26203006 -0.19461129 -0.22964817\n",
      "  0.10461494 -0.36697426]\n",
      "Training Error:  10.495263935927118\n",
      "====================================================================================================\n",
      "Iteration:  799\n",
      "Previous theta :  [ 0.00069708 -0.09361088  0.08993155  0.02982918  0.05825384 -0.25163149\n",
      "  0.3473778   0.00148516 -0.3230967   0.26203006 -0.19461129 -0.22964817\n",
      "  0.10461494 -0.36697426]\n",
      "New theta_0 : [ 0.00069612 -0.09362041  0.08995556  0.02985591  0.05825109 -0.2516738\n",
      "  0.34736626  0.0014886  -0.32313696  0.26210163 -0.19468105 -0.22965246\n",
      "  0.10461325 -0.36697836]\n",
      "Training Error:  10.49524996601613\n",
      "====================================================================================================\n",
      "Iteration:  800\n",
      "Previous theta :  [ 0.00069612 -0.09362041  0.08995556  0.02985591  0.05825109 -0.2516738\n",
      "  0.34736626  0.0014886  -0.32313696  0.26210163 -0.19468105 -0.22965246\n",
      "  0.10461325 -0.36697836]\n",
      "New theta_0 : [ 0.00069518 -0.0936299   0.08997947  0.02988258  0.05824834 -0.25171585\n",
      "  0.34735478  0.00149203 -0.32317695  0.26217299 -0.19475066 -0.22965671\n",
      "  0.10461158 -0.36698245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.495236094479461\n",
      "====================================================================================================\n",
      "Iteration:  801\n",
      "Previous theta :  [ 0.00069518 -0.0936299   0.08997947  0.02988258  0.05824834 -0.25171585\n",
      "  0.34735478  0.00149203 -0.32317695  0.26217299 -0.19475066 -0.22965671\n",
      "  0.10461158 -0.36698245]\n",
      "New theta_0 : [ 0.00069424 -0.09363934  0.09000326  0.02990919  0.05824559 -0.25175764\n",
      "  0.34734337  0.00149546 -0.32321667  0.26224414 -0.19482013 -0.22966095\n",
      "  0.10460993 -0.36698652]\n",
      "Training Error:  10.495222320460993\n",
      "====================================================================================================\n",
      "Iteration:  802\n",
      "Previous theta :  [ 0.00069424 -0.09363934  0.09000326  0.02990919  0.05824559 -0.25175764\n",
      "  0.34734337  0.00149546 -0.32321667  0.26224414 -0.19482013 -0.22966095\n",
      "  0.10460993 -0.36698652]\n",
      "New theta_0 : [ 0.00069331 -0.09364873  0.09002694  0.02993575  0.05824284 -0.25179918\n",
      "  0.34733202  0.00149888 -0.32325613  0.26231509 -0.19488944 -0.22966516\n",
      "  0.10460829 -0.36699057]\n",
      "Training Error:  10.49520864311383\n",
      "====================================================================================================\n",
      "Iteration:  803\n",
      "Previous theta :  [ 0.00069331 -0.09364873  0.09002694  0.02993575  0.05824284 -0.25179918\n",
      "  0.34733202  0.00149888 -0.32325613  0.26231509 -0.19488944 -0.22966516\n",
      "  0.10460829 -0.36699057]\n",
      "New theta_0 : [ 0.00069238 -0.09365808  0.09005051  0.02996225  0.0582401  -0.25184046\n",
      "  0.34732073  0.00150229 -0.32329532  0.26238584 -0.1949586  -0.22966935\n",
      "  0.10460667 -0.36699459]\n",
      "Training Error:  10.4951950616002\n",
      "====================================================================================================\n",
      "Iteration:  804\n",
      "Previous theta :  [ 0.00069238 -0.09365808  0.09005051  0.02996225  0.0582401  -0.25184046\n",
      "  0.34732073  0.00150229 -0.32329532  0.26238584 -0.1949586  -0.22966935\n",
      "  0.10460667 -0.36699459]\n",
      "New theta_0 : [ 0.00069146 -0.09366739  0.09007397  0.02998869  0.05823736 -0.25188149\n",
      "  0.34730951  0.00150569 -0.32333425  0.26245638 -0.19502761 -0.22967352\n",
      "  0.10460507 -0.36699861]\n",
      "Training Error:  10.495181575091319\n",
      "====================================================================================================\n",
      "Iteration:  805\n",
      "Previous theta :  [ 0.00069146 -0.09366739  0.09007397  0.02998869  0.05823736 -0.25188149\n",
      "  0.34730951  0.00150569 -0.32333425  0.26245638 -0.19502761 -0.22967352\n",
      "  0.10460507 -0.36699861]\n",
      "New theta_0 : [ 0.00069055 -0.09367666  0.09009731  0.03001507  0.05823463 -0.25192226\n",
      "  0.34729835  0.00150909 -0.32337291  0.26252672 -0.19509648 -0.22967766\n",
      "  0.10460348 -0.3670026 ]\n",
      "Training Error:  10.495168182767289\n",
      "====================================================================================================\n",
      "Iteration:  806\n",
      "Previous theta :  [ 0.00069055 -0.09367666  0.09009731  0.03001507  0.05823463 -0.25192226\n",
      "  0.34729835  0.00150909 -0.32337291  0.26252672 -0.19509648 -0.22967766\n",
      "  0.10460348 -0.3670026 ]\n",
      "New theta_0 : [ 0.00068964 -0.09368588  0.09012055  0.0300414   0.05823189 -0.25196278\n",
      "  0.34728725  0.00151248 -0.32341131  0.26259686 -0.19516519 -0.22968179\n",
      "  0.1046019  -0.36700657]\n",
      "Training Error:  10.49515488381699\n",
      "====================================================================================================\n",
      "Iteration:  807\n",
      "Previous theta :  [ 0.00068964 -0.09368588  0.09012055  0.0300414   0.05823189 -0.25196278\n",
      "  0.34728725  0.00151248 -0.32341131  0.26259686 -0.19516519 -0.22968179\n",
      "  0.1046019  -0.36700657]\n",
      "New theta_0 : [ 0.00068874 -0.09369506  0.09014368  0.03006767  0.05822916 -0.25200305\n",
      "  0.34727621  0.00151586 -0.32344946  0.26266679 -0.19523376 -0.22968589\n",
      "  0.10460034 -0.36701053]\n",
      "Training Error:  10.495141677437973\n",
      "====================================================================================================\n",
      "Iteration:  808\n",
      "Previous theta :  [ 0.00068874 -0.09369506  0.09014368  0.03006767  0.05822916 -0.25200305\n",
      "  0.34727621  0.00151586 -0.32344946  0.26266679 -0.19523376 -0.22968589\n",
      "  0.10460034 -0.36701053]\n",
      "New theta_0 : [ 0.00068785 -0.0937042   0.0901667   0.03009388  0.05822644 -0.25204308\n",
      "  0.34726523  0.00151923 -0.32348735  0.26273653 -0.19530217 -0.22968997\n",
      "  0.10459879 -0.36701447]\n",
      "Training Error:  10.495128562836339\n",
      "====================================================================================================\n",
      "Iteration:  809\n",
      "Previous theta :  [ 0.00068785 -0.0937042   0.0901667   0.03009388  0.05822644 -0.25204308\n",
      "  0.34726523  0.00151923 -0.32348735  0.26273653 -0.19530217 -0.22968997\n",
      "  0.10459879 -0.36701447]\n",
      "New theta_0 : [ 0.00068696 -0.09371329  0.09018961  0.03012003  0.05822371 -0.25208286\n",
      "  0.34725431  0.0015226  -0.32352499  0.26280607 -0.19537044 -0.22969402\n",
      "  0.10459726 -0.36701839]\n",
      "Training Error:  10.495115539226642\n",
      "====================================================================================================\n",
      "Iteration:  810\n",
      "Previous theta :  [ 0.00068696 -0.09371329  0.09018961  0.03012003  0.05822371 -0.25208286\n",
      "  0.34725431  0.0015226  -0.32352499  0.26280607 -0.19537044 -0.22969402\n",
      "  0.10459726 -0.36701839]\n",
      "New theta_0 : [ 0.00068608 -0.09372235  0.09021241  0.03014613  0.05822099 -0.25212239\n",
      "  0.34724346  0.00152596 -0.32356237  0.2628754  -0.19543856 -0.22969806\n",
      "  0.10459574 -0.36702229]\n",
      "Training Error:  10.495102605831791\n",
      "====================================================================================================\n",
      "Iteration:  811\n",
      "Previous theta :  [ 0.00068608 -0.09372235  0.09021241  0.03014613  0.05822099 -0.25212239\n",
      "  0.34724346  0.00152596 -0.32356237  0.2628754  -0.19543856 -0.22969806\n",
      "  0.10459574 -0.36702229]\n",
      "New theta_0 : [ 0.0006852  -0.09373136  0.09023511  0.03017217  0.05821827 -0.25216169\n",
      "  0.34723266  0.00152931 -0.3235995   0.26294454 -0.19550653 -0.22970207\n",
      "  0.10459424 -0.36702618]\n",
      "Training Error:  10.495089761882932\n",
      "====================================================================================================\n",
      "Iteration:  812\n",
      "Previous theta :  [ 0.0006852  -0.09373136  0.09023511  0.03017217  0.05821827 -0.25216169\n",
      "  0.34723266  0.00152931 -0.3235995   0.26294454 -0.19550653 -0.22970207\n",
      "  0.10459424 -0.36702618]\n",
      "New theta_0 : [ 0.00068433 -0.09374033  0.0902577   0.03019816  0.05821555 -0.25220074\n",
      "  0.34722192  0.00153266 -0.32363638  0.26301348 -0.19557435 -0.22970607\n",
      "  0.10459275 -0.36703005]\n",
      "Training Error:  10.495077006619356\n",
      "====================================================================================================\n",
      "Iteration:  813\n",
      "Previous theta :  [ 0.00068433 -0.09374033  0.0902577   0.03019816  0.05821555 -0.25220074\n",
      "  0.34722192  0.00153266 -0.32363638  0.26301348 -0.19557435 -0.22970607\n",
      "  0.10459275 -0.36703005]\n",
      "New theta_0 : [ 0.00068346 -0.09374926  0.09028018  0.03022408  0.05821284 -0.25223955\n",
      "  0.34721124  0.001536   -0.32367302  0.26308223 -0.19564203 -0.22971004\n",
      "  0.10459127 -0.3670339 ]\n",
      "Training Error:  10.495064339288398\n",
      "====================================================================================================\n",
      "Iteration:  814\n",
      "Previous theta :  [ 0.00068346 -0.09374926  0.09028018  0.03022408  0.05821284 -0.25223955\n",
      "  0.34721124  0.001536   -0.32367302  0.26308223 -0.19564203 -0.22971004\n",
      "  0.10459127 -0.3670339 ]\n",
      "New theta_0 : [ 0.0006826  -0.09375815  0.09030256  0.03024995  0.05821013 -0.25227813\n",
      "  0.34720062  0.00153933 -0.32370941  0.26315077 -0.19570955 -0.22971399\n",
      "  0.10458981 -0.36703773]\n",
      "Training Error:  10.495051759145332\n",
      "====================================================================================================\n",
      "Iteration:  815\n",
      "Previous theta :  [ 0.0006826  -0.09375815  0.09030256  0.03024995  0.05821013 -0.25227813\n",
      "  0.34720062  0.00153933 -0.32370941  0.26315077 -0.19570955 -0.22971399\n",
      "  0.10458981 -0.36703773]\n",
      "New theta_0 : [ 0.00068175 -0.09376699  0.09032484  0.03027576  0.05820743 -0.25231647\n",
      "  0.34719005  0.00154266 -0.32374555  0.26321913 -0.19577693 -0.22971792\n",
      "  0.10458837 -0.36704155]\n",
      "Training Error:  10.495039265453277\n",
      "====================================================================================================\n",
      "Iteration:  816\n",
      "Previous theta :  [ 0.00068175 -0.09376699  0.09032484  0.03027576  0.05820743 -0.25231647\n",
      "  0.34719005  0.00154266 -0.32374555  0.26321913 -0.19577693 -0.22971792\n",
      "  0.10458837 -0.36704155]\n",
      "New theta_0 : [ 0.0006809  -0.0937758   0.09034701  0.03030152  0.05820472 -0.25235457\n",
      "  0.34717955  0.00154597 -0.32378145  0.26328728 -0.19584416 -0.22972183\n",
      "  0.10458693 -0.36704535]\n",
      "Training Error:  10.495026857483108\n",
      "====================================================================================================\n",
      "Iteration:  817\n",
      "Previous theta :  [ 0.0006809  -0.0937758   0.09034701  0.03030152  0.05820472 -0.25235457\n",
      "  0.34717955  0.00154597 -0.32378145  0.26328728 -0.19584416 -0.22972183\n",
      "  0.10458693 -0.36704535]\n",
      "New theta_0 : [ 0.00068006 -0.09378457  0.09036908  0.03032722  0.05820202 -0.25239244\n",
      "  0.3471691   0.00154928 -0.32381712  0.26335524 -0.19591124 -0.22972572\n",
      "  0.10458552 -0.36704913]\n",
      "Training Error:  10.495014534513336\n",
      "====================================================================================================\n",
      "Iteration:  818\n",
      "Previous theta :  [ 0.00068006 -0.09378457  0.09036908  0.03032722  0.05820202 -0.25239244\n",
      "  0.3471691   0.00154928 -0.32381712  0.26335524 -0.19591124 -0.22972572\n",
      "  0.10458552 -0.36704913]\n",
      "New theta_0 : [ 0.00067923 -0.09379329  0.09039105  0.03035286  0.05819932 -0.25243008\n",
      "  0.34715871  0.00155259 -0.32385254  0.26342301 -0.19597818 -0.22972959\n",
      "  0.10458411 -0.3670529 ]\n",
      "Training Error:  10.495002295830048\n",
      "====================================================================================================\n",
      "Iteration:  819\n",
      "Previous theta :  [ 0.00067923 -0.09379329  0.09039105  0.03035286  0.05819932 -0.25243008\n",
      "  0.34715871  0.00155259 -0.32385254  0.26342301 -0.19597818 -0.22972959\n",
      "  0.10458411 -0.3670529 ]\n",
      "New theta_0 : [ 0.0006784  -0.09380198  0.09041291  0.03037845  0.05819663 -0.25246749\n",
      "  0.34714837  0.00155588 -0.32388773  0.26349058 -0.19604496 -0.22973344\n",
      "  0.10458272 -0.36705665]\n",
      "Training Error:  10.494990140726786\n",
      "====================================================================================================\n",
      "Iteration:  820\n",
      "Previous theta :  [ 0.0006784  -0.09380198  0.09041291  0.03037845  0.05819663 -0.25246749\n",
      "  0.34714837  0.00155588 -0.32388773  0.26349058 -0.19604496 -0.22973344\n",
      "  0.10458272 -0.36705665]\n",
      "New theta_0 : [ 0.00067757 -0.09381062  0.09043467  0.03040397  0.05819394 -0.25250467\n",
      "  0.34713809  0.00155917 -0.32392268  0.26355796 -0.1961116  -0.22973726\n",
      "  0.10458134 -0.36706039]\n",
      "Training Error:  10.494978068504475\n",
      "====================================================================================================\n",
      "Iteration:  821\n",
      "Previous theta :  [ 0.00067757 -0.09381062  0.09043467  0.03040397  0.05819394 -0.25250467\n",
      "  0.34713809  0.00155917 -0.32392268  0.26355796 -0.1961116  -0.22973726\n",
      "  0.10458134 -0.36706039]\n",
      "New theta_0 : [ 0.00067675 -0.09381923  0.09045634  0.03042944  0.05819125 -0.25254162\n",
      "  0.34712786  0.00156246 -0.32395739  0.26362515 -0.1961781  -0.22974107\n",
      "  0.10457997 -0.3670641 ]\n",
      "Training Error:  10.494966078471316\n",
      "====================================================================================================\n",
      "Iteration:  822\n",
      "Previous theta :  [ 0.00067675 -0.09381923  0.09045634  0.03042944  0.05819125 -0.25254162\n",
      "  0.34712786  0.00156246 -0.32395739  0.26362515 -0.1961781  -0.22974107\n",
      "  0.10457997 -0.3670641 ]\n",
      "New theta_0 : [ 0.00067594 -0.0938278   0.0904779   0.03045486  0.05818857 -0.25257835\n",
      "  0.3471177   0.00156573 -0.32399187  0.26369214 -0.19624444 -0.22974486\n",
      "  0.10457862 -0.36706781]\n",
      "Training Error:  10.494954169942712\n",
      "====================================================================================================\n",
      "Iteration:  823\n",
      "Previous theta :  [ 0.00067594 -0.0938278   0.0904779   0.03045486  0.05818857 -0.25257835\n",
      "  0.3471177   0.00156573 -0.32399187  0.26369214 -0.19624444 -0.22974486\n",
      "  0.10457862 -0.36706781]\n",
      "New theta_0 : [ 0.00067513 -0.09383633  0.09049936  0.03048022  0.05818588 -0.25261485\n",
      "  0.34710758  0.001569   -0.32402613  0.26375895 -0.19631064 -0.22974863\n",
      "  0.10457728 -0.36707149]\n",
      "Training Error:  10.494942342241163\n",
      "====================================================================================================\n",
      "Iteration:  824\n",
      "Previous theta :  [ 0.00067513 -0.09383633  0.09049936  0.03048022  0.05818588 -0.25261485\n",
      "  0.34710758  0.001569   -0.32402613  0.26375895 -0.19631064 -0.22974863\n",
      "  0.10457728 -0.36707149]\n",
      "New theta_0 : [ 0.00067433 -0.09384482  0.09052073  0.03050552  0.05818321 -0.25265113\n",
      "  0.34709752  0.00157227 -0.32406015  0.26382556 -0.19637669 -0.22975237\n",
      "  0.10457595 -0.36707516]\n",
      "Training Error:  10.494930594696203\n",
      "====================================================================================================\n",
      "Iteration:  825\n",
      "Previous theta :  [ 0.00067433 -0.09384482  0.09052073  0.03050552  0.05818321 -0.25265113\n",
      "  0.34709752  0.00157227 -0.32406015  0.26382556 -0.19637669 -0.22975237\n",
      "  0.10457595 -0.36707516]\n",
      "New theta_0 : [ 0.00067353 -0.09385327  0.09054199  0.03053076  0.05818053 -0.25268719\n",
      "  0.34708751  0.00157552 -0.32409395  0.26389198 -0.1964426  -0.2297561\n",
      "  0.10457464 -0.36707882]\n",
      "Training Error:  10.494918926644292\n",
      "====================================================================================================\n",
      "Iteration:  826\n",
      "Previous theta :  [ 0.00067353 -0.09385327  0.09054199  0.03053076  0.05818053 -0.25268719\n",
      "  0.34708751  0.00157552 -0.32409395  0.26389198 -0.1964426  -0.2297561\n",
      "  0.10457464 -0.36707882]\n",
      "New theta_0 : [ 0.00067274 -0.09386168  0.09056316  0.03055595  0.05817786 -0.25272303\n",
      "  0.34707756  0.00157877 -0.32412752  0.26395822 -0.19650836 -0.22975981\n",
      "  0.10457334 -0.36708246]\n",
      "Training Error:  10.494907337428742\n",
      "====================================================================================================\n",
      "Iteration:  827\n",
      "Previous theta :  [ 0.00067274 -0.09386168  0.09056316  0.03055595  0.05817786 -0.25272303\n",
      "  0.34707756  0.00157877 -0.32412752  0.26395822 -0.19650836 -0.22975981\n",
      "  0.10457334 -0.36708246]\n",
      "New theta_0 : [ 0.00067195 -0.09387006  0.09058423  0.03058108  0.05817519 -0.25275866\n",
      "  0.34706766  0.00158201 -0.32416086  0.26402426 -0.19657398 -0.2297635\n",
      "  0.10457205 -0.36708608]\n",
      "Training Error:  10.494895826399633\n",
      "====================================================================================================\n",
      "Iteration:  828\n",
      "Previous theta :  [ 0.00067195 -0.09387006  0.09058423  0.03058108  0.05817519 -0.25275866\n",
      "  0.34706766  0.00158201 -0.32416086  0.26402426 -0.19657398 -0.2297635\n",
      "  0.10457205 -0.36708608]\n",
      "New theta_0 : [ 0.00067117 -0.0938784   0.0906052   0.03060616  0.05817253 -0.25279406\n",
      "  0.34705782  0.00158525 -0.32419399  0.26409012 -0.19663944 -0.22976717\n",
      "  0.10457077 -0.36708969]\n",
      "Training Error:  10.49488439291373\n",
      "====================================================================================================\n",
      "Iteration:  829\n",
      "Previous theta :  [ 0.00067117 -0.0938784   0.0906052   0.03060616  0.05817253 -0.25279406\n",
      "  0.34705782  0.00158525 -0.32419399  0.26409012 -0.19663944 -0.22976717\n",
      "  0.10457077 -0.36708969]\n",
      "New theta_0 : [ 0.00067039 -0.0938867   0.09062608  0.03063117  0.05816986 -0.25282925\n",
      "  0.34704802  0.00158848 -0.32422689  0.26415579 -0.19670477 -0.22977082\n",
      "  0.10456951 -0.36709328]\n",
      "Training Error:  10.494873036334399\n",
      "====================================================================================================\n",
      "Iteration:  830\n",
      "Previous theta :  [ 0.00067039 -0.0938867   0.09062608  0.03063117  0.05816986 -0.25282925\n",
      "  0.34704802  0.00158848 -0.32422689  0.26415579 -0.19670477 -0.22977082\n",
      "  0.10456951 -0.36709328]\n",
      "New theta_0 : [ 0.00066962 -0.09389496  0.09064686  0.03065614  0.05816721 -0.25286423\n",
      "  0.34703828  0.0015917  -0.32425957  0.26422127 -0.19676994 -0.22977445\n",
      "  0.10456826 -0.36709686]\n",
      "Training Error:  10.494861756031536\n",
      "====================================================================================================\n",
      "Iteration:  831\n",
      "Previous theta :  [ 0.00066962 -0.09389496  0.09064686  0.03065614  0.05816721 -0.25286423\n",
      "  0.34703828  0.0015917  -0.32425957  0.26422127 -0.19676994 -0.22977445\n",
      "  0.10456826 -0.36709686]\n",
      "New theta_0 : [ 0.00066886 -0.09390318  0.09066754  0.03068104  0.05816455 -0.25289899\n",
      "  0.34702859  0.00159492 -0.32429203  0.26428657 -0.19683497 -0.22977806\n",
      "  0.10456702 -0.36710043]\n",
      "Training Error:  10.494850551381473\n",
      "====================================================================================================\n",
      "Iteration:  832\n",
      "Previous theta :  [ 0.00066886 -0.09390318  0.09066754  0.03068104  0.05816455 -0.25289899\n",
      "  0.34702859  0.00159492 -0.32429203  0.26428657 -0.19683497 -0.22977806\n",
      "  0.10456702 -0.36710043]\n",
      "New theta_0 : [ 0.00066809 -0.09391137  0.09068814  0.03070589  0.0581619  -0.25293355\n",
      "  0.34701896  0.00159812 -0.32432428  0.26435168 -0.19689986 -0.22978166\n",
      "  0.10456579 -0.36710397]\n",
      "Training Error:  10.494839421766914\n",
      "====================================================================================================\n",
      "Iteration:  833\n",
      "Previous theta :  [ 0.00066809 -0.09391137  0.09068814  0.03070589  0.0581619  -0.25293355\n",
      "  0.34701896  0.00159812 -0.32432428  0.26435168 -0.19689986 -0.22978166\n",
      "  0.10456579 -0.36710397]\n",
      "New theta_0 : [ 0.00066734 -0.09391952  0.09070863  0.03073068  0.05815925 -0.25296789\n",
      "  0.34700937  0.00160133 -0.32435631  0.2644166  -0.1969646  -0.22978523\n",
      "  0.10456458 -0.36710751]\n",
      "Training Error:  10.494828366576856\n",
      "====================================================================================================\n",
      "Iteration:  834\n",
      "Previous theta :  [ 0.00066734 -0.09391952  0.09070863  0.03073068  0.05815925 -0.25296789\n",
      "  0.34700937  0.00160133 -0.32435631  0.2644166  -0.1969646  -0.22978523\n",
      "  0.10456458 -0.36710751]\n",
      "New theta_0 : [ 0.00066659 -0.09392764  0.09072904  0.03075542  0.05815661 -0.25300203\n",
      "  0.34699984  0.00160452 -0.32438813  0.26448134 -0.1970292  -0.22978879\n",
      "  0.10456337 -0.36711103]\n",
      "Training Error:  10.494817385206499\n",
      "====================================================================================================\n",
      "Iteration:  835\n",
      "Previous theta :  [ 0.00066659 -0.09392764  0.09072904  0.03075542  0.05815661 -0.25300203\n",
      "  0.34699984  0.00160452 -0.32438813  0.26448134 -0.1970292  -0.22978879\n",
      "  0.10456337 -0.36711103]\n",
      "New theta_0 : [ 0.00066584 -0.09393572  0.09074935  0.0307801   0.05815396 -0.25303595\n",
      "  0.34699035  0.00160771 -0.32441973  0.2645459  -0.19709365 -0.22979232\n",
      "  0.10456218 -0.36711453]\n",
      "Training Error:  10.494806477057201\n",
      "====================================================================================================\n",
      "Iteration:  836\n",
      "Previous theta :  [ 0.00066584 -0.09393572  0.09074935  0.0307801   0.05815396 -0.25303595\n",
      "  0.34699035  0.00160771 -0.32441973  0.2645459  -0.19709365 -0.22979232\n",
      "  0.10456218 -0.36711453]\n",
      "New theta_0 : [ 0.0006651  -0.09394376  0.09076957  0.03080473  0.05815133 -0.25306968\n",
      "  0.34698092  0.00161089 -0.32445113  0.26461027 -0.19715796 -0.22979584\n",
      "  0.104561   -0.36711802]\n",
      "Training Error:  10.494795641536363\n",
      "====================================================================================================\n",
      "Iteration:  837\n",
      "Previous theta :  [ 0.0006651  -0.09394376  0.09076957  0.03080473  0.05815133 -0.25306968\n",
      "  0.34698092  0.00161089 -0.32445113  0.26461027 -0.19715796 -0.22979584\n",
      "  0.104561   -0.36711802]\n",
      "New theta_0 : [ 0.00066437 -0.09395176  0.09078969  0.03082929  0.05814869 -0.2531032\n",
      "  0.34697153  0.00161407 -0.32448231  0.26467446 -0.19722212 -0.22979934\n",
      "  0.10455983 -0.3671215 ]\n",
      "Training Error:  10.494784878057391\n",
      "====================================================================================================\n",
      "Iteration:  838\n",
      "Previous theta :  [ 0.00066437 -0.09395176  0.09078969  0.03082929  0.05814869 -0.2531032\n",
      "  0.34697153  0.00161407 -0.32448231  0.26467446 -0.19722212 -0.22979934\n",
      "  0.10455983 -0.3671215 ]\n",
      "New theta_0 : [ 0.00066364 -0.09395973  0.09080973  0.03085381  0.05814606 -0.25313651\n",
      "  0.3469622   0.00161724 -0.32451329  0.26473847 -0.19728614 -0.22980283\n",
      "  0.10455868 -0.36712496]\n",
      "Training Error:  10.494774186039615\n",
      "====================================================================================================\n",
      "Iteration:  839\n",
      "Previous theta :  [ 0.00066364 -0.09395973  0.09080973  0.03085381  0.05814606 -0.25313651\n",
      "  0.3469622   0.00161724 -0.32451329  0.26473847 -0.19728614 -0.22980283\n",
      "  0.10455868 -0.36712496]\n",
      "New theta_0 : [ 0.00066291 -0.09396767  0.09082967  0.03087826  0.05814343 -0.25316963\n",
      "  0.34695291  0.0016204  -0.32454406  0.26480229 -0.19735001 -0.22980629\n",
      "  0.10455753 -0.36712841]\n",
      "Training Error:  10.494763564908205\n",
      "====================================================================================================\n",
      "Iteration:  840\n",
      "Previous theta :  [ 0.00066291 -0.09396767  0.09082967  0.03087826  0.05814343 -0.25316963\n",
      "  0.34695291  0.0016204  -0.32454406  0.26480229 -0.19735001 -0.22980629\n",
      "  0.10455753 -0.36712841]\n",
      "New theta_0 : [ 0.00066219 -0.09397557  0.09084952  0.03090266  0.05814081 -0.25320254\n",
      "  0.34694367  0.00162356 -0.32457463  0.26486594 -0.19741375 -0.22980974\n",
      "  0.1045564  -0.36713184]\n",
      "Training Error:  10.494753014094112\n",
      "====================================================================================================\n",
      "Iteration:  841\n",
      "Previous theta :  [ 0.00066219 -0.09397557  0.09084952  0.03090266  0.05814081 -0.25320254\n",
      "  0.34694367  0.00162356 -0.32457463  0.26486594 -0.19741375 -0.22980974\n",
      "  0.1045564  -0.36713184]\n",
      "New theta_0 : [ 0.00066147 -0.09398343  0.09086929  0.03092701  0.05813819 -0.25323525\n",
      "  0.34693449  0.00162671 -0.32460499  0.2649294  -0.19747733 -0.22981317\n",
      "  0.10455527 -0.36713526]\n",
      "Training Error:  10.494742533034001\n",
      "====================================================================================================\n",
      "Iteration:  842\n",
      "Previous theta :  [ 0.00066147 -0.09398343  0.09086929  0.03092701  0.05813819 -0.25323525\n",
      "  0.34693449  0.00162671 -0.32460499  0.2649294  -0.19747733 -0.22981317\n",
      "  0.10455527 -0.36713526]\n",
      "New theta_0 : [ 0.00066076 -0.09399126  0.09088896  0.0309513   0.05813557 -0.25326777\n",
      "  0.34692534  0.00162986 -0.32463515  0.26499268 -0.19754078 -0.22981658\n",
      "  0.10455416 -0.36713867]\n",
      "Training Error:  10.494732121170179\n",
      "====================================================================================================\n",
      "Iteration:  843\n",
      "Previous theta :  [ 0.00066076 -0.09399126  0.09088896  0.0309513   0.05813557 -0.25326777\n",
      "  0.34692534  0.00162986 -0.32463515  0.26499268 -0.19754078 -0.22981658\n",
      "  0.10455416 -0.36713867]\n",
      "New theta_0 : [ 0.00066006 -0.09399905  0.09090854  0.03097553  0.05813296 -0.25330009\n",
      "  0.34691625  0.00163299 -0.32466511  0.26505579 -0.19760408 -0.22981997\n",
      "  0.10455306 -0.36714206]\n",
      "Training Error:  10.494721777950524\n",
      "====================================================================================================\n",
      "Iteration:  844\n",
      "Previous theta :  [ 0.00066006 -0.09399905  0.09090854  0.03097553  0.05813296 -0.25330009\n",
      "  0.34691625  0.00163299 -0.32466511  0.26505579 -0.19760408 -0.22981997\n",
      "  0.10455306 -0.36714206]\n",
      "New theta_0 : [ 0.00065936 -0.09400681  0.09092804  0.03099971  0.05813035 -0.25333222\n",
      "  0.34690721  0.00163612 -0.32469487  0.26511871 -0.19766724 -0.22982335\n",
      "  0.10455197 -0.36714544]\n",
      "Training Error:  10.494711502828423\n",
      "====================================================================================================\n",
      "Iteration:  845\n",
      "Previous theta :  [ 0.00065936 -0.09400681  0.09092804  0.03099971  0.05813035 -0.25333222\n",
      "  0.34690721  0.00163612 -0.32469487  0.26511871 -0.19766724 -0.22982335\n",
      "  0.10455197 -0.36714544]\n",
      "New theta_0 : [ 0.00065866 -0.09401453  0.09094745  0.03102383  0.05812774 -0.25336415\n",
      "  0.34689821  0.00163925 -0.32472443  0.26518146 -0.19773025 -0.22982671\n",
      "  0.10455089 -0.3671488 ]\n",
      "Training Error:  10.494701295262711\n",
      "====================================================================================================\n",
      "Iteration:  846\n",
      "Previous theta :  [ 0.00065866 -0.09401453  0.09094745  0.03102383  0.05812774 -0.25336415\n",
      "  0.34689821  0.00163925 -0.32472443  0.26518146 -0.19773025 -0.22982671\n",
      "  0.10455089 -0.3671488 ]\n",
      "New theta_0 : [ 0.00065797 -0.09402223  0.09096677  0.0310479   0.05812514 -0.25339589\n",
      "  0.34688926  0.00164237 -0.32475379  0.26524402 -0.19779312 -0.22983005\n",
      "  0.10454982 -0.36715216]\n",
      "Training Error:  10.494691154717593\n",
      "====================================================================================================\n",
      "Iteration:  847\n",
      "Previous theta :  [ 0.00065797 -0.09402223  0.09096677  0.0310479   0.05812514 -0.25339589\n",
      "  0.34688926  0.00164237 -0.32475379  0.26524402 -0.19779312 -0.22983005\n",
      "  0.10454982 -0.36715216]\n",
      "New theta_0 : [ 0.00065728 -0.09402988  0.090986    0.03107191  0.05812254 -0.25342744\n",
      "  0.34688036  0.00164548 -0.32478296  0.26530641 -0.19785585 -0.22983337\n",
      "  0.10454877 -0.3671555 ]\n",
      "Training Error:  10.494681080662597\n",
      "====================================================================================================\n",
      "Iteration:  848\n",
      "Previous theta :  [ 0.00065728 -0.09402988  0.090986    0.03107191  0.05812254 -0.25342744\n",
      "  0.34688036  0.00164548 -0.32478296  0.26530641 -0.19785585 -0.22983337\n",
      "  0.10454877 -0.3671555 ]\n",
      "New theta_0 : [ 0.0006566  -0.0940375   0.09100515  0.03109586  0.05811995 -0.2534588\n",
      "  0.3468715   0.00164859 -0.32481194  0.26536863 -0.19791844 -0.22983668\n",
      "  0.10454772 -0.36715882]\n",
      "Training Error:  10.49467107257249\n",
      "====================================================================================================\n",
      "Iteration:  849\n",
      "Previous theta :  [ 0.0006566  -0.0940375   0.09100515  0.03109586  0.05811995 -0.2534588\n",
      "  0.3468715   0.00164859 -0.32481194  0.26536863 -0.19791844 -0.22983668\n",
      "  0.10454772 -0.36715882]\n",
      "New theta_0 : [ 0.00065592 -0.09404509  0.09102421  0.03111976  0.05811736 -0.25348997\n",
      "  0.34686269  0.00165169 -0.32484072  0.26543066 -0.19798089 -0.22983997\n",
      "  0.10454668 -0.36716213]\n",
      "Training Error:  10.494661129927241\n",
      "====================================================================================================\n",
      "Iteration:  850\n",
      "Previous theta :  [ 0.00065592 -0.09404509  0.09102421  0.03111976  0.05811736 -0.25348997\n",
      "  0.34686269  0.00165169 -0.32484072  0.26543066 -0.19798089 -0.22983997\n",
      "  0.10454668 -0.36716213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00065524 -0.09405265  0.09104319  0.03114361  0.05811477 -0.25352096\n",
      "  0.34685392  0.00165478 -0.32486932  0.26549252 -0.19804319 -0.22984324\n",
      "  0.10454565 -0.36716543]\n",
      "Training Error:  10.494651252211938\n",
      "====================================================================================================\n",
      "Iteration:  851\n",
      "Previous theta :  [ 0.00065524 -0.09405265  0.09104319  0.03114361  0.05811477 -0.25352096\n",
      "  0.34685392  0.00165478 -0.32486932  0.26549252 -0.19804319 -0.22984324\n",
      "  0.10454565 -0.36716543]\n",
      "New theta_0 : [ 0.00065457 -0.09406017  0.09106208  0.0311674   0.05811219 -0.25355175\n",
      "  0.3468452   0.00165787 -0.32489772  0.26555421 -0.19810535 -0.2298465\n",
      "  0.10454464 -0.36716872]\n",
      "Training Error:  10.49464143891674\n",
      "====================================================================================================\n",
      "Iteration:  852\n",
      "Previous theta :  [ 0.00065457 -0.09406017  0.09106208  0.0311674   0.05811219 -0.25355175\n",
      "  0.3468452   0.00165787 -0.32489772  0.26555421 -0.19810535 -0.2298465\n",
      "  0.10454464 -0.36716872]\n",
      "New theta_0 : [ 0.00065391 -0.09406766  0.09108089  0.03119113  0.0581096  -0.25358236\n",
      "  0.34683652  0.00166095 -0.32492593  0.26561572 -0.19816737 -0.22984974\n",
      "  0.10454363 -0.36717199]\n",
      "Training Error:  10.494631689536813\n",
      "====================================================================================================\n",
      "Iteration:  853\n",
      "Previous theta :  [ 0.00065391 -0.09406766  0.09108089  0.03119113  0.0581096  -0.25358236\n",
      "  0.34683652  0.00166095 -0.32492593  0.26561572 -0.19816737 -0.22984974\n",
      "  0.10454363 -0.36717199]\n",
      "New theta_0 : [ 0.00065325 -0.09407511  0.09109961  0.03121481  0.05810703 -0.25361279\n",
      "  0.34682789  0.00166402 -0.32495396  0.26567706 -0.19822925 -0.22985296\n",
      "  0.10454264 -0.36717526]\n",
      "Training Error:  10.494622003572267\n",
      "====================================================================================================\n",
      "Iteration:  854\n",
      "Previous theta :  [ 0.00065325 -0.09407511  0.09109961  0.03121481  0.05810703 -0.25361279\n",
      "  0.34682789  0.00166402 -0.32495396  0.26567706 -0.19822925 -0.22985296\n",
      "  0.10454264 -0.36717526]\n",
      "New theta_0 : [ 0.00065259 -0.09408253  0.09111825  0.03123844  0.05810446 -0.25364304\n",
      "  0.34681931  0.00166709 -0.3249818   0.26573822 -0.19829099 -0.22985617\n",
      "  0.10454165 -0.3671785 ]\n",
      "Training Error:  10.49461238052811\n",
      "====================================================================================================\n",
      "Iteration:  855\n",
      "Previous theta :  [ 0.00065259 -0.09408253  0.09111825  0.03123844  0.05810446 -0.25364304\n",
      "  0.34681931  0.00166709 -0.3249818   0.26573822 -0.19829099 -0.22985617\n",
      "  0.10454165 -0.3671785 ]\n",
      "New theta_0 : [ 0.00065194 -0.09408992  0.0911368   0.03126201  0.05810189 -0.2536731\n",
      "  0.34681077  0.00167015 -0.32500946  0.26579921 -0.19835258 -0.22985936\n",
      "  0.10454067 -0.36718174]\n",
      "Training Error:  10.494602819914176\n",
      "====================================================================================================\n",
      "Iteration:  856\n",
      "Previous theta :  [ 0.00065194 -0.09408992  0.0911368   0.03126201  0.05810189 -0.2536731\n",
      "  0.34681077  0.00167015 -0.32500946  0.26579921 -0.19835258 -0.22985936\n",
      "  0.10454067 -0.36718174]\n",
      "New theta_0 : [ 0.00065129 -0.09409728  0.09115528  0.03128552  0.05809932 -0.25370299\n",
      "  0.34680227  0.00167321 -0.32503693  0.26586003 -0.19841404 -0.22986253\n",
      "  0.10453971 -0.36718496]\n",
      "Training Error:  10.494593321245075\n",
      "====================================================================================================\n",
      "Iteration:  857\n",
      "Previous theta :  [ 0.00065129 -0.09409728  0.09115528  0.03128552  0.05809932 -0.25370299\n",
      "  0.34680227  0.00167321 -0.32503693  0.26586003 -0.19841404 -0.22986253\n",
      "  0.10453971 -0.36718496]\n",
      "New theta_0 : [ 0.00065065 -0.09410461  0.09117367  0.03130898  0.05809676 -0.25373269\n",
      "  0.34679381  0.00167626 -0.32506422  0.26592068 -0.19847536 -0.22986569\n",
      "  0.10453875 -0.36718817]\n",
      "Training Error:  10.494583884040141\n",
      "====================================================================================================\n",
      "Iteration:  858\n",
      "Previous theta :  [ 0.00065065 -0.09410461  0.09117367  0.03130898  0.05809676 -0.25373269\n",
      "  0.34679381  0.00167626 -0.32506422  0.26592068 -0.19847536 -0.22986569\n",
      "  0.10453875 -0.36718817]\n",
      "New theta_0 : [ 0.00065001 -0.0941119   0.09119198  0.03133238  0.0580942  -0.25376222\n",
      "  0.3467854   0.00167931 -0.32509133  0.26598115 -0.19853653 -0.22986883\n",
      "  0.10453781 -0.36719137]\n",
      "Training Error:  10.494574507823371\n",
      "====================================================================================================\n",
      "Iteration:  859\n",
      "Previous theta :  [ 0.00065001 -0.0941119   0.09119198  0.03133238  0.0580942  -0.25376222\n",
      "  0.3467854   0.00167931 -0.32509133  0.26598115 -0.19853653 -0.22986883\n",
      "  0.10453781 -0.36719137]\n",
      "New theta_0 : [ 0.00064938 -0.09411916  0.0912102   0.03135573  0.05809165 -0.25379157\n",
      "  0.34677703  0.00168234 -0.32511826  0.26604145 -0.19859757 -0.22987196\n",
      "  0.10453687 -0.36719456]\n",
      "Training Error:  10.494565192123373\n",
      "====================================================================================================\n",
      "Iteration:  860\n",
      "Previous theta :  [ 0.00064938 -0.09411916  0.0912102   0.03135573  0.05809165 -0.25379157\n",
      "  0.34677703  0.00168234 -0.32511826  0.26604145 -0.19859757 -0.22987196\n",
      "  0.10453687 -0.36719456]\n",
      "New theta_0 : [ 0.00064875 -0.09412639  0.09122835  0.03137903  0.0580891  -0.25382075\n",
      "  0.34676871  0.00168538 -0.32514502  0.26610159 -0.19865846 -0.22987507\n",
      "  0.10453594 -0.36719774]\n",
      "Training Error:  10.494555936473306\n",
      "====================================================================================================\n",
      "Iteration:  861\n",
      "Previous theta :  [ 0.00064875 -0.09412639  0.09122835  0.03137903  0.0580891  -0.25382075\n",
      "  0.34676871  0.00168538 -0.32514502  0.26610159 -0.19865846 -0.22987507\n",
      "  0.10453594 -0.36719774]\n",
      "New theta_0 : [ 0.00064812 -0.09413359  0.09124642  0.03140227  0.05808655 -0.25384975\n",
      "  0.34676043  0.0016884  -0.32517159  0.26616155 -0.19871922 -0.22987816\n",
      "  0.10453502 -0.3672009 ]\n",
      "Training Error:  10.494546740410842\n",
      "====================================================================================================\n",
      "Iteration:  862\n",
      "Previous theta :  [ 0.00064812 -0.09413359  0.09124642  0.03140227  0.05808655 -0.25384975\n",
      "  0.34676043  0.0016884  -0.32517159  0.26616155 -0.19871922 -0.22987816\n",
      "  0.10453502 -0.3672009 ]\n",
      "New theta_0 : [ 0.0006475  -0.09414076  0.0912644   0.03142546  0.05808401 -0.25387858\n",
      "  0.34675219  0.00169142 -0.32519799  0.26622134 -0.19877983 -0.22988124\n",
      "  0.10453412 -0.36720405]\n",
      "Training Error:  10.494537603478099\n",
      "====================================================================================================\n",
      "Iteration:  863\n",
      "Previous theta :  [ 0.0006475  -0.09414076  0.0912644   0.03142546  0.05808401 -0.25387858\n",
      "  0.34675219  0.00169142 -0.32519799  0.26622134 -0.19877983 -0.22988124\n",
      "  0.10453412 -0.36720405]\n",
      "New theta_0 : [ 0.00064688 -0.09414789  0.09128231  0.03144859  0.05808147 -0.25390724\n",
      "  0.34674399  0.00169443 -0.32522421  0.26628097 -0.19884031 -0.2298843\n",
      "  0.10453322 -0.36720719]\n",
      "Training Error:  10.494528525221588\n",
      "====================================================================================================\n",
      "Iteration:  864\n",
      "Previous theta :  [ 0.00064688 -0.09414789  0.09128231  0.03144859  0.05808147 -0.25390724\n",
      "  0.34674399  0.00169443 -0.32522421  0.26628097 -0.19884031 -0.2298843\n",
      "  0.10453322 -0.36720719]\n",
      "New theta_0 : [ 0.00064627 -0.094155    0.09130014  0.03147167  0.05807893 -0.25393572\n",
      "  0.34673583  0.00169744 -0.32525026  0.26634042 -0.19890065 -0.22988735\n",
      "  0.10453233 -0.36721031]\n",
      "Training Error:  10.49451950519218\n",
      "====================================================================================================\n",
      "Iteration:  865\n",
      "Previous theta :  [ 0.00064627 -0.094155    0.09130014  0.03147167  0.05807893 -0.25393572\n",
      "  0.34673583  0.00169744 -0.32525026  0.26634042 -0.19890065 -0.22988735\n",
      "  0.10453233 -0.36721031]\n",
      "New theta_0 : [ 0.00064566 -0.09416207  0.09131789  0.03149469  0.0580764  -0.25396404\n",
      "  0.34672772  0.00170044 -0.32527614  0.26639971 -0.19896084 -0.22989038\n",
      "  0.10453145 -0.36721343]\n",
      "Training Error:  10.494510542945033\n",
      "====================================================================================================\n",
      "Iteration:  866\n",
      "Previous theta :  [ 0.00064566 -0.09416207  0.09131789  0.03149469  0.0580764  -0.25396404\n",
      "  0.34672772  0.00170044 -0.32527614  0.26639971 -0.19896084 -0.22989038\n",
      "  0.10453145 -0.36721343]\n",
      "New theta_0 : [ 0.00064505 -0.09416911  0.09133556  0.03151766  0.05807388 -0.25399218\n",
      "  0.34671964  0.00170344 -0.32530185  0.26645883 -0.1990209  -0.22989339\n",
      "  0.10453057 -0.36721653]\n",
      "Training Error:  10.494501638039564\n",
      "====================================================================================================\n",
      "Iteration:  867\n",
      "Previous theta :  [ 0.00064505 -0.09416911  0.09133556  0.03151766  0.05807388 -0.25399218\n",
      "  0.34671964  0.00170344 -0.32530185  0.26645883 -0.1990209  -0.22989339\n",
      "  0.10453057 -0.36721653]\n",
      "New theta_0 : [ 0.00064445 -0.09417612  0.09135315  0.03154057  0.05807135 -0.25402016\n",
      "  0.34671161  0.00170643 -0.32532739  0.26651779 -0.19908083 -0.22989639\n",
      "  0.10452971 -0.36721963]\n",
      "Training Error:  10.494492790039379\n",
      "====================================================================================================\n",
      "Iteration:  868\n",
      "Previous theta :  [ 0.00064445 -0.09417612  0.09135315  0.03154057  0.05807135 -0.25402016\n",
      "  0.34671161  0.00170643 -0.32532739  0.26651779 -0.19908083 -0.22989639\n",
      "  0.10452971 -0.36721963]\n",
      "New theta_0 : [ 0.00064386 -0.09418311  0.09137067  0.03156343  0.05806883 -0.25404798\n",
      "  0.34670362  0.00170941 -0.32535276  0.26657658 -0.19914061 -0.22989938\n",
      "  0.10452886 -0.36722271]\n",
      "Training Error:  10.494483998512237\n",
      "====================================================================================================\n",
      "Iteration:  869\n",
      "Previous theta :  [ 0.00064386 -0.09418311  0.09137067  0.03156343  0.05806883 -0.25404798\n",
      "  0.34670362  0.00170941 -0.32535276  0.26657658 -0.19914061 -0.22989938\n",
      "  0.10452886 -0.36722271]\n",
      "New theta_0 : [ 0.00064326 -0.09419006  0.09138811  0.03158624  0.05806632 -0.25407562\n",
      "  0.34669566  0.00171239 -0.32537796  0.2666352  -0.19920025 -0.22990235\n",
      "  0.10452801 -0.36722578]\n",
      "Training Error:  10.494475263030006\n",
      "====================================================================================================\n",
      "Iteration:  870\n",
      "Previous theta :  [ 0.00064326 -0.09419006  0.09138811  0.03158624  0.05806632 -0.25407562\n",
      "  0.34669566  0.00171239 -0.32537796  0.2666352  -0.19920025 -0.22990235\n",
      "  0.10452801 -0.36722578]\n",
      "New theta_0 : [ 0.00064267 -0.09419698  0.09140547  0.03160899  0.05806381 -0.25410311\n",
      "  0.34668775  0.00171536 -0.32540299  0.26669365 -0.19925976 -0.22990531\n",
      "  0.10452718 -0.36722883]\n",
      "Training Error:  10.4944665831686\n",
      "====================================================================================================\n",
      "Iteration:  871\n",
      "Previous theta :  [ 0.00064267 -0.09419698  0.09140547  0.03160899  0.05806381 -0.25410311\n",
      "  0.34668775  0.00171536 -0.32540299  0.26669365 -0.19925976 -0.22990531\n",
      "  0.10452718 -0.36722883]\n",
      "New theta_0 : [ 0.00064209 -0.09420387  0.09142275  0.03163169  0.0580613  -0.25413043\n",
      "  0.34667988  0.00171833 -0.32542786  0.26675195 -0.19931913 -0.22990825\n",
      "  0.10452635 -0.36723188]\n",
      "Training Error:  10.494457958507951\n",
      "====================================================================================================\n",
      "Iteration:  872\n",
      "Previous theta :  [ 0.00064209 -0.09420387  0.09142275  0.03163169  0.0580613  -0.25413043\n",
      "  0.34667988  0.00171833 -0.32542786  0.26675195 -0.19931913 -0.22990825\n",
      "  0.10452635 -0.36723188]\n",
      "New theta_0 : [ 0.00064151 -0.09421073  0.09143996  0.03165434  0.0580588  -0.25415759\n",
      "  0.34667205  0.00172129 -0.32545257  0.26681007 -0.19937836 -0.22991117\n",
      "  0.10452553 -0.36723492]\n",
      "Training Error:  10.494449388631944\n",
      "====================================================================================================\n",
      "Iteration:  873\n",
      "Previous theta :  [ 0.00064151 -0.09421073  0.09143996  0.03165434  0.0580588  -0.25415759\n",
      "  0.34667205  0.00172129 -0.32545257  0.26681007 -0.19937836 -0.22991117\n",
      "  0.10452553 -0.36723492]\n",
      "New theta_0 : [ 0.00064093 -0.09421756  0.0914571   0.03167693  0.0580563  -0.25418458\n",
      "  0.34666425  0.00172424 -0.32547711  0.26686804 -0.19943745 -0.22991408\n",
      "  0.10452472 -0.36723794]\n",
      "Training Error:  10.494440873128392\n",
      "====================================================================================================\n",
      "Iteration:  874\n",
      "Previous theta :  [ 0.00064093 -0.09421756  0.0914571   0.03167693  0.0580563  -0.25418458\n",
      "  0.34666425  0.00172424 -0.32547711  0.26686804 -0.19943745 -0.22991408\n",
      "  0.10452472 -0.36723794]\n",
      "New theta_0 : [ 0.00064035 -0.09422437  0.09147416  0.03169947  0.0580538  -0.25421142\n",
      "  0.3466565   0.00172719 -0.32550149  0.26692584 -0.19949641 -0.22991698\n",
      "  0.10452392 -0.36724096]\n",
      "Training Error:  10.49443241158897\n",
      "====================================================================================================\n",
      "Iteration:  875\n",
      "Previous theta :  [ 0.00064035 -0.09422437  0.09147416  0.03169947  0.0580538  -0.25421142\n",
      "  0.3466565   0.00172719 -0.32550149  0.26692584 -0.19949641 -0.22991698\n",
      "  0.10452392 -0.36724096]\n",
      "New theta_0 : [ 0.00063978 -0.09423114  0.09149114  0.03172195  0.05805131 -0.2542381\n",
      "  0.34664878  0.00173014 -0.32552571  0.26698348 -0.19955523 -0.22991986\n",
      "  0.10452312 -0.36724396]\n",
      "Training Error:  10.494424003609193\n",
      "====================================================================================================\n",
      "Iteration:  876\n",
      "Previous theta :  [ 0.00063978 -0.09423114  0.09149114  0.03172195  0.05805131 -0.2542381\n",
      "  0.34664878  0.00173014 -0.32552571  0.26698348 -0.19955523 -0.22991986\n",
      "  0.10452312 -0.36724396]\n",
      "New theta_0 : [ 0.00063922 -0.09423788  0.09150806  0.03174438  0.05804882 -0.25426462\n",
      "  0.34664111  0.00173307 -0.32554978  0.26704095 -0.19961391 -0.22992273\n",
      "  0.10452234 -0.36724695]\n",
      "Training Error:  10.494415648788351\n",
      "====================================================================================================\n",
      "Iteration:  877\n",
      "Previous theta :  [ 0.00063922 -0.09423788  0.09150806  0.03174438  0.05804882 -0.25426462\n",
      "  0.34664111  0.00173307 -0.32554978  0.26704095 -0.19961391 -0.22992273\n",
      "  0.10452234 -0.36724695]\n",
      "New theta_0 : [ 0.00063866 -0.0942446   0.09152489  0.03176676  0.05804634 -0.25429098\n",
      "  0.34663347  0.001736   -0.32557368  0.26709826 -0.19967246 -0.22992558\n",
      "  0.10452156 -0.36724993]\n",
      "Training Error:  10.49440734672948\n",
      "====================================================================================================\n",
      "Iteration:  878\n",
      "Previous theta :  [ 0.00063866 -0.0942446   0.09152489  0.03176676  0.05804634 -0.25429098\n",
      "  0.34663347  0.001736   -0.32557368  0.26709826 -0.19967246 -0.22992558\n",
      "  0.10452156 -0.36724993]\n",
      "New theta_0 : [ 0.0006381  -0.09425129  0.09154166  0.03178909  0.05804386 -0.25431719\n",
      "  0.34662587  0.00173893 -0.32559742  0.26715542 -0.19973087 -0.22992842\n",
      "  0.10452079 -0.3672529 ]\n",
      "Training Error:  10.494399097039315\n",
      "====================================================================================================\n",
      "Iteration:  879\n",
      "Previous theta :  [ 0.0006381  -0.09425129  0.09154166  0.03178909  0.05804386 -0.25431719\n",
      "  0.34662587  0.00173893 -0.32559742  0.26715542 -0.19973087 -0.22992842\n",
      "  0.10452079 -0.3672529 ]\n",
      "New theta_0 : [ 0.00063754 -0.09425794  0.09155835  0.03181136  0.05804138 -0.25434324\n",
      "  0.34661831  0.00174185 -0.32562101  0.26721241 -0.19978915 -0.22993124\n",
      "  0.10452003 -0.36725586]\n",
      "Training Error:  10.494390899328247\n",
      "====================================================================================================\n",
      "Iteration:  880\n",
      "Previous theta :  [ 0.00063754 -0.09425794  0.09155835  0.03181136  0.05804138 -0.25434324\n",
      "  0.34661831  0.00174185 -0.32562101  0.26721241 -0.19978915 -0.22993124\n",
      "  0.10452003 -0.36725586]\n",
      "New theta_0 : [ 0.00063699 -0.09426457  0.09157497  0.03183357  0.05803891 -0.25436914\n",
      "  0.34661078  0.00174476 -0.32564444  0.26726924 -0.19984729 -0.22993405\n",
      "  0.10451928 -0.36725881]\n",
      "Training Error:  10.494382753210283\n",
      "====================================================================================================\n",
      "Iteration:  881\n",
      "Previous theta :  [ 0.00063699 -0.09426457  0.09157497  0.03183357  0.05803891 -0.25436914\n",
      "  0.34661078  0.00174476 -0.32564444  0.26726924 -0.19984729 -0.22993405\n",
      "  0.10451928 -0.36725881]\n",
      "New theta_0 : [ 0.00063644 -0.09427117  0.09159152  0.03185574  0.05803644 -0.25439488\n",
      "  0.34660329  0.00174767 -0.32566772  0.26732591 -0.19990529 -0.22993685\n",
      "  0.10451853 -0.36726175]\n",
      "Training Error:  10.494374658303007\n",
      "====================================================================================================\n",
      "Iteration:  882\n",
      "Previous theta :  [ 0.00063644 -0.09427117  0.09159152  0.03185574  0.05803644 -0.25439488\n",
      "  0.34660329  0.00174767 -0.32566772  0.26732591 -0.19990529 -0.22993685\n",
      "  0.10451853 -0.36726175]\n",
      "New theta_0 : [ 0.0006359  -0.09427775  0.09160799  0.03187785  0.05803398 -0.25442048\n",
      "  0.34659584  0.00175057 -0.32569085  0.26738242 -0.19996316 -0.22993963\n",
      "  0.1045178  -0.36726468]\n",
      "Training Error:  10.49436661422753\n",
      "====================================================================================================\n",
      "Iteration:  883\n",
      "Previous theta :  [ 0.0006359  -0.09427775  0.09160799  0.03187785  0.05803398 -0.25442048\n",
      "  0.34659584  0.00175057 -0.32569085  0.26738242 -0.19996316 -0.22993963\n",
      "  0.1045178  -0.36726468]\n",
      "New theta_0 : [ 0.00063536 -0.09428429  0.0916244   0.03189991  0.05803152 -0.25444592\n",
      "  0.34658843  0.00175347 -0.32571382  0.26743877 -0.20002089 -0.2299424\n",
      "  0.10451707 -0.3672676 ]\n",
      "Training Error:  10.49435862060847\n",
      "====================================================================================================\n",
      "Iteration:  884\n",
      "Previous theta :  [ 0.00063536 -0.09428429  0.0916244   0.03189991  0.05803152 -0.25444592\n",
      "  0.34658843  0.00175347 -0.32571382  0.26743877 -0.20002089 -0.2299424\n",
      "  0.10451707 -0.3672676 ]\n",
      "New theta_0 : [ 0.00063482 -0.09429081  0.09164073  0.03192192  0.05802906 -0.25447121\n",
      "  0.34658105  0.00175636 -0.32573665  0.26749497 -0.20007849 -0.22994515\n",
      "  0.10451635 -0.36727051]\n",
      "Training Error:  10.494350677073886\n",
      "====================================================================================================\n",
      "Iteration:  885\n",
      "Previous theta :  [ 0.00063482 -0.09429081  0.09164073  0.03192192  0.05802906 -0.25447121\n",
      "  0.34658105  0.00175636 -0.32573665  0.26749497 -0.20007849 -0.22994515\n",
      "  0.10451635 -0.36727051]\n",
      "New theta_0 : [ 0.00063429 -0.0942973   0.091657    0.03194387  0.05802661 -0.25449636\n",
      "  0.34657371  0.00175924 -0.32575932  0.267551   -0.20013595 -0.22994789\n",
      "  0.10451563 -0.3672734 ]\n",
      "Training Error:  10.494342783255263\n",
      "====================================================================================================\n",
      "Iteration:  886\n",
      "Previous theta :  [ 0.00063429 -0.0942973   0.091657    0.03194387  0.05802661 -0.25449636\n",
      "  0.34657371  0.00175924 -0.32575932  0.267551   -0.20013595 -0.22994789\n",
      "  0.10451563 -0.3672734 ]\n",
      "New theta_0 : [ 0.00063376 -0.09430376  0.09167319  0.03196577  0.05802416 -0.25452135\n",
      "  0.3465664   0.00176212 -0.32578184  0.26760688 -0.20019328 -0.22995062\n",
      "  0.10451493 -0.36727629]\n",
      "Training Error:  10.494334938787459\n",
      "====================================================================================================\n",
      "Iteration:  887\n",
      "Previous theta :  [ 0.00063376 -0.09430376  0.09167319  0.03196577  0.05802416 -0.25452135\n",
      "  0.3465664   0.00176212 -0.32578184  0.26760688 -0.20019328 -0.22995062\n",
      "  0.10451493 -0.36727629]\n",
      "New theta_0 : [ 0.00063323 -0.09431019  0.09168931  0.03198762  0.05802172 -0.2545462\n",
      "  0.34655914  0.001765   -0.32580422  0.2676626  -0.20025047 -0.22995334\n",
      "  0.10451423 -0.36727917]\n",
      "Training Error:  10.494327143308674\n",
      "====================================================================================================\n",
      "Iteration:  888\n",
      "Previous theta :  [ 0.00063323 -0.09431019  0.09168931  0.03198762  0.05802172 -0.2545462\n",
      "  0.34655914  0.001765   -0.32580422  0.2676626  -0.20025047 -0.22995334\n",
      "  0.10451423 -0.36727917]\n",
      "New theta_0 : [ 0.00063271 -0.0943166   0.09170537  0.03200941  0.05801928 -0.25457091\n",
      "  0.3465519   0.00176786 -0.32582645  0.26771817 -0.20030753 -0.22995604\n",
      "  0.10451354 -0.36728204]\n",
      "Training Error:  10.49431939646041\n",
      "====================================================================================================\n",
      "Iteration:  889\n",
      "Previous theta :  [ 0.00063271 -0.0943166   0.09170537  0.03200941  0.05801928 -0.25457091\n",
      "  0.3465519   0.00176786 -0.32582645  0.26771817 -0.20030753 -0.22995604\n",
      "  0.10451354 -0.36728204]\n",
      "New theta_0 : [ 0.00063219 -0.09432298  0.09172135  0.03203116  0.05801685 -0.25459546\n",
      "  0.3465447   0.00177073 -0.32584853  0.26777358 -0.20036446 -0.22995872\n",
      "  0.10451286 -0.36728489]\n",
      "Training Error:  10.494311697887431\n",
      "====================================================================================================\n",
      "Iteration:  890\n",
      "Previous theta :  [ 0.00063219 -0.09432298  0.09172135  0.03203116  0.05801685 -0.25459546\n",
      "  0.3465447   0.00177073 -0.32584853  0.26777358 -0.20036446 -0.22995872\n",
      "  0.10451286 -0.36728489]\n",
      "New theta_0 : [ 0.00063167 -0.09432933  0.09173727  0.03205285  0.05801441 -0.25461988\n",
      "  0.34653754  0.00177358 -0.32587047  0.26782883 -0.20042125 -0.22996139\n",
      "  0.10451218 -0.36728774]\n",
      "Training Error:  10.49430404723774\n",
      "====================================================================================================\n",
      "Iteration:  891\n",
      "Previous theta :  [ 0.00063167 -0.09432933  0.09173727  0.03205285  0.05801441 -0.25461988\n",
      "  0.34653754  0.00177358 -0.32587047  0.26782883 -0.20042125 -0.22996139\n",
      "  0.10451218 -0.36728774]\n",
      "New theta_0 : [ 0.00063116 -0.09433566  0.09175312  0.03207448  0.05801199 -0.25464415\n",
      "  0.34653042  0.00177643 -0.32589227  0.26788393 -0.20047791 -0.22996405\n",
      "  0.10451151 -0.36729058]\n",
      "Training Error:  10.494296444162524\n",
      "====================================================================================================\n",
      "Iteration:  892\n",
      "Previous theta :  [ 0.00063116 -0.09433566  0.09175312  0.03207448  0.05801199 -0.25464415\n",
      "  0.34653042  0.00177643 -0.32589227  0.26788393 -0.20047791 -0.22996405\n",
      "  0.10451151 -0.36729058]\n",
      "New theta_0 : [ 0.00063065 -0.09434196  0.0917689   0.03209607  0.05800956 -0.25466828\n",
      "  0.34652332  0.00177928 -0.32591392  0.26793887 -0.20053444 -0.2299667\n",
      "  0.10451085 -0.36729341]\n",
      "Training Error:  10.494288888316124\n",
      "====================================================================================================\n",
      "Iteration:  893\n",
      "Previous theta :  [ 0.00063065 -0.09434196  0.0917689   0.03209607  0.05800956 -0.25466828\n",
      "  0.34652332  0.00177928 -0.32591392  0.26793887 -0.20053444 -0.2299667\n",
      "  0.10451085 -0.36729341]\n",
      "New theta_0 : [ 0.00063015 -0.09434823  0.09178461  0.0321176   0.05800715 -0.25469226\n",
      "  0.34651626  0.00178212 -0.32593543  0.26799366 -0.20059083 -0.22996933\n",
      "  0.1045102  -0.36729622]\n",
      "Training Error:  10.494281379356018\n",
      "====================================================================================================\n",
      "Iteration:  894\n",
      "Previous theta :  [ 0.00063015 -0.09434823  0.09178461  0.0321176   0.05800715 -0.25469226\n",
      "  0.34651626  0.00178212 -0.32593543  0.26799366 -0.20059083 -0.22996933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.1045102  -0.36729622]\n",
      "New theta_0 : [ 0.00062964 -0.09435448  0.09180025  0.03213909  0.05800473 -0.25471611\n",
      "  0.34650924  0.00178495 -0.3259568   0.2680483  -0.20064709 -0.22997196\n",
      "  0.10450955 -0.36729903]\n",
      "Training Error:  10.494273916942758\n",
      "====================================================================================================\n",
      "Iteration:  895\n",
      "Previous theta :  [ 0.00062964 -0.09435448  0.09180025  0.03213909  0.05800473 -0.25471611\n",
      "  0.34650924  0.00178495 -0.3259568   0.2680483  -0.20064709 -0.22997196\n",
      "  0.10450955 -0.36729903]\n",
      "New theta_0 : [ 0.00062914 -0.09436069  0.09181583  0.03216052  0.05800232 -0.25473982\n",
      "  0.34650225  0.00178778 -0.32597803  0.26810278 -0.20070322 -0.22997456\n",
      "  0.10450891 -0.36730183]\n",
      "Training Error:  10.494266500739954\n",
      "====================================================================================================\n",
      "Iteration:  896\n",
      "Previous theta :  [ 0.00062914 -0.09436069  0.09181583  0.03216052  0.05800232 -0.25473982\n",
      "  0.34650225  0.00178778 -0.32597803  0.26810278 -0.20070322 -0.22997456\n",
      "  0.10450891 -0.36730183]\n",
      "New theta_0 : [ 0.00062865 -0.09436689  0.09183134  0.0321819   0.05799991 -0.25476339\n",
      "  0.3464953   0.00179061 -0.32599912  0.26815711 -0.20075921 -0.22997716\n",
      "  0.10450828 -0.36730462]\n",
      "Training Error:  10.49425913041424\n",
      "====================================================================================================\n",
      "Iteration:  897\n",
      "Previous theta :  [ 0.00062865 -0.09436689  0.09183134  0.0321819   0.05799991 -0.25476339\n",
      "  0.3464953   0.00179061 -0.32599912  0.26815711 -0.20075921 -0.22997716\n",
      "  0.10450828 -0.36730462]\n",
      "New theta_0 : [ 0.00062816 -0.09437306  0.09184679  0.03220322  0.05799751 -0.25478682\n",
      "  0.34648837  0.00179342 -0.32602007  0.26821129 -0.20081507 -0.22997974\n",
      "  0.10450765 -0.3673074 ]\n",
      "Training Error:  10.494251805635233\n",
      "====================================================================================================\n",
      "Iteration:  898\n",
      "Previous theta :  [ 0.00062816 -0.09437306  0.09184679  0.03220322  0.05799751 -0.25478682\n",
      "  0.34648837  0.00179342 -0.32602007  0.26821129 -0.20081507 -0.22997974\n",
      "  0.10450765 -0.3673074 ]\n",
      "New theta_0 : [ 0.00062767 -0.0943792   0.09186217  0.0322245   0.05799511 -0.25481011\n",
      "  0.34648149  0.00179623 -0.32604089  0.26826531 -0.2008708  -0.22998231\n",
      "  0.10450703 -0.36731017]\n",
      "Training Error:  10.494244526075502\n",
      "====================================================================================================\n",
      "Iteration:  899\n",
      "Previous theta :  [ 0.00062767 -0.0943792   0.09186217  0.0322245   0.05799511 -0.25481011\n",
      "  0.34648149  0.00179623 -0.32604089  0.26826531 -0.2008708  -0.22998231\n",
      "  0.10450703 -0.36731017]\n",
      "New theta_0 : [ 0.00062718 -0.09438531  0.09187749  0.03224572  0.05799272 -0.25483327\n",
      "  0.34647463  0.00179904 -0.32606157  0.26831919 -0.2009264  -0.22998487\n",
      "  0.10450642 -0.36731293]\n",
      "Training Error:  10.494237291410538\n",
      "====================================================================================================\n",
      "Iteration:  900\n",
      "Previous theta :  [ 0.00062718 -0.09438531  0.09187749  0.03224572  0.05799272 -0.25483327\n",
      "  0.34647463  0.00179904 -0.32606157  0.26831919 -0.2009264  -0.22998487\n",
      "  0.10450642 -0.36731293]\n",
      "New theta_0 : [ 0.0006267  -0.0943914   0.09189274  0.03226689  0.05799033 -0.25485629\n",
      "  0.34646781  0.00180184 -0.32608211  0.26837291 -0.20098187 -0.22998741\n",
      "  0.10450582 -0.36731569]\n",
      "Training Error:  10.494230101318722\n",
      "====================================================================================================\n",
      "Iteration:  901\n",
      "Previous theta :  [ 0.0006267  -0.0943914   0.09189274  0.03226689  0.05799033 -0.25485629\n",
      "  0.34646781  0.00180184 -0.32608211  0.26837291 -0.20098187 -0.22998741\n",
      "  0.10450582 -0.36731569]\n",
      "New theta_0 : [ 0.00062622 -0.09439747  0.09190792  0.03228801  0.05798794 -0.25487918\n",
      "  0.34646102  0.00180464 -0.32610252  0.26842648 -0.20103721 -0.22998994\n",
      "  0.10450522 -0.36731843]\n",
      "Training Error:  10.494222955481295\n",
      "====================================================================================================\n",
      "Iteration:  902\n",
      "Previous theta :  [ 0.00062622 -0.09439747  0.09190792  0.03228801  0.05798794 -0.25487918\n",
      "  0.34646102  0.00180464 -0.32610252  0.26842648 -0.20103721 -0.22998994\n",
      "  0.10450522 -0.36731843]\n",
      "New theta_0 : [ 0.00062574 -0.09440351  0.09192304  0.03230908  0.05798556 -0.25490194\n",
      "  0.34645426  0.00180743 -0.3261228   0.2684799  -0.20109241 -0.22999246\n",
      "  0.10450463 -0.36732116]\n",
      "Training Error:  10.494215853582315\n",
      "====================================================================================================\n",
      "Iteration:  903\n",
      "Previous theta :  [ 0.00062574 -0.09440351  0.09192304  0.03230908  0.05798556 -0.25490194\n",
      "  0.34645426  0.00180743 -0.3261228   0.2684799  -0.20109241 -0.22999246\n",
      "  0.10450463 -0.36732116]\n",
      "New theta_0 : [ 0.00062527 -0.09440952  0.0919381   0.0323301   0.05798318 -0.25492456\n",
      "  0.34644754  0.00181021 -0.32614294  0.26853318 -0.20114749 -0.22999497\n",
      "  0.10450404 -0.36732389]\n",
      "Training Error:  10.494208795308646\n",
      "====================================================================================================\n",
      "Iteration:  904\n",
      "Previous theta :  [ 0.00062527 -0.09440952  0.0919381   0.0323301   0.05798318 -0.25492456\n",
      "  0.34644754  0.00181021 -0.32614294  0.26853318 -0.20114749 -0.22999497\n",
      "  0.10450404 -0.36732389]\n",
      "New theta_0 : [ 0.0006248  -0.09441551  0.09195309  0.03235107  0.05798081 -0.25494705\n",
      "  0.34644085  0.00181299 -0.32616295  0.2685863  -0.20120243 -0.22999746\n",
      "  0.10450346 -0.3673266 ]\n",
      "Training Error:  10.49420178034991\n",
      "====================================================================================================\n",
      "Iteration:  905\n",
      "Previous theta :  [ 0.0006248  -0.09441551  0.09195309  0.03235107  0.05798081 -0.25494705\n",
      "  0.34644085  0.00181299 -0.32616295  0.2685863  -0.20120243 -0.22999746\n",
      "  0.10450346 -0.3673266 ]\n",
      "New theta_0 : [ 0.00062433 -0.09442147  0.09196803  0.03237198  0.05797844 -0.25496941\n",
      "  0.34643419  0.00181576 -0.32618284  0.26863927 -0.20125724 -0.22999994\n",
      "  0.10450289 -0.36732931]\n",
      "Training Error:  10.494194808398461\n",
      "====================================================================================================\n",
      "Iteration:  906\n",
      "Previous theta :  [ 0.00062433 -0.09442147  0.09196803  0.03237198  0.05797844 -0.25496941\n",
      "  0.34643419  0.00181576 -0.32618284  0.26863927 -0.20125724 -0.22999994\n",
      "  0.10450289 -0.36732931]\n",
      "New theta_0 : [ 0.00062387 -0.09442741  0.09198289  0.03239285  0.05797608 -0.25499164\n",
      "  0.34642756  0.00181853 -0.32620259  0.2686921  -0.20131193 -0.23000241\n",
      "  0.10450233 -0.367332  ]\n",
      "Training Error:  10.494187879149369\n",
      "====================================================================================================\n",
      "Iteration:  907\n",
      "Previous theta :  [ 0.00062387 -0.09442741  0.09198289  0.03239285  0.05797608 -0.25499164\n",
      "  0.34642756  0.00181853 -0.32620259  0.2686921  -0.20131193 -0.23000241\n",
      "  0.10450233 -0.367332  ]\n",
      "New theta_0 : [ 0.00062341 -0.09443333  0.0919977   0.03241366  0.05797372 -0.25501375\n",
      "  0.34642097  0.00182129 -0.32622221  0.26874478 -0.20136648 -0.23000487\n",
      "  0.10450177 -0.36733469]\n",
      "Training Error:  10.494180992300366\n",
      "====================================================================================================\n",
      "Iteration:  908\n",
      "Previous theta :  [ 0.00062341 -0.09443333  0.0919977   0.03241366  0.05797372 -0.25501375\n",
      "  0.34642097  0.00182129 -0.32622221  0.26874478 -0.20136648 -0.23000487\n",
      "  0.10450177 -0.36733469]\n",
      "New theta_0 : [ 0.00062295 -0.09443922  0.09201244  0.03243442  0.05797136 -0.25503572\n",
      "  0.3464144   0.00182405 -0.32624171  0.26879731 -0.20142091 -0.23000732\n",
      "  0.10450121 -0.36733737]\n",
      "Training Error:  10.49417414755184\n",
      "====================================================================================================\n",
      "Iteration:  909\n",
      "Previous theta :  [ 0.00062295 -0.09443922  0.09201244  0.03243442  0.05797136 -0.25503572\n",
      "  0.3464144   0.00182405 -0.32624171  0.26879731 -0.20142091 -0.23000732\n",
      "  0.10450121 -0.36733737]\n",
      "New theta_0 : [ 0.00062249 -0.09444508  0.09202712  0.03245513  0.05796901 -0.25505757\n",
      "  0.34640787  0.0018268  -0.32626108  0.26884969 -0.2014752  -0.23000975\n",
      "  0.10450067 -0.36734004]\n",
      "Training Error:  10.494167344606792\n",
      "====================================================================================================\n",
      "Iteration:  910\n",
      "Previous theta :  [ 0.00062249 -0.09444508  0.09202712  0.03245513  0.05796901 -0.25505757\n",
      "  0.34640787  0.0018268  -0.32626108  0.26884969 -0.2014752  -0.23000975\n",
      "  0.10450067 -0.36734004]\n",
      "New theta_0 : [ 0.00062204 -0.09445092  0.09204174  0.0324758   0.05796666 -0.25507929\n",
      "  0.34640137  0.00182955 -0.32628032  0.26890193 -0.20152937 -0.23001217\n",
      "  0.10450013 -0.3673427 ]\n",
      "Training Error:  10.49416058317081\n",
      "====================================================================================================\n",
      "Iteration:  911\n",
      "Previous theta :  [ 0.00062204 -0.09445092  0.09204174  0.0324758   0.05796666 -0.25507929\n",
      "  0.34640137  0.00182955 -0.32628032  0.26890193 -0.20152937 -0.23001217\n",
      "  0.10450013 -0.3673427 ]\n",
      "New theta_0 : [ 0.00062159 -0.09445674  0.0920563   0.03249641  0.05796431 -0.25510088\n",
      "  0.3463949   0.00183229 -0.32629944  0.26895402 -0.2015834  -0.23001458\n",
      "  0.10449959 -0.36734536]\n",
      "Training Error:  10.49415386295205\n",
      "====================================================================================================\n",
      "Iteration:  912\n",
      "Previous theta :  [ 0.00062159 -0.09445674  0.0920563   0.03249641  0.05796431 -0.25510088\n",
      "  0.3463949   0.00183229 -0.32629944  0.26895402 -0.2015834  -0.23001458\n",
      "  0.10449959 -0.36734536]\n",
      "New theta_0 : [ 0.00062115 -0.09446253  0.09207079  0.03251697  0.05796197 -0.25512235\n",
      "  0.34638846  0.00183502 -0.32631843  0.26900597 -0.20163731 -0.23001698\n",
      "  0.10449906 -0.367348  ]\n",
      "Training Error:  10.494147183661198\n",
      "====================================================================================================\n",
      "Iteration:  913\n",
      "Previous theta :  [ 0.00062115 -0.09446253  0.09207079  0.03251697  0.05796197 -0.25512235\n",
      "  0.34638846  0.00183502 -0.32631843  0.26900597 -0.20163731 -0.23001698\n",
      "  0.10449906 -0.367348  ]\n",
      "New theta_0 : [ 0.0006207  -0.0944683   0.09208523  0.03253748  0.05795964 -0.25514369\n",
      "  0.34638205  0.00183775 -0.3263373   0.26905777 -0.20169109 -0.23001937\n",
      "  0.10449854 -0.36735064]\n",
      "Training Error:  10.494140545011447\n",
      "====================================================================================================\n",
      "Iteration:  914\n",
      "Previous theta :  [ 0.0006207  -0.0944683   0.09208523  0.03253748  0.05795964 -0.25514369\n",
      "  0.34638205  0.00183775 -0.3263373   0.26905777 -0.20169109 -0.23001937\n",
      "  0.10449854 -0.36735064]\n",
      "New theta_0 : [ 0.00062026 -0.09447405  0.0920996   0.03255794  0.05795731 -0.25516492\n",
      "  0.34637567  0.00184048 -0.32635605  0.26910942 -0.20174474 -0.23002174\n",
      "  0.10449803 -0.36735327]\n",
      "Training Error:  10.49413394671847\n",
      "====================================================================================================\n",
      "Iteration:  915\n",
      "Previous theta :  [ 0.00062026 -0.09447405  0.0920996   0.03255794  0.05795731 -0.25516492\n",
      "  0.34637567  0.00184048 -0.32635605  0.26910942 -0.20174474 -0.23002174\n",
      "  0.10449803 -0.36735327]\n",
      "New theta_0 : [ 0.00061983 -0.09447977  0.09211392  0.03257835  0.05795498 -0.25518602\n",
      "  0.34636932  0.0018432  -0.32637467  0.26916093 -0.20179826 -0.23002411\n",
      "  0.10449752 -0.36735588]\n",
      "Training Error:  10.494127388500393\n",
      "====================================================================================================\n",
      "Iteration:  916\n",
      "Previous theta :  [ 0.00061983 -0.09447977  0.09211392  0.03257835  0.05795498 -0.25518602\n",
      "  0.34636932  0.0018432  -0.32637467  0.26916093 -0.20179826 -0.23002411\n",
      "  0.10449752 -0.36735588]\n",
      "New theta_0 : [ 0.00061939 -0.09448547  0.09212817  0.03259871  0.05795266 -0.25520699\n",
      "  0.346363    0.00184591 -0.32639317  0.2692123  -0.20185165 -0.23002646\n",
      "  0.10449701 -0.36735849]\n",
      "Training Error:  10.49412087007777\n",
      "====================================================================================================\n",
      "Iteration:  917\n",
      "Previous theta :  [ 0.00061939 -0.09448547  0.09212817  0.03259871  0.05795266 -0.25520699\n",
      "  0.346363    0.00184591 -0.32639317  0.2692123  -0.20185165 -0.23002646\n",
      "  0.10449701 -0.36735849]\n",
      "New theta_0 : [ 0.00061896 -0.09449114  0.09214237  0.03261902  0.05795034 -0.25522785\n",
      "  0.34635671  0.00184862 -0.32641156  0.26926352 -0.20190492 -0.2300288\n",
      "  0.10449651 -0.3673611 ]\n",
      "Training Error:  10.494114391173554\n",
      "====================================================================================================\n",
      "Iteration:  918\n",
      "Previous theta :  [ 0.00061896 -0.09449114  0.09214237  0.03261902  0.05795034 -0.25522785\n",
      "  0.34635671  0.00184862 -0.32641156  0.26926352 -0.20190492 -0.2300288\n",
      "  0.10449651 -0.3673611 ]\n",
      "New theta_0 : [ 0.00061853 -0.09449679  0.09215651  0.03263928  0.05794802 -0.25524859\n",
      "  0.34635045  0.00185132 -0.32642982  0.2693146  -0.20195806 -0.23003113\n",
      "  0.10449602 -0.36736369]\n",
      "Training Error:  10.494107951513072\n",
      "====================================================================================================\n",
      "Iteration:  919\n",
      "Previous theta :  [ 0.00061853 -0.09449679  0.09215651  0.03263928  0.05794802 -0.25524859\n",
      "  0.34635045  0.00185132 -0.32642982  0.2693146  -0.20195806 -0.23003113\n",
      "  0.10449602 -0.36736369]\n",
      "New theta_0 : [ 0.00061811 -0.09450242  0.09217059  0.03265949  0.05794571 -0.2552692\n",
      "  0.34634422  0.00185402 -0.32644797  0.26936554 -0.20201107 -0.23003345\n",
      "  0.10449553 -0.36736628]\n",
      "Training Error:  10.49410155082401\n",
      "====================================================================================================\n",
      "Iteration:  920\n",
      "Previous theta :  [ 0.00061811 -0.09450242  0.09217059  0.03265949  0.05794571 -0.2552692\n",
      "  0.34634422  0.00185402 -0.32644797  0.26936554 -0.20201107 -0.23003345\n",
      "  0.10449553 -0.36736628]\n",
      "New theta_0 : [ 0.00061768 -0.09450802  0.09218461  0.03267965  0.05794341 -0.2552897\n",
      "  0.34633801  0.00185671 -0.326466    0.26941633 -0.20206396 -0.23003576\n",
      "  0.10449505 -0.36736885]\n",
      "Training Error:  10.494095188836365\n",
      "====================================================================================================\n",
      "Iteration:  921\n",
      "Previous theta :  [ 0.00061768 -0.09450802  0.09218461  0.03267965  0.05794341 -0.2552897\n",
      "  0.34633801  0.00185671 -0.326466    0.26941633 -0.20206396 -0.23003576\n",
      "  0.10449505 -0.36736885]\n",
      "New theta_0 : [ 0.00061726 -0.09451361  0.09219857  0.03269976  0.05794111 -0.25531008\n",
      "  0.34633184  0.0018594  -0.32648391  0.26946699 -0.20211672 -0.23003805\n",
      "  0.10449458 -0.36737142]\n",
      "Training Error:  10.494088865282448\n",
      "====================================================================================================\n",
      "Iteration:  922\n",
      "Previous theta :  [ 0.00061726 -0.09451361  0.09219857  0.03269976  0.05794111 -0.25531008\n",
      "  0.34633184  0.0018594  -0.32648391  0.26946699 -0.20211672 -0.23003805\n",
      "  0.10449458 -0.36737142]\n",
      "New theta_0 : [ 0.00061684 -0.09451916  0.09221247  0.03271982  0.05793881 -0.25533035\n",
      "  0.3463257   0.00186208 -0.3265017   0.2695175  -0.20216935 -0.23004034\n",
      "  0.10449411 -0.36737398]\n",
      "Training Error:  10.494082579896835\n",
      "====================================================================================================\n",
      "Iteration:  923\n",
      "Previous theta :  [ 0.00061684 -0.09451916  0.09221247  0.03271982  0.05793881 -0.25533035\n",
      "  0.3463257   0.00186208 -0.3265017   0.2695175  -0.20216935 -0.23004034\n",
      "  0.10449411 -0.36737398]\n",
      "New theta_0 : [ 0.00061643 -0.0945247   0.09222632  0.03273983  0.05793651 -0.25535049\n",
      "  0.34631958  0.00186476 -0.32651938  0.26956787 -0.20222185 -0.23004261\n",
      "  0.10449364 -0.36737653]\n",
      "Training Error:  10.494076332416368\n",
      "====================================================================================================\n",
      "Iteration:  924\n",
      "Previous theta :  [ 0.00061643 -0.0945247   0.09222632  0.03273983  0.05793651 -0.25535049\n",
      "  0.34631958  0.00186476 -0.32651938  0.26956787 -0.20222185 -0.23004261\n",
      "  0.10449364 -0.36737653]\n",
      "New theta_0 : [ 0.00061602 -0.09453021  0.09224011  0.03275979  0.05793423 -0.25537052\n",
      "  0.3463135   0.00186743 -0.32653695  0.2696181  -0.20227423 -0.23004487\n",
      "  0.10449318 -0.36737908]\n",
      "Training Error:  10.494070122580101\n",
      "====================================================================================================\n",
      "Iteration:  925\n",
      "Previous theta :  [ 0.00061602 -0.09453021  0.09224011  0.03275979  0.05793423 -0.25537052\n",
      "  0.3463135   0.00186743 -0.32653695  0.2696181  -0.20227423 -0.23004487\n",
      "  0.10449318 -0.36737908]\n",
      "New theta_0 : [ 0.00061561 -0.09453571  0.09225384  0.0327797   0.05793194 -0.25539044\n",
      "  0.34630744  0.0018701  -0.3265544   0.26966819 -0.20232649 -0.23004712\n",
      "  0.10449273 -0.36738162]\n",
      "Training Error:  10.494063950129307\n",
      "====================================================================================================\n",
      "Iteration:  926\n",
      "Previous theta :  [ 0.00061561 -0.09453571  0.09225384  0.0327797   0.05793194 -0.25539044\n",
      "  0.34630744  0.0018701  -0.3265544   0.26966819 -0.20232649 -0.23004712\n",
      "  0.10449273 -0.36738162]\n",
      "New theta_0 : [ 0.0006152  -0.09454117  0.09226752  0.03279957  0.05792966 -0.25541024\n",
      "  0.34630141  0.00187276 -0.32657173  0.26971814 -0.20237861 -0.23004937\n",
      "  0.10449228 -0.36738414]\n",
      "Training Error:  10.494057814807427\n",
      "====================================================================================================\n",
      "Iteration:  927\n",
      "Previous theta :  [ 0.0006152  -0.09454117  0.09226752  0.03279957  0.05792966 -0.25541024\n",
      "  0.34630141  0.00187276 -0.32657173  0.26971814 -0.20237861 -0.23004937\n",
      "  0.10449228 -0.36738414]\n",
      "New theta_0 : [ 0.0006148  -0.09454662  0.09228113  0.03281938  0.05792738 -0.25542993\n",
      "  0.34629541  0.00187542 -0.32658896  0.26976795 -0.20243062 -0.2300516\n",
      "  0.10449184 -0.36738666]\n",
      "Training Error:  10.494051716360076\n",
      "====================================================================================================\n",
      "Iteration:  928\n",
      "Previous theta :  [ 0.0006148  -0.09454662  0.09228113  0.03281938  0.05792738 -0.25542993\n",
      "  0.34629541  0.00187542 -0.32658896  0.26976795 -0.20243062 -0.2300516\n",
      "  0.10449184 -0.36738666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.0006144  -0.09455204  0.0922947   0.03283915  0.05792511 -0.25544951\n",
      "  0.34628943  0.00187807 -0.32660608  0.26981763 -0.20248249 -0.23005382\n",
      "  0.1044914  -0.36738918]\n",
      "Training Error:  10.494045654534993\n",
      "====================================================================================================\n",
      "Iteration:  929\n",
      "Previous theta :  [ 0.0006144  -0.09455204  0.0922947   0.03283915  0.05792511 -0.25544951\n",
      "  0.34628943  0.00187807 -0.32660608  0.26981763 -0.20248249 -0.23005382\n",
      "  0.1044914  -0.36738918]\n",
      "New theta_0 : [ 0.000614   -0.09455745  0.09230821  0.03285886  0.05792284 -0.25546897\n",
      "  0.34628349  0.00188071 -0.32662308  0.26986716 -0.20253425 -0.23005602\n",
      "  0.10449097 -0.36739168]\n",
      "Training Error:  10.49403962908204\n",
      "====================================================================================================\n",
      "Iteration:  930\n",
      "Previous theta :  [ 0.000614   -0.09455745  0.09230821  0.03285886  0.05792284 -0.25546897\n",
      "  0.34628349  0.00188071 -0.32662308  0.26986716 -0.20253425 -0.23005602\n",
      "  0.10449097 -0.36739168]\n",
      "New theta_0 : [ 0.0006136  -0.09456283  0.09232166  0.03287853  0.05792058 -0.25548833\n",
      "  0.34627757  0.00188335 -0.32663997  0.26991655 -0.20258588 -0.23005822\n",
      "  0.10449055 -0.36739418]\n",
      "Training Error:  10.494033639753164\n",
      "====================================================================================================\n",
      "Iteration:  931\n",
      "Previous theta :  [ 0.0006136  -0.09456283  0.09232166  0.03287853  0.05792058 -0.25548833\n",
      "  0.34627757  0.00188335 -0.32663997  0.26991655 -0.20258588 -0.23005822\n",
      "  0.10449055 -0.36739418]\n",
      "New theta_0 : [ 0.00061321 -0.09456818  0.09233505  0.03289815  0.05791832 -0.25550757\n",
      "  0.34627168  0.00188599 -0.32665676  0.26996581 -0.20263738 -0.23006041\n",
      "  0.10449012 -0.36739667]\n",
      "Training Error:  10.494027686302386\n",
      "====================================================================================================\n",
      "Iteration:  932\n",
      "Previous theta :  [ 0.00061321 -0.09456818  0.09233505  0.03289815  0.05791832 -0.25550757\n",
      "  0.34627168  0.00188599 -0.32665676  0.26996581 -0.20263738 -0.23006041\n",
      "  0.10449012 -0.36739667]\n",
      "New theta_0 : [ 0.00061282 -0.09457352  0.0923484   0.03291772  0.05791606 -0.2555267\n",
      "  0.34626581  0.00188862 -0.32667343  0.27001493 -0.20268876 -0.23006259\n",
      "  0.10448971 -0.36739915]\n",
      "Training Error:  10.494021768485773\n",
      "====================================================================================================\n",
      "Iteration:  933\n",
      "Previous theta :  [ 0.00061282 -0.09457352  0.0923484   0.03291772  0.05791606 -0.2555267\n",
      "  0.34626581  0.00188862 -0.32667343  0.27001493 -0.20268876 -0.23006259\n",
      "  0.10448971 -0.36739915]\n",
      "New theta_0 : [ 0.00061243 -0.09457884  0.09236168  0.03293724  0.05791381 -0.25554573\n",
      "  0.34625998  0.00189124 -0.32669     0.27006392 -0.20274001 -0.23006476\n",
      "  0.1044893  -0.36740162]\n",
      "Training Error:  10.49401588606142\n",
      "====================================================================================================\n",
      "Iteration:  934\n",
      "Previous theta :  [ 0.00061243 -0.09457884  0.09236168  0.03293724  0.05791381 -0.25554573\n",
      "  0.34625998  0.00189124 -0.32669     0.27006392 -0.20274001 -0.23006476\n",
      "  0.1044893  -0.36740162]\n",
      "New theta_0 : [ 0.00061204 -0.09458413  0.09237492  0.03295671  0.05791157 -0.25556464\n",
      "  0.34625417  0.00189386 -0.32670646  0.27011276 -0.20279114 -0.23006691\n",
      "  0.10448889 -0.36740409]\n",
      "Training Error:  10.494010038789435\n",
      "====================================================================================================\n",
      "Iteration:  935\n",
      "Previous theta :  [ 0.00061204 -0.09458413  0.09237492  0.03295671  0.05791157 -0.25556464\n",
      "  0.34625417  0.00189386 -0.32670646  0.27011276 -0.20279114 -0.23006691\n",
      "  0.10448889 -0.36740409]\n",
      "New theta_0 : [ 0.00061166 -0.0945894   0.09238809  0.03297614  0.05790933 -0.25558345\n",
      "  0.34624838  0.00189647 -0.32672282  0.27016147 -0.20284215 -0.23006906\n",
      "  0.10448849 -0.36740655]\n",
      "Training Error:  10.4940042264319\n",
      "====================================================================================================\n",
      "Iteration:  936\n",
      "Previous theta :  [ 0.00061166 -0.0945894   0.09238809  0.03297614  0.05790933 -0.25558345\n",
      "  0.34624838  0.00189647 -0.32672282  0.27016147 -0.20284215 -0.23006906\n",
      "  0.10448849 -0.36740655]\n",
      "New theta_0 : [ 0.00061128 -0.09459465  0.09240122  0.03299552  0.05790709 -0.25560215\n",
      "  0.34624263  0.00189908 -0.32673907  0.27021005 -0.20289304 -0.23007119\n",
      "  0.10448809 -0.367409  ]\n",
      "Training Error:  10.493998448752867\n",
      "====================================================================================================\n",
      "Iteration:  937\n",
      "Previous theta :  [ 0.00061128 -0.09459465  0.09240122  0.03299552  0.05790709 -0.25560215\n",
      "  0.34624263  0.00189908 -0.32673907  0.27021005 -0.20289304 -0.23007119\n",
      "  0.10448809 -0.367409  ]\n",
      "New theta_0 : [ 0.0006109  -0.09459988  0.09241429  0.03301484  0.05790485 -0.25562075\n",
      "  0.34623689  0.00190169 -0.32675522  0.27025849 -0.2029438  -0.23007332\n",
      "  0.1044877  -0.36741144]\n",
      "Training Error:  10.49399270551834\n",
      "====================================================================================================\n",
      "Iteration:  938\n",
      "Previous theta :  [ 0.0006109  -0.09459988  0.09241429  0.03301484  0.05790485 -0.25562075\n",
      "  0.34623689  0.00190169 -0.32675522  0.27025849 -0.2029438  -0.23007332\n",
      "  0.1044877  -0.36741144]\n",
      "New theta_0 : [ 0.00061052 -0.09460509  0.09242731  0.03303412  0.05790262 -0.25563924\n",
      "  0.34623119  0.00190429 -0.32677126  0.2703068  -0.20299444 -0.23007544\n",
      "  0.10448732 -0.36741388]\n",
      "Training Error:  10.493986996496234\n",
      "====================================================================================================\n",
      "Iteration:  939\n",
      "Previous theta :  [ 0.00061052 -0.09460509  0.09242731  0.03303412  0.05790262 -0.25563924\n",
      "  0.34623119  0.00190429 -0.32677126  0.2703068  -0.20299444 -0.23007544\n",
      "  0.10448732 -0.36741388]\n",
      "New theta_0 : [ 0.00061015 -0.09461028  0.09244027  0.03305336  0.0579004  -0.25565762\n",
      "  0.34622551  0.00190688 -0.3267872   0.27035497 -0.20304495 -0.23007754\n",
      "  0.10448693 -0.36741631]\n",
      "Training Error:  10.493981321456381\n",
      "====================================================================================================\n",
      "Iteration:  940\n",
      "Previous theta :  [ 0.00061015 -0.09461028  0.09244027  0.03305336  0.0579004  -0.25565762\n",
      "  0.34622551  0.00190688 -0.3267872   0.27035497 -0.20304495 -0.23007754\n",
      "  0.10448693 -0.36741631]\n",
      "New theta_0 : [ 0.00060978 -0.09461544  0.09245319  0.03307254  0.05789818 -0.2556759\n",
      "  0.34621986  0.00190947 -0.32680303  0.270403   -0.20309535 -0.23007964\n",
      "  0.10448656 -0.36741873]\n",
      "Training Error:  10.493975680170497\n",
      "====================================================================================================\n",
      "Iteration:  941\n",
      "Previous theta :  [ 0.00060978 -0.09461544  0.09245319  0.03307254  0.05789818 -0.2556759\n",
      "  0.34621986  0.00190947 -0.32680303  0.270403   -0.20309535 -0.23007964\n",
      "  0.10448656 -0.36741873]\n",
      "New theta_0 : [ 0.00060941 -0.09462059  0.09246605  0.03309168  0.05789596 -0.25569408\n",
      "  0.34621423  0.00191205 -0.32681876  0.2704509  -0.20314562 -0.23008172\n",
      "  0.10448619 -0.36742114]\n",
      "Training Error:  10.493970072412155\n",
      "====================================================================================================\n",
      "Iteration:  942\n",
      "Previous theta :  [ 0.00060941 -0.09462059  0.09246605  0.03309168  0.05789596 -0.25569408\n",
      "  0.34621423  0.00191205 -0.32681876  0.2704509  -0.20314562 -0.23008172\n",
      "  0.10448619 -0.36742114]\n",
      "New theta_0 : [ 0.00060904 -0.09462572  0.09247885  0.03311077  0.05789375 -0.25571215\n",
      "  0.34620863  0.00191463 -0.3268344   0.27049867 -0.20319577 -0.2300838\n",
      "  0.10448582 -0.36742355]\n",
      "Training Error:  10.49396449795679\n",
      "====================================================================================================\n",
      "Iteration:  943\n",
      "Previous theta :  [ 0.00060904 -0.09462572  0.09247885  0.03311077  0.05789375 -0.25571215\n",
      "  0.34620863  0.00191463 -0.3268344   0.27049867 -0.20319577 -0.2300838\n",
      "  0.10448582 -0.36742355]\n",
      "New theta_0 : [ 0.00060868 -0.09463082  0.09249161  0.03312981  0.05789154 -0.25573012\n",
      "  0.34620305  0.0019172  -0.32684993  0.27054631 -0.20324579 -0.23008587\n",
      "  0.10448546 -0.36742594]\n",
      "Training Error:  10.493958956581652\n",
      "====================================================================================================\n",
      "Iteration:  944\n",
      "Previous theta :  [ 0.00060868 -0.09463082  0.09249161  0.03312981  0.05789154 -0.25573012\n",
      "  0.34620305  0.0019172  -0.32684993  0.27054631 -0.20324579 -0.23008587\n",
      "  0.10448546 -0.36742594]\n",
      "New theta_0 : [ 0.00060832 -0.0946359   0.09250431  0.0331488   0.05788934 -0.25574799\n",
      "  0.3461975   0.00191977 -0.32686536  0.27059381 -0.2032957  -0.23008792\n",
      "  0.1044851  -0.36742834]\n",
      "Training Error:  10.493953448065806\n",
      "====================================================================================================\n",
      "Iteration:  945\n",
      "Previous theta :  [ 0.00060832 -0.0946359   0.09250431  0.0331488   0.05788934 -0.25574799\n",
      "  0.3461975   0.00191977 -0.32686536  0.27059381 -0.2032957  -0.23008792\n",
      "  0.1044851  -0.36742834]\n",
      "New theta_0 : [ 0.00060796 -0.09464097  0.09251697  0.03316775  0.05788714 -0.25576576\n",
      "  0.34619198  0.00192233 -0.32688069  0.27064119 -0.20334548 -0.23008997\n",
      "  0.10448474 -0.36743072]\n",
      "Training Error:  10.493947972190114\n",
      "====================================================================================================\n",
      "Iteration:  946\n",
      "Previous theta :  [ 0.00060796 -0.09464097  0.09251697  0.03316775  0.05788714 -0.25576576\n",
      "  0.34619198  0.00192233 -0.32688069  0.27064119 -0.20334548 -0.23008997\n",
      "  0.10448474 -0.36743072]\n",
      "New theta_0 : [ 0.0006076  -0.09464601  0.09252957  0.03318665  0.05788494 -0.25578343\n",
      "  0.34618648  0.00192489 -0.32689593  0.27068843 -0.20339515 -0.23009201\n",
      "  0.10448439 -0.3674331 ]\n",
      "Training Error:  10.493942528737202\n",
      "====================================================================================================\n",
      "Iteration:  947\n",
      "Previous theta :  [ 0.0006076  -0.09464601  0.09252957  0.03318665  0.05788494 -0.25578343\n",
      "  0.34618648  0.00192489 -0.32689593  0.27068843 -0.20339515 -0.23009201\n",
      "  0.10448439 -0.3674331 ]\n",
      "New theta_0 : [ 0.00060725 -0.09465104  0.09254212  0.0332055   0.05788275 -0.255801\n",
      "  0.346181    0.00192744 -0.32691106  0.27073553 -0.20344469 -0.23009403\n",
      "  0.10448405 -0.36743547]\n",
      "Training Error:  10.493937117491459\n",
      "====================================================================================================\n",
      "Iteration:  948\n",
      "Previous theta :  [ 0.00060725 -0.09465104  0.09254212  0.0332055   0.05788275 -0.255801\n",
      "  0.346181    0.00192744 -0.32691106  0.27073553 -0.20344469 -0.23009403\n",
      "  0.10448405 -0.36743547]\n",
      "New theta_0 : [ 0.00060689 -0.09465604  0.09255462  0.0332243   0.05788056 -0.25581846\n",
      "  0.34617555  0.00192999 -0.3269261   0.27078251 -0.20349411 -0.23009605\n",
      "  0.10448371 -0.36743783]\n",
      "Training Error:  10.49393173823901\n",
      "====================================================================================================\n",
      "Iteration:  949\n",
      "Previous theta :  [ 0.00060689 -0.09465604  0.09255462  0.0332243   0.05788056 -0.25581846\n",
      "  0.34617555  0.00192999 -0.3269261   0.27078251 -0.20349411 -0.23009605\n",
      "  0.10448371 -0.36743783]\n",
      "New theta_0 : [ 0.00060654 -0.09466102  0.09256707  0.03324306  0.05787838 -0.25583584\n",
      "  0.34617012  0.00193253 -0.32694105  0.27082936 -0.20354342 -0.23009806\n",
      "  0.10448338 -0.36744019]\n",
      "Training Error:  10.493926390767694\n",
      "====================================================================================================\n",
      "Iteration:  950\n",
      "Previous theta :  [ 0.00060654 -0.09466102  0.09256707  0.03324306  0.05787838 -0.25583584\n",
      "  0.34617012  0.00193253 -0.32694105  0.27082936 -0.20354342 -0.23009806\n",
      "  0.10448338 -0.36744019]\n",
      "New theta_0 : [ 0.0006062  -0.09466599  0.09257947  0.03326177  0.0578762  -0.25585311\n",
      "  0.34616472  0.00193507 -0.32695589  0.27087608 -0.2035926  -0.23010006\n",
      "  0.10448304 -0.36744254]\n",
      "Training Error:  10.49392107486706\n",
      "====================================================================================================\n",
      "Iteration:  951\n",
      "Previous theta :  [ 0.0006062  -0.09466599  0.09257947  0.03326177  0.0578762  -0.25585311\n",
      "  0.34616472  0.00193507 -0.32695589  0.27087608 -0.2035926  -0.23010006\n",
      "  0.10448304 -0.36744254]\n",
      "New theta_0 : [ 0.00060585 -0.09467093  0.09259182  0.03328043  0.05787403 -0.25587028\n",
      "  0.34615934  0.0019376  -0.32697064  0.27092266 -0.20364166 -0.23010205\n",
      "  0.10448272 -0.36744488]\n",
      "Training Error:  10.49391579032834\n",
      "====================================================================================================\n",
      "Iteration:  952\n",
      "Previous theta :  [ 0.00060585 -0.09467093  0.09259182  0.03328043  0.05787403 -0.25587028\n",
      "  0.34615934  0.0019376  -0.32697064  0.27092266 -0.20364166 -0.23010205\n",
      "  0.10448272 -0.36744488]\n",
      "New theta_0 : [ 0.00060551 -0.09467585  0.09260412  0.03329905  0.05787186 -0.25588736\n",
      "  0.34615399  0.00194013 -0.3269853   0.27096912 -0.2036906  -0.23010403\n",
      "  0.1044824  -0.36744721]\n",
      "Training Error:  10.493910536944444\n",
      "====================================================================================================\n",
      "Iteration:  953\n",
      "Previous theta :  [ 0.00060551 -0.09467585  0.09260412  0.03329905  0.05787186 -0.25588736\n",
      "  0.34615399  0.00194013 -0.3269853   0.27096912 -0.2036906  -0.23010403\n",
      "  0.1044824  -0.36744721]\n",
      "New theta_0 : [ 0.00060517 -0.09468076  0.09261637  0.03331762  0.05786969 -0.25590435\n",
      "  0.34614866  0.00194265 -0.32699987  0.27101545 -0.20373943 -0.230106\n",
      "  0.10448208 -0.36744954]\n",
      "Training Error:  10.493905314509918\n",
      "====================================================================================================\n",
      "Iteration:  954\n",
      "Previous theta :  [ 0.00060517 -0.09468076  0.09261637  0.03331762  0.05786969 -0.25590435\n",
      "  0.34614866  0.00194265 -0.32699987  0.27101545 -0.20373943 -0.230106\n",
      "  0.10448208 -0.36744954]\n",
      "New theta_0 : [ 0.00060483 -0.09468564  0.09262858  0.03333614  0.05786753 -0.25592124\n",
      "  0.34614336  0.00194517 -0.32701434  0.27106165 -0.20378813 -0.23010796\n",
      "  0.10448176 -0.36745186]\n",
      "Training Error:  10.493900122820953\n",
      "====================================================================================================\n",
      "Iteration:  955\n",
      "Previous theta :  [ 0.00060483 -0.09468564  0.09262858  0.03333614  0.05786753 -0.25592124\n",
      "  0.34614336  0.00194517 -0.32701434  0.27106165 -0.20378813 -0.23010796\n",
      "  0.10448176 -0.36745186]\n",
      "New theta_0 : [ 0.00060449 -0.09469051  0.09264073  0.03335462  0.05786538 -0.25593803\n",
      "  0.34613807  0.00194768 -0.32702871  0.27110772 -0.20383672 -0.23010991\n",
      "  0.10448145 -0.36745418]\n",
      "Training Error:  10.493894961675363\n",
      "====================================================================================================\n",
      "Iteration:  956\n",
      "Previous theta :  [ 0.00060449 -0.09469051  0.09264073  0.03335462  0.05786538 -0.25593803\n",
      "  0.34613807  0.00194768 -0.32702871  0.27110772 -0.20383672 -0.23010991\n",
      "  0.10448145 -0.36745418]\n",
      "New theta_0 : [ 0.00060416 -0.09469536  0.09265284  0.03337305  0.05786322 -0.25595473\n",
      "  0.34613281  0.00195019 -0.327043    0.27115366 -0.20388518 -0.23011186\n",
      "  0.10448115 -0.36745648]\n",
      "Training Error:  10.493889830872558\n",
      "====================================================================================================\n",
      "Iteration:  957\n",
      "Previous theta :  [ 0.00060416 -0.09469536  0.09265284  0.03337305  0.05786322 -0.25595473\n",
      "  0.34613281  0.00195019 -0.327043    0.27115366 -0.20388518 -0.23011186\n",
      "  0.10448115 -0.36745648]\n",
      "New theta_0 : [ 0.00060382 -0.09470019  0.09266489  0.03339144  0.05786107 -0.25597133\n",
      "  0.34612758  0.00195269 -0.32705719  0.27119948 -0.20393353 -0.23011379\n",
      "  0.10448085 -0.36745878]\n",
      "Training Error:  10.493884730213543\n",
      "====================================================================================================\n",
      "Iteration:  958\n",
      "Previous theta :  [ 0.00060382 -0.09470019  0.09266489  0.03339144  0.05786107 -0.25597133\n",
      "  0.34612758  0.00195269 -0.32705719  0.27119948 -0.20393353 -0.23011379\n",
      "  0.10448085 -0.36745878]\n",
      "New theta_0 : [ 0.00060349 -0.09470499  0.0926769   0.03340978  0.05785893 -0.25598785\n",
      "  0.34612237  0.00195519 -0.3270713   0.27124517 -0.20398176 -0.23011571\n",
      "  0.10448055 -0.36746108]\n",
      "Training Error:  10.493879659500884\n",
      "====================================================================================================\n",
      "Iteration:  959\n",
      "Previous theta :  [ 0.00060349 -0.09470499  0.0926769   0.03340978  0.05785893 -0.25598785\n",
      "  0.34612237  0.00195519 -0.3270713   0.27124517 -0.20398176 -0.23011571\n",
      "  0.10448055 -0.36746108]\n",
      "New theta_0 : [ 0.00060316 -0.09470978  0.09268886  0.03342807  0.05785679 -0.25600427\n",
      "  0.34611718  0.00195768 -0.32708531  0.27129073 -0.20402987 -0.23011763\n",
      "  0.10448026 -0.36746337]\n",
      "Training Error:  10.493874618538719\n",
      "====================================================================================================\n",
      "Iteration:  960\n",
      "Previous theta :  [ 0.00060316 -0.09470978  0.09268886  0.03342807  0.05785679 -0.25600427\n",
      "  0.34611718  0.00195768 -0.32708531  0.27129073 -0.20402987 -0.23011763\n",
      "  0.10448026 -0.36746337]\n",
      "New theta_0 : [ 0.00060284 -0.09471455  0.09270078  0.03344631  0.05785465 -0.2560206\n",
      "  0.34611201  0.00196017 -0.32709923  0.27133616 -0.20407787 -0.23011954\n",
      "  0.10447997 -0.36746565]\n",
      "Training Error:  10.493869607132712\n",
      "====================================================================================================\n",
      "Iteration:  961\n",
      "Previous theta :  [ 0.00060284 -0.09471455  0.09270078  0.03344631  0.05785465 -0.2560206\n",
      "  0.34611201  0.00196017 -0.32709923  0.27133616 -0.20407787 -0.23011954\n",
      "  0.10447997 -0.36746565]\n",
      "New theta_0 : [ 0.00060252 -0.09471931  0.09271264  0.03346451  0.05785252 -0.25603683\n",
      "  0.34610687  0.00196265 -0.32711307  0.27138147 -0.20412574 -0.23012144\n",
      "  0.10447968 -0.36746792]\n",
      "Training Error:  10.493864625090062\n",
      "====================================================================================================\n",
      "Iteration:  962\n",
      "Previous theta :  [ 0.00060252 -0.09471931  0.09271264  0.03346451  0.05785252 -0.25603683\n",
      "  0.34610687  0.00196265 -0.32711307  0.27138147 -0.20412574 -0.23012144\n",
      "  0.10447968 -0.36746792]\n",
      "New theta_0 : [ 0.00060219 -0.09472404  0.09272446  0.03348267  0.0578504  -0.25605298\n",
      "  0.34610175  0.00196513 -0.32712682  0.27142666 -0.2041735  -0.23012333\n",
      "  0.1044794  -0.36747019]\n",
      "Training Error:  10.493859672219477\n",
      "====================================================================================================\n",
      "Iteration:  963\n",
      "Previous theta :  [ 0.00060219 -0.09472404  0.09272446  0.03348267  0.0578504  -0.25605298\n",
      "  0.34610175  0.00196513 -0.32712682  0.27142666 -0.2041735  -0.23012333\n",
      "  0.1044794  -0.36747019]\n",
      "New theta_0 : [ 0.00060187 -0.09472875  0.09273623  0.03350078  0.05784827 -0.25606904\n",
      "  0.34609665  0.0019676  -0.32714048  0.27147171 -0.20422114 -0.23012521\n",
      "  0.10447912 -0.36747245]\n",
      "Training Error:  10.493854748331158\n",
      "====================================================================================================\n",
      "Iteration:  964\n",
      "Previous theta :  [ 0.00060187 -0.09472875  0.09273623  0.03350078  0.05784827 -0.25606904\n",
      "  0.34609665  0.0019676  -0.32714048  0.27147171 -0.20422114 -0.23012521\n",
      "  0.10447912 -0.36747245]\n",
      "New theta_0 : [ 0.00060156 -0.09473345  0.09274796  0.03351884  0.05784616 -0.256085\n",
      "  0.34609158  0.00197007 -0.32715405  0.27151665 -0.20426867 -0.23012708\n",
      "  0.10447885 -0.3674747 ]\n",
      "Training Error:  10.493849853236794\n",
      "====================================================================================================\n",
      "Iteration:  965\n",
      "Previous theta :  [ 0.00060156 -0.09473345  0.09274796  0.03351884  0.05784616 -0.256085\n",
      "  0.34609158  0.00197007 -0.32715405  0.27151665 -0.20426867 -0.23012708\n",
      "  0.10447885 -0.3674747 ]\n",
      "New theta_0 : [ 0.00060124 -0.09473813  0.09275964  0.03353686  0.05784404 -0.25610088\n",
      "  0.34608652  0.00197253 -0.32716753  0.27156145 -0.20431608 -0.23012894\n",
      "  0.10447858 -0.36747695]\n",
      "Training Error:  10.493844986749533\n",
      "====================================================================================================\n",
      "Iteration:  966\n",
      "Previous theta :  [ 0.00060124 -0.09473813  0.09275964  0.03353686  0.05784404 -0.25610088\n",
      "  0.34608652  0.00197253 -0.32716753  0.27156145 -0.20431608 -0.23012894\n",
      "  0.10447858 -0.36747695]\n",
      "New theta_0 : [ 0.00060093 -0.09474279  0.09277127  0.03355483  0.05784193 -0.25611667\n",
      "  0.34608149  0.00197499 -0.32718093  0.27160614 -0.20436337 -0.2301308\n",
      "  0.10447831 -0.36747919]\n",
      "Training Error:  10.493840148683983\n",
      "====================================================================================================\n",
      "Iteration:  967\n",
      "Previous theta :  [ 0.00060093 -0.09474279  0.09277127  0.03355483  0.05784193 -0.25611667\n",
      "  0.34608149  0.00197499 -0.32718093  0.27160614 -0.20436337 -0.2301308\n",
      "  0.10447831 -0.36747919]\n",
      "New theta_0 : [ 0.00060062 -0.09474743  0.09278286  0.03357275  0.05783983 -0.25613238\n",
      "  0.34607649  0.00197745 -0.32719425  0.2716507  -0.20441055 -0.23013264\n",
      "  0.10447805 -0.36748142]\n",
      "Training Error:  10.493835338856185\n",
      "====================================================================================================\n",
      "Iteration:  968\n",
      "Previous theta :  [ 0.00060062 -0.09474743  0.09278286  0.03357275  0.05783983 -0.25613238\n",
      "  0.34607649  0.00197745 -0.32719425  0.2716507  -0.20441055 -0.23013264\n",
      "  0.10447805 -0.36748142]\n",
      "New theta_0 : [ 0.00060031 -0.09475205  0.0927944   0.03359063  0.05783772 -0.25614799\n",
      "  0.3460715   0.00197989 -0.32720748  0.27169513 -0.20445761 -0.23013448\n",
      "  0.10447779 -0.36748365]\n",
      "Training Error:  10.493830557083609\n",
      "====================================================================================================\n",
      "Iteration:  969\n",
      "Previous theta :  [ 0.00060031 -0.09475205  0.0927944   0.03359063  0.05783772 -0.25614799\n",
      "  0.3460715   0.00197989 -0.32720748  0.27169513 -0.20445761 -0.23013448\n",
      "  0.10447779 -0.36748365]\n",
      "New theta_0 : [ 0.0006     -0.09475666  0.0928059   0.03360847  0.05783563 -0.25616352\n",
      "  0.34606653  0.00198234 -0.32722062  0.27173945 -0.20450455 -0.23013631\n",
      "  0.10447754 -0.36748587]\n",
      "Training Error:  10.493825803185132\n",
      "====================================================================================================\n",
      "Iteration:  970\n",
      "Previous theta :  [ 0.0006     -0.09475666  0.0928059   0.03360847  0.05783563 -0.25616352\n",
      "  0.34606653  0.00198234 -0.32722062  0.27173945 -0.20450455 -0.23013631\n",
      "  0.10447754 -0.36748587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00059969 -0.09476124  0.09281735  0.03362626  0.05783353 -0.25617896\n",
      "  0.34606159  0.00198478 -0.32723369  0.27178364 -0.20455138 -0.23013813\n",
      "  0.10447729 -0.36748809]\n",
      "Training Error:  10.493821076981028\n",
      "====================================================================================================\n",
      "Iteration:  971\n",
      "Previous theta :  [ 0.00059969 -0.09476124  0.09281735  0.03362626  0.05783353 -0.25617896\n",
      "  0.34606159  0.00198478 -0.32723369  0.27178364 -0.20455138 -0.23013813\n",
      "  0.10447729 -0.36748809]\n",
      "New theta_0 : [ 0.00059939 -0.09476581  0.09282875  0.03364401  0.05783145 -0.25619432\n",
      "  0.34605667  0.00198721 -0.32724667  0.27182771 -0.20459809 -0.23013994\n",
      "  0.10447704 -0.3674903 ]\n",
      "Training Error:  10.493816378292962\n",
      "====================================================================================================\n",
      "Iteration:  972\n",
      "Previous theta :  [ 0.00059939 -0.09476581  0.09282875  0.03364401  0.05783145 -0.25619432\n",
      "  0.34605667  0.00198721 -0.32724667  0.27182771 -0.20459809 -0.23013994\n",
      "  0.10447704 -0.3674903 ]\n",
      "New theta_0 : [ 0.00059909 -0.09477036  0.09284011  0.03366171  0.05782936 -0.25620959\n",
      "  0.34605177  0.00198964 -0.32725956  0.27187165 -0.20464469 -0.23014174\n",
      "  0.1044768  -0.3674925 ]\n",
      "Training Error:  10.493811706943962\n",
      "====================================================================================================\n",
      "Iteration:  973\n",
      "Previous theta :  [ 0.00059909 -0.09477036  0.09284011  0.03366171  0.05782936 -0.25620959\n",
      "  0.34605177  0.00198964 -0.32725956  0.27187165 -0.20464469 -0.23014174\n",
      "  0.1044768  -0.3674925 ]\n",
      "New theta_0 : [ 0.00059879 -0.0947749   0.09285143  0.03367936  0.05782728 -0.25622478\n",
      "  0.34604689  0.00199206 -0.32727238  0.27191548 -0.20469118 -0.23014354\n",
      "  0.10447656 -0.3674947 ]\n",
      "Training Error:  10.493807062758416\n",
      "====================================================================================================\n",
      "Iteration:  974\n",
      "Previous theta :  [ 0.00059879 -0.0947749   0.09285143  0.03367936  0.05782728 -0.25622478\n",
      "  0.34604689  0.00199206 -0.32727238  0.27191548 -0.20469118 -0.23014354\n",
      "  0.10447656 -0.3674947 ]\n",
      "New theta_0 : [ 0.00059849 -0.09477941  0.0928627   0.03369698  0.05782521 -0.25623988\n",
      "  0.34604203  0.00199448 -0.32728511  0.27195918 -0.20473755 -0.23014533\n",
      "  0.10447632 -0.36749689]\n",
      "Training Error:  10.493802445562057\n",
      "====================================================================================================\n",
      "Iteration:  975\n",
      "Previous theta :  [ 0.00059849 -0.09477941  0.0928627   0.03369698  0.05782521 -0.25623988\n",
      "  0.34604203  0.00199448 -0.32728511  0.27195918 -0.20473755 -0.23014533\n",
      "  0.10447632 -0.36749689]\n",
      "New theta_0 : [ 0.00059819 -0.09478391  0.09287393  0.03371454  0.05782313 -0.2562549\n",
      "  0.3460372   0.00199689 -0.32729776  0.27200276 -0.2047838  -0.23014711\n",
      "  0.10447609 -0.36749907]\n",
      "Training Error:  10.493797855181947\n",
      "====================================================================================================\n",
      "Iteration:  976\n",
      "Previous theta :  [ 0.00059819 -0.09478391  0.09287393  0.03371454  0.05782313 -0.2562549\n",
      "  0.3460372   0.00199689 -0.32729776  0.27200276 -0.2047838  -0.23014711\n",
      "  0.10447609 -0.36749907]\n",
      "New theta_0 : [ 0.0005979  -0.09478839  0.09288511  0.03373206  0.05782107 -0.25626984\n",
      "  0.34603238  0.0019993  -0.32731034  0.27204622 -0.20482994 -0.23014888\n",
      "  0.10447586 -0.36750125]\n",
      "Training Error:  10.493793291446467\n",
      "====================================================================================================\n",
      "Iteration:  977\n",
      "Previous theta :  [ 0.0005979  -0.09478839  0.09288511  0.03373206  0.05782107 -0.25626984\n",
      "  0.34603238  0.0019993  -0.32731034  0.27204622 -0.20482994 -0.23014888\n",
      "  0.10447586 -0.36750125]\n",
      "New theta_0 : [ 0.00059761 -0.09479286  0.09289625  0.03374954  0.057819   -0.25628469\n",
      "  0.34602759  0.00200171 -0.32732283  0.27208956 -0.20487597 -0.23015064\n",
      "  0.10447563 -0.36750342]\n",
      "Training Error:  10.493788754185308\n",
      "====================================================================================================\n",
      "Iteration:  978\n",
      "Previous theta :  [ 0.00059761 -0.09479286  0.09289625  0.03374954  0.057819   -0.25628469\n",
      "  0.34602759  0.00200171 -0.32732283  0.27208956 -0.20487597 -0.23015064\n",
      "  0.10447563 -0.36750342]\n",
      "New theta_0 : [ 0.00059732 -0.0947973   0.09290735  0.03376698  0.05781694 -0.25629947\n",
      "  0.34602281  0.00200411 -0.32733524  0.27213278 -0.20492188 -0.23015239\n",
      "  0.10447541 -0.36750558]\n",
      "Training Error:  10.49378424322945\n",
      "====================================================================================================\n",
      "Iteration:  979\n",
      "Previous theta :  [ 0.00059732 -0.0947973   0.09290735  0.03376698  0.05781694 -0.25629947\n",
      "  0.34602281  0.00200411 -0.32733524  0.27213278 -0.20492188 -0.23015239\n",
      "  0.10447541 -0.36750558]\n",
      "New theta_0 : [ 0.00059703 -0.09480173  0.0929184   0.03378437  0.05781489 -0.25631416\n",
      "  0.34601806  0.0020065  -0.32734758  0.27217588 -0.20496768 -0.23015414\n",
      "  0.10447519 -0.36750774]\n",
      "Training Error:  10.49377975841116\n",
      "====================================================================================================\n",
      "Iteration:  980\n",
      "Previous theta :  [ 0.00059703 -0.09480173  0.0929184   0.03378437  0.05781489 -0.25631416\n",
      "  0.34601806  0.0020065  -0.32734758  0.27217588 -0.20496768 -0.23015414\n",
      "  0.10447519 -0.36750774]\n",
      "New theta_0 : [ 0.00059674 -0.09480614  0.09292941  0.03380171  0.05781284 -0.25632877\n",
      "  0.34601333  0.00200889 -0.32735983  0.27221886 -0.20501337 -0.23015588\n",
      "  0.10447497 -0.3675099 ]\n",
      "Training Error:  10.493775299563966\n",
      "====================================================================================================\n",
      "Iteration:  981\n",
      "Previous theta :  [ 0.00059674 -0.09480614  0.09292941  0.03380171  0.05781284 -0.25632877\n",
      "  0.34601333  0.00200889 -0.32735983  0.27221886 -0.20501337 -0.23015588\n",
      "  0.10447497 -0.3675099 ]\n",
      "New theta_0 : [ 0.00059646 -0.09481054  0.09294038  0.03381901  0.05781079 -0.2563433\n",
      "  0.34600862  0.00201128 -0.32737201  0.27226172 -0.20505894 -0.23015761\n",
      "  0.10447476 -0.36751204]\n",
      "Training Error:  10.49377086652266\n",
      "====================================================================================================\n",
      "Iteration:  982\n",
      "Previous theta :  [ 0.00059646 -0.09481054  0.09294038  0.03381901  0.05781079 -0.2563433\n",
      "  0.34600862  0.00201128 -0.32737201  0.27226172 -0.20505894 -0.23015761\n",
      "  0.10447476 -0.36751204]\n",
      "New theta_0 : [ 0.00059618 -0.09481492  0.09295131  0.03383627  0.05780875 -0.25635775\n",
      "  0.34600392  0.00201366 -0.32738412  0.27230447 -0.20510441 -0.23015933\n",
      "  0.10447455 -0.36751418]\n",
      "Training Error:  10.493766459123277\n",
      "====================================================================================================\n",
      "Iteration:  983\n",
      "Previous theta :  [ 0.00059618 -0.09481492  0.09295131  0.03383627  0.05780875 -0.25635775\n",
      "  0.34600392  0.00201366 -0.32738412  0.27230447 -0.20510441 -0.23015933\n",
      "  0.10447455 -0.36751418]\n",
      "New theta_0 : [ 0.0005959  -0.09481928  0.09296219  0.03385348  0.05780671 -0.25637212\n",
      "  0.34599925  0.00201603 -0.32739614  0.27234709 -0.20514976 -0.23016105\n",
      "  0.10447434 -0.36751632]\n",
      "Training Error:  10.49376207720309\n",
      "====================================================================================================\n",
      "Iteration:  984\n",
      "Previous theta :  [ 0.0005959  -0.09481928  0.09296219  0.03385348  0.05780671 -0.25637212\n",
      "  0.34599925  0.00201603 -0.32739614  0.27234709 -0.20514976 -0.23016105\n",
      "  0.10447434 -0.36751632]\n",
      "New theta_0 : [ 0.00059562 -0.09482362  0.09297303  0.03387065  0.05780468 -0.25638641\n",
      "  0.3459946   0.0020184  -0.32740809  0.2723896  -0.20519499 -0.23016275\n",
      "  0.10447414 -0.36751845]\n",
      "Training Error:  10.493757720600586\n",
      "====================================================================================================\n",
      "Iteration:  985\n",
      "Previous theta :  [ 0.00059562 -0.09482362  0.09297303  0.03387065  0.05780468 -0.25638641\n",
      "  0.3459946   0.0020184  -0.32740809  0.2723896  -0.20519499 -0.23016275\n",
      "  0.10447414 -0.36751845]\n",
      "New theta_0 : [ 0.00059534 -0.09482795  0.09298383  0.03388778  0.05780265 -0.25640063\n",
      "  0.34598997  0.00202077 -0.32741997  0.27243199 -0.20524012 -0.23016445\n",
      "  0.10447394 -0.36752057]\n",
      "Training Error:  10.49375338915547\n",
      "====================================================================================================\n",
      "Iteration:  986\n",
      "Previous theta :  [ 0.00059534 -0.09482795  0.09298383  0.03388778  0.05780265 -0.25640063\n",
      "  0.34598997  0.00202077 -0.32741997  0.27243199 -0.20524012 -0.23016445\n",
      "  0.10447394 -0.36752057]\n",
      "New theta_0 : [ 0.00059506 -0.09483226  0.09299458  0.03390486  0.05780063 -0.25641476\n",
      "  0.34598536  0.00202313 -0.32743177  0.27247426 -0.20528513 -0.23016614\n",
      "  0.10447374 -0.36752269]\n",
      "Training Error:  10.493749082708645\n",
      "====================================================================================================\n",
      "Iteration:  987\n",
      "Previous theta :  [ 0.00059506 -0.09483226  0.09299458  0.03390486  0.05780063 -0.25641476\n",
      "  0.34598536  0.00202313 -0.32743177  0.27247426 -0.20528513 -0.23016614\n",
      "  0.10447374 -0.36752269]\n",
      "New theta_0 : [ 0.00059479 -0.09483656  0.0930053   0.0339219   0.05779861 -0.25642882\n",
      "  0.34598076  0.00202549 -0.32744349  0.27251642 -0.20533003 -0.23016783\n",
      "  0.10447355 -0.3675248 ]\n",
      "Training Error:  10.493744801102194\n",
      "====================================================================================================\n",
      "Iteration:  988\n",
      "Previous theta :  [ 0.00059479 -0.09483656  0.0930053   0.0339219   0.05779861 -0.25642882\n",
      "  0.34598076  0.00202549 -0.32744349  0.27251642 -0.20533003 -0.23016783\n",
      "  0.10447355 -0.3675248 ]\n",
      "New theta_0 : [ 0.00059452 -0.09484084  0.09301597  0.03393889  0.05779659 -0.25644281\n",
      "  0.34597619  0.00202784 -0.32745514  0.27255845 -0.20537482 -0.2301695\n",
      "  0.10447336 -0.3675269 ]\n",
      "Training Error:  10.493740544179394\n",
      "====================================================================================================\n",
      "Iteration:  989\n",
      "Previous theta :  [ 0.00059452 -0.09484084  0.09301597  0.03393889  0.05779659 -0.25644281\n",
      "  0.34597619  0.00202784 -0.32745514  0.27255845 -0.20537482 -0.2301695\n",
      "  0.10447336 -0.3675269 ]\n",
      "New theta_0 : [ 0.00059425 -0.0948451   0.0930266   0.03395585  0.05779458 -0.25645671\n",
      "  0.34597164  0.00203019 -0.32746672  0.27260038 -0.2054195  -0.23017117\n",
      "  0.10447317 -0.367529  ]\n",
      "Training Error:  10.493736311784668\n",
      "====================================================================================================\n",
      "Iteration:  990\n",
      "Previous theta :  [ 0.00059425 -0.0948451   0.0930266   0.03395585  0.05779458 -0.25645671\n",
      "  0.34597164  0.00203019 -0.32746672  0.27260038 -0.2054195  -0.23017117\n",
      "  0.10447317 -0.367529  ]\n",
      "New theta_0 : [ 0.00059398 -0.09484934  0.0930372   0.03397275  0.05779257 -0.25647054\n",
      "  0.3459671   0.00203253 -0.32747823  0.27264218 -0.20546407 -0.23017283\n",
      "  0.10447299 -0.3675311 ]\n",
      "Training Error:  10.49373210376361\n",
      "====================================================================================================\n",
      "Iteration:  991\n",
      "Previous theta :  [ 0.00059398 -0.09484934  0.0930372   0.03397275  0.05779257 -0.25647054\n",
      "  0.3459671   0.00203253 -0.32747823  0.27264218 -0.20546407 -0.23017283\n",
      "  0.10447299 -0.3675311 ]\n",
      "New theta_0 : [ 0.00059371 -0.09485357  0.09304775  0.03398962  0.05779057 -0.2564843\n",
      "  0.34596259  0.00203487 -0.32748966  0.27268387 -0.20550853 -0.23017449\n",
      "  0.10447281 -0.36753318]\n",
      "Training Error:  10.493727919962954\n",
      "====================================================================================================\n",
      "Iteration:  992\n",
      "Previous theta :  [ 0.00059371 -0.09485357  0.09304775  0.03398962  0.05779057 -0.2564843\n",
      "  0.34596259  0.00203487 -0.32748966  0.27268387 -0.20550853 -0.23017449\n",
      "  0.10447281 -0.36753318]\n",
      "New theta_0 : [ 0.00059345 -0.09485778  0.09305826  0.03400644  0.05778857 -0.25649798\n",
      "  0.34595809  0.0020372  -0.32750102  0.27272545 -0.20555287 -0.23017613\n",
      "  0.10447263 -0.36753526]\n",
      "Training Error:  10.493723760230566\n",
      "====================================================================================================\n",
      "Iteration:  993\n",
      "Previous theta :  [ 0.00059345 -0.09485778  0.09305826  0.03400644  0.05778857 -0.25649798\n",
      "  0.34595809  0.0020372  -0.32750102  0.27272545 -0.20555287 -0.23017613\n",
      "  0.10447263 -0.36753526]\n",
      "New theta_0 : [ 0.00059318 -0.09486198  0.09306873  0.03402322  0.05778657 -0.25651158\n",
      "  0.34595362  0.00203953 -0.32751231  0.27276691 -0.20559711 -0.23017777\n",
      "  0.10447246 -0.36753734]\n",
      "Training Error:  10.493719624415434\n",
      "====================================================================================================\n",
      "Iteration:  994\n",
      "Previous theta :  [ 0.00059318 -0.09486198  0.09306873  0.03402322  0.05778657 -0.25651158\n",
      "  0.34595362  0.00203953 -0.32751231  0.27276691 -0.20559711 -0.23017777\n",
      "  0.10447246 -0.36753734]\n",
      "New theta_0 : [ 0.00059292 -0.09486616  0.09307916  0.03403996  0.05778458 -0.25652511\n",
      "  0.34594916  0.00204185 -0.32752353  0.27280826 -0.20564124 -0.2301794\n",
      "  0.10447228 -0.36753941]\n",
      "Training Error:  10.493715512367668\n",
      "====================================================================================================\n",
      "Iteration:  995\n",
      "Previous theta :  [ 0.00059292 -0.09486616  0.09307916  0.03403996  0.05778458 -0.25652511\n",
      "  0.34594916  0.00204185 -0.32752353  0.27280826 -0.20564124 -0.2301794\n",
      "  0.10447228 -0.36753941]\n",
      "New theta_0 : [ 0.00059266 -0.09487033  0.09308955  0.03405665  0.05778259 -0.25653857\n",
      "  0.34594472  0.00204417 -0.32753467  0.27284949 -0.20568526 -0.23018103\n",
      "  0.10447211 -0.36754147]\n",
      "Training Error:  10.49371142393847\n",
      "====================================================================================================\n",
      "Iteration:  996\n",
      "Previous theta :  [ 0.00059266 -0.09487033  0.09308955  0.03405665  0.05778259 -0.25653857\n",
      "  0.34594472  0.00204417 -0.32753467  0.27284949 -0.20568526 -0.23018103\n",
      "  0.10447211 -0.36754147]\n",
      "New theta_0 : [ 0.0005924  -0.09487448  0.09309989  0.03407331  0.05778061 -0.25655195\n",
      "  0.3459403   0.00204648 -0.32754575  0.27289061 -0.20572916 -0.23018264\n",
      "  0.10447195 -0.36754353]\n",
      "Training Error:  10.49370735898014\n",
      "====================================================================================================\n",
      "Iteration:  997\n",
      "Previous theta :  [ 0.0005924  -0.09487448  0.09309989  0.03407331  0.05778061 -0.25655195\n",
      "  0.3459403   0.00204648 -0.32754575  0.27289061 -0.20572916 -0.23018264\n",
      "  0.10447195 -0.36754353]\n",
      "New theta_0 : [ 0.00059214 -0.09487861  0.0931102   0.03408992  0.05777863 -0.25656527\n",
      "  0.3459359   0.00204879 -0.32755676  0.27293161 -0.20577296 -0.23018425\n",
      "  0.10447178 -0.36754559]\n",
      "Training Error:  10.493703317346068\n",
      "====================================================================================================\n",
      "Iteration:  998\n",
      "Previous theta :  [ 0.00059214 -0.09487861  0.0931102   0.03408992  0.05777863 -0.25656527\n",
      "  0.3459359   0.00204879 -0.32755676  0.27293161 -0.20577296 -0.23018425\n",
      "  0.10447178 -0.36754559]\n",
      "New theta_0 : [ 0.00059189 -0.09488273  0.09312048  0.03410648  0.05777666 -0.25657851\n",
      "  0.34593152  0.0020511  -0.3275677   0.2729725  -0.20581665 -0.23018585\n",
      "  0.10447162 -0.36754763]\n",
      "Training Error:  10.493699298890704\n",
      "====================================================================================================\n",
      "Iteration:  999\n",
      "Previous theta :  [ 0.00059189 -0.09488273  0.09312048  0.03410648  0.05777666 -0.25657851\n",
      "  0.34593152  0.0020511  -0.3275677   0.2729725  -0.20581665 -0.23018585\n",
      "  0.10447162 -0.36754763]\n",
      "New theta_0 : [ 0.00059164 -0.09488683  0.09313071  0.03412301  0.05777469 -0.25659167\n",
      "  0.34592715  0.0020534  -0.32757857  0.27301328 -0.20586023 -0.23018745\n",
      "  0.10447147 -0.36754968]\n",
      "Training Error:  10.493695303469568\n",
      "====================================================================================================\n",
      "Iteration:  1000\n",
      "Previous theta :  [ 0.00059164 -0.09488683  0.09313071  0.03412301  0.05777469 -0.25659167\n",
      "  0.34592715  0.0020534  -0.32757857  0.27301328 -0.20586023 -0.23018745\n",
      "  0.10447147 -0.36754968]\n",
      "New theta_0 : [ 0.00059138 -0.09489092  0.0931409   0.03413949  0.05777272 -0.25660477\n",
      "  0.34592281  0.00205569 -0.32758937  0.27305394 -0.20590371 -0.23018904\n",
      "  0.10447131 -0.36755171]\n",
      "Training Error:  10.493691330939237\n",
      "====================================================================================================\n",
      "Iteration:  1001\n",
      "Previous theta :  [ 0.00059138 -0.09489092  0.0931409   0.03413949  0.05777272 -0.25660477\n",
      "  0.34592281  0.00205569 -0.32758937  0.27305394 -0.20590371 -0.23018904\n",
      "  0.10447131 -0.36755171]\n",
      "New theta_0 : [ 0.00059113 -0.09489499  0.09315105  0.03415593  0.05777076 -0.2566178\n",
      "  0.34591848  0.00205798 -0.32760011  0.2730945  -0.20594707 -0.23019062\n",
      "  0.10447116 -0.36755374]\n",
      "Training Error:  10.493687381157322\n",
      "====================================================================================================\n",
      "Iteration:  1002\n",
      "Previous theta :  [ 0.00059113 -0.09489499  0.09315105  0.03415593  0.05777076 -0.2566178\n",
      "  0.34591848  0.00205798 -0.32760011  0.2730945  -0.20594707 -0.23019062\n",
      "  0.10447116 -0.36755374]\n",
      "New theta_0 : [ 0.00059088 -0.09489904  0.09316117  0.03417233  0.0577688  -0.25663075\n",
      "  0.34591417  0.00206027 -0.32761077  0.27313494 -0.20599033 -0.23019219\n",
      "  0.10447101 -0.36755577]\n",
      "Training Error:  10.49368345398248\n",
      "====================================================================================================\n",
      "Iteration:  1003\n",
      "Previous theta :  [ 0.00059088 -0.09489904  0.09316117  0.03417233  0.0577688  -0.25663075\n",
      "  0.34591417  0.00206027 -0.32761077  0.27313494 -0.20599033 -0.23019219\n",
      "  0.10447101 -0.36755577]\n",
      "New theta_0 : [ 0.00059064 -0.09490308  0.09317124  0.03418868  0.05776685 -0.25664364\n",
      "  0.34590988  0.00206255 -0.32762137  0.27317527 -0.20603347 -0.23019375\n",
      "  0.10447086 -0.36755779]\n",
      "Training Error:  10.493679549274388\n",
      "====================================================================================================\n",
      "Iteration:  1004\n",
      "Previous theta :  [ 0.00059064 -0.09490308  0.09317124  0.03418868  0.05776685 -0.25664364\n",
      "  0.34590988  0.00206255 -0.32762137  0.27317527 -0.20603347 -0.23019375\n",
      "  0.10447086 -0.36755779]\n",
      "New theta_0 : [ 0.00059039 -0.09490711  0.09318128  0.034205    0.0577649  -0.25665645\n",
      "  0.34590561  0.00206482 -0.32763191  0.27321549 -0.20607651 -0.23019531\n",
      "  0.10447072 -0.3675598 ]\n",
      "Training Error:  10.49367566689374\n",
      "====================================================================================================\n",
      "Iteration:  1005\n",
      "Previous theta :  [ 0.00059039 -0.09490711  0.09318128  0.034205    0.0577649  -0.25665645\n",
      "  0.34590561  0.00206482 -0.32763191  0.27321549 -0.20607651 -0.23019531\n",
      "  0.10447072 -0.3675598 ]\n",
      "New theta_0 : [ 0.00059015 -0.09491112  0.09319128  0.03422127  0.05776295 -0.2566692\n",
      "  0.34590135  0.0020671  -0.32764238  0.27325559 -0.20611945 -0.23019687\n",
      "  0.10447058 -0.36756181]\n",
      "Training Error:  10.493671806702231\n",
      "====================================================================================================\n",
      "Iteration:  1006\n",
      "Previous theta :  [ 0.00059015 -0.09491112  0.09319128  0.03422127  0.05776295 -0.2566692\n",
      "  0.34590135  0.0020671  -0.32764238  0.27325559 -0.20611945 -0.23019687\n",
      "  0.10447058 -0.36756181]\n",
      "New theta_0 : [ 0.0005899  -0.09491511  0.09320124  0.0342375   0.05776101 -0.25668188\n",
      "  0.34589711  0.00206936 -0.32765278  0.27329559 -0.20616227 -0.23019841\n",
      "  0.10447044 -0.36756381]\n",
      "Training Error:  10.493667968562566\n",
      "====================================================================================================\n",
      "Iteration:  1007\n",
      "Previous theta :  [ 0.0005899  -0.09491511  0.09320124  0.0342375   0.05776101 -0.25668188\n",
      "  0.34589711  0.00206936 -0.32765278  0.27329559 -0.20616227 -0.23019841\n",
      "  0.10447044 -0.36756381]\n",
      "New theta_0 : [ 0.00058966 -0.09491909  0.09321117  0.03425369  0.05775907 -0.25669449\n",
      "  0.34589289  0.00207163 -0.32766312  0.27333547 -0.20620499 -0.23019995\n",
      "  0.1044703  -0.36756581]\n",
      "Training Error:  10.493664152338427\n",
      "====================================================================================================\n",
      "Iteration:  1008\n",
      "Previous theta :  [ 0.00058966 -0.09491909  0.09321117  0.03425369  0.05775907 -0.25669449\n",
      "  0.34589289  0.00207163 -0.32766312  0.27333547 -0.20620499 -0.23019995\n",
      "  0.1044703  -0.36756581]\n",
      "New theta_0 : [ 0.00058942 -0.09492306  0.09322106  0.03426983  0.05775714 -0.25670703\n",
      "  0.34588869  0.00207388 -0.32767339  0.27337525 -0.2062476  -0.23020148\n",
      "  0.10447017 -0.3675678 ]\n",
      "Training Error:  10.493660357894484\n",
      "====================================================================================================\n",
      "Iteration:  1009\n",
      "Previous theta :  [ 0.00058942 -0.09492306  0.09322106  0.03426983  0.05775714 -0.25670703\n",
      "  0.34588869  0.00207388 -0.32767339  0.27337525 -0.2062476  -0.23020148\n",
      "  0.10447017 -0.3675678 ]\n",
      "New theta_0 : [ 0.00058919 -0.09492701  0.0932309   0.03428594  0.05775521 -0.25671951\n",
      "  0.3458845   0.00207614 -0.3276836   0.27341492 -0.20629011 -0.23020301\n",
      "  0.10447004 -0.36756979]\n",
      "Training Error:  10.493656585096373\n",
      "====================================================================================================\n",
      "Iteration:  1010\n",
      "Previous theta :  [ 0.00058919 -0.09492701  0.0932309   0.03428594  0.05775521 -0.25671951\n",
      "  0.3458845   0.00207614 -0.3276836   0.27341492 -0.20629011 -0.23020301\n",
      "  0.10447004 -0.36756979]\n",
      "New theta_0 : [ 0.00058895 -0.09493094  0.09324072  0.034302    0.05775329 -0.25673192\n",
      "  0.34588033  0.00207839 -0.32769375  0.27345447 -0.20633251 -0.23020452\n",
      "  0.10446991 -0.36757177]\n",
      "Training Error:  10.493652833810696\n",
      "====================================================================================================\n",
      "Iteration:  1011\n",
      "Previous theta :  [ 0.00058895 -0.09493094  0.09324072  0.034302    0.05775329 -0.25673192\n",
      "  0.34588033  0.00207839 -0.32769375  0.27345447 -0.20633251 -0.23020452\n",
      "  0.10446991 -0.36757177]\n",
      "New theta_0 : [ 0.00058871 -0.09493486  0.09325049  0.03431803  0.05775137 -0.25674426\n",
      "  0.34587618  0.00208063 -0.32770383  0.27349392 -0.2063748  -0.23020603\n",
      "  0.10446978 -0.36757375]\n",
      "Training Error:  10.493649103905012\n",
      "====================================================================================================\n",
      "Iteration:  1012\n",
      "Previous theta :  [ 0.00058871 -0.09493486  0.09325049  0.03431803  0.05775137 -0.25674426\n",
      "  0.34587618  0.00208063 -0.32770383  0.27349392 -0.2063748  -0.23020603\n",
      "  0.10446978 -0.36757375]\n",
      "New theta_0 : [ 0.00058848 -0.09493877  0.09326023  0.03433401  0.05774945 -0.25675653\n",
      "  0.34587205  0.00208287 -0.32771385  0.27353326 -0.20641699 -0.23020754\n",
      "  0.10446966 -0.36757572]\n",
      "Training Error:  10.49364539524782\n",
      "====================================================================================================\n",
      "Iteration:  1013\n",
      "Previous theta :  [ 0.00058848 -0.09493877  0.09326023  0.03433401  0.05774945 -0.25675653\n",
      "  0.34587205  0.00208287 -0.32771385  0.27353326 -0.20641699 -0.23020754\n",
      "  0.10446966 -0.36757572]\n",
      "New theta_0 : [ 0.00058825 -0.09494266  0.09326993  0.03434995  0.05774754 -0.25676874\n",
      "  0.34586793  0.0020851  -0.32772381  0.27357249 -0.20645907 -0.23020904\n",
      "  0.10446954 -0.36757768]\n",
      "Training Error:  10.493641707708553\n",
      "====================================================================================================\n",
      "Iteration:  1014\n",
      "Previous theta :  [ 0.00058825 -0.09494266  0.09326993  0.03434995  0.05774754 -0.25676874\n",
      "  0.34586793  0.0020851  -0.32772381  0.27357249 -0.20645907 -0.23020904\n",
      "  0.10446954 -0.36757768]\n",
      "New theta_0 : [ 0.00058802 -0.09494654  0.0932796   0.03436585  0.05774563 -0.25678089\n",
      "  0.34586383  0.00208733 -0.3277337   0.27361161 -0.20650105 -0.23021053\n",
      "  0.10446942 -0.36757964]\n",
      "Training Error:  10.493638041157586\n",
      "====================================================================================================\n",
      "Iteration:  1015\n",
      "Previous theta :  [ 0.00058802 -0.09494654  0.0932796   0.03436585  0.05774563 -0.25678089\n",
      "  0.34586383  0.00208733 -0.3277337   0.27361161 -0.20650105 -0.23021053\n",
      "  0.10446942 -0.36757964]\n",
      "New theta_0 : [ 0.00058779 -0.0949504   0.09328923  0.03438171  0.05774373 -0.25679297\n",
      "  0.34585975  0.00208956 -0.32774353  0.27365062 -0.20654292 -0.23021201\n",
      "  0.1044693  -0.3675816 ]\n",
      "Training Error:  10.493634395466204\n",
      "====================================================================================================\n",
      "Iteration:  1016\n",
      "Previous theta :  [ 0.00058779 -0.0949504   0.09328923  0.03438171  0.05774373 -0.25679297\n",
      "  0.34585975  0.00208956 -0.32774353  0.27365062 -0.20654292 -0.23021201\n",
      "  0.1044693  -0.3675816 ]\n",
      "New theta_0 : [ 0.00058756 -0.09495425  0.09329882  0.03439753  0.05774183 -0.25680498\n",
      "  0.34585568  0.00209178 -0.32775331  0.27368953 -0.20658469 -0.23021349\n",
      "  0.10446919 -0.36758355]\n",
      "Training Error:  10.49363077050661\n",
      "====================================================================================================\n",
      "Iteration:  1017\n",
      "Previous theta :  [ 0.00058756 -0.09495425  0.09329882  0.03439753  0.05774183 -0.25680498\n",
      "  0.34585568  0.00209178 -0.32775331  0.27368953 -0.20658469 -0.23021349\n",
      "  0.10446919 -0.36758355]\n",
      "New theta_0 : [ 0.00058734 -0.09495808  0.09330838  0.03441331  0.05773993 -0.25681693\n",
      "  0.34585163  0.002094   -0.32776302  0.27372833 -0.20662635 -0.23021496\n",
      "  0.10446908 -0.36758549]\n",
      "Training Error:  10.49362716615191\n",
      "====================================================================================================\n",
      "Iteration:  1018\n",
      "Previous theta :  [ 0.00058734 -0.09495808  0.09330838  0.03441331  0.05773993 -0.25681693\n",
      "  0.34585163  0.002094   -0.32776302  0.27372833 -0.20662635 -0.23021496\n",
      "  0.10446908 -0.36758549]\n",
      "New theta_0 : [ 0.00058711 -0.0949619   0.0933179   0.03442904  0.05773804 -0.25682882\n",
      "  0.3458476   0.00209621 -0.32777267  0.27376702 -0.20666791 -0.23021643\n",
      "  0.10446897 -0.36758743]\n",
      "Training Error:  10.493623582276106\n",
      "====================================================================================================\n",
      "Iteration:  1019\n",
      "Previous theta :  [ 0.00058711 -0.0949619   0.0933179   0.03442904  0.05773804 -0.25682882\n",
      "  0.3458476   0.00209621 -0.32777267  0.27376702 -0.20666791 -0.23021643\n",
      "  0.10446897 -0.36758743]\n",
      "New theta_0 : [ 0.00058689 -0.0949657   0.09332738  0.03444474  0.05773616 -0.25684065\n",
      "  0.34584358  0.00209842 -0.32778226  0.2738056  -0.20670936 -0.23021789\n",
      "  0.10446886 -0.36758937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.493620018754088\n",
      "====================================================================================================\n",
      "Iteration:  1020\n",
      "Previous theta :  [ 0.00058689 -0.0949657   0.09332738  0.03444474  0.05773616 -0.25684065\n",
      "  0.34584358  0.00209842 -0.32778226  0.2738056  -0.20670936 -0.23021789\n",
      "  0.10446886 -0.36758937]\n",
      "New theta_0 : [ 0.00058666 -0.0949695   0.09333683  0.0344604   0.05773427 -0.25685241\n",
      "  0.34583958  0.00210062 -0.32779179  0.27384408 -0.20675071 -0.23021934\n",
      "  0.10446876 -0.3675913 ]\n",
      "Training Error:  10.493616475461634\n",
      "====================================================================================================\n",
      "Iteration:  1021\n",
      "Previous theta :  [ 0.00058666 -0.0949695   0.09333683  0.0344604   0.05773427 -0.25685241\n",
      "  0.34583958  0.00210062 -0.32779179  0.27384408 -0.20675071 -0.23021934\n",
      "  0.10446876 -0.3675913 ]\n",
      "New theta_0 : [ 0.00058644 -0.09497327  0.09334625  0.03447601  0.05773239 -0.25686411\n",
      "  0.3458356   0.00210282 -0.32780127  0.27388246 -0.20679195 -0.23022078\n",
      "  0.10446866 -0.36759322]\n",
      "Training Error:  10.493612952275384\n",
      "====================================================================================================\n",
      "Iteration:  1022\n",
      "Previous theta :  [ 0.00058644 -0.09497327  0.09334625  0.03447601  0.05773239 -0.25686411\n",
      "  0.3458356   0.00210282 -0.32780127  0.27388246 -0.20679195 -0.23022078\n",
      "  0.10446866 -0.36759322]\n",
      "New theta_0 : [ 0.00058623 -0.09497703  0.09335563  0.03449159  0.05773052 -0.25687574\n",
      "  0.34583163  0.00210501 -0.32781068  0.27392072 -0.2068331  -0.23022222\n",
      "  0.10446856 -0.36759514]\n",
      "Training Error:  10.493609449072858\n",
      "====================================================================================================\n",
      "Iteration:  1023\n",
      "Previous theta :  [ 0.00058623 -0.09497703  0.09335563  0.03449159  0.05773052 -0.25687574\n",
      "  0.34583163  0.00210501 -0.32781068  0.27392072 -0.2068331  -0.23022222\n",
      "  0.10446856 -0.36759514]\n",
      "New theta_0 : [ 0.00058601 -0.09498078  0.09336497  0.03450712  0.05772865 -0.25688732\n",
      "  0.34582768  0.0021072  -0.32782004  0.27395888 -0.20687413 -0.23022365\n",
      "  0.10446846 -0.36759705]\n",
      "Training Error:  10.493605965732423\n",
      "====================================================================================================\n",
      "Iteration:  1024\n",
      "Previous theta :  [ 0.00058601 -0.09498078  0.09336497  0.03450712  0.05772865 -0.25688732\n",
      "  0.34582768  0.0021072  -0.32782004  0.27395888 -0.20687413 -0.23022365\n",
      "  0.10446846 -0.36759705]\n",
      "New theta_0 : [ 0.00058579 -0.09498452  0.09337428  0.03452262  0.05772678 -0.25689883\n",
      "  0.34582375  0.00210939 -0.32782933  0.27399694 -0.20691507 -0.23022508\n",
      "  0.10446836 -0.36759896]\n",
      "Training Error:  10.493602502133303\n",
      "====================================================================================================\n",
      "Iteration:  1025\n",
      "Previous theta :  [ 0.00058579 -0.09498452  0.09337428  0.03452262  0.05772678 -0.25689883\n",
      "  0.34582375  0.00210939 -0.32782933  0.27399694 -0.20691507 -0.23022508\n",
      "  0.10446836 -0.36759896]\n",
      "New theta_0 : [ 0.00058558 -0.09498824  0.09338355  0.03453808  0.05772492 -0.25691028\n",
      "  0.34581983  0.00211157 -0.32783857  0.27403489 -0.2069559  -0.2302265\n",
      "  0.10446827 -0.36760086]\n",
      "Training Error:  10.493599058155564\n",
      "====================================================================================================\n",
      "Iteration:  1026\n",
      "Previous theta :  [ 0.00058558 -0.09498824  0.09338355  0.03453808  0.05772492 -0.25691028\n",
      "  0.34581983  0.00211157 -0.32783857  0.27403489 -0.2069559  -0.2302265\n",
      "  0.10446827 -0.36760086]\n",
      "New theta_0 : [ 0.00058536 -0.09499195  0.09339279  0.03455349  0.05772306 -0.25692167\n",
      "  0.34581592  0.00211374 -0.32784776  0.27407274 -0.20699663 -0.23022792\n",
      "  0.10446818 -0.36760276]\n",
      "Training Error:  10.493595633680108\n",
      "====================================================================================================\n",
      "Iteration:  1027\n",
      "Previous theta :  [ 0.00058536 -0.09499195  0.09339279  0.03455349  0.05772306 -0.25692167\n",
      "  0.34581592  0.00211374 -0.32784776  0.27407274 -0.20699663 -0.23022792\n",
      "  0.10446818 -0.36760276]\n",
      "New theta_0 : [ 0.00058515 -0.09499564  0.093402    0.03456887  0.05772121 -0.25693301\n",
      "  0.34581204  0.00211591 -0.32785688  0.27411048 -0.20703726 -0.23022932\n",
      "  0.10446809 -0.36760465]\n",
      "Training Error:  10.493592228588668\n",
      "====================================================================================================\n",
      "Iteration:  1028\n",
      "Previous theta :  [ 0.00058515 -0.09499564  0.093402    0.03456887  0.05772121 -0.25693301\n",
      "  0.34581204  0.00211591 -0.32785688  0.27411048 -0.20703726 -0.23022932\n",
      "  0.10446809 -0.36760465]\n",
      "New theta_0 : [ 0.00058494 -0.09499932  0.09341117  0.0345842   0.05771936 -0.25694428\n",
      "  0.34580817  0.00211808 -0.32786595  0.27414812 -0.20707778 -0.23023073\n",
      "  0.10446801 -0.36760654]\n",
      "Training Error:  10.493588842763799\n",
      "====================================================================================================\n",
      "Iteration:  1029\n",
      "Previous theta :  [ 0.00058494 -0.09499932  0.09341117  0.0345842   0.05771936 -0.25694428\n",
      "  0.34580817  0.00211808 -0.32786595  0.27414812 -0.20707778 -0.23023073\n",
      "  0.10446801 -0.36760654]\n",
      "New theta_0 : [ 0.00058473 -0.09500298  0.09342031  0.0345995   0.05771751 -0.25695549\n",
      "  0.34580431  0.00212024 -0.32787497  0.27418566 -0.20711821 -0.23023212\n",
      "  0.10446792 -0.36760843]\n",
      "Training Error:  10.49358547608887\n",
      "====================================================================================================\n",
      "Iteration:  1030\n",
      "Previous theta :  [ 0.00058473 -0.09500298  0.09342031  0.0345995   0.05771751 -0.25695549\n",
      "  0.34580431  0.00212024 -0.32787497  0.27418566 -0.20711821 -0.23023212\n",
      "  0.10446792 -0.36760843]\n",
      "New theta_0 : [ 0.00058452 -0.09500664  0.09342941  0.03461476  0.05771567 -0.25696664\n",
      "  0.34580047  0.0021224  -0.32788393  0.27422309 -0.20715853 -0.23023351\n",
      "  0.10446784 -0.3676103 ]\n",
      "Training Error:  10.493582128448056\n",
      "====================================================================================================\n",
      "Iteration:  1031\n",
      "Previous theta :  [ 0.00058452 -0.09500664  0.09342941  0.03461476  0.05771567 -0.25696664\n",
      "  0.34580047  0.0021224  -0.32788393  0.27422309 -0.20715853 -0.23023351\n",
      "  0.10446784 -0.3676103 ]\n",
      "New theta_0 : [ 0.00058431 -0.09501028  0.09343849  0.03462998  0.05771383 -0.25697774\n",
      "  0.34579664  0.00212455 -0.32789283  0.27426042 -0.20719875 -0.23023489\n",
      "  0.10446776 -0.36761218]\n",
      "Training Error:  10.493578799726338\n",
      "====================================================================================================\n",
      "Iteration:  1032\n",
      "Previous theta :  [ 0.00058431 -0.09501028  0.09343849  0.03462998  0.05771383 -0.25697774\n",
      "  0.34579664  0.00212455 -0.32789283  0.27426042 -0.20719875 -0.23023489\n",
      "  0.10446776 -0.36761218]\n",
      "New theta_0 : [ 0.00058411 -0.0950139   0.09344752  0.03464515  0.057712   -0.25698877\n",
      "  0.34579283  0.0021267  -0.32790168  0.27429764 -0.20723886 -0.23023627\n",
      "  0.10446768 -0.36761405]\n",
      "Training Error:  10.49357548980949\n",
      "====================================================================================================\n",
      "Iteration:  1033\n",
      "Previous theta :  [ 0.00058411 -0.0950139   0.09344752  0.03464515  0.057712   -0.25698877\n",
      "  0.34579283  0.0021267  -0.32790168  0.27429764 -0.20723886 -0.23023627\n",
      "  0.10446768 -0.36761405]\n",
      "New theta_0 : [ 0.0005839  -0.09501752  0.09345653  0.03466029  0.05771017 -0.25699975\n",
      "  0.34578904  0.00212885 -0.32791047  0.27433477 -0.20727888 -0.23023764\n",
      "  0.1044676  -0.36761591]\n",
      "Training Error:  10.493572198584076\n",
      "====================================================================================================\n",
      "Iteration:  1034\n",
      "Previous theta :  [ 0.0005839  -0.09501752  0.09345653  0.03466029  0.05771017 -0.25699975\n",
      "  0.34578904  0.00212885 -0.32791047  0.27433477 -0.20727888 -0.23023764\n",
      "  0.1044676  -0.36761591]\n",
      "New theta_0 : [ 0.0005837  -0.09502111  0.0934655   0.03467539  0.05770834 -0.25701067\n",
      "  0.34578526  0.00213099 -0.32791921  0.27437179 -0.2073188  -0.23023901\n",
      "  0.10446753 -0.36761777]\n",
      "Training Error:  10.493568925937431\n",
      "====================================================================================================\n",
      "Iteration:  1035\n",
      "Previous theta :  [ 0.0005837  -0.09502111  0.0934655   0.03467539  0.05770834 -0.25701067\n",
      "  0.34578526  0.00213099 -0.32791921  0.27437179 -0.2073188  -0.23023901\n",
      "  0.10446753 -0.36761777]\n",
      "New theta_0 : [ 0.0005835  -0.0950247   0.09347443  0.03469045  0.05770652 -0.25702153\n",
      "  0.3457815   0.00213312 -0.3279279   0.27440871 -0.20735861 -0.23024037\n",
      "  0.10446746 -0.36761962]\n",
      "Training Error:  10.493565671757677\n",
      "====================================================================================================\n",
      "Iteration:  1036\n",
      "Previous theta :  [ 0.0005835  -0.0950247   0.09347443  0.03469045  0.05770652 -0.25702153\n",
      "  0.3457815   0.00213312 -0.3279279   0.27440871 -0.20735861 -0.23024037\n",
      "  0.10446746 -0.36761962]\n",
      "New theta_0 : [ 0.0005833  -0.09502827  0.09348334  0.03470548  0.0577047  -0.25703234\n",
      "  0.34577775  0.00213525 -0.32793653  0.27444552 -0.20739833 -0.23024172\n",
      "  0.10446739 -0.36762147]\n",
      "Training Error:  10.493562435933699\n",
      "====================================================================================================\n",
      "Iteration:  1037\n",
      "Previous theta :  [ 0.0005833  -0.09502827  0.09348334  0.03470548  0.0577047  -0.25703234\n",
      "  0.34577775  0.00213525 -0.32793653  0.27444552 -0.20739833 -0.23024172\n",
      "  0.10446739 -0.36762147]\n",
      "New theta_0 : [ 0.0005831  -0.09503183  0.09349221  0.03472046  0.05770289 -0.25704309\n",
      "  0.34577401  0.00213738 -0.32794511  0.27448224 -0.20743794 -0.23024307\n",
      "  0.10446732 -0.36762331]\n",
      "Training Error:  10.493559218355141\n",
      "====================================================================================================\n",
      "Iteration:  1038\n",
      "Previous theta :  [ 0.0005831  -0.09503183  0.09349221  0.03472046  0.05770289 -0.25704309\n",
      "  0.34577401  0.00213738 -0.32794511  0.27448224 -0.20743794 -0.23024307\n",
      "  0.10446732 -0.36762331]\n",
      "New theta_0 : [ 0.0005829  -0.09503538  0.09350105  0.0347354   0.05770108 -0.25705378\n",
      "  0.34577029  0.0021395  -0.32795363  0.27451886 -0.20747746 -0.23024441\n",
      "  0.10446725 -0.36762515]\n",
      "Training Error:  10.493556018912406\n",
      "====================================================================================================\n",
      "Iteration:  1039\n",
      "Previous theta :  [ 0.0005829  -0.09503538  0.09350105  0.0347354   0.05770108 -0.25705378\n",
      "  0.34577029  0.0021395  -0.32795363  0.27451886 -0.20747746 -0.23024441\n",
      "  0.10446725 -0.36762515]\n",
      "New theta_0 : [ 0.0005827  -0.09503891  0.09350986  0.03475031  0.05769927 -0.25706442\n",
      "  0.34576659  0.00214162 -0.32796211  0.27455537 -0.20751687 -0.23024575\n",
      "  0.10446719 -0.36762699]\n",
      "Training Error:  10.493552837496642\n",
      "====================================================================================================\n",
      "Iteration:  1040\n",
      "Previous theta :  [ 0.0005827  -0.09503891  0.09350986  0.03475031  0.05769927 -0.25706442\n",
      "  0.34576659  0.00214162 -0.32796211  0.27455537 -0.20751687 -0.23024575\n",
      "  0.10446719 -0.36762699]\n",
      "New theta_0 : [ 0.00058251 -0.09504243  0.09351863  0.03476518  0.05769747 -0.257075\n",
      "  0.3457629   0.00214373 -0.32797053  0.27459178 -0.20755619 -0.23024708\n",
      "  0.10446713 -0.36762882]\n",
      "Training Error:  10.493549673999746\n",
      "====================================================================================================\n",
      "Iteration:  1041\n",
      "Previous theta :  [ 0.00058251 -0.09504243  0.09351863  0.03476518  0.05769747 -0.257075\n",
      "  0.3457629   0.00214373 -0.32797053  0.27459178 -0.20755619 -0.23024708\n",
      "  0.10446713 -0.36762882]\n",
      "New theta_0 : [ 0.00058231 -0.09504594  0.09352737  0.03478001  0.05769567 -0.25708553\n",
      "  0.34575923  0.00214584 -0.3279789   0.2746281  -0.2075954  -0.2302484\n",
      "  0.10446707 -0.36763064]\n",
      "Training Error:  10.493546528314345\n",
      "====================================================================================================\n",
      "Iteration:  1042\n",
      "Previous theta :  [ 0.00058231 -0.09504594  0.09352737  0.03478001  0.05769567 -0.25708553\n",
      "  0.34575923  0.00214584 -0.3279789   0.2746281  -0.2075954  -0.2302484\n",
      "  0.10446707 -0.36763064]\n",
      "New theta_0 : [ 0.00058212 -0.09504944  0.09353608  0.0347948   0.05769388 -0.257096\n",
      "  0.34575557  0.00214795 -0.32798722  0.27466431 -0.20763452 -0.23024972\n",
      "  0.10446701 -0.36763246]\n",
      "Training Error:  10.493543400333797\n",
      "====================================================================================================\n",
      "Iteration:  1043\n",
      "Previous theta :  [ 0.00058212 -0.09504944  0.09353608  0.0347948   0.05769388 -0.257096\n",
      "  0.34575557  0.00214795 -0.32798722  0.27466431 -0.20763452 -0.23024972\n",
      "  0.10446701 -0.36763246]\n",
      "New theta_0 : [ 0.00058193 -0.09505292  0.09354476  0.03480955  0.05769209 -0.25710641\n",
      "  0.34575192  0.00215005 -0.32799549  0.27470043 -0.20767354 -0.23025103\n",
      "  0.10446695 -0.36763428]\n",
      "Training Error:  10.493540289952184\n",
      "====================================================================================================\n",
      "Iteration:  1044\n",
      "Previous theta :  [ 0.00058193 -0.09505292  0.09354476  0.03480955  0.05769209 -0.25710641\n",
      "  0.34575192  0.00215005 -0.32799549  0.27470043 -0.20767354 -0.23025103\n",
      "  0.10446695 -0.36763428]\n",
      "New theta_0 : [ 0.00058173 -0.09505639  0.09355341  0.03482426  0.0576903  -0.25711678\n",
      "  0.34574829  0.00215214 -0.3280037   0.27473644 -0.20771246 -0.23025234\n",
      "  0.1044669  -0.36763609]\n",
      "Training Error:  10.493537197064315\n",
      "====================================================================================================\n",
      "Iteration:  1045\n",
      "Previous theta :  [ 0.00058173 -0.09505639  0.09355341  0.03482426  0.0576903  -0.25711678\n",
      "  0.34574829  0.00215214 -0.3280037   0.27473644 -0.20771246 -0.23025234\n",
      "  0.1044669  -0.36763609]\n",
      "New theta_0 : [ 0.00058154 -0.09505985  0.09356202  0.03483894  0.05768852 -0.25712708\n",
      "  0.34574467  0.00215423 -0.32801187  0.27477236 -0.20775128 -0.23025364\n",
      "  0.10446684 -0.36763789]\n",
      "Training Error:  10.493534121565695\n",
      "====================================================================================================\n",
      "Iteration:  1046\n",
      "Previous theta :  [ 0.00058154 -0.09505985  0.09356202  0.03483894  0.05768852 -0.25712708\n",
      "  0.34574467  0.00215423 -0.32801187  0.27477236 -0.20775128 -0.23025364\n",
      "  0.10446684 -0.36763789]\n",
      "New theta_0 : [ 0.00058136 -0.09506329  0.09357061  0.03485358  0.05768674 -0.25713734\n",
      "  0.34574107  0.00215632 -0.32801999  0.27480817 -0.20779    -0.23025494\n",
      "  0.10446679 -0.36763969]\n",
      "Training Error:  10.493531063352547\n",
      "====================================================================================================\n",
      "Iteration:  1047\n",
      "Previous theta :  [ 0.00058136 -0.09506329  0.09357061  0.03485358  0.05768674 -0.25713734\n",
      "  0.34574107  0.00215632 -0.32801999  0.27480817 -0.20779    -0.23025494\n",
      "  0.10446679 -0.36763969]\n",
      "New theta_0 : [ 0.00058117 -0.09506672  0.09357916  0.03486818  0.05768497 -0.25714754\n",
      "  0.34573748  0.0021584  -0.32802806  0.27484389 -0.20782863 -0.23025623\n",
      "  0.10446674 -0.36764149]\n",
      "Training Error:  10.493528022321792\n",
      "====================================================================================================\n",
      "Iteration:  1048\n",
      "Previous theta :  [ 0.00058117 -0.09506672  0.09357916  0.03486818  0.05768497 -0.25714754\n",
      "  0.34573748  0.0021584  -0.32802806  0.27484389 -0.20782863 -0.23025623\n",
      "  0.10446674 -0.36764149]\n",
      "New theta_0 : [ 0.00058098 -0.09507014  0.09358768  0.03488274  0.0576832  -0.25715769\n",
      "  0.34573391  0.00216048 -0.32803607  0.27487951 -0.20786715 -0.23025752\n",
      "  0.1044667  -0.36764328]\n",
      "Training Error:  10.493524998371047\n",
      "====================================================================================================\n",
      "Iteration:  1049\n",
      "Previous theta :  [ 0.00058098 -0.09507014  0.09358768  0.03488274  0.0576832  -0.25715769\n",
      "  0.34573391  0.00216048 -0.32803607  0.27487951 -0.20786715 -0.23025752\n",
      "  0.1044667  -0.36764328]\n",
      "New theta_0 : [ 0.0005808  -0.09507355  0.09359617  0.03489726  0.05768144 -0.25716779\n",
      "  0.34573035  0.00216256 -0.32804404  0.27491504 -0.20790558 -0.23025879\n",
      "  0.10446665 -0.36764507]\n",
      "Training Error:  10.493521991398614\n",
      "====================================================================================================\n",
      "Iteration:  1050\n",
      "Previous theta :  [ 0.0005808  -0.09507355  0.09359617  0.03489726  0.05768144 -0.25716779\n",
      "  0.34573035  0.00216256 -0.32804404  0.27491504 -0.20790558 -0.23025879\n",
      "  0.10446665 -0.36764507]\n",
      "New theta_0 : [ 0.00058061 -0.09507695  0.09360463  0.03491175  0.05767967 -0.25717783\n",
      "  0.3457268   0.00216463 -0.32805196  0.27495046 -0.20794391 -0.23026007\n",
      "  0.10446661 -0.36764685]\n",
      "Training Error:  10.49351900130348\n",
      "====================================================================================================\n",
      "Iteration:  1051\n",
      "Previous theta :  [ 0.00058061 -0.09507695  0.09360463  0.03491175  0.05767967 -0.25717783\n",
      "  0.3457268   0.00216463 -0.32805196  0.27495046 -0.20794391 -0.23026007\n",
      "  0.10446661 -0.36764685]\n",
      "New theta_0 : [ 0.00058043 -0.09508033  0.09361306  0.0349262   0.05767792 -0.25718782\n",
      "  0.34572327  0.00216669 -0.32805984  0.27498579 -0.20798215 -0.23026134\n",
      "  0.10446656 -0.36764863]\n",
      "Training Error:  10.49351602798531\n",
      "====================================================================================================\n",
      "Iteration:  1052\n",
      "Previous theta :  [ 0.00058043 -0.09508033  0.09361306  0.0349262   0.05767792 -0.25718782\n",
      "  0.34572327  0.00216669 -0.32805984  0.27498579 -0.20798215 -0.23026134\n",
      "  0.10446656 -0.36764863]\n",
      "New theta_0 : [ 0.00058025 -0.0950837   0.09362146  0.03494061  0.05767616 -0.25719776\n",
      "  0.34571975  0.00216875 -0.32806766  0.27502102 -0.20802029 -0.2302626\n",
      "  0.10446652 -0.3676504 ]\n",
      "Training Error:  10.493513071344445\n",
      "====================================================================================================\n",
      "Iteration:  1053\n",
      "Previous theta :  [ 0.00058025 -0.0950837   0.09362146  0.03494061  0.05767616 -0.25719776\n",
      "  0.34571975  0.00216875 -0.32806766  0.27502102 -0.20802029 -0.2302626\n",
      "  0.10446652 -0.3676504 ]\n",
      "New theta_0 : [ 0.00058007 -0.09508706  0.09362982  0.03495498  0.05767441 -0.25720765\n",
      "  0.34571625  0.00217081 -0.32807544  0.27505615 -0.20805833 -0.23026386\n",
      "  0.10446648 -0.36765217]\n",
      "Training Error:  10.493510131281885\n",
      "====================================================================================================\n",
      "Iteration:  1054\n",
      "Previous theta :  [ 0.00058007 -0.09508706  0.09362982  0.03495498  0.05767441 -0.25720765\n",
      "  0.34571625  0.00217081 -0.32807544  0.27505615 -0.20805833 -0.23026386\n",
      "  0.10446648 -0.36765217]\n",
      "New theta_0 : [ 0.00057989 -0.0950904   0.09363816  0.03496932  0.05767267 -0.25721749\n",
      "  0.34571276  0.00217286 -0.32808317  0.27509119 -0.20809627 -0.23026511\n",
      "  0.10446645 -0.36765393]\n",
      "Training Error:  10.493507207699297\n",
      "====================================================================================================\n",
      "Iteration:  1055\n",
      "Previous theta :  [ 0.00057989 -0.0950904   0.09363816  0.03496932  0.05767267 -0.25721749\n",
      "  0.34571276  0.00217286 -0.32808317  0.27509119 -0.20809627 -0.23026511\n",
      "  0.10446645 -0.36765393]\n",
      "New theta_0 : [ 0.00057971 -0.09509374  0.09364647  0.03498362  0.05767093 -0.25722727\n",
      "  0.34570928  0.00217491 -0.32809085  0.27512613 -0.20813412 -0.23026636\n",
      "  0.10446641 -0.36765569]\n",
      "Training Error:  10.493504300499007\n",
      "====================================================================================================\n",
      "Iteration:  1056\n",
      "Previous theta :  [ 0.00057971 -0.09509374  0.09364647  0.03498362  0.05767093 -0.25722727\n",
      "  0.34570928  0.00217491 -0.32809085  0.27512613 -0.20813412 -0.23026636\n",
      "  0.10446641 -0.36765569]\n",
      "New theta_0 : [ 0.00057953 -0.09509706  0.09365474  0.03499788  0.05766919 -0.25723701\n",
      "  0.34570582  0.00217695 -0.32809848  0.27516098 -0.20817187 -0.2302676\n",
      "  0.10446638 -0.36765745]\n",
      "Training Error:  10.493501409583981\n",
      "====================================================================================================\n",
      "Iteration:  1057\n",
      "Previous theta :  [ 0.00057953 -0.09509706  0.09365474  0.03499788  0.05766919 -0.25723701\n",
      "  0.34570582  0.00217695 -0.32809848  0.27516098 -0.20817187 -0.2302676\n",
      "  0.10446638 -0.36765745]\n",
      "New theta_0 : [ 0.00057936 -0.09510037  0.09366299  0.0350121   0.05766745 -0.2572467\n",
      "  0.34570237  0.00217899 -0.32810607  0.27519572 -0.20820953 -0.23026884\n",
      "  0.10446634 -0.3676592 ]\n",
      "Training Error:  10.493498534857839\n",
      "====================================================================================================\n",
      "Iteration:  1058\n",
      "Previous theta :  [ 0.00057936 -0.09510037  0.09366299  0.0350121   0.05766745 -0.2572467\n",
      "  0.34570237  0.00217899 -0.32810607  0.27519572 -0.20820953 -0.23026884\n",
      "  0.10446634 -0.3676592 ]\n",
      "New theta_0 : [ 0.00057918 -0.09510367  0.09367121  0.03502629  0.05766572 -0.25725633\n",
      "  0.34569893  0.00218103 -0.32811362  0.27523038 -0.20824709 -0.23027007\n",
      "  0.10446631 -0.36766094]\n",
      "Training Error:  10.49349567622484\n",
      "====================================================================================================\n",
      "Iteration:  1059\n",
      "Previous theta :  [ 0.00057918 -0.09510367  0.09367121  0.03502629  0.05766572 -0.25725633\n",
      "  0.34569893  0.00218103 -0.32811362  0.27523038 -0.20824709 -0.23027007\n",
      "  0.10446631 -0.36766094]\n",
      "New theta_0 : [ 0.00057901 -0.09510696  0.0936794   0.03504044  0.057664   -0.25726592\n",
      "  0.34569551  0.00218306 -0.32812111  0.27526494 -0.20828455 -0.23027129\n",
      "  0.10446628 -0.36766268]\n",
      "Training Error:  10.493492833589878\n",
      "====================================================================================================\n",
      "Iteration:  1060\n",
      "Previous theta :  [ 0.00057901 -0.09510696  0.0936794   0.03504044  0.057664   -0.25726592\n",
      "  0.34569551  0.00218306 -0.32812111  0.27526494 -0.20828455 -0.23027129\n",
      "  0.10446628 -0.36766268]\n",
      "New theta_0 : [ 0.00057883 -0.09511023  0.09368756  0.03505456  0.05766228 -0.25727546\n",
      "  0.3456921   0.00218508 -0.32812856  0.2752994  -0.20832192 -0.23027251\n",
      "  0.10446626 -0.36766442]\n",
      "Training Error:  10.493490006858472\n",
      "====================================================================================================\n",
      "Iteration:  1061\n",
      "Previous theta :  [ 0.00057883 -0.09511023  0.09368756  0.03505456  0.05766228 -0.25727546\n",
      "  0.3456921   0.00218508 -0.32812856  0.2752994  -0.20832192 -0.23027251\n",
      "  0.10446626 -0.36766442]\n",
      "New theta_0 : [ 0.00057866 -0.09511349  0.09369569  0.03506864  0.05766056 -0.25728495\n",
      "  0.3456887   0.0021871  -0.32813597  0.27533377 -0.2083592  -0.23027373\n",
      "  0.10446623 -0.36766615]\n",
      "Training Error:  10.493487195936774\n",
      "====================================================================================================\n",
      "Iteration:  1062\n",
      "Previous theta :  [ 0.00057866 -0.09511349  0.09369569  0.03506864  0.05766056 -0.25728495\n",
      "  0.3456887   0.0021871  -0.32813597  0.27533377 -0.2083592  -0.23027373\n",
      "  0.10446623 -0.36766615]\n",
      "New theta_0 : [ 0.00057849 -0.09511674  0.09370379  0.03508268  0.05765884 -0.25729439\n",
      "  0.34568532  0.00218912 -0.32814333  0.27536804 -0.20839638 -0.23027494\n",
      "  0.1044662  -0.36766788]\n",
      "Training Error:  10.49348440073155\n",
      "====================================================================================================\n",
      "Iteration:  1063\n",
      "Previous theta :  [ 0.00057849 -0.09511674  0.09370379  0.03508268  0.05765884 -0.25729439\n",
      "  0.34568532  0.00218912 -0.32814333  0.27536804 -0.20839638 -0.23027494\n",
      "  0.1044662  -0.36766788]\n",
      "New theta_0 : [ 0.00057832 -0.09511998  0.09371186  0.03509668  0.05765713 -0.25730378\n",
      "  0.34568195  0.00219114 -0.32815065  0.27540222 -0.20843347 -0.23027615\n",
      "  0.10446618 -0.3676696 ]\n",
      "Training Error:  10.493481621150183\n",
      "====================================================================================================\n",
      "Iteration:  1064\n",
      "Previous theta :  [ 0.00057832 -0.09511998  0.09371186  0.03509668  0.05765713 -0.25730378\n",
      "  0.34568195  0.00219114 -0.32815065  0.27540222 -0.20843347 -0.23027615\n",
      "  0.10446618 -0.3676696 ]\n",
      "New theta_0 : [ 0.00057815 -0.09512321  0.0937199   0.03511065  0.05765543 -0.25731312\n",
      "  0.34567859  0.00219314 -0.32815792  0.27543631 -0.20847046 -0.23027735\n",
      "  0.10446616 -0.36767132]\n",
      "Training Error:  10.493478857100667\n",
      "====================================================================================================\n",
      "Iteration:  1065\n",
      "Previous theta :  [ 0.00057815 -0.09512321  0.0937199   0.03511065  0.05765543 -0.25731312\n",
      "  0.34567859  0.00219314 -0.32815792  0.27543631 -0.20847046 -0.23027735\n",
      "  0.10446616 -0.36767132]\n",
      "New theta_0 : [ 0.00057799 -0.09512643  0.09372791  0.03512458  0.05765372 -0.25732242\n",
      "  0.34567525  0.00219515 -0.32816515  0.2754703  -0.20850735 -0.23027854\n",
      "  0.10446614 -0.36767304]\n",
      "Training Error:  10.4934761084916\n",
      "====================================================================================================\n",
      "Iteration:  1066\n",
      "Previous theta :  [ 0.00057799 -0.09512643  0.09372791  0.03512458  0.05765372 -0.25732242\n",
      "  0.34567525  0.00219515 -0.32816515  0.2754703  -0.20850735 -0.23027854\n",
      "  0.10446614 -0.36767304]\n",
      "New theta_0 : [ 0.00057782 -0.09512963  0.0937359   0.03513848  0.05765202 -0.25733167\n",
      "  0.34567192  0.00219715 -0.32817233  0.2755042  -0.20854416 -0.23027973\n",
      "  0.10446612 -0.36767475]\n",
      "Training Error:  10.493473375232181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  1067\n",
      "Previous theta :  [ 0.00057782 -0.09512963  0.0937359   0.03513848  0.05765202 -0.25733167\n",
      "  0.34567192  0.00219715 -0.32817233  0.2755042  -0.20854416 -0.23027973\n",
      "  0.10446612 -0.36767475]\n",
      "New theta_0 : [ 0.00057765 -0.09513283  0.09374385  0.03515233  0.05765033 -0.25734087\n",
      "  0.3456686   0.00219915 -0.32817948  0.27553801 -0.20858087 -0.23028092\n",
      "  0.1044661  -0.36767645]\n",
      "Training Error:  10.4934706572322\n",
      "====================================================================================================\n",
      "Iteration:  1068\n",
      "Previous theta :  [ 0.00057765 -0.09513283  0.09374385  0.03515233  0.05765033 -0.25734087\n",
      "  0.3456686   0.00219915 -0.32817948  0.27553801 -0.20858087 -0.23028092\n",
      "  0.1044661  -0.36767645]\n",
      "New theta_0 : [ 0.00057749 -0.09513601  0.09375178  0.03516616  0.05764864 -0.25735003\n",
      "  0.34566529  0.00220114 -0.32818657  0.27557172 -0.20861748 -0.2302821\n",
      "  0.10446609 -0.36767815]\n",
      "Training Error:  10.49346795440205\n",
      "====================================================================================================\n",
      "Iteration:  1069\n",
      "Previous theta :  [ 0.00057749 -0.09513601  0.09375178  0.03516616  0.05764864 -0.25735003\n",
      "  0.34566529  0.00220114 -0.32818657  0.27557172 -0.20861748 -0.2302821\n",
      "  0.10446609 -0.36767815]\n",
      "New theta_0 : [ 0.00057733 -0.09513918  0.09375968  0.03517994  0.05764695 -0.25735913\n",
      "  0.345662    0.00220313 -0.32819363  0.27560534 -0.208654   -0.23028327\n",
      "  0.10446607 -0.36767985]\n",
      "Training Error:  10.493465266652695\n",
      "====================================================================================================\n",
      "Iteration:  1070\n",
      "Previous theta :  [ 0.00057733 -0.09513918  0.09375968  0.03517994  0.05764695 -0.25735913\n",
      "  0.345662    0.00220313 -0.32819363  0.27560534 -0.208654   -0.23028327\n",
      "  0.10446607 -0.36767985]\n",
      "New theta_0 : [ 0.00057716 -0.09514234  0.09376755  0.03519369  0.05764527 -0.2573682\n",
      "  0.34565872  0.00220511 -0.32820064  0.27563887 -0.20869043 -0.23028444\n",
      "  0.10446606 -0.36768154]\n",
      "Training Error:  10.493462593895693\n",
      "====================================================================================================\n",
      "Iteration:  1071\n",
      "Previous theta :  [ 0.00057716 -0.09514234  0.09376755  0.03519369  0.05764527 -0.2573682\n",
      "  0.34565872  0.00220511 -0.32820064  0.27563887 -0.20869043 -0.23028444\n",
      "  0.10446606 -0.36768154]\n",
      "New theta_0 : [ 0.000577   -0.09514549  0.09377539  0.03520741  0.05764359 -0.25737721\n",
      "  0.34565545  0.00220709 -0.32820761  0.27567231 -0.20872677 -0.23028561\n",
      "  0.10446605 -0.36768323]\n",
      "Training Error:  10.493459936043175\n",
      "====================================================================================================\n",
      "Iteration:  1072\n",
      "Previous theta :  [ 0.000577   -0.09514549  0.09377539  0.03520741  0.05764359 -0.25737721\n",
      "  0.34565545  0.00220709 -0.32820761  0.27567231 -0.20872677 -0.23028561\n",
      "  0.10446605 -0.36768323]\n",
      "New theta_0 : [ 0.00057684 -0.09514863  0.09378321  0.03522109  0.05764191 -0.25738618\n",
      "  0.3456522   0.00220906 -0.32821454  0.27570565 -0.20876302 -0.23028677\n",
      "  0.10446604 -0.36768492]\n",
      "Training Error:  10.493457293007841\n",
      "====================================================================================================\n",
      "Iteration:  1073\n",
      "Previous theta :  [ 0.00057684 -0.09514863  0.09378321  0.03522109  0.05764191 -0.25738618\n",
      "  0.3456522   0.00220906 -0.32821454  0.27570565 -0.20876302 -0.23028677\n",
      "  0.10446604 -0.36768492]\n",
      "New theta_0 : [ 0.00057668 -0.09515175  0.093791    0.03523473  0.05764024 -0.25739511\n",
      "  0.34564895  0.00221104 -0.32822143  0.27573891 -0.20879917 -0.23028792\n",
      "  0.10446603 -0.3676866 ]\n",
      "Training Error:  10.493454664702965\n",
      "====================================================================================================\n",
      "Iteration:  1074\n",
      "Previous theta :  [ 0.00057668 -0.09515175  0.093791    0.03523473  0.05764024 -0.25739511\n",
      "  0.34564895  0.00221104 -0.32822143  0.27573891 -0.20879917 -0.23028792\n",
      "  0.10446603 -0.3676866 ]\n",
      "New theta_0 : [ 0.00057652 -0.09515487  0.09379875  0.03524834  0.05763857 -0.25740399\n",
      "  0.34564572  0.002213   -0.32822827  0.27577207 -0.20883523 -0.23028907\n",
      "  0.10446602 -0.36768827]\n",
      "Training Error:  10.49345205104238\n",
      "====================================================================================================\n",
      "Iteration:  1075\n",
      "Previous theta :  [ 0.00057652 -0.09515487  0.09379875  0.03524834  0.05763857 -0.25740399\n",
      "  0.34564572  0.002213   -0.32822827  0.27577207 -0.20883523 -0.23028907\n",
      "  0.10446602 -0.36768827]\n",
      "New theta_0 : [ 0.00057636 -0.09515797  0.09380649  0.03526191  0.05763691 -0.25741282\n",
      "  0.3456425   0.00221496 -0.32823508  0.27580514 -0.20887119 -0.23029022\n",
      "  0.10446602 -0.36768994]\n",
      "Training Error:  10.49344945194048\n",
      "====================================================================================================\n",
      "Iteration:  1076\n",
      "Previous theta :  [ 0.00057636 -0.09515797  0.09380649  0.03526191  0.05763691 -0.25741282\n",
      "  0.3456425   0.00221496 -0.32823508  0.27580514 -0.20887119 -0.23029022\n",
      "  0.10446602 -0.36768994]\n",
      "New theta_0 : [ 0.00057621 -0.09516106  0.09381419  0.03527545  0.05763525 -0.25742161\n",
      "  0.3456393   0.00221692 -0.32824184  0.27583812 -0.20890707 -0.23029136\n",
      "  0.10446601 -0.36769161]\n",
      "Training Error:  10.493446867312219\n",
      "====================================================================================================\n",
      "Iteration:  1077\n",
      "Previous theta :  [ 0.00057621 -0.09516106  0.09381419  0.03527545  0.05763525 -0.25742161\n",
      "  0.3456393   0.00221692 -0.32824184  0.27583812 -0.20890707 -0.23029136\n",
      "  0.10446601 -0.36769161]\n",
      "New theta_0 : [ 0.00057605 -0.09516415  0.09382187  0.03528895  0.05763359 -0.25743036\n",
      "  0.34563611  0.00221888 -0.32824856  0.27587101 -0.20894285 -0.2302925\n",
      "  0.10446601 -0.36769327]\n",
      "Training Error:  10.493444297073088\n",
      "====================================================================================================\n",
      "Iteration:  1078\n",
      "Previous theta :  [ 0.00057605 -0.09516415  0.09382187  0.03528895  0.05763359 -0.25743036\n",
      "  0.34563611  0.00221888 -0.32824856  0.27587101 -0.20894285 -0.2302925\n",
      "  0.10446601 -0.36769327]\n",
      "New theta_0 : [ 0.0005759  -0.09516722  0.09382952  0.03530242  0.05763194 -0.25743906\n",
      "  0.34563292  0.00222083 -0.32825524  0.27590381 -0.20897855 -0.23029363\n",
      "  0.10446601 -0.36769493]\n",
      "Training Error:  10.493441741139142\n",
      "====================================================================================================\n",
      "Iteration:  1079\n",
      "Previous theta :  [ 0.0005759  -0.09516722  0.09382952  0.03530242  0.05763194 -0.25743906\n",
      "  0.34563292  0.00222083 -0.32825524  0.27590381 -0.20897855 -0.23029363\n",
      "  0.10446601 -0.36769493]\n",
      "New theta_0 : [ 0.00057574 -0.09517028  0.09383714  0.03531585  0.05763029 -0.25744772\n",
      "  0.34562975  0.00222277 -0.32826189  0.27593652 -0.20901415 -0.23029476\n",
      "  0.10446601 -0.36769658]\n",
      "Training Error:  10.493439199426966\n",
      "====================================================================================================\n",
      "Iteration:  1080\n",
      "Previous theta :  [ 0.00057574 -0.09517028  0.09383714  0.03531585  0.05763029 -0.25744772\n",
      "  0.34562975  0.00222277 -0.32826189  0.27593652 -0.20901415 -0.23029476\n",
      "  0.10446601 -0.36769658]\n",
      "New theta_0 : [ 0.00057559 -0.09517333  0.09384474  0.03532925  0.05762865 -0.25745633\n",
      "  0.3456266   0.00222471 -0.32826849  0.27596914 -0.20904966 -0.23029588\n",
      "  0.10446601 -0.36769823]\n",
      "Training Error:  10.493436671853685\n",
      "====================================================================================================\n",
      "Iteration:  1081\n",
      "Previous theta :  [ 0.00057559 -0.09517333  0.09384474  0.03532925  0.05762865 -0.25745633\n",
      "  0.3456266   0.00222471 -0.32826849  0.27596914 -0.20904966 -0.23029588\n",
      "  0.10446601 -0.36769823]\n",
      "New theta_0 : [ 0.00057544 -0.09517637  0.09385231  0.03534261  0.05762701 -0.2574649\n",
      "  0.34562345  0.00222665 -0.32827505  0.27600167 -0.20908508 -0.23029699\n",
      "  0.10446601 -0.36769988]\n",
      "Training Error:  10.493434158336962\n",
      "====================================================================================================\n",
      "Iteration:  1082\n",
      "Previous theta :  [ 0.00057544 -0.09517637  0.09385231  0.03534261  0.05762701 -0.2574649\n",
      "  0.34562345  0.00222665 -0.32827505  0.27600167 -0.20908508 -0.23029699\n",
      "  0.10446601 -0.36769988]\n",
      "New theta_0 : [ 0.00057529 -0.09517939  0.09385985  0.03535593  0.05762537 -0.25747343\n",
      "  0.34562032  0.00222859 -0.32828158  0.27603412 -0.20912041 -0.23029811\n",
      "  0.10446601 -0.36770152]\n",
      "Training Error:  10.493431658794984\n",
      "====================================================================================================\n",
      "Iteration:  1083\n",
      "Previous theta :  [ 0.00057529 -0.09517939  0.09385985  0.03535593  0.05762537 -0.25747343\n",
      "  0.34562032  0.00222859 -0.32828158  0.27603412 -0.20912041 -0.23029811\n",
      "  0.10446601 -0.36770152]\n",
      "New theta_0 : [ 0.00057514 -0.09518241  0.09386737  0.03536922  0.05762374 -0.25748191\n",
      "  0.3456172   0.00223051 -0.32828806  0.27606647 -0.20915564 -0.23029922\n",
      "  0.10446602 -0.36770316]\n",
      "Training Error:  10.493429173146469\n",
      "====================================================================================================\n",
      "Iteration:  1084\n",
      "Previous theta :  [ 0.00057514 -0.09518241  0.09386737  0.03536922  0.05762374 -0.25748191\n",
      "  0.3456172   0.00223051 -0.32828806  0.27606647 -0.20915564 -0.23029922\n",
      "  0.10446602 -0.36770316]\n",
      "New theta_0 : [ 0.00057499 -0.09518542  0.09387486  0.03538248  0.05762211 -0.25749035\n",
      "  0.34561409  0.00223244 -0.32829451  0.27609873 -0.20919079 -0.23030032\n",
      "  0.10446602 -0.36770479]\n",
      "Training Error:  10.493426701310653\n",
      "====================================================================================================\n",
      "Iteration:  1085\n",
      "Previous theta :  [ 0.00057499 -0.09518542  0.09387486  0.03538248  0.05762211 -0.25749035\n",
      "  0.34561409  0.00223244 -0.32829451  0.27609873 -0.20919079 -0.23030032\n",
      "  0.10446602 -0.36770479]\n",
      "New theta_0 : [ 0.00057484 -0.09518841  0.09388232  0.0353957   0.05762048 -0.25749875\n",
      "  0.34561099  0.00223436 -0.32830091  0.27613091 -0.20922585 -0.23030142\n",
      "  0.10446603 -0.36770642]\n",
      "Training Error:  10.493424243207292\n",
      "====================================================================================================\n",
      "Iteration:  1086\n",
      "Previous theta :  [ 0.00057484 -0.09518841  0.09388232  0.0353957   0.05762048 -0.25749875\n",
      "  0.34561099  0.00223436 -0.32830091  0.27613091 -0.20922585 -0.23030142\n",
      "  0.10446603 -0.36770642]\n",
      "New theta_0 : [ 0.00057469 -0.0951914   0.09388976  0.03540889  0.05761886 -0.25750711\n",
      "  0.3456079   0.00223628 -0.32830728  0.276163   -0.20926082 -0.23030251\n",
      "  0.10446604 -0.36770805]\n",
      "Training Error:  10.493421798756655\n",
      "====================================================================================================\n",
      "Iteration:  1087\n",
      "Previous theta :  [ 0.00057469 -0.0951914   0.09388976  0.03540889  0.05761886 -0.25750711\n",
      "  0.3456079   0.00223628 -0.32830728  0.276163   -0.20926082 -0.23030251\n",
      "  0.10446604 -0.36770805]\n",
      "New theta_0 : [ 0.00057455 -0.09519437  0.09389717  0.03542204  0.05761724 -0.25751543\n",
      "  0.34560483  0.00223819 -0.32831361  0.276195   -0.2092957  -0.2303036\n",
      "  0.10446605 -0.36770967]\n",
      "Training Error:  10.493419367879518\n",
      "====================================================================================================\n",
      "Iteration:  1088\n",
      "Previous theta :  [ 0.00057455 -0.09519437  0.09389717  0.03542204  0.05761724 -0.25751543\n",
      "  0.34560483  0.00223819 -0.32831361  0.276195   -0.2092957  -0.2303036\n",
      "  0.10446605 -0.36770967]\n",
      "New theta_0 : [ 0.0005744  -0.09519734  0.09390455  0.03543516  0.05761563 -0.2575237\n",
      "  0.34560177  0.0022401  -0.3283199   0.27622691 -0.20933049 -0.23030469\n",
      "  0.10446606 -0.36771128]\n",
      "Training Error:  10.49341695049717\n",
      "====================================================================================================\n",
      "Iteration:  1089\n",
      "Previous theta :  [ 0.0005744  -0.09519734  0.09390455  0.03543516  0.05761563 -0.2575237\n",
      "  0.34560177  0.0022401  -0.3283199   0.27622691 -0.20933049 -0.23030469\n",
      "  0.10446606 -0.36771128]\n",
      "New theta_0 : [ 0.00057426 -0.09520029  0.09391191  0.03544825  0.05761401 -0.25753193\n",
      "  0.34559871  0.002242   -0.32832616  0.27625873 -0.20936519 -0.23030577\n",
      "  0.10446607 -0.3677129 ]\n",
      "Training Error:  10.493414546531392\n",
      "====================================================================================================\n",
      "Iteration:  1090\n",
      "Previous theta :  [ 0.00057426 -0.09520029  0.09391191  0.03544825  0.05761401 -0.25753193\n",
      "  0.34559871  0.002242   -0.32832616  0.27625873 -0.20936519 -0.23030577\n",
      "  0.10446607 -0.3677129 ]\n",
      "New theta_0 : [ 0.00057411 -0.09520324  0.09391924  0.0354613   0.05761241 -0.25754013\n",
      "  0.34559567  0.0022439  -0.32833238  0.27629047 -0.2093998  -0.23030685\n",
      "  0.10446608 -0.3677145 ]\n",
      "Training Error:  10.493412155904473\n",
      "====================================================================================================\n",
      "Iteration:  1091\n",
      "Previous theta :  [ 0.00057411 -0.09520324  0.09391924  0.0354613   0.05761241 -0.25754013\n",
      "  0.34559567  0.0022439  -0.32833238  0.27629047 -0.2093998  -0.23030685\n",
      "  0.10446608 -0.3677145 ]\n",
      "New theta_0 : [ 0.00057397 -0.09520617  0.09392655  0.03547431  0.0576108  -0.25754828\n",
      "  0.34559264  0.0022458  -0.32833856  0.27632212 -0.20943433 -0.23030792\n",
      "  0.1044661  -0.36771611]\n",
      "Training Error:  10.493409778539192\n",
      "====================================================================================================\n",
      "Iteration:  1092\n",
      "Previous theta :  [ 0.00057397 -0.09520617  0.09392655  0.03547431  0.0576108  -0.25754828\n",
      "  0.34559264  0.0022458  -0.32833856  0.27632212 -0.20943433 -0.23030792\n",
      "  0.1044661  -0.36771611]\n",
      "New theta_0 : [ 0.00057383 -0.09520909  0.09393383  0.03548729  0.0576092  -0.25755639\n",
      "  0.34558963  0.00224769 -0.3283447   0.27635368 -0.20946876 -0.23030899\n",
      "  0.10446611 -0.36771771]\n",
      "Training Error:  10.493407414358817\n",
      "====================================================================================================\n",
      "Iteration:  1093\n",
      "Previous theta :  [ 0.00057383 -0.09520909  0.09393383  0.03548729  0.0576092  -0.25755639\n",
      "  0.34558963  0.00224769 -0.3283447   0.27635368 -0.20946876 -0.23030899\n",
      "  0.10446611 -0.36771771]\n",
      "New theta_0 : [ 0.00057368 -0.09521201  0.09394109  0.03550024  0.05760761 -0.25756446\n",
      "  0.34558662  0.00224958 -0.32835081  0.27638516 -0.20950311 -0.23031005\n",
      "  0.10446613 -0.36771931]\n",
      "Training Error:  10.493405063287108\n",
      "====================================================================================================\n",
      "Iteration:  1094\n",
      "Previous theta :  [ 0.00057368 -0.09521201  0.09394109  0.03550024  0.05760761 -0.25756446\n",
      "  0.34558662  0.00224958 -0.32835081  0.27638516 -0.20950311 -0.23031005\n",
      "  0.10446613 -0.36771931]\n",
      "New theta_0 : [ 0.00057354 -0.09521491  0.09394832  0.03551316  0.05760602 -0.25757249\n",
      "  0.34558363  0.00225146 -0.32835688  0.27641655 -0.20953737 -0.23031111\n",
      "  0.10446614 -0.3677209 ]\n",
      "Training Error:  10.493402725248302\n",
      "====================================================================================================\n",
      "Iteration:  1095\n",
      "Previous theta :  [ 0.00057354 -0.09521491  0.09394832  0.03551316  0.05760602 -0.25757249\n",
      "  0.34558363  0.00225146 -0.32835688  0.27641655 -0.20953737 -0.23031111\n",
      "  0.10446614 -0.3677209 ]\n",
      "New theta_0 : [ 0.0005734  -0.0952178   0.09395553  0.03552603  0.05760443 -0.25758048\n",
      "  0.34558064  0.00225334 -0.32836292  0.27644785 -0.20957154 -0.23031216\n",
      "  0.10446616 -0.36772249]\n",
      "Training Error:  10.493400400167122\n",
      "====================================================================================================\n",
      "Iteration:  1096\n",
      "Previous theta :  [ 0.0005734  -0.0952178   0.09395553  0.03552603  0.05760443 -0.25758048\n",
      "  0.34558064  0.00225334 -0.32836292  0.27644785 -0.20957154 -0.23031216\n",
      "  0.10446616 -0.36772249]\n",
      "New theta_0 : [ 0.00057327 -0.09522069  0.09396271  0.03553888  0.05760284 -0.25758843\n",
      "  0.34557767  0.00225522 -0.32836892  0.27647907 -0.20960562 -0.23031321\n",
      "  0.10446618 -0.36772407]\n",
      "Training Error:  10.493398087968766\n",
      "====================================================================================================\n",
      "Iteration:  1097\n",
      "Previous theta :  [ 0.00057327 -0.09522069  0.09396271  0.03553888  0.05760284 -0.25758843\n",
      "  0.34557767  0.00225522 -0.32836892  0.27647907 -0.20960562 -0.23031321\n",
      "  0.10446618 -0.36772407]\n",
      "New theta_0 : [ 0.00057313 -0.09522356  0.09396986  0.03555169  0.05760126 -0.25759634\n",
      "  0.34557471  0.00225709 -0.32837488  0.27651021 -0.20963962 -0.23031426\n",
      "  0.1044662  -0.36772565]\n",
      "Training Error:  10.493395788578901\n",
      "====================================================================================================\n",
      "Iteration:  1098\n",
      "Previous theta :  [ 0.00057313 -0.09522356  0.09396986  0.03555169  0.05760126 -0.25759634\n",
      "  0.34557471  0.00225709 -0.32837488  0.27651021 -0.20963962 -0.23031426\n",
      "  0.1044662  -0.36772565]\n",
      "New theta_0 : [ 0.00057299 -0.09522642  0.09397699  0.03556447  0.05759969 -0.25760421\n",
      "  0.34557176  0.00225896 -0.32838081  0.27654126 -0.20967352 -0.2303153\n",
      "  0.10446622 -0.36772723]\n",
      "Training Error:  10.493393501923665\n",
      "====================================================================================================\n",
      "Iteration:  1099\n",
      "Previous theta :  [ 0.00057299 -0.09522642  0.09397699  0.03556447  0.05759969 -0.25760421\n",
      "  0.34557176  0.00225896 -0.32838081  0.27654126 -0.20967352 -0.2303153\n",
      "  0.10446622 -0.36772723]\n",
      "New theta_0 : [ 0.00057286 -0.09522928  0.0939841   0.03557722  0.05759811 -0.25761205\n",
      "  0.34556882  0.00226082 -0.3283867   0.27657222 -0.20970735 -0.23031634\n",
      "  0.10446625 -0.3677288 ]\n",
      "Training Error:  10.493391227929665\n",
      "====================================================================================================\n",
      "Iteration:  1100\n",
      "Previous theta :  [ 0.00057286 -0.09522928  0.0939841   0.03557722  0.05759811 -0.25761205\n",
      "  0.34556882  0.00226082 -0.3283867   0.27657222 -0.20970735 -0.23031634\n",
      "  0.10446625 -0.3677288 ]\n",
      "New theta_0 : [ 0.00057272 -0.09523212  0.09399118  0.03558993  0.05759654 -0.25761984\n",
      "  0.34556589  0.00226268 -0.32839256  0.2766031  -0.20974108 -0.23031737\n",
      "  0.10446627 -0.36773037]\n",
      "Training Error:  10.493388966523966\n",
      "====================================================================================================\n",
      "Iteration:  1101\n",
      "Previous theta :  [ 0.00057272 -0.09523212  0.09399118  0.03558993  0.05759654 -0.25761984\n",
      "  0.34556589  0.00226268 -0.32839256  0.2766031  -0.20974108 -0.23031737\n",
      "  0.10446627 -0.36773037]\n",
      "New theta_0 : [ 0.00057259 -0.09523495  0.09399824  0.03560261  0.05759498 -0.2576276\n",
      "  0.34556297  0.00226453 -0.32839839  0.27663389 -0.20977473 -0.2303184\n",
      "  0.10446629 -0.36773193]\n",
      "Training Error:  10.493386717634094\n",
      "====================================================================================================\n",
      "Iteration:  1102\n",
      "Previous theta :  [ 0.00057259 -0.09523495  0.09399824  0.03560261  0.05759498 -0.2576276\n",
      "  0.34556297  0.00226453 -0.32839839  0.27663389 -0.20977473 -0.2303184\n",
      "  0.10446629 -0.36773193]\n",
      "New theta_0 : [ 0.00057245 -0.09523778  0.09400527  0.03561525  0.05759341 -0.25763531\n",
      "  0.34556006  0.00226639 -0.32840418  0.2766646  -0.20980829 -0.23031942\n",
      "  0.10446632 -0.36773349]\n",
      "Training Error:  10.493384481188029\n",
      "====================================================================================================\n",
      "Iteration:  1103\n",
      "Previous theta :  [ 0.00057245 -0.09523778  0.09400527  0.03561525  0.05759341 -0.25763531\n",
      "  0.34556006  0.00226639 -0.32840418  0.2766646  -0.20980829 -0.23031942\n",
      "  0.10446632 -0.36773349]\n",
      "New theta_0 : [ 0.00057232 -0.09524059  0.09401228  0.03562787  0.05759185 -0.25764299\n",
      "  0.34555717  0.00226823 -0.32840993  0.27669523 -0.20984176 -0.23032044\n",
      "  0.10446635 -0.36773505]\n",
      "Training Error:  10.493382257114204\n",
      "====================================================================================================\n",
      "Iteration:  1104\n",
      "Previous theta :  [ 0.00057232 -0.09524059  0.09401228  0.03562787  0.05759185 -0.25764299\n",
      "  0.34555717  0.00226823 -0.32840993  0.27669523 -0.20984176 -0.23032044\n",
      "  0.10446635 -0.36773505]\n",
      "New theta_0 : [ 0.00057219 -0.09524339  0.09401926  0.03564045  0.0575903  -0.25765064\n",
      "  0.34555428  0.00227008 -0.32841565  0.27672577 -0.20987515 -0.23032146\n",
      "  0.10446637 -0.3677366 ]\n",
      "Training Error:  10.493380045341501\n",
      "====================================================================================================\n",
      "Iteration:  1105\n",
      "Previous theta :  [ 0.00057219 -0.09524339  0.09401926  0.03564045  0.0575903  -0.25765064\n",
      "  0.34555428  0.00227008 -0.32841565  0.27672577 -0.20987515 -0.23032146\n",
      "  0.10446637 -0.3677366 ]\n",
      "New theta_0 : [ 0.00057205 -0.09524619  0.09402622  0.03565299  0.05758875 -0.25765824\n",
      "  0.34555141  0.00227192 -0.32842134  0.27675622 -0.20990846 -0.23032247\n",
      "  0.1044664  -0.36773815]\n",
      "Training Error:  10.493377845799245\n",
      "====================================================================================================\n",
      "Iteration:  1106\n",
      "Previous theta :  [ 0.00057205 -0.09524619  0.09402622  0.03565299  0.05758875 -0.25765824\n",
      "  0.34555141  0.00227192 -0.32842134  0.27675622 -0.20990846 -0.23032247\n",
      "  0.1044664  -0.36773815]\n",
      "New theta_0 : [ 0.00057192 -0.09524897  0.09403316  0.0356655   0.0575872  -0.25766581\n",
      "  0.34554854  0.00227375 -0.328427    0.2767866  -0.20994167 -0.23032348\n",
      "  0.10446643 -0.3677397 ]\n",
      "Training Error:  10.493375658417204\n",
      "====================================================================================================\n",
      "Iteration:  1107\n",
      "Previous theta :  [ 0.00057192 -0.09524897  0.09403316  0.0356655   0.0575872  -0.25766581\n",
      "  0.34554854  0.00227375 -0.328427    0.2767866  -0.20994167 -0.23032348\n",
      "  0.10446643 -0.3677397 ]\n",
      "New theta_0 : [ 0.00057179 -0.09525175  0.09404007  0.03567799  0.05758566 -0.25767334\n",
      "  0.34554569  0.00227558 -0.32843262  0.27681689 -0.20997481 -0.23032449\n",
      "  0.10446646 -0.36774124]\n",
      "Training Error:  10.493373483125588\n",
      "====================================================================================================\n",
      "Iteration:  1108\n",
      "Previous theta :  [ 0.00057179 -0.09525175  0.09404007  0.03567799  0.05758566 -0.25767334\n",
      "  0.34554569  0.00227558 -0.32843262  0.27681689 -0.20997481 -0.23032449\n",
      "  0.10446646 -0.36774124]\n",
      "New theta_0 : [ 0.00057167 -0.09525451  0.09404696  0.03569043  0.05758412 -0.25768083\n",
      "  0.34554285  0.00227741 -0.3284382   0.2768471  -0.21000785 -0.23032549\n",
      "  0.10446649 -0.36774277]\n",
      "Training Error:  10.49337131985504\n",
      "====================================================================================================\n",
      "Iteration:  1109\n",
      "Previous theta :  [ 0.00057167 -0.09525451  0.09404696  0.03569043  0.05758412 -0.25768083\n",
      "  0.34554285  0.00227741 -0.3284382   0.2768471  -0.21000785 -0.23032549\n",
      "  0.10446649 -0.36774277]\n",
      "New theta_0 : [ 0.00057154 -0.09525727  0.09405382  0.03570285  0.05758258 -0.25768829\n",
      "  0.34554001  0.00227923 -0.32844376  0.27687723 -0.21004081 -0.23032648\n",
      "  0.10446653 -0.36774431]\n",
      "Training Error:  10.493369168536635\n",
      "====================================================================================================\n",
      "Iteration:  1110\n",
      "Previous theta :  [ 0.00057154 -0.09525727  0.09405382  0.03570285  0.05758258 -0.25768829\n",
      "  0.34554001  0.00227923 -0.32844376  0.27687723 -0.21004081 -0.23032648\n",
      "  0.10446653 -0.36774431]\n",
      "New theta_0 : [ 0.00057141 -0.09526001  0.09406066  0.03571523  0.05758105 -0.25769571\n",
      "  0.34553719  0.00228105 -0.32844928  0.27690727 -0.21007369 -0.23032747\n",
      "  0.10446656 -0.36774584]\n",
      "Training Error:  10.49336702910188\n",
      "====================================================================================================\n",
      "Iteration:  1111\n",
      "Previous theta :  [ 0.00057141 -0.09526001  0.09406066  0.03571523  0.05758105 -0.25769571\n",
      "  0.34553719  0.00228105 -0.32844928  0.27690727 -0.21007369 -0.23032747\n",
      "  0.10446656 -0.36774584]\n",
      "New theta_0 : [ 0.00057128 -0.09526275  0.09406748  0.03572758  0.05757952 -0.25770309\n",
      "  0.34553438  0.00228287 -0.32845477  0.27693723 -0.21010648 -0.23032846\n",
      "  0.10446659 -0.36774736]\n",
      "Training Error:  10.493364901482702\n",
      "====================================================================================================\n",
      "Iteration:  1112\n",
      "Previous theta :  [ 0.00057128 -0.09526275  0.09406748  0.03572758  0.05757952 -0.25770309\n",
      "  0.34553438  0.00228287 -0.32845477  0.27693723 -0.21010648 -0.23032846\n",
      "  0.10446659 -0.36774736]\n",
      "New theta_0 : [ 0.00057116 -0.09526548  0.09407427  0.0357399   0.05757799 -0.25771044\n",
      "  0.34553158  0.00228468 -0.32846023  0.27696711 -0.21013919 -0.23032944\n",
      "  0.10446663 -0.36774888]\n",
      "Training Error:  10.493362785611458\n",
      "====================================================================================================\n",
      "Iteration:  1113\n",
      "Previous theta :  [ 0.00057116 -0.09526548  0.09407427  0.0357399   0.05757799 -0.25771044\n",
      "  0.34553158  0.00228468 -0.32846023  0.27696711 -0.21013919 -0.23032944\n",
      "  0.10446663 -0.36774888]\n",
      "New theta_0 : [ 0.00057103 -0.0952682   0.09408104  0.03575218  0.05757647 -0.25771775\n",
      "  0.34552878  0.00228649 -0.32846565  0.27699691 -0.21017182 -0.23033042\n",
      "  0.10446667 -0.3677504 ]\n",
      "Training Error:  10.493360681420924\n",
      "====================================================================================================\n",
      "Iteration:  1114\n",
      "Previous theta :  [ 0.00057103 -0.0952682   0.09408104  0.03575218  0.05757647 -0.25771775\n",
      "  0.34552878  0.00228649 -0.32846565  0.27699691 -0.21017182 -0.23033042\n",
      "  0.10446667 -0.3677504 ]\n",
      "New theta_0 : [ 0.00057091 -0.09527091  0.09408779  0.03576443  0.05757495 -0.25772502\n",
      "  0.345526    0.00228829 -0.32847105  0.27702662 -0.21020436 -0.2303314\n",
      "  0.1044667  -0.36775192]\n",
      "Training Error:  10.49335858884429\n",
      "====================================================================================================\n",
      "Iteration:  1115\n",
      "Previous theta :  [ 0.00057091 -0.09527091  0.09408779  0.03576443  0.05757495 -0.25772502\n",
      "  0.345526    0.00228829 -0.32847105  0.27702662 -0.21020436 -0.2303314\n",
      "  0.1044667  -0.36775192]\n",
      "New theta_0 : [ 0.00057078 -0.09527361  0.09409451  0.03577666  0.05757343 -0.25773226\n",
      "  0.34552323  0.00229009 -0.32847641  0.27705626 -0.21023681 -0.23033237\n",
      "  0.10446674 -0.36775343]\n",
      "Training Error:  10.493356507815161\n",
      "====================================================================================================\n",
      "Iteration:  1116\n",
      "Previous theta :  [ 0.00057078 -0.09527361  0.09409451  0.03577666  0.05757343 -0.25773226\n",
      "  0.34552323  0.00229009 -0.32847641  0.27705626 -0.21023681 -0.23033237\n",
      "  0.10446674 -0.36775343]\n",
      "New theta_0 : [ 0.00057066 -0.0952763   0.09410121  0.03578884  0.05757192 -0.25773947\n",
      "  0.34552047  0.00229188 -0.32848174  0.27708581 -0.21026918 -0.23033334\n",
      "  0.10446678 -0.36775493]\n",
      "Training Error:  10.49335443826755\n",
      "====================================================================================================\n",
      "Iteration:  1117\n",
      "Previous theta :  [ 0.00057066 -0.0952763   0.09410121  0.03578884  0.05757192 -0.25773947\n",
      "  0.34552047  0.00229188 -0.32848174  0.27708581 -0.21026918 -0.23033334\n",
      "  0.10446678 -0.36775493]\n",
      "New theta_0 : [ 0.00057054 -0.09527898  0.09410789  0.035801    0.05757041 -0.25774664\n",
      "  0.34551772  0.00229368 -0.32848704  0.27711528 -0.21030147 -0.2303343\n",
      "  0.10446682 -0.36775644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.493352380135889\n",
      "====================================================================================================\n",
      "Iteration:  1118\n",
      "Previous theta :  [ 0.00057054 -0.09527898  0.09410789  0.035801    0.05757041 -0.25774664\n",
      "  0.34551772  0.00229368 -0.32848704  0.27711528 -0.21030147 -0.2303343\n",
      "  0.10446682 -0.36775644]\n",
      "New theta_0 : [ 0.00057042 -0.09528165  0.09411454  0.03581312  0.05756891 -0.25775378\n",
      "  0.34551498  0.00229546 -0.32849231  0.27714468 -0.21033368 -0.23033526\n",
      "  0.10446686 -0.36775794]\n",
      "Training Error:  10.493350333355002\n",
      "====================================================================================================\n",
      "Iteration:  1119\n",
      "Previous theta :  [ 0.00057042 -0.09528165  0.09411454  0.03581312  0.05756891 -0.25775378\n",
      "  0.34551498  0.00229546 -0.32849231  0.27714468 -0.21033368 -0.23033526\n",
      "  0.10446686 -0.36775794]\n",
      "New theta_0 : [ 0.0005703  -0.09528431  0.09412117  0.03582522  0.05756741 -0.25776088\n",
      "  0.34551225  0.00229725 -0.32849754  0.27717399 -0.2103658  -0.23033622\n",
      "  0.1044669  -0.36775943]\n",
      "Training Error:  10.493348297860122\n",
      "====================================================================================================\n",
      "Iteration:  1120\n",
      "Previous theta :  [ 0.0005703  -0.09528431  0.09412117  0.03582522  0.05756741 -0.25776088\n",
      "  0.34551225  0.00229725 -0.32849754  0.27717399 -0.2103658  -0.23033622\n",
      "  0.1044669  -0.36775943]\n",
      "New theta_0 : [ 0.00057018 -0.09528697  0.09412778  0.03583728  0.05756591 -0.25776794\n",
      "  0.34550953  0.00229903 -0.32850275  0.27720322 -0.21039784 -0.23033717\n",
      "  0.10446694 -0.36776092]\n",
      "Training Error:  10.493346273586878\n",
      "====================================================================================================\n",
      "Iteration:  1121\n",
      "Previous theta :  [ 0.00057018 -0.09528697  0.09412778  0.03583728  0.05756591 -0.25776794\n",
      "  0.34550953  0.00229903 -0.32850275  0.27720322 -0.21039784 -0.23033717\n",
      "  0.10446694 -0.36776092]\n",
      "New theta_0 : [ 0.00057006 -0.09528961  0.09413437  0.03584931  0.05756442 -0.25777498\n",
      "  0.34550681  0.0023008  -0.32850793  0.27723237 -0.2104298  -0.23033812\n",
      "  0.10446699 -0.36776241]\n",
      "Training Error:  10.4933442604713\n",
      "====================================================================================================\n",
      "Iteration:  1122\n",
      "Previous theta :  [ 0.00057006 -0.09528961  0.09413437  0.03584931  0.05756442 -0.25777498\n",
      "  0.34550681  0.0023008  -0.32850793  0.27723237 -0.2104298  -0.23033812\n",
      "  0.10446699 -0.36776241]\n",
      "New theta_0 : [ 0.00056994 -0.09529225  0.09414093  0.0358613   0.05756293 -0.25778197\n",
      "  0.34550411  0.00230257 -0.32851307  0.27726144 -0.21046167 -0.23033907\n",
      "  0.10446703 -0.36776389]\n",
      "Training Error:  10.493342258449808\n",
      "====================================================================================================\n",
      "Iteration:  1123\n",
      "Previous theta :  [ 0.00056994 -0.09529225  0.09414093  0.0358613   0.05756293 -0.25778197\n",
      "  0.34550411  0.00230257 -0.32851307  0.27726144 -0.21046167 -0.23033907\n",
      "  0.10446703 -0.36776389]\n",
      "New theta_0 : [ 0.00056982 -0.09529487  0.09414748  0.03587327  0.05756144 -0.25778894\n",
      "  0.34550142  0.00230434 -0.32851819  0.27729043 -0.21049346 -0.23034001\n",
      "  0.10446707 -0.36776538]\n",
      "Training Error:  10.493340267459214\n",
      "====================================================================================================\n",
      "Iteration:  1124\n",
      "Previous theta :  [ 0.00056982 -0.09529487  0.09414748  0.03587327  0.05756144 -0.25778894\n",
      "  0.34550142  0.00230434 -0.32851819  0.27729043 -0.21049346 -0.23034001\n",
      "  0.10446707 -0.36776538]\n",
      "New theta_0 : [ 0.0005697  -0.09529749  0.094154    0.0358852   0.05755996 -0.25779587\n",
      "  0.34549874  0.00230611 -0.32852328  0.27731935 -0.21052517 -0.23034095\n",
      "  0.10446712 -0.36776685]\n",
      "Training Error:  10.493338287436716\n",
      "====================================================================================================\n",
      "Iteration:  1125\n",
      "Previous theta :  [ 0.0005697  -0.09529749  0.094154    0.0358852   0.05755996 -0.25779587\n",
      "  0.34549874  0.00230611 -0.32852328  0.27731935 -0.21052517 -0.23034095\n",
      "  0.10446712 -0.36776685]\n",
      "New theta_0 : [ 0.00056959 -0.0953001   0.09416049  0.03589711  0.05755848 -0.25780277\n",
      "  0.34549607  0.00230787 -0.32852833  0.27734818 -0.2105568  -0.23034188\n",
      "  0.10446717 -0.36776832]\n",
      "Training Error:  10.493336318319898\n",
      "====================================================================================================\n",
      "Iteration:  1126\n",
      "Previous theta :  [ 0.00056959 -0.0953001   0.09416049  0.03589711  0.05755848 -0.25780277\n",
      "  0.34549607  0.00230787 -0.32852833  0.27734818 -0.2105568  -0.23034188\n",
      "  0.10446717 -0.36776832]\n",
      "New theta_0 : [ 0.00056947 -0.0953027   0.09416697  0.03590898  0.057557   -0.25780963\n",
      "  0.3454934   0.00230962 -0.32853336  0.27737694 -0.21058835 -0.23034281\n",
      "  0.10446721 -0.36776979]\n",
      "Training Error:  10.493334360046733\n",
      "====================================================================================================\n",
      "Iteration:  1127\n",
      "Previous theta :  [ 0.00056947 -0.0953027   0.09416697  0.03590898  0.057557   -0.25780963\n",
      "  0.3454934   0.00230962 -0.32853336  0.27737694 -0.21058835 -0.23034281\n",
      "  0.10446721 -0.36776979]\n",
      "New theta_0 : [ 0.00056935 -0.09530529  0.09417342  0.03592082  0.05755553 -0.25781646\n",
      "  0.34549075  0.00231137 -0.32853836  0.27740561 -0.21061981 -0.23034374\n",
      "  0.10446726 -0.36777126]\n",
      "Training Error:  10.493332412555564\n",
      "====================================================================================================\n",
      "Iteration:  1128\n",
      "Previous theta :  [ 0.00056935 -0.09530529  0.09417342  0.03592082  0.05755553 -0.25781646\n",
      "  0.34549075  0.00231137 -0.32853836  0.27740561 -0.21061981 -0.23034374\n",
      "  0.10446726 -0.36777126]\n",
      "New theta_0 : [ 0.00056924 -0.09530787  0.09417985  0.03593263  0.05755406 -0.25782326\n",
      "  0.34548811  0.00231312 -0.32854333  0.27743421 -0.2106512  -0.23034466\n",
      "  0.10446731 -0.36777272]\n",
      "Training Error:  10.493330475785115\n",
      "====================================================================================================\n",
      "Iteration:  1129\n",
      "Previous theta :  [ 0.00056924 -0.09530787  0.09417985  0.03593263  0.05755406 -0.25782326\n",
      "  0.34548811  0.00231312 -0.32854333  0.27743421 -0.2106512  -0.23034466\n",
      "  0.10446731 -0.36777272]\n",
      "New theta_0 : [ 0.00056913 -0.09531045  0.09418626  0.0359444   0.0575526  -0.25783003\n",
      "  0.34548547  0.00231487 -0.32854827  0.27746273 -0.2106825  -0.23034558\n",
      "  0.10446736 -0.36777418]\n",
      "Training Error:  10.493328549674487\n",
      "====================================================================================================\n",
      "Iteration:  1130\n",
      "Previous theta :  [ 0.00056913 -0.09531045  0.09418626  0.0359444   0.0575526  -0.25783003\n",
      "  0.34548547  0.00231487 -0.32854827  0.27746273 -0.2106825  -0.23034558\n",
      "  0.10446736 -0.36777418]\n",
      "New theta_0 : [ 0.00056901 -0.09531301  0.09419265  0.03595615  0.05755114 -0.25783676\n",
      "  0.34548285  0.00231661 -0.32855318  0.27749117 -0.21071372 -0.23034649\n",
      "  0.10446741 -0.36777563]\n",
      "Training Error:  10.49332663416315\n",
      "====================================================================================================\n",
      "Iteration:  1131\n",
      "Previous theta :  [ 0.00056901 -0.09531301  0.09419265  0.03595615  0.05755114 -0.25783676\n",
      "  0.34548285  0.00231661 -0.32855318  0.27749117 -0.21071372 -0.23034649\n",
      "  0.10446741 -0.36777563]\n",
      "New theta_0 : [ 0.0005689  -0.09531557  0.09419902  0.03596787  0.05754968 -0.25784346\n",
      "  0.34548023  0.00231835 -0.32855806  0.27751954 -0.21074486 -0.2303474\n",
      "  0.10446746 -0.36777709]\n",
      "Training Error:  10.493324729190944\n",
      "====================================================================================================\n",
      "Iteration:  1132\n",
      "Previous theta :  [ 0.0005689  -0.09531557  0.09419902  0.03596787  0.05754968 -0.25784346\n",
      "  0.34548023  0.00231835 -0.32855806  0.27751954 -0.21074486 -0.2303474\n",
      "  0.10446746 -0.36777709]\n",
      "New theta_0 : [ 0.00056879 -0.09531811  0.09420536  0.03597955  0.05754822 -0.25785013\n",
      "  0.34547763  0.00232008 -0.32856292  0.27754782 -0.21077592 -0.23034831\n",
      "  0.10446751 -0.36777853]\n",
      "Training Error:  10.493322834698077\n",
      "====================================================================================================\n",
      "Iteration:  1133\n",
      "Previous theta :  [ 0.00056879 -0.09531811  0.09420536  0.03597955  0.05754822 -0.25785013\n",
      "  0.34547763  0.00232008 -0.32856292  0.27754782 -0.21077592 -0.23034831\n",
      "  0.10446751 -0.36777853]\n",
      "New theta_0 : [ 0.00056868 -0.09532065  0.09421169  0.03599121  0.05754677 -0.25785677\n",
      "  0.34547503  0.00232181 -0.32856775  0.27757603 -0.2108069  -0.23034922\n",
      "  0.10446756 -0.36777998]\n",
      "Training Error:  10.493320950625115\n",
      "====================================================================================================\n",
      "Iteration:  1134\n",
      "Previous theta :  [ 0.00056868 -0.09532065  0.09421169  0.03599121  0.05754677 -0.25785677\n",
      "  0.34547503  0.00232181 -0.32856775  0.27757603 -0.2108069  -0.23034922\n",
      "  0.10446756 -0.36777998]\n",
      "New theta_0 : [ 0.00056857 -0.09532318  0.09421799  0.03600283  0.05754532 -0.25786338\n",
      "  0.34547244  0.00232353 -0.32857254  0.27760417 -0.2108378  -0.23035012\n",
      "  0.10446761 -0.36778142]\n",
      "Training Error:  10.493319076912993\n",
      "====================================================================================================\n",
      "Iteration:  1135\n",
      "Previous theta :  [ 0.00056857 -0.09532318  0.09421799  0.03600283  0.05754532 -0.25786338\n",
      "  0.34547244  0.00232353 -0.32857254  0.27760417 -0.2108378  -0.23035012\n",
      "  0.10446761 -0.36778142]\n",
      "New theta_0 : [ 0.00056846 -0.0953257   0.09422427  0.03601442  0.05754388 -0.25786995\n",
      "  0.34546986  0.00232525 -0.32857732  0.27763222 -0.21086862 -0.23035102\n",
      "  0.10446767 -0.36778285]\n",
      "Training Error:  10.493317213503003\n",
      "====================================================================================================\n",
      "Iteration:  1136\n",
      "Previous theta :  [ 0.00056846 -0.0953257   0.09422427  0.03601442  0.05754388 -0.25786995\n",
      "  0.34546986  0.00232525 -0.32857732  0.27763222 -0.21086862 -0.23035102\n",
      "  0.10446767 -0.36778285]\n",
      "New theta_0 : [ 0.00056835 -0.09532822  0.09423053  0.03602598  0.05754244 -0.25787649\n",
      "  0.3454673   0.00232697 -0.32858206  0.2776602  -0.21089936 -0.23035191\n",
      "  0.10446772 -0.36778429]\n",
      "Training Error:  10.493315360336794\n",
      "====================================================================================================\n",
      "Iteration:  1137\n",
      "Previous theta :  [ 0.00056835 -0.09532822  0.09423053  0.03602598  0.05754244 -0.25787649\n",
      "  0.3454673   0.00232697 -0.32858206  0.2776602  -0.21089936 -0.23035191\n",
      "  0.10446772 -0.36778429]\n",
      "New theta_0 : [ 0.00056824 -0.09533072  0.09423677  0.03603752  0.057541   -0.257883\n",
      "  0.34546474  0.00232869 -0.32858678  0.2776881  -0.21093003 -0.2303528\n",
      "  0.10446778 -0.36778572]\n",
      "Training Error:  10.493313517356365\n",
      "====================================================================================================\n",
      "Iteration:  1138\n",
      "Previous theta :  [ 0.00056824 -0.09533072  0.09423677  0.03603752  0.057541   -0.257883\n",
      "  0.34546474  0.00232869 -0.32858678  0.2776881  -0.21093003 -0.2303528\n",
      "  0.10446778 -0.36778572]\n",
      "New theta_0 : [ 0.00056813 -0.09533322  0.09424298  0.03604902  0.05753957 -0.25788949\n",
      "  0.34546219  0.0023304  -0.32859146  0.27771593 -0.21096061 -0.23035369\n",
      "  0.10446783 -0.36778714]\n",
      "Training Error:  10.493311684504066\n",
      "====================================================================================================\n",
      "Iteration:  1139\n",
      "Previous theta :  [ 0.00056813 -0.09533322  0.09424298  0.03604902  0.05753957 -0.25788949\n",
      "  0.34546219  0.0023304  -0.32859146  0.27771593 -0.21096061 -0.23035369\n",
      "  0.10446783 -0.36778714]\n",
      "New theta_0 : [ 0.00056802 -0.09533571  0.09424918  0.03606049  0.05753814 -0.25789594\n",
      "  0.34545964  0.0023321  -0.32859613  0.27774368 -0.21099111 -0.23035457\n",
      "  0.10446789 -0.36778857]\n",
      "Training Error:  10.493309861722604\n",
      "====================================================================================================\n",
      "Iteration:  1140\n",
      "Previous theta :  [ 0.00056802 -0.09533571  0.09424918  0.03606049  0.05753814 -0.25789594\n",
      "  0.34545964  0.0023321  -0.32859613  0.27774368 -0.21099111 -0.23035457\n",
      "  0.10446789 -0.36778857]\n",
      "New theta_0 : [ 0.00056792 -0.09533819  0.09425535  0.03607193  0.05753671 -0.25790235\n",
      "  0.34545711  0.0023338  -0.32860076  0.27777135 -0.21102153 -0.23035545\n",
      "  0.10446795 -0.36778998]\n",
      "Training Error:  10.493308048955027\n",
      "====================================================================================================\n",
      "Iteration:  1141\n",
      "Previous theta :  [ 0.00056792 -0.09533819  0.09425535  0.03607193  0.05753671 -0.25790235\n",
      "  0.34545711  0.0023338  -0.32860076  0.27777135 -0.21102153 -0.23035545\n",
      "  0.10446795 -0.36778998]\n",
      "New theta_0 : [ 0.00056781 -0.09534066  0.09426151  0.03608334  0.05753529 -0.25790874\n",
      "  0.34545459  0.0023355  -0.32860537  0.27779895 -0.21105188 -0.23035633\n",
      "  0.104468   -0.3677914 ]\n",
      "Training Error:  10.493306246144726\n",
      "====================================================================================================\n",
      "Iteration:  1142\n",
      "Previous theta :  [ 0.00056781 -0.09534066  0.09426151  0.03608334  0.05753529 -0.25790874\n",
      "  0.34545459  0.0023355  -0.32860537  0.27779895 -0.21105188 -0.23035633\n",
      "  0.104468   -0.3677914 ]\n",
      "New theta_0 : [ 0.00056771 -0.09534312  0.09426764  0.03609472  0.05753387 -0.2579151\n",
      "  0.34545207  0.0023372  -0.32860995  0.27782648 -0.21108214 -0.2303572\n",
      "  0.10446806 -0.36779281]\n",
      "Training Error:  10.49330445323544\n",
      "====================================================================================================\n",
      "Iteration:  1143\n",
      "Previous theta :  [ 0.00056771 -0.09534312  0.09426764  0.03609472  0.05753387 -0.2579151\n",
      "  0.34545207  0.0023372  -0.32860995  0.27782648 -0.21108214 -0.2303572\n",
      "  0.10446806 -0.36779281]\n",
      "New theta_0 : [ 0.0005676  -0.09534557  0.09427376  0.03610607  0.05753245 -0.25792143\n",
      "  0.34544957  0.00233889 -0.32861451  0.27785393 -0.21111233 -0.23035807\n",
      "  0.10446812 -0.36779422]\n",
      "Training Error:  10.493302670171238\n",
      "====================================================================================================\n",
      "Iteration:  1144\n",
      "Previous theta :  [ 0.0005676  -0.09534557  0.09427376  0.03610607  0.05753245 -0.25792143\n",
      "  0.34544957  0.00233889 -0.32861451  0.27785393 -0.21111233 -0.23035807\n",
      "  0.10446812 -0.36779422]\n",
      "New theta_0 : [ 0.0005675  -0.09534802  0.09427985  0.03611739  0.05753103 -0.25792773\n",
      "  0.34544707  0.00234058 -0.32861904  0.2778813  -0.21114244 -0.23035893\n",
      "  0.10446818 -0.36779562]\n",
      "Training Error:  10.493300896896534\n",
      "====================================================================================================\n",
      "Iteration:  1145\n",
      "Previous theta :  [ 0.0005675  -0.09534802  0.09427985  0.03611739  0.05753103 -0.25792773\n",
      "  0.34544707  0.00234058 -0.32861904  0.2778813  -0.21114244 -0.23035893\n",
      "  0.10446818 -0.36779562]\n",
      "New theta_0 : [ 0.00056739 -0.09535046  0.09428592  0.03612868  0.05752962 -0.257934\n",
      "  0.34544458  0.00234226 -0.32862354  0.2779086  -0.21117247 -0.2303598\n",
      "  0.10446824 -0.36779703]\n",
      "Training Error:  10.493299133356077\n",
      "====================================================================================================\n",
      "Iteration:  1146\n",
      "Previous theta :  [ 0.00056739 -0.09535046  0.09428592  0.03612868  0.05752962 -0.257934\n",
      "  0.34544458  0.00234226 -0.32862354  0.2779086  -0.21117247 -0.2303598\n",
      "  0.10446824 -0.36779703]\n",
      "New theta_0 : [ 0.00056729 -0.09535289  0.09429198  0.03613994  0.05752822 -0.25794024\n",
      "  0.3454421   0.00234394 -0.32862802  0.27793582 -0.21120242 -0.23036066\n",
      "  0.1044683  -0.36779842]\n",
      "Training Error:  10.493297379494946\n",
      "====================================================================================================\n",
      "Iteration:  1147\n",
      "Previous theta :  [ 0.00056729 -0.09535289  0.09429198  0.03613994  0.05752822 -0.25794024\n",
      "  0.3454421   0.00234394 -0.32862802  0.27793582 -0.21120242 -0.23036066\n",
      "  0.1044683  -0.36779842]\n",
      "New theta_0 : [ 0.00056719 -0.09535531  0.09429801  0.03615117  0.05752682 -0.25794645\n",
      "  0.34543963  0.00234561 -0.32863247  0.27796297 -0.2112323  -0.23036151\n",
      "  0.10446836 -0.36779982]\n",
      "Training Error:  10.493295635258544\n",
      "====================================================================================================\n",
      "Iteration:  1148\n",
      "Previous theta :  [ 0.00056719 -0.09535531  0.09429801  0.03615117  0.05752682 -0.25794645\n",
      "  0.34543963  0.00234561 -0.32863247  0.27796297 -0.2112323  -0.23036151\n",
      "  0.10446836 -0.36779982]\n",
      "New theta_0 : [ 0.00056709 -0.09535772  0.09430402  0.03616238  0.05752542 -0.25795263\n",
      "  0.34543717  0.00234729 -0.3286369   0.27799005 -0.2112621  -0.23036236\n",
      "  0.10446842 -0.36780121]\n",
      "Training Error:  10.493293900592617\n",
      "====================================================================================================\n",
      "Iteration:  1149\n",
      "Previous theta :  [ 0.00056709 -0.09535772  0.09430402  0.03616238  0.05752542 -0.25795263\n",
      "  0.34543717  0.00234729 -0.3286369   0.27799005 -0.2112621  -0.23036236\n",
      "  0.10446842 -0.36780121]\n",
      "New theta_0 : [ 0.00056699 -0.09536013  0.09431001  0.03617355  0.05752402 -0.25795878\n",
      "  0.34543472  0.00234896 -0.3286413   0.27801705 -0.21129182 -0.23036321\n",
      "  0.10446849 -0.3678026 ]\n",
      "Training Error:  10.493292175443221\n",
      "====================================================================================================\n",
      "Iteration:  1150\n",
      "Previous theta :  [ 0.00056699 -0.09536013  0.09431001  0.03617355  0.05752402 -0.25795878\n",
      "  0.34543472  0.00234896 -0.3286413   0.27801705 -0.21129182 -0.23036321\n",
      "  0.10446849 -0.3678026 ]\n",
      "New theta_0 : [ 0.00056688 -0.09536253  0.09431598  0.03618469  0.05752263 -0.2579649\n",
      "  0.34543227  0.00235062 -0.32864568  0.27804398 -0.21132146 -0.23036406\n",
      "  0.10446855 -0.36780398]\n",
      "Training Error:  10.49329045975675\n",
      "====================================================================================================\n",
      "Iteration:  1151\n",
      "Previous theta :  [ 0.00056688 -0.09536253  0.09431598  0.03618469  0.05752263 -0.2579649\n",
      "  0.34543227  0.00235062 -0.32864568  0.27804398 -0.21132146 -0.23036406\n",
      "  0.10446855 -0.36780398]\n",
      "New theta_0 : [ 0.00056678 -0.09536492  0.09432193  0.0361958   0.05752124 -0.257971\n",
      "  0.34542984  0.00235228 -0.32865003  0.27807083 -0.21135103 -0.2303649\n",
      "  0.10446861 -0.36780536]\n",
      "Training Error:  10.493288753479904\n",
      "====================================================================================================\n",
      "Iteration:  1152\n",
      "Previous theta :  [ 0.00056678 -0.09536492  0.09432193  0.0361958   0.05752124 -0.257971\n",
      "  0.34542984  0.00235228 -0.32865003  0.27807083 -0.21135103 -0.2303649\n",
      "  0.10446861 -0.36780536]\n",
      "New theta_0 : [ 0.00056669 -0.0953673   0.09432787  0.03620689  0.05751985 -0.25797706\n",
      "  0.34542741  0.00235394 -0.32865435  0.27809761 -0.21138052 -0.23036574\n",
      "  0.10446868 -0.36780674]\n",
      "Training Error:  10.493287056559716\n",
      "====================================================================================================\n",
      "Iteration:  1153\n",
      "Previous theta :  [ 0.00056669 -0.0953673   0.09432787  0.03620689  0.05751985 -0.25797706\n",
      "  0.34542741  0.00235394 -0.32865435  0.27809761 -0.21138052 -0.23036574\n",
      "  0.10446868 -0.36780674]\n",
      "New theta_0 : [ 0.00056659 -0.09536967  0.09433378  0.03621794  0.05751847 -0.2579831\n",
      "  0.34542499  0.00235559 -0.32865865  0.27812432 -0.21140993 -0.23036658\n",
      "  0.10446874 -0.36780811]\n",
      "Training Error:  10.49328536894353\n",
      "====================================================================================================\n",
      "Iteration:  1154\n",
      "Previous theta :  [ 0.00056659 -0.09536967  0.09433378  0.03621794  0.05751847 -0.2579831\n",
      "  0.34542499  0.00235559 -0.32865865  0.27812432 -0.21140993 -0.23036658\n",
      "  0.10446874 -0.36780811]\n",
      "New theta_0 : [ 0.00056649 -0.09537204  0.09433967  0.03622897  0.05751709 -0.25798911\n",
      "  0.34542258  0.00235724 -0.32866293  0.27815095 -0.21143927 -0.23036741\n",
      "  0.10446881 -0.36780948]\n",
      "Training Error:  10.493283690579005\n",
      "====================================================================================================\n",
      "Iteration:  1155\n",
      "Previous theta :  [ 0.00056649 -0.09537204  0.09433967  0.03622897  0.05751709 -0.25798911\n",
      "  0.34542258  0.00235724 -0.32866293  0.27815095 -0.21143927 -0.23036741\n",
      "  0.10446881 -0.36780948]\n",
      "New theta_0 : [ 0.00056639 -0.09537439  0.09434555  0.03623996  0.05751571 -0.25799509\n",
      "  0.34542018  0.00235889 -0.32866718  0.27817752 -0.21146853 -0.23036824\n",
      "  0.10446887 -0.36781085]\n",
      "Training Error:  10.49328202141411\n",
      "====================================================================================================\n",
      "Iteration:  1156\n",
      "Previous theta :  [ 0.00056639 -0.09537439  0.09434555  0.03623996  0.05751571 -0.25799509\n",
      "  0.34542018  0.00235889 -0.32866718  0.27817752 -0.21146853 -0.23036824\n",
      "  0.10446887 -0.36781085]\n",
      "New theta_0 : [ 0.00056629 -0.09537674  0.0943514   0.03625093  0.05751434 -0.25800104\n",
      "  0.34541779  0.00236053 -0.32867141  0.27820401 -0.21149771 -0.23036907\n",
      "  0.10446894 -0.36781221]\n",
      "Training Error:  10.493280361397131\n",
      "====================================================================================================\n",
      "Iteration:  1157\n",
      "Previous theta :  [ 0.00056629 -0.09537674  0.0943514   0.03625093  0.05751434 -0.25800104\n",
      "  0.34541779  0.00236053 -0.32867141  0.27820401 -0.21149771 -0.23036907\n",
      "  0.10446894 -0.36781221]\n",
      "New theta_0 : [ 0.0005662  -0.09537909  0.09435723  0.03626187  0.05751297 -0.25800697\n",
      "  0.3454154   0.00236217 -0.32867562  0.27823042 -0.21152682 -0.23036989\n",
      "  0.104469   -0.36781357]\n",
      "Training Error:  10.493278710476657\n",
      "====================================================================================================\n",
      "Iteration:  1158\n",
      "Previous theta :  [ 0.0005662  -0.09537909  0.09435723  0.03626187  0.05751297 -0.25800697\n",
      "  0.3454154   0.00236217 -0.32867562  0.27823042 -0.21152682 -0.23036989\n",
      "  0.104469   -0.36781357]\n",
      "New theta_0 : [ 0.0005661  -0.09538142  0.09436305  0.03627277  0.0575116  -0.25801286\n",
      "  0.34541303  0.0023638  -0.3286798   0.27825677 -0.21155586 -0.23037071\n",
      "  0.10446907 -0.36781493]\n",
      "Training Error:  10.493277068601587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  1159\n",
      "Previous theta :  [ 0.0005661  -0.09538142  0.09436305  0.03627277  0.0575116  -0.25801286\n",
      "  0.34541303  0.0023638  -0.3286798   0.27825677 -0.21155586 -0.23037071\n",
      "  0.10446907 -0.36781493]\n",
      "New theta_0 : [ 0.00056601 -0.09538375  0.09436884  0.03628365  0.05751024 -0.25801873\n",
      "  0.34541066  0.00236543 -0.32868395  0.27828304 -0.21158482 -0.23037152\n",
      "  0.10446914 -0.36781628]\n",
      "Training Error:  10.493275435721122\n",
      "====================================================================================================\n",
      "Iteration:  1160\n",
      "Previous theta :  [ 0.00056601 -0.09538375  0.09436884  0.03628365  0.05751024 -0.25801873\n",
      "  0.34541066  0.00236543 -0.32868395  0.27828304 -0.21158482 -0.23037152\n",
      "  0.10446914 -0.36781628]\n",
      "New theta_0 : [ 0.00056591 -0.09538607  0.09437462  0.03629451  0.05750888 -0.25802458\n",
      "  0.3454083   0.00236706 -0.32868809  0.27830924 -0.2116137  -0.23037234\n",
      "  0.10446921 -0.36781763]\n",
      "Training Error:  10.493273811784766\n",
      "====================================================================================================\n",
      "Iteration:  1161\n",
      "Previous theta :  [ 0.00056591 -0.09538607  0.09437462  0.03629451  0.05750888 -0.25802458\n",
      "  0.3454083   0.00236706 -0.32868809  0.27830924 -0.2116137  -0.23037234\n",
      "  0.10446921 -0.36781763]\n",
      "New theta_0 : [ 0.00056582 -0.09538838  0.09438038  0.03630533  0.05750753 -0.25803039\n",
      "  0.34540595  0.00236869 -0.3286922   0.27833537 -0.21164251 -0.23037315\n",
      "  0.10446928 -0.36781898]\n",
      "Training Error:  10.493272196742323\n",
      "====================================================================================================\n",
      "Iteration:  1162\n",
      "Previous theta :  [ 0.00056582 -0.09538838  0.09438038  0.03630533  0.05750753 -0.25803039\n",
      "  0.34540595  0.00236869 -0.3286922   0.27833537 -0.21164251 -0.23037315\n",
      "  0.10446928 -0.36781898]\n",
      "New theta_0 : [ 0.00056572 -0.09539068  0.09438611  0.03631612  0.05750617 -0.25803618\n",
      "  0.3454036   0.00237031 -0.32869628  0.27836143 -0.21167124 -0.23037396\n",
      "  0.10446935 -0.36782032]\n",
      "Training Error:  10.493270590543897\n",
      "====================================================================================================\n",
      "Iteration:  1163\n",
      "Previous theta :  [ 0.00056572 -0.09539068  0.09438611  0.03631612  0.05750617 -0.25803618\n",
      "  0.3454036   0.00237031 -0.32869628  0.27836143 -0.21167124 -0.23037396\n",
      "  0.10446935 -0.36782032]\n",
      "New theta_0 : [ 0.00056563 -0.09539298  0.09439183  0.03632689  0.05750482 -0.25804194\n",
      "  0.34540127  0.00237192 -0.32870035  0.27838742 -0.2116999  -0.23037476\n",
      "  0.10446942 -0.36782166]\n",
      "Training Error:  10.493268993139887\n",
      "====================================================================================================\n",
      "Iteration:  1164\n",
      "Previous theta :  [ 0.00056563 -0.09539298  0.09439183  0.03632689  0.05750482 -0.25804194\n",
      "  0.34540127  0.00237192 -0.32870035  0.27838742 -0.2116999  -0.23037476\n",
      "  0.10446942 -0.36782166]\n",
      "New theta_0 : [ 0.00056554 -0.09539527  0.09439753  0.03633762  0.05750348 -0.25804768\n",
      "  0.34539894  0.00237353 -0.32870439  0.27841334 -0.21172848 -0.23037556\n",
      "  0.10446949 -0.367823  ]\n",
      "Training Error:  10.493267404480987\n",
      "====================================================================================================\n",
      "Iteration:  1165\n",
      "Previous theta :  [ 0.00056554 -0.09539527  0.09439753  0.03633762  0.05750348 -0.25804768\n",
      "  0.34539894  0.00237353 -0.32870439  0.27841334 -0.21172848 -0.23037556\n",
      "  0.10446949 -0.367823  ]\n",
      "New theta_0 : [ 0.00056544 -0.09539755  0.09440322  0.03634833  0.05750213 -0.25805339\n",
      "  0.34539662  0.00237514 -0.3287084   0.27843919 -0.21175699 -0.23037636\n",
      "  0.10446956 -0.36782433]\n",
      "Training Error:  10.49326582451818\n",
      "====================================================================================================\n",
      "Iteration:  1166\n",
      "Previous theta :  [ 0.00056544 -0.09539755  0.09440322  0.03634833  0.05750213 -0.25805339\n",
      "  0.34539662  0.00237514 -0.3287084   0.27843919 -0.21175699 -0.23037636\n",
      "  0.10446956 -0.36782433]\n",
      "New theta_0 : [ 0.00056535 -0.09539982  0.09440888  0.03635901  0.05750079 -0.25805907\n",
      "  0.34539431  0.00237675 -0.3287124   0.27846496 -0.21178542 -0.23037715\n",
      "  0.10446963 -0.36782566]\n",
      "Training Error:  10.493264253202742\n",
      "====================================================================================================\n",
      "Iteration:  1167\n",
      "Previous theta :  [ 0.00056535 -0.09539982  0.09440888  0.03635901  0.05750079 -0.25805907\n",
      "  0.34539431  0.00237675 -0.3287124   0.27846496 -0.21178542 -0.23037715\n",
      "  0.10446963 -0.36782566]\n",
      "New theta_0 : [ 0.00056526 -0.09540209  0.09441452  0.03636967  0.05749946 -0.25806472\n",
      "  0.345392    0.00237835 -0.32871637  0.27849067 -0.21181379 -0.23037795\n",
      "  0.1044697  -0.36782699]\n",
      "Training Error:  10.493262690486242\n",
      "====================================================================================================\n",
      "Iteration:  1168\n",
      "Previous theta :  [ 0.00056526 -0.09540209  0.09441452  0.03636967  0.05749946 -0.25806472\n",
      "  0.345392    0.00237835 -0.32871637  0.27849067 -0.21181379 -0.23037795\n",
      "  0.1044697  -0.36782699]\n",
      "New theta_0 : [ 0.00056517 -0.09540434  0.09442015  0.03638029  0.05749812 -0.25807035\n",
      "  0.34538971  0.00237995 -0.32872032  0.2785163  -0.21184207 -0.23037874\n",
      "  0.10446977 -0.36782831]\n",
      "Training Error:  10.493261136320529\n",
      "====================================================================================================\n",
      "Iteration:  1169\n",
      "Previous theta :  [ 0.00056517 -0.09540434  0.09442015  0.03638029  0.05749812 -0.25807035\n",
      "  0.34538971  0.00237995 -0.32872032  0.2785163  -0.21184207 -0.23037874\n",
      "  0.10446977 -0.36782831]\n",
      "New theta_0 : [ 0.00056508 -0.0954066   0.09442575  0.03639088  0.05749679 -0.25807596\n",
      "  0.34538742  0.00238154 -0.32872425  0.27854187 -0.21187029 -0.23037952\n",
      "  0.10446985 -0.36782963]\n",
      "Training Error:  10.493259590657734\n",
      "====================================================================================================\n",
      "Iteration:  1170\n",
      "Previous theta :  [ 0.00056508 -0.0954066   0.09442575  0.03639088  0.05749679 -0.25807596\n",
      "  0.34538742  0.00238154 -0.32872425  0.27854187 -0.21187029 -0.23037952\n",
      "  0.10446985 -0.36782963]\n",
      "New theta_0 : [ 0.00056499 -0.09540884  0.09443134  0.03640145  0.05749547 -0.25808153\n",
      "  0.34538514  0.00238314 -0.32872815  0.27856736 -0.21189843 -0.2303803\n",
      "  0.10446992 -0.36783095]\n",
      "Training Error:  10.493258053450283\n",
      "====================================================================================================\n",
      "Iteration:  1171\n",
      "Previous theta :  [ 0.00056499 -0.09540884  0.09443134  0.03640145  0.05749547 -0.25808153\n",
      "  0.34538514  0.00238314 -0.32872815  0.27856736 -0.21189843 -0.2303803\n",
      "  0.10446992 -0.36783095]\n",
      "New theta_0 : [ 0.0005649  -0.09541107  0.09443691  0.03641199  0.05749414 -0.25808709\n",
      "  0.34538287  0.00238472 -0.32873204  0.27859279 -0.21192649 -0.23038108\n",
      "  0.10446999 -0.36783226]\n",
      "Training Error:  10.49325652465087\n",
      "====================================================================================================\n",
      "Iteration:  1172\n",
      "Previous theta :  [ 0.0005649  -0.09541107  0.09443691  0.03641199  0.05749414 -0.25808709\n",
      "  0.34538287  0.00238472 -0.32873204  0.27859279 -0.21192649 -0.23038108\n",
      "  0.10446999 -0.36783226]\n",
      "New theta_0 : [ 0.00056481 -0.0954133   0.09444247  0.0364225   0.05749282 -0.25809261\n",
      "  0.34538061  0.00238631 -0.3287359   0.27861815 -0.21195449 -0.23038186\n",
      "  0.10447007 -0.36783357]\n",
      "Training Error:  10.493255004212479\n",
      "====================================================================================================\n",
      "Iteration:  1173\n",
      "Previous theta :  [ 0.00056481 -0.0954133   0.09444247  0.0364225   0.05749282 -0.25809261\n",
      "  0.34538061  0.00238631 -0.3287359   0.27861815 -0.21195449 -0.23038186\n",
      "  0.10447007 -0.36783357]\n",
      "New theta_0 : [ 0.00056473 -0.09541552  0.094448    0.03643299  0.05749151 -0.25809812\n",
      "  0.34537835  0.00238789 -0.32873974  0.27864343 -0.21198241 -0.23038263\n",
      "  0.10447014 -0.36783488]\n",
      "Training Error:  10.493253492088359\n",
      "====================================================================================================\n",
      "Iteration:  1174\n",
      "Previous theta :  [ 0.00056473 -0.09541552  0.094448    0.03643299  0.05749151 -0.25809812\n",
      "  0.34537835  0.00238789 -0.32873974  0.27864343 -0.21198241 -0.23038263\n",
      "  0.10447014 -0.36783488]\n",
      "New theta_0 : [ 0.00056464 -0.09541774  0.09445351  0.03644344  0.05749019 -0.25810359\n",
      "  0.3453761   0.00238946 -0.32874356  0.27866865 -0.21201026 -0.23038341\n",
      "  0.10447022 -0.36783619]\n",
      "Training Error:  10.493251988232045\n",
      "====================================================================================================\n",
      "Iteration:  1175\n",
      "Previous theta :  [ 0.00056464 -0.09541774  0.09445351  0.03644344  0.05749019 -0.25810359\n",
      "  0.3453761   0.00238946 -0.32874356  0.27866865 -0.21201026 -0.23038341\n",
      "  0.10447022 -0.36783619]\n",
      "New theta_0 : [ 0.00056455 -0.09541995  0.09445901  0.03645387  0.05748888 -0.25810904\n",
      "  0.34537386  0.00239104 -0.32874736  0.2786938  -0.21203803 -0.23038417\n",
      "  0.10447029 -0.36783749]\n",
      "Training Error:  10.49325049259734\n",
      "====================================================================================================\n",
      "Iteration:  1176\n",
      "Previous theta :  [ 0.00056455 -0.09541995  0.09445901  0.03645387  0.05748888 -0.25810904\n",
      "  0.34537386  0.00239104 -0.32874736  0.2786938  -0.21203803 -0.23038417\n",
      "  0.10447029 -0.36783749]\n",
      "New theta_0 : [ 0.00056446 -0.09542215  0.09446449  0.03646427  0.05748758 -0.25811447\n",
      "  0.34537163  0.00239261 -0.32875113  0.27871888 -0.21206573 -0.23038494\n",
      "  0.10447037 -0.36783878]\n",
      "Training Error:  10.49324900513832\n",
      "====================================================================================================\n",
      "Iteration:  1177\n",
      "Previous theta :  [ 0.00056446 -0.09542215  0.09446449  0.03646427  0.05748758 -0.25811447\n",
      "  0.34537163  0.00239261 -0.32875113  0.27871888 -0.21206573 -0.23038494\n",
      "  0.10447037 -0.36783878]\n",
      "New theta_0 : [ 0.00056438 -0.09542434  0.09446995  0.03647465  0.05748627 -0.25811987\n",
      "  0.3453694   0.00239417 -0.32875489  0.2787439  -0.21209336 -0.2303857\n",
      "  0.10447044 -0.36784008]\n",
      "Training Error:  10.493247525809334\n",
      "====================================================================================================\n",
      "Iteration:  1178\n",
      "Previous theta :  [ 0.00056438 -0.09542434  0.09446995  0.03647465  0.05748627 -0.25811987\n",
      "  0.3453694   0.00239417 -0.32875489  0.2787439  -0.21209336 -0.2303857\n",
      "  0.10447044 -0.36784008]\n",
      "New theta_0 : [ 0.00056429 -0.09542652  0.0944754   0.03648499  0.05748497 -0.25812525\n",
      "  0.34536718  0.00239573 -0.32875862  0.27876884 -0.21212092 -0.23038646\n",
      "  0.10447052 -0.36784137]\n",
      "Training Error:  10.493246054564993\n",
      "====================================================================================================\n",
      "Iteration:  1179\n",
      "Previous theta :  [ 0.00056429 -0.09542652  0.0944754   0.03648499  0.05748497 -0.25812525\n",
      "  0.34536718  0.00239573 -0.32875862  0.27876884 -0.21212092 -0.23038646\n",
      "  0.10447052 -0.36784137]\n",
      "New theta_0 : [ 0.00056421 -0.0954287   0.09448082  0.03649531  0.05748367 -0.2581306\n",
      "  0.34536497  0.00239729 -0.32876233  0.27879372 -0.21214841 -0.23038722\n",
      "  0.1044706  -0.36784266]\n",
      "Training Error:  10.493244591360181\n",
      "====================================================================================================\n",
      "Iteration:  1180\n",
      "Previous theta :  [ 0.00056421 -0.0954287   0.09448082  0.03649531  0.05748367 -0.2581306\n",
      "  0.34536497  0.00239729 -0.32876233  0.27879372 -0.21214841 -0.23038722\n",
      "  0.1044706  -0.36784266]\n",
      "New theta_0 : [ 0.00056412 -0.09543087  0.09448623  0.0365056   0.05748238 -0.25813593\n",
      "  0.34536277  0.00239885 -0.32876602  0.27881853 -0.21217583 -0.23038797\n",
      "  0.10447067 -0.36784394]\n",
      "Training Error:  10.49324313615004\n",
      "====================================================================================================\n",
      "Iteration:  1181\n",
      "Previous theta :  [ 0.00056412 -0.09543087  0.09448623  0.0365056   0.05748238 -0.25813593\n",
      "  0.34536277  0.00239885 -0.32876602  0.27881853 -0.21217583 -0.23038797\n",
      "  0.10447067 -0.36784394]\n",
      "New theta_0 : [ 0.00056404 -0.09543304  0.09449162  0.03651586  0.05748109 -0.25814123\n",
      "  0.34536058  0.0024004  -0.3287697   0.27884327 -0.21220317 -0.23038872\n",
      "  0.10447075 -0.36784522]\n",
      "Training Error:  10.493241688889983\n",
      "====================================================================================================\n",
      "Iteration:  1182\n",
      "Previous theta :  [ 0.00056404 -0.09543304  0.09449162  0.03651586  0.05748109 -0.25814123\n",
      "  0.34536058  0.0024004  -0.3287697   0.27884327 -0.21220317 -0.23038872\n",
      "  0.10447075 -0.36784522]\n",
      "New theta_0 : [ 0.00056396 -0.09543519  0.09449699  0.0365261   0.0574798  -0.25814651\n",
      "  0.34535839  0.00240195 -0.32877335  0.27886794 -0.21223044 -0.23038947\n",
      "  0.10447083 -0.3678465 ]\n",
      "Training Error:  10.493240249535674\n",
      "====================================================================================================\n",
      "Iteration:  1183\n",
      "Previous theta :  [ 0.00056396 -0.09543519  0.09449699  0.0365261   0.0574798  -0.25814651\n",
      "  0.34535839  0.00240195 -0.32877335  0.27886794 -0.21223044 -0.23038947\n",
      "  0.10447083 -0.3678465 ]\n",
      "New theta_0 : [ 0.00056387 -0.09543734  0.09450235  0.03653631  0.05747851 -0.25815177\n",
      "  0.34535621  0.00240349 -0.32877698  0.27889255 -0.21225764 -0.23039021\n",
      "  0.10447091 -0.36784778]\n",
      "Training Error:  10.493238818043048\n",
      "====================================================================================================\n",
      "Iteration:  1184\n",
      "Previous theta :  [ 0.00056387 -0.09543734  0.09450235  0.03653631  0.05747851 -0.25815177\n",
      "  0.34535621  0.00240349 -0.32877698  0.27889255 -0.21225764 -0.23039021\n",
      "  0.10447091 -0.36784778]\n",
      "New theta_0 : [ 0.00056379 -0.09543948  0.09450769  0.03654649  0.05747723 -0.258157\n",
      "  0.34535404  0.00240503 -0.32878059  0.27891709 -0.21228477 -0.23039096\n",
      "  0.10447099 -0.36784905]\n",
      "Training Error:  10.49323739436829\n",
      "====================================================================================================\n",
      "Iteration:  1185\n",
      "Previous theta :  [ 0.00056379 -0.09543948  0.09450769  0.03654649  0.05747723 -0.258157\n",
      "  0.34535404  0.00240503 -0.32878059  0.27891709 -0.21228477 -0.23039096\n",
      "  0.10447099 -0.36784905]\n",
      "New theta_0 : [ 0.00056371 -0.09544162  0.09451301  0.03655665  0.05747595 -0.25816221\n",
      "  0.34535187  0.00240657 -0.32878418  0.27894156 -0.21231183 -0.2303917\n",
      "  0.10447107 -0.36785032]\n",
      "Training Error:  10.493235978467842\n",
      "====================================================================================================\n",
      "Iteration:  1186\n",
      "Previous theta :  [ 0.00056371 -0.09544162  0.09451301  0.03655665  0.05747595 -0.25816221\n",
      "  0.34535187  0.00240657 -0.32878418  0.27894156 -0.21231183 -0.2303917\n",
      "  0.10447107 -0.36785032]\n",
      "New theta_0 : [ 0.00056363 -0.09544375  0.09451831  0.03656677  0.05747468 -0.25816739\n",
      "  0.34534971  0.0024081  -0.32878775  0.27896597 -0.21233882 -0.23039243\n",
      "  0.10447115 -0.36785158]\n",
      "Training Error:  10.493234570298405\n",
      "====================================================================================================\n",
      "Iteration:  1187\n",
      "Previous theta :  [ 0.00056363 -0.09544375  0.09451831  0.03656677  0.05747468 -0.25816739\n",
      "  0.34534971  0.0024081  -0.32878775  0.27896597 -0.21233882 -0.23039243\n",
      "  0.10447115 -0.36785158]\n",
      "New theta_0 : [ 0.00056354 -0.09544587  0.0945236   0.03657688  0.05747341 -0.25817255\n",
      "  0.34534756  0.00240963 -0.3287913   0.27899031 -0.21236574 -0.23039317\n",
      "  0.10447123 -0.36785285]\n",
      "Training Error:  10.493233169816927\n",
      "====================================================================================================\n",
      "Iteration:  1188\n",
      "Previous theta :  [ 0.00056354 -0.09544587  0.0945236   0.03657688  0.05747341 -0.25817255\n",
      "  0.34534756  0.00240963 -0.3287913   0.27899031 -0.21236574 -0.23039317\n",
      "  0.10447123 -0.36785285]\n",
      "New theta_0 : [ 0.00056346 -0.09544798  0.09452887  0.03658695  0.05747214 -0.25817769\n",
      "  0.34534542  0.00241116 -0.32879483  0.27901458 -0.21239259 -0.2303939\n",
      "  0.10447131 -0.3678541 ]\n",
      "Training Error:  10.493231776980613\n",
      "====================================================================================================\n",
      "Iteration:  1189\n",
      "Previous theta :  [ 0.00056346 -0.09544798  0.09452887  0.03658695  0.05747214 -0.25817769\n",
      "  0.34534542  0.00241116 -0.32879483  0.27901458 -0.21239259 -0.2303939\n",
      "  0.10447131 -0.3678541 ]\n",
      "New theta_0 : [ 0.00056338 -0.09545009  0.09453412  0.036597    0.05747087 -0.25818281\n",
      "  0.34534328  0.00241268 -0.32879834  0.27903879 -0.21241937 -0.23039463\n",
      "  0.10447139 -0.36785536]\n",
      "Training Error:  10.493230391746913\n",
      "====================================================================================================\n",
      "Iteration:  1190\n",
      "Previous theta :  [ 0.00056338 -0.09545009  0.09453412  0.036597    0.05747087 -0.25818281\n",
      "  0.34534328  0.00241268 -0.32879834  0.27903879 -0.21241937 -0.23039463\n",
      "  0.10447139 -0.36785536]\n",
      "New theta_0 : [ 0.0005633  -0.09545219  0.09453935  0.03660702  0.05746961 -0.2581879\n",
      "  0.34534115  0.0024142  -0.32880183  0.27906293 -0.21244607 -0.23039535\n",
      "  0.10447147 -0.36785661]\n",
      "Training Error:  10.493229014073524\n",
      "====================================================================================================\n",
      "Iteration:  1191\n",
      "Previous theta :  [ 0.0005633  -0.09545219  0.09453935  0.03660702  0.05746961 -0.2581879\n",
      "  0.34534115  0.0024142  -0.32880183  0.27906293 -0.21244607 -0.23039535\n",
      "  0.10447147 -0.36785661]\n",
      "New theta_0 : [ 0.00056322 -0.09545429  0.09454457  0.03661701  0.05746835 -0.25819297\n",
      "  0.34533903  0.00241572 -0.3288053   0.279087   -0.21247271 -0.23039607\n",
      "  0.10447155 -0.36785786]\n",
      "Training Error:  10.493227643918399\n",
      "====================================================================================================\n",
      "Iteration:  1192\n",
      "Previous theta :  [ 0.00056322 -0.09545429  0.09454457  0.03661701  0.05746835 -0.25819297\n",
      "  0.34533903  0.00241572 -0.3288053   0.279087   -0.21247271 -0.23039607\n",
      "  0.10447155 -0.36785786]\n",
      "New theta_0 : [ 0.00056315 -0.09545638  0.09454977  0.03662698  0.05746709 -0.25819801\n",
      "  0.34533692  0.00241723 -0.32880876  0.27911101 -0.21249928 -0.23039679\n",
      "  0.10447163 -0.36785911]\n",
      "Training Error:  10.493226281239723\n",
      "====================================================================================================\n",
      "Iteration:  1193\n",
      "Previous theta :  [ 0.00056315 -0.09545638  0.09454977  0.03662698  0.05746709 -0.25819801\n",
      "  0.34533692  0.00241723 -0.32880876  0.27911101 -0.21249928 -0.23039679\n",
      "  0.10447163 -0.36785911]\n",
      "New theta_0 : [ 0.00056307 -0.09545846  0.09455495  0.03663692  0.05746584 -0.25820303\n",
      "  0.34533481  0.00241874 -0.32881219  0.27913496 -0.21252578 -0.23039751\n",
      "  0.10447171 -0.36786035]\n",
      "Training Error:  10.493224925995934\n",
      "====================================================================================================\n",
      "Iteration:  1194\n",
      "Previous theta :  [ 0.00056307 -0.09545846  0.09455495  0.03663692  0.05746584 -0.25820303\n",
      "  0.34533481  0.00241874 -0.32881219  0.27913496 -0.21252578 -0.23039751\n",
      "  0.10447171 -0.36786035]\n",
      "New theta_0 : [ 0.00056299 -0.09546053  0.09456012  0.03664684  0.05746459 -0.25820804\n",
      "  0.34533271  0.00242025 -0.32881561  0.27915884 -0.21255221 -0.23039823\n",
      "  0.10447179 -0.3678616 ]\n",
      "Training Error:  10.493223578145704\n",
      "====================================================================================================\n",
      "Iteration:  1195\n",
      "Previous theta :  [ 0.00056299 -0.09546053  0.09456012  0.03664684  0.05746459 -0.25820804\n",
      "  0.34533271  0.00242025 -0.32881561  0.27915884 -0.21255221 -0.23039823\n",
      "  0.10447179 -0.3678616 ]\n",
      "New theta_0 : [ 0.00056291 -0.0954626   0.09456527  0.03665673  0.05746334 -0.25821301\n",
      "  0.34533062  0.00242175 -0.328819    0.27918265 -0.21257857 -0.23039894\n",
      "  0.10447188 -0.36786283]\n",
      "Training Error:  10.493222237647954\n",
      "====================================================================================================\n",
      "Iteration:  1196\n",
      "Previous theta :  [ 0.00056291 -0.0954626   0.09456527  0.03665673  0.05746334 -0.25821301\n",
      "  0.34533062  0.00242175 -0.328819    0.27918265 -0.21257857 -0.23039894\n",
      "  0.10447188 -0.36786283]\n",
      "New theta_0 : [ 0.00056283 -0.09546466  0.09457041  0.03666659  0.0574621  -0.25821797\n",
      "  0.34532853  0.00242325 -0.32882238  0.2792064  -0.21260486 -0.23039965\n",
      "  0.10447196 -0.36786407]\n",
      "Training Error:  10.493220904461834\n",
      "====================================================================================================\n",
      "Iteration:  1197\n",
      "Previous theta :  [ 0.00056283 -0.09546466  0.09457041  0.03666659  0.0574621  -0.25821797\n",
      "  0.34532853  0.00242325 -0.32882238  0.2792064  -0.21260486 -0.23039965\n",
      "  0.10447196 -0.36786407]\n",
      "New theta_0 : [ 0.00056276 -0.09546671  0.09457552  0.03667643  0.05746085 -0.2582229\n",
      "  0.34532645  0.00242474 -0.32882574  0.27923009 -0.21263109 -0.23040035\n",
      "  0.10447204 -0.3678653 ]\n",
      "Training Error:  10.493219578546741\n",
      "====================================================================================================\n",
      "Iteration:  1198\n",
      "Previous theta :  [ 0.00056276 -0.09546671  0.09457552  0.03667643  0.05746085 -0.2582229\n",
      "  0.34532645  0.00242474 -0.32882574  0.27923009 -0.21263109 -0.23040035\n",
      "  0.10447204 -0.3678653 ]\n",
      "New theta_0 : [ 0.00056268 -0.09546876  0.09458062  0.03668624  0.05745962 -0.25822782\n",
      "  0.34532438  0.00242624 -0.32882908  0.2792537  -0.21265724 -0.23040106\n",
      "  0.10447213 -0.36786653]\n",
      "Training Error:  10.493218259862298\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1199\n",
      "Previous theta :  [ 0.00056268 -0.09546876  0.09458062  0.03668624  0.05745962 -0.25822782\n",
      "  0.34532438  0.00242624 -0.32882908  0.2792537  -0.21265724 -0.23040106\n",
      "  0.10447213 -0.36786653]\n",
      "New theta_0 : [ 0.00056261 -0.0954708   0.09458571  0.03669602  0.05745838 -0.25823271\n",
      "  0.34532232  0.00242772 -0.3288324   0.27927726 -0.21268333 -0.23040176\n",
      "  0.10447221 -0.36786775]\n",
      "Training Error:  10.493216948368369\n",
      "====================================================================================================\n",
      "Iteration:  1200\n",
      "Previous theta :  [ 0.00056261 -0.0954708   0.09458571  0.03669602  0.05745838 -0.25823271\n",
      "  0.34532232  0.00242772 -0.3288324   0.27927726 -0.21268333 -0.23040176\n",
      "  0.10447221 -0.36786775]\n",
      "New theta_0 : [ 0.00056253 -0.09547283  0.09459078  0.03670578  0.05745715 -0.25823757\n",
      "  0.34532026  0.00242921 -0.32883571  0.27930075 -0.21270934 -0.23040246\n",
      "  0.10447229 -0.36786898]\n",
      "Training Error:  10.493215644025046\n",
      "====================================================================================================\n",
      "Iteration:  1201\n",
      "Previous theta :  [ 0.00056253 -0.09547283  0.09459078  0.03670578  0.05745715 -0.25823757\n",
      "  0.34532026  0.00242921 -0.32883571  0.27930075 -0.21270934 -0.23040246\n",
      "  0.10447229 -0.36786898]\n",
      "New theta_0 : [ 0.00056245 -0.09547486  0.09459583  0.03671551  0.05745592 -0.25824242\n",
      "  0.34531821  0.00243069 -0.32883899  0.27932418 -0.21273529 -0.23040315\n",
      "  0.10447238 -0.3678702 ]\n",
      "Training Error:  10.493214346792657\n",
      "====================================================================================================\n",
      "Iteration:  1202\n",
      "Previous theta :  [ 0.00056245 -0.09547486  0.09459583  0.03671551  0.05745592 -0.25824242\n",
      "  0.34531821  0.00243069 -0.32883899  0.27932418 -0.21273529 -0.23040315\n",
      "  0.10447238 -0.3678702 ]\n",
      "New theta_0 : [ 0.00056238 -0.09547688  0.09460086  0.03672522  0.05745469 -0.25824724\n",
      "  0.34531616  0.00243217 -0.32884226  0.27934754 -0.21276118 -0.23040385\n",
      "  0.10447246 -0.36787141]\n",
      "Training Error:  10.493213056631753\n",
      "====================================================================================================\n",
      "Iteration:  1203\n",
      "Previous theta :  [ 0.00056238 -0.09547688  0.09460086  0.03672522  0.05745469 -0.25824724\n",
      "  0.34531616  0.00243217 -0.32884226  0.27934754 -0.21276118 -0.23040385\n",
      "  0.10447246 -0.36787141]\n",
      "New theta_0 : [ 0.00056231 -0.0954789   0.09460588  0.0367349   0.05745347 -0.25825205\n",
      "  0.34531413  0.00243364 -0.32884551  0.27937084 -0.21278699 -0.23040454\n",
      "  0.10447255 -0.36787263]\n",
      "Training Error:  10.49321177350312\n",
      "====================================================================================================\n",
      "Iteration:  1204\n",
      "Previous theta :  [ 0.00056231 -0.0954789   0.09460588  0.0367349   0.05745347 -0.25825205\n",
      "  0.34531413  0.00243364 -0.32884551  0.27937084 -0.21278699 -0.23040454\n",
      "  0.10447255 -0.36787263]\n",
      "New theta_0 : [ 0.00056223 -0.0954809   0.09461089  0.03674456  0.05745225 -0.25825683\n",
      "  0.3453121   0.00243512 -0.32884874  0.27939408 -0.21281274 -0.23040523\n",
      "  0.10447263 -0.36787384]\n",
      "Training Error:  10.493210497367766\n",
      "====================================================================================================\n",
      "Iteration:  1205\n",
      "Previous theta :  [ 0.00056223 -0.0954809   0.09461089  0.03674456  0.05745225 -0.25825683\n",
      "  0.3453121   0.00243512 -0.32884874  0.27939408 -0.21281274 -0.23040523\n",
      "  0.10447263 -0.36787384]\n",
      "New theta_0 : [ 0.00056216 -0.09548291  0.09461587  0.03675419  0.05745104 -0.25826159\n",
      "  0.34531007  0.00243658 -0.32885196  0.27941725 -0.21283842 -0.23040591\n",
      "  0.10447272 -0.36787504]\n",
      "Training Error:  10.493209228186927\n",
      "====================================================================================================\n",
      "Iteration:  1206\n",
      "Previous theta :  [ 0.00056216 -0.09548291  0.09461587  0.03675419  0.05745104 -0.25826159\n",
      "  0.34531007  0.00243658 -0.32885196  0.27941725 -0.21283842 -0.23040591\n",
      "  0.10447272 -0.36787504]\n",
      "New theta_0 : [ 0.00056209 -0.0954849   0.09462084  0.03676379  0.05744982 -0.25826633\n",
      "  0.34530805  0.00243805 -0.32885515  0.27944036 -0.21286403 -0.2304066\n",
      "  0.1044728  -0.36787625]\n",
      "Training Error:  10.49320796592206\n",
      "====================================================================================================\n",
      "Iteration:  1207\n",
      "Previous theta :  [ 0.00056209 -0.0954849   0.09462084  0.03676379  0.05744982 -0.25826633\n",
      "  0.34530805  0.00243805 -0.32885515  0.27944036 -0.21286403 -0.2304066\n",
      "  0.1044728  -0.36787625]\n",
      "New theta_0 : [ 0.00056201 -0.09548689  0.0946258   0.03677337  0.05744861 -0.25827105\n",
      "  0.34530604  0.00243951 -0.32885833  0.27946341 -0.21288957 -0.23040728\n",
      "  0.10447289 -0.36787745]\n",
      "Training Error:  10.493206710534851\n",
      "====================================================================================================\n",
      "Iteration:  1208\n",
      "Previous theta :  [ 0.00056201 -0.09548689  0.0946258   0.03677337  0.05744861 -0.25827105\n",
      "  0.34530604  0.00243951 -0.32885833  0.27946341 -0.21288957 -0.23040728\n",
      "  0.10447289 -0.36787745]\n",
      "New theta_0 : [ 0.00056194 -0.09548887  0.09463074  0.03678292  0.0574474  -0.25827575\n",
      "  0.34530404  0.00244097 -0.32886149  0.27948639 -0.21291505 -0.23040796\n",
      "  0.10447298 -0.36787865]\n",
      "Training Error:  10.493205461987195\n",
      "====================================================================================================\n",
      "Iteration:  1209\n",
      "Previous theta :  [ 0.00056194 -0.09548887  0.09463074  0.03678292  0.0574474  -0.25827575\n",
      "  0.34530404  0.00244097 -0.32886149  0.27948639 -0.21291505 -0.23040796\n",
      "  0.10447298 -0.36787865]\n",
      "New theta_0 : [ 0.00056187 -0.09549085  0.09463566  0.03679245  0.0574462  -0.25828042\n",
      "  0.34530204  0.00244242 -0.32886464  0.27950932 -0.21294046 -0.23040863\n",
      "  0.10447306 -0.36787984]\n",
      "Training Error:  10.493204220241218\n",
      "====================================================================================================\n",
      "Iteration:  1210\n",
      "Previous theta :  [ 0.00056187 -0.09549085  0.09463566  0.03679245  0.0574462  -0.25828042\n",
      "  0.34530204  0.00244242 -0.32886464  0.27950932 -0.21294046 -0.23040863\n",
      "  0.10447306 -0.36787984]\n",
      "New theta_0 : [ 0.0005618  -0.09549282  0.09464057  0.03680195  0.057445   -0.25828508\n",
      "  0.34530005  0.00244387 -0.32886776  0.27953218 -0.21296581 -0.23040931\n",
      "  0.10447315 -0.36788104]\n",
      "Training Error:  10.493202985259261\n",
      "====================================================================================================\n",
      "Iteration:  1211\n",
      "Previous theta :  [ 0.0005618  -0.09549282  0.09464057  0.03680195  0.057445   -0.25828508\n",
      "  0.34530005  0.00244387 -0.32886776  0.27953218 -0.21296581 -0.23040931\n",
      "  0.10447315 -0.36788104]\n",
      "New theta_0 : [ 0.00056173 -0.09549478  0.09464546  0.03681143  0.0574438  -0.25828972\n",
      "  0.34529807  0.00244532 -0.32887088  0.27955497 -0.21299109 -0.23040998\n",
      "  0.10447324 -0.36788222]\n",
      "Training Error:  10.49320175700388\n",
      "====================================================================================================\n",
      "Iteration:  1212\n",
      "Previous theta :  [ 0.00056173 -0.09549478  0.09464546  0.03681143  0.0574438  -0.25828972\n",
      "  0.34529807  0.00244532 -0.32887088  0.27955497 -0.21299109 -0.23040998\n",
      "  0.10447324 -0.36788222]\n",
      "New theta_0 : [ 0.00056166 -0.09549674  0.09465034  0.03682088  0.0574426  -0.25829433\n",
      "  0.34529609  0.00244677 -0.32887397  0.27957771 -0.2130163  -0.23041064\n",
      "  0.10447332 -0.36788341]\n",
      "Training Error:  10.493200535437847\n",
      "====================================================================================================\n",
      "Iteration:  1213\n",
      "Previous theta :  [ 0.00056166 -0.09549674  0.09465034  0.03682088  0.0574426  -0.25829433\n",
      "  0.34529609  0.00244677 -0.32887397  0.27957771 -0.2130163  -0.23041064\n",
      "  0.10447332 -0.36788341]\n",
      "New theta_0 : [ 0.00056159 -0.09549869  0.0946552   0.03683031  0.05744141 -0.25829893\n",
      "  0.34529412  0.00244821 -0.32887705  0.27960038 -0.21304145 -0.23041131\n",
      "  0.10447341 -0.3678846 ]\n",
      "Training Error:  10.493199320524148\n",
      "====================================================================================================\n",
      "Iteration:  1214\n",
      "Previous theta :  [ 0.00056159 -0.09549869  0.0946552   0.03683031  0.05744141 -0.25829893\n",
      "  0.34529412  0.00244821 -0.32887705  0.27960038 -0.21304145 -0.23041131\n",
      "  0.10447341 -0.3678846 ]\n",
      "New theta_0 : [ 0.00056152 -0.09550063  0.09466004  0.03683971  0.05744022 -0.2583035\n",
      "  0.34529216  0.00244964 -0.32888011  0.27962299 -0.21306653 -0.23041197\n",
      "  0.1044735  -0.36788578]\n",
      "Training Error:  10.493198112225986\n",
      "====================================================================================================\n",
      "Iteration:  1215\n",
      "Previous theta :  [ 0.00056152 -0.09550063  0.09466004  0.03683971  0.05744022 -0.2583035\n",
      "  0.34529216  0.00244964 -0.32888011  0.27962299 -0.21306653 -0.23041197\n",
      "  0.1044735  -0.36788578]\n",
      "New theta_0 : [ 0.00056145 -0.09550257  0.09466487  0.03684908  0.05743903 -0.25830806\n",
      "  0.3452902   0.00245108 -0.32888315  0.27964554 -0.21309154 -0.23041264\n",
      "  0.10447359 -0.36788695]\n",
      "Training Error:  10.49319691050677\n",
      "====================================================================================================\n",
      "Iteration:  1216\n",
      "Previous theta :  [ 0.00056145 -0.09550257  0.09466487  0.03684908  0.05743903 -0.25830806\n",
      "  0.3452902   0.00245108 -0.32888315  0.27964554 -0.21309154 -0.23041264\n",
      "  0.10447359 -0.36788695]\n",
      "New theta_0 : [ 0.00056138 -0.0955045   0.09466969  0.03685844  0.05743785 -0.25831259\n",
      "  0.34528825  0.00245251 -0.32888618  0.27966803 -0.21311649 -0.23041329\n",
      "  0.10447367 -0.36788813]\n",
      "Training Error:  10.493195715330119\n",
      "====================================================================================================\n",
      "Iteration:  1217\n",
      "Previous theta :  [ 0.00056138 -0.0955045   0.09466969  0.03685844  0.05743785 -0.25831259\n",
      "  0.34528825  0.00245251 -0.32888618  0.27966803 -0.21311649 -0.23041329\n",
      "  0.10447367 -0.36788813]\n",
      "New theta_0 : [ 0.00056131 -0.09550643  0.09467449  0.03686776  0.05743667 -0.25831711\n",
      "  0.34528631  0.00245394 -0.32888919  0.27969046 -0.21314137 -0.23041395\n",
      "  0.10447376 -0.3678893 ]\n",
      "Training Error:  10.493194526659867\n",
      "====================================================================================================\n",
      "Iteration:  1218\n",
      "Previous theta :  [ 0.00056131 -0.09550643  0.09467449  0.03686776  0.05743667 -0.25831711\n",
      "  0.34528631  0.00245394 -0.32888919  0.27969046 -0.21314137 -0.23041395\n",
      "  0.10447376 -0.3678893 ]\n",
      "New theta_0 : [ 0.00056124 -0.09550835  0.09467927  0.03687706  0.05743549 -0.2583216\n",
      "  0.34528437  0.00245536 -0.32889218  0.27971283 -0.21316619 -0.2304146\n",
      "  0.10447385 -0.36789047]\n",
      "Training Error:  10.493193344460048\n",
      "====================================================================================================\n",
      "Iteration:  1219\n",
      "Previous theta :  [ 0.00056124 -0.09550835  0.09467927  0.03687706  0.05743549 -0.2583216\n",
      "  0.34528437  0.00245536 -0.32889218  0.27971283 -0.21316619 -0.2304146\n",
      "  0.10447385 -0.36789047]\n",
      "New theta_0 : [ 0.00056117 -0.09551026  0.09468404  0.03688634  0.05743432 -0.25832608\n",
      "  0.34528244  0.00245678 -0.32889516  0.27973513 -0.21319095 -0.23041526\n",
      "  0.10447394 -0.36789164]\n",
      "Training Error:  10.493192168694907\n",
      "====================================================================================================\n",
      "Iteration:  1220\n",
      "Previous theta :  [ 0.00056117 -0.09551026  0.09468404  0.03688634  0.05743432 -0.25832608\n",
      "  0.34528244  0.00245678 -0.32889516  0.27973513 -0.21319095 -0.23041526\n",
      "  0.10447394 -0.36789164]\n",
      "New theta_0 : [ 0.00056111 -0.09551217  0.09468879  0.03689559  0.05743314 -0.25833053\n",
      "  0.34528051  0.0024582  -0.32889812  0.27975738 -0.21321563 -0.2304159\n",
      "  0.10447403 -0.3678928 ]\n",
      "Training Error:  10.493190999328897\n",
      "====================================================================================================\n",
      "Iteration:  1221\n",
      "Previous theta :  [ 0.00056111 -0.09551217  0.09468879  0.03689559  0.05743314 -0.25833053\n",
      "  0.34528051  0.0024582  -0.32889812  0.27975738 -0.21321563 -0.2304159\n",
      "  0.10447403 -0.3678928 ]\n",
      "New theta_0 : [ 0.00056104 -0.09551407  0.09469353  0.03690482  0.05743197 -0.25833497\n",
      "  0.34527859  0.00245961 -0.32890107  0.27977956 -0.21324026 -0.23041655\n",
      "  0.10447412 -0.36789396]\n",
      "Training Error:  10.493189836326662\n",
      "====================================================================================================\n",
      "Iteration:  1222\n",
      "Previous theta :  [ 0.00056104 -0.09551407  0.09469353  0.03690482  0.05743197 -0.25833497\n",
      "  0.34527859  0.00245961 -0.32890107  0.27977956 -0.21324026 -0.23041655\n",
      "  0.10447412 -0.36789396]\n",
      "New theta_0 : [ 0.00056097 -0.09551596  0.09469825  0.03691403  0.05743081 -0.25833939\n",
      "  0.34527668  0.00246102 -0.328904    0.27980168 -0.21326482 -0.2304172\n",
      "  0.10447421 -0.36789512]\n",
      "Training Error:  10.493188679653066\n",
      "====================================================================================================\n",
      "Iteration:  1223\n",
      "Previous theta :  [ 0.00056097 -0.09551596  0.09469825  0.03691403  0.05743081 -0.25833939\n",
      "  0.34527668  0.00246102 -0.328904    0.27980168 -0.21326482 -0.2304172\n",
      "  0.10447421 -0.36789512]\n",
      "New theta_0 : [ 0.00056091 -0.09551785  0.09470296  0.03692321  0.05742964 -0.25834378\n",
      "  0.34527477  0.00246243 -0.32890691  0.27982375 -0.21328931 -0.23041784\n",
      "  0.1044743  -0.36789627]\n",
      "Training Error:  10.493187529273161\n",
      "====================================================================================================\n",
      "Iteration:  1224\n",
      "Previous theta :  [ 0.00056091 -0.09551785  0.09470296  0.03692321  0.05742964 -0.25834378\n",
      "  0.34527477  0.00246243 -0.32890691  0.27982375 -0.21328931 -0.23041784\n",
      "  0.1044743  -0.36789627]\n",
      "New theta_0 : [ 0.00056084 -0.09551974  0.09470766  0.03693236  0.05742848 -0.25834816\n",
      "  0.34527287  0.00246384 -0.32890981  0.27984575 -0.21331374 -0.23041848\n",
      "  0.10447438 -0.36789742]\n",
      "Training Error:  10.493186385152203\n",
      "====================================================================================================\n",
      "Iteration:  1225\n",
      "Previous theta :  [ 0.00056084 -0.09551974  0.09470766  0.03693236  0.05742848 -0.25834816\n",
      "  0.34527287  0.00246384 -0.32890981  0.27984575 -0.21331374 -0.23041848\n",
      "  0.10447438 -0.36789742]\n",
      "New theta_0 : [ 0.00056077 -0.09552161  0.09471233  0.03694149  0.05742733 -0.25835252\n",
      "  0.34527098  0.00246524 -0.32891269  0.2798677  -0.21333811 -0.23041911\n",
      "  0.10447447 -0.36789857]\n",
      "Training Error:  10.493185247255647\n",
      "====================================================================================================\n",
      "Iteration:  1226\n",
      "Previous theta :  [ 0.00056077 -0.09552161  0.09471233  0.03694149  0.05742733 -0.25835252\n",
      "  0.34527098  0.00246524 -0.32891269  0.2798677  -0.21333811 -0.23041911\n",
      "  0.10447447 -0.36789857]\n",
      "New theta_0 : [ 0.00056071 -0.09552348  0.094717    0.0369506   0.05742617 -0.25835686\n",
      "  0.34526909  0.00246664 -0.32891556  0.27988958 -0.21336241 -0.23041975\n",
      "  0.10447456 -0.36789972]\n",
      "Training Error:  10.493184115549145\n",
      "====================================================================================================\n",
      "Iteration:  1227\n",
      "Previous theta :  [ 0.00056071 -0.09552348  0.094717    0.0369506   0.05742617 -0.25835686\n",
      "  0.34526909  0.00246664 -0.32891556  0.27988958 -0.21336241 -0.23041975\n",
      "  0.10447456 -0.36789972]\n",
      "New theta_0 : [ 0.00056064 -0.09552535  0.09472165  0.03695968  0.05742502 -0.25836119\n",
      "  0.34526721  0.00246803 -0.32891841  0.2799114  -0.21338665 -0.23042038\n",
      "  0.10447465 -0.36790086]\n",
      "Training Error:  10.493182989998544\n",
      "====================================================================================================\n",
      "Iteration:  1228\n",
      "Previous theta :  [ 0.00056064 -0.09552535  0.09472165  0.03695968  0.05742502 -0.25836119\n",
      "  0.34526721  0.00246803 -0.32891841  0.2799114  -0.21338665 -0.23042038\n",
      "  0.10447465 -0.36790086]\n",
      "New theta_0 : [ 0.00056058 -0.09552721  0.09472628  0.03696873  0.05742387 -0.25836549\n",
      "  0.34526533  0.00246942 -0.32892125  0.27993317 -0.21341082 -0.23042101\n",
      "  0.10447474 -0.367902  ]\n",
      "Training Error:  10.493181870569893\n",
      "====================================================================================================\n",
      "Iteration:  1229\n",
      "Previous theta :  [ 0.00056058 -0.09552721  0.09472628  0.03696873  0.05742387 -0.25836549\n",
      "  0.34526533  0.00246942 -0.32892125  0.27993317 -0.21341082 -0.23042101\n",
      "  0.10447474 -0.367902  ]\n",
      "New theta_0 : [ 0.00056051 -0.09552906  0.0947309   0.03697777  0.05742273 -0.25836977\n",
      "  0.34526347  0.00247081 -0.32892407  0.27995488 -0.21343493 -0.23042164\n",
      "  0.10447484 -0.36790314]\n",
      "Training Error:  10.493180757229421\n",
      "====================================================================================================\n",
      "Iteration:  1230\n",
      "Previous theta :  [ 0.00056051 -0.09552906  0.0947309   0.03697777  0.05742273 -0.25836977\n",
      "  0.34526347  0.00247081 -0.32892407  0.27995488 -0.21343493 -0.23042164\n",
      "  0.10447484 -0.36790314]\n",
      "New theta_0 : [ 0.00056045 -0.09553091  0.0947355   0.03698678  0.05742158 -0.25837404\n",
      "  0.3452616   0.00247219 -0.32892687  0.27997652 -0.21345898 -0.23042227\n",
      "  0.10447493 -0.36790427]\n",
      "Training Error:  10.493179649943565\n",
      "====================================================================================================\n",
      "Iteration:  1231\n",
      "Previous theta :  [ 0.00056045 -0.09553091  0.0947355   0.03698678  0.05742158 -0.25837404\n",
      "  0.3452616   0.00247219 -0.32892687  0.27997652 -0.21345898 -0.23042227\n",
      "  0.10447493 -0.36790427]\n",
      "New theta_0 : [ 0.00056039 -0.09553275  0.09474009  0.03699576  0.05742044 -0.25837829\n",
      "  0.34525975  0.00247358 -0.32892967  0.27999811 -0.21348297 -0.23042289\n",
      "  0.10447502 -0.36790541]\n",
      "Training Error:  10.493178548678944\n",
      "====================================================================================================\n",
      "Iteration:  1232\n",
      "Previous theta :  [ 0.00056039 -0.09553275  0.09474009  0.03699576  0.05742044 -0.25837829\n",
      "  0.34525975  0.00247358 -0.32892967  0.27999811 -0.21348297 -0.23042289\n",
      "  0.10447502 -0.36790541]\n",
      "New theta_0 : [ 0.00056032 -0.09553459  0.09474467  0.03700472  0.05741931 -0.25838252\n",
      "  0.3452579   0.00247495 -0.32893244  0.28001964 -0.21350689 -0.23042351\n",
      "  0.10447511 -0.36790653]\n",
      "Training Error:  10.49317745340237\n",
      "====================================================================================================\n",
      "Iteration:  1233\n",
      "Previous theta :  [ 0.00056032 -0.09553459  0.09474467  0.03700472  0.05741931 -0.25838252\n",
      "  0.3452579   0.00247495 -0.32893244  0.28001964 -0.21350689 -0.23042351\n",
      "  0.10447511 -0.36790653]\n",
      "New theta_0 : [ 0.00056026 -0.09553642  0.09474923  0.03701366  0.05741817 -0.25838673\n",
      "  0.34525605  0.00247633 -0.3289352   0.28004111 -0.21353075 -0.23042413\n",
      "  0.1044752  -0.36790766]\n",
      "Training Error:  10.493176364080842\n",
      "====================================================================================================\n",
      "Iteration:  1234\n",
      "Previous theta :  [ 0.00056026 -0.09553642  0.09474923  0.03701366  0.05741817 -0.25838673\n",
      "  0.34525605  0.00247633 -0.3289352   0.28004111 -0.21353075 -0.23042413\n",
      "  0.1044752  -0.36790766]\n",
      "New theta_0 : [ 0.0005602  -0.09553824  0.09475378  0.03702258  0.05741704 -0.25839092\n",
      "  0.34525421  0.0024777  -0.32893795  0.28006252 -0.21355454 -0.23042475\n",
      "  0.10447529 -0.36790878]\n",
      "Training Error:  10.493175280681548\n",
      "====================================================================================================\n",
      "Iteration:  1235\n",
      "Previous theta :  [ 0.0005602  -0.09553824  0.09475378  0.03702258  0.05741704 -0.25839092\n",
      "  0.34525421  0.0024777  -0.32893795  0.28006252 -0.21355454 -0.23042475\n",
      "  0.10447529 -0.36790878]\n",
      "New theta_0 : [ 0.00056014 -0.09554006  0.09475831  0.03703147  0.05741591 -0.2583951\n",
      "  0.34525238  0.00247907 -0.32894068  0.28008388 -0.21357828 -0.23042536\n",
      "  0.10447538 -0.36790991]\n",
      "Training Error:  10.493174203171867\n",
      "====================================================================================================\n",
      "Iteration:  1236\n",
      "Previous theta :  [ 0.00056014 -0.09554006  0.09475831  0.03703147  0.05741591 -0.2583951\n",
      "  0.34525238  0.00247907 -0.32894068  0.28008388 -0.21357828 -0.23042536\n",
      "  0.10447538 -0.36790991]\n",
      "New theta_0 : [ 0.00056007 -0.09554187  0.09476283  0.03704033  0.05741478 -0.25839926\n",
      "  0.34525055  0.00248043 -0.3289434   0.28010517 -0.21360195 -0.23042597\n",
      "  0.10447547 -0.36791102]\n",
      "Training Error:  10.493173131519358\n",
      "====================================================================================================\n",
      "Iteration:  1237\n",
      "Previous theta :  [ 0.00056007 -0.09554187  0.09476283  0.03704033  0.05741478 -0.25839926\n",
      "  0.34525055  0.00248043 -0.3289434   0.28010517 -0.21360195 -0.23042597\n",
      "  0.10447547 -0.36791102]\n",
      "New theta_0 : [ 0.00056001 -0.09554368  0.09476733  0.03704917  0.05741366 -0.25840339\n",
      "  0.34524873  0.0024818  -0.3289461   0.28012641 -0.21362556 -0.23042658\n",
      "  0.10447556 -0.36791214]\n",
      "Training Error:  10.493172065691764\n",
      "====================================================================================================\n",
      "Iteration:  1238\n",
      "Previous theta :  [ 0.00056001 -0.09554368  0.09476733  0.03704917  0.05741366 -0.25840339\n",
      "  0.34524873  0.0024818  -0.3289461   0.28012641 -0.21362556 -0.23042658\n",
      "  0.10447556 -0.36791214]\n",
      "New theta_0 : [ 0.00055995 -0.09554548  0.09477182  0.03705799  0.05741254 -0.25840752\n",
      "  0.34524692  0.00248315 -0.32894879  0.28014759 -0.2136491  -0.23042719\n",
      "  0.10447566 -0.36791325]\n",
      "Training Error:  10.49317100565702\n",
      "====================================================================================================\n",
      "Iteration:  1239\n",
      "Previous theta :  [ 0.00055995 -0.09554548  0.09477182  0.03705799  0.05741254 -0.25840752\n",
      "  0.34524692  0.00248315 -0.32894879  0.28014759 -0.2136491  -0.23042719\n",
      "  0.10447566 -0.36791325]\n",
      "New theta_0 : [ 0.00055989 -0.09554728  0.0947763   0.03706679  0.05741142 -0.25841162\n",
      "  0.34524511  0.00248451 -0.32895147  0.28016871 -0.21367259 -0.2304278\n",
      "  0.10447575 -0.36791436]\n",
      "Training Error:  10.49316995138323\n",
      "====================================================================================================\n",
      "Iteration:  1240\n",
      "Previous theta :  [ 0.00055989 -0.09554728  0.0947763   0.03706679  0.05741142 -0.25841162\n",
      "  0.34524511  0.00248451 -0.32895147  0.28016871 -0.21367259 -0.2304278\n",
      "  0.10447575 -0.36791436]\n",
      "New theta_0 : [ 0.00055983 -0.09554907  0.09478076  0.03707556  0.05741031 -0.25841571\n",
      "  0.34524331  0.00248586 -0.32895413  0.28018978 -0.21369601 -0.2304284\n",
      "  0.10447584 -0.36791547]\n",
      "Training Error:  10.493168902838693\n",
      "====================================================================================================\n",
      "Iteration:  1241\n",
      "Previous theta :  [ 0.00055983 -0.09554907  0.09478076  0.03707556  0.05741031 -0.25841571\n",
      "  0.34524331  0.00248586 -0.32895413  0.28018978 -0.21369601 -0.2304284\n",
      "  0.10447584 -0.36791547]\n",
      "New theta_0 : [ 0.00055977 -0.09555085  0.09478521  0.03708431  0.0574092  -0.25841978\n",
      "  0.34524151  0.00248721 -0.32895677  0.28021079 -0.21371937 -0.230429\n",
      "  0.10447593 -0.36791657]\n",
      "Training Error:  10.493167859991875\n",
      "====================================================================================================\n",
      "Iteration:  1242\n",
      "Previous theta :  [ 0.00055977 -0.09555085  0.09478521  0.03708431  0.0574092  -0.25841978\n",
      "  0.34524151  0.00248721 -0.32895677  0.28021079 -0.21371937 -0.230429\n",
      "  0.10447593 -0.36791657]\n",
      "New theta_0 : [ 0.00055971 -0.09555263  0.09478964  0.03709304  0.05740809 -0.25842383\n",
      "  0.34523972  0.00248856 -0.3289594   0.28023174 -0.21374267 -0.2304296\n",
      "  0.10447602 -0.36791767]\n",
      "Training Error:  10.493166822811432\n",
      "====================================================================================================\n",
      "Iteration:  1243\n",
      "Previous theta :  [ 0.00055971 -0.09555263  0.09478964  0.03709304  0.05740809 -0.25842383\n",
      "  0.34523972  0.00248856 -0.3289594   0.28023174 -0.21374267 -0.2304296\n",
      "  0.10447602 -0.36791767]\n",
      "New theta_0 : [ 0.00055965 -0.0955544   0.09479406  0.03710174  0.05740698 -0.25842786\n",
      "  0.34523793  0.0024899  -0.32896202  0.28025263 -0.21376591 -0.2304302\n",
      "  0.10447612 -0.36791877]\n",
      "Training Error:  10.493165791266188\n",
      "====================================================================================================\n",
      "Iteration:  1244\n",
      "Previous theta :  [ 0.00055965 -0.0955544   0.09479406  0.03710174  0.05740698 -0.25842786\n",
      "  0.34523793  0.0024899  -0.32896202  0.28025263 -0.21376591 -0.2304302\n",
      "  0.10447612 -0.36791877]\n",
      "New theta_0 : [ 0.00055959 -0.09555617  0.09479847  0.03711042  0.05740588 -0.25843188\n",
      "  0.34523615  0.00249124 -0.32896463  0.28027347 -0.21378909 -0.23043079\n",
      "  0.10447621 -0.36791987]\n",
      "Training Error:  10.493164765325155\n",
      "====================================================================================================\n",
      "Iteration:  1245\n",
      "Previous theta :  [ 0.00055959 -0.09555617  0.09479847  0.03711042  0.05740588 -0.25843188\n",
      "  0.34523615  0.00249124 -0.32896463  0.28027347 -0.21378909 -0.23043079\n",
      "  0.10447621 -0.36791987]\n",
      "New theta_0 : [ 0.00055953 -0.09555793  0.09480286  0.03711907  0.05740478 -0.25843588\n",
      "  0.34523438  0.00249258 -0.32896722  0.28029425 -0.21381221 -0.23043138\n",
      "  0.1044763  -0.36792096]\n",
      "Training Error:  10.493163744957508\n",
      "====================================================================================================\n",
      "Iteration:  1246\n",
      "Previous theta :  [ 0.00055953 -0.09555793  0.09480286  0.03711907  0.05740478 -0.25843588\n",
      "  0.34523438  0.00249258 -0.32896722  0.28029425 -0.21381221 -0.23043138\n",
      "  0.1044763  -0.36792096]\n",
      "New theta_0 : [ 0.00055947 -0.09555969  0.09480724  0.03712771  0.05740368 -0.25843986\n",
      "  0.34523261  0.00249391 -0.32896979  0.28031497 -0.21383526 -0.23043198\n",
      "  0.1044764  -0.36792205]\n",
      "Training Error:  10.49316273013261\n",
      "====================================================================================================\n",
      "Iteration:  1247\n",
      "Previous theta :  [ 0.00055947 -0.09555969  0.09480724  0.03712771  0.05740368 -0.25843986\n",
      "  0.34523261  0.00249391 -0.32896979  0.28031497 -0.21383526 -0.23043198\n",
      "  0.1044764  -0.36792205]\n",
      "New theta_0 : [ 0.00055942 -0.09556144  0.0948116   0.03713632  0.05740258 -0.25844383\n",
      "  0.34523085  0.00249524 -0.32897236  0.28033564 -0.21385826 -0.23043256\n",
      "  0.10447649 -0.36792314]\n",
      "Training Error:  10.493161720819986\n",
      "====================================================================================================\n",
      "Iteration:  1248\n",
      "Previous theta :  [ 0.00055942 -0.09556144  0.0948116   0.03713632  0.05740258 -0.25844383\n",
      "  0.34523085  0.00249524 -0.32897236  0.28033564 -0.21385826 -0.23043256\n",
      "  0.10447649 -0.36792314]\n",
      "New theta_0 : [ 0.00055936 -0.09556318  0.09481595  0.0371449   0.05740149 -0.25844778\n",
      "  0.34522909  0.00249657 -0.32897491  0.28035625 -0.21388119 -0.23043315\n",
      "  0.10447658 -0.36792422]\n",
      "Training Error:  10.493160716989335\n",
      "====================================================================================================\n",
      "Iteration:  1249\n",
      "Previous theta :  [ 0.00055936 -0.09556318  0.09481595  0.0371449   0.05740149 -0.25844778\n",
      "  0.34522909  0.00249657 -0.32897491  0.28035625 -0.21388119 -0.23043315\n",
      "  0.10447658 -0.36792422]\n",
      "New theta_0 : [ 0.0005593  -0.09556492  0.09482029  0.03715347  0.0574004  -0.25845171\n",
      "  0.34522734  0.00249789 -0.32897744  0.28037681 -0.21390407 -0.23043373\n",
      "  0.10447667 -0.36792531]\n",
      "Training Error:  10.493159718610537\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = test_train_split(X, y, validation_sample4)\n",
    "learning_rate = 0.01\n",
    "train_error4, valid_error4, theta4 = linear_regression(X_train, y_train, X_test, y_test, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Second Sample')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(train_error4))], train_error4, label='Training error')\n",
    "plt.plot([i for i in range(len(valid_error4))], valid_error4, label='Validation error')\n",
    "plt.gca().legend(('Training error','Validation error'))\n",
    "plt.title('Second Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  0\n",
      "Previous theta :  [1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5]\n",
      "New theta_0 : [1.44564035 1.31856136 1.5712472  1.31763039 1.4509704  1.32558694\n",
      " 1.57141313 1.35409016 1.61260055 1.31038829 1.30765618 1.3865367\n",
      " 1.54607914 1.35716799]\n",
      "Training Error:  119.75763959649055\n",
      "====================================================================================================\n",
      "Iteration:  1\n",
      "Previous theta :  [1.44564035 1.31856136 1.5712472  1.31763039 1.4509704  1.32558694\n",
      " 1.57141313 1.35409016 1.61260055 1.31038829 1.30765618 1.3865367\n",
      " 1.54607914 1.35716799]\n",
      "New theta_0 : [1.39372128 1.16652537 1.61851527 1.17008711 1.405744   1.18477847\n",
      " 1.62430003 1.23638997 1.69640534 1.1518735  1.14675671 1.29152693\n",
      " 1.57769554 1.24015024]\n",
      "Training Error:  104.88188603426232\n",
      "====================================================================================================\n",
      "Iteration:  2\n",
      "Previous theta :  [1.39372128 1.16652537 1.61851527 1.17008711 1.405744   1.18477847\n",
      " 1.62430003 1.23638997 1.69640534 1.1518735  1.14675671 1.29152693\n",
      " 1.57769554 1.24015024]\n",
      "New theta_0 : [1.34404669 1.0384766  1.64676802 1.05062067 1.36369875 1.07105128\n",
      " 1.66235494 1.14135478 1.75716122 1.01870916 1.01146199 1.21147655\n",
      " 1.59770209 1.14393846]\n",
      "Training Error:  93.50253059723386\n",
      "====================================================================================================\n",
      "Iteration:  3\n",
      "Previous theta :  [1.34404669 1.0384766  1.64676802 1.05062067 1.36369875 1.07105128\n",
      " 1.66235494 1.14135478 1.75716122 1.01870916 1.01146199 1.21147655\n",
      " 1.59770209 1.14393846]\n",
      "New theta_0 : [1.29644904 0.93003273 1.65999872 0.95378579 1.32433189 0.97914295\n",
      " 1.68855514 1.06451575 1.79949902 0.90624644 0.89704954 1.14356356\n",
      " 1.6084027  1.06449296]\n",
      "Training Error:  84.82893040975914\n",
      "====================================================================================================\n",
      "Iteration:  4\n",
      "Previous theta :  [1.29644904 0.93003273 1.65999872 0.95378579 1.32433189 0.97914295\n",
      " 1.68855514 1.06451575 1.79949902 0.90624644 0.89704954 1.14356356\n",
      " 1.6084027  1.06449296]\n",
      "New theta_0 : [1.25078414 0.83764571 1.66141785 0.87518974 1.28723684 0.90480855\n",
      " 1.70529937 1.002272   1.82714916 0.81072283 0.79969892 1.08550846\n",
      " 1.61165805 0.99855569]\n",
      "Training Error:  78.2073988625879\n",
      "====================================================================================================\n",
      "Iteration:  5\n",
      "Previous theta :  [1.25078414 0.83764571 1.66141785 0.87518974 1.28723684 0.90480855\n",
      " 1.70529937 1.002272   1.82714916 0.81072283 0.79969892 1.08550846\n",
      " 1.61165805 0.99855569]\n",
      "New theta_0 : [1.20692697 0.75844134 1.65360467 0.81128909 1.25208449 0.84462421\n",
      " 1.71451968 0.95172291 1.8431157  0.72909165 0.71631808 1.03546975\n",
      " 1.60897098 0.94349928]\n",
      "Training Error:  73.11126914368135\n",
      "====================================================================================================\n",
      "Iteration:  6\n",
      "Previous theta :  [1.20692697 0.75844134 1.65360467 0.81128909 1.25208449 0.84462421\n",
      " 1.71451968 0.95172291 1.8431157  0.72909165 0.71631808 1.03546975\n",
      " 1.60897098 0.94349928]\n",
      "New theta_0 : [1.16476825 0.69008977 1.63862949 0.75922582 1.21860824 0.79582864\n",
      " 1.71777156 0.91053272 1.84981675 0.6588844  0.64440323 0.99195946\n",
      " 1.60155535 0.89720536]\n",
      "Training Error:  69.12932873606778\n",
      "====================================================================================================\n",
      "Iteration:  7\n",
      "Previous theta :  [1.16476825 0.69008977 1.63862949 0.75922582 1.21860824 0.79582864\n",
      " 1.71777156 0.91053272 1.84981675 0.6588844  0.64440323 0.99195946\n",
      " 1.60155535 0.89720536]\n",
      "New theta_0 : [1.1242117  0.63070093 1.61815233 0.71669498 1.18659182 0.75619513\n",
      " 1.71630676 0.87682127 1.8491978  0.5980996  0.58192568 0.95377506\n",
      " 1.59039164 0.85796617]\n",
      "Training Error:  65.95056924957342\n",
      "====================================================================================================\n",
      "Iteration:  8\n",
      "Previous theta :  [1.1242117  0.63070093 1.61815233 0.71669498 1.18659182 0.75619513\n",
      " 1.71630676 0.87682127 1.8491978  0.5980996  0.58192568 0.95377506\n",
      " 1.59039164 0.85796617]\n",
      "New theta_0 : [1.08517176 0.57874012 1.59350252 0.68183787 1.15585955 0.72392838\n",
      " 1.71113205 0.84907591 1.84282314 0.54511314 0.52724058 0.91994443\n",
      " 1.5762719  0.82440533]\n",
      "Training Error:  63.34639327897081\n",
      "====================================================================================================\n",
      "Iteration:  9\n",
      "Previous theta :  [1.08517176 0.57874012 1.59350252 0.68183787 1.15585955 0.72392838\n",
      " 1.71113205 0.84907591 1.84282314 0.54511314 0.52724058 0.91994443\n",
      " 1.5762719  0.82440533]\n",
      "New theta_0 : [1.04757185 0.53295992 1.56574295 0.65315588 1.12626838 0.69758112\n",
      " 1.70305658 0.82608029 1.83194971 0.49860585 0.47901313 0.88968152\n",
      " 1.55983592 0.79541375]\n",
      "Training Error:  61.152667550932065\n",
      "====================================================================================================\n",
      "Iteration:  10\n",
      "Previous theta :  [1.04757185 0.53295992 1.56574295 0.65315588 1.12626838 0.69758112\n",
      " 1.70305658 0.82608029 1.83194971 0.49860585 0.47901313 0.88968152\n",
      " 1.55983592 0.79541375]\n",
      "New theta_0 : [1.01134282 0.49234509 1.53572188 0.62944094 1.09770162 0.67598692\n",
      " 1.69273018 0.80685702 1.81758658 0.45750502 0.43615915 0.86235049\n",
      " 1.54160055 0.77009805]\n",
      "Training Error:  59.25362514179331\n",
      "====================================================================================================\n",
      "Iteration:  11\n",
      "Previous theta :  [1.01134282 0.49234509 1.53572188 0.62944094 1.09770162 0.67598692\n",
      " 1.69273018 0.80685702 1.81758658 0.45750502 0.43615915 0.86235049\n",
      " 1.54160055 0.77009805]\n",
      "New theta_0 : [0.97642181 0.45606824 1.50411474 0.60971941 1.07006374 0.65820586\n",
      " 1.68067419 0.79062133 1.80054305 0.42093722 0.39779695 0.8374368\n",
      " 1.52198325 0.74773878]\n",
      "Training Error:  57.56862852346451\n",
      "====================================================================================================\n",
      "Iteration:  12\n",
      "Previous theta :  [0.97642181 0.45606824 1.50411474 0.60971941 1.07006374 0.65820586\n",
      " 1.68067419 0.79062133 1.80054305 0.42093722 0.39779695 0.8374368\n",
      " 1.52198325 0.74773878]\n",
      "New theta_0 : [0.94275123 0.42345391 1.47145786 0.59320671 1.04327631 0.64348082\n",
      " 1.66730639 0.77674372 1.78146736 0.38819021 0.36320861 0.81452389\n",
      " 1.50132122 0.72775686]\n",
      "Training Error:  56.04194506061124\n",
      "====================================================================================================\n",
      "Iteration:  13\n",
      "Previous theta :  [0.94275123 0.42345391 1.47145786 0.59320671 1.04327631 0.64348082\n",
      " 1.66730639 0.77674372 1.78146736 0.38819021 0.36320861 0.81452389\n",
      " 1.50132122 0.72775686]\n",
      "New theta_0 : [0.91027803 0.39394961 1.43817568 0.57927086 1.01727457 0.63120208\n",
      " 1.6529611  0.76471979 1.76087803 0.35868214 0.33180865 0.79327428\n",
      " 1.47988678 0.70968638]\n",
      "Training Error:  54.635192068116666\n",
      "====================================================================================================\n",
      "Iteration:  14\n",
      "Previous theta :  [0.91027803 0.39394961 1.43817568 0.57927086 1.01727457 0.63120208\n",
      " 1.6529611  0.76471979 1.76087803 0.35868214 0.33180865 0.79327428\n",
      " 1.47988678 0.70968638]\n",
      "New theta_0 : [0.87895299 0.36710245 1.40460265 0.5674029  0.99200487 0.62087883\n",
      " 1.63790538 0.75414592 1.73918905 0.33193668 0.30311871 0.77341442\n",
      " 1.45789979 0.69315271]\n",
      "Training Error:  53.32192577417913\n",
      "====================================================================================================\n",
      "Iteration:  15\n",
      "Previous theta :  [0.87895299 0.36710245 1.40460265 0.5674029  0.99200487 0.62087883\n",
      " 1.63790538 0.75414592 1.73918905 0.33193668 0.30311871 0.77341442\n",
      " 1.45789979 0.69315271]\n",
      "New theta_0 : [0.84873021 0.34254024 1.37100097 0.55719317 0.9674224  0.61211615\n",
      " 1.62235211 0.74469967 1.71673025 0.30756303 0.27674716 0.75472239\n",
      " 1.43553767 0.67785483]\n",
      "Training Error:  52.08384931998952\n",
      "====================================================================================================\n",
      "Iteration:  16\n",
      "Previous theta :  [0.84873021 0.34254024 1.37100097 0.55719317 0.9674224  0.61211615\n",
      " 1.62235211 0.74469967 1.71673025 0.30756303 0.27674716 0.75472239\n",
      " 1.43553767 0.67785483]\n",
      "New theta_0 : [0.81956668 0.31995618 1.33757479 0.548312   0.94348952 0.60459647\n",
      " 1.60647058 0.73612391 1.69376369 0.28523962 0.25237259 0.73701797\n",
      " 1.41294358 0.66355103]\n",
      "Training Error:  50.90819537309611\n",
      "====================================================================================================\n",
      "Iteration:  17\n",
      "Previous theta :  [0.81956668 0.31995618 1.33757479 0.548312   0.94348952 0.60459647\n",
      " 1.60647058 0.73612391 1.69376369 0.28523962 0.25237259 0.73701797\n",
      " 1.41294358 0.66355103]\n",
      "New theta_0 : [0.79142195 0.29909662 1.30448176 0.5404943  0.92017435 0.59806454\n",
      " 1.59039497 0.72821412 1.67049697 0.26470107 0.22973051 0.72015465\n",
      " 1.39023289 0.65004743]\n",
      "Training Error:  49.78593844632214\n",
      "====================================================================================================\n",
      "Iteration:  18\n",
      "Previous theta :  [0.79142195 0.29909662 1.30448176 0.5404943  0.92017435 0.59806454\n",
      " 1.59039497 0.72821412 1.67049697 0.26470107 0.22973051 0.72015465\n",
      " 1.39023289 0.65004743]\n",
      "New theta_0 : [0.76425777 0.279751   1.27184227 0.53352701 0.89744961 0.59231539\n",
      " 1.57423122 0.72080801 1.64709384 0.24572759 0.20860257 0.70401318\n",
      " 1.36749851 0.6371887 ]\n",
      "Training Error:  48.710582793022304\n",
      "====================================================================================================\n",
      "Iteration:  19\n",
      "Previous theta :  [0.76425777 0.279751   1.27184227 0.53352701 0.89744961 0.59231539\n",
      " 1.57423122 0.72080801 1.64709384 0.24572759 0.20860257 0.70401318\n",
      " 1.36749851 0.6371887 ]\n",
      "New theta_0 : [0.7380379  0.26174384 1.23974692 0.52723903 0.87529176 0.58718455\n",
      " 1.55806258 0.71377731 1.62368286 0.22813641 0.18880787 0.68849632\n",
      " 1.34481517 0.62485053]\n",
      "Training Error:  47.67734468487038\n",
      "====================================================================================================\n",
      "Iteration:  20\n",
      "Previous theta :  [0.7380379  0.26174384 1.23974692 0.52723903 0.87529176 0.58718455\n",
      " 1.55806258 0.71377731 1.62368286 0.22813641 0.18880787 0.68849632\n",
      " 1.34481517 0.62485053]\n",
      "New theta_0 : [0.71272788 0.24492822 1.20826254 0.52149303 0.85368024 0.58254018\n",
      " 1.54195408 0.70702099 1.6003643  0.21177493 0.17019594 0.67352466\n",
      " 1.32224284 0.61293361]\n",
      "Training Error:  46.68260262540776\n",
      "====================================================================================================\n",
      "Iteration:  21\n",
      "Previous theta :  [0.71272788 0.24492822 1.20826254 0.52149303 0.85368024 0.58254018\n",
      " 1.54195408 0.70702099 1.6003643  0.21177493 0.17019594 0.67352466\n",
      " 1.32224284 0.61293361]\n",
      "New theta_0 : [0.68829488 0.2291805  1.17743699 0.51617896 0.8325969  0.57827674\n",
      " 1.52595613 0.70045993 1.5772158  0.19651505 0.15264105 0.65903322\n",
      " 1.29982957 0.60135878]\n",
      "Training Error:  45.723528514637685\n",
      "====================================================================================================\n",
      "Iteration:  22\n",
      "Previous theta :  [0.68829488 0.2291805  1.17743699 0.51617896 0.8325969  0.57827674\n",
      " 1.52595613 0.70045993 1.5772158  0.19651505 0.15264105 0.65903322\n",
      " 1.29982957 0.60135878]\n",
      "New theta_0 : [0.66470753 0.21439608 1.14730313 0.51120869 0.81202555 0.57430985\n",
      " 1.51010739 0.69403255 1.55429682 0.1822487  0.13603761 0.64496866\n",
      " 1.27761372 0.59006303]\n",
      "Training Error:  44.7978405066072\n",
      "====================================================================================================\n",
      "Iteration:  23\n",
      "Previous theta :  [0.66470753 0.21439608 1.14730313 0.51120869 0.81202555 0.57430985\n",
      " 1.51010739 0.69403255 1.55429682 0.1822487  0.13603761 0.64496866\n",
      " 1.27761372 0.59006303]\n",
      "New theta_0 : [0.64193583 0.20048591 1.11788189 0.50651175 0.79195152 0.5705722\n",
      " 1.49443718 0.68769129 1.53165229 0.16888418 0.12029649 0.63128712\n",
      " 1.25562576 0.57899638]\n",
      "Training Error:  43.903637460973464\n",
      "====================================================================================================\n",
      "Iteration:  24\n",
      "Previous theta :  [0.64193583 0.20048591 1.11788189 0.50651175 0.79195152 0.5705722\n",
      " 1.49443718 0.68769129 1.53165229 0.16888418 0.12029649 0.63128712\n",
      " 1.25562576 0.57899638]\n",
      "New theta_0 : [0.61995101 0.18737374 1.08918483 0.50203191 0.77236145 0.56701017\n",
      " 1.4789673  0.68139981 1.50931556 0.15634317 0.10534197 0.61795235\n",
      " 1.2338898  0.56811932]\n",
      "Training Error:  43.03928798187953\n",
      "====================================================================================================\n",
      "Iteration:  25\n",
      "Previous theta :  [0.61995101 0.18737374 1.08918483 0.50203191 0.77236145 0.56701017\n",
      " 1.4789673  0.68139981 1.50931556 0.15634317 0.10534197 0.61795235\n",
      " 1.2338898  0.56811932]\n",
      "New theta_0 : [0.59872548 0.17499381 1.06121613 0.49772436 0.75324298 0.56358115\n",
      " 1.46371356 0.67513072 1.48731075 0.14455836 0.09110936 0.60493435\n",
      " 1.21242476 0.55740071]\n",
      "Training Error:  42.20335591664111\n",
      "====================================================================================================\n",
      "Iteration:  26\n",
      "Previous theta :  [0.59872548 0.17499381 1.06121613 0.49772436 0.75324298 0.56358115\n",
      " 1.46371356 0.67513072 1.48731075 0.14455836 0.09110936 0.60493435\n",
      " 1.21242476 0.55740071]\n",
      "New theta_0 : [0.57823272 0.16328904 1.03397423 0.49355349 0.73458458 0.56025143\n",
      " 1.44868704 0.66886373 1.46565461 0.13347149 0.07754297 0.59220813\n",
      " 1.19124532 0.54681617]\n",
      "Training Error:  41.39455017708968\n",
      "====================================================================================================\n",
      "Iteration:  27\n",
      "Previous theta :  [0.57823272 0.16328904 1.03397423 0.49355349 0.73458458 0.56025143\n",
      " 1.44868704 0.66886373 1.46565461 0.13347149 0.07754297 0.59220813\n",
      " 1.19124532 0.54681617]\n",
      "New theta_0 : [0.55844725 0.15220954 1.00745314 0.48949108 0.7163754  0.55699438\n",
      " 1.43389504 0.6625842  1.44435809 0.12303177 0.06459454 0.57975281\n",
      " 1.17036274 0.53634668]\n",
      "Training Error:  40.611690772846046\n",
      "====================================================================================================\n",
      "Iteration:  28\n",
      "Previous theta :  [0.55844725 0.15220954 1.00745314 0.48949108 0.7163754  0.55699438\n",
      " 1.43389504 0.6625842  1.44435809 0.12303177 0.06459454 0.57975281\n",
      " 1.17036274 0.53634668]\n",
      "New theta_0 : [0.53934452 0.14171136 0.98164348 0.48551484 0.69860516 0.55378909\n",
      " 1.41934187 0.65628197 1.42342756 0.11319463 0.05222197 0.56755082\n",
      " 1.14978546 0.52597757]\n",
      "Training Error:  39.85368564488167\n",
      "====================================================================================================\n",
      "Iteration:  29\n",
      "Previous theta :  [0.53934452 0.14171136 0.98164348 0.48551484 0.69860516 0.55378909\n",
      " 1.41934187 0.65628197 1.42342756 0.11319463 0.05222197 0.56755082\n",
      " 1.14978546 0.52597757]\n",
      "New theta_0 : [0.52090092 0.13175557 0.95653329 0.48160725 0.68126402 0.55061925\n",
      " 1.40502951 0.64995036 1.40286576 0.10392062 0.04038823 0.5555873\n",
      " 1.12951965 0.51569758]\n",
      "Training Error:  39.11951469335175\n",
      "====================================================================================================\n",
      "Iteration:  30\n",
      "Previous theta :  [0.52090092 0.13175557 0.95653329 0.48160725 0.68126402 0.55061925\n",
      " 1.40502951 0.64995036 1.40286576 0.10392062 0.04038823 0.5555873\n",
      " 1.12951965 0.51569758]\n",
      "New theta_0 : [0.50309367 0.1223074  0.93210874 0.47775458 0.66434253 0.54747216\n",
      " 1.39095811 0.64358546 1.38267263 0.09517464 0.02906053 0.54384959\n",
      " 1.1095696  0.5054982 ]\n",
      "Training Error:  38.40821859966271\n",
      "====================================================================================================\n",
      "Iteration:  31\n",
      "Previous theta :  [0.50309367 0.1223074  0.93210874 0.47775458 0.66434253 0.54747216\n",
      " 1.39095811 0.64358546 1.38267263 0.09517464 0.02906053 0.54384959\n",
      " 1.1095696  0.5054982 ]\n",
      "New theta_0 : [0.48590085 0.11333559 0.90835462 0.47394618 0.64783156 0.54433809\n",
      " 1.37712638 0.6371855  1.36284593 0.08692518 0.01820959 0.53232683\n",
      " 1.08993806 0.49537312]\n",
      "Training Error:  37.718890847122935\n",
      "====================================================================================================\n",
      "Iteration:  32\n",
      "Previous theta :  [0.48590085 0.11333559 0.90835462 0.47394618 0.64783156 0.54433809\n",
      " 1.37712638 0.6371855  1.36284593 0.08692518 0.01820959 0.53232683\n",
      " 1.08993806 0.49537312]\n",
      "New theta_0 : [0.46930129 0.10481189 0.88525475 0.4701738  0.63172225 0.54120963\n",
      " 1.36353195 0.63075036 1.34338174 0.07914379 0.00780913 0.52100966\n",
      " 1.07062655 0.48531772]\n",
      "Training Error:  37.05067188040425\n",
      "====================================================================================================\n",
      "Iteration:  33\n",
      "Previous theta :  [0.46930129 0.10481189 0.88525475 0.4701738  0.63172225 0.54120963\n",
      " 1.36353195 0.63075036 1.34338174 0.07914379 0.00780913 0.52100966\n",
      " 1.07062655 0.48531772]\n",
      "New theta_0 : [ 0.45327458  0.09671058  0.86279237  0.46643115  0.61600598  0.53808123\n",
      "  1.35017162  0.62428116  1.32427488  0.07180464 -0.00216464  0.50988989\n",
      "  1.05163555  0.47532877]\n",
      "Training Error:  36.40274470063624\n",
      "====================================================================================================\n",
      "Iteration:  34\n",
      "Previous theta :  [ 0.45327458  0.09671058  0.86279237  0.46643115  0.61600598  0.53808123\n",
      "  1.35017162  0.62428116  1.32427488  0.07180464 -0.00216464  0.50988989\n",
      "  1.05163555  0.47532877]\n",
      "New theta_0 : [ 0.43780102  0.08900814  0.84095036  0.46271349  0.60067433  0.53494881\n",
      "  1.33704156  0.61778001  1.30551921  0.06488408 -0.01173337  0.49896034\n",
      "  1.03296468  0.4654041 ]\n",
      "Training Error:  35.77433142997696\n",
      "====================================================================================================\n",
      "Iteration:  35\n",
      "Previous theta :  [ 0.43780102  0.08900814  0.84095036  0.46271349  0.60067433  0.53494881\n",
      "  1.33704156  0.61778001  1.30551921  0.06488408 -0.01173337  0.49896034\n",
      "  1.03296468  0.4654041 ]\n",
      "New theta_0 : [ 0.42286162  0.08168293  0.81971143  0.4590173   0.58571908  0.53180947\n",
      "  1.32413749  0.61124967  1.28710794  0.05836041 -0.0209169   0.48821465\n",
      "  1.01461291  0.45554237]\n",
      "Training Error:  35.164690536862246\n",
      "====================================================================================================\n",
      "Iteration:  36\n",
      "Previous theta :  [ 0.42286162  0.08168293  0.81971143  0.4590173   0.58571908  0.53180947\n",
      "  1.32413749  0.61124967  1.28710794  0.05836041 -0.0209169   0.48821465\n",
      "  1.01461291  0.45554237]\n",
      "New theta_0 : [ 0.40843803  0.07471496  0.79905833  0.45534002  0.57113217  0.52866122\n",
      "  1.31145481  0.60469343  1.26903375  0.05221356 -0.0297335   0.47764713\n",
      "  0.99657858  0.44574288]\n",
      "Training Error:  34.573114517474465\n",
      "====================================================================================================\n",
      "Iteration:  37\n",
      "Previous theta :  [ 0.40843803  0.07471496  0.79905833  0.45534002  0.57113217  0.52866122\n",
      "  1.31145481  0.60469343  1.26903375  0.05221356 -0.0297335   0.47764713\n",
      "  0.99657858  0.44574288]\n",
      "New theta_0 : [ 0.39451253  0.06808568  0.77897394  0.45167986  0.55690567  0.52550279\n",
      "  1.29898873  0.59811493  1.25128904  0.0464249  -0.03820009  0.46725265\n",
      "  0.97885962  0.43600543]\n",
      "Training Error:  33.99892789805894\n",
      "====================================================================================================\n",
      "Iteration:  38\n",
      "Previous theta :  [ 0.39451253  0.06808568  0.77897394  0.45167986  0.55690567  0.52550279\n",
      "  1.29898873  0.59811493  1.25128904  0.0464249  -0.03820009  0.46725265\n",
      "  0.97885962  0.43600543]\n",
      "New theta_0 : [ 0.38106803  0.06177781  0.75944136  0.44803563  0.54303181  0.52233349\n",
      "  1.28673428  0.59151802  1.23386599  0.04097709 -0.04633239  0.45702654\n",
      "  0.96145352  0.42633019]\n",
      "Training Error:  33.44148546839469\n",
      "====================================================================================================\n",
      "Iteration:  39\n",
      "Previous theta :  [ 0.38106803  0.06177781  0.75944136  0.44803563  0.54303181  0.52233349\n",
      "  1.28673428  0.59151802  1.23386599  0.04097709 -0.04633239  0.45702654\n",
      "  0.96145352  0.42633019]\n",
      "New theta_0 : [ 0.36808801  0.0557752   0.740444    0.4444066   0.52950297  0.51915305\n",
      "  1.27468646  0.58490668  1.21675671  0.03585388 -0.0541451   0.44696453\n",
      "  0.94435749  0.41671763]\n",
      "Training Error:  32.90017068687546\n",
      "====================================================================================================\n",
      "Iteration:  40\n",
      "Previous theta :  [ 0.36808801  0.0557752   0.740444    0.4444066   0.52950297  0.51915305\n",
      "  1.27468646  0.58490668  1.21675671  0.03585388 -0.0541451   0.44696453\n",
      "  0.94435749  0.41671763]\n",
      "New theta_0 : [ 0.35555653  0.05006272  0.72196563  0.4407924   0.51631162  0.51596156\n",
      "  1.26284026  0.57828493  1.19995329  0.03104004 -0.06165198  0.43706269\n",
      "  0.92756845  0.40716838]\n",
      "Training Error:  32.374394217521676\n",
      "====================================================================================================\n",
      "Iteration:  41\n",
      "Previous theta :  [ 0.35555653  0.05006272  0.72196563  0.4407924   0.51631162  0.51596156\n",
      "  1.26284026  0.57828493  1.19995329  0.03104004 -0.06165198  0.43706269\n",
      "  0.92756845  0.40716838]\n",
      "New theta_0 : [ 0.34345818  0.04462613  0.70399041  0.43719294  0.50345038  0.51275933\n",
      "  1.25119067  0.5716568   1.18344785  0.02652125 -0.06886598  0.42731734\n",
      "  0.91108312  0.39768324]\n",
      "Training Error:  31.863592572306207\n",
      "====================================================================================================\n",
      "Iteration:  42\n",
      "Previous theta :  [ 0.34345818  0.04462613  0.70399041  0.43719294  0.50345038  0.51275933\n",
      "  1.25119067  0.5716568   1.18344785  0.02652125 -0.06886598  0.42731734\n",
      "  0.91108312  0.39768324]\n",
      "New theta_0 : [ 0.33177811  0.03945204  0.68650291  0.43360833  0.490912    0.50954688\n",
      "  1.23973276  0.56502626  1.16723264  0.02228397 -0.07579932  0.41772506\n",
      "  0.89489803  0.38826311]\n",
      "Training Error:  31.367226840748604\n",
      "====================================================================================================\n",
      "Iteration:  43\n",
      "Previous theta :  [ 0.33177811  0.03945204  0.68650291  0.43360833  0.490912    0.50954688\n",
      "  1.23973276  0.56502626  1.16723264  0.02228397 -0.07579932  0.41772506\n",
      "  0.89489803  0.38826311]\n",
      "New theta_0 : [ 0.32050194  0.03452779  0.66948814  0.43003883  0.47868931  0.50632487\n",
      "  1.22846168  0.55839718  1.1513      0.01831542 -0.08246355  0.40828262\n",
      "  0.87900958  0.37890891]\n",
      "Training Error:  30.88478149434594\n",
      "====================================================================================================\n",
      "Iteration:  44\n",
      "Previous theta :  [ 0.32050194  0.03452779  0.66948814  0.43003883  0.47868931  0.50632487\n",
      "  1.22846168  0.55839718  1.1513      0.01831542 -0.08246355  0.40828262\n",
      "  0.87900958  0.37890891]\n",
      "New theta_0 : [ 0.30961579  0.02984142  0.65293156  0.42648481  0.46677529  0.50309405\n",
      "  1.21737265  0.55177335  1.13564245  0.01460349 -0.08886959  0.39898697\n",
      "  0.86341402  0.36962162]\n",
      "Training Error:  30.415763257078055\n",
      "====================================================================================================\n",
      "Iteration:  45\n",
      "Previous theta :  [ 0.30961579  0.02984142  0.65293156  0.42648481  0.46677529  0.50309405\n",
      "  1.21737265  0.55177335  1.13564245  0.01460349 -0.08886959  0.39898697\n",
      "  0.86341402  0.36962162]\n",
      "New theta_0 : [ 0.29910628  0.02538162  0.63681908  0.42294673  0.45516302  0.49985525\n",
      "  1.20646104  0.54515841  1.12025268  0.01113668 -0.09502783  0.3898352\n",
      "  0.84810755  0.3604022 ]\n",
      "Training Error:  29.959700035620987\n",
      "====================================================================================================\n",
      "Iteration:  46\n",
      "Previous theta :  [ 0.29910628  0.02538162  0.63681908  0.42294673  0.45516302  0.49985525\n",
      "  1.20646104  0.54515841  1.12025268  0.01113668 -0.09502783  0.3898352\n",
      "  0.84810755  0.3604022 ]\n",
      "New theta_0 : [ 0.28896045  0.02113764  0.62113705  0.4194251   0.4438457   0.49660933\n",
      "  1.1957223   0.53855585  1.10512354  0.00790407 -0.10094816  0.38082454\n",
      "  0.83308626  0.3512516 ]\n",
      "Training Error:  29.516139904466176\n",
      "====================================================================================================\n",
      "Iteration:  47\n",
      "Previous theta :  [ 0.28896045  0.02113764  0.62113705  0.4194251   0.4438457   0.49660933\n",
      "  1.1957223   0.53855585  1.10512354  0.00790407 -0.10094816  0.38082454\n",
      "  0.83308626  0.3512516 ]\n",
      "New theta_0 : [ 0.2791658   0.01709929  0.60587227  0.41592044  0.43281665  0.49335716\n",
      "  1.18515204  0.53196902  1.09024811  0.00489527 -0.10663996  0.37195235\n",
      "  0.8183462   0.34217075]\n",
      "Training Error:  29.084650142166165\n",
      "====================================================================================================\n",
      "Iteration:  48\n",
      "Previous theta :  [ 0.2791658   0.01709929  0.60587227  0.41592044  0.43281665  0.49335716\n",
      "  1.18515204  0.53196902  1.09024811  0.00489527 -0.10663996  0.37195235\n",
      "  0.8183462   0.34217075]\n",
      "New theta_0 : [ 0.26971025  0.01325689  0.59101198  0.4124333   0.42206928  0.49009964\n",
      "  1.17474597  0.52540111  1.07561965  0.00210039 -0.11211222  0.36321607\n",
      "  0.80388334  0.33316054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  28.664816315600397\n",
      "====================================================================================================\n",
      "Iteration:  49\n",
      "Previous theta :  [ 0.26971025  0.01325689  0.59101198  0.4124333   0.42206928  0.49009964\n",
      "  1.17474597  0.52540111  1.07561965  0.00210039 -0.11211222  0.36321607\n",
      "  0.80388334  0.33316054]\n",
      "New theta_0 : [ 2.60582152e-01  9.60122594e-03  5.76543844e-01  4.08964231e-01\n",
      "  4.11597134e-01  4.86837650e-01  1.16449995e+00  5.18855173e-01\n",
      "  1.06123164e+00 -4.90019999e-04 -1.17373491e-01  3.54613235e-01\n",
      "  7.89693662e-01  3.24221800e-01]\n",
      "Training Error:  28.25624140960203\n",
      "====================================================================================================\n",
      "Iteration:  50\n",
      "Previous theta :  [ 2.60582152e-01  9.60122594e-03  5.76543844e-01  4.08964231e-01\n",
      "  4.11597134e-01  4.86837650e-01  1.16449995e+00  5.18855173e-01\n",
      "  1.06123164e+00 -4.90019999e-04 -1.17373491e-01  3.54613235e-01\n",
      "  7.89693662e-01  3.24221800e-01]\n",
      "New theta_0 : [ 0.25177022  0.00612355  0.56245595  0.40551378  0.40139387  0.48357207\n",
      "  1.15440996  0.51233407  1.04707772 -0.00288494 -0.12243194  0.34614148\n",
      "  0.77577309  0.31535532]\n",
      "Training Error:  27.85854499958997\n",
      "====================================================================================================\n",
      "Iteration:  51\n",
      "Previous theta :  [ 0.25177022  0.00612355  0.56245595  0.40551378  0.40139387  0.48357207\n",
      "  1.15440996  0.51233407  1.04707772 -0.00288494 -0.12243194  0.34614148\n",
      "  0.77577309  0.31535532]\n",
      "New theta_0 : [ 0.24326359  0.00281551  0.54873679  0.40208246  0.39145324  0.48030373\n",
      "  1.14447212  0.50584053  1.03315178 -0.00509298 -0.12729539  0.33779851\n",
      "  0.76211756  0.30656183]\n",
      "Training Error:  27.47136246506209\n",
      "====================================================================================================\n",
      "Iteration:  52\n",
      "Previous theta :  [ 0.24326359  0.00281551  0.54873679  0.40208246  0.39145324  0.48030373\n",
      "  1.14447212  0.50584053  1.03315178 -0.00509298 -0.12729539  0.33779851\n",
      "  0.76211756  0.30656183]\n",
      "New theta_0 : [ 2.35051730e-01 -3.30818679e-04  5.35375249e-01  3.98670782e-01\n",
      "  3.81769132e-01  4.77033482e-01  1.13468266e+00  4.99377107e-01\n",
      "  1.01944789e+00 -7.12232100e-03 -1.31971325e-01  3.29582080e-01\n",
      "  7.48722966e-01  2.97842009e-01]\n",
      "Training Error:  27.09434424195974\n",
      "====================================================================================================\n",
      "Iteration:  53\n",
      "Previous theta :  [ 2.35051730e-01 -3.30818679e-04  5.35375249e-01  3.98670782e-01\n",
      "  3.81769132e-01  4.77033482e-01  1.13468266e+00  4.99377107e-01\n",
      "  1.01944789e+00 -7.12232100e-03 -1.31971325e-01  3.29582080e-01\n",
      "  7.48722966e-01  2.97842009e-01]\n",
      "New theta_0 : [ 0.2271245  -0.00332302  0.52236061  0.39527923  0.37233553  0.4737621\n",
      "  1.12503795  0.49294623  1.0059603  -0.00898082 -0.1364669   0.32149003\n",
      "  0.73558524  0.28919647]\n",
      "Training Error:  26.727155112031905\n",
      "====================================================================================================\n",
      "Iteration:  54\n",
      "Previous theta :  [ 0.2271245  -0.00332302  0.52236061  0.39527923  0.37233553  0.4737621\n",
      "  1.12503795  0.49294623  1.0059603  -0.00898082 -0.1364669   0.32149003\n",
      "  0.73558524  0.28919647]\n",
      "New theta_0 : [ 0.21947209 -0.00616831  0.50968252  0.39190826  0.36314652  0.47049037\n",
      "  1.11553448  0.48655015  0.99268346 -0.01067598 -0.14078897  0.31352026\n",
      "  0.72270028  0.28062578]\n",
      "Training Error:  26.369473527423555\n",
      "====================================================================================================\n",
      "Iteration:  55\n",
      "Previous theta :  [ 0.21947209 -0.00616831  0.50968252  0.39190826  0.36314652  0.47049037\n",
      "  1.11553448  0.48655015  0.99268346 -0.01067598 -0.14078897  0.31352026\n",
      "  0.72270028  0.28062578]\n",
      "New theta_0 : [ 0.21208503 -0.00887356  0.49733099  0.38855829  0.35419633  0.467219\n",
      "  1.10616887  0.48019101  0.97961201 -0.01221495 -0.14494411  0.3056707\n",
      "  0.71006404  0.27213042]\n",
      "Training Error:  26.020990968794948\n",
      "====================================================================================================\n",
      "Iteration:  56\n",
      "Previous theta :  [ 0.21208503 -0.00887356  0.49733099  0.38855829  0.35419633  0.467219\n",
      "  1.10616887  0.48019101  0.97961201 -0.01221495 -0.14494411  0.3056707\n",
      "  0.71006404  0.27213042]\n",
      "New theta_0 : [ 0.20495416 -0.01144533  0.48529637  0.38522972  0.34547928  0.46394871\n",
      "  1.09693784  0.4738708   0.96674076 -0.01360461 -0.14893863  0.29793936\n",
      "  0.69767245  0.26371085]\n",
      "Training Error:  25.681411335352898\n",
      "====================================================================================================\n",
      "Iteration:  57\n",
      "Previous theta :  [ 0.20495416 -0.01144533  0.48529637  0.38522972  0.34547928  0.46394871\n",
      "  1.09693784  0.4738708   0.96674076 -0.01360461 -0.14893863  0.29793936\n",
      "  0.69767245  0.26371085]\n",
      "New theta_0 : [ 0.19807066 -0.0138899   0.47356934  0.38192293  0.33698978  0.46068016\n",
      "  1.08783823  0.46759135  0.9540647  -0.01485151 -0.15277856  0.29032427\n",
      "  0.68552147  0.25536744]\n",
      "Training Error:  25.35045036524388\n",
      "====================================================================================================\n",
      "Iteration:  58\n",
      "Previous theta :  [ 0.19807066 -0.0138899   0.47356934  0.38192293  0.33698978  0.46068016\n",
      "  1.08783823  0.46759135  0.9540647  -0.01485151 -0.15277856  0.29032427\n",
      "  0.68552147  0.25536744]\n",
      "New theta_0 : [ 0.19142599 -0.01621322  0.46214092  0.37863824  0.32872239  0.45741398\n",
      "  1.07886698  0.46135442  0.94157899 -0.01596195 -0.15646971  0.28282353\n",
      "  0.6736071   0.24710054]\n",
      "Training Error:  25.027835084824233\n",
      "====================================================================================================\n",
      "Iteration:  59\n",
      "Previous theta :  [ 0.19142599 -0.01621322  0.46214092  0.37863824  0.32872239  0.45741398\n",
      "  1.07886698  0.46135442  0.94157899 -0.01596195 -0.15646971  0.28282353\n",
      "  0.6736071   0.24710054]\n",
      "New theta_0 : [ 0.1850119  -0.018421    0.45100244  0.37537597  0.32067175  0.45415079\n",
      "  1.07002116  0.4551616   0.92927894 -0.01694194 -0.16001763  0.27543527\n",
      "  0.66192535  0.23891041]\n",
      "Training Error:  24.713303285385887\n",
      "====================================================================================================\n",
      "Iteration:  60\n",
      "Previous theta :  [ 0.1850119  -0.018421    0.45100244  0.37537597  0.32067175  0.45415079\n",
      "  1.07002116  0.4551616   0.92927894 -0.01694194 -0.16001763  0.27543527\n",
      "  0.66192535  0.23891041]\n",
      "New theta_0 : [ 0.17882043 -0.02051868  0.44014551  0.37213639  0.31283262  0.45089114\n",
      "  1.06129793  0.44901438  0.91716003 -0.01779723 -0.16342768  0.26815766\n",
      "  0.65047226  0.23079728]\n",
      "Training Error:  24.40660302597748\n",
      "====================================================================================================\n",
      "Iteration:  61\n",
      "Previous theta :  [ 0.17882043 -0.02051868  0.44014551  0.37213639  0.31283262  0.45089114\n",
      "  1.06129793  0.44901438  0.91716003 -0.01779723 -0.16342768  0.26815766\n",
      "  0.65047226  0.23079728]\n",
      "New theta_0 : [ 0.1728439  -0.02251146  0.42956204  0.36891976  0.30519985  0.44763558\n",
      "  1.05269453  0.44291415  0.90521788 -0.01853335 -0.16670497  0.26098892\n",
      "  0.63924389  0.22276133]\n",
      "Training Error:  24.107492161020183\n",
      "====================================================================================================\n",
      "Iteration:  62\n",
      "Previous theta :  [ 0.1728439  -0.02251146  0.42956204  0.36891976  0.30519985  0.44763558\n",
      "  1.05269453  0.44291415  0.90521788 -0.01853335 -0.16670497  0.26098892\n",
      "  0.63924389  0.22276133]\n",
      "New theta_0 : [ 0.16707487 -0.02440429  0.41924423  0.36572631  0.29776842  0.44438461\n",
      "  1.04420832  0.43686217  0.89344827 -0.01915558 -0.16985443  0.25392728\n",
      "  0.62823637  0.21480268]\n",
      "Training Error:  23.815737891475912\n",
      "====================================================================================================\n",
      "Iteration:  63\n",
      "Previous theta :  [ 0.16707487 -0.02440429  0.41924423  0.36572631  0.29776842  0.44438461\n",
      "  1.04420832  0.43686217  0.89344827 -0.01915558 -0.16985443  0.25392728\n",
      "  0.62823637  0.21480268]\n",
      "New theta_0 : [ 0.16150619 -0.0262019   0.40918452  0.36255623  0.2905334   0.44113873\n",
      "  1.03583673  0.43085962  0.88184711 -0.019669   -0.1728808   0.24697104\n",
      "  0.61744582  0.20692143]\n",
      "Training Error:  23.531116338381892\n",
      "====================================================================================================\n",
      "Iteration:  64\n",
      "Previous theta :  [ 0.16150619 -0.0262019   0.40918452  0.36255623  0.2905334   0.44113873\n",
      "  1.03583673  0.43085962  0.88184711 -0.019669   -0.1728808   0.24697104\n",
      "  0.61744582  0.20692143]\n",
      "New theta_0 : [ 0.15613091 -0.02790881  0.39937563  0.3594097   0.28348996  0.43789837\n",
      "  1.02757731  0.42490757  0.87041045 -0.02007844 -0.1757886   0.24011851\n",
      "  0.60686844  0.1991176 ]\n",
      "Training Error:  23.253412137620813\n",
      "====================================================================================================\n",
      "Iteration:  65\n",
      "Previous theta :  [ 0.15613091 -0.02790881  0.39937563  0.3594097   0.28348996  0.43789837\n",
      "  1.02757731  0.42490757  0.87041045 -0.02007844 -0.1757886   0.24011851\n",
      "  0.60686844  0.1991176 ]\n",
      "New theta_0 : [ 0.15094235 -0.02952935  0.38981052  0.35628686  0.27663338  0.43466398\n",
      "  1.01942766  0.419007    0.85913446 -0.02038856 -0.17858222  0.23336805\n",
      "  0.59650043  0.1913912 ]\n",
      "Training Error:  22.982418054848686\n",
      "====================================================================================================\n",
      "Iteration:  66\n",
      "Previous theta :  [ 0.15094235 -0.02952935  0.38981052  0.35628686  0.27663338  0.43466398\n",
      "  1.01942766  0.419007    0.85913446 -0.02038856 -0.17858222  0.23336805\n",
      "  0.59650043  0.1913912 ]\n",
      "New theta_0 : [ 0.14593406 -0.03106762  0.38048238  0.35318786  0.26995903  0.43143595\n",
      "  1.01138547  0.41315881  0.84801544 -0.02060382 -0.18126585  0.22671802\n",
      "  0.58633807  0.18374219]\n",
      "Training Error:  22.717934619554196\n",
      "====================================================================================================\n",
      "Iteration:  67\n",
      "Previous theta :  [ 0.14593406 -0.03106762  0.38048238  0.35318786  0.26995903  0.43143595\n",
      "  1.01138547  0.41315881  0.84801544 -0.02060382 -0.18126585  0.22671802\n",
      "  0.58633807  0.18374219]\n",
      "New theta_0 : [ 0.14109979 -0.03252756  0.37138463  0.35011279  0.2634624   0.42821467\n",
      "  1.00344851  0.40736381  0.83704982 -0.02072848 -0.18384351  0.22016685\n",
      "  0.57637764  0.17617048]\n",
      "Training Error:  22.459769777272783\n",
      "====================================================================================================\n",
      "Iteration:  68\n",
      "Previous theta :  [ 0.14109979 -0.03252756  0.37138463  0.35011279  0.2634624   0.42821467\n",
      "  1.00344851  0.40736381  0.83704982 -0.02072848 -0.18384351  0.22016685\n",
      "  0.57637764  0.17617048]\n",
      "New theta_0 : [ 0.13643352 -0.03391294  0.36251092  0.34706175  0.25713907  0.42500048\n",
      "  0.99561464  0.40162274  0.82623413 -0.02076664 -0.18631909  0.21371297\n",
      "  0.56661549  0.16867595]\n",
      "Training Error:  22.207738559026712\n",
      "====================================================================================================\n",
      "Iteration:  69\n",
      "Previous theta :  [ 0.13643352 -0.03391294  0.36251092  0.34706175  0.25713907  0.42500048\n",
      "  0.99561464  0.40162274  0.82623413 -0.02076664 -0.18631909  0.21371297\n",
      "  0.56661549  0.16867595]\n",
      "New theta_0 : [ 0.13192943 -0.03522732  0.3538551   0.34403479  0.2509847   0.42179373\n",
      "  0.98788178  0.39593624  0.81556503 -0.02072223 -0.18869631  0.20735486\n",
      "  0.55704802  0.16125847]\n",
      "Training Error:  21.961662767107903\n",
      "====================================================================================================\n",
      "Iteration:  70\n",
      "Previous theta :  [ 0.13192943 -0.03522732  0.3538551   0.34403479  0.2509847   0.42179373\n",
      "  0.98788178  0.39593624  0.81556503 -0.02072223 -0.18869631  0.20735486\n",
      "  0.55704802  0.16125847]\n",
      "New theta_0 : [ 0.12758191 -0.03647415  0.34541122  0.34103198  0.24499507  0.41859472\n",
      "  0.9802479   0.39030492  0.80503927 -0.020599   -0.19097875  0.20109102\n",
      "  0.54767165  0.15391784]\n",
      "Training Error:  21.721370676364845\n",
      "====================================================================================================\n",
      "Iteration:  71\n",
      "Previous theta :  [ 0.12758191 -0.03647415  0.34541122  0.34103198  0.24499507  0.41859472\n",
      "  0.9802479   0.39030492  0.80503927 -0.020599   -0.19097875  0.20109102\n",
      "  0.54767165  0.15391784]\n",
      "New theta_0 : [ 0.12338552 -0.0376567   0.33717355  0.33805334  0.23916604  0.41540375\n",
      "  0.97271106  0.38472928  0.7946537  -0.02040057 -0.19316987  0.19491996\n",
      "  0.53848286  0.14665386]\n",
      "Training Error:  21.486696750196487\n",
      "====================================================================================================\n",
      "Iteration:  72\n",
      "Previous theta :  [ 0.12338552 -0.0376567   0.33717355  0.33805334  0.23916604  0.41540375\n",
      "  0.97271106  0.38472928  0.7946537  -0.02040057 -0.19316987  0.19491996\n",
      "  0.53848286  0.14665386]\n",
      "New theta_0 : [ 0.11933503 -0.03877807  0.32913653  0.33509889  0.23349357  0.4122211\n",
      "  0.96526938  0.37920978  0.78440529 -0.02013038 -0.19527297  0.18884024\n",
      "  0.52947817  0.13946629]\n",
      "Training Error:  21.257481370496848\n",
      "====================================================================================================\n",
      "Iteration:  73\n",
      "Previous theta :  [ 0.11933503 -0.03877807  0.32913653  0.33509889  0.23349357  0.4122211\n",
      "  0.96526938  0.37920978  0.78440529 -0.02013038 -0.19527297  0.18884024\n",
      "  0.52947817  0.13946629]\n",
      "New theta_0 : [ 0.11542539 -0.03984126  0.32129476  0.33216863  0.2279737   0.40904702\n",
      "  0.95792104  0.37374682  0.77429109 -0.01979176 -0.19729125  0.18285043\n",
      "  0.52065415  0.13235484]\n",
      "Training Error:  21.033570580832286\n",
      "====================================================================================================\n",
      "Iteration:  74\n",
      "Previous theta :  [ 0.11542539 -0.03984126  0.32129476  0.33216863  0.2279737   0.40904702\n",
      "  0.95792104  0.37374682  0.77429109 -0.01979176 -0.19729125  0.18285043\n",
      "  0.52065415  0.13235484]\n",
      "New theta_0 : [ 0.1116517  -0.04084912  0.31364306  0.32926255  0.22260258  0.40588176\n",
      "  0.95066426  0.36834073  0.76430823 -0.01938788 -0.19922778  0.17694913\n",
      "  0.51200743  0.12531924]\n",
      "Training Error:  20.814815842170233\n",
      "====================================================================================================\n",
      "Iteration:  75\n",
      "Previous theta :  [ 0.1116517  -0.04084912  0.31364306  0.32926255  0.22260258  0.40588176\n",
      "  0.95066426  0.36834073  0.76430823 -0.01938788 -0.19922778  0.17694913\n",
      "  0.51200743  0.12531924]\n",
      "New theta_0 : [ 0.10800925 -0.04180437  0.30617638  0.32638063  0.21737643  0.40272554\n",
      "  0.94349735  0.36299179  0.75445396 -0.01892179 -0.20108549  0.17113497\n",
      "  0.50353466  0.11835917]\n",
      "Training Error:  20.601073800513227\n",
      "====================================================================================================\n",
      "Iteration:  76\n",
      "Previous theta :  [ 0.10800925 -0.04180437  0.30617638  0.32638063  0.21737643  0.40272554\n",
      "  0.94349735  0.36299179  0.75445396 -0.01892179 -0.20108549  0.17113497\n",
      "  0.50353466  0.11835917]\n",
      "New theta_0 : [ 0.10449348 -0.04270959  0.29888984  0.32352282  0.21229156  0.39957858\n",
      "  0.93641865  0.35770025  0.74472559 -0.01839641 -0.20286724  0.1654066\n",
      "  0.49523255  0.11147427]\n",
      "Training Error:  20.392206065825487\n",
      "====================================================================================================\n",
      "Iteration:  77\n",
      "Previous theta :  [ 0.10449348 -0.04270959  0.29888984  0.32352282  0.21229156  0.39957858\n",
      "  0.93641865  0.35770025  0.74472559 -0.01839641 -0.20286724  0.1654066\n",
      "  0.49523255  0.11147427]\n",
      "New theta_0 : [ 0.1011     -0.04356728  0.29177874  0.32068908  0.20734437  0.39644107\n",
      "  0.92942654  0.35246627  0.73512052 -0.01781456 -0.20457576  0.15976268\n",
      "  0.48709787  0.10466419]\n",
      "Training Error:  20.1880790016709\n",
      "====================================================================================================\n",
      "Iteration:  78\n",
      "Previous theta :  [ 0.1011     -0.04356728  0.29177874  0.32068908  0.20734437  0.39644107\n",
      "  0.92942654  0.35246627  0.73512052 -0.01781456 -0.20457576  0.15976268\n",
      "  0.48709787  0.10466419]\n",
      "New theta_0 : [ 0.09782457 -0.04437979  0.28483848  0.31787934  0.20253136  0.3933132\n",
      "  0.92251949  0.34729     0.72563622 -0.0171789  -0.20621367  0.15420191\n",
      "  0.47912743  0.09792854]\n",
      "Training Error:  19.98856352501172\n",
      "====================================================================================================\n",
      "Iteration:  79\n",
      "Previous theta :  [ 0.09782457 -0.04437979  0.28483848  0.31787934  0.20253136  0.3933132\n",
      "  0.92251949  0.34729     0.72563622 -0.0171789  -0.20621367  0.15420191\n",
      "  0.47912743  0.09792854]\n",
      "New theta_0 : [ 0.09466308 -0.0451494   0.27806466  0.31509354  0.19784907  0.39019513\n",
      "  0.91569599  0.34217152  0.71627025 -0.01649204 -0.20778352  0.148723\n",
      "  0.47131807  0.09126693]\n",
      "Training Error:  19.793534915645726\n",
      "====================================================================================================\n",
      "Iteration:  80\n",
      "Previous theta :  [ 0.09466308 -0.0451494   0.27806466  0.31509354  0.19784907  0.39019513\n",
      "  0.91569599  0.34217152  0.71627025 -0.01649204 -0.20778352  0.148723\n",
      "  0.47131807  0.09126693]\n",
      "New theta_0 : [ 0.09161157 -0.04587824  0.27145297  0.3123316   0.19329417  0.38708704\n",
      "  0.90895456  0.3371109   0.70702022 -0.01575643 -0.20928773  0.14332469\n",
      "  0.4636667   0.08467893]\n",
      "Training Error:  19.602872634787094\n",
      "====================================================================================================\n",
      "Iteration:  81\n",
      "Previous theta :  [ 0.09161157 -0.04587824  0.27145297  0.3123316   0.19329417  0.38708704\n",
      "  0.90895456  0.3371109   0.70702022 -0.01575643 -0.20928773  0.14332469\n",
      "  0.4636667   0.08467893]\n",
      "New theta_0 : [ 0.08866622 -0.0465684   0.26499926  0.30959342  0.18886336  0.38398905\n",
      "  0.9022938   0.33210815  0.69788384 -0.01497444 -0.21072865  0.13800574\n",
      "  0.45617027  0.07816411]\n",
      "Training Error:  19.416460152321957\n",
      "====================================================================================================\n",
      "Iteration:  82\n",
      "Previous theta :  [ 0.08866622 -0.0465684   0.26499926  0.30959342  0.18886336  0.38398905\n",
      "  0.9022938   0.33210815  0.69788384 -0.01497444 -0.21072865  0.13800574\n",
      "  0.45617027  0.07816411]\n",
      "New theta_0 : [ 0.08582334 -0.04722182  0.25869951  0.30687892  0.18455347  0.38090133\n",
      "  0.89571234  0.32716323  0.68885886 -0.01414836 -0.21210855  0.13276492\n",
      "  0.44882579  0.07172202]\n",
      "Training Error:  19.234184782294385\n",
      "====================================================================================================\n",
      "Iteration:  83\n",
      "Previous theta :  [ 0.08582334 -0.04722182  0.25869951  0.30687892  0.18455347  0.38090133\n",
      "  0.89571234  0.32716323  0.68885886 -0.01414836 -0.21210855  0.13276492\n",
      "  0.44882579  0.07172202]\n",
      "New theta_0 : [ 0.08307937 -0.0478404   0.2525498   0.30418798  0.18036137  0.37782398\n",
      "  0.88920882  0.3222761   0.67994312 -0.01328037 -0.2134296   0.12760103\n",
      "  0.44163029  0.06535218]\n",
      "Training Error:  19.05593752620158\n",
      "====================================================================================================\n",
      "Iteration:  84\n",
      "Previous theta :  [ 0.08307937 -0.0478404   0.2525498   0.30418798  0.18036137  0.37782398\n",
      "  0.88920882  0.3222761   0.67994312 -0.01328037 -0.2134296   0.12760103\n",
      "  0.44163029  0.06535218]\n",
      "New theta_0 : [ 0.08043087 -0.04842592  0.24654637  0.3015205   0.17628402  0.37475714\n",
      "  0.88278197  0.31744666  0.6711345  -0.01237255 -0.2146939   0.12251288\n",
      "  0.43458087  0.05905412]\n",
      "Training Error:  18.88161292369948\n",
      "====================================================================================================\n",
      "Iteration:  85\n",
      "Previous theta :  [ 0.08043087 -0.04842592  0.24654637  0.3015205   0.17628402  0.37475714\n",
      "  0.88278197  0.31744666  0.6711345  -0.01237255 -0.2146939   0.12251288\n",
      "  0.43458087  0.05905412]\n",
      "New theta_0 : [ 0.07787451 -0.04898008  0.24068552  0.29887635  0.17231844  0.37170091\n",
      "  0.87643051  0.31267479  0.66243094 -0.01142692 -0.21590346  0.11749932\n",
      "  0.42767468  0.05282736]\n",
      "Training Error:  18.71110891034075\n",
      "====================================================================================================\n",
      "Iteration:  86\n",
      "Previous theta :  [ 0.07787451 -0.04898008  0.24068552  0.29887635  0.17231844  0.37170091\n",
      "  0.87643051  0.31267479  0.66243094 -0.01142692 -0.21590346  0.11749932\n",
      "  0.42767468  0.05282736]\n",
      "New theta_0 : [ 0.0754071  -0.04950454  0.23496372  0.29625541  0.16846173  0.36865539\n",
      "  0.87015323  0.30796035  0.65383046 -0.0104454  -0.21706023  0.11255919\n",
      "  0.4209089   0.04667137]\n",
      "Training Error:  18.544326681987094\n",
      "====================================================================================================\n",
      "Iteration:  87\n",
      "Previous theta :  [ 0.0754071  -0.04950454  0.23496372  0.29625541  0.16846173  0.36865539\n",
      "  0.87015323  0.30796035  0.65383046 -0.0104454  -0.21706023  0.11255919\n",
      "  0.4209089   0.04667137]\n",
      "New theta_0 : [ 0.07302553 -0.05000083  0.22937749  0.29365756  0.16471107  0.36562067\n",
      "  0.86394893  0.30330315  0.64533113 -0.00942983 -0.21816608  0.10769137\n",
      "  0.41428077  0.04058566]\n",
      "Training Error:  18.381170565556513\n",
      "====================================================================================================\n",
      "Iteration:  88\n",
      "Previous theta :  [ 0.07302553 -0.05000083  0.22937749  0.29365756  0.16471107  0.36562067\n",
      "  0.86394893  0.30330315  0.64533113 -0.00942983 -0.21816608  0.10769137\n",
      "  0.41428077  0.04058566]\n",
      "New theta_0 : [ 0.07072682 -0.05047045  0.2239235   0.29108267  0.1610637   0.36259686\n",
      "  0.85781647  0.298703    0.63693104 -0.008382   -0.21922282  0.10289474\n",
      "  0.40778756  0.03456969]\n",
      "Training Error:  18.221547895784283\n",
      "====================================================================================================\n",
      "Iteration:  89\n",
      "Previous theta :  [ 0.07072682 -0.05047045  0.2239235   0.29108267  0.1610637   0.36259686\n",
      "  0.85781647  0.298703    0.63693104 -0.008382   -0.21922282  0.10289474\n",
      "  0.40778756  0.03456969]\n",
      "New theta_0 : [ 0.06850807 -0.05091482  0.2185985   0.28853058  0.15751693  0.35958401\n",
      "  0.8517547   0.29415967  0.62862839 -0.0073036  -0.22023219  0.09816823\n",
      "  0.40142662  0.02862294]\n",
      "Training Error:  18.065368897692956\n",
      "====================================================================================================\n",
      "Iteration:  90\n",
      "Previous theta :  [ 0.06850807 -0.05091482  0.2185985   0.28853058  0.15751693  0.35958401\n",
      "  0.8517547   0.29415967  0.62862839 -0.0073036  -0.22023219  0.09816823\n",
      "  0.40142662  0.02862294]\n",
      "New theta_0 : [ 0.06636652 -0.05133529  0.21339932  0.28600116  0.15406812  0.35658221\n",
      "  0.84576255  0.28967292  0.62042137 -0.00619626 -0.22119587  0.09351074\n",
      "  0.3951953   0.02274486]\n",
      "Training Error:  17.912546574482935\n",
      "====================================================================================================\n",
      "Iteration:  91\n",
      "Previous theta :  [ 0.06636652 -0.05133529  0.21339932  0.28600116  0.15406812  0.35658221\n",
      "  0.84576255  0.28967292  0.62042137 -0.00619626 -0.22119587  0.09351074\n",
      "  0.3951953   0.02274486]\n",
      "New theta_0 : [ 0.06429946 -0.05173316  0.20832291  0.28349426  0.15071473  0.35359152\n",
      "  0.83983894  0.28524246  0.61230827 -0.00506154 -0.22211546  0.08892124\n",
      "  0.38909104  0.0169349 ]\n",
      "Training Error:  17.76299660057033\n",
      "====================================================================================================\n",
      "Iteration:  92\n",
      "Previous theta :  [ 0.06429946 -0.05173316  0.20832291  0.28349426  0.15071473  0.35359152\n",
      "  0.83983894  0.28524246  0.61230827 -0.00506154 -0.22211546  0.08892124\n",
      "  0.38909104  0.0169349 ]\n",
      "New theta_0 : [ 0.06230431 -0.05210965  0.20336629  0.28100974  0.14745424  0.350612\n",
      "  0.83398283  0.28086802  0.60428739 -0.00390095 -0.22299254  0.08439866\n",
      "  0.38311129  0.01119251]\n",
      "Training Error:  17.616637219512977\n",
      "====================================================================================================\n",
      "Iteration:  93\n",
      "Previous theta :  [ 0.06230431 -0.05210965  0.20336629  0.28100974  0.14745424  0.350612\n",
      "  0.83398283  0.28086802  0.60428739 -0.00390095 -0.22299254  0.08439866\n",
      "  0.38311129  0.01119251]\n",
      "New theta_0 : [ 0.06037855 -0.05246594  0.19852658  0.27854743  0.14428424  0.34764371\n",
      "  0.82819321  0.2765493   0.5963571  -0.00271592 -0.22382859  0.079942\n",
      "  0.37725356  0.00551713]\n",
      "Training Error:  17.473389146579297\n",
      "====================================================================================================\n",
      "Iteration:  94\n",
      "Previous theta :  [ 0.06037855 -0.05246594  0.19852658  0.27854743  0.14428424  0.34764371\n",
      "  0.82819321  0.2765493   0.5963571  -0.00271592 -0.22382859  0.079942\n",
      "  0.37725356  0.00551713]\n",
      "New theta_0 : [ 5.85197645e-02 -5.28031490e-02  1.93800963e-01  2.76107186e-01\n",
      "  1.41202334e-01  3.44686702e-01  8.22469101e-01  2.72285952e-01\n",
      "  5.88515791e-01 -1.50783631e-03 -2.24625077e-01  7.55502419e-02\n",
      "  3.71515416e-01 -9.18191547e-05]\n",
      "Training Error:  17.333175475727405\n",
      "====================================================================================================\n",
      "Iteration:  95\n",
      "Previous theta :  [ 5.85197645e-02 -5.28031490e-02  1.93800963e-01  2.76107186e-01\n",
      "  1.41202334e-01  3.44686702e-01  8.22469101e-01  2.72285952e-01\n",
      "  5.88515791e-01 -1.50783631e-03 -2.24625077e-01  7.55502419e-02\n",
      "  3.71515416e-01 -9.18191547e-05]\n",
      "New theta_0 : [ 5.67256229e-02 -5.31223504e-02  1.89186726e-01  2.73688844e-01\n",
      "  1.38206217e-01  3.41741012e-01  8.16809538e-01  2.68077655e-01\n",
      "  5.80761915e-01 -2.78024714e-04 -2.25383384e-01  7.12223922e-02\n",
      "  3.65894442e-01 -5.63489792e-03]\n",
      "Training Error:  17.19592159077409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  96\n",
      "Previous theta :  [ 5.67256229e-02 -5.31223504e-02  1.89186726e-01  2.73688844e-01\n",
      "  1.38206217e-01  3.41741012e-01  8.16809538e-01  2.68077655e-01\n",
      "  5.80761915e-01 -2.78024714e-04 -2.25383384e-01  7.12223922e-02\n",
      "  3.65894442e-01 -5.63489792e-03]\n",
      "New theta_0 : [ 0.05499387 -0.05342456  0.18468122  0.27129224  0.13529363  0.33880668\n",
      "  0.81121358  0.26392405  0.57309395  0.00097225 -0.22610486  0.06695748\n",
      "  0.36038828 -0.01111269]\n",
      "Training Error:  17.06155508054486\n",
      "====================================================================================================\n",
      "Iteration:  97\n",
      "Previous theta :  [ 0.05499387 -0.05342456  0.18468122  0.27129224  0.13529363  0.33880668\n",
      "  0.81121358  0.26392405  0.57309395  0.00097225 -0.22610486  0.06695748\n",
      "  0.36038828 -0.01111269]\n",
      "New theta_0 : [ 0.05332233 -0.05371076  0.18028187  0.26891722  0.13246237  0.33588375\n",
      "  0.80568033  0.25982477  0.56551043  0.00224176 -0.2267908   0.06275453\n",
      "  0.35499462 -0.01652577]\n",
      "Training Error:  16.930005657807033\n",
      "====================================================================================================\n",
      "Iteration:  98\n",
      "Previous theta :  [ 0.05332233 -0.05371076  0.18028187  0.26891722  0.13246237  0.33588375\n",
      "  0.80568033  0.25982477  0.56551043  0.00224176 -0.2267908   0.06275453\n",
      "  0.35499462 -0.01652577]\n",
      "New theta_0 : [ 0.05170889 -0.05398186  0.17598618  0.26656362  0.1297103   0.33297225\n",
      "  0.80020887  0.25577943  0.55800992  0.00352934 -0.22744247  0.05861261\n",
      "  0.34971117 -0.02187472]\n",
      "Training Error:  16.801205081798372\n",
      "====================================================================================================\n",
      "Iteration:  99\n",
      "Previous theta :  [ 0.05170889 -0.05398186  0.17598618  0.26656362  0.1297103   0.33297225\n",
      "  0.80020887  0.25577943  0.55800992  0.00352934 -0.22744247  0.05861261\n",
      "  0.34971117 -0.02187472]\n",
      "New theta_0 : [ 0.05015155 -0.05423876  0.17179171  0.26423126  0.12703532  0.33007221\n",
      "  0.79479835  0.25178764  0.550591    0.00483387 -0.22806106  0.05453079\n",
      "  0.34453571 -0.02716014]\n",
      "Training Error:  16.675087084173295\n",
      "====================================================================================================\n",
      "Iteration:  100\n",
      "Previous theta :  [ 0.05015155 -0.05423876  0.17179171  0.26423126  0.12703532  0.33007221\n",
      "  0.79479835  0.25178764  0.550591    0.00483387 -0.22806106  0.05453079\n",
      "  0.34453571 -0.02716014]\n",
      "New theta_0 : [ 0.04864832 -0.05448229  0.1676961   0.26191998  0.1244354   0.32718365\n",
      "  0.78944791  0.247849    0.54325232  0.00615427 -0.22864774  0.05050814\n",
      "  0.33946605 -0.03238261]\n",
      "Training Error:  16.551587298198218\n",
      "====================================================================================================\n",
      "Iteration:  101\n",
      "Previous theta :  [ 0.04864832 -0.05448229  0.1676961   0.26191998  0.1244354   0.32718365\n",
      "  0.78944791  0.247849    0.54325232  0.00615427 -0.22864774  0.05050814\n",
      "  0.33946605 -0.03238261]\n",
      "New theta_0 : [ 0.04719734 -0.05471326  0.16369706  0.25962962  0.12190855  0.32430659\n",
      "  0.78415673  0.24396309  0.53599254  0.00748952 -0.22920364  0.04654377\n",
      "  0.33450003 -0.03754272]\n",
      "Training Error:  16.43064319103607\n",
      "====================================================================================================\n",
      "Iteration:  102\n",
      "Previous theta :  [ 0.04719734 -0.05471326  0.16369706  0.25962962  0.12190855  0.32430659\n",
      "  0.78415673  0.24396309  0.53599254  0.00748952 -0.22920364  0.04654377\n",
      "  0.33450003 -0.03754272]\n",
      "New theta_0 : [ 0.04579677 -0.05493243  0.15979235  0.25735999  0.11945283  0.32144105\n",
      "  0.77892398  0.24012949  0.52881036  0.00883861 -0.22972984  0.04263678\n",
      "  0.32963555 -0.04264106]\n",
      "Training Error:  16.312193998968542\n",
      "====================================================================================================\n",
      "Iteration:  103\n",
      "Previous theta :  [ 0.04579677 -0.05493243  0.15979235  0.25735999  0.11945283  0.32144105\n",
      "  0.77892398  0.24012949  0.52881036  0.00883861 -0.22972984  0.04263678\n",
      "  0.32963555 -0.04264106]\n",
      "New theta_0 : [ 0.04444485 -0.05514053  0.15597979  0.25511094  0.11706636  0.31858704\n",
      "  0.77374888  0.23634776  0.52170452  0.01020061 -0.23022738  0.0387863\n",
      "  0.32487052 -0.04767824]\n",
      "Training Error:  16.196180665412296\n",
      "====================================================================================================\n",
      "Iteration:  104\n",
      "Previous theta :  [ 0.04444485 -0.05514053  0.15597979  0.25511094  0.11706636  0.31858704\n",
      "  0.77374888  0.23634776  0.52170452  0.01020061 -0.23022738  0.0387863\n",
      "  0.32487052 -0.04767824]\n",
      "New theta_0 : [ 0.04313989 -0.05533826  0.15225728  0.25288229  0.1147473   0.31574458\n",
      "  0.76863066  0.23261748  0.51467379  0.01157461 -0.23069729  0.03499147\n",
      "  0.32020291 -0.05265484]\n",
      "Training Error:  16.082545781592927\n",
      "====================================================================================================\n",
      "Iteration:  105\n",
      "Previous theta :  [ 0.04313989 -0.05533826  0.15225728  0.25288229  0.1147473   0.31574458\n",
      "  0.76863066  0.23261748  0.51467379  0.01157461 -0.23069729  0.03499147\n",
      "  0.32020291 -0.05265484]\n",
      "New theta_0 : [ 0.04188024 -0.05552628  0.14862274  0.25067386  0.11249387  0.31291367\n",
      "  0.76356854  0.22893819  0.50771695  0.01295972 -0.23114053  0.03125145\n",
      "  0.31563074 -0.05757145]\n",
      "Training Error:  15.971233529747451\n",
      "====================================================================================================\n",
      "Iteration:  106\n",
      "Previous theta :  [ 0.04188024 -0.05552628  0.14862274  0.25067386  0.11249387  0.31291367\n",
      "  0.76356854  0.22893819  0.50771695  0.01295972 -0.23114053  0.03125145\n",
      "  0.31563074 -0.05757145]\n",
      "New theta_0 : [ 0.04066433 -0.05570521  0.14507417  0.2484855   0.1103043   0.31009432\n",
      "  0.7585618   0.22530944  0.50083283  0.01435511 -0.23155803  0.02756539\n",
      "  0.31115205 -0.06242868]\n",
      "Training Error:  15.862189628732654\n",
      "====================================================================================================\n",
      "Iteration:  107\n",
      "Previous theta :  [ 0.04066433 -0.05570521  0.14507417  0.2484855   0.1103043   0.31009432\n",
      "  0.7585618   0.22530944  0.50083283  0.01435511 -0.23155803  0.02756539\n",
      "  0.31115205 -0.06242868]\n",
      "New theta_0 : [ 0.03949062 -0.05587565  0.14160964  0.24631702  0.10817692  0.30728653\n",
      "  0.75360969  0.22173077  0.49402027  0.01575998 -0.23195073  0.02393247\n",
      "  0.30676491 -0.06722712]\n",
      "Training Error:  15.755361281923173\n",
      "====================================================================================================\n",
      "Iteration:  108\n",
      "Previous theta :  [ 0.03949062 -0.05587565  0.14160964  0.24631702  0.10817692  0.30728653\n",
      "  0.75360969  0.22173077  0.49402027  0.01575998 -0.23195073  0.02393247\n",
      "  0.30676491 -0.06722712]\n",
      "New theta_0 : [ 0.03835764 -0.05603819  0.13822722  0.24416825  0.10611005  0.30449031\n",
      "  0.74871152  0.21820172  0.48727817  0.01717356 -0.23231947  0.0203519\n",
      "  0.30246744 -0.07196736]\n",
      "Training Error:  15.650697127288867\n",
      "====================================================================================================\n",
      "Iteration:  109\n",
      "Previous theta :  [ 0.03835764 -0.05603819  0.13822722  0.24416825  0.10611005  0.30449031\n",
      "  0.74871152  0.21820172  0.48727817  0.01717356 -0.23231947  0.0203519\n",
      "  0.30246744 -0.07196736]\n",
      "New theta_0 : [ 0.03726397 -0.05619335  0.13492509  0.24203902  0.10410209  0.30170565\n",
      "  0.74386659  0.21472182  0.48060541  0.01859511 -0.23266513  0.01682286\n",
      "  0.29825781 -0.07665   ]\n",
      "Training Error:  15.54814718954695\n",
      "====================================================================================================\n",
      "Iteration:  110\n",
      "Previous theta :  [ 0.03726397 -0.05619335  0.13492509  0.24203902  0.10410209  0.30170565\n",
      "  0.74386659  0.21472182  0.48060541  0.01859511 -0.23266513  0.01682286\n",
      "  0.29825781 -0.07665   ]\n",
      "New theta_0 : [ 0.03620823 -0.05634166  0.13170143  0.23992917  0.10215146  0.29893256\n",
      "  0.7390742   0.2112906   0.47400094  0.02002392 -0.2329885   0.01334457\n",
      "  0.29413418 -0.08127563]\n",
      "Training Error:  15.447662834289513\n",
      "====================================================================================================\n",
      "Iteration:  111\n",
      "Previous theta :  [ 0.03620823 -0.05634166  0.13170143  0.23992917  0.10215146  0.29893256\n",
      "  0.7390742   0.2112906   0.47400094  0.02002392 -0.2329885   0.01334457\n",
      "  0.29413418 -0.08127563]\n",
      "New theta_0 : [ 0.0351891  -0.05648361  0.12855448  0.23783851  0.10025663  0.29617102\n",
      "  0.7343337   0.20790758  0.46746371  0.02145932 -0.23329038  0.00991627\n",
      "  0.2900948  -0.08584484]\n",
      "Training Error:  15.349196723992248\n",
      "====================================================================================================\n",
      "Iteration:  112\n",
      "Previous theta :  [ 0.0351891  -0.05648361  0.12855448  0.23783851  0.10025663  0.29617102\n",
      "  0.7343337   0.20790758  0.46746371  0.02145932 -0.23329038  0.00991627\n",
      "  0.2900948  -0.08584484]\n",
      "New theta_0 : [ 0.03420531 -0.05661966  0.12548255  0.23576688  0.09841612  0.29342102\n",
      "  0.72964442  0.20457228  0.46099269  0.02290065 -0.23357154  0.0065372\n",
      "  0.28613792 -0.09035822]\n",
      "Training Error:  15.252702775814933\n",
      "====================================================================================================\n",
      "Iteration:  113\n",
      "Previous theta :  [ 0.03420531 -0.05661966  0.12548255  0.23576688  0.09841612  0.29342102\n",
      "  0.72964442  0.20457228  0.46099269  0.02290065 -0.23357154  0.0065372\n",
      "  0.28613792 -0.09035822]\n",
      "New theta_0 : [ 0.0332556  -0.05675025  0.12248397  0.23371411  0.09662847  0.29068257\n",
      "  0.72500572  0.20128422  0.45458689  0.02434729 -0.23383271  0.0032066\n",
      "  0.28226184 -0.09481635]\n",
      "Training Error:  15.158136121108853\n",
      "====================================================================================================\n",
      "Iteration:  114\n",
      "Previous theta :  [ 0.0332556  -0.05675025  0.12248397  0.23371411  0.09662847  0.29068257\n",
      "  0.72500572  0.20128422  0.45458689  0.02434729 -0.23383271  0.0032066\n",
      "  0.28226184 -0.09481635]\n",
      "New theta_0 : [ 3.23388022e-02 -5.68758245e-02  1.19557109e-01  2.31680025e-01\n",
      "  9.48922571e-02  2.87955652e-01  7.20416975e-01  1.98042921e-01\n",
      "  4.48245333e-01  2.57986424e-02 -2.34074596e-01 -7.62649053e-05\n",
      "  2.78464873e-01 -9.92198307e-02]\n",
      "Training Error:  15.065453066550546\n",
      "====================================================================================================\n",
      "Iteration:  115\n",
      "Previous theta :  [ 3.23388022e-02 -5.68758245e-02  1.19557109e-01  2.31680025e-01\n",
      "  9.48922571e-02  2.87955652e-01  7.20416975e-01  1.98042921e-01\n",
      "  4.48245333e-01  2.57986424e-02 -2.34074596e-01 -7.62649053e-05\n",
      "  2.78464873e-01 -9.92198307e-02]\n",
      "New theta_0 : [ 0.03145376 -0.05699677  0.11670039  0.22966446  0.09320612  0.28524025\n",
      "  0.71587756  0.19484789  0.44196706  0.02725414 -0.23429789 -0.00331211\n",
      "  0.27474539 -0.10356923]\n",
      "Training Error:  14.97461105682544\n",
      "====================================================================================================\n",
      "Iteration:  116\n",
      "Previous theta :  [ 0.03145376 -0.05699677  0.11670039  0.22966446  0.09320612  0.28524025\n",
      "  0.71587756  0.19484789  0.44196706  0.02725414 -0.23429789 -0.00331211\n",
      "  0.27474539 -0.10356923]\n",
      "New theta_0 : [ 0.03059935 -0.05711346  0.11391227  0.22766725  0.0915687   0.28253636\n",
      "  0.71138687  0.19169864  0.43575114  0.02871322 -0.23450326 -0.00650166\n",
      "  0.27110178 -0.10786515]\n",
      "Training Error:  14.885568638788785\n",
      "====================================================================================================\n",
      "Iteration:  117\n",
      "Previous theta :  [ 0.03059935 -0.05711346  0.11391227  0.22766725  0.0915687   0.28253636\n",
      "  0.71138687  0.19169864  0.43575114  0.02871322 -0.23450326 -0.00650166\n",
      "  0.27110178 -0.10786515]\n",
      "New theta_0 : [ 0.02977452 -0.05722628  0.11119124  0.22568821  0.0899787   0.27984396\n",
      "  0.7069443   0.18859469  0.42959667  0.03017538 -0.23469133 -0.00964561\n",
      "  0.26753246 -0.11210814]\n",
      "Training Error:  14.798285427034896\n",
      "====================================================================================================\n",
      "Iteration:  118\n",
      "Previous theta :  [ 0.02977452 -0.05722628  0.11119124  0.22568821  0.0899787   0.27984396\n",
      "  0.7069443   0.18859469  0.42959667  0.03017538 -0.23469133 -0.00964561\n",
      "  0.26753246 -0.11210814]\n",
      "New theta_0 : [ 0.02897823 -0.05733555  0.10853584  0.2237272   0.08843485  0.27716303\n",
      "  0.70254927  0.18553555  0.42350275  0.03164009 -0.23486274 -0.01274465\n",
      "  0.2640359  -0.1162988 ]\n",
      "Training Error:  14.712722070809328\n",
      "====================================================================================================\n",
      "Iteration:  119\n",
      "Previous theta :  [ 0.02897823 -0.05733555  0.10853584  0.2237272   0.08843485  0.27716303\n",
      "  0.70254927  0.18553555  0.42350275  0.03164009 -0.23486274 -0.01274465\n",
      "  0.2640359  -0.1162988 ]\n",
      "New theta_0 : [ 0.02820948 -0.05744161  0.10594465  0.22178403  0.08693591  0.27449357\n",
      "  0.69820121  0.18252072  0.4174685   0.03310689 -0.23501808 -0.01579947\n",
      "  0.26061058 -0.12043769]\n",
      "Training Error:  14.628840222201777\n",
      "====================================================================================================\n",
      "Iteration:  120\n",
      "Previous theta :  [ 0.02820948 -0.05744161  0.10594465  0.22178403  0.08693591  0.27449357\n",
      "  0.69820121  0.18252072  0.4174685   0.03310689 -0.23501808 -0.01579947\n",
      "  0.26061058 -0.12043769]\n",
      "New theta_0 : [ 0.02746731 -0.05754476  0.10341625  0.21985855  0.08548066  0.27183554\n",
      "  0.69389955  0.17954972  0.41149307  0.03457531 -0.23515792 -0.01881073\n",
      "  0.25725501 -0.12452538]\n",
      "Training Error:  14.54660250556067\n",
      "====================================================================================================\n",
      "Iteration:  121\n",
      "Previous theta :  [ 0.02746731 -0.05754476  0.10341625  0.21985855  0.08548066  0.27183554\n",
      "  0.69389955  0.17954972  0.41149307  0.03457531 -0.23515792 -0.01881073\n",
      "  0.25725501 -0.12452538]\n",
      "New theta_0 : [ 0.02675079 -0.0576453   0.10094931  0.21795059  0.08406795  0.26918894\n",
      "  0.68964372  0.17662206  0.40557564  0.0360449  -0.23528283 -0.0217791\n",
      "  0.25396774 -0.12856245]\n",
      "Training Error:  14.465972488073419\n",
      "====================================================================================================\n",
      "Iteration:  122\n",
      "Previous theta :  [ 0.02675079 -0.0576453   0.10094931  0.21795059  0.08406795  0.26918894\n",
      "  0.68964372  0.17662206  0.40557564  0.0360449  -0.23528283 -0.0217791\n",
      "  0.25396774 -0.12856245]\n",
      "New theta_0 : [ 0.02605902 -0.05774351  0.09854248  0.21605999  0.08269661  0.26655375\n",
      "  0.6854332   0.17373725  0.39971537  0.03751525 -0.23539335 -0.02470523\n",
      "  0.25074735 -0.13254944]\n",
      "Training Error:  14.386914651459014\n",
      "====================================================================================================\n",
      "Iteration:  123\n",
      "Previous theta :  [ 0.02605902 -0.05774351  0.09854248  0.21605999  0.08269661  0.26655375\n",
      "  0.6854332   0.17373725  0.39971537  0.03751525 -0.23539335 -0.02470523\n",
      "  0.25074735 -0.13254944]\n",
      "New theta_0 : [ 0.02539114 -0.05783965  0.09619447  0.21418658  0.08136554  0.26392994\n",
      "  0.68126743  0.17089479  0.39391146  0.03898594 -0.23548999 -0.02758975\n",
      "  0.24759244 -0.13648693]\n",
      "Training Error:  14.30939436472242\n",
      "====================================================================================================\n",
      "Iteration:  124\n",
      "Previous theta :  [ 0.02539114 -0.05783965  0.09619447  0.21418658  0.08136554  0.26392994\n",
      "  0.68126743  0.17089479  0.39391146  0.03898594 -0.23548999 -0.02758975\n",
      "  0.24759244 -0.13648693]\n",
      "New theta_0 : [ 0.02474632 -0.05793397  0.09390402  0.21233022  0.08007365  0.26131748\n",
      "  0.6771459   0.16809422  0.38816314  0.0404566  -0.23557327 -0.0304333\n",
      "  0.24450164 -0.14037546]\n",
      "Training Error:  14.233377857922665\n",
      "====================================================================================================\n",
      "Iteration:  125\n",
      "Previous theta :  [ 0.02474632 -0.05793397  0.09390402  0.21233022  0.08007365  0.26131748\n",
      "  0.6771459   0.16809422  0.38816314  0.0404566  -0.23557327 -0.0304333\n",
      "  0.24450164 -0.14037546]\n",
      "New theta_0 : [ 0.02412374 -0.05802671  0.0916699   0.21049072  0.07881989  0.25871637\n",
      "  0.67306807  0.16533503  0.38246964  0.04192684 -0.23564367 -0.03323649\n",
      "  0.24147362 -0.14421559]\n",
      "Training Error:  14.158832196908941\n",
      "====================================================================================================\n",
      "Iteration:  126\n",
      "Previous theta :  [ 0.02412374 -0.05802671  0.0916699   0.21049072  0.07881989  0.25871637\n",
      "  0.67306807  0.16533503  0.38246964  0.04192684 -0.23564367 -0.03323649\n",
      "  0.24147362 -0.14421559]\n",
      "New theta_0 : [ 0.02352264 -0.05811809  0.08949089  0.20866795  0.07760323  0.25612657\n",
      "  0.66903344  0.16261675  0.37683019  0.04339632 -0.23570167 -0.03599994\n",
      "  0.23850705 -0.14800787]\n",
      "Training Error:  14.085725258981354\n",
      "====================================================================================================\n",
      "Iteration:  127\n",
      "Previous theta :  [ 0.02352264 -0.05811809  0.08949089  0.20866795  0.07760323  0.25612657\n",
      "  0.66903344  0.16261675  0.37683019  0.04339632 -0.23570167 -0.03599994\n",
      "  0.23850705 -0.14800787]\n",
      "New theta_0 : [ 0.02294225 -0.05820832  0.08736584  0.20686174  0.07642267  0.25354806\n",
      "  0.66504151  0.15993889  0.37124407  0.04486469 -0.23574771 -0.03872424\n",
      "  0.23560066 -0.15175285]\n",
      "Training Error:  14.014025709435016\n",
      "====================================================================================================\n",
      "Iteration:  128\n",
      "Previous theta :  [ 0.02294225 -0.05820832  0.08736584  0.20686174  0.07642267  0.25354806\n",
      "  0.66504151  0.15993889  0.37124407  0.04486469 -0.23574771 -0.03872424\n",
      "  0.23560066 -0.15175285]\n",
      "New theta_0 : [ 0.02238187 -0.0582976   0.08529358  0.20507193  0.07527723  0.25098082\n",
      "  0.66109178  0.15730097  0.36571055  0.04633163 -0.23578224 -0.04140999\n",
      "  0.23275319 -0.15545105]\n",
      "Training Error:  13.94370297894835\n",
      "====================================================================================================\n",
      "Iteration:  129\n",
      "Previous theta :  [ 0.02238187 -0.0582976   0.08529358  0.20507193  0.07527723  0.25098082\n",
      "  0.66109178  0.15730097  0.36571055  0.04633163 -0.23578224 -0.04140999\n",
      "  0.23275319 -0.15545105]\n",
      "New theta_0 : [ 0.02184078 -0.05838612  0.083273    0.20329837  0.07416597  0.24842482\n",
      "  0.65718376  0.15470251  0.36022892  0.04779684 -0.23580569 -0.04405777\n",
      "  0.22996339 -0.15910302]\n",
      "Training Error:  13.874727241778245\n",
      "====================================================================================================\n",
      "Iteration:  130\n",
      "Previous theta :  [ 0.02184078 -0.05838612  0.083273    0.20329837  0.07416597  0.24842482\n",
      "  0.65718376  0.15470251  0.36022892  0.04779684 -0.23580569 -0.04405777\n",
      "  0.22996339 -0.15910302]\n",
      "New theta_0 : [ 0.02131832 -0.05847406  0.081303    0.20154091  0.07308795  0.24588003\n",
      "  0.65331698  0.15214304  0.35479849  0.04926    -0.23581846 -0.04666816\n",
      "  0.22723007 -0.1627093 ]\n",
      "Training Error:  13.807069394726739\n",
      "====================================================================================================\n",
      "Iteration:  131\n",
      "Previous theta :  [ 0.02131832 -0.05847406  0.081303    0.20154091  0.07308795  0.24588003\n",
      "  0.65331698  0.15214304  0.35479849  0.04926    -0.23581846 -0.04666816\n",
      "  0.22723007 -0.1627093 ]\n",
      "New theta_0 : [ 0.02081383 -0.05856159  0.07938251  0.1997994   0.07204229  0.24334643\n",
      "  0.64949095  0.14962208  0.34941859  0.05072085 -0.23582096 -0.04924171\n",
      "  0.22455203 -0.1662704 ]\n",
      "Training Error:  13.74070103684546\n",
      "====================================================================================================\n",
      "Iteration:  132\n",
      "Previous theta :  [ 0.02081383 -0.05856159  0.07938251  0.1997994   0.07204229  0.24334643\n",
      "  0.64949095  0.14962208  0.34941859  0.05072085 -0.23582096 -0.04924171\n",
      "  0.22455203 -0.1662704 ]\n",
      "New theta_0 : [ 0.02032669 -0.05864886  0.07751049  0.19807368  0.07102811  0.24082399\n",
      "  0.64570521  0.14713915  0.34408853  0.0521791  -0.23581357 -0.05177898\n",
      "  0.22192812 -0.16978686]\n",
      "Training Error:  13.675594449845908\n",
      "====================================================================================================\n",
      "Iteration:  133\n",
      "Previous theta :  [ 0.02032669 -0.05864886  0.07751049  0.19807368  0.07102811  0.24082399\n",
      "  0.64570521  0.14713915  0.34408853  0.0521791  -0.23581357 -0.05177898\n",
      "  0.22192812 -0.16978686]\n",
      "New theta_0 : [ 0.01985629 -0.05873602  0.07568593  0.1963636   0.07004455  0.23831269\n",
      "  0.64195931  0.1446938   0.33880768  0.0536345  -0.23579667 -0.05428053\n",
      "  0.2193572  -0.17325919]\n",
      "Training Error:  13.611722579184992\n",
      "====================================================================================================\n",
      "Iteration:  134\n",
      "Previous theta :  [ 0.01985629 -0.05873602  0.07568593  0.1963636   0.07004455  0.23831269\n",
      "  0.64195931  0.1446938   0.33880768  0.0536345  -0.23579667 -0.05428053\n",
      "  0.2193572  -0.17325919]\n",
      "New theta_0 : [ 0.01940204 -0.05882322  0.07390781  0.19466902  0.06909079  0.23581248\n",
      "  0.63825279  0.14228555  0.33357538  0.05508681 -0.23577061 -0.05674688\n",
      "  0.21683816 -0.17668791]\n",
      "Training Error:  13.549059015796999\n",
      "====================================================================================================\n",
      "Iteration:  135\n",
      "Previous theta :  [ 0.01940204 -0.05882322  0.07390781  0.19466902  0.06909079  0.23581248\n",
      "  0.63825279  0.14228555  0.33357538  0.05508681 -0.23577061 -0.05674688\n",
      "  0.21683816 -0.17668791]\n",
      "New theta_0 : [ 0.0189634  -0.05891058  0.07217517  0.19298979  0.06816602  0.23332336\n",
      "  0.6345852   0.13991394  0.32839101  0.05653579 -0.23573574 -0.05917857\n",
      "  0.21436991 -0.18007353]\n",
      "Training Error:  13.487577978444369\n",
      "====================================================================================================\n",
      "Iteration:  136\n",
      "Previous theta :  [ 0.0189634  -0.05891058  0.07217517  0.19298979  0.06816602  0.23332336\n",
      "  0.6345852   0.13991394  0.32839101  0.05653579 -0.23573574 -0.05917857\n",
      "  0.21436991 -0.18007353]\n",
      "New theta_0 : [ 0.0185398  -0.05899824  0.07048705  0.19132577  0.06726945  0.23084528\n",
      "  0.63095611  0.13757851  0.32325395  0.05798121 -0.23569241 -0.06157612\n",
      "  0.21195138 -0.18341655]\n",
      "Training Error:  13.427254296661102\n",
      "====================================================================================================\n",
      "Iteration:  137\n",
      "Previous theta :  [ 0.0185398  -0.05899824  0.07048705  0.19132577  0.06726945  0.23084528\n",
      "  0.63095611  0.13757851  0.32325395  0.05798121 -0.23569241 -0.06157612\n",
      "  0.21195138 -0.18341655]\n",
      "New theta_0 : [ 0.01813072 -0.0590863   0.06884253  0.1896768   0.06640032  0.22837822\n",
      "  0.62736507  0.1352788   0.3181636   0.05942286 -0.23564093 -0.06394004\n",
      "  0.20958153 -0.18671748]\n",
      "Training Error:  13.368063394263869\n",
      "====================================================================================================\n",
      "Iteration:  138\n",
      "Previous theta :  [ 0.01813072 -0.0590863   0.06884253  0.1896768   0.06640032  0.22837822\n",
      "  0.62736507  0.1352788   0.3181636   0.05942286 -0.23564093 -0.06394004\n",
      "  0.20958153 -0.18671748]\n",
      "New theta_0 : [ 0.01773567 -0.05917487  0.06724069  0.18804276  0.06555789  0.22592214\n",
      "  0.62381168  0.13301436  0.31311937  0.06086053 -0.23558162 -0.06627085\n",
      "  0.20725933 -0.18997681]\n",
      "Training Error:  13.309981273407143\n",
      "====================================================================================================\n",
      "Iteration:  139\n",
      "Previous theta :  [ 0.01773567 -0.05917487  0.06724069  0.18804276  0.06555789  0.22592214\n",
      "  0.62381168  0.13301436  0.31311937  0.06086053 -0.23558162 -0.06627085\n",
      "  0.20725933 -0.18997681]\n",
      "New theta_0 : [ 0.01735415 -0.05926406  0.06568065  0.18642349  0.06474143  0.22347703\n",
      "  0.62029549  0.13078473  0.30812066  0.06229404 -0.2355148  -0.06856903\n",
      "  0.20498379 -0.19319505]\n",
      "Training Error:  13.252984499159714\n",
      "====================================================================================================\n",
      "Iteration:  140\n",
      "Previous theta :  [ 0.01735415 -0.05926406  0.06568065  0.18642349  0.06474143  0.22347703\n",
      "  0.62029549  0.13078473  0.30812066  0.06229404 -0.2355148  -0.06856903\n",
      "  0.20498379 -0.19319505]\n",
      "New theta_0 : [ 0.01698568 -0.05935397  0.06416153  0.18481885  0.06395023  0.22104284\n",
      "  0.6168161   0.12858947  0.30316691  0.06372319 -0.23544074 -0.07083507\n",
      "  0.20275391 -0.19637267]\n",
      "Training Error:  13.19705018458119\n",
      "====================================================================================================\n",
      "Iteration:  141\n",
      "Previous theta :  [ 0.01698568 -0.05935397  0.06416153  0.18481885  0.06395023  0.22104284\n",
      "  0.6168161   0.12858947  0.30316691  0.06372319 -0.23544074 -0.07083507\n",
      "  0.20275391 -0.19637267]\n",
      "New theta_0 : [ 0.01662982 -0.05944468  0.06268249  0.18322871  0.06318361  0.21861954\n",
      "  0.6133731   0.12642814  0.29825756  0.06514781 -0.23535974 -0.07306947\n",
      "  0.20056875 -0.19951016]\n",
      "Training Error:  13.142155976278014\n",
      "====================================================================================================\n",
      "Iteration:  142\n",
      "Previous theta :  [ 0.01662982 -0.05944468  0.06268249  0.18322871  0.06318361  0.21861954\n",
      "  0.6133731   0.12642814  0.29825756  0.06514781 -0.23535974 -0.07306947\n",
      "  0.20056875 -0.19951016]\n",
      "New theta_0 : [ 0.01628613 -0.05953627  0.06124269  0.18165293  0.06244089  0.21620711\n",
      "  0.60996608  0.12430029  0.29339205  0.06656773 -0.23527208 -0.07527268\n",
      "  0.19842736 -0.202608  ]\n",
      "Training Error:  13.088280040419496\n",
      "====================================================================================================\n",
      "Iteration:  143\n",
      "Previous theta :  [ 0.01628613 -0.05953627  0.06124269  0.18165293  0.06244089  0.21620711\n",
      "  0.60996608  0.12430029  0.29339205  0.06656773 -0.23527208 -0.07527268\n",
      "  0.19842736 -0.202608  ]\n",
      "New theta_0 : [ 0.01595418 -0.05962882  0.05984132  0.18009138  0.06172145  0.21380551\n",
      "  0.60659464  0.12220549  0.28856984  0.0679828  -0.23517802 -0.07744519\n",
      "  0.19632881 -0.20566666]\n",
      "Training Error:  13.03540104919541\n",
      "====================================================================================================\n",
      "Iteration:  144\n",
      "Previous theta :  [ 0.01595418 -0.05962882  0.05984132  0.18009138  0.06172145  0.21380551\n",
      "  0.60659464  0.12220549  0.28856984  0.0679828  -0.23517802 -0.07744519\n",
      "  0.19632881 -0.20566666]\n",
      "New theta_0 : [ 0.01563356 -0.05972241  0.05847759  0.17854391  0.06102462  0.21141472\n",
      "  0.60325838  0.1201433   0.28379041  0.06939286 -0.23507782 -0.07958745\n",
      "  0.19427221 -0.20868662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  12.983498167697464\n",
      "====================================================================================================\n",
      "Iteration:  145\n",
      "Previous theta :  [ 0.01563356 -0.05972241  0.05847759  0.17854391  0.06102462  0.21141472\n",
      "  0.60325838  0.1201433   0.28379041  0.06939286 -0.23507782 -0.07958745\n",
      "  0.19427221 -0.20868662]\n",
      "New theta_0 : [ 0.01532389 -0.0598171   0.05715071  0.1770104   0.06034981  0.20903469\n",
      "  0.59995693  0.11811329  0.27905323  0.07079776 -0.23497173 -0.08169991\n",
      "  0.19225668 -0.21166834]\n",
      "Training Error:  12.932551041207843\n",
      "====================================================================================================\n",
      "Iteration:  146\n",
      "Previous theta :  [ 0.01532389 -0.0598171   0.05715071  0.1770104   0.06034981  0.20903469\n",
      "  0.59995693  0.11811329  0.27905323  0.07079776 -0.23497173 -0.08169991\n",
      "  0.19225668 -0.21166834]\n",
      "New theta_0 : [ 0.01502477 -0.05991294  0.05585993  0.17549071  0.05969642  0.2066654\n",
      "  0.59668989  0.11611504  0.27435778  0.07219738 -0.23485999 -0.08378302\n",
      "  0.19028134 -0.21461228]\n",
      "Training Error:  12.88253978287881\n",
      "====================================================================================================\n",
      "Iteration:  147\n",
      "Previous theta :  [ 0.01502477 -0.05991294  0.05585993  0.17549071  0.05969642  0.2066654\n",
      "  0.59668989  0.11611504  0.27435778  0.07219738 -0.23485999 -0.08378302\n",
      "  0.19028134 -0.21461228]\n",
      "New theta_0 : [ 0.01473584 -0.06001001  0.0546045   0.17398472  0.05906385  0.20430681\n",
      "  0.59345689  0.11414813  0.26970357  0.07359158 -0.23474285 -0.08583722\n",
      "  0.18834536 -0.2175189 ]\n",
      "Training Error:  12.833444961788194\n",
      "====================================================================================================\n",
      "Iteration:  148\n",
      "Previous theta :  [ 0.01473584 -0.06001001  0.0546045   0.17398472  0.05906385  0.20430681\n",
      "  0.59345689  0.11414813  0.26970357  0.07359158 -0.23474285 -0.08583722\n",
      "  0.18834536 -0.2175189 ]\n",
      "New theta_0 : [ 0.01445676 -0.06010835  0.05338369  0.17249228  0.05845154  0.2019589\n",
      "  0.59025755  0.11221213  0.2650901   0.07498024 -0.23462051 -0.08786294\n",
      "  0.18644791 -0.22038864]\n",
      "Training Error:  12.785247591356084\n",
      "====================================================================================================\n",
      "Iteration:  149\n",
      "Previous theta :  [ 0.01445676 -0.06010835  0.05338369  0.17249228  0.05845154  0.2019589\n",
      "  0.59025755  0.11221213  0.2650901   0.07498024 -0.23462051 -0.08786294\n",
      "  0.18644791 -0.22038864]\n",
      "New theta_0 : [ 0.01418717 -0.060208    0.05219679  0.17101329  0.05785894  0.19962162\n",
      "  0.58709149  0.11030663  0.26051687  0.07636325 -0.23449321 -0.08986061\n",
      "  0.18458816 -0.22322197]\n",
      "Training Error:  12.737929118109067\n",
      "====================================================================================================\n",
      "Iteration:  150\n",
      "Previous theta :  [ 0.01418717 -0.060208    0.05219679  0.17101329  0.05785894  0.19962162\n",
      "  0.58709149  0.11030663  0.26051687  0.07636325 -0.23449321 -0.08986061\n",
      "  0.18458816 -0.22322197]\n",
      "New theta_0 : [ 0.01392675 -0.06030902  0.0510431   0.1695476   0.05728552  0.19729495\n",
      "  0.58395837  0.10843123  0.25598343  0.07774049 -0.23436116 -0.09183064\n",
      "  0.18276534 -0.22601931]\n",
      "Training Error:  12.691471410778597\n",
      "====================================================================================================\n",
      "Iteration:  151\n",
      "Previous theta :  [ 0.01392675 -0.06030902  0.0510431   0.1695476   0.05728552  0.19729495\n",
      "  0.58395837  0.10843123  0.25598343  0.07774049 -0.23436116 -0.09183064\n",
      "  0.18276534 -0.22601931]\n",
      "New theta_0 : [ 0.01367518 -0.06041144  0.04992194  0.16809509  0.05673074  0.19497885\n",
      "  0.58085781  0.10658551  0.25148928  0.07911186 -0.23422456 -0.09377345\n",
      "  0.18097866 -0.22878111]\n",
      "Training Error:  12.645856749721126\n",
      "====================================================================================================\n",
      "Iteration:  152\n",
      "Previous theta :  [ 0.01367518 -0.06041144  0.04992194  0.16809509  0.05673074  0.19497885\n",
      "  0.58085781  0.10658551  0.25148928  0.07911186 -0.23422456 -0.09377345\n",
      "  0.18097866 -0.22878111]\n",
      "New theta_0 : [ 0.01343215 -0.0605153   0.04883263  0.16665564  0.0561941   0.19267329\n",
      "  0.57778946  0.10476907  0.24703398  0.08047726 -0.23408361 -0.09568943\n",
      "  0.17922736 -0.23150781]\n",
      "Training Error:  12.601067816647793\n",
      "====================================================================================================\n",
      "Iteration:  153\n",
      "Previous theta :  [ 0.01343215 -0.0605153   0.04883263  0.16665564  0.0561941   0.19267329\n",
      "  0.57778946  0.10476907  0.24703398  0.08047726 -0.23408361 -0.09568943\n",
      "  0.17922736 -0.23150781]\n",
      "New theta_0 : [ 0.01319738 -0.06062063  0.04777454  0.16522912  0.05567511  0.19037824\n",
      "  0.57475297  0.10298152  0.24261707  0.0818366  -0.2339385  -0.097579\n",
      "  0.1775107  -0.23419982]\n",
      "Training Error:  12.557087684652378\n",
      "====================================================================================================\n",
      "Iteration:  154\n",
      "Previous theta :  [ 0.01319738 -0.06062063  0.04777454  0.16522912  0.05567511  0.19037824\n",
      "  0.57475297  0.10298152  0.24261707  0.0818366  -0.2339385  -0.097579\n",
      "  0.1775107  -0.23419982]\n",
      "New theta_0 : [ 0.01297056 -0.06072746  0.046747    0.16381542  0.05517327  0.18809366\n",
      "  0.57174799  0.10122245  0.2382381   0.0831898  -0.23378943 -0.09944255\n",
      "  0.17582795 -0.23685758]\n",
      "Training Error:  12.513899808526466\n",
      "====================================================================================================\n",
      "Iteration:  155\n",
      "Previous theta :  [ 0.01297056 -0.06072746  0.046747    0.16381542  0.05517327  0.18809366\n",
      "  0.57174799  0.10122245  0.2382381   0.0831898  -0.23378943 -0.09944255\n",
      "  0.17582795 -0.23685758]\n",
      "New theta_0 : [ 0.01275143 -0.06083582  0.04574941  0.16241441  0.05468813  0.18581952\n",
      "  0.56877417  0.09949148  0.23389663  0.08453677 -0.23363656 -0.10128045\n",
      "  0.17417839 -0.2394815 ]\n",
      "Training Error:  12.47148801535149\n",
      "====================================================================================================\n",
      "Iteration:  156\n",
      "Previous theta :  [ 0.01275143 -0.06083582  0.04574941  0.16241441  0.05468813  0.18581952\n",
      "  0.56877417  0.09949148  0.23389663  0.08453677 -0.23363656 -0.10128045\n",
      "  0.17417839 -0.2394815 ]\n",
      "New theta_0 : [ 0.01253973 -0.06094572  0.04478114  0.16102598  0.05421922  0.18355578\n",
      "  0.56583119  0.09778822  0.22959224  0.08587744 -0.23348007 -0.1030931\n",
      "  0.17256133 -0.242072  ]\n",
      "Training Error:  12.429836495357636\n",
      "====================================================================================================\n",
      "Iteration:  157\n",
      "Previous theta :  [ 0.01253973 -0.06094572  0.04478114  0.16102598  0.05421922  0.18355578\n",
      "  0.56583119  0.09778822  0.22959224  0.08587744 -0.23348007 -0.1030931\n",
      "  0.17256133 -0.242072  ]\n",
      "New theta_0 : [ 0.01233519 -0.0610572   0.04384159  0.15965     0.05376611  0.18130241\n",
      "  0.5629187   0.09611229  0.22532449  0.08721174 -0.23332014 -0.10488086\n",
      "  0.17097608 -0.24462949]\n",
      "Training Error:  12.38892979304014\n",
      "====================================================================================================\n",
      "Iteration:  158\n",
      "Previous theta :  [ 0.01233519 -0.0610572   0.04384159  0.15965     0.05376611  0.18130241\n",
      "  0.5629187   0.09611229  0.22532449  0.08721174 -0.23332014 -0.10488086\n",
      "  0.17097608 -0.24462949]\n",
      "New theta_0 : [ 0.01213757 -0.06117026  0.04293017  0.15828636  0.05332835  0.17905938\n",
      "  0.56003636  0.09446331  0.22109297  0.08853959 -0.23315692 -0.10664411\n",
      "  0.16942197 -0.24715438]\n",
      "Training Error:  12.348752798523863\n",
      "====================================================================================================\n",
      "Iteration:  159\n",
      "Previous theta :  [ 0.01213757 -0.06117026  0.04293017  0.15828636  0.05332835  0.17905938\n",
      "  0.56003636  0.09446331  0.22109297  0.08853959 -0.23315692 -0.10664411\n",
      "  0.16942197 -0.24715438]\n",
      "New theta_0 : [ 0.01194663 -0.06128492  0.04204631  0.15693494  0.05290553  0.17682665\n",
      "  0.55718387  0.0928409   0.21689728  0.08986093 -0.23299058 -0.10838321\n",
      "  0.16789834 -0.24964707]\n",
      "Training Error:  12.309290739167523\n",
      "====================================================================================================\n",
      "Iteration:  160\n",
      "Previous theta :  [ 0.01194663 -0.06128492  0.04204631  0.15693494  0.05290553  0.17682665\n",
      "  0.55718387  0.0928409   0.21689728  0.08986093 -0.23299058 -0.10838321\n",
      "  0.16789834 -0.24964707]\n",
      "New theta_0 : [ 0.01176214 -0.0614012   0.04118945  0.15559564  0.05249724  0.17460419\n",
      "  0.55436088  0.0912447   0.21273699  0.09117571 -0.23282126 -0.11009852\n",
      "  0.16640457 -0.25210796]\n",
      "Training Error:  12.270529171399225\n",
      "====================================================================================================\n",
      "Iteration:  161\n",
      "Previous theta :  [ 0.01176214 -0.0614012   0.04118945  0.15559564  0.05249724  0.17460419\n",
      "  0.55436088  0.0912447   0.21273699  0.09117571 -0.23282126 -0.11009852\n",
      "  0.16640457 -0.25210796]\n",
      "New theta_0 : [ 0.01158387 -0.0615191   0.04035902  0.15426832  0.05210308  0.17239196\n",
      "  0.55156709  0.08967433  0.20861173  0.09248388 -0.23264911 -0.11179039\n",
      "  0.16494001 -0.25453743]\n",
      "Training Error:  12.232453972775412\n",
      "====================================================================================================\n",
      "Iteration:  162\n",
      "Previous theta :  [ 0.01158387 -0.0615191   0.04035902  0.15426832  0.05210308  0.17239196\n",
      "  0.55156709  0.08967433  0.20861173  0.09248388 -0.23264911 -0.11179039\n",
      "  0.16494001 -0.25453743]\n",
      "New theta_0 : [ 0.01141162 -0.06163864  0.03955449  0.1529529   0.05172266  0.17018993\n",
      "  0.54880217  0.08812944  0.20452109  0.09378537 -0.23247429 -0.11345917\n",
      "  0.16350406 -0.25693589]\n",
      "Training Error:  12.195051334255679\n",
      "====================================================================================================\n",
      "Iteration:  163\n",
      "Previous theta :  [ 0.01141162 -0.06163864  0.03955449  0.1529529   0.05172266  0.17018993\n",
      "  0.54880217  0.08812944  0.20452109  0.09378537 -0.23247429 -0.11345917\n",
      "  0.16350406 -0.25693589]\n",
      "New theta_0 : [ 0.01124518 -0.06175981  0.03877533  0.15164924  0.0513556   0.16799806\n",
      "  0.54606582  0.08660966  0.2004647   0.09508015 -0.23229692 -0.11510519\n",
      "  0.16209611 -0.2593037 ]\n",
      "Training Error:  12.158307752686097\n",
      "====================================================================================================\n",
      "Iteration:  164\n",
      "Previous theta :  [ 0.01124518 -0.06175981  0.03877533  0.15164924  0.0513556   0.16799806\n",
      "  0.54606582  0.08660966  0.2004647   0.09508015 -0.23229692 -0.11510519\n",
      "  0.16209611 -0.2593037 ]\n",
      "New theta_0 : [ 0.01108435 -0.06188262  0.03802101  0.15035725  0.05100154  0.16581633\n",
      "  0.54335772  0.08511465  0.19644216  0.09636817 -0.23211714 -0.1167288\n",
      "  0.16071557 -0.26164126]\n",
      "Training Error:  12.12221002348428\n",
      "====================================================================================================\n",
      "Iteration:  165\n",
      "Previous theta :  [ 0.01108435 -0.06188262  0.03802101  0.15035725  0.05100154  0.16581633\n",
      "  0.54335772  0.08511465  0.19644216  0.09636817 -0.23211714 -0.1167288\n",
      "  0.16071557 -0.26164126]\n",
      "New theta_0 : [ 0.01092893 -0.06200708  0.03729103  0.14907681  0.05066012  0.16364469\n",
      "  0.54067757  0.08364404  0.19245312  0.0976494  -0.23193508 -0.11833032\n",
      "  0.15936187 -0.26394894]\n",
      "Training Error:  12.086745233519352\n",
      "====================================================================================================\n",
      "Iteration:  166\n",
      "Previous theta :  [ 0.01092893 -0.06200708  0.03729103  0.14907681  0.05066012  0.16364469\n",
      "  0.54067757  0.08364404  0.19245312  0.0976494  -0.23193508 -0.11833032\n",
      "  0.15936187 -0.26394894]\n",
      "New theta_0 : [ 0.01077874 -0.06213318  0.0365849   0.14780782  0.050331    0.16148311\n",
      "  0.53802506  0.0821975   0.1884972   0.09892379 -0.23175086 -0.11991008\n",
      "  0.15803445 -0.26622711]\n",
      "Training Error:  12.051900754180648\n",
      "====================================================================================================\n",
      "Iteration:  167\n",
      "Previous theta :  [ 0.01077874 -0.06213318  0.0365849   0.14780782  0.050331    0.16148311\n",
      "  0.53802506  0.0821975   0.1884972   0.09892379 -0.23175086 -0.11991008\n",
      "  0.15803445 -0.26622711]\n",
      "New theta_0 : [ 0.01063361 -0.06226092  0.03590211  0.14655017  0.05001382  0.15933156\n",
      "  0.53539991  0.08077468  0.18457404  0.10019132 -0.23156461 -0.1214684\n",
      "  0.15673275 -0.26847614]\n",
      "Training Error:  12.01766423462892\n",
      "====================================================================================================\n",
      "Iteration:  168\n",
      "Previous theta :  [ 0.01063361 -0.06226092  0.03590211  0.14655017  0.05001382  0.15933156\n",
      "  0.53539991  0.08077468  0.18457404  0.10019132 -0.23156461 -0.1214684\n",
      "  0.15673275 -0.26847614]\n",
      "New theta_0 : [ 0.01049335 -0.06239029  0.03524219  0.14530376  0.04970827  0.15718999\n",
      "  0.53280181  0.07937524  0.18068329  0.10145194 -0.23137644 -0.12300561\n",
      "  0.15545624 -0.27069639]\n",
      "Training Error:  11.984023595224308\n",
      "====================================================================================================\n",
      "Iteration:  169\n",
      "Previous theta :  [ 0.01049335 -0.06239029  0.03524219  0.14530376  0.04970827  0.15718999\n",
      "  0.53280181  0.07937524  0.18068329  0.10145194 -0.23137644 -0.12300561\n",
      "  0.15545624 -0.27069639]\n",
      "New theta_0 : [ 0.0103578  -0.0625213   0.03460467  0.14406848  0.04941402  0.15505839\n",
      "  0.53023048  0.07799885  0.17682459  0.10270565 -0.23118647 -0.12452199\n",
      "  0.15420438 -0.27288823]\n",
      "Training Error:  11.950967021125383\n",
      "====================================================================================================\n",
      "Iteration:  170\n",
      "Previous theta :  [ 0.0103578  -0.0625213   0.03460467  0.14406848  0.04941402  0.15505839\n",
      "  0.53023048  0.07799885  0.17682459  0.10270565 -0.23118647 -0.12452199\n",
      "  0.15420438 -0.27288823]\n",
      "New theta_0 : [ 0.01022681 -0.06265394  0.0339891   0.14284423  0.04913077  0.1529367\n",
      "  0.52768562  0.07664518  0.17299761  0.10395241 -0.23099481 -0.12601787\n",
      "  0.15297665 -0.27505199]\n",
      "Training Error:  11.918482956054026\n",
      "====================================================================================================\n",
      "Iteration:  171\n",
      "Previous theta :  [ 0.01022681 -0.06265394  0.0339891   0.14284423  0.04913077  0.1529367\n",
      "  0.52768562  0.07664518  0.17299761  0.10395241 -0.23099481 -0.12601787\n",
      "  0.15297665 -0.27505199]\n",
      "New theta_0 : [ 0.01010021 -0.0627882   0.03339502  0.1416309   0.0488582   0.1508249\n",
      "  0.52516695  0.0753139   0.16920199  0.1051922  -0.23080156 -0.12749355\n",
      "  0.15177256 -0.27718804]\n",
      "Training Error:  11.886560096220862\n",
      "====================================================================================================\n",
      "Iteration:  172\n",
      "Previous theta :  [ 0.01010021 -0.0627882   0.03339502  0.1416309   0.0488582   0.1508249\n",
      "  0.52516695  0.0753139   0.16920199  0.1051922  -0.23080156 -0.12749355\n",
      "  0.15177256 -0.27718804]\n",
      "New theta_0 : [ 0.00997786 -0.06292406  0.03282198  0.14042841  0.04859602  0.14872296\n",
      "  0.52267418  0.07400468  0.16543741  0.106425   -0.23060683 -0.12894932\n",
      "  0.15059161 -0.27929673]\n",
      "Training Error:  11.85518738440642\n",
      "====================================================================================================\n",
      "Iteration:  173\n",
      "Previous theta :  [ 0.00997786 -0.06292406  0.03282198  0.14042841  0.04859602  0.14872296\n",
      "  0.52267418  0.07400468  0.16543741  0.106425   -0.23060683 -0.12894932\n",
      "  0.15059161 -0.27929673]\n",
      "New theta_0 : [ 0.00985962 -0.06306153  0.03226957  0.13923663  0.04834395  0.14663083\n",
      "  0.52020705  0.07271721  0.16170354  0.1076508  -0.23041071 -0.13038547\n",
      "  0.1494333  -0.28137839]\n",
      "Training Error:  11.824354004193209\n",
      "====================================================================================================\n",
      "Iteration:  174\n",
      "Previous theta :  [ 0.00985962 -0.06306153  0.03226957  0.13923663  0.04834395  0.14663083\n",
      "  0.52020705  0.07271721  0.16170354  0.1076508  -0.23041071 -0.13038547\n",
      "  0.1494333  -0.28137839]\n",
      "New theta_0 : [ 0.00974533 -0.06320059  0.03173734  0.13805549  0.04810171  0.14454848\n",
      "  0.51776527  0.07145118  0.15800005  0.10886959 -0.2302133  -0.13180229\n",
      "  0.14829718 -0.28343337]\n",
      "Training Error:  11.794049374344183\n",
      "====================================================================================================\n",
      "Iteration:  175\n",
      "Previous theta :  [ 0.00974533 -0.06320059  0.03173734  0.13805549  0.04810171  0.14454848\n",
      "  0.51776527  0.07145118  0.15800005  0.10886959 -0.2302133  -0.13180229\n",
      "  0.14829718 -0.28343337]\n",
      "New theta_0 : [ 0.00963488 -0.06334122  0.03122489  0.13688488  0.04786902  0.14247588\n",
      "  0.51534857  0.07020626  0.15432662  0.11008135 -0.2300147  -0.13320006\n",
      "  0.14718277 -0.28546199]\n",
      "Training Error:  11.764263143323259\n",
      "====================================================================================================\n",
      "Iteration:  176\n",
      "Previous theta :  [ 0.00963488 -0.06334122  0.03122489  0.13688488  0.04786902  0.14247588\n",
      "  0.51534857  0.07020626  0.15432662  0.11008135 -0.2300147  -0.13320006\n",
      "  0.14718277 -0.28546199]\n",
      "New theta_0 : [ 0.00952813 -0.06348341  0.03073181  0.1357247   0.04764562  0.14041299\n",
      "  0.51295668  0.06898216  0.15068293  0.11128607 -0.22981499 -0.13457907\n",
      "  0.14608961 -0.28746459]\n",
      "Training Error:  11.734985183953551\n",
      "====================================================================================================\n",
      "Iteration:  177\n",
      "Previous theta :  [ 0.00952813 -0.06348341  0.03073181  0.1357247   0.04764562  0.14041299\n",
      "  0.51295668  0.06898216  0.15068293  0.11128607 -0.22981499 -0.13457907\n",
      "  0.14608961 -0.28746459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00942495 -0.06362716  0.03025769  0.13457486  0.04743125  0.13835978\n",
      "  0.51058934  0.06777857  0.14706869  0.11248375 -0.22961427 -0.13593958\n",
      "  0.14501727 -0.2894415 ]\n",
      "Training Error:  11.706205588209476\n",
      "====================================================================================================\n",
      "Iteration:  178\n",
      "Previous theta :  [ 0.00942495 -0.06362716  0.03025769  0.13457486  0.04743125  0.13835978\n",
      "  0.51058934  0.06777857  0.14706869  0.11248375 -0.22961427 -0.13593958\n",
      "  0.14501727 -0.2894415 ]\n",
      "New theta_0 : [ 0.00932522 -0.06377244  0.02980216  0.13343526  0.04722566  0.13631621\n",
      "  0.50824628  0.06659519  0.14348357  0.11367438 -0.22941261 -0.13728187\n",
      "  0.14396531 -0.29139304]\n",
      "Training Error:  11.677914662138658\n",
      "====================================================================================================\n",
      "Iteration:  179\n",
      "Previous theta :  [ 0.00932522 -0.06377244  0.02980216  0.13343526  0.04722566  0.13631621\n",
      "  0.50824628  0.06659519  0.14348357  0.11367438 -0.22941261 -0.13728187\n",
      "  0.14396531 -0.29139304]\n",
      "New theta_0 : [ 0.00922884 -0.06391923  0.02936481  0.13230581  0.0470286   0.13428225\n",
      "  0.50592724  0.06543172  0.13992728  0.11485796 -0.22921009 -0.1386062\n",
      "  0.1429333  -0.29331953]\n",
      "Training Error:  11.650102920909994\n",
      "====================================================================================================\n",
      "Iteration:  180\n",
      "Previous theta :  [ 0.00922884 -0.06391923  0.02936481  0.13230581  0.0470286   0.13428225\n",
      "  0.50592724  0.06543172  0.13992728  0.11485796 -0.22921009 -0.1386062\n",
      "  0.1429333  -0.29331953]\n",
      "New theta_0 : [ 0.00913568 -0.06406753  0.02894528  0.13118642  0.04683985  0.13225786\n",
      "  0.50363196  0.06428787  0.13639952  0.11603449 -0.22900681 -0.13991283\n",
      "  0.14192083 -0.29522128]\n",
      "Training Error:  11.622761083984223\n",
      "====================================================================================================\n",
      "Iteration:  181\n",
      "Previous theta :  [ 0.00913568 -0.06406753  0.02894528  0.13118642  0.04683985  0.13225786\n",
      "  0.50363196  0.06428787  0.13639952  0.11603449 -0.22900681 -0.13991283\n",
      "  0.14192083 -0.29522128]\n",
      "New theta_0 : [ 0.00904564 -0.06421731  0.0285432   0.13007699  0.04665916  0.13024301\n",
      "  0.50136019  0.06316335  0.1329      0.11720397 -0.22880282 -0.14120203\n",
      "  0.14092749 -0.2970986 ]\n",
      "Training Error:  11.595880070403581\n",
      "====================================================================================================\n",
      "Iteration:  182\n",
      "Previous theta :  [ 0.00904564 -0.06421731  0.0285432   0.13007699  0.04665916  0.13024301\n",
      "  0.50136019  0.06316335  0.1329      0.11720397 -0.22880282 -0.14120203\n",
      "  0.14092749 -0.2970986 ]\n",
      "New theta_0 : [ 0.00895861 -0.06436856  0.0281582   0.12897743  0.04648632  0.12823766\n",
      "  0.49911168  0.06205788  0.12942843  0.11836641 -0.2285982  -0.14247404\n",
      "  0.13995288 -0.29895181]\n",
      "Training Error:  11.56945099419713\n",
      "====================================================================================================\n",
      "Iteration:  183\n",
      "Previous theta :  [ 0.00895861 -0.06436856  0.0281582   0.12897743  0.04648632  0.12823766\n",
      "  0.49911168  0.06205788  0.12942843  0.11836641 -0.2285982  -0.14247404\n",
      "  0.13995288 -0.29895181]\n",
      "New theta_0 : [ 0.00887449 -0.06452126  0.02778992  0.12788767  0.0463211   0.12624178\n",
      "  0.49688617  0.06097118  0.12598452  0.1195218  -0.22839304 -0.14372911\n",
      "  0.1389966  -0.30078121]\n",
      "Training Error:  11.543465159898581\n",
      "====================================================================================================\n",
      "Iteration:  184\n",
      "Previous theta :  [ 0.00887449 -0.06452126  0.02778992  0.12788767  0.0463211   0.12624178\n",
      "  0.49688617  0.06097118  0.12598452  0.1195218  -0.22839304 -0.14372911\n",
      "  0.1389966  -0.30078121]\n",
      "New theta_0 : [ 0.00879319 -0.06467539  0.02743803  0.12680759  0.04616329  0.12425533\n",
      "  0.49468342  0.05990295  0.12256799  0.12067015 -0.22818738 -0.1449675\n",
      "  0.13805829 -0.30258709]\n",
      "Training Error:  11.517914058173496\n",
      "====================================================================================================\n",
      "Iteration:  185\n",
      "Previous theta :  [ 0.00879319 -0.06467539  0.02743803  0.12680759  0.04616329  0.12425533\n",
      "  0.49468342  0.05990295  0.12256799  0.12067015 -0.22818738 -0.1449675\n",
      "  0.13805829 -0.30258709]\n",
      "New theta_0 : [ 0.00871461 -0.06483092  0.02710218  0.12573712  0.04601269  0.12227828\n",
      "  0.49250319  0.05885294  0.11917858  0.12181148 -0.22798131 -0.14618944\n",
      "  0.13713755 -0.30436976]\n",
      "Training Error:  11.492789361552852\n",
      "====================================================================================================\n",
      "Iteration:  186\n",
      "Previous theta :  [ 0.00871461 -0.06483092  0.02710218  0.12573712  0.04601269  0.12227828\n",
      "  0.49250319  0.05885294  0.11917858  0.12181148 -0.22798131 -0.14618944\n",
      "  0.13713755 -0.30436976]\n",
      "New theta_0 : [ 0.00863866 -0.06498784  0.02678204  0.12467618  0.04586909  0.12031059\n",
      "  0.49034523  0.05782087  0.11581599  0.12294578 -0.22777488 -0.14739517\n",
      "  0.13623404 -0.30612951]\n",
      "Training Error:  11.46808292027008\n",
      "====================================================================================================\n",
      "Iteration:  187\n",
      "Previous theta :  [ 0.00863866 -0.06498784  0.02678204  0.12467618  0.04586909  0.12031059\n",
      "  0.49034523  0.05782087  0.11581599  0.12294578 -0.22777488 -0.14739517\n",
      "  0.13623404 -0.30612951]\n",
      "New theta_0 : [ 0.00856525 -0.06514613  0.02647727  0.12362466  0.04573229  0.11835223\n",
      "  0.48820931  0.05680647  0.11247997  0.12407308 -0.22756816 -0.14858492\n",
      "  0.13534738 -0.30786662]\n",
      "Training Error:  11.443786758198765\n",
      "====================================================================================================\n",
      "Iteration:  188\n",
      "Previous theta :  [ 0.00856525 -0.06514613  0.02647727  0.12362466  0.04573229  0.11835223\n",
      "  0.48820931  0.05680647  0.11247997  0.12407308 -0.22756816 -0.14858492\n",
      "  0.13534738 -0.30786662]\n",
      "New theta_0 : [ 0.00849431 -0.06530577  0.02618755  0.1225825   0.04560212  0.11640316\n",
      "  0.48609518  0.05580948  0.10917025  0.12519338 -0.2273612  -0.14975894\n",
      "  0.13447723 -0.30958139]\n",
      "Training Error:  11.419893068888356\n",
      "====================================================================================================\n",
      "Iteration:  189\n",
      "Previous theta :  [ 0.00849431 -0.06530577  0.02618755  0.1225825   0.04560212  0.11640316\n",
      "  0.48609518  0.05580948  0.10917025  0.12519338 -0.2273612  -0.14975894\n",
      "  0.13447723 -0.30958139]\n",
      "New theta_0 : [ 0.00842574 -0.06546674  0.02591257  0.1215496   0.04547837  0.11446335\n",
      "  0.48400262  0.05482964  0.10588657  0.12630669 -0.22715406 -0.15091744\n",
      "  0.13362325 -0.31127409]\n",
      "Training Error:  11.3963942116952\n",
      "====================================================================================================\n",
      "Iteration:  190\n",
      "Previous theta :  [ 0.00842574 -0.06546674  0.02591257  0.1215496   0.04547837  0.11446335\n",
      "  0.48400262  0.05482964  0.10588657  0.12630669 -0.22715406 -0.15091744\n",
      "  0.13362325 -0.31127409]\n",
      "New theta_0 : [ 0.00835947 -0.065629    0.02565202  0.12052588  0.04536087  0.11253276\n",
      "  0.4819314   0.05386669  0.10262866  0.12741304 -0.22694681 -0.15206065\n",
      "  0.1327851  -0.31294501]\n",
      "Training Error:  11.373282708006432\n",
      "====================================================================================================\n",
      "Iteration:  191\n",
      "Previous theta :  [ 0.00835947 -0.065629    0.02565202  0.12052588  0.04536087  0.11253276\n",
      "  0.4819314   0.05386669  0.10262866  0.12741304 -0.22694681 -0.15206065\n",
      "  0.1327851  -0.31294501]\n",
      "New theta_0 : [ 0.00829542 -0.06579255  0.0254056   0.11951125  0.04524944  0.11061137\n",
      "  0.47988128  0.05292037  0.09939628  0.12851243 -0.22673948 -0.15318879\n",
      "  0.13196245 -0.31459442]\n",
      "Training Error:  11.350551237554265\n",
      "====================================================================================================\n",
      "Iteration:  192\n",
      "Previous theta :  [ 0.00829542 -0.06579255  0.0254056   0.11951125  0.04524944  0.11061137\n",
      "  0.47988128  0.05292037  0.09939628  0.12851243 -0.22673948 -0.15318879\n",
      "  0.13196245 -0.31459442]\n",
      "New theta_0 : [ 0.00823353 -0.06595736  0.025173    0.11850564  0.04514391  0.10869912\n",
      "  0.47785204  0.05199044  0.09618917  0.12960489 -0.22653214 -0.15430208\n",
      "  0.13115498 -0.31622259]\n",
      "Training Error:  11.328192634818299\n",
      "====================================================================================================\n",
      "Iteration:  193\n",
      "Previous theta :  [ 0.00823353 -0.06595736  0.025173    0.11850564  0.04514391  0.10869912\n",
      "  0.47785204  0.05199044  0.09618917  0.12960489 -0.22653214 -0.15430208\n",
      "  0.13115498 -0.31622259]\n",
      "New theta_0 : [ 0.00817371 -0.0661234   0.02495394  0.11750897  0.04504412  0.106796\n",
      "  0.47584345  0.05107665  0.09300709  0.13069042 -0.22632484 -0.15540073\n",
      "  0.13036238 -0.3178298 ]\n",
      "Training Error:  11.306199885513587\n",
      "====================================================================================================\n",
      "Iteration:  194\n",
      "Previous theta :  [ 0.00817371 -0.0661234   0.02495394  0.11750897  0.04504412  0.106796\n",
      "  0.47584345  0.05107665  0.09300709  0.13069042 -0.22632484 -0.15540073\n",
      "  0.13036238 -0.3178298 ]\n",
      "New theta_0 : [ 0.00811591 -0.06629066  0.02474813  0.11652115  0.04494991  0.10490196\n",
      "  0.4738553   0.05017875  0.08984979  0.13176906 -0.22611762 -0.15648495\n",
      "  0.12958433 -0.3194163 ]\n",
      "Training Error:  11.284566123162227\n",
      "====================================================================================================\n",
      "Iteration:  195\n",
      "Previous theta :  [ 0.00811591 -0.06629066  0.02474813  0.11652115  0.04494991  0.10490196\n",
      "  0.4738553   0.05017875  0.08984979  0.13176906 -0.22611762 -0.15648495\n",
      "  0.12958433 -0.3194163 ]\n",
      "New theta_0 : [ 0.00806005 -0.06645911  0.02455528  0.1155421   0.0448611   0.10301697\n",
      "  0.47188737  0.04929651  0.08671703  0.13284081 -0.22591052 -0.15755495\n",
      "  0.12882054 -0.32098237]\n",
      "Training Error:  11.263284625746362\n",
      "====================================================================================================\n",
      "Iteration:  196\n",
      "Previous theta :  [ 0.00806005 -0.06645911  0.02455528  0.1155421   0.0448611   0.10301697\n",
      "  0.47188737  0.04929651  0.08671703  0.13284081 -0.22591052 -0.15755495\n",
      "  0.12882054 -0.32098237]\n",
      "New theta_0 : [ 0.00800608 -0.06662873  0.02437512  0.11457175  0.04477756  0.101141\n",
      "  0.46993944  0.04842968  0.08360856  0.13390571 -0.22570361 -0.15861093\n",
      "  0.12807072 -0.32252825]\n",
      "Training Error:  11.24234881244045\n",
      "====================================================================================================\n",
      "Iteration:  197\n",
      "Previous theta :  [ 0.00800608 -0.06662873  0.02437512  0.11457175  0.04477756  0.101141\n",
      "  0.46993944  0.04842968  0.08360856  0.13390571 -0.22570361 -0.15861093\n",
      "  0.12807072 -0.32252825]\n",
      "New theta_0 : [ 0.00795393 -0.06679949  0.02420738  0.11361002  0.04469913  0.09927401\n",
      "  0.46801129  0.04757804  0.08052417  0.13496377 -0.2254969  -0.1596531\n",
      "  0.12733457 -0.32405421]\n",
      "Training Error:  11.221752240420868\n",
      "====================================================================================================\n",
      "Iteration:  198\n",
      "Previous theta :  [ 0.00795393 -0.06679949  0.02420738  0.11361002  0.04469913  0.09927401\n",
      "  0.46801129  0.04757804  0.08052417  0.13496377 -0.2254969  -0.1596531\n",
      "  0.12733457 -0.32405421]\n",
      "New theta_0 : [ 0.00790354 -0.06697137  0.0240518   0.11265682  0.04462567  0.09741596\n",
      "  0.46610271  0.04674134  0.0774636   0.13601501 -0.22529046 -0.16068166\n",
      "  0.12661181 -0.32556051]\n",
      "Training Error:  11.20148860175083\n",
      "====================================================================================================\n",
      "Iteration:  199\n",
      "Previous theta :  [ 0.00790354 -0.06697137  0.0240518   0.11265682  0.04462567  0.09741596\n",
      "  0.46610271  0.04674134  0.0774636   0.13601501 -0.22529046 -0.16068166\n",
      "  0.12661181 -0.32556051]\n",
      "New theta_0 : [ 0.00785486 -0.06714435  0.02390812  0.11171209  0.04455704  0.09556682\n",
      "  0.4642135   0.04591937  0.07442665  0.13705946 -0.22508432 -0.16169679\n",
      "  0.12590216 -0.32704738]\n",
      "Training Error:  11.181551720338776\n",
      "====================================================================================================\n",
      "Iteration:  200\n",
      "Previous theta :  [ 0.00785486 -0.06714435  0.02390812  0.11171209  0.04455704  0.09556682\n",
      "  0.4642135   0.04591937  0.07442665  0.13705946 -0.22508432 -0.16169679\n",
      "  0.12590216 -0.32704738]\n",
      "New theta_0 : [ 0.00780783 -0.06731841  0.02377607  0.11077575  0.04449309  0.09372657\n",
      "  0.46234344  0.04511189  0.07141307  0.13809715 -0.22487851 -0.1626987\n",
      "  0.12520537 -0.32851508]\n",
      "Training Error:  11.16193554896835\n",
      "====================================================================================================\n",
      "Iteration:  201\n",
      "Previous theta :  [ 0.00780783 -0.06731841  0.02377607  0.11077575  0.04449309  0.09372657\n",
      "  0.46234344  0.04511189  0.07141307  0.13809715 -0.22487851 -0.1626987\n",
      "  0.12520537 -0.32851508]\n",
      "New theta_0 : [ 0.0077624  -0.06749351  0.02365541  0.10984773  0.04443369  0.09189515\n",
      "  0.46049234  0.04431869  0.06842265  0.13912809 -0.22467308 -0.16368756\n",
      "  0.12452115 -0.32996384]\n",
      "Training Error:  11.142634166398208\n",
      "====================================================================================================\n",
      "Iteration:  202\n",
      "Previous theta :  [ 0.0077624  -0.06749351  0.02365541  0.10984773  0.04443369  0.09189515\n",
      "  0.46049234  0.04431869  0.06842265  0.13912809 -0.22467308 -0.16368756\n",
      "  0.12452115 -0.32996384]\n",
      "New theta_0 : [ 0.00771852 -0.06766964  0.02354589  0.10892794  0.04437872  0.09007255\n",
      "  0.45865998  0.04353954  0.06545516  0.14015232 -0.22446807 -0.16466357\n",
      "  0.12384926 -0.33139392]\n",
      "Training Error:  11.123641774529919\n",
      "====================================================================================================\n",
      "Iteration:  203\n",
      "Previous theta :  [ 0.00771852 -0.06766964  0.02354589  0.10892794  0.04437872  0.09007255\n",
      "  0.45865998  0.04353954  0.06545516  0.14015232 -0.22446807 -0.16466357\n",
      "  0.12384926 -0.33139392]\n",
      "New theta_0 : [ 0.00767613 -0.06784677  0.02344728  0.10801632  0.04432804  0.08825872\n",
      "  0.45684618  0.04277424  0.06251039  0.14116986 -0.22426349 -0.16562691\n",
      "  0.12318943 -0.33280554]\n",
      "Training Error:  11.104952695642273\n",
      "====================================================================================================\n",
      "Iteration:  204\n",
      "Previous theta :  [ 0.00767613 -0.06784677  0.02344728  0.10801632  0.04432804  0.08825872\n",
      "  0.45684618  0.04277424  0.06251039  0.14116986 -0.22426349 -0.16562691\n",
      "  0.12318943 -0.33280554]\n",
      "New theta_0 : [ 0.00763519 -0.06802489  0.02335933  0.10711279  0.04428153  0.08645363\n",
      "  0.45505072  0.04202256  0.05958813  0.14218073 -0.2240594  -0.16657776\n",
      "  0.12254143 -0.33419895]\n",
      "Training Error:  11.086561369690363\n",
      "====================================================================================================\n",
      "Iteration:  205\n",
      "Previous theta :  [ 0.00763519 -0.06802489  0.02335933  0.10711279  0.04428153  0.08645363\n",
      "  0.45505072  0.04202256  0.05958813  0.14218073 -0.2240594  -0.16657776\n",
      "  0.12254143 -0.33419895]\n",
      "New theta_0 : [ 0.00759566 -0.06820395  0.02328181  0.10621728  0.04423908  0.08465724\n",
      "  0.45327342  0.0412843   0.05668816  0.14318497 -0.22385582 -0.1675163\n",
      "  0.12190501 -0.33557437]\n",
      "Training Error:  11.06846235166785\n",
      "====================================================================================================\n",
      "Iteration:  206\n",
      "Previous theta :  [ 0.00759566 -0.06820395  0.02328181  0.10621728  0.04423908  0.08465724\n",
      "  0.45327342  0.0412843   0.05668816  0.14318497 -0.22385582 -0.1675163\n",
      "  0.12190501 -0.33557437]\n",
      "New theta_0 : [ 0.00755748 -0.06838395  0.0232145   0.10532972  0.04420056  0.08286953\n",
      "  0.45151407  0.04055925  0.05381027  0.1441826  -0.22365278 -0.16844271\n",
      "  0.12127993 -0.33693204]\n",
      "Training Error:  11.050650309030878\n",
      "====================================================================================================\n",
      "Iteration:  207\n",
      "Previous theta :  [ 0.00755748 -0.06838395  0.0232145   0.10532972  0.04420056  0.08286953\n",
      "  0.45151407  0.04055925  0.05381027  0.1441826  -0.22365278 -0.16844271\n",
      "  0.12127993 -0.33693204]\n",
      "New theta_0 : [ 0.00752063 -0.06856486  0.02315717  0.10445004  0.04416587  0.08109046\n",
      "  0.44977249  0.03984721  0.05095426  0.14517365 -0.22345032 -0.16935715\n",
      "  0.12066596 -0.33827217]\n",
      "Training Error:  11.033120019182103\n",
      "====================================================================================================\n",
      "Iteration:  208\n",
      "Previous theta :  [ 0.00752063 -0.06856486  0.02315717  0.10445004  0.04416587  0.08109046\n",
      "  0.44977249  0.03984721  0.05095426  0.14517365 -0.22345032 -0.16935715\n",
      "  0.12066596 -0.33827217]\n",
      "New theta_0 : [ 0.00748504 -0.06874665  0.0231096   0.10357818  0.04413488  0.07931999\n",
      "  0.44804849  0.03914797  0.04811993  0.14615816 -0.22324845 -0.1702598\n",
      "  0.12006287 -0.339595  ]\n",
      "Training Error:  11.015866367013434\n",
      "====================================================================================================\n",
      "Iteration:  209\n",
      "Previous theta :  [ 0.00748504 -0.06874665  0.0231096   0.10357818  0.04413488  0.07931999\n",
      "  0.44804849  0.03914797  0.04811993  0.14615816 -0.22324845 -0.1702598\n",
      "  0.12006287 -0.339595  ]\n",
      "New theta_0 : [ 0.00745069 -0.0689293   0.02307158  0.10271405  0.0441075   0.07755808\n",
      "  0.44634188  0.03846134  0.04530706  0.14713615 -0.22304722 -0.17115082\n",
      "  0.11947044 -0.34090074]\n",
      "Training Error:  10.998884342506013\n",
      "====================================================================================================\n",
      "Iteration:  210\n",
      "Previous theta :  [ 0.00745069 -0.0689293   0.02307158  0.10271405  0.0441075   0.07755808\n",
      "  0.44634188  0.03846134  0.04530706  0.14713615 -0.22304722 -0.17115082\n",
      "  0.11947044 -0.34090074]\n",
      "New theta_0 : [ 0.00741754 -0.06911278  0.0230429   0.10185759  0.04408361  0.07580472\n",
      "  0.44465247  0.03778711  0.04251547  0.14810764 -0.22284664 -0.17203039\n",
      "  0.11888845 -0.34218961]\n",
      "Training Error:  10.982169038386063\n",
      "====================================================================================================\n",
      "Iteration:  211\n",
      "Previous theta :  [ 0.00741754 -0.06911278  0.0230429   0.10185759  0.04408361  0.07580472\n",
      "  0.44465247  0.03778711  0.04251547  0.14810764 -0.22284664 -0.17203039\n",
      "  0.11888845 -0.34218961]\n",
      "New theta_0 : [ 0.00738555 -0.06929708  0.02302334  0.10100874  0.04406312  0.07405985\n",
      "  0.44298008  0.0371251   0.03974495  0.14907268 -0.22264673 -0.17289865\n",
      "  0.1183167  -0.34346182]\n",
      "Training Error:  10.965715647835282\n",
      "====================================================================================================\n",
      "Iteration:  212\n",
      "Previous theta :  [ 0.00738555 -0.06929708  0.02302334  0.10100874  0.04406312  0.07405985\n",
      "  0.44298008  0.0371251   0.03974495  0.14907268 -0.22264673 -0.17289865\n",
      "  0.1183167  -0.34346182]\n",
      "New theta_0 : [ 0.00735468 -0.06948217  0.02301271  0.10016742  0.04404593  0.07232346\n",
      "  0.44132453  0.03647512  0.03699532  0.1500313  -0.22244754 -0.17375578\n",
      "  0.11775496 -0.34471759]\n",
      "Training Error:  10.949519462254468\n",
      "====================================================================================================\n",
      "Iteration:  213\n",
      "Previous theta :  [ 0.00735468 -0.06948217  0.02301271  0.10016742  0.04404593  0.07232346\n",
      "  0.44132453  0.03647512  0.03699532  0.1500313  -0.22244754 -0.17375578\n",
      "  0.11775496 -0.34471759]\n",
      "New theta_0 : [ 0.0073249  -0.06966803  0.02301081  0.09933357  0.04403194  0.0705955\n",
      "  0.43968563  0.03583698  0.03426637  0.15098351 -0.22224907 -0.17460193\n",
      "  0.11720304 -0.34595713]\n",
      "Training Error:  10.93357586907904\n",
      "====================================================================================================\n",
      "Iteration:  214\n",
      "Previous theta :  [ 0.0073249  -0.06966803  0.02301081  0.09933357  0.04403194  0.0705955\n",
      "  0.43968563  0.03583698  0.03426637  0.15098351 -0.22224907 -0.17460193\n",
      "  0.11720304 -0.34595713]\n",
      "New theta_0 : [ 0.00729617 -0.06985463  0.02301744  0.09850713  0.04402105  0.06887593\n",
      "  0.43806322  0.03521048  0.03155793  0.15192937 -0.22205135 -0.17543725\n",
      "  0.11666074 -0.34718064]\n",
      "Training Error:  10.917880349645328\n",
      "====================================================================================================\n",
      "Iteration:  215\n",
      "Previous theta :  [ 0.00729617 -0.06985463  0.02301744  0.09850713  0.04402105  0.06887593\n",
      "  0.43806322  0.03521048  0.03155793  0.15192937 -0.22205135 -0.17543725\n",
      "  0.11666074 -0.34718064]\n",
      "New theta_0 : [ 0.00726847 -0.07004196  0.0230324   0.09768803  0.04401317  0.06716474\n",
      "  0.4364571   0.03459546  0.0288698   0.15286889 -0.2218544  -0.1762619\n",
      "  0.11612787 -0.34838833]\n",
      "Training Error:  10.902428477106305\n",
      "====================================================================================================\n",
      "Iteration:  216\n",
      "Previous theta :  [ 0.00726847 -0.07004196  0.0230324   0.09768803  0.04401317  0.06716474\n",
      "  0.4364571   0.03459546  0.0288698   0.15286889 -0.2218544  -0.1762619\n",
      "  0.11612787 -0.34838833]\n",
      "New theta_0 : [ 0.00724176 -0.07022998  0.02305552  0.0968762   0.04400822  0.06546188\n",
      "  0.43486712  0.03399173  0.02620181  0.15380212 -0.22165824 -0.17707602\n",
      "  0.11560422 -0.3495804 ]\n",
      "Training Error:  10.887215914395663\n",
      "====================================================================================================\n",
      "Iteration:  217\n",
      "Previous theta :  [ 0.00724176 -0.07022998  0.02305552  0.0968762   0.04400822  0.06546188\n",
      "  0.43486712  0.03399173  0.02620181  0.15380212 -0.22165824 -0.17707602\n",
      "  0.11560422 -0.3495804 ]\n",
      "New theta_0 : [ 0.007216   -0.07041867  0.0230866   0.09607158  0.0440061   0.06376732\n",
      "  0.43329309  0.03339911  0.02355376  0.15472908 -0.2214629  -0.17787978\n",
      "  0.11508962 -0.35075705]\n",
      "Training Error:  10.872238412239048\n",
      "====================================================================================================\n",
      "Iteration:  218\n",
      "Previous theta :  [ 0.007216   -0.07041867  0.0230866   0.09607158  0.0440061   0.06376732\n",
      "  0.43329309  0.03339911  0.02355376  0.15472908 -0.2214629  -0.17787978\n",
      "  0.11508962 -0.35075705]\n",
      "New theta_0 : [ 0.00719118 -0.07060802  0.02312547  0.09527411  0.04400674  0.06208102\n",
      "  0.43173485  0.03281742  0.02092547  0.1556498  -0.22126838 -0.17867331\n",
      "  0.11458388 -0.35191847]\n",
      "Training Error:  10.857491807211327\n",
      "====================================================================================================\n",
      "Iteration:  219\n",
      "Previous theta :  [ 0.00719118 -0.07060802  0.02312547  0.09527411  0.04400674  0.06208102\n",
      "  0.43173485  0.03281742  0.02092547  0.1556498  -0.22126838 -0.17867331\n",
      "  0.11458388 -0.35191847]\n",
      "New theta_0 : [ 0.00716727 -0.07079801  0.02317194  0.09448372  0.04401005  0.06040296\n",
      "  0.43019223  0.03224651  0.01831678  0.15656433 -0.22107472 -0.17945675\n",
      "  0.11408682 -0.35306487]\n",
      "Training Error:  10.842972019838848\n",
      "====================================================================================================\n",
      "Iteration:  220\n",
      "Previous theta :  [ 0.00716727 -0.07079801  0.02317194  0.09448372  0.04401005  0.06040296\n",
      "  0.43019223  0.03224651  0.01831678  0.15656433 -0.22107472 -0.17945675\n",
      "  0.11408682 -0.35306487]\n",
      "New theta_0 : [ 0.00714423 -0.07098859  0.02322584  0.09370035  0.04401595  0.05873309\n",
      "  0.42866505  0.03168618  0.01572749  0.15747269 -0.22088192 -0.18023025\n",
      "  0.11359827 -0.35419642]\n",
      "Training Error:  10.828675052745561\n",
      "====================================================================================================\n",
      "Iteration:  221\n",
      "Previous theta :  [ 0.00714423 -0.07098859  0.02322584  0.09370035  0.04401595  0.05873309\n",
      "  0.42866505  0.03168618  0.01572749  0.15747269 -0.22088192 -0.18023025\n",
      "  0.11359827 -0.35419642]\n",
      "New theta_0 : [ 0.00712203 -0.07117977  0.02328701  0.09292394  0.04402436  0.0570714\n",
      "  0.42715316  0.03113629  0.01315745  0.15837492 -0.22069    -0.18099395\n",
      "  0.11311806 -0.35531332]\n",
      "Training Error:  10.814596988842004\n",
      "====================================================================================================\n",
      "Iteration:  222\n",
      "Previous theta :  [ 0.00712203 -0.07117977  0.02328701  0.09292394  0.04402436  0.0570714\n",
      "  0.42715316  0.03113629  0.01315745  0.15837492 -0.22069    -0.18099395\n",
      "  0.11311806 -0.35531332]\n",
      "New theta_0 : [ 0.00710067 -0.07137151  0.02335526  0.09215444  0.04403521  0.05541783\n",
      "  0.4256564   0.03059665  0.01060647  0.15927105 -0.22049898 -0.18174799\n",
      "  0.11264601 -0.35641576]\n",
      "Training Error:  10.800733989556132\n",
      "====================================================================================================\n",
      "Iteration:  223\n",
      "Previous theta :  [ 0.00710067 -0.07137151  0.02335526  0.09215444  0.04403521  0.05541783\n",
      "  0.4256564   0.03059665  0.01060647  0.15927105 -0.22049898 -0.18174799\n",
      "  0.11264601 -0.35641576]\n",
      "New theta_0 : [ 0.0070801  -0.07156379  0.02343045  0.09139176  0.04404842  0.05377237\n",
      "  0.4241746   0.03006712  0.00807439  0.16016112 -0.22030887 -0.1824925\n",
      "  0.11218197 -0.35750393]\n",
      "Training Error:  10.787082293105028\n",
      "====================================================================================================\n",
      "Iteration:  224\n",
      "Previous theta :  [ 0.0070801  -0.07156379  0.02343045  0.09139176  0.04404842  0.05377237\n",
      "  0.4241746   0.03006712  0.00807439  0.16016112 -0.22030887 -0.1824925\n",
      "  0.11218197 -0.35750393]\n",
      "New theta_0 : [ 0.00706031 -0.0717566   0.0235124   0.09063587  0.04406392  0.05213497\n",
      "  0.42270759  0.02954752  0.00556104  0.16104516 -0.22011969 -0.18322761\n",
      "  0.11172577 -0.35857799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.77363821280647\n",
      "====================================================================================================\n",
      "Iteration:  225\n",
      "Previous theta :  [ 0.00706031 -0.0717566   0.0235124   0.09063587  0.04406392  0.05213497\n",
      "  0.42270759  0.02954752  0.00556104  0.16104516 -0.22011969 -0.18322761\n",
      "  0.11172577 -0.35857799]\n",
      "New theta_0 : [ 0.00704127 -0.07194991  0.02360095  0.0898867   0.04408164  0.0505056\n",
      "  0.42125523  0.0290377   0.00306625  0.16192321 -0.21993145 -0.18395346\n",
      "  0.11127725 -0.35963814]\n",
      "Training Error:  10.76039813542949\n",
      "====================================================================================================\n",
      "Iteration:  226\n",
      "Previous theta :  [ 0.00704127 -0.07194991  0.02360095  0.0898867   0.04408164  0.0505056\n",
      "  0.42125523  0.0290377   0.00306625  0.16192321 -0.21993145 -0.18395346\n",
      "  0.11127725 -0.35963814]\n",
      "New theta_0 : [ 0.00702296 -0.07214369  0.02369596  0.08914419  0.04410152  0.04888424\n",
      "  0.41981736  0.02853751  0.00058986  0.16279529 -0.21974417 -0.18467018\n",
      "  0.11083627 -0.36068456]\n",
      "Training Error:  10.747358519582974\n",
      "====================================================================================================\n",
      "Iteration:  227\n",
      "Previous theta :  [ 0.00702296 -0.07214369  0.02369596  0.08914419  0.04410152  0.04888424\n",
      "  0.41981736  0.02853751  0.00058986  0.16279529 -0.21974417 -0.18467018\n",
      "  0.11083627 -0.36068456]\n",
      "New theta_0 : [ 0.00700537 -0.07233793  0.02379726  0.08840828  0.04412349  0.04727084\n",
      "  0.41839383  0.02804679 -0.0018683   0.16366146 -0.21955785 -0.18537788\n",
      "  0.11040266 -0.3617174 ]\n",
      "Training Error:  10.734515894141378\n",
      "====================================================================================================\n",
      "Iteration:  228\n",
      "Previous theta :  [ 0.00700537 -0.07233793  0.02379726  0.08840828  0.04412349  0.04727084\n",
      "  0.41839383  0.02804679 -0.0018683   0.16366146 -0.21955785 -0.18537788\n",
      "  0.11040266 -0.3617174 ]\n",
      "New theta_0 : [ 0.00698846 -0.07253262  0.02390471  0.08767891  0.04414747  0.04566538\n",
      "  0.41698447  0.02756539 -0.00430838  0.16452173 -0.21937251 -0.18607671\n",
      "  0.10997629 -0.36273686]\n",
      "Training Error:  10.72186685670677\n",
      "====================================================================================================\n",
      "Iteration:  229\n",
      "Previous theta :  [ 0.00698846 -0.07253262  0.02390471  0.08767891  0.04414747  0.04566538\n",
      "  0.41698447  0.02756539 -0.00430838  0.16452173 -0.21937251 -0.18607671\n",
      "  0.10997629 -0.36273686]\n",
      "New theta_0 : [ 0.00697222 -0.07272771  0.02401816  0.08695603  0.04417342  0.04406782\n",
      "  0.41558914  0.02709315 -0.00673054  0.16537615 -0.21918815 -0.18676678\n",
      "  0.10955701 -0.3637431 ]\n",
      "Training Error:  10.70940807210627\n",
      "====================================================================================================\n",
      "Iteration:  230\n",
      "Previous theta :  [ 0.00697222 -0.07272771  0.02401816  0.08695603  0.04417342  0.04406782\n",
      "  0.41558914  0.02709315 -0.00673054  0.16537615 -0.21918815 -0.18676678\n",
      "  0.10955701 -0.3637431 ]\n",
      "New theta_0 : [ 0.00695663 -0.07292321  0.02413747  0.08623958  0.04420126  0.04247813\n",
      "  0.41420769  0.02662994 -0.00913494  0.16622474 -0.2190048  -0.18744822\n",
      "  0.10914468 -0.36473629]\n",
      "Training Error:  10.697136270924085\n",
      "====================================================================================================\n",
      "Iteration:  231\n",
      "Previous theta :  [ 0.00695663 -0.07292321  0.02413747  0.08623958  0.04420126  0.04247813\n",
      "  0.41420769  0.02662994 -0.00913494  0.16622474 -0.2190048  -0.18744822\n",
      "  0.10914468 -0.36473629]\n",
      "New theta_0 : [ 0.00694167 -0.07311908  0.02426248  0.08552951  0.04423094  0.04089628\n",
      "  0.41283997  0.02617561 -0.01152173  0.16706756 -0.21882245 -0.18812114\n",
      "  0.10873915 -0.36571659]\n",
      "Training Error:  10.685048248067357\n",
      "====================================================================================================\n",
      "Iteration:  232\n",
      "Previous theta :  [ 0.00694167 -0.07311908  0.02426248  0.08552951  0.04423094  0.04089628\n",
      "  0.41283997  0.02617561 -0.01152173  0.16706756 -0.21882245 -0.18812114\n",
      "  0.10873915 -0.36571659]\n",
      "New theta_0 : [ 0.00692732 -0.07331531  0.02439308  0.08482575  0.04426241  0.03932223\n",
      "  0.41148584  0.02573001 -0.01389107  0.16790462 -0.21864113 -0.18878567\n",
      "  0.1083403  -0.36668418]\n",
      "Training Error:  10.673140861364974\n",
      "====================================================================================================\n",
      "Iteration:  233\n",
      "Previous theta :  [ 0.00692732 -0.07331531  0.02439308  0.08482575  0.04426241  0.03932223\n",
      "  0.41148584  0.02573001 -0.01389107  0.16790462 -0.21864113 -0.18878567\n",
      "  0.1083403  -0.36668418]\n",
      "New theta_0 : [ 0.00691357 -0.07351188  0.02452911  0.08412826  0.0442956   0.03775595\n",
      "  0.41014514  0.02529301 -0.01624311  0.16873598 -0.21846083 -0.18944191\n",
      "  0.10794799 -0.3676392 ]\n",
      "Training Error:  10.661411030198627\n",
      "====================================================================================================\n",
      "Iteration:  234\n",
      "Previous theta :  [ 0.00691357 -0.07351188  0.02452911  0.08412826  0.0442956   0.03775595\n",
      "  0.41014514  0.02529301 -0.01624311  0.16873598 -0.21846083 -0.18944191\n",
      "  0.10794799 -0.3676392 ]\n",
      "New theta_0 : [ 0.00690039 -0.07370876  0.02467045  0.08343698  0.04433046  0.03619742\n",
      "  0.40881775  0.02486446 -0.018578    0.16956165 -0.21828157 -0.19008999\n",
      "  0.1075621  -0.36858183]\n",
      "Training Error:  10.649855734165335\n",
      "====================================================================================================\n",
      "Iteration:  235\n",
      "Previous theta :  [ 0.00690039 -0.07370876  0.02467045  0.08343698  0.04433046  0.03619742\n",
      "  0.40881775  0.02486446 -0.018578    0.16956165 -0.21828157 -0.19008999\n",
      "  0.1075621  -0.36858183]\n",
      "New theta_0 : [ 0.00688778 -0.07390595  0.02481696  0.08275185  0.04436694  0.03464658\n",
      "  0.40750351  0.02444423 -0.02089588  0.17038168 -0.21810335 -0.19073002\n",
      "  0.10718248 -0.36951222]\n",
      "Training Error:  10.638472011770691\n",
      "====================================================================================================\n",
      "Iteration:  236\n",
      "Previous theta :  [ 0.00688778 -0.07390595  0.02481696  0.08275185  0.04436694  0.03464658\n",
      "  0.40750351  0.02444423 -0.02089588  0.17038168 -0.21810335 -0.19073002\n",
      "  0.10718248 -0.36951222]\n",
      "New theta_0 : [ 0.00687571 -0.07410341  0.02496851  0.08207283  0.04440498  0.03310343\n",
      "  0.40620228  0.02403218 -0.0231969   0.17119611 -0.21792618 -0.19136211\n",
      "  0.10680903 -0.37043053]\n",
      "Training Error:  10.62725695915214\n",
      "====================================================================================================\n",
      "Iteration:  237\n",
      "Previous theta :  [ 0.00687571 -0.07410341  0.02496851  0.08207283  0.04440498  0.03310343\n",
      "  0.40620228  0.02403218 -0.0231969   0.17119611 -0.21792618 -0.19136211\n",
      "  0.10680903 -0.37043053]\n",
      "New theta_0 : [ 0.00686418 -0.07430114  0.02512498  0.08139985  0.04444453  0.03156792\n",
      "  0.40491394  0.02362818 -0.02548122  0.17200496 -0.21775007 -0.19198637\n",
      "  0.10644162 -0.37133691]\n",
      "Training Error:  10.61620772883155\n",
      "====================================================================================================\n",
      "Iteration:  238\n",
      "Previous theta :  [ 0.00686418 -0.07430114  0.02512498  0.08139985  0.04444453  0.03156792\n",
      "  0.40491394  0.02362818 -0.02548122  0.17200496 -0.21775007 -0.19198637\n",
      "  0.10644162 -0.37133691]\n",
      "New theta_0 : [ 0.00685316 -0.07449911  0.02528624  0.08073287  0.04448555  0.03004001\n",
      "  0.40363833  0.0232321  -0.02774896  0.17280828 -0.21757503 -0.19260291\n",
      "  0.10608013 -0.37223152]\n",
      "Training Error:  10.605321528496445\n",
      "====================================================================================================\n",
      "Iteration:  239\n",
      "Previous theta :  [ 0.00685316 -0.07449911  0.02528624  0.08073287  0.04448555  0.03004001\n",
      "  0.40363833  0.0232321  -0.02774896  0.17280828 -0.21757503 -0.19260291\n",
      "  0.10608013 -0.37223152]\n",
      "New theta_0 : [ 0.00684264 -0.07469731  0.02545217  0.08007183  0.04452799  0.02851969\n",
      "  0.40237533  0.02284382 -0.03000027  0.17360609 -0.21740105 -0.19321184\n",
      "  0.10572444 -0.3731145 ]\n",
      "Training Error:  10.594595619809153\n",
      "====================================================================================================\n",
      "Iteration:  240\n",
      "Previous theta :  [ 0.00684264 -0.07469731  0.02545217  0.08007183  0.04452799  0.02851969\n",
      "  0.40237533  0.02284382 -0.03000027  0.17360609 -0.21740105 -0.19321184\n",
      "  0.10572444 -0.3731145 ]\n",
      "New theta_0 : [ 0.00683261 -0.07489571  0.02562266  0.07941668  0.0445718   0.02700691\n",
      "  0.4011248   0.0224632  -0.0322353   0.17439844 -0.21722815 -0.19381325\n",
      "  0.10537445 -0.373986  ]\n",
      "Training Error:  10.5840273172433\n",
      "====================================================================================================\n",
      "Iteration:  241\n",
      "Previous theta :  [ 0.00683261 -0.07489571  0.02562266  0.07941668  0.0445718   0.02700691\n",
      "  0.4011248   0.0224632  -0.0322353   0.17439844 -0.21722815 -0.19381325\n",
      "  0.10537445 -0.373986  ]\n",
      "New theta_0 : [ 0.00682305 -0.0750943   0.02579757  0.07876737  0.04461694  0.02550165\n",
      "  0.39988661  0.02209012 -0.03445418  0.17518537 -0.21705633 -0.19440726\n",
      "  0.10503003 -0.37484617]\n",
      "Training Error:  10.57361398694695\n",
      "====================================================================================================\n",
      "Iteration:  242\n",
      "Previous theta :  [ 0.00682305 -0.0750943   0.02579757  0.07876737  0.04461694  0.02550165\n",
      "  0.39988661  0.02209012 -0.03445418  0.17518537 -0.21705633 -0.19440726\n",
      "  0.10503003 -0.37484617]\n",
      "New theta_0 : [ 0.00681396 -0.07529306  0.02597681  0.07812386  0.04466335  0.02400387\n",
      "  0.39866062  0.02172445 -0.03665704  0.17596689 -0.2168856  -0.19499396\n",
      "  0.10469108 -0.37569515]\n",
      "Training Error:  10.563353045631793\n",
      "====================================================================================================\n",
      "Iteration:  243\n",
      "Previous theta :  [ 0.00681396 -0.07529306  0.02597681  0.07812386  0.04466335  0.02400387\n",
      "  0.39866062  0.02172445 -0.03665704  0.17596689 -0.2168856  -0.19499396\n",
      "  0.10469108 -0.37569515]\n",
      "New theta_0 : [ 0.00680531 -0.07549198  0.02616025  0.07748608  0.044711    0.02251354\n",
      "  0.39744671  0.02136608 -0.03884403  0.17674306 -0.21671596 -0.19557346\n",
      "  0.1043575  -0.37653309]\n",
      "Training Error:  10.55324195948778\n",
      "====================================================================================================\n",
      "Iteration:  244\n",
      "Previous theta :  [ 0.00680531 -0.07549198  0.02616025  0.07748608  0.044711    0.02251354\n",
      "  0.39744671  0.02136608 -0.03884403  0.17674306 -0.21671596 -0.19557346\n",
      "  0.1043575  -0.37653309]\n",
      "New theta_0 : [ 0.0067971  -0.07569103  0.02634779  0.076854    0.04475985  0.02103063\n",
      "  0.39624475  0.02101488 -0.04101528  0.17751391 -0.21654741 -0.19614586\n",
      "  0.10402917 -0.37736013]\n",
      "Training Error:  10.543278243122584\n",
      "====================================================================================================\n",
      "Iteration:  245\n",
      "Previous theta :  [ 0.0067971  -0.07569103  0.02634779  0.076854    0.04475985  0.02103063\n",
      "  0.39624475  0.02101488 -0.04101528  0.17751391 -0.21654741 -0.19614586\n",
      "  0.10402917 -0.37736013]\n",
      "New theta_0 : [ 0.00678931 -0.07589021  0.02653932  0.07622755  0.04480986  0.01955511\n",
      "  0.39505462  0.02067074 -0.04317091  0.17827946 -0.21637996 -0.19671125\n",
      "  0.10370599 -0.37817641]\n",
      "Training Error:  10.533459458525336\n",
      "====================================================================================================\n",
      "Iteration:  246\n",
      "Previous theta :  [ 0.00678931 -0.07589021  0.02653932  0.07622755  0.04480986  0.01955511\n",
      "  0.39505462  0.02067074 -0.04317091  0.17827946 -0.21637996 -0.19671125\n",
      "  0.10370599 -0.37817641]\n",
      "New theta_0 : [ 0.00678194 -0.07608949  0.02673472  0.0756067   0.04486098  0.01808694\n",
      "  0.39387618  0.02033354 -0.04531107  0.17903977 -0.21621361 -0.19726973\n",
      "  0.10338788 -0.37898206]\n",
      "Training Error:  10.52378321405405\n",
      "====================================================================================================\n",
      "Iteration:  247\n",
      "Previous theta :  [ 0.00678194 -0.07608949  0.02673472  0.0756067   0.04486098  0.01808694\n",
      "  0.39387618  0.02033354 -0.04531107  0.17903977 -0.21621361 -0.19726973\n",
      "  0.10338788 -0.37898206]\n",
      "New theta_0 : [ 0.00677497 -0.07628885  0.0269339   0.07499139  0.04491318  0.01662611\n",
      "  0.39270931  0.02000316 -0.04743587  0.17979485 -0.21604837 -0.19782139\n",
      "  0.10307472 -0.37977722]\n",
      "Training Error:  10.514247163446196\n",
      "====================================================================================================\n",
      "Iteration:  248\n",
      "Previous theta :  [ 0.00677497 -0.07628885  0.0269339   0.07499139  0.04491318  0.01662611\n",
      "  0.39270931  0.02000316 -0.04743587  0.17979485 -0.21604837 -0.19782139\n",
      "  0.10307472 -0.37977722]\n",
      "New theta_0 : [ 0.00676839 -0.07648829  0.02713675  0.07438158  0.04496641  0.01517256\n",
      "  0.3915539   0.01967951 -0.04954546  0.18054476 -0.21588423 -0.19836634\n",
      "  0.10276642 -0.38056202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.504849004851849\n",
      "====================================================================================================\n",
      "Iteration:  249\n",
      "Previous theta :  [ 0.00676839 -0.07648829  0.02713675  0.07438158  0.04496641  0.01517256\n",
      "  0.3915539   0.01967951 -0.04954546  0.18054476 -0.21588423 -0.19836634\n",
      "  0.10276642 -0.38056202]\n",
      "New theta_0 : [ 0.00676219 -0.07668778  0.02734317  0.07377721  0.04502065  0.01372628\n",
      "  0.39040981  0.01936245 -0.05163995  0.18128951 -0.2157212  -0.19890465\n",
      "  0.10246289 -0.3813366 ]\n",
      "Training Error:  10.495586479888953\n",
      "====================================================================================================\n",
      "Iteration:  250\n",
      "Previous theta :  [ 0.00676219 -0.07668778  0.02734317  0.07377721  0.04502065  0.01372628\n",
      "  0.39040981  0.01936245 -0.05163995  0.18128951 -0.2157212  -0.19890465\n",
      "  0.10246289 -0.3813366 ]\n",
      "New theta_0 : [ 0.00675637 -0.07688731  0.02755307  0.07317825  0.04507586  0.01228722\n",
      "  0.38927693  0.01905188 -0.05371947  0.18202915 -0.21555928 -0.19943642\n",
      "  0.10216403 -0.38210109]\n",
      "Training Error:  10.4864573727201\n",
      "====================================================================================================\n",
      "Iteration:  251\n",
      "Previous theta :  [ 0.00675637 -0.07688731  0.02755307  0.07317825  0.04507586  0.01228722\n",
      "  0.38927693  0.01905188 -0.05371947  0.18202915 -0.21555928 -0.19943642\n",
      "  0.10216403 -0.38210109]\n",
      "New theta_0 : [ 0.0067509  -0.07708687  0.02776634  0.07258463  0.045132    0.01085537\n",
      "  0.38815514  0.01874771 -0.05578415  0.18276372 -0.21539848 -0.19996174\n",
      "  0.10186976 -0.38285561]\n",
      "Training Error:  10.477459509150382\n",
      "====================================================================================================\n",
      "Iteration:  252\n",
      "Previous theta :  [ 0.0067509  -0.07708687  0.02776634  0.07258463  0.045132    0.01085537\n",
      "  0.38815514  0.01874771 -0.05578415  0.18276372 -0.21539848 -0.19996174\n",
      "  0.10186976 -0.38285561]\n",
      "New theta_0 : [ 0.00674579 -0.07728644  0.02798289  0.07199633  0.04518904  0.00943069\n",
      "  0.38704433  0.01844981 -0.05783411  0.18349324 -0.21523878 -0.20048071\n",
      "  0.10157999 -0.3836003 ]\n",
      "Training Error:  10.468590755745801\n",
      "====================================================================================================\n",
      "Iteration:  253\n",
      "Previous theta :  [ 0.00674579 -0.07728644  0.02798289  0.07199633  0.04518904  0.00943069\n",
      "  0.38704433  0.01844981 -0.05783411  0.18349324 -0.21523878 -0.20048071\n",
      "  0.10157999 -0.3836003 ]\n",
      "New theta_0 : [ 0.00674101 -0.077486    0.02820263  0.07141329  0.04524695  0.00801315\n",
      "  0.38594437  0.01815809 -0.05986947  0.18421775 -0.21508021 -0.20099339\n",
      "  0.10129463 -0.38433527]\n",
      "Training Error:  10.459849018971752\n",
      "====================================================================================================\n",
      "Iteration:  254\n",
      "Previous theta :  [ 0.00674101 -0.077486    0.02820263  0.07141329  0.04524695  0.00801315\n",
      "  0.38594437  0.01815809 -0.05986947  0.18421775 -0.21508021 -0.20099339\n",
      "  0.10129463 -0.38433527]\n",
      "New theta_0 : [ 0.00673658 -0.07768554  0.02842546  0.07083546  0.04530569  0.00660271\n",
      "  0.38485515  0.01787243 -0.06189035  0.18493728 -0.21492275 -0.20149989\n",
      "  0.10101359 -0.38506066]\n",
      "Training Error:  10.451232244351125\n",
      "====================================================================================================\n",
      "Iteration:  255\n",
      "Previous theta :  [ 0.00673658 -0.07768554  0.02842546  0.07083546  0.04530569  0.00660271\n",
      "  0.38485515  0.01787243 -0.06189035  0.18493728 -0.21492275 -0.20149989\n",
      "  0.10101359 -0.38506066]\n",
      "New theta_0 : [ 0.00673247 -0.07788504  0.0286513   0.07026281  0.04536524  0.00519935\n",
      "  0.38377656  0.01759275 -0.06389687  0.18565188 -0.2147664  -0.20200028\n",
      "  0.1007368  -0.38577658]\n",
      "Training Error:  10.44273841564155\n",
      "====================================================================================================\n",
      "Iteration:  256\n",
      "Previous theta :  [ 0.00673247 -0.07788504  0.0286513   0.07026281  0.04536524  0.00519935\n",
      "  0.38377656  0.01759275 -0.06389687  0.18565188 -0.2147664  -0.20200028\n",
      "  0.1007368  -0.38577658]\n",
      "New theta_0 : [ 0.00672867 -0.07808449  0.02888006  0.06969528  0.04542555  0.00380303\n",
      "  0.38270849  0.01731895 -0.06588915  0.18636157 -0.21461118 -0.20249465\n",
      "  0.10046417 -0.38648315]\n",
      "Training Error:  10.434365554031338\n",
      "====================================================================================================\n",
      "Iteration:  257\n",
      "Previous theta :  [ 0.00672867 -0.07808449  0.02888006  0.06969528  0.04542555  0.00380303\n",
      "  0.38270849  0.01731895 -0.06588915  0.18636157 -0.21461118 -0.20249465\n",
      "  0.10046417 -0.38648315]\n",
      "New theta_0 : [ 0.00672518 -0.07828389  0.02911165  0.06913283  0.04548661  0.00241374\n",
      "  0.38165082  0.01705091 -0.06786731  0.18706639 -0.21445707 -0.20298308\n",
      "  0.10019563 -0.3871805 ]\n",
      "Training Error:  10.426111717353718\n",
      "====================================================================================================\n",
      "Iteration:  258\n",
      "Previous theta :  [ 0.00672518 -0.07828389  0.02911165  0.06913283  0.04548661  0.00241374\n",
      "  0.38165082  0.01705091 -0.06786731  0.18706639 -0.21445707 -0.20298308\n",
      "  0.10019563 -0.3871805 ]\n",
      "New theta_0 : [ 0.006722   -0.0784832   0.02934599  0.06857542  0.04554839  0.00103142\n",
      "  0.38060345  0.01678855 -0.06983145  0.18776637 -0.21430408 -0.20346565\n",
      "  0.09993109 -0.38786874]\n",
      "Training Error:  10.417974999318874\n",
      "====================================================================================================\n",
      "Iteration:  259\n",
      "Previous theta :  [ 0.006722   -0.0784832   0.02934599  0.06857542  0.04554839  0.00103142\n",
      "  0.38060345  0.01678855 -0.06983145  0.18776637 -0.21430408 -0.20346565\n",
      "  0.09993109 -0.38786874]\n",
      "New theta_0 : [ 6.71910710e-03 -7.86824223e-02  2.95829888e-02  6.80230087e-02\n",
      "  4.56108524e-02 -3.43935482e-04  3.79566261e-01  1.65317710e-02\n",
      " -7.17817048e-02  1.88461549e-01 -2.14152199e-01 -2.03942438e-01\n",
      "  9.96704771e-02 -3.88547995e-01]\n",
      "Training Error:  10.409953528763426\n",
      "====================================================================================================\n",
      "Iteration:  260\n",
      "Previous theta :  [ 6.71910710e-03 -7.86824223e-02  2.95829888e-02  6.80230087e-02\n",
      "  4.56108524e-02 -3.43935482e-04  3.79566261e-01  1.65317710e-02\n",
      " -7.17817048e-02  1.88461549e-01 -2.14152199e-01 -2.03942438e-01\n",
      "  9.96704771e-02 -3.88547995e-01]\n",
      "New theta_0 : [ 0.0067165  -0.07888154  0.02982257  0.06747555  0.04567398 -0.00171237\n",
      "  0.37853915  0.01628048 -0.07371818  0.18915196 -0.21400144 -0.20441353\n",
      "  0.09941372 -0.38921837]\n",
      "Training Error:  10.402045468916905\n",
      "====================================================================================================\n",
      "Iteration:  261\n",
      "Previous theta :  [ 0.0067165  -0.07888154  0.02982257  0.06747555  0.04567398 -0.00171237\n",
      "  0.37853915  0.01628048 -0.07371818  0.18915196 -0.21400144 -0.20441353\n",
      "  0.09941372 -0.38921837]\n",
      "New theta_0 : [ 0.00671417 -0.07908054  0.03006466  0.06693299  0.04573773 -0.00307391\n",
      "  0.37752201  0.01603458 -0.07564098  0.18983763 -0.21385179 -0.20487899\n",
      "  0.09916075 -0.38987998]\n",
      "Training Error:  10.394249016684881\n",
      "====================================================================================================\n",
      "Iteration:  262\n",
      "Previous theta :  [ 0.00671417 -0.07908054  0.03006466  0.06693299  0.04573773 -0.00307391\n",
      "  0.37752201  0.01603458 -0.07564098  0.18983763 -0.21385179 -0.20487899\n",
      "  0.09916075 -0.38987998]\n",
      "New theta_0 : [ 0.00671212 -0.07927941  0.03030916  0.06639531  0.0458021  -0.00442859\n",
      "  0.37651474  0.01579398 -0.07755022  0.1905186  -0.21370326 -0.20533891\n",
      "  0.09891149 -0.39053294]\n",
      "Training Error:  10.386562401948266\n",
      "====================================================================================================\n",
      "Iteration:  263\n",
      "Previous theta :  [ 0.00671212 -0.07927941  0.03030916  0.06639531  0.0458021  -0.00442859\n",
      "  0.37651474  0.01579398 -0.07755022  0.1905186  -0.21370326 -0.20533891\n",
      "  0.09891149 -0.39053294]\n",
      "New theta_0 : [ 0.00671033 -0.07947814  0.03055602  0.06586244  0.04586704 -0.00577643\n",
      "  0.37551724  0.0155586  -0.07944602  0.1911949  -0.21355585 -0.20579335\n",
      "  0.09866587 -0.39117736]\n",
      "Training Error:  10.3789838868785\n",
      "====================================================================================================\n",
      "Iteration:  264\n",
      "Previous theta :  [ 0.00671033 -0.07947814  0.03055602  0.06586244  0.04586704 -0.00577643\n",
      "  0.37551724  0.0155586  -0.07944602  0.1911949  -0.21355585 -0.20579335\n",
      "  0.09866587 -0.39117736]\n",
      "New theta_0 : [ 0.0067088  -0.07967671  0.03080514  0.06533437  0.04593255 -0.00711747\n",
      "  0.37452939  0.01532835 -0.08132847  0.19186656 -0.21340954 -0.20624239\n",
      "  0.09842383 -0.39181334]\n",
      "Training Error:  10.371511765268192\n",
      "====================================================================================================\n",
      "Iteration:  265\n",
      "Previous theta :  [ 0.0067088  -0.07967671  0.03080514  0.06533437  0.04593255 -0.00711747\n",
      "  0.37452939  0.01532835 -0.08132847  0.19186656 -0.21340954 -0.20624239\n",
      "  0.09842383 -0.39181334]\n",
      "New theta_0 : [ 0.00670752 -0.07987511  0.03105647  0.06481103  0.04599859 -0.00845173\n",
      "  0.3735511   0.01510313 -0.08319769  0.19253362 -0.21326434 -0.20668611\n",
      "  0.09818529 -0.392441  ]\n",
      "Training Error:  10.364144361876884\n",
      "====================================================================================================\n",
      "Iteration:  266\n",
      "Previous theta :  [ 0.00670752 -0.07987511  0.03105647  0.06481103  0.04599859 -0.00845173\n",
      "  0.3735511   0.01510313 -0.08319769  0.19253362 -0.21326434 -0.20668611\n",
      "  0.09818529 -0.392441  ]\n",
      "New theta_0 : [ 0.00670649 -0.08007333  0.03130991  0.06429239  0.04606514 -0.00977926\n",
      "  0.37258227  0.01488286 -0.08505379  0.19319611 -0.21312026 -0.20712457\n",
      "  0.09795019 -0.39306045]\n",
      "Training Error:  10.356880031791567\n",
      "====================================================================================================\n",
      "Iteration:  267\n",
      "Previous theta :  [ 0.00670649 -0.08007333  0.03130991  0.06429239  0.04606514 -0.00977926\n",
      "  0.37258227  0.01488286 -0.08505379  0.19319611 -0.21312026 -0.20712457\n",
      "  0.09795019 -0.39306045]\n",
      "New theta_0 : [ 0.00670569 -0.08027136  0.03156542  0.06377841  0.04613218 -0.01110006\n",
      "  0.3716228   0.01466746 -0.08689687  0.19385406 -0.21297728 -0.20755785\n",
      "  0.09771847 -0.39367178]\n",
      "Training Error:  10.34971715980162\n",
      "====================================================================================================\n",
      "Iteration:  268\n",
      "Previous theta :  [ 0.00670569 -0.08027136  0.03156542  0.06377841  0.04613218 -0.01110006\n",
      "  0.3716228   0.01466746 -0.08689687  0.19385406 -0.21297728 -0.20755785\n",
      "  0.09771847 -0.39367178]\n",
      "New theta_0 : [ 0.00670513 -0.08046919  0.0318229   0.06326906  0.04619969 -0.01241419\n",
      "  0.37067259  0.01445685 -0.08872703  0.19450751 -0.2128354  -0.20798602\n",
      "  0.09749006 -0.3942751 ]\n",
      "Training Error:  10.342654159787802\n",
      "====================================================================================================\n",
      "Iteration:  269\n",
      "Previous theta :  [ 0.00670513 -0.08046919  0.0318229   0.06326906  0.04619969 -0.01241419\n",
      "  0.37067259  0.01445685 -0.08872703  0.19450751 -0.2128354  -0.20798602\n",
      "  0.09749006 -0.3942751 ]\n",
      "New theta_0 : [ 0.0067048  -0.0806668   0.0320823   0.06276428  0.04626764 -0.01372165\n",
      "  0.36973154  0.01425094 -0.09054438  0.19515648 -0.21269462 -0.20840914\n",
      "  0.09726491 -0.39487051]\n",
      "Training Error:  10.335689474125024\n",
      "====================================================================================================\n",
      "Iteration:  270\n",
      "Previous theta :  [ 0.0067048  -0.0806668   0.0320823   0.06276428  0.04626764 -0.01372165\n",
      "  0.36973154  0.01425094 -0.09054438  0.19515648 -0.21269462 -0.20840914\n",
      "  0.09726491 -0.39487051]\n",
      "New theta_0 : [ 0.0067047  -0.08086419  0.03234355  0.06226404  0.04633602 -0.01502249\n",
      "  0.36879956  0.01404965 -0.09234901  0.19580102 -0.21255495 -0.20882728\n",
      "  0.09704295 -0.39545811]\n",
      "Training Error:  10.3288215730985\n",
      "====================================================================================================\n",
      "Iteration:  271\n",
      "Previous theta :  [ 0.0067047  -0.08086419  0.03234355  0.06226404  0.04633602 -0.01502249\n",
      "  0.36879956  0.01404965 -0.09234901  0.19580102 -0.21255495 -0.20882728\n",
      "  0.09704295 -0.39545811]\n",
      "New theta_0 : [ 0.00670481 -0.08106133  0.03260658  0.06176831  0.0464048  -0.01631674\n",
      "  0.36787654  0.01385291 -0.09414104  0.19644114 -0.21241637 -0.20924051\n",
      "  0.09682412 -0.39603801]\n",
      "Training Error:  10.322048954333049\n",
      "====================================================================================================\n",
      "Iteration:  272\n",
      "Previous theta :  [ 0.00670481 -0.08106133  0.03260658  0.06176831  0.0464048  -0.01631674\n",
      "  0.36787654  0.01385291 -0.09414104  0.19644114 -0.21241637 -0.20924051\n",
      "  0.09682412 -0.39603801]\n",
      "New theta_0 : [ 0.00670513 -0.08125823  0.03287133  0.06127704  0.04647397 -0.01760442\n",
      "  0.36696241  0.01366063 -0.09592057  0.19707689 -0.21227889 -0.2096489\n",
      "  0.09660837 -0.3966103 ]\n",
      "Training Error:  10.31537014223518\n",
      "====================================================================================================\n",
      "Iteration:  273\n",
      "Previous theta :  [ 0.00670513 -0.08125823  0.03287133  0.06127704  0.04647397 -0.01760442\n",
      "  0.36696241  0.01366063 -0.09592057  0.19707689 -0.21227889 -0.2096489\n",
      "  0.09660837 -0.3966103 ]\n",
      "New theta_0 : [ 0.00670566 -0.08145487  0.03313773  0.06079019  0.04654351 -0.01888556\n",
      "  0.36605706  0.01347274 -0.09768768  0.1977083  -0.21214249 -0.21005251\n",
      "  0.09639563 -0.39717508]\n",
      "Training Error:  10.308783687447677\n",
      "====================================================================================================\n",
      "Iteration:  274\n",
      "Previous theta :  [ 0.00670566 -0.08145487  0.03313773  0.06079019  0.04654351 -0.01888556\n",
      "  0.36605706  0.01347274 -0.09768768  0.1977083  -0.21214249 -0.21005251\n",
      "  0.09639563 -0.39717508]\n",
      "New theta_0 : [ 0.00670639 -0.08165124  0.03340573  0.06030773  0.04661339 -0.02016019\n",
      "  0.3651604   0.01328916 -0.09944248  0.19833539 -0.21200719 -0.2104514\n",
      "  0.09618586 -0.39773244]\n",
      "Training Error:  10.302288166316389\n",
      "====================================================================================================\n",
      "Iteration:  275\n",
      "Previous theta :  [ 0.00670639 -0.08165124  0.03340573  0.06030773  0.04661339 -0.02016019\n",
      "  0.3651604   0.01328916 -0.09944248  0.19833539 -0.21200719 -0.2104514\n",
      "  0.09618586 -0.39773244]\n",
      "New theta_0 : [ 0.00670732 -0.08184733  0.03367526  0.05982962  0.04668361 -0.02142835\n",
      "  0.36427234  0.01310982 -0.10118507  0.1989582  -0.21187297 -0.21084564\n",
      "  0.095979   -0.39828248]\n",
      "Training Error:  10.29588218036897\n",
      "====================================================================================================\n",
      "Iteration:  276\n",
      "Previous theta :  [ 0.00670732 -0.08184733  0.03367526  0.05982962  0.04668361 -0.02142835\n",
      "  0.36427234  0.01310982 -0.10118507  0.1989582  -0.21187297 -0.21084564\n",
      "  0.095979   -0.39828248]\n",
      "New theta_0 : [ 0.00670844 -0.08204313  0.03394625  0.05935581  0.04675413 -0.02269005\n",
      "  0.3633928   0.01293465 -0.10291554  0.19957676 -0.21173984 -0.21123529\n",
      "  0.095775   -0.39882529]\n",
      "Training Error:  10.28956435580523\n",
      "====================================================================================================\n",
      "Iteration:  277\n",
      "Previous theta :  [ 0.00670844 -0.08204313  0.03394625  0.05935581  0.04675413 -0.02269005\n",
      "  0.3633928   0.01293465 -0.10291554  0.19957676 -0.21173984 -0.21123529\n",
      "  0.095775   -0.39882529]\n",
      "New theta_0 : [ 0.00670976 -0.08223863  0.03421867  0.05888628  0.04682495 -0.02394533\n",
      "  0.36252167  0.01276356 -0.10463399  0.2001911  -0.21160778 -0.21162041\n",
      "  0.0955738  -0.39936096]\n",
      "Training Error:  10.283333342998862\n",
      "====================================================================================================\n",
      "Iteration:  278\n",
      "Previous theta :  [ 0.00670976 -0.08223863  0.03421867  0.05888628  0.04682495 -0.02394533\n",
      "  0.36252167  0.01276356 -0.10463399  0.2001911  -0.21160778 -0.21162041\n",
      "  0.0955738  -0.39936096]\n",
      "New theta_0 : [ 0.00671125 -0.08243382  0.03449244  0.05842099  0.04689605 -0.02519422\n",
      "  0.36165888  0.01259651 -0.10634051  0.20080126 -0.2114768  -0.21200106\n",
      "  0.09537536 -0.39988959]\n",
      "Training Error:  10.277187816010317\n",
      "====================================================================================================\n",
      "Iteration:  279\n",
      "Previous theta :  [ 0.00671125 -0.08243382  0.03449244  0.05842099  0.04689605 -0.02519422\n",
      "  0.36165888  0.01259651 -0.10634051  0.20080126 -0.2114768  -0.21200106\n",
      "  0.09537536 -0.39988959]\n",
      "New theta_0 : [ 0.00671293 -0.08262869  0.03476751  0.0579599   0.04696742 -0.02643674\n",
      "  0.36080434  0.0124334  -0.1080352   0.20140726 -0.21134689 -0.2123773\n",
      "  0.09517961 -0.40041127]\n",
      "Training Error:  10.271126472110456\n",
      "====================================================================================================\n",
      "Iteration:  280\n",
      "Previous theta :  [ 0.00671293 -0.08262869  0.03476751  0.0579599   0.04696742 -0.02643674\n",
      "  0.36080434  0.0124334  -0.1080352   0.20140726 -0.21134689 -0.2123773\n",
      "  0.09517961 -0.40041127]\n",
      "New theta_0 : [ 0.00671478 -0.08282323  0.03504382  0.05750297  0.04703902 -0.02767293\n",
      "  0.35995795  0.01227417 -0.10971815  0.20200913 -0.21121805 -0.21274919\n",
      "  0.09498653 -0.40092608]\n",
      "Training Error:  10.265148031314848\n",
      "====================================================================================================\n",
      "Iteration:  281\n",
      "Previous theta :  [ 0.00671478 -0.08282323  0.03504382  0.05750297  0.04703902 -0.02767293\n",
      "  0.35995795  0.01227417 -0.10971815  0.20200913 -0.21121805 -0.21274919\n",
      "  0.09498653 -0.40092608]\n",
      "New theta_0 : [ 0.0067168  -0.08301744  0.03532133  0.05705018  0.04711086 -0.02890281\n",
      "  0.35911964  0.01211876 -0.11138945  0.2026069  -0.21109028 -0.21311679\n",
      "  0.09479605 -0.40143411]\n",
      "Training Error:  10.259251235928378\n",
      "====================================================================================================\n",
      "Iteration:  282\n",
      "Previous theta :  [ 0.0067168  -0.08301744  0.03532133  0.05705018  0.04711086 -0.02890281\n",
      "  0.35911964  0.01211876 -0.11138945  0.2026069  -0.21109028 -0.21311679\n",
      "  0.09479605 -0.40143411]\n",
      "New theta_0 : [ 0.00671899 -0.08321129  0.03559997  0.05660147  0.04718292 -0.03012641\n",
      "  0.35828932  0.0119671  -0.1130492   0.20320061 -0.21096356 -0.21348016\n",
      "  0.09460813 -0.40193544]\n",
      "Training Error:  10.253434850099984\n",
      "====================================================================================================\n",
      "Iteration:  283\n",
      "Previous theta :  [ 0.00671899 -0.08321129  0.03559997  0.05660147  0.04718292 -0.03012641\n",
      "  0.35828932  0.0119671  -0.1130492   0.20320061 -0.21096356 -0.21348016\n",
      "  0.09460813 -0.40193544]\n",
      "New theta_0 : [ 0.00672134 -0.0834048   0.03587971  0.05615682  0.04725518 -0.03134377\n",
      "  0.35746691  0.01181912 -0.11469748  0.20379028 -0.2108379  -0.21383934\n",
      "  0.09442273 -0.40243017]\n",
      "Training Error:  10.247697659387226\n",
      "====================================================================================================\n",
      "Iteration:  284\n",
      "Previous theta :  [ 0.00672134 -0.0834048   0.03587971  0.05615682  0.04725518 -0.03134377\n",
      "  0.35746691  0.01181912 -0.11469748  0.20379028 -0.2108379  -0.21383934\n",
      "  0.09442273 -0.40243017]\n",
      "New theta_0 : [ 0.00672386 -0.08359794  0.03616047  0.0557162   0.04732762 -0.0325549\n",
      "  0.35665233  0.01167476 -0.11633437  0.20437594 -0.2107133  -0.2141944\n",
      "  0.09423979 -0.40291838]\n",
      "Training Error:  10.242038470330524\n",
      "====================================================================================================\n",
      "Iteration:  285\n",
      "Previous theta :  [ 0.00672386 -0.08359794  0.03616047  0.0557162   0.04732762 -0.0325549\n",
      "  0.35665233  0.01167476 -0.11633437  0.20437594 -0.2107133  -0.2141944\n",
      "  0.09423979 -0.40291838]\n",
      "New theta_0 : [ 0.00672653 -0.0837907   0.03644223  0.05527956  0.04740024 -0.03375983\n",
      "  0.35584549  0.01153395 -0.11795998  0.20495763 -0.21058974 -0.21454539\n",
      "  0.09405928 -0.40340015]\n",
      "Training Error:  10.236456110036777\n",
      "====================================================================================================\n",
      "Iteration:  286\n",
      "Previous theta :  [ 0.00672653 -0.0837907   0.03644223  0.05527956  0.04740024 -0.03375983\n",
      "  0.35584549  0.01153395 -0.11795998  0.20495763 -0.21058974 -0.21454539\n",
      "  0.09405928 -0.40340015]\n",
      "New theta_0 : [ 0.00672935 -0.08398309  0.03672492  0.05484688  0.04747302 -0.0349586\n",
      "  0.35504631  0.01139663 -0.11957439  0.20553537 -0.21046723 -0.21489237\n",
      "  0.09388115 -0.40387555]\n",
      "Training Error:  10.230949425772188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  287\n",
      "Previous theta :  [ 0.00672935 -0.08398309  0.03672492  0.05484688  0.04747302 -0.0349586\n",
      "  0.35504631  0.01139663 -0.11957439  0.20553537 -0.21046723 -0.21489237\n",
      "  0.09388115 -0.40387555]\n",
      "New theta_0 : [ 0.00673232 -0.08417509  0.0370085   0.05441811  0.04754595 -0.03615123\n",
      "  0.35425472  0.01126275 -0.12117769  0.2061092  -0.21034576 -0.21523538\n",
      "  0.09370537 -0.40434469]\n",
      "Training Error:  10.225517284564049\n",
      "====================================================================================================\n",
      "Iteration:  288\n",
      "Previous theta :  [ 0.00673232 -0.08417509  0.0370085   0.05441811  0.04754595 -0.03615123\n",
      "  0.35425472  0.01126275 -0.12117769  0.2061092  -0.21034576 -0.21523538\n",
      "  0.09370537 -0.40434469]\n",
      "New theta_0 : [ 0.00673544 -0.08436669  0.03729292  0.05399323  0.04761901 -0.03733776\n",
      "  0.35347063  0.01113223 -0.12276995  0.20667913 -0.21022532 -0.21557448\n",
      "  0.09353188 -0.40480762]\n",
      "Training Error:  10.220158572811306\n",
      "====================================================================================================\n",
      "Iteration:  289\n",
      "Previous theta :  [ 0.00673544 -0.08436669  0.03729292  0.05399323  0.04761901 -0.03733776\n",
      "  0.35347063  0.01113223 -0.12276995  0.20667913 -0.21022532 -0.21557448\n",
      "  0.09353188 -0.40480762]\n",
      "New theta_0 : [ 0.0067387  -0.08455789  0.03757814  0.05357221  0.04769219 -0.0385182\n",
      "  0.35269396  0.01100502 -0.12435127  0.20724521 -0.21010592 -0.21590973\n",
      "  0.09336065 -0.40526444]\n",
      "Training Error:  10.214872195903663\n",
      "====================================================================================================\n",
      "Iteration:  290\n",
      "Previous theta :  [ 0.0067387  -0.08455789  0.03757814  0.05357221  0.04769219 -0.0385182\n",
      "  0.35269396  0.01100502 -0.12435127  0.20724521 -0.21010592 -0.21590973\n",
      "  0.09336065 -0.40526444]\n",
      "New theta_0 : [ 0.0067421  -0.08474867  0.03786411  0.053155    0.04776549 -0.03969258\n",
      "  0.35192465  0.01088106 -0.12592173  0.20780745 -0.20998754 -0.21624117\n",
      "  0.09319164 -0.40571522]\n",
      "Training Error:  10.209657077849075\n",
      "====================================================================================================\n",
      "Iteration:  291\n",
      "Previous theta :  [ 0.0067421  -0.08474867  0.03786411  0.053155    0.04776549 -0.03969258\n",
      "  0.35192465  0.01088106 -0.12592173  0.20780745 -0.20998754 -0.21624117\n",
      "  0.09319164 -0.40571522]\n",
      "New theta_0 : [ 0.00674563 -0.08493904  0.03815079  0.05274158  0.04783888 -0.04086094\n",
      "  0.35116261  0.0107603  -0.12748142  0.2083659  -0.20987018 -0.21656885\n",
      "  0.09302481 -0.40616004]\n",
      "Training Error:  10.20451216090937\n",
      "====================================================================================================\n",
      "Iteration:  292\n",
      "Previous theta :  [ 0.00674563 -0.08493904  0.03815079  0.05274158  0.04783888 -0.04086094\n",
      "  0.35116261  0.0107603  -0.12748142  0.2083659  -0.20987018 -0.21656885\n",
      "  0.09302481 -0.40616004]\n",
      "New theta_0 : [ 0.0067493  -0.08512898  0.03843813  0.05233191  0.04791236 -0.0420233\n",
      "  0.35040776  0.01064267 -0.12903041  0.20892057 -0.20975385 -0.21689282\n",
      "  0.09286012 -0.40659897]\n",
      "Training Error:  10.199436405243878\n",
      "====================================================================================================\n",
      "Iteration:  293\n",
      "Previous theta :  [ 0.0067493  -0.08512898  0.03843813  0.05233191  0.04791236 -0.0420233\n",
      "  0.35040776  0.01064267 -0.12903041  0.20892057 -0.20975385 -0.21689282\n",
      "  0.09286012 -0.40659897]\n",
      "New theta_0 : [ 0.0067531  -0.08531849  0.0387261   0.05192597  0.04798592 -0.04317969\n",
      "  0.34966004  0.01052811 -0.13056879  0.20947149 -0.20963852 -0.21721313\n",
      "  0.09269754 -0.40703208]\n",
      "Training Error:  10.19442878856082\n",
      "====================================================================================================\n",
      "Iteration:  294\n",
      "Previous theta :  [ 0.0067531  -0.08531849  0.0387261   0.05192597  0.04798592 -0.04317969\n",
      "  0.34966004  0.01052811 -0.13056879  0.20947149 -0.20963852 -0.21721313\n",
      "  0.09269754 -0.40703208]\n",
      "New theta_0 : [ 0.00675702 -0.08550756  0.03901465  0.05152371  0.04805955 -0.04433013\n",
      "  0.34891937  0.01041659 -0.13209664  0.21001869 -0.20952421 -0.21752984\n",
      "  0.09253702 -0.40745946]\n",
      "Training Error:  10.189488305776324\n",
      "====================================================================================================\n",
      "Iteration:  295\n",
      "Previous theta :  [ 0.00675702 -0.08550756  0.03901465  0.05152371  0.04805955 -0.04433013\n",
      "  0.34891937  0.01041659 -0.13209664  0.21001869 -0.20952421 -0.21752984\n",
      "  0.09253702 -0.40745946]\n",
      "New theta_0 : [ 0.00676107 -0.08569618  0.03930373  0.05112511  0.04813323 -0.04547465\n",
      "  0.34818568  0.01030803 -0.13361404  0.21056221 -0.2094109  -0.21784298\n",
      "  0.09237854 -0.40788118]\n",
      "Training Error:  10.184613968680857\n",
      "====================================================================================================\n",
      "Iteration:  296\n",
      "Previous theta :  [ 0.00676107 -0.08569618  0.03930373  0.05112511  0.04813323 -0.04547465\n",
      "  0.34818568  0.01030803 -0.13361404  0.21056221 -0.2094109  -0.21784298\n",
      "  0.09237854 -0.40788118]\n",
      "New theta_0 : [ 0.00676524 -0.08588435  0.03959332  0.05073014  0.04820695 -0.04661329\n",
      "  0.34745889  0.01020239 -0.13512107  0.21110206 -0.20929859 -0.2181526\n",
      "  0.09222205 -0.4082973 ]\n",
      "Training Error:  10.179804805612921\n",
      "====================================================================================================\n",
      "Iteration:  297\n",
      "Previous theta :  [ 0.00676524 -0.08588435  0.03959332  0.05073014  0.04820695 -0.04661329\n",
      "  0.34745889  0.01020239 -0.13512107  0.21110206 -0.20929859 -0.2181526\n",
      "  0.09222205 -0.4082973 ]\n",
      "New theta_0 : [ 0.00676952 -0.08607205  0.03988337  0.05033876  0.04828072 -0.04774606\n",
      "  0.34673893  0.01009961 -0.13661781  0.21163828 -0.20918727 -0.21845875\n",
      "  0.09206753 -0.40870791]\n",
      "Training Error:  10.175059861139834\n",
      "====================================================================================================\n",
      "Iteration:  298\n",
      "Previous theta :  [ 0.00676952 -0.08607205  0.03988337  0.05033876  0.04828072 -0.04774606\n",
      "  0.34673893  0.01009961 -0.13661781  0.21163828 -0.20918727 -0.21845875\n",
      "  0.09206753 -0.40870791]\n",
      "New theta_0 : [ 0.00677393 -0.08625929  0.04017385  0.04995094  0.0483545  -0.048873\n",
      "  0.34602573  0.00999964 -0.13810434  0.21217089 -0.20907694 -0.21876148\n",
      "  0.09191494 -0.40911306]\n",
      "Training Error:  10.170378195745425\n",
      "====================================================================================================\n",
      "Iteration:  299\n",
      "Previous theta :  [ 0.00677393 -0.08625929  0.04017385  0.04995094  0.0483545  -0.048873\n",
      "  0.34602573  0.00999964 -0.13810434  0.21217089 -0.20907694 -0.21876148\n",
      "  0.09191494 -0.40911306]\n",
      "New theta_0 : [ 0.00677844 -0.08644606  0.04046471  0.04956666  0.04842831 -0.04999412\n",
      "  0.34531923  0.00990244 -0.13958074  0.21269993 -0.2089676  -0.21906082\n",
      "  0.09176424 -0.40951283]\n",
      "Training Error:  10.165758885524502\n",
      "====================================================================================================\n",
      "Iteration:  300\n",
      "Previous theta :  [ 0.00677844 -0.08644606  0.04046471  0.04956666  0.04842831 -0.04999412\n",
      "  0.34531923  0.00990244 -0.13958074  0.21269993 -0.2089676  -0.21906082\n",
      "  0.09176424 -0.40951283]\n",
      "New theta_0 : [ 0.00678307 -0.08663235  0.04075592  0.04918588  0.04850212 -0.05110947\n",
      "  0.34461935  0.00980794 -0.14104707  0.2132254  -0.20885923 -0.21935683\n",
      "  0.09161541 -0.40990729]\n",
      "Training Error:  10.16120102188392\n",
      "====================================================================================================\n",
      "Iteration:  301\n",
      "Previous theta :  [ 0.00678307 -0.08663235  0.04075592  0.04918588  0.04850212 -0.05110947\n",
      "  0.34461935  0.00980794 -0.14104707  0.2132254  -0.20885923 -0.21935683\n",
      "  0.09161541 -0.40990729]\n",
      "New theta_0 : [ 0.00678781 -0.08681816  0.04104744  0.04880857  0.04857593 -0.05221905\n",
      "  0.34392603  0.00971611 -0.14250343  0.21374736 -0.20875184 -0.21964955\n",
      "  0.09146841 -0.4102965 ]\n",
      "Training Error:  10.156703711250092\n",
      "====================================================================================================\n",
      "Iteration:  302\n",
      "Previous theta :  [ 0.00678781 -0.08681816  0.04104744  0.04880857  0.04857593 -0.05221905\n",
      "  0.34392603  0.00971611 -0.14250343  0.21374736 -0.20875184 -0.21964955\n",
      "  0.09146841 -0.4102965 ]\n",
      "New theta_0 : [ 0.00679265 -0.08700348  0.04133925  0.04843471  0.04864974 -0.05332291\n",
      "  0.34323919  0.00962689 -0.14394988  0.21426581 -0.20864542 -0.21993902\n",
      "  0.09132321 -0.41068053]\n",
      "Training Error:  10.152266074782812\n",
      "====================================================================================================\n",
      "Iteration:  303\n",
      "Previous theta :  [ 0.00679265 -0.08700348  0.04133925  0.04843471  0.04864974 -0.05332291\n",
      "  0.34323919  0.00962689 -0.14394988  0.21426581 -0.20864542 -0.21993902\n",
      "  0.09132321 -0.41068053]\n",
      "New theta_0 : [ 0.00679759 -0.0871883   0.0416313   0.04806426  0.04872352 -0.05442107\n",
      "  0.34255877  0.00954024 -0.14538649  0.21478079 -0.20853996 -0.22022528\n",
      "  0.09117978 -0.41105946]\n",
      "Training Error:  10.147887248095223\n",
      "====================================================================================================\n",
      "Iteration:  304\n",
      "Previous theta :  [ 0.00679759 -0.0871883   0.0416313   0.04806426  0.04872352 -0.05442107\n",
      "  0.34255877  0.00954024 -0.14538649  0.21478079 -0.20853996 -0.22022528\n",
      "  0.09117978 -0.41105946]\n",
      "New theta_0 : [ 0.00680264 -0.08737262  0.04192356  0.04769719  0.04879728 -0.05551355\n",
      "  0.34188471  0.0094561  -0.14681335  0.21529232 -0.20843546 -0.22050837\n",
      "  0.09103809 -0.41143333]\n",
      "Training Error:  10.1435663809798\n",
      "====================================================================================================\n",
      "Iteration:  305\n",
      "Previous theta :  [ 0.00680264 -0.08737262  0.04192356  0.04769719  0.04879728 -0.05551355\n",
      "  0.34188471  0.0094561  -0.14681335  0.21529232 -0.20843546 -0.22050837\n",
      "  0.09103809 -0.41143333]\n",
      "New theta_0 : [ 0.00680778 -0.08755643  0.042216    0.04733348  0.048871   -0.05660038\n",
      "  0.34121694  0.00937443 -0.14823053  0.21580043 -0.20833192 -0.22078834\n",
      "  0.09089811 -0.41180223]\n",
      "Training Error:  10.139302637140213\n",
      "====================================================================================================\n",
      "Iteration:  306\n",
      "Previous theta :  [ 0.00680778 -0.08755643  0.042216    0.04733348  0.048871   -0.05660038\n",
      "  0.34121694  0.00937443 -0.14823053  0.21580043 -0.20833192 -0.22078834\n",
      "  0.09089811 -0.41180223]\n",
      "New theta_0 : [ 0.00681302 -0.08773973  0.04250859  0.04697309  0.04894469 -0.05768159\n",
      "  0.3405554   0.00929519 -0.1496381   0.21630514 -0.20822932 -0.22106523\n",
      "  0.09075982 -0.4121662 ]\n",
      "Training Error:  10.135095193928908\n",
      "====================================================================================================\n",
      "Iteration:  307\n",
      "Previous theta :  [ 0.00681302 -0.08773973  0.04250859  0.04697309  0.04894469 -0.05768159\n",
      "  0.3405554   0.00929519 -0.1496381   0.21630514 -0.20822932 -0.22106523\n",
      "  0.09075982 -0.4121662 ]\n",
      "New theta_0 : [ 0.00681835 -0.08792252  0.04280129  0.04661599  0.04901832 -0.0587572\n",
      "  0.33990001  0.00921833 -0.15103613  0.21680648 -0.20812767 -0.22133907\n",
      "  0.09062318 -0.41252532]\n",
      "Training Error:  10.130943242090314\n",
      "====================================================================================================\n",
      "Iteration:  308\n",
      "Previous theta :  [ 0.00681835 -0.08792252  0.04280129  0.04661599  0.04901832 -0.0587572\n",
      "  0.33990001  0.00921833 -0.15103613  0.21680648 -0.20812767 -0.22133907\n",
      "  0.09062318 -0.41252532]\n",
      "New theta_0 : [ 0.00682378 -0.08810479  0.04309407  0.04626217  0.0490919  -0.05982723\n",
      "  0.33925072  0.00914381 -0.15242469  0.21730448 -0.20802696 -0.2216099\n",
      "  0.09048818 -0.41287964]\n",
      "Training Error:  10.126845985509506\n",
      "====================================================================================================\n",
      "Iteration:  309\n",
      "Previous theta :  [ 0.00682378 -0.08810479  0.04309407  0.04626217  0.0490919  -0.05982723\n",
      "  0.33925072  0.00914381 -0.15242469  0.21730448 -0.20802696 -0.2216099\n",
      "  0.09048818 -0.41287964]\n",
      "New theta_0 : [ 0.00682929 -0.08828653  0.04338692  0.04591158  0.04916542 -0.06089173\n",
      "  0.33860747  0.00907158 -0.15380385  0.21779916 -0.20792718 -0.22187777\n",
      "  0.09035477 -0.41322923]\n",
      "Training Error:  10.122802640966219\n",
      "====================================================================================================\n",
      "Iteration:  310\n",
      "Previous theta :  [ 0.00682929 -0.08828653  0.04338692  0.04591158  0.04916542 -0.06089173\n",
      "  0.33860747  0.00907158 -0.15380385  0.21779916 -0.20792718 -0.22187777\n",
      "  0.09035477 -0.41322923]\n",
      "New theta_0 : [ 0.0068349  -0.08846774  0.04367978  0.04556421  0.04923887 -0.0619507\n",
      "  0.33797019  0.00900161 -0.15517369  0.21829055 -0.20782832 -0.22214272\n",
      "  0.09022293 -0.41357414]\n",
      "Training Error:  10.118812437894103\n",
      "====================================================================================================\n",
      "Iteration:  311\n",
      "Previous theta :  [ 0.0068349  -0.08846774  0.04367978  0.04556421  0.04923887 -0.0619507\n",
      "  0.33797019  0.00900161 -0.15517369  0.21829055 -0.20782832 -0.22214272\n",
      "  0.09022293 -0.41357414]\n",
      "New theta_0 : [ 0.00684059 -0.08864841  0.04397264  0.04522002  0.04931224 -0.06300418\n",
      "  0.33733882  0.00893384 -0.15653427  0.21877867 -0.20773039 -0.22240477\n",
      "  0.09009265 -0.41391445]\n",
      "Training Error:  10.114874618145052\n",
      "====================================================================================================\n",
      "Iteration:  312\n",
      "Previous theta :  [ 0.00684059 -0.08864841  0.04397264  0.04522002  0.04931224 -0.06300418\n",
      "  0.33733882  0.00893384 -0.15653427  0.21877867 -0.20773039 -0.22240477\n",
      "  0.09009265 -0.41391445]\n",
      "New theta_0 : [ 0.00684636 -0.08882855  0.04426547  0.04487899  0.04938552 -0.06405219\n",
      "  0.33671331  0.00886824 -0.15788566  0.21926354 -0.20763338 -0.22266397\n",
      "  0.08996389 -0.41425019]\n",
      "Training Error:  10.110988435758552\n",
      "====================================================================================================\n",
      "Iteration:  313\n",
      "Previous theta :  [ 0.00684636 -0.08882855  0.04426547  0.04487899  0.04938552 -0.06405219\n",
      "  0.33671331  0.00886824 -0.15788566  0.21926354 -0.20763338 -0.22266397\n",
      "  0.08996389 -0.41425019]\n",
      "New theta_0 : [ 0.00685221 -0.08900814  0.04455824  0.04454109  0.04945872 -0.06509476\n",
      "  0.33609358  0.00880477 -0.15922794  0.21974519 -0.20753728 -0.22292036\n",
      "  0.08983663 -0.41458144]\n",
      "Training Error:  10.107153156735864\n",
      "====================================================================================================\n",
      "Iteration:  314\n",
      "Previous theta :  [ 0.00685221 -0.08900814  0.04455824  0.04454109  0.04945872 -0.06509476\n",
      "  0.33609358  0.00880477 -0.15922794  0.21974519 -0.20753728 -0.22292036\n",
      "  0.08983663 -0.41458144]\n",
      "New theta_0 : [ 0.00685815 -0.08918719  0.04485093  0.04420629  0.04953183 -0.06613191\n",
      "  0.33547959  0.00874338 -0.16056116  0.22022365 -0.20744208 -0.22317397\n",
      "  0.08971084 -0.41490825]\n",
      "Training Error:  10.103368058818996\n",
      "====================================================================================================\n",
      "Iteration:  315\n",
      "Previous theta :  [ 0.00685815 -0.08918719  0.04485093  0.04420629  0.04953183 -0.06613191\n",
      "  0.33547959  0.00874338 -0.16056116  0.22022365 -0.20744208 -0.22317397\n",
      "  0.08971084 -0.41490825]\n",
      "New theta_0 : [ 0.00686416 -0.08936568  0.0451435   0.04387457  0.04960483 -0.06716367\n",
      "  0.33487127  0.00868404 -0.1618854   0.22069894 -0.20734779 -0.22342483\n",
      "  0.0895865  -0.41523068]\n",
      "Training Error:  10.099632431274314\n",
      "====================================================================================================\n",
      "Iteration:  316\n",
      "Previous theta :  [ 0.00686416 -0.08936568  0.0451435   0.04387457  0.04960483 -0.06716367\n",
      "  0.33487127  0.00868404 -0.1618854   0.22069894 -0.20734779 -0.22342483\n",
      "  0.0895865  -0.41523068]\n",
      "New theta_0 : [ 0.00687025 -0.08954362  0.04543593  0.04354589  0.04967773 -0.06819006\n",
      "  0.33426857  0.00862671 -0.16320073  0.22117108 -0.20725439 -0.22367299\n",
      "  0.08946359 -0.41554878]\n",
      "Training Error:  10.095945574680696\n",
      "====================================================================================================\n",
      "Iteration:  317\n",
      "Previous theta :  [ 0.00687025 -0.08954362  0.04543593  0.04354589  0.04967773 -0.06819006\n",
      "  0.33426857  0.00862671 -0.16320073  0.22117108 -0.20725439 -0.22367299\n",
      "  0.08946359 -0.41554878]\n",
      "New theta_0 : [ 0.00687641 -0.089721    0.0457282   0.04322024  0.04975052 -0.06921112\n",
      "  0.33367143  0.00857136 -0.1645072   0.22164009 -0.20716189 -0.22391847\n",
      "  0.08934208 -0.41586261]\n",
      "Training Error:  10.092306800722119\n",
      "====================================================================================================\n",
      "Iteration:  318\n",
      "Previous theta :  [ 0.00687641 -0.089721    0.0457282   0.04322024  0.04975052 -0.06921112\n",
      "  0.33367143  0.00857136 -0.1645072   0.22164009 -0.20716189 -0.22391847\n",
      "  0.08934208 -0.41586261]\n",
      "New theta_0 : [ 0.00688265 -0.08989781  0.04602028  0.04289759  0.04982319 -0.07022685\n",
      "  0.33307979  0.00851793 -0.16580489  0.22210601 -0.20707027 -0.22416131\n",
      "  0.08922196 -0.41617222]\n",
      "Training Error:  10.088715431984587\n",
      "====================================================================================================\n",
      "Iteration:  319\n",
      "Previous theta :  [ 0.00688265 -0.08989781  0.04602028  0.04289759  0.04982319 -0.07022685\n",
      "  0.33307979  0.00851793 -0.16580489  0.22210601 -0.20707027 -0.22416131\n",
      "  0.08922196 -0.41617222]\n",
      "New theta_0 : [ 0.00688896 -0.09007406  0.04631215  0.0425779   0.04989573 -0.0712373\n",
      "  0.3324936   0.00846641 -0.16709385  0.22256885 -0.20697952 -0.22440155\n",
      "  0.08910319 -0.41647766]\n",
      "Training Error:  10.085170801757306\n",
      "====================================================================================================\n",
      "Iteration:  320\n",
      "Previous theta :  [ 0.00688896 -0.09007406  0.04631215  0.0425779   0.04989573 -0.0712373\n",
      "  0.3324936   0.00846641 -0.16709385  0.22256885 -0.20697952 -0.22440155\n",
      "  0.08910319 -0.41647766]\n",
      "New theta_0 : [ 0.00689533 -0.09024975  0.04660378  0.04226116  0.04996815 -0.07224248\n",
      "  0.3319128   0.00841674 -0.16837416  0.22302864 -0.20688966 -0.22463921\n",
      "  0.08898577 -0.416779  ]\n",
      "Training Error:  10.081672253837981\n",
      "====================================================================================================\n",
      "Iteration:  321\n",
      "Previous theta :  [ 0.00689533 -0.09024975  0.04660378  0.04226116  0.04996815 -0.07224248\n",
      "  0.3319128   0.00841674 -0.16837416  0.22302864 -0.20688966 -0.22463921\n",
      "  0.08898577 -0.416779  ]\n",
      "New theta_0 : [ 0.00690178 -0.09042485  0.04689515  0.04194734  0.05004044 -0.07324242\n",
      "  0.33133734  0.0083689  -0.16964587  0.22348539 -0.20680066 -0.22487434\n",
      "  0.08886966 -0.41707628]\n",
      "Training Error:  10.07821914234218\n",
      "====================================================================================================\n",
      "Iteration:  322\n",
      "Previous theta :  [ 0.00690178 -0.09042485  0.04689515  0.04194734  0.05004044 -0.07324242\n",
      "  0.33133734  0.0083689  -0.16964587  0.22348539 -0.20680066 -0.22487434\n",
      "  0.08886966 -0.41707628]\n",
      "New theta_0 : [ 0.00690829 -0.09059939  0.04718624  0.04163642  0.05011259 -0.07423715\n",
      "  0.33076716  0.00832285 -0.17090906  0.22393915 -0.20671252 -0.22510696\n",
      "  0.08875484 -0.41736955]\n",
      "Training Error:  10.074810831516626\n",
      "====================================================================================================\n",
      "Iteration:  323\n",
      "Previous theta :  [ 0.00690829 -0.09059939  0.04718624  0.04163642  0.05011259 -0.07423715\n",
      "  0.33076716  0.00832285 -0.17090906  0.22393915 -0.20671252 -0.22510696\n",
      "  0.08875484 -0.41736955]\n",
      "New theta_0 : [ 0.00691486 -0.09077334  0.04747703  0.04132836  0.0501846  -0.07522668\n",
      "  0.3302022   0.00827855 -0.17216378  0.22438991 -0.20662525 -0.22533711\n",
      "  0.0886413  -0.41765886]\n",
      "Training Error:  10.071446695556375\n",
      "====================================================================================================\n",
      "Iteration:  324\n",
      "Previous theta :  [ 0.00691486 -0.09077334  0.04747703  0.04132836  0.0501846  -0.07522668\n",
      "  0.3302022   0.00827855 -0.17216378  0.22438991 -0.20662525 -0.22533711\n",
      "  0.0886413  -0.41765886]\n",
      "New theta_0 : [ 0.0069215  -0.09094671  0.04776749  0.04102315  0.05025646 -0.07621105\n",
      "  0.32964243  0.00823598 -0.17341009  0.22483772 -0.20653883 -0.22556481\n",
      "  0.08852902 -0.41794427]\n",
      "Training Error:  10.068126118425766\n",
      "====================================================================================================\n",
      "Iteration:  325\n",
      "Previous theta :  [ 0.0069215  -0.09094671  0.04776749  0.04102315  0.05025646 -0.07621105\n",
      "  0.32964243  0.00823598 -0.17341009  0.22483772 -0.20653883 -0.22556481\n",
      "  0.08852902 -0.41794427]\n",
      "New theta_0 : [ 0.00692819 -0.09111949  0.04805761  0.04072076  0.05032818 -0.07719027\n",
      "  0.32908777  0.00819509 -0.17464806  0.22528259 -0.20645325 -0.2257901\n",
      "  0.08841798 -0.41822582]\n",
      "Training Error:  10.064848493683051\n",
      "====================================================================================================\n",
      "Iteration:  326\n",
      "Previous theta :  [ 0.00692819 -0.09111949  0.04805761  0.04072076  0.05032818 -0.07719027\n",
      "  0.32908777  0.00819509 -0.17464806  0.22528259 -0.20645325 -0.2257901\n",
      "  0.08841798 -0.41822582]\n",
      "New theta_0 : [ 0.00693495 -0.09129169  0.04834736  0.04042117  0.05039974 -0.07816438\n",
      "  0.32853819  0.00815586 -0.17587775  0.22572454 -0.20636852 -0.22601301\n",
      "  0.08830815 -0.41850357]\n",
      "Training Error:  10.061613224308626\n",
      "====================================================================================================\n",
      "Iteration:  327\n",
      "Previous theta :  [ 0.00693495 -0.09129169  0.04834736  0.04042117  0.05039974 -0.07816438\n",
      "  0.32853819  0.00815586 -0.17587775  0.22572454 -0.20636852 -0.22601301\n",
      "  0.08830815 -0.41850357]\n",
      "New theta_0 : [ 0.00694177 -0.0914633   0.04863673  0.04012434  0.05047114 -0.07913339\n",
      "  0.32799363  0.00811825 -0.17709921  0.22616359 -0.20628462 -0.22623356\n",
      "  0.08819952 -0.41877756]\n",
      "Training Error:  10.058419722536819\n",
      "====================================================================================================\n",
      "Iteration:  328\n",
      "Previous theta :  [ 0.00694177 -0.0914633   0.04863673  0.04012434  0.05047114 -0.07913339\n",
      "  0.32799363  0.00811825 -0.17709921  0.22616359 -0.20628462 -0.22623356\n",
      "  0.08819952 -0.41877756]\n",
      "New theta_0 : [ 0.00694864 -0.09163431  0.04892568  0.03983027  0.05054237 -0.08009734\n",
      "  0.32745403  0.00808223 -0.17831252  0.22659978 -0.20620156 -0.2264518\n",
      "  0.08809206 -0.41904783]\n",
      "Training Error:  10.055267409691066\n",
      "====================================================================================================\n",
      "Iteration:  329\n",
      "Previous theta :  [ 0.00694864 -0.09163431  0.04892568  0.03983027  0.05054237 -0.08009734\n",
      "  0.32745403  0.00808223 -0.17831252  0.22659978 -0.20620156 -0.2264518\n",
      "  0.08809206 -0.41904783]\n",
      "New theta_0 : [ 0.00695557 -0.09180473  0.04921422  0.03953891  0.05061345 -0.08105623\n",
      "  0.32691936  0.00804777 -0.17951772  0.22703311 -0.20611932 -0.22666775\n",
      "  0.08798578 -0.41931445]\n",
      "Training Error:  10.052155716022519\n",
      "====================================================================================================\n",
      "Iteration:  330\n",
      "Previous theta :  [ 0.00695557 -0.09180473  0.04921422  0.03953891  0.05061345 -0.08105623\n",
      "  0.32691936  0.00804777 -0.17951772  0.22703311 -0.20611932 -0.22666775\n",
      "  0.08798578 -0.41931445]\n",
      "New theta_0 : [ 0.00696255 -0.09197455  0.04950231  0.03925026  0.05068435 -0.08201011\n",
      "  0.32638956  0.00801485 -0.18071488  0.22746361 -0.2060379  -0.22688143\n",
      "  0.08788063 -0.41957745]\n",
      "Training Error:  10.049084080551886\n",
      "====================================================================================================\n",
      "Iteration:  331\n",
      "Previous theta :  [ 0.00696255 -0.09197455  0.04950231  0.03925026  0.05068435 -0.08201011\n",
      "  0.32638956  0.00801485 -0.18071488  0.22746361 -0.2060379  -0.22688143\n",
      "  0.08788063 -0.41957745]\n",
      "New theta_0 : [ 0.00696959 -0.09214377  0.04978994  0.03896429  0.05075508 -0.08295899\n",
      "  0.32586457  0.00798342 -0.18190405  0.22789131 -0.2059573  -0.22709288\n",
      "  0.08777661 -0.41983688]\n",
      "Training Error:  10.046051950914523\n",
      "====================================================================================================\n",
      "Iteration:  332\n",
      "Previous theta :  [ 0.00696959 -0.09214377  0.04978994  0.03896429  0.05075508 -0.08295899\n",
      "  0.32586457  0.00798342 -0.18190405  0.22789131 -0.2059573  -0.22709288\n",
      "  0.08777661 -0.41983688]\n",
      "New theta_0 : [ 0.00697667 -0.09231239  0.05007709  0.03868096  0.05082563 -0.0839029\n",
      "  0.32534436  0.00795346 -0.1830853   0.22831622 -0.20587751 -0.22730212\n",
      "  0.0876737  -0.42009278]\n",
      "Training Error:  10.043058783208647\n",
      "====================================================================================================\n",
      "Iteration:  333\n",
      "Previous theta :  [ 0.00697667 -0.09231239  0.05007709  0.03868096  0.05082563 -0.0839029\n",
      "  0.32534436  0.00795346 -0.1830853   0.22831622 -0.20587751 -0.22730212\n",
      "  0.0876737  -0.42009278]\n",
      "New theta_0 : [ 0.00698381 -0.09248041  0.05036374  0.03840027  0.050896   -0.08484186\n",
      "  0.32482887  0.00792494 -0.18425867  0.22873837 -0.20579853 -0.22750918\n",
      "  0.08757188 -0.42034521]\n",
      "Training Error:  10.040104041846643\n",
      "====================================================================================================\n",
      "Iteration:  334\n",
      "Previous theta :  [ 0.00698381 -0.09248041  0.05036374  0.03840027  0.050896   -0.08484186\n",
      "  0.32482887  0.00792494 -0.18425867  0.22873837 -0.20579853 -0.22750918\n",
      "  0.08757188 -0.42034521]\n",
      "New theta_0 : [ 0.00699099 -0.09264782  0.05064988  0.03812219  0.05096619 -0.0857759\n",
      "  0.32431806  0.00789783 -0.18542424  0.22915777 -0.20572034 -0.22771409\n",
      "  0.08747114 -0.4205942 ]\n",
      "Training Error:  10.037187199409352\n",
      "====================================================================================================\n",
      "Iteration:  335\n",
      "Previous theta :  [ 0.00699099 -0.09264782  0.05064988  0.03812219  0.05096619 -0.0857759\n",
      "  0.32431806  0.00789783 -0.18542424  0.22915777 -0.20572034 -0.22771409\n",
      "  0.08747114 -0.4205942 ]\n",
      "New theta_0 : [ 0.00699822 -0.09281461  0.05093549  0.03784669  0.05103619 -0.08670503\n",
      "  0.32381188  0.00787211 -0.18658205  0.22957445 -0.20564295 -0.22791688\n",
      "  0.08737146 -0.4208398 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  10.034307736503314\n",
      "====================================================================================================\n",
      "Iteration:  336\n",
      "Previous theta :  [ 0.00699822 -0.09281461  0.05093549  0.03784669  0.05103619 -0.08670503\n",
      "  0.32381188  0.00787211 -0.18658205  0.22957445 -0.20564295 -0.22791688\n",
      "  0.08737146 -0.4208398 ]\n",
      "New theta_0 : [ 0.0070055  -0.0929808   0.05122055  0.03757375  0.051106   -0.08762928\n",
      "  0.32331028  0.00784774 -0.18773216  0.22998842 -0.20556634 -0.22811758\n",
      "  0.08727283 -0.42108205]\n",
      "Training Error:  10.031465141620862\n",
      "====================================================================================================\n",
      "Iteration:  337\n",
      "Previous theta :  [ 0.0070055  -0.0929808   0.05122055  0.03757375  0.051106   -0.08762928\n",
      "  0.32331028  0.00784774 -0.18773216  0.22998842 -0.20556634 -0.22811758\n",
      "  0.08727283 -0.42108205]\n",
      "New theta_0 : [ 0.00701282 -0.09314638  0.05150506  0.03730336  0.05117562 -0.08854868\n",
      "  0.32281322  0.0078247  -0.18887462  0.23039972 -0.20549053 -0.2283162\n",
      "  0.08717522 -0.42132099]\n",
      "Training Error:  10.028658911003037\n",
      "====================================================================================================\n",
      "Iteration:  338\n",
      "Previous theta :  [ 0.00701282 -0.09314638  0.05150506  0.03730336  0.05117562 -0.08854868\n",
      "  0.32281322  0.0078247  -0.18887462  0.23039972 -0.20549053 -0.2283162\n",
      "  0.08717522 -0.42132099]\n",
      "New theta_0 : [ 0.00702019 -0.09331134  0.05178898  0.03703548  0.05124504 -0.08946325\n",
      "  0.32232065  0.00780296 -0.1900095   0.23080835 -0.20541548 -0.22851278\n",
      "  0.08707863 -0.42155667]\n",
      "Training Error:  10.02588854850524\n",
      "====================================================================================================\n",
      "Iteration:  339\n",
      "Previous theta :  [ 0.00702019 -0.09331134  0.05178898  0.03703548  0.05124504 -0.08946325\n",
      "  0.32232065  0.00780296 -0.1900095   0.23080835 -0.20541548 -0.22851278\n",
      "  0.08707863 -0.42155667]\n",
      "New theta_0 : [ 0.0070276  -0.09347569  0.05207231  0.0367701   0.05131427 -0.09037301\n",
      "  0.32183253  0.0077825  -0.19113684  0.23121434 -0.20534122 -0.22870733\n",
      "  0.08698303 -0.42178913]\n",
      "Training Error:  10.023153565465565\n",
      "====================================================================================================\n",
      "Iteration:  340\n",
      "Previous theta :  [ 0.0070276  -0.09347569  0.05207231  0.0367701   0.05131427 -0.09037301\n",
      "  0.32183253  0.0077825  -0.19113684  0.23121434 -0.20534122 -0.22870733\n",
      "  0.08698303 -0.42178913]\n",
      "New theta_0 : [ 0.00703505 -0.09363943  0.05235504  0.0365072   0.0513833  -0.09127798\n",
      "  0.32134881  0.00776328 -0.1922567   0.23161771 -0.20526772 -0.2288999\n",
      "  0.08688842 -0.42201841]\n",
      "Training Error:  10.020453480575751\n",
      "====================================================================================================\n",
      "Iteration:  341\n",
      "Previous theta :  [ 0.00703505 -0.09363943  0.05235504  0.0365072   0.0513833  -0.09127798\n",
      "  0.32134881  0.00776328 -0.1922567   0.23161771 -0.20526772 -0.2288999\n",
      "  0.08688842 -0.42201841]\n",
      "New theta_0 : [ 0.00704254 -0.09380254  0.05263715  0.03624675  0.05145212 -0.09217819\n",
      "  0.32086945  0.00774529 -0.19336914  0.23201847 -0.20519498 -0.2290905\n",
      "  0.08679478 -0.42224455]\n",
      "Training Error:  10.017787819754709\n",
      "====================================================================================================\n",
      "Iteration:  342\n",
      "Previous theta :  [ 0.00704254 -0.09380254  0.05263715  0.03624675  0.05145212 -0.09217819\n",
      "  0.32086945  0.00774529 -0.19336914  0.23201847 -0.20519498 -0.2290905\n",
      "  0.08679478 -0.42224455]\n",
      "New theta_0 : [ 0.00705006 -0.09396503  0.05291862  0.03598873  0.05152074 -0.09307366\n",
      "  0.3203944   0.00772849 -0.1944742   0.23241666 -0.205123   -0.22927915\n",
      "  0.0867021  -0.42246759]\n",
      "Training Error:  10.015156116024533\n",
      "====================================================================================================\n",
      "Iteration:  343\n",
      "Previous theta :  [ 0.00705006 -0.09396503  0.05291862  0.03598873  0.05152074 -0.09307366\n",
      "  0.3203944   0.00772849 -0.1944742   0.23241666 -0.205123   -0.22927915\n",
      "  0.0867021  -0.42246759]\n",
      "New theta_0 : [ 0.00705763 -0.09412691  0.05319945  0.03573312  0.05158915 -0.09396442\n",
      "  0.31992363  0.00771288 -0.19557195  0.23281228 -0.20505178 -0.22946588\n",
      "  0.08661036 -0.42268756]\n",
      "Training Error:  10.012557909388994\n",
      "====================================================================================================\n",
      "Iteration:  344\n",
      "Previous theta :  [ 0.00705763 -0.09412691  0.05319945  0.03573312  0.05158915 -0.09396442\n",
      "  0.31992363  0.00771288 -0.19557195  0.23281228 -0.20505178 -0.22946588\n",
      "  0.08661036 -0.42268756]\n",
      "New theta_0 : [ 0.00706523 -0.09428816  0.05347962  0.0354799   0.05165734 -0.09485048\n",
      "  0.31945708  0.0076984  -0.19666242  0.23320536 -0.2049813  -0.22965072\n",
      "  0.08651954 -0.42290452]\n",
      "Training Error:  10.009992746714392\n",
      "====================================================================================================\n",
      "Iteration:  345\n",
      "Previous theta :  [ 0.00706523 -0.09428816  0.05347962  0.0354799   0.05165734 -0.09485048\n",
      "  0.31945708  0.0076984  -0.19666242  0.23320536 -0.2049813  -0.22965072\n",
      "  0.08651954 -0.42290452]\n",
      "New theta_0 : [ 0.00707287 -0.09444879  0.05375911  0.03522905  0.05172533 -0.09573187\n",
      "  0.31899472  0.00768506 -0.19774568  0.23359591 -0.20491156 -0.22983368\n",
      "  0.08642964 -0.42311849]\n",
      "Training Error:  10.0074601816128\n",
      "====================================================================================================\n",
      "Iteration:  346\n",
      "Previous theta :  [ 0.00707287 -0.09444879  0.05375911  0.03522905  0.05172533 -0.09573187\n",
      "  0.31899472  0.00768506 -0.19774568  0.23359591 -0.20491156 -0.22983368\n",
      "  0.08642964 -0.42311849]\n",
      "New theta_0 : [ 0.00708054 -0.09460879  0.05403792  0.03498055  0.0517931  -0.09660862\n",
      "  0.31853651  0.00767282 -0.19882178  0.23398396 -0.20484256 -0.2300148\n",
      "  0.08634065 -0.42332952]\n",
      "Training Error:  10.004959774327528\n",
      "====================================================================================================\n",
      "Iteration:  347\n",
      "Previous theta :  [ 0.00708054 -0.09460879  0.05403792  0.03498055  0.0517931  -0.09660862\n",
      "  0.31853651  0.00767282 -0.19882178  0.23398396 -0.20484256 -0.2300148\n",
      "  0.08634065 -0.42332952]\n",
      "New theta_0 : [ 0.00708825 -0.09476817  0.05431603  0.03473438  0.05186066 -0.09748074\n",
      "  0.3180824   0.00766165 -0.19989076  0.23436953 -0.20477429 -0.23019408\n",
      "  0.08625254 -0.42353764]\n",
      "Training Error:  10.002491091620916\n",
      "====================================================================================================\n",
      "Iteration:  348\n",
      "Previous theta :  [ 0.00708825 -0.09476817  0.05431603  0.03473438  0.05186066 -0.09748074\n",
      "  0.3180824   0.00766165 -0.19989076  0.23436953 -0.20477429 -0.23019408\n",
      "  0.08625254 -0.42353764]\n",
      "New theta_0 : [ 0.00709599 -0.09492693  0.05459343  0.03449052  0.051928   -0.09834825\n",
      "  0.31763235  0.00765155 -0.20095268  0.23475263 -0.20470675 -0.23037157\n",
      "  0.08616531 -0.42374289]\n",
      "Training Error:  10.000053706664247\n",
      "====================================================================================================\n",
      "Iteration:  349\n",
      "Previous theta :  [ 0.00709599 -0.09492693  0.05459343  0.03449052  0.051928   -0.09834825\n",
      "  0.31763235  0.00765155 -0.20095268  0.23475263 -0.20470675 -0.23037157\n",
      "  0.08616531 -0.42374289]\n",
      "New theta_0 : [ 0.00710376 -0.09508506  0.05487011  0.03424894  0.05199511 -0.09921119\n",
      "  0.31718633  0.00764247 -0.20200759  0.23513327 -0.20463993 -0.23054727\n",
      "  0.08607894 -0.42394531]\n",
      "Training Error:  9.997647198929839\n",
      "====================================================================================================\n",
      "Iteration:  350\n",
      "Previous theta :  [ 0.00710376 -0.09508506  0.05487011  0.03424894  0.05199511 -0.09921119\n",
      "  0.31718633  0.00764247 -0.20200759  0.23513327 -0.20463993 -0.23054727\n",
      "  0.08607894 -0.42394531]\n",
      "New theta_0 : [ 0.00711156 -0.09524256  0.05514606  0.03400964  0.05206201 -0.10006956\n",
      "  0.31674429  0.00763441 -0.20305553  0.23551149 -0.20457382 -0.23072122\n",
      "  0.08599342 -0.42414492]\n",
      "Training Error:  9.995271154085216\n",
      "====================================================================================================\n",
      "Iteration:  351\n",
      "Previous theta :  [ 0.00711156 -0.09524256  0.05514606  0.03400964  0.05206201 -0.10006956\n",
      "  0.31674429  0.00763441 -0.20305553  0.23551149 -0.20457382 -0.23072122\n",
      "  0.08599342 -0.42414492]\n",
      "New theta_0 : [ 0.00711939 -0.09539943  0.05542126  0.03377258  0.05212868 -0.1009234\n",
      "  0.31630619  0.00762734 -0.20409657  0.2358873  -0.20450843 -0.23089343\n",
      "  0.08590875 -0.42434178]\n",
      "Training Error:  9.992925163889366\n",
      "====================================================================================================\n",
      "Iteration:  352\n",
      "Previous theta :  [ 0.00711939 -0.09539943  0.05542126  0.03377258  0.05212868 -0.1009234\n",
      "  0.31630619  0.00762734 -0.20409657  0.2358873  -0.20450843 -0.23089343\n",
      "  0.08590875 -0.42434178]\n",
      "New theta_0 : [ 0.00712725 -0.09555567  0.05569572  0.03353775  0.05219512 -0.10177273\n",
      "  0.315872    0.00762124 -0.20513074  0.23626071 -0.20444375 -0.23106392\n",
      "  0.0858249  -0.42453591]\n",
      "Training Error:  9.990608826090934\n",
      "====================================================================================================\n",
      "Iteration:  353\n",
      "Previous theta :  [ 0.00712725 -0.09555567  0.05569572  0.03353775  0.05219512 -0.10177273\n",
      "  0.315872    0.00762124 -0.20513074  0.23626071 -0.20444375 -0.23106392\n",
      "  0.0858249  -0.42453591]\n",
      "New theta_0 : [ 0.00713513 -0.09571128  0.05596941  0.03330513  0.05226134 -0.10261757\n",
      "  0.31544167  0.00761609 -0.20615809  0.23663175 -0.20437976 -0.23123271\n",
      "  0.08574187 -0.42472735]\n",
      "Training Error:  9.988321744328456\n",
      "====================================================================================================\n",
      "Iteration:  354\n",
      "Previous theta :  [ 0.00713513 -0.09571128  0.05596941  0.03330513  0.05226134 -0.10261757\n",
      "  0.31544167  0.00761609 -0.20615809  0.23663175 -0.20437976 -0.23123271\n",
      "  0.08574187 -0.42472735]\n",
      "New theta_0 : [ 0.00714304 -0.09586627  0.05624232  0.0330747   0.05232733 -0.10345793\n",
      "  0.31501517  0.00761187 -0.20717868  0.23700043 -0.20431648 -0.23139984\n",
      "  0.08565965 -0.42491613]\n",
      "Training Error:  9.986063528032467\n",
      "====================================================================================================\n",
      "Iteration:  355\n",
      "Previous theta :  [ 0.00714304 -0.09586627  0.05624232  0.0330747   0.05232733 -0.10345793\n",
      "  0.31501517  0.00761187 -0.20717868  0.23700043 -0.20431648 -0.23139984\n",
      "  0.08565965 -0.42491613]\n",
      "New theta_0 : [ 0.00715098 -0.09602062  0.05651446  0.03284644  0.05239309 -0.10429385\n",
      "  0.31459246  0.00760855 -0.20819255  0.23736677 -0.20425388 -0.23156531\n",
      "  0.08557822 -0.42510229]\n",
      "Training Error:  9.98383379232948\n",
      "====================================================================================================\n",
      "Iteration:  356\n",
      "Previous theta :  [ 0.00715098 -0.09602062  0.05651446  0.03284644  0.05239309 -0.10429385\n",
      "  0.31459246  0.00760855 -0.20819255  0.23736677 -0.20425388 -0.23156531\n",
      "  0.08557822 -0.42510229]\n",
      "New theta_0 : [ 0.00715894 -0.09617434  0.0567858   0.03262033  0.05245862 -0.10512534\n",
      "  0.31417351  0.00760613 -0.20919975  0.23773079 -0.20419197 -0.23172914\n",
      "  0.08549757 -0.42528586]\n",
      "Training Error:  9.981632157947843\n",
      "====================================================================================================\n",
      "Iteration:  357\n",
      "Previous theta :  [ 0.00715894 -0.09617434  0.0567858   0.03262033  0.05245862 -0.10512534\n",
      "  0.31417351  0.00760613 -0.20919975  0.23773079 -0.20419197 -0.23172914\n",
      "  0.08549757 -0.42528586]\n",
      "New theta_0 : [ 0.00716693 -0.09632744  0.05705635  0.03239636  0.05252391 -0.10595242\n",
      "  0.31375827  0.00760457 -0.21020032  0.23809251 -0.20413074 -0.23189137\n",
      "  0.0854177  -0.42546687]\n",
      "Training Error:  9.97945825112535\n",
      "====================================================================================================\n",
      "Iteration:  358\n",
      "Previous theta :  [ 0.00716693 -0.09632744  0.05705635  0.03239636  0.05252391 -0.10595242\n",
      "  0.31375827  0.00760457 -0.21020032  0.23809251 -0.20413074 -0.23189137\n",
      "  0.0854177  -0.42546687]\n",
      "New theta_0 : [ 0.00717494 -0.0964799   0.05732608  0.0321745   0.05258897 -0.10677512\n",
      "  0.31334671  0.00760386 -0.21119432  0.23845193 -0.20407019 -0.23205199\n",
      "  0.08533859 -0.42564536]\n",
      "Training Error:  9.977311703518627\n",
      "====================================================================================================\n",
      "Iteration:  359\n",
      "Previous theta :  [ 0.00717494 -0.0964799   0.05732608  0.0321745   0.05258897 -0.10677512\n",
      "  0.31334671  0.00760386 -0.21119432  0.23845193 -0.20407019 -0.23205199\n",
      "  0.08533859 -0.42564536]\n",
      "New theta_0 : [ 0.00718297 -0.09663173  0.057595    0.03195474  0.0526538  -0.10759346\n",
      "  0.31293879  0.00760399 -0.21218179  0.23880909 -0.20401031 -0.23221105\n",
      "  0.08526024 -0.42582135]\n",
      "Training Error:  9.975192152114253\n",
      "====================================================================================================\n",
      "Iteration:  360\n",
      "Previous theta :  [ 0.00718297 -0.09663173  0.057595    0.03195474  0.0526538  -0.10759346\n",
      "  0.31293879  0.00760399 -0.21218179  0.23880909 -0.20401031 -0.23221105\n",
      "  0.08526024 -0.42582135]\n",
      "New theta_0 : [ 0.00719102 -0.09678293  0.05786309  0.03173706  0.05271838 -0.10840746\n",
      "  0.31253448  0.00760493 -0.21316277  0.23916399 -0.2039511  -0.23236855\n",
      "  0.08518262 -0.42599489]\n",
      "Training Error:  9.973099239141531\n",
      "====================================================================================================\n",
      "Iteration:  361\n",
      "Previous theta :  [ 0.00719102 -0.09678293  0.05786309  0.03173706  0.05271838 -0.10840746\n",
      "  0.31253448  0.00760493 -0.21316277  0.23916399 -0.2039511  -0.23236855\n",
      "  0.08518262 -0.42599489]\n",
      "New theta_0 : [ 0.00719909 -0.09693349  0.05813035  0.03152144  0.05278273 -0.10921714\n",
      "  0.31213374  0.00760666 -0.21413732  0.23951666 -0.20389255 -0.23252452\n",
      "  0.08510574 -0.42616599]\n",
      "Training Error:  9.971032611986942\n",
      "====================================================================================================\n",
      "Iteration:  362\n",
      "Previous theta :  [ 0.00719909 -0.09693349  0.05813035  0.03152144  0.05278273 -0.10921714\n",
      "  0.31213374  0.00760666 -0.21413732  0.23951666 -0.20389255 -0.23252452\n",
      "  0.08510574 -0.42616599]\n",
      "New theta_0 : [ 0.00720719 -0.09708343  0.05839676  0.03130786  0.05284685 -0.11002253\n",
      "  0.31173653  0.00760917 -0.21510547  0.23986711 -0.20383466 -0.23267897\n",
      "  0.08502958 -0.4263347 ]\n",
      "Training Error:  9.968991923110181\n",
      "====================================================================================================\n",
      "Iteration:  363\n",
      "Previous theta :  [ 0.00720719 -0.09708343  0.05839676  0.03130786  0.05284685 -0.11002253\n",
      "  0.31173653  0.00760917 -0.21510547  0.23986711 -0.20383466 -0.23267897\n",
      "  0.08502958 -0.4263347 ]\n",
      "New theta_0 : [ 0.0072153  -0.09723273  0.05866233  0.0310963   0.05291072 -0.11082363\n",
      "  0.31134283  0.00761244 -0.21606727  0.24021536 -0.20377742 -0.23283192\n",
      "  0.08495414 -0.42650104]\n",
      "Training Error:  9.96697682996178\n",
      "====================================================================================================\n",
      "Iteration:  364\n",
      "Previous theta :  [ 0.0072153  -0.09723273  0.05866233  0.0310963   0.05291072 -0.11082363\n",
      "  0.31134283  0.00761244 -0.21606727  0.24021536 -0.20377742 -0.23283192\n",
      "  0.08495414 -0.42650104]\n",
      "New theta_0 : [ 0.00722342 -0.0973814   0.05892704  0.03088675  0.05297435 -0.11162048\n",
      "  0.3109526   0.00761645 -0.21702276  0.24056142 -0.20372083 -0.23298339\n",
      "  0.08487939 -0.42666505]\n",
      "Training Error:  9.96498699490229\n",
      "====================================================================================================\n",
      "Iteration:  365\n",
      "Previous theta :  [ 0.00722342 -0.0973814   0.05892704  0.03088675  0.05297435 -0.11162048\n",
      "  0.3109526   0.00761645 -0.21702276  0.24056142 -0.20372083 -0.23298339\n",
      "  0.08487939 -0.42666505]\n",
      "New theta_0 : [ 0.00723157 -0.09752944  0.05919088  0.03067919  0.05303774 -0.1124131\n",
      "  0.3105658   0.00762118 -0.217972    0.24090531 -0.20366488 -0.23313339\n",
      "  0.08480535 -0.42682675]\n",
      "Training Error:  9.963022085122942\n",
      "====================================================================================================\n",
      "Iteration:  366\n",
      "Previous theta :  [ 0.00723157 -0.09752944  0.05919088  0.03067919  0.05303774 -0.1124131\n",
      "  0.3105658   0.00762118 -0.217972    0.24090531 -0.20366488 -0.23313339\n",
      "  0.08480535 -0.42682675]\n",
      "New theta_0 : [ 0.00723973 -0.09767685  0.05945386  0.0304736   0.05310088 -0.1132015\n",
      "  0.3101824   0.00762663 -0.21891502  0.24124704 -0.20360957 -0.23328196\n",
      "  0.08473199 -0.42698617]\n",
      "Training Error:  9.961081772567818\n",
      "====================================================================================================\n",
      "Iteration:  367\n",
      "Previous theta :  [ 0.00723973 -0.09767685  0.05945386  0.0304736   0.05310088 -0.1132015\n",
      "  0.3101824   0.00762663 -0.21891502  0.24124704 -0.20360957 -0.23328196\n",
      "  0.08473199 -0.42698617]\n",
      "New theta_0 : [ 0.00724791 -0.09782363  0.05971596  0.03026997  0.05316379 -0.11398571\n",
      "  0.30980236  0.00763277 -0.21985186  0.24158664 -0.20355489 -0.23342909\n",
      "  0.0846593  -0.42714334]\n",
      "Training Error:  9.959165733857441\n",
      "====================================================================================================\n",
      "Iteration:  368\n",
      "Previous theta :  [ 0.00724791 -0.09782363  0.05971596  0.03026997  0.05316379 -0.11398571\n",
      "  0.30980236  0.00763277 -0.21985186  0.24158664 -0.20355489 -0.23342909\n",
      "  0.0846593  -0.42714334]\n",
      "New theta_0 : [ 0.0072561  -0.09796978  0.05997718  0.03006827  0.05322645 -0.11476575\n",
      "  0.30942566  0.00763958 -0.22078258  0.24192412 -0.20350085 -0.23357482\n",
      "  0.08458729 -0.42729829]\n",
      "Training Error:  9.957273650213809\n",
      "====================================================================================================\n",
      "Iteration:  369\n",
      "Previous theta :  [ 0.0072561  -0.09796978  0.05997718  0.03006827  0.05322645 -0.11476575\n",
      "  0.30942566  0.00763958 -0.22078258  0.24192412 -0.20350085 -0.23357482\n",
      "  0.08458729 -0.42729829]\n",
      "New theta_0 : [ 0.00726431 -0.09811529  0.06023751  0.02986849  0.05328886 -0.11554164\n",
      "  0.30905227  0.00764706 -0.22170721  0.24225949 -0.20344742 -0.23371915\n",
      "  0.08451593 -0.42745105]\n",
      "Training Error:  9.955405207386786\n",
      "====================================================================================================\n",
      "Iteration:  370\n",
      "Previous theta :  [ 0.00726431 -0.09811529  0.06023751  0.02986849  0.05328886 -0.11554164\n",
      "  0.30905227  0.00764706 -0.22170721  0.24225949 -0.20344742 -0.23371915\n",
      "  0.08451593 -0.42745105]\n",
      "New theta_0 : [ 0.00727253 -0.09826018  0.06049694  0.02967062  0.05335103 -0.11631339\n",
      "  0.30868214  0.00765518 -0.2226258   0.24259277 -0.20339462 -0.23386211\n",
      "  0.08444522 -0.42760165]\n",
      "Training Error:  9.953560095581878\n",
      "====================================================================================================\n",
      "Iteration:  371\n",
      "Previous theta :  [ 0.00727253 -0.09826018  0.06049694  0.02967062  0.05335103 -0.11631339\n",
      "  0.30868214  0.00765518 -0.2226258   0.24259277 -0.20339462 -0.23386211\n",
      "  0.08444522 -0.42760165]\n",
      "New theta_0 : [ 0.00728076 -0.09840444  0.06075547  0.02947464  0.05341295 -0.11708103\n",
      "  0.30831525  0.00766393 -0.22353838  0.24292398 -0.20334243 -0.23400371\n",
      "  0.08437516 -0.42775012]\n",
      "Training Error:  9.951738009389306\n",
      "====================================================================================================\n",
      "Iteration:  372\n",
      "Previous theta :  [ 0.00728076 -0.09840444  0.06075547  0.02947464  0.05341295 -0.11708103\n",
      "  0.30831525  0.00766393 -0.22353838  0.24292398 -0.20334243 -0.23400371\n",
      "  0.08437516 -0.42775012]\n",
      "New theta_0 : [ 0.007289   -0.09854807  0.0610131   0.02928052  0.05347463 -0.11784459\n",
      "  0.30795156  0.0076733  -0.224445    0.24325313 -0.20329085 -0.23414396\n",
      "  0.08430573 -0.42789647]\n",
      "Training Error:  9.949938647714417\n",
      "====================================================================================================\n",
      "Iteration:  373\n",
      "Previous theta :  [ 0.007289   -0.09854807  0.0610131   0.02928052  0.05347463 -0.11784459\n",
      "  0.30795156  0.0076733  -0.224445    0.24325313 -0.20329085 -0.23414396\n",
      "  0.08430573 -0.42789647]\n",
      "New theta_0 : [ 0.00729726 -0.09869107  0.06126982  0.02908826  0.05353605 -0.11860407\n",
      "  0.30759105  0.00768326 -0.22534571  0.24358024 -0.20323988 -0.23428289\n",
      "  0.08423693 -0.42804075]\n",
      "Training Error:  9.948161713709332\n",
      "====================================================================================================\n",
      "Iteration:  374\n",
      "Previous theta :  [ 0.00729726 -0.09869107  0.06126982  0.02908826  0.05353605 -0.11860407\n",
      "  0.30759105  0.00768326 -0.22534571  0.24358024 -0.20323988 -0.23428289\n",
      "  0.08423693 -0.42804075]\n",
      "New theta_0 : [ 0.00730553 -0.09883344  0.06152562  0.02889784  0.05359723 -0.11935951\n",
      "  0.30723368  0.00769382 -0.22624053  0.24390532 -0.20318951 -0.2344205\n",
      "  0.08416875 -0.42818297]\n",
      "Training Error:  9.946406914705864\n",
      "====================================================================================================\n",
      "Iteration:  375\n",
      "Previous theta :  [ 0.00730553 -0.09883344  0.06152562  0.02889784  0.05359723 -0.11935951\n",
      "  0.30723368  0.00769382 -0.22624053  0.24390532 -0.20318951 -0.2344205\n",
      "  0.08416875 -0.42818297]\n",
      "New theta_0 : [ 0.0073138  -0.09897518  0.06178049  0.02870924  0.05365816 -0.12011091\n",
      "  0.30687943  0.00770494 -0.22712952  0.24422838 -0.20313974 -0.23455682\n",
      "  0.08410117 -0.42832316]\n",
      "Training Error:  9.944673962149643\n",
      "====================================================================================================\n",
      "Iteration:  376\n",
      "Previous theta :  [ 0.0073138  -0.09897518  0.06178049  0.02870924  0.05365816 -0.12011091\n",
      "  0.30687943  0.00770494 -0.22712952  0.24422838 -0.20313974 -0.23455682\n",
      "  0.08410117 -0.42832316]\n",
      "New theta_0 : [ 0.00732209 -0.0991163   0.06203445  0.02852244  0.05371885 -0.12085831\n",
      "  0.30652826  0.00771663 -0.22801271  0.24454945 -0.20309056 -0.23469186\n",
      "  0.0840342  -0.42846135]\n",
      "Training Error:  9.942962571535453\n",
      "====================================================================================================\n",
      "Iteration:  377\n",
      "Previous theta :  [ 0.00732209 -0.0991163   0.06203445  0.02852244  0.05371885 -0.12085831\n",
      "  0.30652826  0.00771663 -0.22801271  0.24454945 -0.20309056 -0.23469186\n",
      "  0.0840342  -0.42846135]\n",
      "New theta_0 : [ 0.00733038 -0.09925679  0.06228747  0.02833744  0.05377928 -0.12160171\n",
      "  0.30618015  0.00772886 -0.22889015  0.24486853 -0.20304197 -0.23482564\n",
      "  0.08396783 -0.42859757]\n",
      "Training Error:  9.941272462343713\n",
      "====================================================================================================\n",
      "Iteration:  378\n",
      "Previous theta :  [ 0.00733038 -0.09925679  0.06228747  0.02833744  0.05377928 -0.12160171\n",
      "  0.30618015  0.00772886 -0.22889015  0.24486853 -0.20304197 -0.23482564\n",
      "  0.08396783 -0.42859757]\n",
      "New theta_0 : [ 0.00733868 -0.09939666  0.06253956  0.02815421  0.05383947 -0.12234115\n",
      "  0.30583505  0.00774162 -0.22976187  0.24518565 -0.20299396 -0.23495816\n",
      "  0.08390205 -0.42873183]\n",
      "Training Error:  9.939603357978127\n",
      "====================================================================================================\n",
      "Iteration:  379\n",
      "Previous theta :  [ 0.00733868 -0.09939666  0.06253956  0.02815421  0.05383947 -0.12234115\n",
      "  0.30583505  0.00774162 -0.22976187  0.24518565 -0.20299396 -0.23495816\n",
      "  0.08390205 -0.42873183]\n",
      "New theta_0 : [ 0.00734699 -0.0995359   0.06279071  0.02797273  0.0538994  -0.12307664\n",
      "  0.30549296  0.0077549  -0.23062791  0.24550081 -0.20294653 -0.23508945\n",
      "  0.08383684 -0.42886417]\n",
      "Training Error:  9.937954985704444\n",
      "====================================================================================================\n",
      "Iteration:  380\n",
      "Previous theta :  [ 0.00734699 -0.0995359   0.06279071  0.02797273  0.0538994  -0.12307664\n",
      "  0.30549296  0.0077549  -0.23062791  0.24550081 -0.20294653 -0.23508945\n",
      "  0.08383684 -0.42886417]\n",
      "New theta_0 : [ 0.00735531 -0.09967452  0.06304092  0.02779301  0.05395908 -0.12380819\n",
      "  0.30515383  0.00776868 -0.23148831  0.24581404 -0.20289967 -0.23521952\n",
      "  0.08377222 -0.4289946 ]\n",
      "Training Error:  9.936327076590326\n",
      "====================================================================================================\n",
      "Iteration:  381\n",
      "Previous theta :  [ 0.00735531 -0.09967452  0.06304092  0.02779301  0.05395908 -0.12380819\n",
      "  0.30515383  0.00776868 -0.23148831  0.24581404 -0.20289967 -0.23521952\n",
      "  0.08377222 -0.4289946 ]\n",
      "New theta_0 : [ 0.00736363 -0.09981251  0.06329019  0.02761501  0.05401852 -0.12453584\n",
      "  0.30481763  0.00778296 -0.23234312  0.24612533 -0.20285339 -0.23534839\n",
      "  0.08370815 -0.42912316]\n",
      "Training Error:  9.934719365446275\n",
      "====================================================================================================\n",
      "Iteration:  382\n",
      "Previous theta :  [ 0.00736363 -0.09981251  0.06329019  0.02761501  0.05401852 -0.12453584\n",
      "  0.30481763  0.00778296 -0.23234312  0.24612533 -0.20285339 -0.23534839\n",
      "  0.08370815 -0.42912316]\n",
      "New theta_0 : [ 0.00737195 -0.09994988  0.0635385   0.02743872  0.0540777  -0.12525959\n",
      "  0.30448435  0.00779771 -0.23319236  0.24643472 -0.20280767 -0.23547606\n",
      "  0.08364465 -0.42924987]\n",
      "Training Error:  9.933131590767642\n",
      "====================================================================================================\n",
      "Iteration:  383\n",
      "Previous theta :  [ 0.00737195 -0.09994988  0.0635385   0.02743872  0.0540777  -0.12525959\n",
      "  0.30448435  0.00779771 -0.23319236  0.24643472 -0.20280767 -0.23547606\n",
      "  0.08364465 -0.42924987]\n",
      "New theta_0 : [ 0.00738029 -0.10008663  0.06378586  0.02726413  0.05413663 -0.12597948\n",
      "  0.30415395  0.00781294 -0.23403609  0.24674221 -0.20276252 -0.23560256\n",
      "  0.08358171 -0.42937475]\n",
      "Training Error:  9.931563494677642\n",
      "====================================================================================================\n",
      "Iteration:  384\n",
      "Previous theta :  [ 0.00738029 -0.10008663  0.06378586  0.02726413  0.05413663 -0.12597948\n",
      "  0.30415395  0.00781294 -0.23403609  0.24674221 -0.20276252 -0.23560256\n",
      "  0.08358171 -0.42937475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00738862 -0.10022276  0.06403226  0.02709122  0.05419531 -0.12669551\n",
      "  0.3038264   0.00782862 -0.23487433  0.24704782 -0.20271792 -0.23572789\n",
      "  0.08351931 -0.42949782]\n",
      "Training Error:  9.930014822871383\n",
      "====================================================================================================\n",
      "Iteration:  385\n",
      "Previous theta :  [ 0.00738862 -0.10022276  0.06403226  0.02709122  0.05419531 -0.12669551\n",
      "  0.3038264   0.00782862 -0.23487433  0.24704782 -0.20271792 -0.23572789\n",
      "  0.08351931 -0.42949782]\n",
      "New theta_0 : [ 0.00739696 -0.10035828  0.06427771  0.02691999  0.05425374 -0.12740771\n",
      "  0.30350167  0.00784474 -0.23570712  0.24735156 -0.20267388 -0.23585207\n",
      "  0.08345745 -0.42961911]\n",
      "Training Error:  9.928485324560915\n",
      "====================================================================================================\n",
      "Iteration:  386\n",
      "Previous theta :  [ 0.00739696 -0.10035828  0.06427771  0.02691999  0.05425374 -0.12740771\n",
      "  0.30350167  0.00784474 -0.23570712  0.24735156 -0.20267388 -0.23585207\n",
      "  0.08345745 -0.42961911]\n",
      "New theta_0 : [ 0.0074053  -0.10049317  0.06452219  0.0267504   0.05431192 -0.12811609\n",
      "  0.30317975  0.0078613  -0.23653451  0.24765345 -0.20263038 -0.23597512\n",
      "  0.08339612 -0.42973864]\n",
      "Training Error:  9.926974752421211\n",
      "====================================================================================================\n",
      "Iteration:  387\n",
      "Previous theta :  [ 0.0074053  -0.10049317  0.06452219  0.0267504   0.05431192 -0.12811609\n",
      "  0.30317975  0.0078613  -0.23653451  0.24765345 -0.20263038 -0.23597512\n",
      "  0.08339612 -0.42973864]\n",
      "New theta_0 : [ 0.00741365 -0.10062745  0.06476571  0.02658246  0.05436985 -0.12882068\n",
      "  0.30286059  0.00787827 -0.23735652  0.24795349 -0.20258743 -0.23609704\n",
      "  0.08333533 -0.42985643]\n",
      "Training Error:  9.92548286253711\n",
      "====================================================================================================\n",
      "Iteration:  388\n",
      "Previous theta :  [ 0.00741365 -0.10062745  0.06476571  0.02658246  0.05436985 -0.12882068\n",
      "  0.30286059  0.00787827 -0.23735652  0.24795349 -0.20258743 -0.23609704\n",
      "  0.08333533 -0.42985643]\n",
      "New theta_0 : [ 0.007422   -0.10076111  0.06500826  0.02641614  0.05442752 -0.1295215\n",
      "  0.30254419  0.00789566 -0.2381732   0.24825171 -0.20254502 -0.23621786\n",
      "  0.08327505 -0.42997251]\n",
      "Training Error:  9.924009414351229\n",
      "====================================================================================================\n",
      "Iteration:  389\n",
      "Previous theta :  [ 0.007422   -0.10076111  0.06500826  0.02641614  0.05442752 -0.1295215\n",
      "  0.30254419  0.00789566 -0.2381732   0.24825171 -0.20254502 -0.23621786\n",
      "  0.08327505 -0.42997251]\n",
      "New theta_0 : [ 0.00743034 -0.10089415  0.06524984  0.02625143  0.05448495 -0.13021855\n",
      "  0.3022305   0.00791345 -0.23898458  0.24854811 -0.20250315 -0.23633757\n",
      "  0.08321529 -0.4300869 ]\n",
      "Training Error:  9.922554170612717\n",
      "====================================================================================================\n",
      "Iteration:  390\n",
      "Previous theta :  [ 0.00743034 -0.10089415  0.06524984  0.02625143  0.05448495 -0.13021855\n",
      "  0.3022305   0.00791345 -0.23898458  0.24854811 -0.20250315 -0.23633757\n",
      "  0.08321529 -0.4300869 ]\n",
      "New theta_0 : [ 0.00743869 -0.10102658  0.06549045  0.02608831  0.05454212 -0.13091187\n",
      "  0.3019195   0.00793162 -0.2397907   0.24884271 -0.20246181 -0.23645621\n",
      "  0.08315604 -0.43019961]\n",
      "Training Error:  9.921116897326966\n",
      "====================================================================================================\n",
      "Iteration:  391\n",
      "Previous theta :  [ 0.00743869 -0.10102658  0.06549045  0.02608831  0.05454212 -0.13091187\n",
      "  0.3019195   0.00793162 -0.2397907   0.24884271 -0.20246181 -0.23645621\n",
      "  0.08315604 -0.43019961]\n",
      "New theta_0 : [ 0.00744704 -0.1011584   0.06573008  0.02592678  0.05459904 -0.13160148\n",
      "  0.30161117  0.00795017 -0.2405916   0.24913553 -0.202421   -0.23657377\n",
      "  0.0830973  -0.43031068]\n",
      "Training Error:  9.91969736370617\n",
      "====================================================================================================\n",
      "Iteration:  392\n",
      "Previous theta :  [ 0.00744704 -0.1011584   0.06573008  0.02592678  0.05459904 -0.13160148\n",
      "  0.30161117  0.00795017 -0.2405916   0.24913553 -0.202421   -0.23657377\n",
      "  0.0830973  -0.43031068]\n",
      "New theta_0 : [ 0.00745539 -0.1012896   0.06596874  0.02576682  0.05465571 -0.13228738\n",
      "  0.30130549  0.00796909 -0.24138731  0.24942657 -0.20238071 -0.23669027\n",
      "  0.08303905 -0.43042012]\n",
      "Training Error:  9.918295342120748\n",
      "====================================================================================================\n",
      "Iteration:  393\n",
      "Previous theta :  [ 0.00745539 -0.1012896   0.06596874  0.02576682  0.05465571 -0.13228738\n",
      "  0.30130549  0.00796909 -0.24138731  0.24942657 -0.20238071 -0.23669027\n",
      "  0.08303905 -0.43042012]\n",
      "New theta_0 : [ 0.00746374 -0.1014202   0.06620642  0.02560841  0.05471213 -0.1329696\n",
      "  0.30100242  0.00798837 -0.24217786  0.24971585 -0.20234094 -0.23680573\n",
      "  0.08298129 -0.43052795]\n",
      "Training Error:  9.9169106080516\n",
      "====================================================================================================\n",
      "Iteration:  394\n",
      "Previous theta :  [ 0.00746374 -0.1014202   0.06620642  0.02560841  0.05471213 -0.1329696\n",
      "  0.30100242  0.00798837 -0.24217786  0.24971585 -0.20234094 -0.23680573\n",
      "  0.08298129 -0.43052795]\n",
      "New theta_0 : [ 0.00747209 -0.10155019  0.06644312  0.02545154  0.05476829 -0.13364815\n",
      "  0.30070194  0.00800799 -0.24296329  0.25000338 -0.20230169 -0.23692015\n",
      "  0.08292402 -0.43063419]\n",
      "Training Error:  9.91554294004321\n",
      "====================================================================================================\n",
      "Iteration:  395\n",
      "Previous theta :  [ 0.00747209 -0.10155019  0.06644312  0.02545154  0.05476829 -0.13364815\n",
      "  0.30070194  0.00800799 -0.24296329  0.25000338 -0.20230169 -0.23692015\n",
      "  0.08292402 -0.43063419]\n",
      "New theta_0 : [ 0.00748044 -0.10167957  0.06667884  0.0252962   0.05482421 -0.13432307\n",
      "  0.30040403  0.00802795 -0.24374364  0.25028918 -0.20226296 -0.23703355\n",
      "  0.08286724 -0.43073887]\n",
      "Training Error:  9.914192119657528\n",
      "====================================================================================================\n",
      "Iteration:  396\n",
      "Previous theta :  [ 0.00748044 -0.10167957  0.06667884  0.0252962   0.05482421 -0.13432307\n",
      "  0.30040403  0.00802795 -0.24374364  0.25028918 -0.20226296 -0.23703355\n",
      "  0.08286724 -0.43073887]\n",
      "New theta_0 : [ 0.00748878 -0.10180834  0.06691357  0.02514237  0.05487987 -0.13499435\n",
      "  0.30010866  0.00804824 -0.24451894  0.25057325 -0.20222473 -0.23714594\n",
      "  0.08281092 -0.43084201]\n",
      "Training Error:  9.912857931428675\n",
      "====================================================================================================\n",
      "Iteration:  397\n",
      "Previous theta :  [ 0.00748878 -0.10180834  0.06691357  0.02514237  0.05487987 -0.13499435\n",
      "  0.30010866  0.00804824 -0.24451894  0.25057325 -0.20222473 -0.23714594\n",
      "  0.08281092 -0.43084201]\n",
      "New theta_0 : [ 0.00749712 -0.10193651  0.06714732  0.02499004  0.05493529 -0.13566203\n",
      "  0.29981581  0.00806885 -0.24528922  0.25085561 -0.202187   -0.23725733\n",
      "  0.08275508 -0.43094361]\n",
      "Training Error:  9.911540162818394\n",
      "====================================================================================================\n",
      "Iteration:  398\n",
      "Previous theta :  [ 0.00749712 -0.10193651  0.06714732  0.02499004  0.05493529 -0.13566203\n",
      "  0.29981581  0.00806885 -0.24528922  0.25085561 -0.202187   -0.23725733\n",
      "  0.08275508 -0.43094361]\n",
      "New theta_0 : [ 0.00750546 -0.10206407  0.06738008  0.0248392   0.05499045 -0.13632612\n",
      "  0.29952546  0.00808976 -0.24605453  0.25113628 -0.20214978 -0.23736774\n",
      "  0.0826997  -0.43104372]\n",
      "Training Error:  9.910238604172283\n",
      "====================================================================================================\n",
      "Iteration:  399\n",
      "Previous theta :  [ 0.00750546 -0.10206407  0.06738008  0.0248392   0.05499045 -0.13632612\n",
      "  0.29952546  0.00808976 -0.24605453  0.25113628 -0.20214978 -0.23736774\n",
      "  0.0826997  -0.43104372]\n",
      "New theta_0 : [ 0.0075138  -0.10219103  0.06761186  0.02468984  0.05504536 -0.13698664\n",
      "  0.29923758  0.00811098 -0.24681489  0.25141526 -0.20211305 -0.23747717\n",
      "  0.08264479 -0.43114233]\n",
      "Training Error:  9.908953048676771\n",
      "====================================================================================================\n",
      "Iteration:  400\n",
      "Previous theta :  [ 0.0075138  -0.10219103  0.06761186  0.02468984  0.05504536 -0.13698664\n",
      "  0.29923758  0.00811098 -0.24681489  0.25141526 -0.20211305 -0.23747717\n",
      "  0.08264479 -0.43114233]\n",
      "New theta_0 : [ 0.00752213 -0.10231739  0.06784265  0.02454193  0.05510002 -0.1376436\n",
      "  0.29895214  0.00813248 -0.24757033  0.25169257 -0.20207681 -0.23758563\n",
      "  0.08259033 -0.43123948]\n",
      "Training Error:  9.907683292316824\n",
      "====================================================================================================\n",
      "Iteration:  401\n",
      "Previous theta :  [ 0.00752213 -0.10231739  0.06784265  0.02454193  0.05510002 -0.1376436\n",
      "  0.29895214  0.00813248 -0.24757033  0.25169257 -0.20207681 -0.23758563\n",
      "  0.08259033 -0.43123948]\n",
      "New theta_0 : [ 0.00753045 -0.10244315  0.06807245  0.02439547  0.05515444 -0.13829703\n",
      "  0.29866913  0.00815427 -0.2483209   0.25196822 -0.20204107 -0.23769314\n",
      "  0.08253631 -0.43133518]\n",
      "Training Error:  9.906429133834354\n",
      "====================================================================================================\n",
      "Iteration:  402\n",
      "Previous theta :  [ 0.00753045 -0.10244315  0.06807245  0.02439547  0.05515444 -0.13829703\n",
      "  0.29866913  0.00815427 -0.2483209   0.25196822 -0.20204107 -0.23769314\n",
      "  0.08253631 -0.43133518]\n",
      "New theta_0 : [ 0.00753878 -0.10256831  0.06830126  0.02425045  0.0552086  -0.13894694\n",
      "  0.29838852  0.00817633 -0.24906662  0.25224222 -0.20200581 -0.23779971\n",
      "  0.08248275 -0.43142945]\n",
      "Training Error:  9.90519037468736\n",
      "====================================================================================================\n",
      "Iteration:  403\n",
      "Previous theta :  [ 0.00753878 -0.10256831  0.06830126  0.02425045  0.0552086  -0.13894694\n",
      "  0.29838852  0.00817633 -0.24906662  0.25224222 -0.20200581 -0.23779971\n",
      "  0.08248275 -0.43142945]\n",
      "New theta_0 : [ 0.00754709 -0.10269288  0.06852908  0.02410685  0.05526251 -0.13959335\n",
      "  0.29811029  0.00819866 -0.24980752  0.25251458 -0.20197103 -0.23790534\n",
      "  0.08242962 -0.4315223 ]\n",
      "Training Error:  9.903966819009735\n",
      "====================================================================================================\n",
      "Iteration:  404\n",
      "Previous theta :  [ 0.00754709 -0.10269288  0.06852908  0.02410685  0.05526251 -0.13959335\n",
      "  0.29811029  0.00819866 -0.24980752  0.25251458 -0.20197103 -0.23790534\n",
      "  0.08242962 -0.4315223 ]\n",
      "New theta_0 : [ 0.0075554  -0.10281685  0.06875591  0.02396466  0.05531618 -0.14023628\n",
      "  0.29783442  0.00822124 -0.25054365  0.25278532 -0.20193673 -0.23801006\n",
      "  0.08237693 -0.43161377]\n",
      "Training Error:  9.902758273571752\n",
      "====================================================================================================\n",
      "Iteration:  405\n",
      "Previous theta :  [ 0.0075554  -0.10281685  0.06875591  0.02396466  0.05531618 -0.14023628\n",
      "  0.29783442  0.00822124 -0.25054365  0.25278532 -0.20193673 -0.23801006\n",
      "  0.08237693 -0.43161377]\n",
      "New theta_0 : [ 0.00756371 -0.10294023  0.06898174  0.02382387  0.05536959 -0.14087575\n",
      "  0.29756088  0.00824407 -0.25127502  0.25305444 -0.2019029  -0.23811386\n",
      "  0.08232467 -0.43170386]\n",
      "Training Error:  9.901564547741225\n",
      "====================================================================================================\n",
      "Iteration:  406\n",
      "Previous theta :  [ 0.00756371 -0.10294023  0.06898174  0.02382387  0.05536959 -0.14087575\n",
      "  0.29756088  0.00824407 -0.25127502  0.25305444 -0.2019029  -0.23811386\n",
      "  0.08232467 -0.43170386]\n",
      "New theta_0 : [ 0.00757201 -0.10306301  0.06920659  0.02368446  0.05542276 -0.14151177\n",
      "  0.29728965  0.00826715 -0.25200168  0.25332197 -0.20186954 -0.23821677\n",
      "  0.08227283 -0.43179259]\n",
      "Training Error:  9.900385453445306\n",
      "====================================================================================================\n",
      "Iteration:  407\n",
      "Previous theta :  [ 0.00757201 -0.10306301  0.06920659  0.02368446  0.05542276 -0.14151177\n",
      "  0.29728965  0.00826715 -0.25200168  0.25332197 -0.20186954 -0.23821677\n",
      "  0.08227283 -0.43179259]\n",
      "New theta_0 : [ 0.0075803  -0.1031852   0.06943044  0.02354643  0.05547568 -0.14214436\n",
      "  0.29702071  0.00829045 -0.25272366  0.2535879  -0.20183665 -0.23831878\n",
      "  0.08222142 -0.43187998]\n",
      "Training Error:  9.899220805132932\n",
      "====================================================================================================\n",
      "Iteration:  408\n",
      "Previous theta :  [ 0.0075803  -0.1031852   0.06943044  0.02354643  0.05547568 -0.14214436\n",
      "  0.29702071  0.00829045 -0.25272366  0.2535879  -0.20183665 -0.23831878\n",
      "  0.08222142 -0.43187998]\n",
      "New theta_0 : [ 0.00758858 -0.10330681  0.0696533   0.02340976  0.05552835 -0.14277354\n",
      "  0.29675405  0.00831398 -0.25344098  0.25385226 -0.20180422 -0.23841991\n",
      "  0.08217042 -0.43196605]\n",
      "Training Error:  9.898070419737884\n",
      "====================================================================================================\n",
      "Iteration:  409\n",
      "Previous theta :  [ 0.00758858 -0.10330681  0.0696533   0.02340976  0.05552835 -0.14277354\n",
      "  0.29675405  0.00831398 -0.25344098  0.25385226 -0.20180422 -0.23841991\n",
      "  0.08217042 -0.43196605]\n",
      "New theta_0 : [ 0.00759686 -0.10342783  0.06987517  0.02327443  0.05558077 -0.14339932\n",
      "  0.29648963  0.00833773 -0.25415368  0.25411505 -0.20177225 -0.23852018\n",
      "  0.08211983 -0.43205082]\n",
      "Training Error:  9.896934116642464\n",
      "====================================================================================================\n",
      "Iteration:  410\n",
      "Previous theta :  [ 0.00759686 -0.10342783  0.06987517  0.02327443  0.05558077 -0.14339932\n",
      "  0.29648963  0.00833773 -0.25415368  0.25411505 -0.20177225 -0.23852018\n",
      "  0.08211983 -0.43205082]\n",
      "New theta_0 : [ 0.00760513 -0.10354826  0.07009605  0.02314045  0.05563295 -0.14402173\n",
      "  0.29622743  0.00836169 -0.25486179  0.25437629 -0.20174074 -0.23861958\n",
      "  0.08206966 -0.43213429]\n",
      "Training Error:  9.895811717641784\n",
      "====================================================================================================\n",
      "Iteration:  411\n",
      "Previous theta :  [ 0.00760513 -0.10354826  0.07009605  0.02314045  0.05563295 -0.14402173\n",
      "  0.29622743  0.00836169 -0.25486179  0.25437629 -0.20174074 -0.23861958\n",
      "  0.08206966 -0.43213429]\n",
      "New theta_0 : [ 0.00761338 -0.1036681   0.07031594  0.02300778  0.05568488 -0.14464078\n",
      "  0.29596745  0.00838585 -0.25556535  0.25463598 -0.20170968 -0.23871814\n",
      "  0.08201988 -0.4322165 ]\n",
      "Training Error:  9.894703046908635\n",
      "====================================================================================================\n",
      "Iteration:  412\n",
      "Previous theta :  [ 0.00761338 -0.1036681   0.07031594  0.02300778  0.05568488 -0.14464078\n",
      "  0.29596745  0.00838585 -0.25556535  0.25463598 -0.20170968 -0.23871814\n",
      "  0.08201988 -0.4322165 ]\n",
      "New theta_0 : [ 0.00762164 -0.10378737  0.07053483  0.02287644  0.05573656 -0.14525649\n",
      "  0.29570964  0.00841021 -0.25626437  0.25489414 -0.20167906 -0.23881585\n",
      "  0.08197051 -0.43229745]\n",
      "Training Error:  9.893607930958922\n",
      "====================================================================================================\n",
      "Iteration:  413\n",
      "Previous theta :  [ 0.00762164 -0.10378737  0.07053483  0.02287644  0.05573656 -0.14525649\n",
      "  0.29570964  0.00841021 -0.25626437  0.25489414 -0.20167906 -0.23881585\n",
      "  0.08197051 -0.43229745]\n",
      "New theta_0 : [ 0.00762988 -0.10390605  0.07075273  0.02274639  0.055788   -0.14586887\n",
      "  0.29545401  0.00843475 -0.2569589   0.25515077 -0.20164889 -0.23891273\n",
      "  0.08192153 -0.43237716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.892526198617698\n",
      "====================================================================================================\n",
      "Iteration:  414\n",
      "Previous theta :  [ 0.00762988 -0.10390605  0.07075273  0.02274639  0.055788   -0.14586887\n",
      "  0.29545401  0.00843475 -0.2569589   0.25515077 -0.20164889 -0.23891273\n",
      "  0.08192153 -0.43237716]\n",
      "New theta_0 : [ 0.00763811 -0.10402416  0.07096965  0.02261763  0.05583919 -0.14647794\n",
      "  0.29520051  0.00845948 -0.25764896  0.2554059  -0.20161917 -0.23900879\n",
      "  0.08187294 -0.43245565]\n",
      "Training Error:  9.891457680985727\n",
      "====================================================================================================\n",
      "Iteration:  415\n",
      "Previous theta :  [ 0.00763811 -0.10402416  0.07096965  0.02261763  0.05583919 -0.14647794\n",
      "  0.29520051  0.00845948 -0.25764896  0.2554059  -0.20161917 -0.23900879\n",
      "  0.08187294 -0.43245565]\n",
      "New theta_0 : [ 0.00764633 -0.10414169  0.07118557  0.02249015  0.05589014 -0.14708372\n",
      "  0.29494914  0.00848439 -0.25833458  0.25565953 -0.20158988 -0.23910403\n",
      "  0.08182474 -0.43253293]\n",
      "Training Error:  9.890402211406604\n",
      "====================================================================================================\n",
      "Iteration:  416\n",
      "Previous theta :  [ 0.00764633 -0.10414169  0.07118557  0.02249015  0.05589014 -0.14708372\n",
      "  0.29494914  0.00848439 -0.25833458  0.25565953 -0.20158988 -0.23910403\n",
      "  0.08182474 -0.43253293]\n",
      "New theta_0 : [ 0.00765454 -0.10425864  0.0714005   0.02236394  0.05594084 -0.14768622\n",
      "  0.29469988  0.00850946 -0.2590158   0.25591167 -0.20156102 -0.23919848\n",
      "  0.08177693 -0.43260902]\n",
      "Training Error:  9.889359625434414\n",
      "====================================================================================================\n",
      "Iteration:  417\n",
      "Previous theta :  [ 0.00765454 -0.10425864  0.0714005   0.02236394  0.05594084 -0.14768622\n",
      "  0.29469988  0.00850946 -0.2590158   0.25591167 -0.20156102 -0.23919848\n",
      "  0.08177693 -0.43260902]\n",
      "New theta_0 : [ 0.00766274 -0.10437502  0.07161444  0.02223899  0.0559913  -0.14828547\n",
      "  0.2944527   0.0085347  -0.25969264  0.25616233 -0.2015326  -0.23929213\n",
      "  0.08172949 -0.43268393]\n",
      "Training Error:  9.88832976080191\n",
      "====================================================================================================\n",
      "Iteration:  418\n",
      "Previous theta :  [ 0.00766274 -0.10437502  0.07161444  0.02223899  0.0559913  -0.14828547\n",
      "  0.2944527   0.0085347  -0.25969264  0.25616233 -0.2015326  -0.23929213\n",
      "  0.08172949 -0.43268393]\n",
      "New theta_0 : [ 0.00767093 -0.10449082  0.07182739  0.02211528  0.05604152 -0.14888148\n",
      "  0.29420759  0.00856009 -0.26036512  0.25641152 -0.2015046  -0.23938499\n",
      "  0.08168243 -0.43275768]\n",
      "Training Error:  9.887312457389218\n",
      "====================================================================================================\n",
      "Iteration:  419\n",
      "Previous theta :  [ 0.00767093 -0.10449082  0.07182739  0.02211528  0.05604152 -0.14888148\n",
      "  0.29420759  0.00856009 -0.26036512  0.25641152 -0.2015046  -0.23938499\n",
      "  0.08168243 -0.43275768]\n",
      "New theta_0 : [ 0.00767911 -0.10460606  0.07203936  0.0219928   0.05609149 -0.14947426\n",
      "  0.29396452  0.00858563 -0.2610333   0.25665925 -0.20147703 -0.23947707\n",
      "  0.08163574 -0.43283029]\n",
      "Training Error:  9.886307557193025\n",
      "====================================================================================================\n",
      "Iteration:  420\n",
      "Previous theta :  [ 0.00767911 -0.10460606  0.07203936  0.0219928   0.05609149 -0.14947426\n",
      "  0.29396452  0.00858563 -0.2610333   0.25665925 -0.20147703 -0.23947707\n",
      "  0.08163574 -0.43283029]\n",
      "New theta_0 : [ 0.00768728 -0.10472072  0.07225034  0.02187155  0.05614123 -0.15006384\n",
      "  0.29372348  0.00861131 -0.26169718  0.25690554 -0.20144988 -0.23956839\n",
      "  0.08158942 -0.43290177]\n",
      "Training Error:  9.885314904296298\n",
      "====================================================================================================\n",
      "Iteration:  421\n",
      "Previous theta :  [ 0.00768728 -0.10472072  0.07225034  0.02187155  0.05614123 -0.15006384\n",
      "  0.29372348  0.00861131 -0.26169718  0.25690554 -0.20144988 -0.23956839\n",
      "  0.08158942 -0.43290177]\n",
      "New theta_0 : [ 0.00769544 -0.10483482  0.07246033  0.0217515   0.05619072 -0.15065022\n",
      "  0.29348445  0.00863714 -0.26235679  0.2571504  -0.20142314 -0.23965895\n",
      "  0.08154346 -0.43297213]\n",
      "Training Error:  9.884334344838463\n",
      "====================================================================================================\n",
      "Iteration:  422\n",
      "Previous theta :  [ 0.00769544 -0.10483482  0.07246033  0.0217515   0.05619072 -0.15065022\n",
      "  0.29348445  0.00863714 -0.26235679  0.2571504  -0.20142314 -0.23965895\n",
      "  0.08154346 -0.43297213]\n",
      "New theta_0 : [ 0.00770358 -0.10494836  0.07266934  0.02163266  0.05623997 -0.15123342\n",
      "  0.29324741  0.00866309 -0.26301218  0.25739382 -0.20139682 -0.23974875\n",
      "  0.08149786 -0.43304139]\n",
      "Training Error:  9.88336572698607\n",
      "====================================================================================================\n",
      "Iteration:  423\n",
      "Previous theta :  [ 0.00770358 -0.10494836  0.07266934  0.02163266  0.05623997 -0.15123342\n",
      "  0.29324741  0.00866309 -0.26301218  0.25739382 -0.20139682 -0.23974875\n",
      "  0.08149786 -0.43304139]\n",
      "New theta_0 : [ 0.00771171 -0.10506133  0.07287737  0.02151501  0.05628897 -0.15181347\n",
      "  0.29301234  0.00868918 -0.26366336  0.25763583 -0.20137091 -0.23983781\n",
      "  0.08145262 -0.43310956]\n",
      "Training Error:  9.882408900903943\n",
      "====================================================================================================\n",
      "Iteration:  424\n",
      "Previous theta :  [ 0.00771171 -0.10506133  0.07287737  0.02151501  0.05628897 -0.15181347\n",
      "  0.29301234  0.00868918 -0.26366336  0.25763583 -0.20137091 -0.23983781\n",
      "  0.08145262 -0.43310956]\n",
      "New theta_0 : [ 0.00771983 -0.10517374  0.07308441  0.02139854  0.05633774 -0.15239038\n",
      "  0.29277922  0.00871538 -0.26431037  0.25787644 -0.20134541 -0.23992614\n",
      "  0.08140773 -0.43317666]\n",
      "Training Error:  9.881463718726758\n",
      "====================================================================================================\n",
      "Iteration:  425\n",
      "Previous theta :  [ 0.00771983 -0.10517374  0.07308441  0.02139854  0.05633774 -0.15239038\n",
      "  0.29277922  0.00871538 -0.26431037  0.25787644 -0.20134541 -0.23992614\n",
      "  0.08140773 -0.43317666]\n",
      "New theta_0 : [ 0.00772793 -0.10528559  0.07329047  0.02128324  0.05638627 -0.15296416\n",
      "  0.29254804  0.0087417  -0.26495322  0.25811565 -0.20132031 -0.24001374\n",
      "  0.08136319 -0.4332427 ]\n",
      "Training Error:  9.880530034531116\n",
      "====================================================================================================\n",
      "Iteration:  426\n",
      "Previous theta :  [ 0.00772793 -0.10528559  0.07329047  0.02128324  0.05638627 -0.15296416\n",
      "  0.29254804  0.0087417  -0.26495322  0.25811565 -0.20132031 -0.24001374\n",
      "  0.08136319 -0.4332427 ]\n",
      "New theta_0 : [ 0.00773602 -0.10539688  0.07349555  0.0211691   0.05643456 -0.15353483\n",
      "  0.29231878  0.00876813 -0.26559196  0.25835347 -0.20129561 -0.24010062\n",
      "  0.081319   -0.4333077 ]\n",
      "Training Error:  9.879607704308022\n",
      "====================================================================================================\n",
      "Iteration:  427\n",
      "Previous theta :  [ 0.00773602 -0.10539688  0.07349555  0.0211691   0.05643456 -0.15353483\n",
      "  0.29231878  0.00876813 -0.26559196  0.25835347 -0.20129561 -0.24010062\n",
      "  0.081319   -0.4333077 ]\n",
      "New theta_0 : [ 0.0077441  -0.10550761  0.07369966  0.02105611  0.05648262 -0.1541024\n",
      "  0.29209142  0.00879466 -0.2662266   0.25858992 -0.20127131 -0.24018679\n",
      "  0.08127515 -0.43337166]\n",
      "Training Error:  9.878696585935822\n",
      "====================================================================================================\n",
      "Iteration:  428\n",
      "Previous theta :  [ 0.0077441  -0.10550761  0.07369966  0.02105611  0.05648262 -0.1541024\n",
      "  0.29209142  0.00879466 -0.2662266   0.25858992 -0.20127131 -0.24018679\n",
      "  0.08127515 -0.43337166]\n",
      "New theta_0 : [ 0.00775216 -0.1056178   0.07390278  0.02094425  0.05653043 -0.1546669\n",
      "  0.29186594  0.00882129 -0.26685718  0.258825   -0.20124741 -0.24027225\n",
      "  0.08123164 -0.43343461]\n",
      "Training Error:  9.877796539153564\n",
      "====================================================================================================\n",
      "Iteration:  429\n",
      "Previous theta :  [ 0.00775216 -0.1056178   0.07390278  0.02094425  0.05653043 -0.1546669\n",
      "  0.29186594  0.00882129 -0.26685718  0.258825   -0.20124741 -0.24027225\n",
      "  0.08123164 -0.43343461]\n",
      "New theta_0 : [ 0.00776021 -0.10572743  0.07410494  0.02083353  0.05657801 -0.15522833\n",
      "  0.29164232  0.00884802 -0.26748372  0.25905873 -0.20122389 -0.24035702\n",
      "  0.08118847 -0.43349655]\n",
      "Training Error:  9.876907425534784\n",
      "====================================================================================================\n",
      "Iteration:  430\n",
      "Previous theta :  [ 0.00776021 -0.10572743  0.07410494  0.02083353  0.05657801 -0.15522833\n",
      "  0.29164232  0.00884802 -0.26748372  0.25905873 -0.20122389 -0.24035702\n",
      "  0.08118847 -0.43349655]\n",
      "New theta_0 : [ 0.00776825 -0.1058365   0.07430611  0.02072392  0.05662535 -0.15578672\n",
      "  0.29142055  0.00887484 -0.26810625  0.2592911  -0.20120077 -0.24044111\n",
      "  0.08114563 -0.4335575 ]\n",
      "Training Error:  9.87602910846168\n",
      "====================================================================================================\n",
      "Iteration:  431\n",
      "Previous theta :  [ 0.00776825 -0.1058365   0.07430611  0.02072392  0.05662535 -0.15578672\n",
      "  0.29142055  0.00887484 -0.26810625  0.2592911  -0.20120077 -0.24044111\n",
      "  0.08114563 -0.4335575 ]\n",
      "New theta_0 : [ 0.00777627 -0.10594504  0.07450632  0.02061542  0.05667246 -0.15634207\n",
      "  0.29120061  0.00890174 -0.26872479  0.25952215 -0.20117803 -0.24052451\n",
      "  0.08110312 -0.43361748]\n",
      "Training Error:  9.87516145309973\n",
      "====================================================================================================\n",
      "Iteration:  432\n",
      "Previous theta :  [ 0.00777627 -0.10594504  0.07450632  0.02061542  0.05667246 -0.15634207\n",
      "  0.29120061  0.00890174 -0.26872479  0.25952215 -0.20117803 -0.24052451\n",
      "  0.08110312 -0.43361748]\n",
      "New theta_0 : [ 0.00778427 -0.10605302  0.07470555  0.02050802  0.05671933 -0.15689441\n",
      "  0.29098249  0.00892872 -0.26933937  0.25975186 -0.20115567 -0.24060724\n",
      "  0.08106094 -0.43367648]\n",
      "Training Error:  9.87430432637268\n",
      "====================================================================================================\n",
      "Iteration:  433\n",
      "Previous theta :  [ 0.00778427 -0.10605302  0.07470555  0.02050802  0.05671933 -0.15689441\n",
      "  0.29098249  0.00892872 -0.26933937  0.25975186 -0.20115567 -0.24060724\n",
      "  0.08106094 -0.43367648]\n",
      "New theta_0 : [ 0.00779226 -0.10616046  0.07490382  0.0204017   0.05676596 -0.15744375\n",
      "  0.29076616  0.00895577 -0.26995002  0.25998026 -0.20113369 -0.2406893\n",
      "  0.08101908 -0.43373454]\n",
      "Training Error:  9.873457596937936\n",
      "====================================================================================================\n",
      "Iteration:  434\n",
      "Previous theta :  [ 0.00779226 -0.10616046  0.07490382  0.0204017   0.05676596 -0.15744375\n",
      "  0.29076616  0.00895577 -0.26995002  0.25998026 -0.20113369 -0.2406893\n",
      "  0.08101908 -0.43373454]\n",
      "New theta_0 : [ 0.00780024 -0.10626736  0.07510112  0.02029647  0.05681237 -0.1579901\n",
      "  0.29055161  0.0089829  -0.27055677  0.26020734 -0.20111208 -0.2407707\n",
      "  0.08097754 -0.43379165]\n",
      "Training Error:  9.872621135162325\n",
      "====================================================================================================\n",
      "Iteration:  435\n",
      "Previous theta :  [ 0.00780024 -0.10626736  0.07510112  0.02029647  0.05681237 -0.1579901\n",
      "  0.29055161  0.0089829  -0.27055677  0.26020734 -0.20111208 -0.2407707\n",
      "  0.08097754 -0.43379165]\n",
      "New theta_0 : [ 0.0078082  -0.10637371  0.07529745  0.02019231  0.05685854 -0.15853349\n",
      "  0.29033883  0.0090101  -0.27115964  0.26043313 -0.20109085 -0.24085145\n",
      "  0.08093632 -0.43384784]\n",
      "Training Error:  9.871794813098253\n",
      "====================================================================================================\n",
      "Iteration:  436\n",
      "Previous theta :  [ 0.0078082  -0.10637371  0.07529745  0.02019231  0.05685854 -0.15853349\n",
      "  0.29033883  0.0090101  -0.27115964  0.26043313 -0.20109085 -0.24085145\n",
      "  0.08093632 -0.43384784]\n",
      "New theta_0 : [ 0.00781614 -0.10647953  0.07549282  0.0200892   0.05690448 -0.15907392\n",
      "  0.2901278   0.00903735 -0.27175865  0.26065762 -0.20106999 -0.24093156\n",
      "  0.08089542 -0.43390311]\n",
      "Training Error:  9.870978504460215\n",
      "====================================================================================================\n",
      "Iteration:  437\n",
      "Previous theta :  [ 0.00781614 -0.10647953  0.07549282  0.0200892   0.05690448 -0.15907392\n",
      "  0.2901278   0.00903735 -0.27175865  0.26065762 -0.20106999 -0.24093156\n",
      "  0.08089542 -0.43390311]\n",
      "New theta_0 : [ 0.00782407 -0.10658481  0.07568723  0.01998715  0.05695018 -0.15961142\n",
      "  0.2899185   0.00906466 -0.27235383  0.26088084 -0.20104949 -0.24101103\n",
      "  0.08085482 -0.43395747]\n",
      "Training Error:  9.870172084601691\n",
      "====================================================================================================\n",
      "Iteration:  438\n",
      "Previous theta :  [ 0.00782407 -0.10658481  0.07568723  0.01998715  0.05695018 -0.15961142\n",
      "  0.2899185   0.00906466 -0.27235383  0.26088084 -0.20104949 -0.24101103\n",
      "  0.08085482 -0.43395747]\n",
      "New theta_0 : [ 0.00783198 -0.10668956  0.07588068  0.01988613  0.05699566 -0.16014599\n",
      "  0.28971091  0.00909203 -0.27294521  0.26110278 -0.20102936 -0.24108987\n",
      "  0.08081453 -0.43401095]\n",
      "Training Error:  9.86937543049237\n",
      "====================================================================================================\n",
      "Iteration:  439\n",
      "Previous theta :  [ 0.00783198 -0.10668956  0.07588068  0.01988613  0.05699566 -0.16014599\n",
      "  0.28971091  0.00909203 -0.27294521  0.26110278 -0.20102936 -0.24108987\n",
      "  0.08081453 -0.43401095]\n",
      "New theta_0 : [ 0.00783987 -0.10679377  0.07607318  0.01978615  0.0570409  -0.16067765\n",
      "  0.28950503  0.00911945 -0.27353282  0.26132346 -0.20100959 -0.24116808\n",
      "  0.08077455 -0.43406354]\n",
      "Training Error:  9.868588420695746\n",
      "====================================================================================================\n",
      "Iteration:  440\n",
      "Previous theta :  [ 0.00783987 -0.10679377  0.07607318  0.01978615  0.0570409  -0.16067765\n",
      "  0.28950503  0.00911945 -0.27353282  0.26132346 -0.20100959 -0.24116808\n",
      "  0.08077455 -0.43406354]\n",
      "New theta_0 : [ 0.00784775 -0.10689746  0.07626471  0.01968719  0.05708592 -0.16120643\n",
      "  0.28930083  0.00914691 -0.27411667  0.26154289 -0.20099018 -0.24124568\n",
      "  0.08073488 -0.43411527]\n",
      "Training Error:  9.867810935347052\n",
      "====================================================================================================\n",
      "Iteration:  441\n",
      "Previous theta :  [ 0.00784775 -0.10689746  0.07626471  0.01968719  0.05708592 -0.16120643\n",
      "  0.28930083  0.00914691 -0.27411667  0.26154289 -0.20099018 -0.24124568\n",
      "  0.08073488 -0.43411527]\n",
      "New theta_0 : [ 0.00785561 -0.10700061  0.0764553   0.01958924  0.05713071 -0.16173232\n",
      "  0.2890983   0.00917441 -0.27469679  0.26176106 -0.20097112 -0.24132267\n",
      "  0.0806955  -0.43416613]\n",
      "Training Error:  9.867042856131533\n",
      "====================================================================================================\n",
      "Iteration:  442\n",
      "Previous theta :  [ 0.00785561 -0.10700061  0.0764553   0.01958924  0.05713071 -0.16173232\n",
      "  0.2890983   0.00917441 -0.27469679  0.26176106 -0.20097112 -0.24132267\n",
      "  0.0806955  -0.43416613]\n",
      "New theta_0 : [ 0.00786345 -0.10710324  0.07664493  0.0194923   0.05717527 -0.16225535\n",
      "  0.28889743  0.00920195 -0.27527321  0.26197801 -0.20095242 -0.24139905\n",
      "  0.08065642 -0.43421616]\n",
      "Training Error:  9.866284066263052\n",
      "====================================================================================================\n",
      "Iteration:  443\n",
      "Previous theta :  [ 0.00786345 -0.10710324  0.07664493  0.0194923   0.05717527 -0.16225535\n",
      "  0.28889743  0.00920195 -0.27527321  0.26197801 -0.20095242 -0.24139905\n",
      "  0.08065642 -0.43421616]\n",
      "New theta_0 : [ 0.00787127 -0.10720534  0.07683362  0.01939635  0.0572196  -0.16277553\n",
      "  0.28869819  0.00922953 -0.27584595  0.26219372 -0.20093406 -0.24147483\n",
      "  0.08061763 -0.43426534]\n",
      "Training Error:  9.865534450463029\n",
      "====================================================================================================\n",
      "Iteration:  444\n",
      "Previous theta :  [ 0.00787127 -0.10720534  0.07683362  0.01939635  0.0572196  -0.16277553\n",
      "  0.28869819  0.00922953 -0.27584595  0.26219372 -0.20093406 -0.24147483\n",
      "  0.08061763 -0.43426534]\n",
      "New theta_0 : [ 0.00787908 -0.10730692  0.07702136  0.01930139  0.0572637  -0.16329288\n",
      "  0.28850058  0.00925713 -0.27641504  0.26240821 -0.20091605 -0.24155003\n",
      "  0.08057914 -0.43431371]\n",
      "Training Error:  9.864793894939679\n",
      "====================================================================================================\n",
      "Iteration:  445\n",
      "Previous theta :  [ 0.00787908 -0.10730692  0.07702136  0.01930139  0.0572637  -0.16329288\n",
      "  0.28850058  0.00925713 -0.27641504  0.26240821 -0.20091605 -0.24155003\n",
      "  0.08057914 -0.43431371]\n",
      "New theta_0 : [ 0.00788687 -0.10740797  0.07720816  0.0192074   0.05730758 -0.16380741\n",
      "  0.28830459  0.00928476 -0.27698049  0.26262149 -0.20089838 -0.24162463\n",
      "  0.08054093 -0.43436126]\n",
      "Training Error:  9.864062287367593\n",
      "====================================================================================================\n",
      "Iteration:  446\n",
      "Previous theta :  [ 0.00788687 -0.10740797  0.07720816  0.0192074   0.05730758 -0.16380741\n",
      "  0.28830459  0.00928476 -0.27698049  0.26262149 -0.20089838 -0.24162463\n",
      "  0.08054093 -0.43436126]\n",
      "New theta_0 : [ 0.00789464 -0.10750851  0.07739401  0.01911439  0.05735124 -0.16431914\n",
      "  0.28811018  0.00931241 -0.27754234  0.26283357 -0.20088106 -0.24169866\n",
      "  0.08050301 -0.43440801]\n",
      "Training Error:  9.863339516867622\n",
      "====================================================================================================\n",
      "Iteration:  447\n",
      "Previous theta :  [ 0.00789464 -0.10750851  0.07739401  0.01911439  0.05735124 -0.16431914\n",
      "  0.28811018  0.00931241 -0.27754234  0.26283357 -0.20088106 -0.24169866\n",
      "  0.08050301 -0.43440801]\n",
      "New theta_0 : [ 0.00790239 -0.10760853  0.07757893  0.01902233  0.05739466 -0.16482808\n",
      "  0.28791736  0.00934009 -0.27810061  0.26304446 -0.20086407 -0.24177211\n",
      "  0.08046538 -0.43445396]\n",
      "Training Error:  9.862625473987043\n",
      "====================================================================================================\n",
      "Iteration:  448\n",
      "Previous theta :  [ 0.00790239 -0.10760853  0.07757893  0.01902233  0.05739466 -0.16482808\n",
      "  0.28791736  0.00934009 -0.27810061  0.26304446 -0.20086407 -0.24177211\n",
      "  0.08046538 -0.43445396]\n",
      "New theta_0 : [ 0.00791012 -0.10770804  0.07776291  0.01893123  0.05743787 -0.16533424\n",
      "  0.28772611  0.00936778 -0.27865532  0.26325416 -0.20084742 -0.241845\n",
      "  0.08042803 -0.43449914]\n",
      "Training Error:  9.861920050680057\n",
      "====================================================================================================\n",
      "Iteration:  449\n",
      "Previous theta :  [ 0.00791012 -0.10770804  0.07776291  0.01893123  0.05743787 -0.16533424\n",
      "  0.28772611  0.00936778 -0.27865532  0.26325416 -0.20084742 -0.241845\n",
      "  0.08042803 -0.43449914]\n",
      "New theta_0 : [ 0.00791784 -0.10780703  0.07794595  0.01884106  0.05748085 -0.16583764\n",
      "  0.2875364   0.00939548 -0.27920649  0.26346268 -0.2008311  -0.24191733\n",
      "  0.08039095 -0.43454354]\n",
      "Training Error:  9.861223140288562\n",
      "====================================================================================================\n",
      "Iteration:  450\n",
      "Previous theta :  [ 0.00791784 -0.10780703  0.07794595  0.01884106  0.05748085 -0.16583764\n",
      "  0.2875364   0.00939548 -0.27920649  0.26346268 -0.2008311  -0.24191733\n",
      "  0.08039095 -0.43454354]\n",
      "New theta_0 : [ 0.00792554 -0.10790552  0.07812807  0.01875184  0.05752361 -0.1663383\n",
      "  0.28734824  0.00942319 -0.27975415  0.26367003 -0.20081511 -0.2419891\n",
      "  0.08035416 -0.43458719]\n",
      "Training Error:  9.860534637523218\n",
      "====================================================================================================\n",
      "Iteration:  451\n",
      "Previous theta :  [ 0.00792554 -0.10790552  0.07812807  0.01875184  0.05752361 -0.1663383\n",
      "  0.28734824  0.00942319 -0.27975415  0.26367003 -0.20081511 -0.2419891\n",
      "  0.08035416 -0.43458719]\n",
      "New theta_0 : [ 0.00793321 -0.10800349  0.07830925  0.01866353  0.05756615 -0.16683623\n",
      "  0.2871616   0.00945091 -0.28029833  0.26387622 -0.20079945 -0.24206032\n",
      "  0.08031763 -0.43463008]\n",
      "Training Error:  9.859854438444803\n",
      "====================================================================================================\n",
      "Iteration:  452\n",
      "Previous theta :  [ 0.00793321 -0.10800349  0.07830925  0.01866353  0.05756615 -0.16683623\n",
      "  0.2871616   0.00945091 -0.28029833  0.26387622 -0.20079945 -0.24206032\n",
      "  0.08031763 -0.43463008]\n",
      "New theta_0 : [ 0.00794087 -0.10810096  0.07848951  0.01857615  0.05760847 -0.16733144\n",
      "  0.28697648  0.00947863 -0.28083903  0.26408125 -0.20078411 -0.242131\n",
      "  0.08028138 -0.43467224]\n",
      "Training Error:  9.859182440445833\n",
      "====================================================================================================\n",
      "Iteration:  453\n",
      "Previous theta :  [ 0.00794087 -0.10810096  0.07848951  0.01857615  0.05760847 -0.16733144\n",
      "  0.28697648  0.00947863 -0.28083903  0.26408125 -0.20078411 -0.242131\n",
      "  0.08028138 -0.43467224]\n",
      "New theta_0 : [ 0.00794851 -0.10819792  0.07866884  0.01848967  0.05765057 -0.16782394\n",
      "  0.28679285  0.00950635 -0.2813763   0.26428514 -0.20076909 -0.24220114\n",
      "  0.0802454  -0.43471366]\n",
      "Training Error:  9.858518542232478\n",
      "====================================================================================================\n",
      "Iteration:  454\n",
      "Previous theta :  [ 0.00794851 -0.10819792  0.07866884  0.01848967  0.05765057 -0.16782394\n",
      "  0.28679285  0.00950635 -0.2813763   0.26428514 -0.20076909 -0.24220114\n",
      "  0.0802454  -0.43471366]\n",
      "New theta_0 : [ 0.00795613 -0.10829438  0.07884726  0.0184041   0.05769245 -0.16831376\n",
      "  0.2866107   0.00953407 -0.28191014  0.2644879  -0.20075439 -0.24227074\n",
      "  0.08020968 -0.43475436]\n",
      "Training Error:  9.857862643806724\n",
      "====================================================================================================\n",
      "Iteration:  455\n",
      "Previous theta :  [ 0.00795613 -0.10829438  0.07884726  0.0184041   0.05769245 -0.16831376\n",
      "  0.2866107   0.00953407 -0.28191014  0.2644879  -0.20075439 -0.24227074\n",
      "  0.08020968 -0.43475436]\n",
      "New theta_0 : [ 0.00796373 -0.10839034  0.07902475  0.01831941  0.05773411 -0.1688009\n",
      "  0.28643003  0.00956179 -0.28244059  0.26468952 -0.20074001 -0.24233982\n",
      "  0.08017423 -0.43479435]\n",
      "Training Error:  9.857214646448828\n",
      "====================================================================================================\n",
      "Iteration:  456\n",
      "Previous theta :  [ 0.00796373 -0.10839034  0.07902475  0.01831941  0.05773411 -0.1688009\n",
      "  0.28643003  0.00956179 -0.28244059  0.26468952 -0.20074001 -0.24233982\n",
      "  0.08017423 -0.43479435]\n",
      "New theta_0 : [ 0.00797131 -0.1084858   0.07920133  0.01823562  0.05777556 -0.16928538\n",
      "  0.28625081  0.0095895  -0.28296766  0.26489002 -0.20072594 -0.24240838\n",
      "  0.08013904 -0.43483364]\n",
      "Training Error:  9.8565744527\n",
      "====================================================================================================\n",
      "Iteration:  457\n",
      "Previous theta :  [ 0.00797131 -0.1084858   0.07920133  0.01823562  0.05777556 -0.16928538\n",
      "  0.28625081  0.0095895  -0.28296766  0.26489002 -0.20072594 -0.24240838\n",
      "  0.08013904 -0.43483364]\n",
      "New theta_0 : [ 0.00797887 -0.10858076  0.079377    0.0181527   0.05781679 -0.16976722\n",
      "  0.28607304  0.00961719 -0.28349138  0.26508941 -0.20071219 -0.24247642\n",
      "  0.08010411 -0.43487224]\n",
      "Training Error:  9.855941966345382\n",
      "====================================================================================================\n",
      "Iteration:  458\n",
      "Previous theta :  [ 0.00797887 -0.10858076  0.079377    0.0181527   0.05781679 -0.16976722\n",
      "  0.28607304  0.00961719 -0.28349138  0.26508941 -0.20071219 -0.24247642\n",
      "  0.08010411 -0.43487224]\n",
      "New theta_0 : [ 0.00798641 -0.10867523  0.07955175  0.01807065  0.0578578  -0.17024642\n",
      "  0.28589669  0.00964487 -0.28401177  0.26528769 -0.20069874 -0.24254395\n",
      "  0.08006944 -0.43491015]\n",
      "Training Error:  9.855317092397232\n",
      "====================================================================================================\n",
      "Iteration:  459\n",
      "Previous theta :  [ 0.00798641 -0.10867523  0.07955175  0.01807065  0.0578578  -0.17024642\n",
      "  0.28589669  0.00964487 -0.28401177  0.26528769 -0.20069874 -0.24254395\n",
      "  0.08006944 -0.43491015]\n",
      "New theta_0 : [ 0.00799393 -0.1087692   0.0797256   0.01798946  0.05789859 -0.170723\n",
      "  0.28572177  0.00967254 -0.28452884  0.26548487 -0.2006856  -0.24261098\n",
      "  0.08003502 -0.43494739]\n",
      "Training Error:  9.854699737078409\n",
      "====================================================================================================\n",
      "Iteration:  460\n",
      "Previous theta :  [ 0.00799393 -0.1087692   0.0797256   0.01798946  0.05789859 -0.170723\n",
      "  0.28572177  0.00967254 -0.28452884  0.26548487 -0.2006856  -0.24261098\n",
      "  0.08003502 -0.43494739]\n",
      "New theta_0 : [ 0.00800143 -0.10886269  0.07989855  0.01790912  0.05793918 -0.17119698\n",
      "  0.28554825  0.00970018 -0.28504263  0.26568096 -0.20067276 -0.2426775\n",
      "  0.08000085 -0.43498397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.854089807806043\n",
      "====================================================================================================\n",
      "Iteration:  461\n",
      "Previous theta :  [ 0.00800143 -0.10886269  0.07989855  0.01790912  0.05793918 -0.17119698\n",
      "  0.28554825  0.00970018 -0.28504263  0.26568096 -0.20067276 -0.2426775\n",
      "  0.08000085 -0.43498397]\n",
      "New theta_0 : [ 0.00800891 -0.10895569  0.08007059  0.01782963  0.05797954 -0.17166836\n",
      "  0.28537613  0.00972781 -0.28555316  0.26587597 -0.20066022 -0.24274353\n",
      "  0.07996694 -0.43501989]\n",
      "Training Error:  9.853487213175505\n",
      "====================================================================================================\n",
      "Iteration:  462\n",
      "Previous theta :  [ 0.00800891 -0.10895569  0.08007059  0.01782963  0.05797954 -0.17166836\n",
      "  0.28537613  0.00972781 -0.28555316  0.26587597 -0.20066022 -0.24274353\n",
      "  0.07996694 -0.43501989]\n",
      "New theta_0 : [ 0.00801636 -0.1090482   0.08024173  0.01775098  0.0580197  -0.17213717\n",
      "  0.28520539  0.00975541 -0.28606044  0.2660699  -0.20064798 -0.24280907\n",
      "  0.07993328 -0.43505516]\n",
      "Training Error:  9.85289186294456\n",
      "====================================================================================================\n",
      "Iteration:  463\n",
      "Previous theta :  [ 0.00801636 -0.1090482   0.08024173  0.01775098  0.0580197  -0.17213717\n",
      "  0.28520539  0.00975541 -0.28606044  0.2660699  -0.20064798 -0.24280907\n",
      "  0.07993328 -0.43505516]\n",
      "New theta_0 : [ 0.0080238  -0.10914022  0.08041198  0.01767315  0.05805964 -0.17260341\n",
      "  0.28503602  0.00978299 -0.2865645   0.26626276 -0.20063604 -0.24287412\n",
      "  0.07989986 -0.43508979]\n",
      "Training Error:  9.85230366801779\n",
      "====================================================================================================\n",
      "Iteration:  464\n",
      "Previous theta :  [ 0.0080238  -0.10914022  0.08041198  0.01767315  0.05805964 -0.17260341\n",
      "  0.28503602  0.00978299 -0.2865645   0.26626276 -0.20063604 -0.24287412\n",
      "  0.07989986 -0.43508979]\n",
      "New theta_0 : [ 0.00803122 -0.10923176  0.08058133  0.01759615  0.05809938 -0.1730671\n",
      "  0.284868    0.00981053 -0.28706535  0.26645456 -0.20062439 -0.24293869\n",
      "  0.07986668 -0.43512379]\n",
      "Training Error:  9.851722540431217\n",
      "====================================================================================================\n",
      "Iteration:  465\n",
      "Previous theta :  [ 0.00803122 -0.10923176  0.08058133  0.01759615  0.05809938 -0.1730671\n",
      "  0.284868    0.00981053 -0.28706535  0.26645456 -0.20062439 -0.24293869\n",
      "  0.07986668 -0.43512379]\n",
      "New theta_0 : [ 0.00803861 -0.10932283  0.0807498   0.01751997  0.0581389  -0.17352825\n",
      "  0.28470133  0.00983805 -0.28756302  0.2666453  -0.20061304 -0.24300279\n",
      "  0.07983375 -0.43515717]\n",
      "Training Error:  9.851148393337173\n",
      "====================================================================================================\n",
      "Iteration:  466\n",
      "Previous theta :  [ 0.00803861 -0.10932283  0.0807498   0.01751997  0.0581389  -0.17352825\n",
      "  0.28470133  0.00983805 -0.28756302  0.2666453  -0.20061304 -0.24300279\n",
      "  0.07983375 -0.43515717]\n",
      "New theta_0 : [ 0.00804599 -0.10941341  0.08091738  0.01744459  0.05817821 -0.17398688\n",
      "  0.28453599  0.00986553 -0.28805754  0.266835   -0.20060197 -0.24306641\n",
      "  0.07980106 -0.43518994]\n",
      "Training Error:  9.85058114098938\n",
      "====================================================================================================\n",
      "Iteration:  467\n",
      "Previous theta :  [ 0.00804599 -0.10941341  0.08091738  0.01744459  0.05817821 -0.17398688\n",
      "  0.28453599  0.00986553 -0.28805754  0.266835   -0.20060197 -0.24306641\n",
      "  0.07980106 -0.43518994]\n",
      "New theta_0 : [ 0.00805334 -0.10950352  0.08108407  0.01737002  0.05821732 -0.174443\n",
      "  0.28437197  0.00989298 -0.28854891  0.26702366 -0.20059119 -0.24312957\n",
      "  0.07976861 -0.4352221 ]\n",
      "Training Error:  9.850020698728235\n",
      "====================================================================================================\n",
      "Iteration:  468\n",
      "Previous theta :  [ 0.00805334 -0.10950352  0.08108407  0.01737002  0.05821732 -0.174443\n",
      "  0.28437197  0.00989298 -0.28854891  0.26702366 -0.20059119 -0.24312957\n",
      "  0.07976861 -0.4352221 ]\n",
      "New theta_0 : [ 0.00806067 -0.10959315  0.08124988  0.01729624  0.05825621 -0.17489661\n",
      "  0.28420926  0.00992039 -0.28903716  0.26721128 -0.20058069 -0.24319227\n",
      "  0.07973639 -0.43525367]\n",
      "Training Error:  9.849466982966343\n",
      "====================================================================================================\n",
      "Iteration:  469\n",
      "Previous theta :  [ 0.00806067 -0.10959315  0.08124988  0.01729624  0.05825621 -0.17489661\n",
      "  0.28420926  0.00992039 -0.28903716  0.26721128 -0.20058069 -0.24319227\n",
      "  0.07973639 -0.43525367]\n",
      "New theta_0 : [ 0.00806798 -0.10968232  0.08141482  0.01722324  0.0582949  -0.17534775\n",
      "  0.28404785  0.00994776 -0.28952232  0.26739788 -0.20057047 -0.24325451\n",
      "  0.07970441 -0.43528464]\n",
      "Training Error:  9.848919911174207\n",
      "====================================================================================================\n",
      "Iteration:  470\n",
      "Previous theta :  [ 0.00806798 -0.10968232  0.08141482  0.01722324  0.0582949  -0.17534775\n",
      "  0.28404785  0.00994776 -0.28952232  0.26739788 -0.20057047 -0.24325451\n",
      "  0.07970441 -0.43528464]\n",
      "New theta_0 : [ 0.00807527 -0.10977101  0.08157888  0.01715103  0.05833338 -0.17579641\n",
      "  0.28388772  0.00997509 -0.29000439  0.26758346 -0.20056053 -0.2433163\n",
      "  0.07967266 -0.43531504]\n",
      "Training Error:  9.848379401866177\n",
      "====================================================================================================\n",
      "Iteration:  471\n",
      "Previous theta :  [ 0.00807527 -0.10977101  0.08157888  0.01715103  0.05833338 -0.17579641\n",
      "  0.28388772  0.00997509 -0.29000439  0.26758346 -0.20056053 -0.2433163\n",
      "  0.07967266 -0.43531504]\n",
      "New theta_0 : [ 0.00808253 -0.10985923  0.08174206  0.01707958  0.05837166 -0.17624261\n",
      "  0.28372887  0.01000238 -0.29048341  0.26776803 -0.20055087 -0.24337764\n",
      "  0.07964114 -0.43534486]\n",
      "Training Error:  9.847845374586582\n",
      "====================================================================================================\n",
      "Iteration:  472\n",
      "Previous theta :  [ 0.00808253 -0.10985923  0.08174206  0.01707958  0.05837166 -0.17624261\n",
      "  0.28372887  0.01000238 -0.29048341  0.26776803 -0.20055087 -0.24337764\n",
      "  0.07964114 -0.43534486]\n",
      "New theta_0 : [ 0.00808978 -0.10994699  0.08190438  0.0170089   0.05840973 -0.17668637\n",
      "  0.28357128  0.01002962 -0.29095939  0.26795159 -0.20054149 -0.24343853\n",
      "  0.07960985 -0.43537412]\n",
      "Training Error:  9.847317749896034\n",
      "====================================================================================================\n",
      "Iteration:  473\n",
      "Previous theta :  [ 0.00808978 -0.10994699  0.08190438  0.0170089   0.05840973 -0.17668637\n",
      "  0.28357128  0.01002962 -0.29095939  0.26795159 -0.20054149 -0.24343853\n",
      "  0.07960985 -0.43537412]\n",
      "New theta_0 : [ 0.008097   -0.11003428  0.08206583  0.01693898  0.0584476  -0.17712769\n",
      "  0.28341495  0.01005681 -0.29143235  0.26813415 -0.20053237 -0.24349899\n",
      "  0.07957879 -0.43540282]\n",
      "Training Error:  9.846796449357981\n",
      "====================================================================================================\n",
      "Iteration:  474\n",
      "Previous theta :  [ 0.008097   -0.11003428  0.08206583  0.01693898  0.0584476  -0.17712769\n",
      "  0.28341495  0.01005681 -0.29143235  0.26813415 -0.20053237 -0.24349899\n",
      "  0.07957879 -0.43540282]\n",
      "New theta_0 : [ 0.0081042  -0.11012111  0.08222643  0.01686982  0.05848527 -0.1775666\n",
      "  0.28325985  0.01008396 -0.29190231  0.26831573 -0.20052353 -0.24355901\n",
      "  0.07954795 -0.43543097]\n",
      "Training Error:  9.846281395525413\n",
      "====================================================================================================\n",
      "Iteration:  475\n",
      "Previous theta :  [ 0.0081042  -0.11012111  0.08222643  0.01686982  0.05848527 -0.1775666\n",
      "  0.28325985  0.01008396 -0.29190231  0.26831573 -0.20052353 -0.24355901\n",
      "  0.07954795 -0.43543097]\n",
      "New theta_0 : [ 0.00811138 -0.11020749  0.08238616  0.01680139  0.05852273 -0.1780031\n",
      "  0.28310599  0.01011105 -0.2923693   0.26849631 -0.20051495 -0.24361861\n",
      "  0.07951733 -0.43545857]\n",
      "Training Error:  9.84577251192777\n",
      "====================================================================================================\n",
      "Iteration:  476\n",
      "Previous theta :  [ 0.00811138 -0.11020749  0.08238616  0.01680139  0.05852273 -0.1780031\n",
      "  0.28310599  0.01011105 -0.2923693   0.26849631 -0.20051495 -0.24361861\n",
      "  0.07951733 -0.43545857]\n",
      "New theta_0 : [ 0.00811854 -0.1102934   0.08254503  0.01673371  0.05855999 -0.1784372\n",
      "  0.28295335  0.01013809 -0.29283332  0.26867592 -0.20050664 -0.24367777\n",
      "  0.07948694 -0.43548565]\n",
      "Training Error:  9.845269723058044\n",
      "====================================================================================================\n",
      "Iteration:  477\n",
      "Previous theta :  [ 0.00811854 -0.1102934   0.08254503  0.01673371  0.05855999 -0.1784372\n",
      "  0.28295335  0.01013809 -0.29283332  0.26867592 -0.20050664 -0.24367777\n",
      "  0.07948694 -0.43548565]\n",
      "New theta_0 : [ 0.00812567 -0.11037886  0.08270305  0.01666675  0.05859705 -0.17886892\n",
      "  0.28280191  0.01016508 -0.2932944   0.26885456 -0.2004986  -0.24373652\n",
      "  0.07945676 -0.43551219]\n",
      "Training Error:  9.844772954360053\n",
      "====================================================================================================\n",
      "Iteration:  478\n",
      "Previous theta :  [ 0.00812567 -0.11037886  0.08270305  0.01666675  0.05859705 -0.17886892\n",
      "  0.28280191  0.01016508 -0.2932944   0.26885456 -0.2004986  -0.24373652\n",
      "  0.07945676 -0.43551219]\n",
      "New theta_0 : [ 0.00813278 -0.11046386  0.08286022  0.01660052  0.05863392 -0.17929827\n",
      "  0.28265167  0.01019201 -0.29375256  0.26903223 -0.20049081 -0.24379484\n",
      "  0.0794268  -0.43553821]\n",
      "Training Error:  9.844282132215913\n",
      "====================================================================================================\n",
      "Iteration:  479\n",
      "Previous theta :  [ 0.00813278 -0.11046386  0.08286022  0.01660052  0.05863392 -0.17929827\n",
      "  0.28265167  0.01019201 -0.29375256  0.26903223 -0.20049081 -0.24379484\n",
      "  0.0794268  -0.43553821]\n",
      "New theta_0 : [ 0.00813987 -0.11054842  0.08301655  0.01653501  0.05867058 -0.17972526\n",
      "  0.28250262  0.01021889 -0.29420782  0.26920894 -0.20048328 -0.24385276\n",
      "  0.07939706 -0.43556372]\n",
      "Training Error:  9.843797183933665\n",
      "====================================================================================================\n",
      "Iteration:  480\n",
      "Previous theta :  [ 0.00813987 -0.11054842  0.08301655  0.01653501  0.05867058 -0.17972526\n",
      "  0.28250262  0.01021889 -0.29420782  0.26920894 -0.20048328 -0.24385276\n",
      "  0.07939706 -0.43556372]\n",
      "New theta_0 : [ 0.00814694 -0.11063252  0.08317203  0.01647021  0.05870704 -0.18014991\n",
      "  0.28235475  0.0102457  -0.29466019  0.2693847  -0.20047601 -0.24391026\n",
      "  0.07936753 -0.43558872]\n",
      "Training Error:  9.843318037735097\n",
      "====================================================================================================\n",
      "Iteration:  481\n",
      "Previous theta :  [ 0.00814694 -0.11063252  0.08317203  0.01647021  0.05870704 -0.18014991\n",
      "  0.28235475  0.0102457  -0.29466019  0.2693847  -0.20047601 -0.24391026\n",
      "  0.07936753 -0.43558872]\n",
      "New theta_0 : [ 0.00815398 -0.11071617  0.08332667  0.01640611  0.05874331 -0.18057223\n",
      "  0.28220804  0.01027246 -0.2951097   0.26955952 -0.200469   -0.24396736\n",
      "  0.07933822 -0.43561322]\n",
      "Training Error:  9.842844622743735\n",
      "====================================================================================================\n",
      "Iteration:  482\n",
      "Previous theta :  [ 0.00815398 -0.11071617  0.08332667  0.01640611  0.05874331 -0.18057223\n",
      "  0.28220804  0.01027246 -0.2951097   0.26955952 -0.200469   -0.24396736\n",
      "  0.07933822 -0.43561322]\n",
      "New theta_0 : [ 0.008161   -0.11079938  0.08348048  0.01634271  0.05877938 -0.18099223\n",
      "  0.28206249  0.01029916 -0.29555636  0.26973339 -0.20046223 -0.24402405\n",
      "  0.07930911 -0.43563723]\n",
      "Training Error:  9.842376868972993\n",
      "====================================================================================================\n",
      "Iteration:  483\n",
      "Previous theta :  [ 0.008161   -0.11079938  0.08348048  0.01634271  0.05877938 -0.18099223\n",
      "  0.28206249  0.01029916 -0.29555636  0.26973339 -0.20046223 -0.24402405\n",
      "  0.07930911 -0.43563723]\n",
      "New theta_0 : [ 0.008168   -0.11088215  0.08363345  0.01628001  0.05881526 -0.18140992\n",
      "  0.28191809  0.01032579 -0.2960002   0.26990633 -0.20045572 -0.24408035\n",
      "  0.07928021 -0.43566076]\n",
      "Training Error:  9.841914707314505\n",
      "====================================================================================================\n",
      "Iteration:  484\n",
      "Previous theta :  [ 0.008168   -0.11088215  0.08363345  0.01628001  0.05881526 -0.18140992\n",
      "  0.28191809  0.01032579 -0.2960002   0.26990633 -0.20045572 -0.24408035\n",
      "  0.07928021 -0.43566076]\n",
      "New theta_0 : [ 0.00817498 -0.11096447  0.08378559  0.01621799  0.05885094 -0.18182531\n",
      "  0.28177482  0.01035235 -0.29644122  0.27007835 -0.20044946 -0.24413625\n",
      "  0.07925152 -0.4356838 ]\n",
      "Training Error:  9.841458069526611\n",
      "====================================================================================================\n",
      "Iteration:  485\n",
      "Previous theta :  [ 0.00817498 -0.11096447  0.08378559  0.01621799  0.05885094 -0.18182531\n",
      "  0.28177482  0.01035235 -0.29644122  0.27007835 -0.20044946 -0.24413625\n",
      "  0.07925152 -0.4356838 ]\n",
      "New theta_0 : [ 0.00818193 -0.11104636  0.0839369   0.01615665  0.05888642 -0.18223843\n",
      "  0.28163268  0.01037885 -0.29687946  0.27024944 -0.20044344 -0.24419177\n",
      "  0.07922304 -0.43570637]\n",
      "Training Error:  9.841006888223015\n",
      "====================================================================================================\n",
      "Iteration:  486\n",
      "Previous theta :  [ 0.00818193 -0.11104636  0.0839369   0.01615665  0.05888642 -0.18223843\n",
      "  0.28163268  0.01037885 -0.29687946  0.27024944 -0.20044344 -0.24419177\n",
      "  0.07922304 -0.43570637]\n",
      "New theta_0 : [ 0.00818886 -0.1111278   0.08408739  0.01609598  0.05892172 -0.18264927\n",
      "  0.28149166  0.01040529 -0.29731492  0.27041962 -0.20043766 -0.24424689\n",
      "  0.07919476 -0.43572847]\n",
      "Training Error:  9.840561096861581\n",
      "====================================================================================================\n",
      "Iteration:  487\n",
      "Previous theta :  [ 0.00818886 -0.1111278   0.08408739  0.01609598  0.05892172 -0.18264927\n",
      "  0.28149166  0.01040529 -0.29731492  0.27041962 -0.20043766 -0.24424689\n",
      "  0.07919476 -0.43572847]\n",
      "New theta_0 : [ 0.00819577 -0.11120881  0.08423706  0.01603598  0.05895682 -0.18305785\n",
      "  0.28135174  0.01043165 -0.29774763  0.27058889 -0.20043213 -0.24430164\n",
      "  0.07916668 -0.43575012]\n",
      "Training Error:  9.840120629733324\n",
      "====================================================================================================\n",
      "Iteration:  488\n",
      "Previous theta :  [ 0.00819577 -0.11120881  0.08423706  0.01603598  0.05895682 -0.18305785\n",
      "  0.28135174  0.01043165 -0.29774763  0.27058889 -0.20043213 -0.24430164\n",
      "  0.07916668 -0.43575012]\n",
      "New theta_0 : [ 0.00820265 -0.11128939  0.08438591  0.01597664  0.05899173 -0.18346419\n",
      "  0.28121292  0.01045795 -0.2981776   0.27075726 -0.20042684 -0.244356\n",
      "  0.0791388  -0.43577131]\n",
      "Training Error:  9.839685421951508\n",
      "====================================================================================================\n",
      "Iteration:  489\n",
      "Previous theta :  [ 0.00820265 -0.11128939  0.08438591  0.01597664  0.05899173 -0.18346419\n",
      "  0.28121292  0.01045795 -0.2981776   0.27075726 -0.20042684 -0.244356\n",
      "  0.0791388  -0.43577131]\n",
      "New theta_0 : [ 0.00820952 -0.11136954  0.08453394  0.01591796  0.05902644 -0.18386829\n",
      "  0.28107519  0.01048417 -0.29860485  0.27092473 -0.20042178 -0.24440999\n",
      "  0.07911112 -0.43579205]\n",
      "Training Error:  9.83925540944095\n",
      "====================================================================================================\n",
      "Iteration:  490\n",
      "Previous theta :  [ 0.00820952 -0.11136954  0.08453394  0.01591796  0.05902644 -0.18386829\n",
      "  0.28107519  0.01048417 -0.29860485  0.27092473 -0.20042178 -0.24440999\n",
      "  0.07911112 -0.43579205]\n",
      "New theta_0 : [ 0.00821635 -0.11144925  0.08468117  0.01585992  0.05906097 -0.18427017\n",
      "  0.28093854  0.01051032 -0.29902939  0.27109131 -0.20041696 -0.24446361\n",
      "  0.07908364 -0.43581235]\n",
      "Training Error:  9.83883052892741\n",
      "====================================================================================================\n",
      "Iteration:  491\n",
      "Previous theta :  [ 0.00821635 -0.11144925  0.08468117  0.01585992  0.05906097 -0.18427017\n",
      "  0.28093854  0.01051032 -0.29902939  0.27109131 -0.20041696 -0.24446361\n",
      "  0.07908364 -0.43581235]\n",
      "New theta_0 : [ 0.00822317 -0.11152854  0.08482759  0.01580253  0.05909531 -0.18466983\n",
      "  0.28080295  0.0105364  -0.29945126  0.27125701 -0.20041238 -0.24451685\n",
      "  0.07905635 -0.43583221]\n",
      "Training Error:  9.838410717927196\n",
      "====================================================================================================\n",
      "Iteration:  492\n",
      "Previous theta :  [ 0.00822317 -0.11152854  0.08482759  0.01580253  0.05909531 -0.18466983\n",
      "  0.28080295  0.0105364  -0.29945126  0.27125701 -0.20041238 -0.24451685\n",
      "  0.07905635 -0.43583221]\n",
      "New theta_0 : [ 0.00822996 -0.11160741  0.0849732   0.01574578  0.05912946 -0.1850673\n",
      "  0.28066843  0.0105624  -0.29987045  0.27142183 -0.20040803 -0.24456974\n",
      "  0.07902926 -0.43585165]\n",
      "Training Error:  9.837995914736862\n",
      "====================================================================================================\n",
      "Iteration:  493\n",
      "Previous theta :  [ 0.00822996 -0.11160741  0.0849732   0.01574578  0.05912946 -0.1850673\n",
      "  0.28066843  0.0105624  -0.29987045  0.27142183 -0.20040803 -0.24456974\n",
      "  0.07902926 -0.43585165]\n",
      "New theta_0 : [ 0.00823673 -0.11168585  0.08511801  0.01568966  0.05916343 -0.18546258\n",
      "  0.28053495  0.01058833 -0.300287    0.27158577 -0.2004039  -0.24462226\n",
      "  0.07900236 -0.43587066]\n",
      "Training Error:  9.837586058423067\n",
      "====================================================================================================\n",
      "Iteration:  494\n",
      "Previous theta :  [ 0.00823673 -0.11168585  0.08511801  0.01568966  0.05916343 -0.18546258\n",
      "  0.28053495  0.01058833 -0.300287    0.27158577 -0.2004039  -0.24462226\n",
      "  0.07900236 -0.43587066]\n",
      "New theta_0 : [ 0.00824347 -0.11176386  0.08526203  0.01563416  0.05919721 -0.18585568\n",
      "  0.28040252  0.01061419 -0.30070091  0.27174885 -0.20040001 -0.24467442\n",
      "  0.07897565 -0.43588926]\n",
      "Training Error:  9.837181088812597\n",
      "====================================================================================================\n",
      "Iteration:  495\n",
      "Previous theta :  [ 0.00824347 -0.11176386  0.08526203  0.01563416  0.05919721 -0.18585568\n",
      "  0.28040252  0.01061419 -0.30070091  0.27174885 -0.20040001 -0.24467442\n",
      "  0.07897565 -0.43588926]\n",
      "New theta_0 : [ 0.00825019 -0.11184146  0.08540525  0.01557928  0.0592308  -0.18624662\n",
      "  0.28027112  0.01063996 -0.30111221  0.27191107 -0.20039634 -0.24472623\n",
      "  0.07894913 -0.43590744]\n",
      "Training Error:  9.836780946482474\n",
      "====================================================================================================\n",
      "Iteration:  496\n",
      "Previous theta :  [ 0.00825019 -0.11184146  0.08540525  0.01557928  0.0592308  -0.18624662\n",
      "  0.28027112  0.01063996 -0.30111221  0.27191107 -0.20039634 -0.24472623\n",
      "  0.07894913 -0.43590744]\n",
      "New theta_0 : [ 0.00825689 -0.11191864  0.08554768  0.01552502  0.0592642  -0.18663541\n",
      "  0.28014075  0.01066566 -0.30152091  0.27207243 -0.20039289 -0.24477769\n",
      "  0.0789228  -0.43592522]\n",
      "Training Error:  9.83638557275026\n",
      "====================================================================================================\n",
      "Iteration:  497\n",
      "Previous theta :  [ 0.00825689 -0.11191864  0.08554768  0.01552502  0.0592642  -0.18663541\n",
      "  0.28014075  0.01066566 -0.30152091  0.27207243 -0.20039289 -0.24477769\n",
      "  0.0789228  -0.43592522]\n",
      "New theta_0 : [ 0.00826357 -0.11199541  0.08568932  0.01547137  0.05929743 -0.18702205\n",
      "  0.28001139  0.01069128 -0.30192703  0.27223294 -0.20038967 -0.24482879\n",
      "  0.07889666 -0.4359426 ]\n",
      "Training Error:  9.835994909664448\n",
      "====================================================================================================\n",
      "Iteration:  498\n",
      "Previous theta :  [ 0.00826357 -0.11199541  0.08568932  0.01547137  0.05929743 -0.18702205\n",
      "  0.28001139  0.01069128 -0.30192703  0.27223294 -0.20038967 -0.24482879\n",
      "  0.07889666 -0.4359426 ]\n",
      "New theta_0 : [ 0.00827022 -0.11207176  0.08583018  0.01541832  0.05933047 -0.18740656\n",
      "  0.27988303  0.01071681 -0.30233058  0.2723926  -0.20038666 -0.24487956\n",
      "  0.0788707  -0.43595958]\n",
      "Training Error:  9.83560889999502\n",
      "====================================================================================================\n",
      "Iteration:  499\n",
      "Previous theta :  [ 0.00827022 -0.11207176  0.08583018  0.01541832  0.05933047 -0.18740656\n",
      "  0.27988303  0.01071681 -0.30233058  0.2723926  -0.20038666 -0.24487956\n",
      "  0.0788707  -0.43595958]\n",
      "New theta_0 : [ 0.00827685 -0.1121477   0.08597026  0.01536586  0.05936332 -0.18778896\n",
      "  0.27975567  0.01074227 -0.30273159  0.27255143 -0.20038388 -0.24492998\n",
      "  0.07884493 -0.43597618]\n",
      "Training Error:  9.835227487224103\n",
      "====================================================================================================\n",
      "Iteration:  500\n",
      "Previous theta :  [ 0.00827685 -0.1121477   0.08597026  0.01536586  0.05936332 -0.18778896\n",
      "  0.27975567  0.01074227 -0.30273159  0.27255143 -0.20038388 -0.24492998\n",
      "  0.07884493 -0.43597618]\n",
      "New theta_0 : [ 0.00828345 -0.11222323  0.08610956  0.015314    0.059396   -0.18816925\n",
      "  0.2796293   0.01076764 -0.30313006  0.27270942 -0.20038131 -0.24498006\n",
      "  0.07881934 -0.43599239]\n",
      "Training Error:  9.834850615536787\n",
      "====================================================================================================\n",
      "Iteration:  501\n",
      "Previous theta :  [ 0.00828345 -0.11222323  0.08610956  0.015314    0.059396   -0.18816925\n",
      "  0.2796293   0.01076764 -0.30313006  0.27270942 -0.20038131 -0.24498006\n",
      "  0.07881934 -0.43599239]\n",
      "New theta_0 : [ 0.00829003 -0.11229835  0.08624808  0.01526273  0.05942849 -0.18854744\n",
      "  0.27950392  0.01079293 -0.30352602  0.27286658 -0.20037895 -0.24502981\n",
      "  0.07879393 -0.43600822]\n",
      "Training Error:  9.83447822981204\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  502\n",
      "Previous theta :  [ 0.00829003 -0.11229835  0.08624808  0.01526273  0.05942849 -0.18854744\n",
      "  0.27950392  0.01079293 -0.30352602  0.27286658 -0.20037895 -0.24502981\n",
      "  0.07879393 -0.43600822]\n",
      "New theta_0 : [ 0.00829659 -0.11237307  0.08638584  0.01521203  0.05946081 -0.18892354\n",
      "  0.2793795   0.01081814 -0.30391947  0.27302293 -0.20037681 -0.24507922\n",
      "  0.0787687  -0.43602368]\n",
      "Training Error:  9.834110275613767\n",
      "====================================================================================================\n",
      "Iteration:  503\n",
      "Previous theta :  [ 0.00829659 -0.11237307  0.08638584  0.01521203  0.05946081 -0.18892354\n",
      "  0.2793795   0.01081814 -0.30391947  0.27302293 -0.20037681 -0.24507922\n",
      "  0.0787687  -0.43602368]\n",
      "New theta_0 : [ 0.00830312 -0.11244738  0.08652283  0.01516191  0.05949294 -0.18929758\n",
      "  0.27925605  0.01084326 -0.30431045  0.27317845 -0.20037488 -0.24512831\n",
      "  0.07874364 -0.43603877]\n",
      "Training Error:  9.833746699181988\n",
      "====================================================================================================\n",
      "Iteration:  504\n",
      "Previous theta :  [ 0.00830312 -0.11244738  0.08652283  0.01516191  0.05949294 -0.18929758\n",
      "  0.27925605  0.01084326 -0.30431045  0.27317845 -0.20037488 -0.24512831\n",
      "  0.07874364 -0.43603877]\n",
      "New theta_0 : [ 0.00830963 -0.11252129  0.08665905  0.01511237  0.0595249  -0.18966955\n",
      "  0.27913355  0.0108683  -0.30469895  0.27333316 -0.20037316 -0.24517707\n",
      "  0.07871877 -0.4360535 ]\n",
      "Training Error:  9.833387447424121\n",
      "====================================================================================================\n",
      "Iteration:  505\n",
      "Previous theta :  [ 0.00830963 -0.11252129  0.08665905  0.01511237  0.0595249  -0.18966955\n",
      "  0.27913355  0.0108683  -0.30469895  0.27333316 -0.20037316 -0.24517707\n",
      "  0.07871877 -0.4360535 ]\n",
      "New theta_0 : [ 0.00831612 -0.1125948   0.08679451  0.01506339  0.05955668 -0.19003946\n",
      "  0.279012    0.01089325 -0.30508501  0.27348707 -0.20037164 -0.2452255\n",
      "  0.07869407 -0.43606787]\n",
      "Training Error:  9.833032467906406\n",
      "====================================================================================================\n",
      "Iteration:  506\n",
      "Previous theta :  [ 0.00831612 -0.1125948   0.08679451  0.01506339  0.05955668 -0.19003946\n",
      "  0.279012    0.01089325 -0.30508501  0.27348707 -0.20037164 -0.2452255\n",
      "  0.07869407 -0.43606787]\n",
      "New theta_0 : [ 0.00832258 -0.11266792  0.08692922  0.01501496  0.05958828 -0.19040734\n",
      "  0.27889139  0.01091812 -0.30546863  0.27364017 -0.20037033 -0.24527362\n",
      "  0.07866954 -0.43608189]\n",
      "Training Error:  9.832681708845438\n",
      "====================================================================================================\n",
      "Iteration:  507\n",
      "Previous theta :  [ 0.00832258 -0.11266792  0.08692922  0.01501496  0.05958828 -0.19040734\n",
      "  0.27889139  0.01091812 -0.30546863  0.27364017 -0.20037033 -0.24527362\n",
      "  0.07866954 -0.43608189]\n",
      "New theta_0 : [ 0.00832902 -0.11274063  0.08706317  0.0149671   0.0596197  -0.19077319\n",
      "  0.27877171  0.0109429  -0.30584983  0.27379248 -0.20036923 -0.24532142\n",
      "  0.07864519 -0.43609556]\n",
      "Training Error:  9.832335119099804\n",
      "====================================================================================================\n",
      "Iteration:  508\n",
      "Previous theta :  [ 0.00832902 -0.11274063  0.08706317  0.0149671   0.0596197  -0.19077319\n",
      "  0.27877171  0.0109429  -0.30584983  0.27379248 -0.20036923 -0.24532142\n",
      "  0.07864519 -0.43609556]\n",
      "New theta_0 : [ 0.00833543 -0.11281295  0.08719638  0.01491978  0.05965096 -0.19113701\n",
      "  0.27865295  0.01096759 -0.30622862  0.273944   -0.20036832 -0.2453689\n",
      "  0.07862101 -0.43610889]\n",
      "Training Error:  9.831992648161858\n",
      "====================================================================================================\n",
      "Iteration:  509\n",
      "Previous theta :  [ 0.00833543 -0.11281295  0.08719638  0.01491978  0.05965096 -0.19113701\n",
      "  0.27865295  0.01096759 -0.30622862  0.273944   -0.20036832 -0.2453689\n",
      "  0.07862101 -0.43610889]\n",
      "New theta_0 : [ 0.00834182 -0.11288488  0.08732883  0.01487301  0.05968203 -0.19149883\n",
      "  0.27853511  0.01099219 -0.30660503  0.27409473 -0.20036762 -0.24541607\n",
      "  0.078597   -0.43612188]\n",
      "Training Error:  9.831654246149578\n",
      "====================================================================================================\n",
      "Iteration:  510\n",
      "Previous theta :  [ 0.00834182 -0.11288488  0.08732883  0.01487301  0.05968203 -0.19149883\n",
      "  0.27853511  0.01099219 -0.30660503  0.27409473 -0.20036762 -0.24541607\n",
      "  0.078597   -0.43612188]\n",
      "New theta_0 : [ 0.00834819 -0.11295642  0.08746054  0.01482677  0.05971294 -0.19185865\n",
      "  0.27841817  0.01101671 -0.30697906  0.27424468 -0.20036711 -0.24546293\n",
      "  0.07857316 -0.43613454]\n",
      "Training Error:  9.831319863798557\n",
      "====================================================================================================\n",
      "Iteration:  511\n",
      "Previous theta :  [ 0.00834819 -0.11295642  0.08746054  0.01482677  0.05971294 -0.19185865\n",
      "  0.27841817  0.01101671 -0.30697906  0.27424468 -0.20036711 -0.24546293\n",
      "  0.07857316 -0.43613454]\n",
      "New theta_0 : [ 0.00835453 -0.11302757  0.08759151  0.01478108  0.05974367 -0.19221649\n",
      "  0.27830214  0.01104113 -0.30735073  0.27439386 -0.2003668  -0.24550949\n",
      "  0.07854948 -0.43614686]\n",
      "Training Error:  9.8309894524541\n",
      "====================================================================================================\n",
      "Iteration:  512\n",
      "Previous theta :  [ 0.00835453 -0.11302757  0.08759151  0.01478108  0.05974367 -0.19221649\n",
      "  0.27830214  0.01104113 -0.30735073  0.27439386 -0.2003668  -0.24550949\n",
      "  0.07854948 -0.43614686]\n",
      "New theta_0 : [ 0.00836085 -0.11309834  0.08772174  0.01473591  0.05977422 -0.19257235\n",
      "  0.27818699  0.01106547 -0.30772006  0.27454226 -0.20036669 -0.24555574\n",
      "  0.07852597 -0.43615887]\n",
      "Training Error:  9.830662964063405\n",
      "====================================================================================================\n",
      "Iteration:  513\n",
      "Previous theta :  [ 0.00836085 -0.11309834  0.08772174  0.01473591  0.05977422 -0.19257235\n",
      "  0.27818699  0.01106547 -0.30772006  0.27454226 -0.20036669 -0.24555574\n",
      "  0.07852597 -0.43615887]\n",
      "New theta_0 : [ 0.00836715 -0.11316872  0.08785124  0.01469127  0.05980461 -0.19292624\n",
      "  0.27807273  0.01108971 -0.30808706  0.2746899  -0.20036677 -0.24560169\n",
      "  0.07850263 -0.43617056]\n",
      "Training Error:  9.830340351167887\n",
      "====================================================================================================\n",
      "Iteration:  514\n",
      "Previous theta :  [ 0.00836715 -0.11316872  0.08785124  0.01469127  0.05980461 -0.19292624\n",
      "  0.27807273  0.01108971 -0.30808706  0.2746899  -0.20036677 -0.24560169\n",
      "  0.07850263 -0.43617056]\n",
      "New theta_0 : [ 0.00837342 -0.11323871  0.08798001  0.01464714  0.05983483 -0.19327818\n",
      "  0.27795935  0.01111386 -0.30845175  0.27483678 -0.20036704 -0.24564734\n",
      "  0.07847945 -0.43618193]\n",
      "Training Error:  9.830021566895574\n",
      "====================================================================================================\n",
      "Iteration:  515\n",
      "Previous theta :  [ 0.00837342 -0.11323871  0.08798001  0.01464714  0.05983483 -0.19327818\n",
      "  0.27795935  0.01111386 -0.30845175  0.27483678 -0.20036704 -0.24564734\n",
      "  0.07847945 -0.43618193]\n",
      "New theta_0 : [ 0.00837967 -0.11330833  0.08810806  0.01460354  0.05986488 -0.19362817\n",
      "  0.27784684  0.01113792 -0.30881414  0.2749829  -0.2003675  -0.2456927\n",
      "  0.07845644 -0.43619299]\n",
      "Training Error:  9.82970656495362\n",
      "====================================================================================================\n",
      "Iteration:  516\n",
      "Previous theta :  [ 0.00837967 -0.11330833  0.08810806  0.01460354  0.05986488 -0.19362817\n",
      "  0.27784684  0.01113792 -0.30881414  0.2749829  -0.2003675  -0.2456927\n",
      "  0.07845644 -0.43619299]\n",
      "New theta_0 : [ 0.00838589 -0.11337757  0.08823537  0.01456044  0.05989475 -0.19397623\n",
      "  0.27773519  0.01116189 -0.30917425  0.27512827 -0.20036815 -0.24573777\n",
      "  0.07843358 -0.43620375]\n",
      "Training Error:  9.829395299620913\n",
      "====================================================================================================\n",
      "Iteration:  517\n",
      "Previous theta :  [ 0.00838589 -0.11337757  0.08823537  0.01456044  0.05989475 -0.19397623\n",
      "  0.27773519  0.01116189 -0.30917425  0.27512827 -0.20036815 -0.24573777\n",
      "  0.07843358 -0.43620375]\n",
      "New theta_0 : [ 0.00839209 -0.11344643  0.08836197  0.01451785  0.05992446 -0.19432236\n",
      "  0.27762439  0.01118577 -0.30953209  0.27527289 -0.20036899 -0.24578254\n",
      "  0.07841089 -0.43621421]\n",
      "Training Error:  9.829087725740791\n",
      "====================================================================================================\n",
      "Iteration:  518\n",
      "Previous theta :  [ 0.00839209 -0.11344643  0.08836197  0.01451785  0.05992446 -0.19432236\n",
      "  0.27762439  0.01118577 -0.30953209  0.27527289 -0.20036899 -0.24578254\n",
      "  0.07841089 -0.43621421]\n",
      "New theta_0 : [ 0.00839827 -0.11351491  0.08848785  0.01447576  0.05995401 -0.19466658\n",
      "  0.27751444  0.01120955 -0.30988767  0.27541678 -0.20037001 -0.24582703\n",
      "  0.07838835 -0.43622437]\n",
      "Training Error:  9.82878379871385\n",
      "====================================================================================================\n",
      "Iteration:  519\n",
      "Previous theta :  [ 0.00839827 -0.11351491  0.08848785  0.01447576  0.05995401 -0.19466658\n",
      "  0.27751444  0.01120955 -0.30988767  0.27541678 -0.20037001 -0.24582703\n",
      "  0.07838835 -0.43622437]\n",
      "New theta_0 : [ 0.00840442 -0.11358302  0.08861302  0.01443416  0.05998339 -0.1950089\n",
      "  0.27740534  0.01123324 -0.31024102  0.27555992 -0.20037121 -0.24587123\n",
      "  0.07836598 -0.43623424]\n",
      "Training Error:  9.828483474490845\n",
      "====================================================================================================\n",
      "Iteration:  520\n",
      "Previous theta :  [ 0.00840442 -0.11358302  0.08861302  0.01443416  0.05998339 -0.1950089\n",
      "  0.27740534  0.01123324 -0.31024102  0.27555992 -0.20037121 -0.24587123\n",
      "  0.07836598 -0.43623424]\n",
      "New theta_0 : [ 0.00841055 -0.11365076  0.08873748  0.01439306  0.0600126  -0.19534933\n",
      "  0.27729706  0.01125684 -0.31059213  0.27570234 -0.2003726  -0.24591515\n",
      "  0.07834375 -0.43624382]\n",
      "Training Error:  9.828186709565692\n",
      "====================================================================================================\n",
      "Iteration:  521\n",
      "Previous theta :  [ 0.00841055 -0.11365076  0.08873748  0.01439306  0.0600126  -0.19534933\n",
      "  0.27729706  0.01125684 -0.31059213  0.27570234 -0.2003726  -0.24591515\n",
      "  0.07834375 -0.43624382]\n",
      "New theta_0 : [ 0.00841666 -0.11371813  0.08886123  0.01435245  0.06004164 -0.19568787\n",
      "  0.27718961  0.01128035 -0.31094104  0.27584402 -0.20037416 -0.24595879\n",
      "  0.07832169 -0.43625311]\n",
      "Training Error:  9.82789346096856\n",
      "====================================================================================================\n",
      "Iteration:  522\n",
      "Previous theta :  [ 0.00841666 -0.11371813  0.08886123  0.01435245  0.06004164 -0.19568787\n",
      "  0.27718961  0.01128035 -0.31094104  0.27584402 -0.20037416 -0.24595879\n",
      "  0.07832169 -0.43625311]\n",
      "New theta_0 : [ 0.00842274 -0.11378513  0.08898428  0.01431231  0.06007053 -0.19602454\n",
      "  0.27708298  0.01130375 -0.31128775  0.27598499 -0.20037591 -0.24600215\n",
      "  0.07829978 -0.43626213]\n",
      "Training Error:  9.827603686259062\n",
      "====================================================================================================\n",
      "Iteration:  523\n",
      "Previous theta :  [ 0.00842274 -0.11378513  0.08898428  0.01431231  0.06007053 -0.19602454\n",
      "  0.27708298  0.01130375 -0.31128775  0.27598499 -0.20037591 -0.24600215\n",
      "  0.07829978 -0.43626213]\n",
      "New theta_0 : [ 0.0084288  -0.11385177  0.08910663  0.01427266  0.06009925 -0.19635934\n",
      "  0.27697717  0.01132707 -0.31163228  0.27612524 -0.20037783 -0.24604523\n",
      "  0.07827802 -0.43627087]\n",
      "Training Error:  9.827317343519532\n",
      "====================================================================================================\n",
      "Iteration:  524\n",
      "Previous theta :  [ 0.0084288  -0.11385177  0.08910663  0.01427266  0.06009925 -0.19635934\n",
      "  0.27697717  0.01132707 -0.31163228  0.27612524 -0.20037783 -0.24604523\n",
      "  0.07827802 -0.43627087]\n",
      "New theta_0 : [ 0.00843483 -0.11391804  0.08922828  0.01423348  0.0601278  -0.1966923\n",
      "  0.27687216  0.01135029 -0.31197464  0.27626477 -0.20037993 -0.24608804\n",
      "  0.07825642 -0.43627934]\n",
      "Training Error:  9.827034391348375\n",
      "====================================================================================================\n",
      "Iteration:  525\n",
      "Previous theta :  [ 0.00843483 -0.11391804  0.08922828  0.01423348  0.0601278  -0.1966923\n",
      "  0.27687216  0.01135029 -0.31197464  0.27626477 -0.20037993 -0.24608804\n",
      "  0.07825642 -0.43627934]\n",
      "New theta_0 : [ 0.00844084 -0.11398395  0.08934923  0.01419477  0.0601562  -0.19702341\n",
      "  0.27676794  0.01137341 -0.31231484  0.27640359 -0.2003822  -0.24613059\n",
      "  0.07823496 -0.43628754]\n",
      "Training Error:  9.826754788853552\n",
      "====================================================================================================\n",
      "Iteration:  526\n",
      "Previous theta :  [ 0.00844084 -0.11398395  0.08934923  0.01419477  0.0601562  -0.19702341\n",
      "  0.27676794  0.01137341 -0.31231484  0.27640359 -0.2003822  -0.24613059\n",
      "  0.07823496 -0.43628754]\n",
      "New theta_0 : [ 0.00844683 -0.1140495   0.0894695   0.01415652  0.06018443 -0.19735269\n",
      "  0.27666452  0.01139644 -0.3126529   0.27654171 -0.20038464 -0.24617286\n",
      "  0.07821366 -0.43629548]\n",
      "Training Error:  9.826478495646096\n",
      "====================================================================================================\n",
      "Iteration:  527\n",
      "Previous theta :  [ 0.00844683 -0.1140495   0.0894695   0.01415652  0.06018443 -0.19735269\n",
      "  0.27666452  0.01139644 -0.3126529   0.27654171 -0.20038464 -0.24617286\n",
      "  0.07821366 -0.43629548]\n",
      "New theta_0 : [ 0.00845279 -0.11411469  0.08958908  0.01411874  0.06021251 -0.19768014\n",
      "  0.27656189  0.01141938 -0.31298884  0.27667913 -0.20038725 -0.24621487\n",
      "  0.0781925  -0.43630315]\n",
      "Training Error:  9.826205471833761\n",
      "====================================================================================================\n",
      "Iteration:  528\n",
      "Previous theta :  [ 0.00845279 -0.11411469  0.08958908  0.01411874  0.06021251 -0.19768014\n",
      "  0.27656189  0.01141938 -0.31298884  0.27667913 -0.20038725 -0.24621487\n",
      "  0.0781925  -0.43630315]\n",
      "New theta_0 : [ 0.00845873 -0.11417953  0.08970798  0.01408141  0.06024042 -0.19800579\n",
      "  0.27646003  0.01144221 -0.31332266  0.27681586 -0.20039004 -0.24625661\n",
      "  0.07817149 -0.43631057]\n",
      "Training Error:  9.82593567801471\n",
      "====================================================================================================\n",
      "Iteration:  529\n",
      "Previous theta :  [ 0.00845873 -0.11417953  0.08970798  0.01408141  0.06024042 -0.19800579\n",
      "  0.27646003  0.01144221 -0.31332266  0.27681586 -0.20039004 -0.24625661\n",
      "  0.07817149 -0.43631057]\n",
      "New theta_0 : [ 0.00846465 -0.114244    0.08982619  0.01404453  0.06026818 -0.19832963\n",
      "  0.27635895  0.01146495 -0.31365438  0.27695189 -0.20039299 -0.24629809\n",
      "  0.07815063 -0.43631774]\n",
      "Training Error:  9.825669075271335\n",
      "====================================================================================================\n",
      "Iteration:  530\n",
      "Previous theta :  [ 0.00846465 -0.114244    0.08982619  0.01404453  0.06026818 -0.19832963\n",
      "  0.27635895  0.01146495 -0.31365438  0.27695189 -0.20039299 -0.24629809\n",
      "  0.07815063 -0.43631774]\n",
      "New theta_0 : [ 0.00847054 -0.11430813  0.08994373  0.0140081   0.06029578 -0.19865167\n",
      "  0.27625863  0.0114876  -0.31398401  0.27708724 -0.2003961  -0.24633932\n",
      "  0.07812992 -0.43632466]\n",
      "Training Error:  9.825405625164128\n",
      "====================================================================================================\n",
      "Iteration:  531\n",
      "Previous theta :  [ 0.00847054 -0.11430813  0.08994373  0.0140081   0.06029578 -0.19865167\n",
      "  0.27625863  0.0114876  -0.31398401  0.27708724 -0.2003961  -0.24633932\n",
      "  0.07812992 -0.43632466]\n",
      "New theta_0 : [ 0.00847641 -0.1143719   0.0900606   0.01397212  0.06032322 -0.19897193\n",
      "  0.27615907  0.01151015 -0.31431157  0.2772219  -0.20039939 -0.24638028\n",
      "  0.07810934 -0.43633133]\n",
      "Training Error:  9.825145289725635\n",
      "====================================================================================================\n",
      "Iteration:  532\n",
      "Previous theta :  [ 0.00847641 -0.1143719   0.0900606   0.01397212  0.06032322 -0.19897193\n",
      "  0.27615907  0.01151015 -0.31431157  0.2772219  -0.20039939 -0.24638028\n",
      "  0.07810934 -0.43633133]\n",
      "New theta_0 : [ 0.00848225 -0.11443533  0.09017679  0.01393657  0.0603505  -0.19929042\n",
      "  0.27606027  0.0115326  -0.31463707  0.27735589 -0.20040283 -0.24642099\n",
      "  0.07808892 -0.43633777]\n",
      "Training Error:  9.824888031454494\n",
      "====================================================================================================\n",
      "Iteration:  533\n",
      "Previous theta :  [ 0.00848225 -0.11443533  0.09017679  0.01393657  0.0603505  -0.19929042\n",
      "  0.27606027  0.0115326  -0.31463707  0.27735589 -0.20040283 -0.24642099\n",
      "  0.07808892 -0.43633777]\n",
      "New theta_0 : [ 0.00848807 -0.1144984   0.09029232  0.01390147  0.06037763 -0.19960714\n",
      "  0.27596221  0.01155495 -0.31496052  0.2774892  -0.20040644 -0.24646145\n",
      "  0.07806863 -0.43634396]\n",
      "Training Error:  9.824633813309568\n",
      "====================================================================================================\n",
      "Iteration:  534\n",
      "Previous theta :  [ 0.00848807 -0.1144984   0.09029232  0.01390147  0.06037763 -0.19960714\n",
      "  0.27596221  0.01155495 -0.31496052  0.2774892  -0.20040644 -0.24646145\n",
      "  0.07806863 -0.43634396]\n",
      "New theta_0 : [ 0.00849387 -0.11456113  0.09040718  0.01386679  0.06040461 -0.19992211\n",
      "  0.27586489  0.01157721 -0.31528194  0.27762185 -0.2004102  -0.24650166\n",
      "  0.07804849 -0.43634992]\n",
      "Training Error:  9.824382598704126\n",
      "====================================================================================================\n",
      "Iteration:  535\n",
      "Previous theta :  [ 0.00849387 -0.11456113  0.09040718  0.01386679  0.06040461 -0.19992211\n",
      "  0.27586489  0.01157721 -0.31528194  0.27762185 -0.2004102  -0.24650166\n",
      "  0.07804849 -0.43634992]\n",
      "New theta_0 : [ 0.00849964 -0.11462352  0.09052139  0.01383254  0.06043143 -0.20023533\n",
      "  0.27576831  0.01159937 -0.31560133  0.27775382 -0.20041413 -0.24654162\n",
      "  0.07802848 -0.43635565]\n",
      "Training Error:  9.824134351500119\n",
      "====================================================================================================\n",
      "Iteration:  536\n",
      "Previous theta :  [ 0.00849964 -0.11462352  0.09052139  0.01383254  0.06043143 -0.20023533\n",
      "  0.27576831  0.01159937 -0.31560133  0.27775382 -0.20041413 -0.24654162\n",
      "  0.07802848 -0.43635565]\n",
      "New theta_0 : [ 0.00850539 -0.11468556  0.09063493  0.01379871  0.0604581  -0.20054682\n",
      "  0.27567245  0.01162144 -0.31591872  0.27788514 -0.20041821 -0.24658133\n",
      "  0.07800862 -0.43636115]\n",
      "Training Error:  9.823889036002534\n",
      "====================================================================================================\n",
      "Iteration:  537\n",
      "Previous theta :  [ 0.00850539 -0.11468556  0.09063493  0.01379871  0.0604581  -0.20054682\n",
      "  0.27567245  0.01162144 -0.31591872  0.27788514 -0.20041821 -0.24658133\n",
      "  0.07800862 -0.43636115]\n",
      "New theta_0 : [ 0.00851112 -0.11474727  0.09074782  0.0137653   0.06048461 -0.20085658\n",
      "  0.27557732  0.0116434  -0.31623411  0.2780158  -0.20042245 -0.2466208\n",
      "  0.07798889 -0.43636643]\n",
      "Training Error:  9.823646616953807\n",
      "====================================================================================================\n",
      "Iteration:  538\n",
      "Previous theta :  [ 0.00851112 -0.11474727  0.09074782  0.0137653   0.06048461 -0.20085658\n",
      "  0.27557732  0.0116434  -0.31623411  0.2780158  -0.20042245 -0.2466208\n",
      "  0.07798889 -0.43636643]\n",
      "New theta_0 : [ 0.00851682 -0.11480863  0.09086007  0.01373231  0.06051098 -0.20116462\n",
      "  0.2754829   0.01166527 -0.31654752  0.27814581 -0.20042685 -0.24666002\n",
      "  0.0779693  -0.43637149]\n",
      "Training Error:  9.823407059528323\n",
      "====================================================================================================\n",
      "Iteration:  539\n",
      "Previous theta :  [ 0.00851682 -0.11480863  0.09086007  0.01373231  0.06051098 -0.20116462\n",
      "  0.2754829   0.01166527 -0.31654752  0.27814581 -0.20042685 -0.24666002\n",
      "  0.0779693  -0.43637149]\n",
      "New theta_0 : [ 0.0085225  -0.11486966  0.09097166  0.01369973  0.06053719 -0.20147095\n",
      "  0.2753892   0.01168705 -0.31685896  0.27827517 -0.20043139 -0.24669901\n",
      "  0.07794985 -0.43637633]\n",
      "Training Error:  9.82317032932699\n",
      "====================================================================================================\n",
      "Iteration:  540\n",
      "Previous theta :  [ 0.0085225  -0.11486966  0.09097166  0.01369973  0.06053719 -0.20147095\n",
      "  0.2753892   0.01168705 -0.31685896  0.27827517 -0.20043139 -0.24669901\n",
      "  0.07794985 -0.43637633]\n",
      "New theta_0 : [ 0.00852816 -0.11493035  0.09108261  0.01366756  0.06056325 -0.20177558\n",
      "  0.27529619  0.01170872 -0.31716845  0.27840388 -0.20043609 -0.24673776\n",
      "  0.07793053 -0.43638096]\n",
      "Training Error:  9.822936392371862\n",
      "====================================================================================================\n",
      "Iteration:  541\n",
      "Previous theta :  [ 0.00852816 -0.11493035  0.09108261  0.01366756  0.06056325 -0.20177558\n",
      "  0.27529619  0.01170872 -0.31716845  0.27840388 -0.20043609 -0.24673776\n",
      "  0.07793053 -0.43638096]\n",
      "New theta_0 : [ 0.00853379 -0.1149907   0.09119292  0.01363579  0.06058917 -0.20207853\n",
      "  0.27520389  0.0117303  -0.31747598  0.27853195 -0.20044094 -0.24677627\n",
      "  0.07791134 -0.43638537]\n",
      "Training Error:  9.82270521510087\n",
      "====================================================================================================\n",
      "Iteration:  542\n",
      "Previous theta :  [ 0.00853379 -0.1149907   0.09119292  0.01363579  0.06058917 -0.20207853\n",
      "  0.27520389  0.0117303  -0.31747598  0.27853195 -0.20044094 -0.24677627\n",
      "  0.07791134 -0.43638537]\n",
      "New theta_0 : [ 0.0085394  -0.11505073  0.09130259  0.01360442  0.06061493 -0.20237979\n",
      "  0.27511228  0.01175178 -0.31778159  0.27865939 -0.20044594 -0.24681455\n",
      "  0.07789229 -0.43638958]\n",
      "Training Error:  9.822476764362573\n",
      "====================================================================================================\n",
      "Iteration:  543\n",
      "Previous theta :  [ 0.0085394  -0.11505073  0.09130259  0.01360442  0.06061493 -0.20237979\n",
      "  0.27511228  0.01175178 -0.31778159  0.27865939 -0.20044594 -0.24681455\n",
      "  0.07789229 -0.43638958]\n",
      "New theta_0 : [ 0.00854498 -0.11511042  0.09141162  0.01357345  0.06064055 -0.20267938\n",
      "  0.27502136  0.01177316 -0.31808527  0.27878619 -0.20045109 -0.24685259\n",
      "  0.07787338 -0.43639358]\n",
      "Training Error:  9.822251007411035\n",
      "====================================================================================================\n",
      "Iteration:  544\n",
      "Previous theta :  [ 0.00854498 -0.11511042  0.09141162  0.01357345  0.06064055 -0.20267938\n",
      "  0.27502136  0.01177316 -0.31808527  0.27878619 -0.20045109 -0.24685259\n",
      "  0.07787338 -0.43639358]\n",
      "New theta_0 : [ 0.00855054 -0.11516979  0.09152003  0.01354287  0.06066602 -0.20297731\n",
      "  0.27493112  0.01179444 -0.31838705  0.27891237 -0.20045638 -0.2468904\n",
      "  0.07785459 -0.43639739]\n",
      "Training Error:  9.822027911900722\n",
      "====================================================================================================\n",
      "Iteration:  545\n",
      "Previous theta :  [ 0.00855054 -0.11516979  0.09152003  0.01354287  0.06066602 -0.20297731\n",
      "  0.27493112  0.01179444 -0.31838705  0.27891237 -0.20045638 -0.2468904\n",
      "  0.07785459 -0.43639739]\n",
      "New theta_0 : [ 0.00855608 -0.11522883  0.09162781  0.01351268  0.06069134 -0.20327358\n",
      "  0.27484155  0.01181563 -0.31868693  0.27903792 -0.20046182 -0.24692799\n",
      "  0.07783593 -0.43640099]\n",
      "Training Error:  9.821807445881475\n",
      "====================================================================================================\n",
      "Iteration:  546\n",
      "Previous theta :  [ 0.00855608 -0.11522883  0.09162781  0.01351268  0.06069134 -0.20327358\n",
      "  0.27484155  0.01181563 -0.31868693  0.27903792 -0.20046182 -0.24692799\n",
      "  0.07783593 -0.43640099]\n",
      "New theta_0 : [ 0.0085616  -0.11528754  0.09173496  0.01348287  0.06071652 -0.20356821\n",
      "  0.27475265  0.01183672 -0.31898492  0.27916285 -0.2004674  -0.24696535\n",
      "  0.0778174  -0.4364044 ]\n",
      "Training Error:  9.821589577793583\n",
      "====================================================================================================\n",
      "Iteration:  547\n",
      "Previous theta :  [ 0.0085616  -0.11528754  0.09173496  0.01348287  0.06071652 -0.20356821\n",
      "  0.27475265  0.01183672 -0.31898492  0.27916285 -0.2004674  -0.24696535\n",
      "  0.0778174  -0.4364044 ]\n",
      "New theta_0 : [ 0.00856709 -0.11534593  0.09184149  0.01345345  0.06074155 -0.20386121\n",
      "  0.27466442  0.01185771 -0.31928105  0.27928716 -0.20047313 -0.24700248\n",
      "  0.07779901 -0.43640761]\n",
      "Training Error:  9.821374276462864\n",
      "====================================================================================================\n",
      "Iteration:  548\n",
      "Previous theta :  [ 0.00856709 -0.11534593  0.09184149  0.01345345  0.06074155 -0.20386121\n",
      "  0.27466442  0.01185771 -0.31928105  0.27928716 -0.20047313 -0.24700248\n",
      "  0.07779901 -0.43640761]\n",
      "New theta_0 : [ 0.00857256 -0.115404    0.0919474   0.0134244   0.06076644 -0.20415257\n",
      "  0.27457685  0.0118786  -0.31957531  0.27941086 -0.20047899 -0.24703939\n",
      "  0.07778074 -0.43641064]\n",
      "Training Error:  9.821161511095864\n",
      "====================================================================================================\n",
      "Iteration:  549\n",
      "Previous theta :  [ 0.00857256 -0.115404    0.0919474   0.0134244   0.06076644 -0.20415257\n",
      "  0.27457685  0.0118786  -0.31957531  0.27941086 -0.20047899 -0.24703939\n",
      "  0.07778074 -0.43641064]\n",
      "New theta_0 : [ 0.00857801 -0.11546174  0.09205269  0.01339573  0.06079118 -0.20444232\n",
      "  0.27448993  0.0118994  -0.31986773  0.27953395 -0.200485   -0.24707608\n",
      "  0.07776259 -0.43641348]\n",
      "Training Error:  9.820951251275071\n",
      "====================================================================================================\n",
      "Iteration:  550\n",
      "Previous theta :  [ 0.00857801 -0.11546174  0.09205269  0.01339573  0.06079118 -0.20444232\n",
      "  0.27448993  0.0118994  -0.31986773  0.27953395 -0.200485   -0.24707608\n",
      "  0.07776259 -0.43641348]\n",
      "New theta_0 : [ 0.00858343 -0.11551917  0.09215738  0.01336743  0.06081578 -0.20473046\n",
      "  0.27440366  0.0119201  -0.32015831  0.27965643 -0.20049114 -0.24711255\n",
      "  0.07774457 -0.43641614]\n",
      "Training Error:  9.82074346695424\n",
      "====================================================================================================\n",
      "Iteration:  551\n",
      "Previous theta :  [ 0.00858343 -0.11551917  0.09215738  0.01336743  0.06081578 -0.20473046\n",
      "  0.27440366  0.0119201  -0.32015831  0.27965643 -0.20049114 -0.24711255\n",
      "  0.07774457 -0.43641614]\n",
      "New theta_0 : [ 0.00858883 -0.11557628  0.09226145  0.0133395   0.06084024 -0.205017\n",
      "  0.27431803  0.0119407  -0.32044706  0.27977831 -0.20049742 -0.2471488\n",
      "  0.07772668 -0.43641862]\n",
      "Training Error:  9.820538128453732\n",
      "====================================================================================================\n",
      "Iteration:  552\n",
      "Previous theta :  [ 0.00858883 -0.11557628  0.09226145  0.0133395   0.06084024 -0.205017\n",
      "  0.27431803  0.0119407  -0.32044706  0.27977831 -0.20049742 -0.2471488\n",
      "  0.07772668 -0.43641862]\n",
      "New theta_0 : [ 0.00859421 -0.11563308  0.09236492  0.01331193  0.06086456 -0.20530195\n",
      "  0.27423304  0.0119612  -0.320734    0.2798996  -0.20050384 -0.24718483\n",
      "  0.07770891 -0.43642092]\n",
      "Training Error:  9.820335206455939\n",
      "====================================================================================================\n",
      "Iteration:  553\n",
      "Previous theta :  [ 0.00859421 -0.11563308  0.09236492  0.01331193  0.06086456 -0.20530195\n",
      "  0.27423304  0.0119612  -0.320734    0.2798996  -0.20050384 -0.24718483\n",
      "  0.07770891 -0.43642092]\n",
      "New theta_0 : [ 0.00859956 -0.11568956  0.09246778  0.01328472  0.06088874 -0.20558531\n",
      "  0.27414869  0.01198161 -0.32101915  0.28002028 -0.20051039 -0.24722065\n",
      "  0.07769126 -0.43642304]\n",
      "Training Error:  9.820134672000776\n",
      "====================================================================================================\n",
      "Iteration:  554\n",
      "Previous theta :  [ 0.00859956 -0.11568956  0.09246778  0.01328472  0.06088874 -0.20558531\n",
      "  0.27414869  0.01198161 -0.32101915  0.28002028 -0.20051039 -0.24722065\n",
      "  0.07769126 -0.43642304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00860489 -0.11574574  0.09257005  0.01325787  0.06091278 -0.2058671\n",
      "  0.27406496  0.01200192 -0.3213025   0.28014038 -0.20051708 -0.24725626\n",
      "  0.07767374 -0.43642499]\n",
      "Training Error:  9.819936496481207\n",
      "====================================================================================================\n",
      "Iteration:  555\n",
      "Previous theta :  [ 0.00860489 -0.11574574  0.09257005  0.01325787  0.06091278 -0.2058671\n",
      "  0.27406496  0.01200192 -0.3213025   0.28014038 -0.20051708 -0.24725626\n",
      "  0.07767374 -0.43642499]\n",
      "New theta_0 : [ 0.0086102  -0.1158016   0.09267172  0.01323137  0.06093668 -0.20614733\n",
      "  0.27398185  0.01202213 -0.32158407  0.28025989 -0.2005239  -0.24729166\n",
      "  0.07765634 -0.43642677]\n",
      "Training Error:  9.819740651638837\n",
      "====================================================================================================\n",
      "Iteration:  556\n",
      "Previous theta :  [ 0.0086102  -0.1158016   0.09267172  0.01323137  0.06093668 -0.20614733\n",
      "  0.27398185  0.01202213 -0.32158407  0.28025989 -0.2005239  -0.24729166\n",
      "  0.07765634 -0.43642677]\n",
      "New theta_0 : [ 0.00861548 -0.11585715  0.09277279  0.01320523  0.06096044 -0.20642599\n",
      "  0.27389936  0.01204225 -0.32186387  0.28037882 -0.20053085 -0.24732685\n",
      "  0.07763906 -0.43642839]\n",
      "Training Error:  9.819547109559585\n",
      "====================================================================================================\n",
      "Iteration:  557\n",
      "Previous theta :  [ 0.00861548 -0.11585715  0.09277279  0.01320523  0.06096044 -0.20642599\n",
      "  0.27389936  0.01204225 -0.32186387  0.28037882 -0.20053085 -0.24732685\n",
      "  0.07763906 -0.43642839]\n",
      "New theta_0 : [ 0.00862075 -0.11591239  0.09287328  0.01317943  0.06098406 -0.20670311\n",
      "  0.27381748  0.01206227 -0.32214192  0.28049716 -0.20053792 -0.24736183\n",
      "  0.07762189 -0.43642984]\n",
      "Training Error:  9.819355842669369\n",
      "====================================================================================================\n",
      "Iteration:  558\n",
      "Previous theta :  [ 0.00862075 -0.11591239  0.09287328  0.01317943  0.06098406 -0.20670311\n",
      "  0.27381748  0.01206227 -0.32214192  0.28049716 -0.20053792 -0.24736183\n",
      "  0.07762189 -0.43642984]\n",
      "New theta_0 : [ 0.00862598 -0.11596733  0.09297318  0.01315397  0.06100754 -0.20697868\n",
      "  0.27373621  0.01208219 -0.32241822  0.28061493 -0.20054513 -0.2473966\n",
      "  0.07760485 -0.43643113]\n",
      "Training Error:  9.819166823729894\n",
      "====================================================================================================\n",
      "Iteration:  559\n",
      "Previous theta :  [ 0.00862598 -0.11596733  0.09297318  0.01315397  0.06100754 -0.20697868\n",
      "  0.27373621  0.01208219 -0.32241822  0.28061493 -0.20054513 -0.2473966\n",
      "  0.07760485 -0.43643113]\n",
      "New theta_0 : [ 0.0086312  -0.11602197  0.09307249  0.01312886  0.06103089 -0.20725273\n",
      "  0.27365554  0.01210202 -0.32269279  0.28073213 -0.20055247 -0.24743117\n",
      "  0.07758793 -0.43643225]\n",
      "Training Error:  9.818980025834456\n",
      "====================================================================================================\n",
      "Iteration:  560\n",
      "Previous theta :  [ 0.0086312  -0.11602197  0.09307249  0.01312886  0.06103089 -0.20725273\n",
      "  0.27365554  0.01210202 -0.32269279  0.28073213 -0.20055247 -0.24743117\n",
      "  0.07758793 -0.43643225]\n",
      "New theta_0 : [ 0.0086364  -0.1160763   0.09317122  0.01310408  0.0610541  -0.20752525\n",
      "  0.27357547  0.01212175 -0.32296564  0.28084876 -0.20055993 -0.24746554\n",
      "  0.07757112 -0.43643323]\n",
      "Training Error:  9.818795422403811\n",
      "====================================================================================================\n",
      "Iteration:  561\n",
      "Previous theta :  [ 0.0086364  -0.1160763   0.09317122  0.01310408  0.0610541  -0.20752525\n",
      "  0.27357547  0.01212175 -0.32296564  0.28084876 -0.20055993 -0.24746554\n",
      "  0.07757112 -0.43643323]\n",
      "New theta_0 : [ 0.00864157 -0.11613034  0.09326937  0.01307963  0.06107718 -0.20779625\n",
      "  0.27349599  0.01214138 -0.32323677  0.28096482 -0.20056751 -0.2474997\n",
      "  0.07755443 -0.43643405]\n",
      "Training Error:  9.818612987182126\n",
      "====================================================================================================\n",
      "Iteration:  562\n",
      "Previous theta :  [ 0.00864157 -0.11613034  0.09326937  0.01307963  0.06107718 -0.20779625\n",
      "  0.27349599  0.01214138 -0.32323677  0.28096482 -0.20056751 -0.2474997\n",
      "  0.07755443 -0.43643405]\n",
      "New theta_0 : [ 0.00864671 -0.11618407  0.09336695  0.01305552  0.06110012 -0.20806574\n",
      "  0.2734171   0.01216092 -0.32350621  0.28108031 -0.20057522 -0.24753367\n",
      "  0.07753785 -0.43643471]\n",
      "Training Error:  9.81843269423293\n",
      "====================================================================================================\n",
      "Iteration:  563\n",
      "Previous theta :  [ 0.00864671 -0.11618407  0.09336695  0.01305552  0.06110012 -0.20806574\n",
      "  0.2734171   0.01216092 -0.32350621  0.28108031 -0.20057522 -0.24753367\n",
      "  0.07753785 -0.43643471]\n",
      "New theta_0 : [ 0.00865184 -0.11623751  0.09346396  0.01303174  0.06112293 -0.20833374\n",
      "  0.27333879  0.01218036 -0.32377395  0.28119525 -0.20058306 -0.24756744\n",
      "  0.07752139 -0.43643523]\n",
      "Training Error:  9.81825451793516\n",
      "====================================================================================================\n",
      "Iteration:  564\n",
      "Previous theta :  [ 0.00865184 -0.11623751  0.09346396  0.01303174  0.06112293 -0.20833374\n",
      "  0.27333879  0.01218036 -0.32377395  0.28119525 -0.20058306 -0.24756744\n",
      "  0.07752139 -0.43643523]\n",
      "New theta_0 : [ 0.00865694 -0.11629065  0.0935604   0.01300828  0.06114561 -0.20860025\n",
      "  0.27326106  0.0121997  -0.32404001  0.28130964 -0.20059101 -0.24760101\n",
      "  0.07750504 -0.4364356 ]\n",
      "Training Error:  9.818078432979236\n",
      "====================================================================================================\n",
      "Iteration:  565\n",
      "Previous theta :  [ 0.00865694 -0.11629065  0.0935604   0.01300828  0.06114561 -0.20860025\n",
      "  0.27326106  0.0121997  -0.32404001  0.28130964 -0.20059101 -0.24760101\n",
      "  0.07750504 -0.4364356 ]\n",
      "New theta_0 : [ 0.00866202 -0.11634349  0.09365627  0.01298514  0.06116816 -0.20886527\n",
      "  0.2731839   0.01221895 -0.3243044   0.28142347 -0.20059909 -0.24763439\n",
      "  0.0774888  -0.43643583]\n",
      "Training Error:  9.817904414363202\n",
      "====================================================================================================\n",
      "Iteration:  566\n",
      "Previous theta :  [ 0.00866202 -0.11634349  0.09365627  0.01298514  0.06116816 -0.20886527\n",
      "  0.2731839   0.01221895 -0.3243044   0.28142347 -0.20059909 -0.24763439\n",
      "  0.0774888  -0.43643583]\n",
      "New theta_0 : [ 0.00866708 -0.11639605  0.09375157  0.01296232  0.06119057 -0.20912882\n",
      "  0.27310731  0.01223811 -0.32456714  0.28153675 -0.20060728 -0.24766757\n",
      "  0.07747268 -0.43643591]\n",
      "Training Error:  9.817732437388898\n",
      "====================================================================================================\n",
      "Iteration:  567\n",
      "Previous theta :  [ 0.00866708 -0.11639605  0.09375157  0.01296232  0.06119057 -0.20912882\n",
      "  0.27310731  0.01223811 -0.32456714  0.28153675 -0.20060728 -0.24766757\n",
      "  0.07747268 -0.43643591]\n",
      "New theta_0 : [ 0.00867212 -0.11644831  0.09384632  0.01293981  0.06121285 -0.2093909\n",
      "  0.27303128  0.01225717 -0.32482823  0.28164948 -0.20061559 -0.24770056\n",
      "  0.07745667 -0.43643586]\n",
      "Training Error:  9.817562477658194\n",
      "====================================================================================================\n",
      "Iteration:  568\n",
      "Previous theta :  [ 0.00867212 -0.11644831  0.09384632  0.01293981  0.06121285 -0.2093909\n",
      "  0.27303128  0.01225717 -0.32482823  0.28164948 -0.20061559 -0.24770056\n",
      "  0.07745667 -0.43643586]\n",
      "New theta_0 : [ 0.00867713 -0.11650028  0.09394051  0.01291762  0.061235   -0.20965152\n",
      "  0.27295582  0.01227613 -0.32508768  0.28176168 -0.20062402 -0.24773336\n",
      "  0.07744077 -0.43643566]\n",
      "Training Error:  9.81739451106928\n",
      "====================================================================================================\n",
      "Iteration:  569\n",
      "Previous theta :  [ 0.00867713 -0.11650028  0.09394051  0.01291762  0.061235   -0.20965152\n",
      "  0.27295582  0.01227613 -0.32508768  0.28176168 -0.20062402 -0.24773336\n",
      "  0.07744077 -0.43643566]\n",
      "New theta_0 : [ 0.00868212 -0.11655197  0.09403415  0.01289574  0.06125703 -0.20991069\n",
      "  0.27288091  0.012295   -0.3253455   0.28187333 -0.20063257 -0.24776597\n",
      "  0.07742498 -0.43643533]\n",
      "Training Error:  9.817228513812962\n",
      "====================================================================================================\n",
      "Iteration:  570\n",
      "Previous theta :  [ 0.00868212 -0.11655197  0.09403415  0.01289574  0.06125703 -0.20991069\n",
      "  0.27288091  0.012295   -0.3253455   0.28187333 -0.20063257 -0.24776597\n",
      "  0.07742498 -0.43643533]\n",
      "New theta_0 : [ 0.00868709 -0.11660337  0.09412724  0.01287416  0.06127892 -0.21016842\n",
      "  0.27280655  0.01231378 -0.32560171  0.28198445 -0.20064123 -0.24779839\n",
      "  0.0774093  -0.43643487]\n",
      "Training Error:  9.817064462369071\n",
      "====================================================================================================\n",
      "Iteration:  571\n",
      "Previous theta :  [ 0.00868709 -0.11660337  0.09412724  0.01287416  0.06127892 -0.21016842\n",
      "  0.27280655  0.01231378 -0.32560171  0.28198445 -0.20064123 -0.24779839\n",
      "  0.0774093  -0.43643487]\n",
      "New theta_0 : [ 0.00869204 -0.11665448  0.09421977  0.01285289  0.06130069 -0.21042471\n",
      "  0.27273273  0.01233246 -0.32585631  0.28209503 -0.20065    -0.24783063\n",
      "  0.07739372 -0.43643428]\n",
      "Training Error:  9.816902333502865\n",
      "====================================================================================================\n",
      "Iteration:  572\n",
      "Previous theta :  [ 0.00869204 -0.11665448  0.09421977  0.01285289  0.06130069 -0.21042471\n",
      "  0.27273273  0.01233246 -0.32585631  0.28209503 -0.20065    -0.24783063\n",
      "  0.07739372 -0.43643428]\n",
      "New theta_0 : [ 0.00869697 -0.11670531  0.09431176  0.01283192  0.06132232 -0.21067957\n",
      "  0.27265946  0.01235105 -0.32610931  0.28220509 -0.20065889 -0.24786268\n",
      "  0.07737826 -0.43643356]\n",
      "Training Error:  9.816742104261493\n",
      "====================================================================================================\n",
      "Iteration:  573\n",
      "Previous theta :  [ 0.00869697 -0.11670531  0.09431176  0.01283192  0.06132232 -0.21067957\n",
      "  0.27265946  0.01235105 -0.32610931  0.28220509 -0.20065889 -0.24786268\n",
      "  0.07737826 -0.43643356]\n",
      "New theta_0 : [ 0.00870187 -0.11675586  0.09440321  0.01281124  0.06134384 -0.21093302\n",
      "  0.27258673  0.01236954 -0.32636073  0.28231462 -0.20066788 -0.24789455\n",
      "  0.0773629  -0.43643271]\n",
      "Training Error:  9.816583751970516\n",
      "====================================================================================================\n",
      "Iteration:  574\n",
      "Previous theta :  [ 0.00870187 -0.11675586  0.09440321  0.01281124  0.06134384 -0.21093302\n",
      "  0.27258673  0.01236954 -0.32636073  0.28231462 -0.20066788 -0.24789455\n",
      "  0.0773629  -0.43643271]\n",
      "New theta_0 : [ 0.00870675 -0.11680613  0.09449412  0.01279086  0.06136522 -0.21118505\n",
      "  0.27251452  0.01238794 -0.32661057  0.28242362 -0.20067699 -0.24792624\n",
      "  0.07734765 -0.43643174]\n",
      "Training Error:  9.816427254230451\n",
      "====================================================================================================\n",
      "Iteration:  575\n",
      "Previous theta :  [ 0.00870675 -0.11680613  0.09449412  0.01279086  0.06136522 -0.21118505\n",
      "  0.27251452  0.01238794 -0.32661057  0.28242362 -0.20067699 -0.24792624\n",
      "  0.07734765 -0.43643174]\n",
      "New theta_0 : [ 0.00871161 -0.11685612  0.0945845   0.01277078  0.06138648 -0.21143568\n",
      "  0.27244285  0.01240624 -0.32685884  0.28253211 -0.20068621 -0.24795774\n",
      "  0.0773325  -0.43643064]\n",
      "Training Error:  9.816272588913385\n",
      "====================================================================================================\n",
      "Iteration:  576\n",
      "Previous theta :  [ 0.00871161 -0.11685612  0.0945845   0.01277078  0.06138648 -0.21143568\n",
      "  0.27244285  0.01240624 -0.32685884  0.28253211 -0.20068621 -0.24795774\n",
      "  0.0773325  -0.43643064]\n",
      "New theta_0 : [ 0.00871645 -0.11690583  0.09467434  0.01275098  0.06140762 -0.21168491\n",
      "  0.2723717   0.01242446 -0.32710556  0.28264008 -0.20069553 -0.24798907\n",
      "  0.07731746 -0.43642943]\n",
      "Training Error:  9.8161197341596\n",
      "====================================================================================================\n",
      "Iteration:  577\n",
      "Previous theta :  [ 0.00871645 -0.11690583  0.09467434  0.01275098  0.06140762 -0.21168491\n",
      "  0.2723717   0.01242446 -0.32710556  0.28264008 -0.20069553 -0.24798907\n",
      "  0.07731746 -0.43642943]\n",
      "New theta_0 : [ 0.00872126 -0.11695526  0.09476365  0.01273147  0.06142863 -0.21193276\n",
      "  0.27230107  0.01244257 -0.32735073  0.28274753 -0.20070497 -0.24802022\n",
      "  0.07730252 -0.43642809]\n",
      "Training Error:  9.815968668374271\n",
      "====================================================================================================\n",
      "Iteration:  578\n",
      "Previous theta :  [ 0.00872126 -0.11695526  0.09476365  0.01273147  0.06142863 -0.21193276\n",
      "  0.27230107  0.01244257 -0.32735073  0.28274753 -0.20070497 -0.24802022\n",
      "  0.07730252 -0.43642809]\n",
      "New theta_0 : [ 0.00872605 -0.11700442  0.09485243  0.01271224  0.06144951 -0.21217922\n",
      "  0.27223096  0.0124606  -0.32759437  0.28285447 -0.20071451 -0.24805119\n",
      "  0.07728768 -0.43642664]\n",
      "Training Error:  9.815819370224192\n",
      "====================================================================================================\n",
      "Iteration:  579\n",
      "Previous theta :  [ 0.00872605 -0.11700442  0.09485243  0.01271224  0.06144951 -0.21217922\n",
      "  0.27223096  0.0124606  -0.32759437  0.28285447 -0.20071451 -0.24805119\n",
      "  0.07728768 -0.43642664]\n",
      "New theta_0 : [ 0.00873083 -0.11705331  0.09494069  0.01269329  0.06147028 -0.21242431\n",
      "  0.27216136  0.01247854 -0.32783647  0.28296091 -0.20072415 -0.24808199\n",
      "  0.07727295 -0.43642508]\n",
      "Training Error:  9.815671818634538\n",
      "====================================================================================================\n",
      "Iteration:  580\n",
      "Previous theta :  [ 0.00873083 -0.11705331  0.09494069  0.01269329  0.06147028 -0.21242431\n",
      "  0.27216136  0.01247854 -0.32783647  0.28296091 -0.20072415 -0.24808199\n",
      "  0.07727295 -0.43642508]\n",
      "New theta_0 : [ 0.00873558 -0.11710193  0.09502842  0.01267463  0.06149092 -0.21266803\n",
      "  0.27209227  0.01249638 -0.32807707  0.28306684 -0.2007339  -0.24811261\n",
      "  0.07725832 -0.4364234 ]\n",
      "Training Error:  9.81552599278569\n",
      "====================================================================================================\n",
      "Iteration:  581\n",
      "Previous theta :  [ 0.00873558 -0.11710193  0.09502842  0.01267463  0.06149092 -0.21266803\n",
      "  0.27209227  0.01249638 -0.32807707  0.28306684 -0.2007339  -0.24811261\n",
      "  0.07725832 -0.4364234 ]\n",
      "New theta_0 : [ 0.0087403  -0.11715027  0.09511564  0.01265623  0.06151144 -0.21291039\n",
      "  0.27202368  0.01251413 -0.32831615  0.28317227 -0.20074375 -0.24814306\n",
      "  0.07724379 -0.43642162]\n",
      "Training Error:  9.81538187211007\n",
      "====================================================================================================\n",
      "Iteration:  582\n",
      "Previous theta :  [ 0.0087403  -0.11715027  0.09511564  0.01265623  0.06151144 -0.21291039\n",
      "  0.27202368  0.01251413 -0.32831615  0.28317227 -0.20074375 -0.24814306\n",
      "  0.07724379 -0.43642162]\n",
      "New theta_0 : [ 0.00874501 -0.11719835  0.09520234  0.01263811  0.06153184 -0.21315141\n",
      "  0.27195559  0.01253179 -0.32855373  0.2832772  -0.2007537  -0.24817334\n",
      "  0.07722936 -0.43641972]\n",
      "Training Error:  9.81523943628904\n",
      "====================================================================================================\n",
      "Iteration:  583\n",
      "Previous theta :  [ 0.00874501 -0.11719835  0.09520234  0.01263811  0.06153184 -0.21315141\n",
      "  0.27195559  0.01253179 -0.32855373  0.2832772  -0.2007537  -0.24817334\n",
      "  0.07722936 -0.43641972]\n",
      "New theta_0 : [ 0.0087497  -0.11724616  0.09528852  0.01262026  0.06155212 -0.21339108\n",
      "  0.27188799  0.01254935 -0.32878983  0.28338164 -0.20076376 -0.24820344\n",
      "  0.07721503 -0.43641772]\n",
      "Training Error:  9.815098665249831\n",
      "====================================================================================================\n",
      "Iteration:  584\n",
      "Previous theta :  [ 0.0087497  -0.11724616  0.09528852  0.01262026  0.06155212 -0.21339108\n",
      "  0.27188799  0.01254935 -0.32878983  0.28338164 -0.20076376 -0.24820344\n",
      "  0.07721503 -0.43641772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00875436 -0.11729371  0.0953742   0.01260268  0.06157228 -0.21362941\n",
      "  0.27182089  0.01256683 -0.32902444  0.28348558 -0.20077391 -0.24823338\n",
      "  0.0772008  -0.43641561]\n",
      "Training Error:  9.814959539162514\n",
      "====================================================================================================\n",
      "Iteration:  585\n",
      "Previous theta :  [ 0.00875436 -0.11729371  0.0953742   0.01260268  0.06157228 -0.21362941\n",
      "  0.27182089  0.01256683 -0.32902444  0.28348558 -0.20077391 -0.24823338\n",
      "  0.0772008  -0.43641561]\n",
      "New theta_0 : [ 0.008759   -0.11734099  0.09545936  0.01258537  0.06159232 -0.21386641\n",
      "  0.27175427  0.01258422 -0.32925759  0.28358903 -0.20078417 -0.24826315\n",
      "  0.07718666 -0.4364134 ]\n",
      "Training Error:  9.814822038437008\n",
      "====================================================================================================\n",
      "Iteration:  586\n",
      "Previous theta :  [ 0.008759   -0.11734099  0.09545936  0.01258537  0.06159232 -0.21386641\n",
      "  0.27175427  0.01258422 -0.32925759  0.28358903 -0.20078417 -0.24826315\n",
      "  0.07718666 -0.4364134 ]\n",
      "New theta_0 : [ 0.00876362 -0.11738801  0.09554402  0.01256831  0.06161225 -0.21410209\n",
      "  0.27168814  0.01260151 -0.32948928  0.283692   -0.20079452 -0.24829275\n",
      "  0.07717263 -0.43641109]\n",
      "Training Error:  9.814686143720118\n",
      "====================================================================================================\n",
      "Iteration:  587\n",
      "Previous theta :  [ 0.00876362 -0.11738801  0.09554402  0.01256831  0.06161225 -0.21410209\n",
      "  0.27168814  0.01260151 -0.32948928  0.283692   -0.20079452 -0.24829275\n",
      "  0.07717263 -0.43641109]\n",
      "New theta_0 : [ 0.00876822 -0.11743476  0.09562818  0.01255152  0.06163205 -0.21433646\n",
      "  0.27162249  0.01261872 -0.32971951  0.28379448 -0.20080497 -0.24832219\n",
      "  0.07715869 -0.43640868]\n",
      "Training Error:  9.81455183589263\n",
      "====================================================================================================\n",
      "Iteration:  588\n",
      "Previous theta :  [ 0.00876822 -0.11743476  0.09562818  0.01255152  0.06163205 -0.21433646\n",
      "  0.27162249  0.01261872 -0.32971951  0.28379448 -0.20080497 -0.24832219\n",
      "  0.07715869 -0.43640868]\n",
      "New theta_0 : [ 0.0087728  -0.11748126  0.09571184  0.01253498  0.06165174 -0.21456952\n",
      "  0.27155732  0.01263583 -0.3299483   0.28389648 -0.20081551 -0.24835147\n",
      "  0.07714485 -0.43640617]\n",
      "Training Error:  9.814419096066418\n",
      "====================================================================================================\n",
      "Iteration:  589\n",
      "Previous theta :  [ 0.0087728  -0.11748126  0.09571184  0.01253498  0.06165174 -0.21456952\n",
      "  0.27155732  0.01263583 -0.3299483   0.28389648 -0.20081551 -0.24835147\n",
      "  0.07714485 -0.43640617]\n",
      "New theta_0 : [ 0.00877736 -0.1175275   0.095795    0.0125187   0.06167131 -0.21480127\n",
      "  0.27149262  0.01265286 -0.33017566  0.283998   -0.20082615 -0.24838058\n",
      "  0.0771311  -0.43640357]\n",
      "Training Error:  9.814287905581617\n",
      "====================================================================================================\n",
      "Iteration:  590\n",
      "Previous theta :  [ 0.00877736 -0.1175275   0.095795    0.0125187   0.06167131 -0.21480127\n",
      "  0.27149262  0.01265286 -0.33017566  0.283998   -0.20082615 -0.24838058\n",
      "  0.0771311  -0.43640357]\n",
      "New theta_0 : [ 0.0087819  -0.11757348  0.09587767  0.01250267  0.06169076 -0.21503174\n",
      "  0.27142838  0.01266979 -0.3304016   0.28409904 -0.20083689 -0.24840953\n",
      "  0.07711745 -0.43640087]\n",
      "Training Error:  9.8141582460038\n",
      "====================================================================================================\n",
      "Iteration:  591\n",
      "Previous theta :  [ 0.0087819  -0.11757348  0.09587767  0.01250267  0.06169076 -0.21503174\n",
      "  0.27142838  0.01266979 -0.3304016   0.28409904 -0.20083689 -0.24840953\n",
      "  0.07711745 -0.43640087]\n",
      "New theta_0 : [ 0.00878641 -0.1176192   0.09595985  0.0124869   0.0617101  -0.21526092\n",
      "  0.27136461  0.01268664 -0.33062611  0.28419962 -0.20084772 -0.24843832\n",
      "  0.07710389 -0.43639808]\n",
      "Training Error:  9.814030099121204\n",
      "====================================================================================================\n",
      "Iteration:  592\n",
      "Previous theta :  [ 0.00878641 -0.1176192   0.09595985  0.0124869   0.0617101  -0.21526092\n",
      "  0.27136461  0.01268664 -0.33062611  0.28419962 -0.20084772 -0.24843832\n",
      "  0.07710389 -0.43639808]\n",
      "New theta_0 : [ 0.00879091 -0.11766468  0.09604154  0.01247136  0.06172933 -0.21548882\n",
      "  0.27130131  0.0127034  -0.33084923  0.28429972 -0.20085864 -0.24846694\n",
      "  0.07709043 -0.4363952 ]\n",
      "Training Error:  9.813903446942014\n",
      "====================================================================================================\n",
      "Iteration:  593\n",
      "Previous theta :  [ 0.00879091 -0.11766468  0.09604154  0.01247136  0.06172933 -0.21548882\n",
      "  0.27130131  0.0127034  -0.33084923  0.28429972 -0.20085864 -0.24846694\n",
      "  0.07709043 -0.4363952 ]\n",
      "New theta_0 : [ 0.00879538 -0.11770989  0.09612274  0.01245608  0.06174844 -0.21571544\n",
      "  0.27123846  0.01272007 -0.33107094  0.28439936 -0.20086965 -0.24849542\n",
      "  0.07707705 -0.43639223]\n",
      "Training Error:  9.813778271691639\n",
      "====================================================================================================\n",
      "Iteration:  594\n",
      "Previous theta :  [ 0.00879538 -0.11770989  0.09612274  0.01245608  0.06174844 -0.21571544\n",
      "  0.27123846  0.01272007 -0.33107094  0.28439936 -0.20086965 -0.24849542\n",
      "  0.07707705 -0.43639223]\n",
      "New theta_0 : [ 0.00879983 -0.11775486  0.09620346  0.01244104  0.06176744 -0.2159408\n",
      "  0.27117606  0.01273665 -0.33129127  0.28449853 -0.20088075 -0.24852373\n",
      "  0.07706377 -0.43638917]\n",
      "Training Error:  9.813654555810048\n",
      "====================================================================================================\n",
      "Iteration:  595\n",
      "Previous theta :  [ 0.00879983 -0.11775486  0.09620346  0.01244104  0.06176744 -0.2159408\n",
      "  0.27117606  0.01273665 -0.33129127  0.28449853 -0.20088075 -0.24852373\n",
      "  0.07706377 -0.43638917]\n",
      "New theta_0 : [ 0.00880426 -0.11779958  0.0962837   0.01242623  0.06178633 -0.21616491\n",
      "  0.27111412  0.01275314 -0.33151022  0.28459723 -0.20089195 -0.24855189\n",
      "  0.07705059 -0.43638603]\n",
      "Training Error:  9.813532281949147\n",
      "====================================================================================================\n",
      "Iteration:  596\n",
      "Previous theta :  [ 0.00880426 -0.11779958  0.0962837   0.01242623  0.06178633 -0.21616491\n",
      "  0.27111412  0.01275314 -0.33151022  0.28459723 -0.20089195 -0.24855189\n",
      "  0.07705059 -0.43638603]\n",
      "New theta_0 : [ 0.00880868 -0.11784404  0.09636346  0.01241167  0.0618051  -0.21638776\n",
      "  0.27105262  0.01276955 -0.33172779  0.28469548 -0.20090323 -0.24857989\n",
      "  0.07703749 -0.4363828 ]\n",
      "Training Error:  9.813411432970156\n",
      "====================================================================================================\n",
      "Iteration:  597\n",
      "Previous theta :  [ 0.00880868 -0.11784404  0.09636346  0.01241167  0.0618051  -0.21638776\n",
      "  0.27105262  0.01276955 -0.33172779  0.28469548 -0.20090323 -0.24857989\n",
      "  0.07703749 -0.4363828 ]\n",
      "New theta_0 : [ 0.00881307 -0.11788826  0.09644274  0.01239734  0.06182376 -0.21660937\n",
      "  0.27099156  0.01278587 -0.331944    0.28479328 -0.2009146  -0.24860773\n",
      "  0.07702448 -0.43637949]\n",
      "Training Error:  9.813291991941059\n",
      "====================================================================================================\n",
      "Iteration:  598\n",
      "Previous theta :  [ 0.00881307 -0.11788826  0.09644274  0.01239734  0.06182376 -0.21660937\n",
      "  0.27099156  0.01278587 -0.331944    0.28479328 -0.2009146  -0.24860773\n",
      "  0.07702448 -0.43637949]\n",
      "New theta_0 : [ 0.00881744 -0.11793224  0.09652156  0.01238325  0.06184231 -0.21682974\n",
      "  0.27093095  0.0128021  -0.33215886  0.28489062 -0.20092605 -0.24863543\n",
      "  0.07701157 -0.43637609]\n",
      "Training Error:  9.813173942134062\n",
      "====================================================================================================\n",
      "Iteration:  599\n",
      "Previous theta :  [ 0.00881744 -0.11793224  0.09652156  0.01238325  0.06184231 -0.21682974\n",
      "  0.27093095  0.0128021  -0.33215886  0.28489062 -0.20092605 -0.24863543\n",
      "  0.07701157 -0.43637609]\n",
      "New theta_0 : [ 0.00882178 -0.11797596  0.0965999   0.01236938  0.06186075 -0.21704888\n",
      "  0.27087077  0.01281825 -0.33237238  0.28498751 -0.2009376  -0.24866297\n",
      "  0.07699874 -0.43637262]\n",
      "Training Error:  9.81305726702308\n",
      "====================================================================================================\n",
      "Iteration:  600\n",
      "Previous theta :  [ 0.00882178 -0.11797596  0.0965999   0.01236938  0.06186075 -0.21704888\n",
      "  0.27087077  0.01281825 -0.33237238  0.28498751 -0.2009376  -0.24866297\n",
      "  0.07699874 -0.43637262]\n",
      "New theta_0 : [ 0.00882611 -0.11801945  0.09667777  0.01235575  0.06187908 -0.21726679\n",
      "  0.27081102  0.01283431 -0.33258455  0.28508394 -0.20094922 -0.24869037\n",
      "  0.076986   -0.43636907]\n",
      "Training Error:  9.81294195028128\n",
      "====================================================================================================\n",
      "Iteration:  601\n",
      "Previous theta :  [ 0.00882611 -0.11801945  0.09667777  0.01235575  0.06187908 -0.21726679\n",
      "  0.27081102  0.01283431 -0.33258455  0.28508394 -0.20094922 -0.24869037\n",
      "  0.076986   -0.43636907]\n",
      "New theta_0 : [ 0.00883042 -0.11806269  0.09675519  0.01234234  0.0618973  -0.21748349\n",
      "  0.27075171  0.01285028 -0.3327954   0.28517994 -0.20096093 -0.24871761\n",
      "  0.07697335 -0.43636544]\n",
      "Training Error:  9.812827975778607\n",
      "====================================================================================================\n",
      "Iteration:  602\n",
      "Previous theta :  [ 0.00883042 -0.11806269  0.09675519  0.01234234  0.0618973  -0.21748349\n",
      "  0.27075171  0.01285028 -0.3327954   0.28517994 -0.20096093 -0.24871761\n",
      "  0.07697335 -0.43636544]\n",
      "New theta_0 : [ 0.00883471 -0.1181057   0.09683213  0.01232916  0.06191542 -0.21769898\n",
      "  0.27069282  0.01286617 -0.33300493  0.28527549 -0.20097273 -0.2487447\n",
      "  0.07696079 -0.43636174]\n",
      "Training Error:  9.812715327579424\n",
      "====================================================================================================\n",
      "Iteration:  603\n",
      "Previous theta :  [ 0.00883471 -0.1181057   0.09683213  0.01232916  0.06191542 -0.21769898\n",
      "  0.27069282  0.01286617 -0.33300493  0.28527549 -0.20097273 -0.2487447\n",
      "  0.07696079 -0.43636174]\n",
      "New theta_0 : [ 0.00883898 -0.11814846  0.09690862  0.0123162   0.06193342 -0.21791326\n",
      "  0.27063435  0.01288197 -0.33321315  0.2853706  -0.20098461 -0.24877165\n",
      "  0.07694831 -0.43635796]\n",
      "Training Error:  9.81260398994008\n",
      "====================================================================================================\n",
      "Iteration:  604\n",
      "Previous theta :  [ 0.00883898 -0.11814846  0.09690862  0.0123162   0.06193342 -0.21791326\n",
      "  0.27063435  0.01288197 -0.33321315  0.2853706  -0.20098461 -0.24877165\n",
      "  0.07694831 -0.43635796]\n",
      "New theta_0 : [ 0.00884323 -0.11819098  0.09698466  0.01230346  0.06195132 -0.21812635\n",
      "  0.2705763   0.01289769 -0.33342006  0.28546527 -0.20099657 -0.24879845\n",
      "  0.07693592 -0.43635411]\n",
      "Training Error:  9.812493947306582\n",
      "====================================================================================================\n",
      "Iteration:  605\n",
      "Previous theta :  [ 0.00884323 -0.11819098  0.09698466  0.01230346  0.06195132 -0.21812635\n",
      "  0.2705763   0.01289769 -0.33342006  0.28546527 -0.20099657 -0.24879845\n",
      "  0.07693592 -0.43635411]\n",
      "New theta_0 : [ 0.00884745 -0.11823327  0.09706023  0.01229093  0.06196911 -0.21833824\n",
      "  0.27051867  0.01291332 -0.33362568  0.2855595  -0.20100861 -0.2488251\n",
      "  0.07692361 -0.43635019]\n",
      "Training Error:  9.812385184312276\n",
      "====================================================================================================\n",
      "Iteration:  606\n",
      "Previous theta :  [ 0.00884745 -0.11823327  0.09706023  0.01229093  0.06196911 -0.21833824\n",
      "  0.27051867  0.01291332 -0.33362568  0.2855595  -0.20100861 -0.2488251\n",
      "  0.07692361 -0.43635019]\n",
      "New theta_0 : [ 0.00885166 -0.11827532  0.09713536  0.01227863  0.0619868  -0.21854895\n",
      "  0.27046145  0.01292887 -0.33383001  0.28565331 -0.20102072 -0.24885161\n",
      "  0.07691139 -0.4363462 ]\n",
      "Training Error:  9.812277685775548\n",
      "====================================================================================================\n",
      "Iteration:  607\n",
      "Previous theta :  [ 0.00885166 -0.11827532  0.09713536  0.01227863  0.0619868  -0.21854895\n",
      "  0.27046145  0.01292887 -0.33383001  0.28565331 -0.20102072 -0.24885161\n",
      "  0.07691139 -0.4363462 ]\n",
      "New theta_0 : [ 0.00885585 -0.11831714  0.09721004  0.01226653  0.06200437 -0.21875848\n",
      "  0.27040464  0.01294434 -0.33403306  0.28574668 -0.20103292 -0.24887798\n",
      "  0.07689925 -0.43634214]\n",
      "Training Error:  9.812171436697557\n",
      "====================================================================================================\n",
      "Iteration:  608\n",
      "Previous theta :  [ 0.00885585 -0.11831714  0.09721004  0.01226653  0.06200437 -0.21875848\n",
      "  0.27040464  0.01294434 -0.33403306  0.28574668 -0.20103292 -0.24887798\n",
      "  0.07689925 -0.43634214]\n",
      "New theta_0 : [ 0.00886002 -0.11835873  0.09728427  0.01225465  0.06202185 -0.21896684\n",
      "  0.27034823  0.01295972 -0.33423484  0.28583962 -0.2010452  -0.2489042\n",
      "  0.0768872  -0.43633801]\n",
      "Training Error:  9.81206642226\n",
      "====================================================================================================\n",
      "Iteration:  609\n",
      "Previous theta :  [ 0.00886002 -0.11835873  0.09728427  0.01225465  0.06202185 -0.21896684\n",
      "  0.27034823  0.01295972 -0.33423484  0.28583962 -0.2010452  -0.2489042\n",
      "  0.0768872  -0.43633801]\n",
      "New theta_0 : [ 0.00886416 -0.11840008  0.09735805  0.01224298  0.06203922 -0.21917404\n",
      "  0.27029223  0.01297502 -0.33443536  0.28593214 -0.20105756 -0.24893028\n",
      "  0.07687523 -0.43633382]\n",
      "Training Error:  9.811962627822913\n",
      "====================================================================================================\n",
      "Iteration:  610\n",
      "Previous theta :  [ 0.00886416 -0.11840008  0.09735805  0.01224298  0.06203922 -0.21917404\n",
      "  0.27029223  0.01297502 -0.33443536  0.28593214 -0.20105756 -0.24893028\n",
      "  0.07687523 -0.43633382]\n",
      "New theta_0 : [ 0.00886829 -0.1184412   0.0974314   0.01223151  0.06205648 -0.21938008\n",
      "  0.27023663  0.01299024 -0.33463462  0.28602423 -0.20106999 -0.24895622\n",
      "  0.07686335 -0.43632956]\n",
      "Training Error:  9.81186003892248\n",
      "====================================================================================================\n",
      "Iteration:  611\n",
      "Previous theta :  [ 0.00886829 -0.1184412   0.0974314   0.01223151  0.06205648 -0.21938008\n",
      "  0.27023663  0.01299024 -0.33463462  0.28602423 -0.20106999 -0.24895622\n",
      "  0.07686335 -0.43632956]\n",
      "New theta_0 : [ 0.0088724  -0.1184821   0.09750431  0.01222025  0.06207364 -0.21958497\n",
      "  0.27018143  0.01300537 -0.33483263  0.28611591 -0.2010825  -0.24898202\n",
      "  0.07685154 -0.43632525]\n",
      "Training Error:  9.811758641268886\n",
      "====================================================================================================\n",
      "Iteration:  612\n",
      "Previous theta :  [ 0.0088724  -0.1184821   0.09750431  0.01222025  0.06207364 -0.21958497\n",
      "  0.27018143  0.01300537 -0.33483263  0.28611591 -0.2010825  -0.24898202\n",
      "  0.07685154 -0.43632525]\n",
      "New theta_0 : [ 0.00887649 -0.11852276  0.09757677  0.0122092   0.0620907  -0.21978871\n",
      "  0.27012662  0.01302043 -0.33502941  0.28620716 -0.20109508 -0.24900769\n",
      "  0.07683982 -0.43632086]\n",
      "Training Error:  9.811658420744187\n",
      "====================================================================================================\n",
      "Iteration:  613\n",
      "Previous theta :  [ 0.00887649 -0.11852276  0.09757677  0.0122092   0.0620907  -0.21978871\n",
      "  0.27012662  0.01302043 -0.33502941  0.28620716 -0.20109508 -0.24900769\n",
      "  0.07683982 -0.43632086]\n",
      "New theta_0 : [ 0.00888056 -0.1185632   0.09764881  0.01219834  0.06210766 -0.21999131\n",
      "  0.2700722   0.0130354  -0.33522495  0.286298   -0.20110773 -0.24903321\n",
      "  0.07682817 -0.43631642]\n",
      "Training Error:  9.811559363400221\n",
      "====================================================================================================\n",
      "Iteration:  614\n",
      "Previous theta :  [ 0.00888056 -0.1185632   0.09764881  0.01219834  0.06210766 -0.21999131\n",
      "  0.2700722   0.0130354  -0.33522495  0.286298   -0.20110773 -0.24903321\n",
      "  0.07682817 -0.43631642]\n",
      "New theta_0 : [ 0.00888461 -0.11860342  0.09772041  0.01218769  0.06212452 -0.22019277\n",
      "  0.27001817  0.01305029 -0.33541927  0.28638843 -0.20112046 -0.2490586\n",
      "  0.07681661 -0.43631192]\n",
      "Training Error:  9.811461455456513\n",
      "====================================================================================================\n",
      "Iteration:  615\n",
      "Previous theta :  [ 0.00888461 -0.11860342  0.09772041  0.01218769  0.06212452 -0.22019277\n",
      "  0.27001817  0.01305029 -0.33541927  0.28638843 -0.20112046 -0.2490586\n",
      "  0.07681661 -0.43631192]\n",
      "New theta_0 : [ 0.00888863 -0.11864341  0.09779159  0.01217723  0.06214127 -0.22039311\n",
      "  0.26996452  0.01306509 -0.33561237  0.28647844 -0.20113327 -0.24908385\n",
      "  0.07680513 -0.43630736]\n",
      "Training Error:  9.811364683298253\n",
      "====================================================================================================\n",
      "Iteration:  616\n",
      "Previous theta :  [ 0.00888863 -0.11864341  0.09779159  0.01217723  0.06214127 -0.22039311\n",
      "  0.26996452  0.01306509 -0.33561237  0.28647844 -0.20113327 -0.24908385\n",
      "  0.07680513 -0.43630736]\n",
      "New theta_0 : [ 0.00889264 -0.11868317  0.09786233  0.01216697  0.06215792 -0.22059233\n",
      "  0.26991126  0.01307982 -0.33580427  0.28656804 -0.20114614 -0.24910896\n",
      "  0.07679373 -0.43630275]\n",
      "Training Error:  9.811269033474256\n",
      "====================================================================================================\n",
      "Iteration:  617\n",
      "Previous theta :  [ 0.00889264 -0.11868317  0.09786233  0.01216697  0.06215792 -0.22059233\n",
      "  0.26991126  0.01307982 -0.33580427  0.28656804 -0.20114614 -0.24910896\n",
      "  0.07679373 -0.43630275]\n",
      "New theta_0 : [ 0.00889664 -0.11872272  0.09793266  0.0121569   0.06217448 -0.22079044\n",
      "  0.26985837  0.01309447 -0.33599496  0.28665724 -0.20115909 -0.24913395\n",
      "  0.0767824  -0.43629807]\n",
      "Training Error:  9.811174492694972\n",
      "====================================================================================================\n",
      "Iteration:  618\n",
      "Previous theta :  [ 0.00889664 -0.11872272  0.09793266  0.0121569   0.06217448 -0.22079044\n",
      "  0.26985837  0.01309447 -0.33599496  0.28665724 -0.20115909 -0.24913395\n",
      "  0.0767824  -0.43629807]\n",
      "New theta_0 : [ 0.00890061 -0.11876204  0.09800256  0.01214702  0.06219093 -0.22098744\n",
      "  0.26980586  0.01310904 -0.33618446  0.28674604 -0.2011721  -0.2491588\n",
      "  0.07677116 -0.43629335]\n",
      "Training Error:  9.81108104783052\n",
      "====================================================================================================\n",
      "Iteration:  619\n",
      "Previous theta :  [ 0.00890061 -0.11876204  0.09800256  0.01214702  0.06219093 -0.22098744\n",
      "  0.26980586  0.01310904 -0.33618446  0.28674604 -0.2011721  -0.2491588\n",
      "  0.07677116 -0.43629335]\n",
      "New theta_0 : [ 0.00890456 -0.11880115  0.09807204  0.01213733  0.06220729 -0.22118333\n",
      "  0.26975372  0.01312352 -0.33637278  0.28683443 -0.20118519 -0.24918351\n",
      "  0.07675999 -0.43628857]\n",
      "Training Error:  9.810988685908725\n",
      "====================================================================================================\n",
      "Iteration:  620\n",
      "Previous theta :  [ 0.00890456 -0.11880115  0.09807204  0.01213733  0.06220729 -0.22118333\n",
      "  0.26975372  0.01312352 -0.33637278  0.28683443 -0.20118519 -0.24918351\n",
      "  0.07675999 -0.43628857]\n",
      "New theta_0 : [ 0.00890849 -0.11884004  0.09814111  0.01212783  0.06222354 -0.22137813\n",
      "  0.26970196  0.01313793 -0.33655992  0.28692242 -0.20119834 -0.2492081\n",
      "  0.0767489  -0.43628374]\n",
      "Training Error:  9.81089739411321\n",
      "====================================================================================================\n",
      "Iteration:  621\n",
      "Previous theta :  [ 0.00890849 -0.11884004  0.09814111  0.01212783  0.06222354 -0.22137813\n",
      "  0.26970196  0.01313793 -0.33655992  0.28692242 -0.20119834 -0.2492081\n",
      "  0.0767489  -0.43628374]\n",
      "New theta_0 : [ 0.00891241 -0.11887871  0.09820976  0.01211851  0.0622397  -0.22157184\n",
      "  0.26965056  0.01315226 -0.33674588  0.28701001 -0.20121157 -0.24923255\n",
      "  0.07673788 -0.43627885]\n",
      "Training Error:  9.81080715978149\n",
      "====================================================================================================\n",
      "Iteration:  622\n",
      "Previous theta :  [ 0.00891241 -0.11887871  0.09820976  0.01211851  0.0622397  -0.22157184\n",
      "  0.26965056  0.01315226 -0.33674588  0.28701001 -0.20121157 -0.24923255\n",
      "  0.07673788 -0.43627885]\n",
      "New theta_0 : [ 0.0089163  -0.11891716  0.09827799  0.01210938  0.06225577 -0.22176446\n",
      "  0.26959952  0.01316651 -0.33693068  0.28709721 -0.20122486 -0.24925687\n",
      "  0.07672694 -0.43627392]\n",
      "Training Error:  9.810717970403099\n",
      "====================================================================================================\n",
      "Iteration:  623\n",
      "Previous theta :  [ 0.0089163  -0.11891716  0.09827799  0.01210938  0.06225577 -0.22176446\n",
      "  0.26959952  0.01316651 -0.33693068  0.28709721 -0.20122486 -0.24925687\n",
      "  0.07672694 -0.43627392]\n",
      "New theta_0 : [ 0.00892018 -0.1189554   0.09834582  0.01210043  0.06227173 -0.22195601\n",
      "  0.26954885  0.01318068 -0.33711433  0.28718402 -0.20123821 -0.24928107\n",
      "  0.07671608 -0.43626894]\n",
      "Training Error:  9.810629813617739\n",
      "====================================================================================================\n",
      "Iteration:  624\n",
      "Previous theta :  [ 0.00892018 -0.1189554   0.09834582  0.01210043  0.06227173 -0.22195601\n",
      "  0.26954885  0.01318068 -0.33711433  0.28718402 -0.20123821 -0.24928107\n",
      "  0.07671608 -0.43626894]\n",
      "New theta_0 : [ 0.00892404 -0.11899343  0.09841324  0.01209167  0.0622876  -0.22214648\n",
      "  0.26949853  0.01319478 -0.33729683  0.28727043 -0.20125163 -0.24930514\n",
      "  0.07670529 -0.43626391]\n",
      "Training Error:  9.810542677213444\n",
      "====================================================================================================\n",
      "Iteration:  625\n",
      "Previous theta :  [ 0.00892404 -0.11899343  0.09841324  0.01209167  0.0622876  -0.22214648\n",
      "  0.26949853  0.01319478 -0.33729683  0.28727043 -0.20125163 -0.24930514\n",
      "  0.07670529 -0.43626391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.00892787 -0.11903125  0.09848026  0.01208308  0.06230337 -0.22233589\n",
      "  0.26944857  0.0132088  -0.33747818  0.28735646 -0.20126512 -0.24932908\n",
      "  0.07669457 -0.43625883]\n",
      "Training Error:  9.81045654912478\n",
      "====================================================================================================\n",
      "Iteration:  626\n",
      "Previous theta :  [ 0.00892787 -0.11903125  0.09848026  0.01208308  0.06230337 -0.22233589\n",
      "  0.26944857  0.0132088  -0.33747818  0.28735646 -0.20126512 -0.24932908\n",
      "  0.07669457 -0.43625883]\n",
      "New theta_0 : [ 0.00893169 -0.11906885  0.09854687  0.01207466  0.06231905 -0.22252423\n",
      "  0.26939896  0.01322274 -0.3376584   0.2874421  -0.20127867 -0.24935289\n",
      "  0.07668393 -0.43625371]\n",
      "Training Error:  9.81037141743106\n",
      "====================================================================================================\n",
      "Iteration:  627\n",
      "Previous theta :  [ 0.00893169 -0.11906885  0.09854687  0.01207466  0.06231905 -0.22252423\n",
      "  0.26939896  0.01322274 -0.3376584   0.2874421  -0.20127867 -0.24935289\n",
      "  0.07668393 -0.43625371]\n",
      "New theta_0 : [ 0.0089355  -0.11910625  0.09861308  0.01206642  0.06233463 -0.22271153\n",
      "  0.26934971  0.0132366  -0.33783749  0.28752736 -0.20129229 -0.24937658\n",
      "  0.07667337 -0.43624854]\n",
      "Training Error:  9.81028727035459\n",
      "====================================================================================================\n",
      "Iteration:  628\n",
      "Previous theta :  [ 0.0089355  -0.11910625  0.09861308  0.01206642  0.06233463 -0.22271153\n",
      "  0.26934971  0.0132366  -0.33783749  0.28752736 -0.20129229 -0.24937658\n",
      "  0.07667337 -0.43624854]\n",
      "New theta_0 : [ 0.00893928 -0.11914343  0.0986789   0.01205836  0.06235012 -0.22289777\n",
      "  0.2693008   0.01325039 -0.33801546  0.28761223 -0.20130596 -0.24940014\n",
      "  0.07666287 -0.43624333]\n",
      "Training Error:  9.810204096258905\n",
      "====================================================================================================\n",
      "Iteration:  629\n",
      "Previous theta :  [ 0.00893928 -0.11914343  0.0986789   0.01205836  0.06235012 -0.22289777\n",
      "  0.2693008   0.01325039 -0.33801546  0.28761223 -0.20130596 -0.24940014\n",
      "  0.07666287 -0.43624333]\n",
      "New theta_0 : [ 0.00894304 -0.11918041  0.09874431  0.01205047  0.06236552 -0.22308297\n",
      "  0.26925223  0.0132641  -0.33819232  0.28769673 -0.2013197  -0.24942358\n",
      "  0.07665245 -0.43623808]\n",
      "Training Error:  9.81012188364708\n",
      "====================================================================================================\n",
      "Iteration:  630\n",
      "Previous theta :  [ 0.00894304 -0.11918041  0.09874431  0.01205047  0.06236552 -0.22308297\n",
      "  0.26925223  0.0132641  -0.33819232  0.28769673 -0.2013197  -0.24942358\n",
      "  0.07665245 -0.43623808]\n",
      "New theta_0 : [ 0.00894679 -0.11921719  0.09880934  0.01204274  0.06238082 -0.22326713\n",
      "  0.26920401  0.01327773 -0.33836807  0.28778084 -0.20133351 -0.2494469\n",
      "  0.0766421  -0.43623278]\n",
      "Training Error:  9.810040621160015\n",
      "====================================================================================================\n",
      "Iteration:  631\n",
      "Previous theta :  [ 0.00894679 -0.11921719  0.09880934  0.01204274  0.06238082 -0.22326713\n",
      "  0.26920401  0.01327773 -0.33836807  0.28778084 -0.20133351 -0.2494469\n",
      "  0.0766421  -0.43623278]\n",
      "New theta_0 : [ 0.00895051 -0.11925375  0.09887397  0.01203519  0.06239603 -0.22345026\n",
      "  0.26915613  0.01329129 -0.33854273  0.28786458 -0.20134737 -0.24947009\n",
      "  0.07663183 -0.43622745]\n",
      "Training Error:  9.809960297574762\n",
      "====================================================================================================\n",
      "Iteration:  632\n",
      "Previous theta :  [ 0.00895051 -0.11925375  0.09887397  0.01203519  0.06239603 -0.22345026\n",
      "  0.26915613  0.01329129 -0.33854273  0.28786458 -0.20134737 -0.24947009\n",
      "  0.07663183 -0.43622745]\n",
      "New theta_0 : [ 0.00895422 -0.11929012  0.09893821  0.0120278   0.06241115 -0.22363237\n",
      "  0.26910858  0.01330478 -0.33871629  0.28794795 -0.20136129 -0.24949316\n",
      "  0.07662162 -0.43622207]\n",
      "Training Error:  9.809880901802874\n",
      "====================================================================================================\n",
      "Iteration:  633\n",
      "Previous theta :  [ 0.00895422 -0.11929012  0.09893821  0.0120278   0.06241115 -0.22363237\n",
      "  0.26910858  0.01330478 -0.33871629  0.28794795 -0.20136129 -0.24949316\n",
      "  0.07662162 -0.43622207]\n",
      "New theta_0 : [ 0.00895791 -0.11932628  0.09900207  0.01202057  0.06242618 -0.22381345\n",
      "  0.26906137  0.01331819 -0.33888876  0.28803095 -0.20137527 -0.24951611\n",
      "  0.07661148 -0.43621666]\n",
      "Training Error:  9.809802422888769\n",
      "====================================================================================================\n",
      "Iteration:  634\n",
      "Previous theta :  [ 0.00895791 -0.11932628  0.09900207  0.01202057  0.06242618 -0.22381345\n",
      "  0.26906137  0.01331819 -0.33888876  0.28803095 -0.20137527 -0.24951611\n",
      "  0.07661148 -0.43621666]\n",
      "New theta_0 : [ 0.00896159 -0.11936224  0.09906554  0.01201351  0.06244111 -0.22399352\n",
      "  0.26901449  0.01333153 -0.33906015  0.28811357 -0.20138931 -0.24953894\n",
      "  0.07660142 -0.4362112 ]\n",
      "Training Error:  9.80972485000811\n",
      "====================================================================================================\n",
      "Iteration:  635\n",
      "Previous theta :  [ 0.00896159 -0.11936224  0.09906554  0.01201351  0.06244111 -0.22399352\n",
      "  0.26901449  0.01333153 -0.33906015  0.28811357 -0.20138931 -0.24953894\n",
      "  0.07660142 -0.4362112 ]\n",
      "New theta_0 : [ 0.00896524 -0.119398    0.09912863  0.01200661  0.06245596 -0.22417259\n",
      "  0.26896794  0.01334479 -0.33923048  0.28819583 -0.20140341 -0.24956166\n",
      "  0.07659142 -0.43620572]\n",
      "Training Error:  9.809648172466222\n",
      "====================================================================================================\n",
      "Iteration:  636\n",
      "Previous theta :  [ 0.00896524 -0.119398    0.09912863  0.01200661  0.06245596 -0.22417259\n",
      "  0.26896794  0.01334479 -0.33923048  0.28819583 -0.20140341 -0.24956166\n",
      "  0.07659142 -0.43620572]\n",
      "New theta_0 : [ 0.00896888 -0.11943356  0.09919134  0.01199987  0.06247072 -0.22435065\n",
      "  0.26892172  0.01335798 -0.33939973  0.28827773 -0.20141757 -0.24958425\n",
      "  0.07658149 -0.43620019]\n",
      "Training Error:  9.809572379696503\n",
      "====================================================================================================\n",
      "Iteration:  637\n",
      "Previous theta :  [ 0.00896888 -0.11943356  0.09919134  0.01199987  0.06247072 -0.22435065\n",
      "  0.26892172  0.01335798 -0.33939973  0.28827773 -0.20141757 -0.24958425\n",
      "  0.07658149 -0.43620019]\n",
      "New theta_0 : [ 0.00897249 -0.11946892  0.09925367  0.01199328  0.06248538 -0.22452771\n",
      "  0.26887582  0.01337109 -0.33956793  0.28835926 -0.20143178 -0.24960672\n",
      "  0.07657163 -0.43619463]\n",
      "Training Error:  9.809497461258877\n",
      "====================================================================================================\n",
      "Iteration:  638\n",
      "Previous theta :  [ 0.00897249 -0.11946892  0.09925367  0.01199328  0.06248538 -0.22452771\n",
      "  0.26887582  0.01337109 -0.33956793  0.28835926 -0.20143178 -0.24960672\n",
      "  0.07657163 -0.43619463]\n",
      "New theta_0 : [ 0.00897609 -0.11950409  0.09931563  0.01198686  0.06249996 -0.22470377\n",
      "  0.26883025  0.01338414 -0.33973508  0.28844043 -0.20144605 -0.24962908\n",
      "  0.07656184 -0.43618904]\n",
      "Training Error:  9.809423406838265\n",
      "====================================================================================================\n",
      "Iteration:  639\n",
      "Previous theta :  [ 0.00897609 -0.11950409  0.09931563  0.01198686  0.06249996 -0.22470377\n",
      "  0.26883025  0.01338414 -0.33973508  0.28844043 -0.20144605 -0.24962908\n",
      "  0.07656184 -0.43618904]\n",
      "New theta_0 : [ 0.00897968 -0.11953905  0.09937721  0.01198059  0.06251445 -0.22487886\n",
      "  0.26878499  0.01339711 -0.33990118  0.28852124 -0.20146037 -0.24965132\n",
      "  0.07655212 -0.43618341]\n",
      "Training Error:  9.809350206243051\n",
      "====================================================================================================\n",
      "Iteration:  640\n",
      "Previous theta :  [ 0.00897968 -0.11953905  0.09937721  0.01198059  0.06251445 -0.22487886\n",
      "  0.26878499  0.01339711 -0.33990118  0.28852124 -0.20146037 -0.24965132\n",
      "  0.07655212 -0.43618341]\n",
      "New theta_0 : [ 0.00898324 -0.11957383  0.09943842  0.01197447  0.06252885 -0.22505296\n",
      "  0.26874005  0.01341001 -0.34006624  0.28860169 -0.20147475 -0.24967345\n",
      "  0.07654246 -0.43617775]\n",
      "Training Error:  9.8092778494036\n",
      "====================================================================================================\n",
      "Iteration:  641\n",
      "Previous theta :  [ 0.00898324 -0.11957383  0.09943842  0.01197447  0.06252885 -0.22505296\n",
      "  0.26874005  0.01341001 -0.34006624  0.28860169 -0.20147475 -0.24967345\n",
      "  0.07654246 -0.43617775]\n",
      "New theta_0 : [ 0.00898679 -0.11960841  0.09949927  0.0119685   0.06254316 -0.22522608\n",
      "  0.26869542  0.01342283 -0.34023027  0.28868179 -0.20148918 -0.24969546\n",
      "  0.07653287 -0.43617206]\n",
      "Training Error:  9.809206326370758\n",
      "====================================================================================================\n",
      "Iteration:  642\n",
      "Previous theta :  [ 0.00898679 -0.11960841  0.09949927  0.0119685   0.06254316 -0.22522608\n",
      "  0.26869542  0.01342283 -0.34023027  0.28868179 -0.20148918 -0.24969546\n",
      "  0.07653287 -0.43617206]\n",
      "New theta_0 : [ 0.00899032 -0.11964279  0.09955974  0.01196268  0.06255739 -0.22539824\n",
      "  0.26865111  0.01343559 -0.34039327  0.28876153 -0.20150367 -0.24971736\n",
      "  0.07652335 -0.43616634]\n",
      "Training Error:  9.80913562731442\n",
      "====================================================================================================\n",
      "Iteration:  643\n",
      "Previous theta :  [ 0.00899032 -0.11964279  0.09955974  0.01196268  0.06255739 -0.22539824\n",
      "  0.26865111  0.01343559 -0.34039327  0.28876153 -0.20150367 -0.24971736\n",
      "  0.07652335 -0.43616634]\n",
      "New theta_0 : [ 0.00899383 -0.11967699  0.09961985  0.01195702  0.06257153 -0.22556943\n",
      "  0.26860711  0.01344827 -0.34055525  0.28884093 -0.20151821 -0.24973914\n",
      "  0.07651389 -0.43616058]\n",
      "Training Error:  9.809065742522066\n",
      "====================================================================================================\n",
      "Iteration:  644\n",
      "Previous theta :  [ 0.00899383 -0.11967699  0.09961985  0.01195702  0.06257153 -0.22556943\n",
      "  0.26860711  0.01344827 -0.34055525  0.28884093 -0.20151821 -0.24973914\n",
      "  0.07651389 -0.43616058]\n",
      "New theta_0 : [ 0.00899732 -0.11971099  0.0996796   0.01195149  0.06258558 -0.22573965\n",
      "  0.26856341  0.01346089 -0.34071622  0.28891997 -0.2015328  -0.24976081\n",
      "  0.0765045  -0.4361548 ]\n",
      "Training Error:  9.808996662397325\n",
      "====================================================================================================\n",
      "Iteration:  645\n",
      "Previous theta :  [ 0.00899732 -0.11971099  0.0996796   0.01195149  0.06258558 -0.22573965\n",
      "  0.26856341  0.01346089 -0.34071622  0.28891997 -0.2015328  -0.24976081\n",
      "  0.0765045  -0.4361548 ]\n",
      "New theta_0 : [ 0.0090008  -0.11974481  0.09973899  0.01194612  0.06259955 -0.22590893\n",
      "  0.26852002  0.01347343 -0.34087618  0.28899867 -0.20154744 -0.24978237\n",
      "  0.07649517 -0.43614899]\n",
      "Training Error:  9.808928377458601\n",
      "====================================================================================================\n",
      "Iteration:  646\n",
      "Previous theta :  [ 0.0090008  -0.11974481  0.09973899  0.01194612  0.06259955 -0.22590893\n",
      "  0.26852002  0.01347343 -0.34087618  0.28899867 -0.20154744 -0.24978237\n",
      "  0.07649517 -0.43614899]\n",
      "New theta_0 : [ 0.00900426 -0.11977843  0.09979801  0.01194089  0.06261343 -0.22607725\n",
      "  0.26847693  0.01348591 -0.34103515  0.28907702 -0.20156214 -0.24980382\n",
      "  0.07648591 -0.43614316]\n",
      "Training Error:  9.808860878337647\n",
      "====================================================================================================\n",
      "Iteration:  647\n",
      "Previous theta :  [ 0.00900426 -0.11977843  0.09979801  0.01194089  0.06261343 -0.22607725\n",
      "  0.26847693  0.01348591 -0.34103515  0.28907702 -0.20156214 -0.24980382\n",
      "  0.07648591 -0.43614316]\n",
      "New theta_0 : [ 0.0090077  -0.11981187  0.09985669  0.0119358   0.06262723 -0.22624464\n",
      "  0.26843414  0.01349831 -0.34119311  0.28915503 -0.20157688 -0.24982516\n",
      "  0.07647671 -0.43613729]\n",
      "Training Error:  9.80879415577822\n",
      "====================================================================================================\n",
      "Iteration:  648\n",
      "Previous theta :  [ 0.0090077  -0.11981187  0.09985669  0.0119358   0.06262723 -0.22624464\n",
      "  0.26843414  0.01349831 -0.34119311  0.28915503 -0.20157688 -0.24982516\n",
      "  0.07647671 -0.43613729]\n",
      "New theta_0 : [ 0.00901112 -0.11984513  0.099915    0.01193085  0.06264095 -0.22641108\n",
      "  0.26839165  0.01351065 -0.34135009  0.28923269 -0.20159167 -0.24984639\n",
      "  0.07646757 -0.4361314 ]\n",
      "Training Error:  9.808728200634702\n",
      "====================================================================================================\n",
      "Iteration:  649\n",
      "Previous theta :  [ 0.00901112 -0.11984513  0.099915    0.01193085  0.06264095 -0.22641108\n",
      "  0.26839165  0.01351065 -0.34135009  0.28923269 -0.20159167 -0.24984639\n",
      "  0.07646757 -0.4361314 ]\n",
      "New theta_0 : [ 0.00901453 -0.11987819  0.09997297  0.01192604  0.06265458 -0.22657659\n",
      "  0.26834946  0.01352291 -0.34150609  0.28931002 -0.20160652 -0.24986751\n",
      "  0.0764585  -0.43612549]\n",
      "Training Error:  9.808663003870771\n",
      "====================================================================================================\n",
      "Iteration:  650\n",
      "Previous theta :  [ 0.00901453 -0.11987819  0.09997297  0.01192604  0.06265458 -0.22657659\n",
      "  0.26834946  0.01352291 -0.34150609  0.28931002 -0.20160652 -0.24986751\n",
      "  0.0764585  -0.43612549]\n",
      "New theta_0 : [ 0.00901792 -0.11991107  0.10003059  0.01192137  0.06266812 -0.22674117\n",
      "  0.26830756  0.01353511 -0.34166111  0.289387   -0.20162141 -0.24988852\n",
      "  0.07644949 -0.43611955]\n",
      "Training Error:  9.808598556558083\n",
      "====================================================================================================\n",
      "Iteration:  651\n",
      "Previous theta :  [ 0.00901792 -0.11991107  0.10003059  0.01192137  0.06266812 -0.22674117\n",
      "  0.26830756  0.01353511 -0.34166111  0.289387   -0.20162141 -0.24988852\n",
      "  0.07644949 -0.43611955]\n",
      "New theta_0 : [ 0.00902129 -0.11994377  0.10008785  0.01191684  0.06268159 -0.22690483\n",
      "  0.26826595  0.01354724 -0.34181516  0.28946366 -0.20163634 -0.24990942\n",
      "  0.07644055 -0.43611359]\n",
      "Training Error:  9.808534849874949\n",
      "====================================================================================================\n",
      "Iteration:  652\n",
      "Previous theta :  [ 0.00902129 -0.11994377  0.10008785  0.01191684  0.06268159 -0.22690483\n",
      "  0.26826595  0.01354724 -0.34181516  0.28946366 -0.20163634 -0.24990942\n",
      "  0.07644055 -0.43611359]\n",
      "New theta_0 : [ 0.00902465 -0.11997629  0.10014477  0.01191244  0.06269497 -0.22706757\n",
      "  0.26822463  0.0135593  -0.34196825  0.28953997 -0.20165133 -0.24993021\n",
      "  0.07643166 -0.4361076 ]\n",
      "Training Error:  9.80847187510505\n",
      "====================================================================================================\n",
      "Iteration:  653\n",
      "Previous theta :  [ 0.00902465 -0.11997629  0.10014477  0.01191244  0.06269497 -0.22706757\n",
      "  0.26822463  0.0135593  -0.34196825  0.28953997 -0.20165133 -0.24993021\n",
      "  0.07643166 -0.4361076 ]\n",
      "New theta_0 : [ 0.00902799 -0.12000863  0.10020135  0.01190818  0.06270827 -0.22722939\n",
      "  0.26818359  0.0135713  -0.34212038  0.28961596 -0.20166636 -0.2499509\n",
      "  0.07642284 -0.43610159]\n",
      "Training Error:  9.808409623636186\n",
      "====================================================================================================\n",
      "Iteration:  654\n",
      "Previous theta :  [ 0.00902799 -0.12000863  0.10020135  0.01190818  0.06270827 -0.22722939\n",
      "  0.26818359  0.0135713  -0.34212038  0.28961596 -0.20166636 -0.2499509\n",
      "  0.07642284 -0.43610159]\n",
      "New theta_0 : [ 0.00903131 -0.12004078  0.10025759  0.01190405  0.06272149 -0.22739031\n",
      "  0.26814285  0.01358323 -0.34227156  0.28969161 -0.20168144 -0.24997148\n",
      "  0.07641408 -0.43609557]\n",
      "Training Error:  9.808348086958969\n",
      "====================================================================================================\n",
      "Iteration:  655\n",
      "Previous theta :  [ 0.00903131 -0.12004078  0.10025759  0.01190405  0.06272149 -0.22739031\n",
      "  0.26814285  0.01358323 -0.34227156  0.28969161 -0.20168144 -0.24997148\n",
      "  0.07641408 -0.43609557]\n",
      "New theta_0 : [ 0.00903462 -0.12007276  0.10031348  0.01190005  0.06273463 -0.22755033\n",
      "  0.26810238  0.01359509 -0.3424218   0.28976694 -0.20169656 -0.24999196\n",
      "  0.07640537 -0.43608952]\n",
      "Training Error:  9.80828725666562\n",
      "====================================================================================================\n",
      "Iteration:  656\n",
      "Previous theta :  [ 0.00903462 -0.12007276  0.10031348  0.01190005  0.06273463 -0.22755033\n",
      "  0.26810238  0.01359509 -0.3424218   0.28976694 -0.20169656 -0.24999196\n",
      "  0.07640537 -0.43608952]\n",
      "New theta_0 : [ 0.00903791 -0.12010456  0.10036904  0.01189618  0.06274769 -0.22770945\n",
      "  0.26806219  0.01360688 -0.34257109  0.28984194 -0.20171173 -0.25001233\n",
      "  0.07639673 -0.43608344]\n",
      "Training Error:  9.808227124448722\n",
      "====================================================================================================\n",
      "Iteration:  657\n",
      "Previous theta :  [ 0.00903791 -0.12010456  0.10036904  0.01189618  0.06274769 -0.22770945\n",
      "  0.26806219  0.01360688 -0.34257109  0.28984194 -0.20171173 -0.25001233\n",
      "  0.07639673 -0.43608344]\n",
      "New theta_0 : [ 0.00904118 -0.12013618  0.10042426  0.01189244  0.06276067 -0.22786767\n",
      "  0.26802229  0.01361861 -0.34271945  0.28991661 -0.20172695 -0.2500326\n",
      "  0.07638815 -0.43607736]\n",
      "Training Error:  9.80816768210001\n",
      "====================================================================================================\n",
      "Iteration:  658\n",
      "Previous theta :  [ 0.00904118 -0.12013618  0.10042426  0.01189244  0.06276067 -0.22786767\n",
      "  0.26802229  0.01361861 -0.34271945  0.28991661 -0.20172695 -0.2500326\n",
      "  0.07638815 -0.43607736]\n",
      "New theta_0 : [ 0.00904444 -0.12016762  0.10047915  0.01188882  0.06277357 -0.22802501\n",
      "  0.26798266  0.01363027 -0.34286688  0.28999096 -0.2017422  -0.25005277\n",
      "  0.07637963 -0.43607125]\n",
      "Training Error:  9.808108921509174\n",
      "====================================================================================================\n",
      "Iteration:  659\n",
      "Previous theta :  [ 0.00904444 -0.12016762  0.10047915  0.01188882  0.06277357 -0.22802501\n",
      "  0.26798266  0.01363027 -0.34286688  0.28999096 -0.2017422  -0.25005277\n",
      "  0.07637963 -0.43607125]\n",
      "New theta_0 : [ 0.00904768 -0.12019889  0.10053371  0.01188533  0.06278639 -0.22818147\n",
      "  0.2679433   0.01364187 -0.34301339  0.29006498 -0.2017575  -0.25007283\n",
      "  0.07637117 -0.43606512]\n",
      "Training Error:  9.808050834662673\n",
      "====================================================================================================\n",
      "Iteration:  660\n",
      "Previous theta :  [ 0.00904768 -0.12019889  0.10053371  0.01188533  0.06278639 -0.22818147\n",
      "  0.2679433   0.01364187 -0.34301339  0.29006498 -0.2017575  -0.25007283\n",
      "  0.07637117 -0.43606512]\n",
      "New theta_0 : [ 0.0090509  -0.12022999  0.10058793  0.01188197  0.06279913 -0.22833704\n",
      "  0.26790422  0.0136534  -0.34315899  0.29013869 -0.20177284 -0.25009279\n",
      "  0.07636276 -0.43605898]\n",
      "Training Error:  9.807993413642562\n",
      "====================================================================================================\n",
      "Iteration:  661\n",
      "Previous theta :  [ 0.0090509  -0.12022999  0.10058793  0.01188197  0.06279913 -0.22833704\n",
      "  0.26790422  0.0136534  -0.34315899  0.29013869 -0.20177284 -0.25009279\n",
      "  0.07636276 -0.43605898]\n",
      "New theta_0 : [ 0.0090541  -0.12026091  0.10064183  0.01187873  0.06281179 -0.22849174\n",
      "  0.2678654   0.01366487 -0.34330367  0.29021208 -0.20178823 -0.25011265\n",
      "  0.07635442 -0.43605281]\n",
      "Training Error:  9.807936650625344\n",
      "====================================================================================================\n",
      "Iteration:  662\n",
      "Previous theta :  [ 0.0090541  -0.12026091  0.10064183  0.01187873  0.06281179 -0.22849174\n",
      "  0.2678654   0.01366487 -0.34330367  0.29021208 -0.20178823 -0.25011265\n",
      "  0.07635442 -0.43605281]\n",
      "New theta_0 : [ 0.0090573  -0.12029166  0.1006954   0.01187561  0.06282438 -0.22864558\n",
      "  0.26782686  0.01367628 -0.34344745  0.29028515 -0.20180365 -0.2501324\n",
      "  0.07634613 -0.43604664]\n",
      "Training Error:  9.807880537880827\n",
      "====================================================================================================\n",
      "Iteration:  663\n",
      "Previous theta :  [ 0.0090573  -0.12029166  0.1006954   0.01187561  0.06282438 -0.22864558\n",
      "  0.26782686  0.01367628 -0.34344745  0.29028515 -0.20180365 -0.2501324\n",
      "  0.07634613 -0.43604664]\n",
      "New theta_0 : [ 0.00906047 -0.12032224  0.10074865  0.01187261  0.06283689 -0.22879855\n",
      "  0.26778858  0.01368762 -0.34359033  0.29035791 -0.20181912 -0.25015206\n",
      "  0.0763379  -0.43604044]\n",
      "Training Error:  9.807825067770995\n",
      "====================================================================================================\n",
      "Iteration:  664\n",
      "Previous theta :  [ 0.00906047 -0.12032224  0.10074865  0.01187261  0.06283689 -0.22879855\n",
      "  0.26778858  0.01368762 -0.34359033  0.29035791 -0.20181912 -0.25015206\n",
      "  0.0763379  -0.43604044]\n",
      "New theta_0 : [ 0.00906363 -0.12035265  0.10080157  0.01186973  0.06284932 -0.22895066\n",
      "  0.26775056  0.01369889 -0.34373231  0.29043036 -0.20183463 -0.25017162\n",
      "  0.07632972 -0.43603424]\n",
      "Training Error:  9.807770232748895\n",
      "====================================================================================================\n",
      "Iteration:  665\n",
      "Previous theta :  [ 0.00906363 -0.12035265  0.10080157  0.01186973  0.06284932 -0.22895066\n",
      "  0.26775056  0.01369889 -0.34373231  0.29043036 -0.20183463 -0.25017162\n",
      "  0.07632972 -0.43603424]\n",
      "New theta_0 : [ 0.00906677 -0.12038289  0.10085418  0.01186697  0.06286168 -0.22910192\n",
      "  0.26771281  0.01371011 -0.34387341  0.29050249 -0.20185017 -0.25019108\n",
      "  0.0763216  -0.43602801]\n",
      "Training Error:  9.80771602535754\n",
      "====================================================================================================\n",
      "Iteration:  666\n",
      "Previous theta :  [ 0.00906677 -0.12038289  0.10085418  0.01186697  0.06286168 -0.22910192\n",
      "  0.26771281  0.01371011 -0.34387341  0.29050249 -0.20185017 -0.25019108\n",
      "  0.0763216  -0.43602801]\n",
      "New theta_0 : [ 0.00906989 -0.12041296  0.10090647  0.01186433  0.06287396 -0.22925233\n",
      "  0.26767531  0.01372126 -0.34401362  0.29057431 -0.20186576 -0.25021044\n",
      "  0.07631354 -0.43602178]\n",
      "Training Error:  9.807662438228821\n",
      "====================================================================================================\n",
      "Iteration:  667\n",
      "Previous theta :  [ 0.00906989 -0.12041296  0.10090647  0.01186433  0.06287396 -0.22925233\n",
      "  0.26767531  0.01372126 -0.34401362  0.29057431 -0.20186576 -0.25021044\n",
      "  0.07631354 -0.43602178]\n",
      "New theta_0 : [ 0.009073   -0.12044286  0.10095844  0.0118618   0.06288616 -0.22940189\n",
      "  0.26763808  0.01373235 -0.34415296  0.29064583 -0.20188138 -0.2502297\n",
      "  0.07630554 -0.43601553]\n",
      "Training Error:  9.807609464082432\n",
      "====================================================================================================\n",
      "Iteration:  668\n",
      "Previous theta :  [ 0.009073   -0.12044286  0.10095844  0.0118618   0.06288616 -0.22940189\n",
      "  0.26763808  0.01373235 -0.34415296  0.29064583 -0.20188138 -0.2502297\n",
      "  0.07630554 -0.43601553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_0 : [ 0.0090761  -0.12047259  0.10101009  0.01185938  0.06289829 -0.22955062\n",
      "  0.2676011   0.01374337 -0.34429142  0.29071704 -0.20189705 -0.25024886\n",
      "  0.07629759 -0.43600927]\n",
      "Training Error:  9.80755709572482\n",
      "====================================================================================================\n",
      "Iteration:  669\n",
      "Previous theta :  [ 0.0090761  -0.12047259  0.10101009  0.01185938  0.06289829 -0.22955062\n",
      "  0.2676011   0.01374337 -0.34429142  0.29071704 -0.20189705 -0.25024886\n",
      "  0.07629759 -0.43600927]\n",
      "New theta_0 : [ 0.00907918 -0.12050217  0.10106143  0.01185708  0.06291035 -0.22969851\n",
      "  0.26756437  0.01375434 -0.34442902  0.29078794 -0.20191275 -0.25026793\n",
      "  0.07628969 -0.43600299]\n",
      "Training Error:  9.807505326048124\n",
      "====================================================================================================\n",
      "Iteration:  670\n",
      "Previous theta :  [ 0.00907918 -0.12050217  0.10106143  0.01185708  0.06291035 -0.22969851\n",
      "  0.26756437  0.01375434 -0.34442902  0.29078794 -0.20191275 -0.25026793\n",
      "  0.07628969 -0.43600299]\n",
      "New theta_0 : [ 0.00908224 -0.12053157  0.10111247  0.01185489  0.06292233 -0.22984557\n",
      "  0.2675279   0.01376524 -0.34456576  0.29085854 -0.20192849 -0.2502869\n",
      "  0.07628185 -0.43599671]\n",
      "Training Error:  9.807454148029157\n",
      "====================================================================================================\n",
      "Iteration:  671\n",
      "Previous theta :  [ 0.00908224 -0.12053157  0.10111247  0.01185489  0.06292233 -0.22984557\n",
      "  0.2675279   0.01376524 -0.34456576  0.29085854 -0.20192849 -0.2502869\n",
      "  0.07628185 -0.43599671]\n",
      "New theta_0 : [ 0.00908529 -0.12056081  0.10116319  0.01185282  0.06293423 -0.2299918\n",
      "  0.26749167  0.01377608 -0.34470164  0.29092884 -0.20194426 -0.25030578\n",
      "  0.07627407 -0.43599041]\n",
      "Training Error:  9.807403554728372\n",
      "====================================================================================================\n",
      "Iteration:  672\n",
      "Previous theta :  [ 0.00908529 -0.12056081  0.10116319  0.01185282  0.06293423 -0.2299918\n",
      "  0.26749167  0.01377608 -0.34470164  0.29092884 -0.20194426 -0.25030578\n",
      "  0.07627407 -0.43599041]\n",
      "New theta_0 : [ 0.00908832 -0.12058989  0.1012136   0.01185085  0.06294607 -0.23013721\n",
      "  0.2674557   0.01378686 -0.34483668  0.29099884 -0.20196007 -0.25032456\n",
      "  0.07626633 -0.4359841 ]\n",
      "Training Error:  9.807353539288856\n",
      "====================================================================================================\n",
      "Iteration:  673\n",
      "Previous theta :  [ 0.00908832 -0.12058989  0.1012136   0.01185085  0.06294607 -0.23013721\n",
      "  0.2674557   0.01378686 -0.34483668  0.29099884 -0.20196007 -0.25032456\n",
      "  0.07626633 -0.4359841 ]\n",
      "New theta_0 : [ 0.00909133 -0.12061881  0.10126371  0.01184899  0.06295783 -0.23028181\n",
      "  0.26741997  0.01379758 -0.34497087  0.29106854 -0.20197592 -0.25034325\n",
      "  0.07625866 -0.43597779]\n",
      "Training Error:  9.807304094935342\n",
      "====================================================================================================\n",
      "Iteration:  674\n",
      "Previous theta :  [ 0.00909133 -0.12061881  0.10126371  0.01184899  0.06295783 -0.23028181\n",
      "  0.26741997  0.01379758 -0.34497087  0.29106854 -0.20197592 -0.25034325\n",
      "  0.07625866 -0.43597779]\n",
      "New theta_0 : [ 0.00909433 -0.12064757  0.10131352  0.01184723  0.06296951 -0.23042559\n",
      "  0.26738449  0.01380824 -0.34510421  0.29113794 -0.2019918  -0.25036184\n",
      "  0.07625103 -0.43597146]\n",
      "Training Error:  9.80725521497322\n",
      "====================================================================================================\n",
      "Iteration:  675\n",
      "Previous theta :  [ 0.00909433 -0.12064757  0.10131352  0.01184723  0.06296951 -0.23042559\n",
      "  0.26738449  0.01380824 -0.34510421  0.29113794 -0.2019918  -0.25036184\n",
      "  0.07625103 -0.43597146]\n",
      "New theta_0 : [ 0.00909732 -0.12067616  0.10136303  0.01184559  0.06298113 -0.23056856\n",
      "  0.26734925  0.01381884 -0.34523673  0.29120705 -0.20200771 -0.25038034\n",
      "  0.07624346 -0.43596513]\n",
      "Training Error:  9.807206892787551\n",
      "====================================================================================================\n",
      "Iteration:  676\n",
      "Previous theta :  [ 0.00909732 -0.12067616  0.10136303  0.01184559  0.06298113 -0.23056856\n",
      "  0.26734925  0.01381884 -0.34523673  0.29120705 -0.20200771 -0.25038034\n",
      "  0.07624346 -0.43596513]\n",
      "New theta_0 : [ 0.00910029 -0.1207046   0.10141223  0.01184405  0.06299267 -0.23071073\n",
      "  0.26731425  0.01382938 -0.34536841  0.29127587 -0.20202366 -0.25039875\n",
      "  0.07623594 -0.43595878]\n",
      "Training Error:  9.80715912184214\n",
      "====================================================================================================\n",
      "Iteration:  677\n",
      "Previous theta :  [ 0.00910029 -0.1207046   0.10141223  0.01184405  0.06299267 -0.23071073\n",
      "  0.26731425  0.01382938 -0.34536841  0.29127587 -0.20202366 -0.25039875\n",
      "  0.07623594 -0.43595878]\n",
      "New theta_0 : [ 0.00910324 -0.12073288  0.10146114  0.01184261  0.06300415 -0.23085211\n",
      "  0.26727949  0.01383986 -0.34549928  0.29134439 -0.20203965 -0.25041706\n",
      "  0.07622847 -0.43595243]\n",
      "Training Error:  9.807111895678554\n",
      "====================================================================================================\n",
      "Iteration:  678\n",
      "Previous theta :  [ 0.00910324 -0.12073288  0.10146114  0.01184261  0.06300415 -0.23085211\n",
      "  0.26727949  0.01383986 -0.34549928  0.29134439 -0.20203965 -0.25041706\n",
      "  0.07622847 -0.43595243]\n",
      "New theta_0 : [ 0.00910618 -0.120761    0.10150975  0.01184127  0.06301555 -0.23099269\n",
      "  0.26724497  0.01385029 -0.34562932  0.29141262 -0.20205566 -0.25043528\n",
      "  0.07622106 -0.43594608]\n",
      "Training Error:  9.807065207915203\n",
      "====================================================================================================\n",
      "Iteration:  679\n",
      "Previous theta :  [ 0.00910618 -0.120761    0.10150975  0.01184127  0.06301555 -0.23099269\n",
      "  0.26724497  0.01385029 -0.34562932  0.29141262 -0.20205566 -0.25043528\n",
      "  0.07622106 -0.43594608]\n",
      "New theta_0 : [ 0.0091091  -0.12078897  0.10155806  0.01184004  0.06302688 -0.23113247\n",
      "  0.26721069  0.01386065 -0.34575855  0.29148057 -0.20207171 -0.25045341\n",
      "  0.07621369 -0.43593971]\n",
      "Training Error:  9.807019052246407\n",
      "====================================================================================================\n",
      "Iteration:  680\n",
      "Previous theta :  [ 0.0091091  -0.12078897  0.10155806  0.01184004  0.06302688 -0.23113247\n",
      "  0.26721069  0.01386065 -0.34575855  0.29148057 -0.20207171 -0.25045341\n",
      "  0.07621369 -0.43593971]\n",
      "New theta_0 : [ 0.00911201 -0.12081678  0.10160609  0.01183891  0.06303814 -0.23127148\n",
      "  0.26717664  0.01387096 -0.34588697  0.29154822 -0.20208779 -0.25047145\n",
      "  0.07620638 -0.43593334]\n",
      "Training Error:  9.806973422441489\n",
      "====================================================================================================\n",
      "Iteration:  681\n",
      "Previous theta :  [ 0.00911201 -0.12081678  0.10160609  0.01183891  0.06303814 -0.23127148\n",
      "  0.26717664  0.01387096 -0.34588697  0.29154822 -0.20208779 -0.25047145\n",
      "  0.07620638 -0.43593334]\n",
      "New theta_0 : [ 0.0091149  -0.12084443  0.10165382  0.01183787  0.06304934 -0.2314097\n",
      "  0.26714282  0.01388121 -0.34601459  0.2916156  -0.20210391 -0.2504894\n",
      "  0.07619912 -0.43592696]\n",
      "Training Error:  9.806928312343867\n",
      "====================================================================================================\n",
      "Iteration:  682\n",
      "Previous theta :  [ 0.0091149  -0.12084443  0.10165382  0.01183787  0.06304934 -0.2314097\n",
      "  0.26714282  0.01388121 -0.34601459  0.2916156  -0.20210391 -0.2504894\n",
      "  0.07619912 -0.43592696]\n",
      "New theta_0 : [ 0.00911778 -0.12087193  0.10170126  0.01183694  0.06306046 -0.23154714\n",
      "  0.26710923  0.0138914  -0.34614141  0.29168268 -0.20212005 -0.25050726\n",
      "  0.07619191 -0.43592058]\n",
      "Training Error:  9.806883715870164\n",
      "====================================================================================================\n",
      "Iteration:  683\n",
      "Previous theta :  [ 0.00911778 -0.12087193  0.10170126  0.01183694  0.06306046 -0.23154714\n",
      "  0.26710923  0.0138914  -0.34614141  0.29168268 -0.20212005 -0.25050726\n",
      "  0.07619191 -0.43592058]\n",
      "New theta_0 : [ 0.00912064 -0.12089928  0.10174842  0.0118361   0.06307151 -0.23168382\n",
      "  0.26707587  0.01390153 -0.34626743  0.29174948 -0.20213622 -0.25052504\n",
      "  0.07618475 -0.43591419]\n",
      "Training Error:  9.806839627009326\n",
      "====================================================================================================\n",
      "Iteration:  684\n",
      "Previous theta :  [ 0.00912064 -0.12089928  0.10174842  0.0118361   0.06307151 -0.23168382\n",
      "  0.26707587  0.01390153 -0.34626743  0.29174948 -0.20213622 -0.25052504\n",
      "  0.07618475 -0.43591419]\n",
      "New theta_0 : [ 0.00912349 -0.12092648  0.10179529  0.01183536  0.0630825  -0.23181972\n",
      "  0.26704274  0.01391161 -0.34639267  0.29181601 -0.20215243 -0.25054272\n",
      "  0.07617763 -0.4359078 ]\n",
      "Training Error:  9.806796039821748\n",
      "====================================================================================================\n",
      "Iteration:  685\n",
      "Previous theta :  [ 0.00912349 -0.12092648  0.10179529  0.01183536  0.0630825  -0.23181972\n",
      "  0.26704274  0.01391161 -0.34639267  0.29181601 -0.20215243 -0.25054272\n",
      "  0.07617763 -0.4359078 ]\n",
      "New theta_0 : [ 0.00912633 -0.12095352  0.10184187  0.01183472  0.06309342 -0.23195486\n",
      "  0.26700984  0.01392163 -0.34651713  0.29188225 -0.20216866 -0.25056031\n",
      "  0.07617057 -0.4359014 ]\n",
      "Training Error:  9.80675294843843\n",
      "====================================================================================================\n",
      "Iteration:  686\n",
      "Previous theta :  [ 0.00912633 -0.12095352  0.10184187  0.01183472  0.06309342 -0.23195486\n",
      "  0.26700984  0.01392163 -0.34651713  0.29188225 -0.20216866 -0.25056031\n",
      "  0.07617057 -0.4359014 ]\n",
      "New theta_0 : [ 0.00912915 -0.12098041  0.10188817  0.01183416  0.06310427 -0.23208924\n",
      "  0.26697715  0.01393159 -0.3466408   0.29194821 -0.20218493 -0.25057782\n",
      "  0.07616356 -0.435895  ]\n",
      "Training Error:  9.8067103470601\n",
      "====================================================================================================\n",
      "Iteration:  687\n",
      "Previous theta :  [ 0.00912915 -0.12098041  0.10188817  0.01183416  0.06310427 -0.23208924\n",
      "  0.26697715  0.01393159 -0.3466408   0.29194821 -0.20218493 -0.25057782\n",
      "  0.07616356 -0.435895  ]\n",
      "New theta_0 : [ 0.00913195 -0.12100716  0.1019342   0.0118337   0.06311505 -0.23222287\n",
      "  0.26694469  0.0139415  -0.3467637   0.2920139  -0.20220122 -0.25059524\n",
      "  0.07615659 -0.4358886 ]\n",
      "Training Error:  9.806668229956406\n",
      "====================================================================================================\n",
      "Iteration:  688\n",
      "Previous theta :  [ 0.00913195 -0.12100716  0.1019342   0.0118337   0.06311505 -0.23222287\n",
      "  0.26694469  0.0139415  -0.3467637   0.2920139  -0.20220122 -0.25059524\n",
      "  0.07615659 -0.4358886 ]\n",
      "New theta_0 : [ 0.00913474 -0.12103376  0.10197994  0.01183334  0.06312576 -0.23235574\n",
      "  0.26691245  0.01395135 -0.34688584  0.29207931 -0.20221754 -0.25061257\n",
      "  0.07614968 -0.4358822 ]\n",
      "Training Error:  9.806626591465067\n",
      "====================================================================================================\n",
      "Iteration:  689\n",
      "Previous theta :  [ 0.00913474 -0.12103376  0.10197994  0.01183334  0.06312576 -0.23235574\n",
      "  0.26691245  0.01395135 -0.34688584  0.29207931 -0.20221754 -0.25061257\n",
      "  0.07614968 -0.4358822 ]\n",
      "New theta_0 : [ 0.00913752 -0.1210602   0.10202541  0.01183306  0.06313641 -0.23248787\n",
      "  0.26688043  0.01396115 -0.3470072   0.29214445 -0.20223389 -0.25062982\n",
      "  0.07614281 -0.43587579]\n",
      "Training Error:  9.806585425991056\n",
      "====================================================================================================\n",
      "Iteration:  690\n",
      "Previous theta :  [ 0.00913752 -0.1210602   0.10202541  0.01183306  0.06313641 -0.23248787\n",
      "  0.26688043  0.01396115 -0.3470072   0.29214445 -0.20223389 -0.25062982\n",
      "  0.07614281 -0.43587579]\n",
      "New theta_0 : [ 0.00914028 -0.1210865   0.1020706   0.01183288  0.063147   -0.23261926\n",
      "  0.26684863  0.01397089 -0.34712781  0.29220931 -0.20225027 -0.25064698\n",
      "  0.07613599 -0.43586938]\n",
      "Training Error:  9.806544728005806\n",
      "====================================================================================================\n",
      "Iteration:  691\n",
      "Previous theta :  [ 0.00914028 -0.1210865   0.1020706   0.01183288  0.063147   -0.23261926\n",
      "  0.26684863  0.01397089 -0.34712781  0.29220931 -0.20225027 -0.25064698\n",
      "  0.07613599 -0.43586938]\n",
      "New theta_0 : [ 0.00914302 -0.12111266  0.10211551  0.01183278  0.06315751 -0.2327499\n",
      "  0.26681704  0.01398058 -0.34724767  0.2922739  -0.20226667 -0.25066406\n",
      "  0.07612922 -0.43586297]\n",
      "Training Error:  9.80650449204639\n",
      "====================================================================================================\n",
      "Iteration:  692\n",
      "Previous theta :  [ 0.00914302 -0.12111266  0.10211551  0.01183278  0.06315751 -0.2327499\n",
      "  0.26681704  0.01398058 -0.34724767  0.2922739  -0.20226667 -0.25066406\n",
      "  0.07612922 -0.43586297]\n",
      "New theta_0 : [ 0.00914575 -0.12113867  0.10216015  0.01183277  0.06316797 -0.23287981\n",
      "  0.26678567  0.01399022 -0.34736677  0.29233823 -0.2022831  -0.25068105\n",
      "  0.07612249 -0.43585655]\n",
      "Training Error:  9.806464712714751\n",
      "====================================================================================================\n",
      "Iteration:  693\n",
      "Previous theta :  [ 0.00914575 -0.12113867  0.10216015  0.01183277  0.06316797 -0.23287981\n",
      "  0.26678567  0.01399022 -0.34736677  0.29233823 -0.2022831  -0.25068105\n",
      "  0.07612249 -0.43585655]\n",
      "New theta_0 : [ 0.00914847 -0.12116453  0.10220453  0.01183285  0.06317835 -0.23300899\n",
      "  0.26675451  0.0139998  -0.34748513  0.29240228 -0.20229956 -0.25069795\n",
      "  0.07611581 -0.43585014]\n",
      "Training Error:  9.806425384676913\n",
      "====================================================================================================\n",
      "Iteration:  694\n",
      "Previous theta :  [ 0.00914847 -0.12116453  0.10220453  0.01183285  0.06317835 -0.23300899\n",
      "  0.26675451  0.0139998  -0.34748513  0.29240228 -0.20229956 -0.25069795\n",
      "  0.07611581 -0.43585014]\n",
      "New theta_0 : [ 0.00915118 -0.12119026  0.10224863  0.01183302  0.06318868 -0.23313745\n",
      "  0.26672356  0.01400932 -0.34760275  0.29246607 -0.20231604 -0.25071478\n",
      "  0.07610918 -0.43584373]\n",
      "Training Error:  9.806386502662212\n",
      "====================================================================================================\n",
      "Iteration:  695\n",
      "Previous theta :  [ 0.00915118 -0.12119026  0.10224863  0.01183302  0.06318868 -0.23313745\n",
      "  0.26672356  0.01400932 -0.34760275  0.29246607 -0.20231604 -0.25071478\n",
      "  0.07610918 -0.43584373]\n",
      "New theta_0 : [ 0.00915387 -0.12121583  0.10229247  0.01183327  0.06319894 -0.23326518\n",
      "  0.26669282  0.01401879 -0.34771963  0.29252959 -0.20233255 -0.25073152\n",
      "  0.07610259 -0.43583731]\n",
      "Training Error:  9.806348061462538\n",
      "====================================================================================================\n",
      "Iteration:  696\n",
      "Previous theta :  [ 0.00915387 -0.12121583  0.10229247  0.01183327  0.06319894 -0.23326518\n",
      "  0.26669282  0.01401879 -0.34771963  0.29252959 -0.20233255 -0.25073152\n",
      "  0.07610259 -0.43583731]\n",
      "New theta_0 : [ 0.00915654 -0.12124127  0.10233604  0.0118336   0.06320913 -0.2333922\n",
      "  0.26666229  0.01402821 -0.34783578  0.29259285 -0.20234908 -0.25074817\n",
      "  0.07609605 -0.4358309 ]\n",
      "Training Error:  9.806310055931581\n",
      "====================================================================================================\n",
      "Iteration:  697\n",
      "Previous theta :  [ 0.00915654 -0.12124127  0.10233604  0.0118336   0.06320913 -0.2333922\n",
      "  0.26666229  0.01402821 -0.34783578  0.29259285 -0.20234908 -0.25074817\n",
      "  0.07609605 -0.4358309 ]\n",
      "New theta_0 : [ 0.0091592  -0.12126657  0.10237934  0.01183402  0.06321926 -0.23351849\n",
      "  0.26663197  0.01403758 -0.34795121  0.29265584 -0.20236564 -0.25076475\n",
      "  0.07608956 -0.43582449]\n",
      "Training Error:  9.806272480984086\n",
      "====================================================================================================\n",
      "Iteration:  698\n",
      "Previous theta :  [ 0.0091592  -0.12126657  0.10237934  0.01183402  0.06321926 -0.23351849\n",
      "  0.26663197  0.01403758 -0.34795121  0.29265584 -0.20236564 -0.25076475\n",
      "  0.07608956 -0.43582449]\n",
      "New theta_0 : [ 0.00916185 -0.12129172  0.10242239  0.01183452  0.06322933 -0.23364408\n",
      "  0.26660184  0.0140469  -0.34806591  0.29271858 -0.20238222 -0.25078124\n",
      "  0.07608311 -0.43581808]\n",
      "Training Error:  9.806235331595133\n",
      "====================================================================================================\n",
      "Iteration:  699\n",
      "Previous theta :  [ 0.00916185 -0.12129172  0.10242239  0.01183452  0.06322933 -0.23364408\n",
      "  0.26660184  0.0140469  -0.34806591  0.29271858 -0.20238222 -0.25078124\n",
      "  0.07608311 -0.43581808]\n",
      "New theta_0 : [ 0.00916448 -0.12131673  0.10246517  0.0118351   0.06323933 -0.23376897\n",
      "  0.26657193  0.01405616 -0.34817989  0.29278105 -0.20239882 -0.25079765\n",
      "  0.0760767  -0.43581167]\n",
      "Training Error:  9.806198602799396\n",
      "====================================================================================================\n",
      "Iteration:  700\n",
      "Previous theta :  [ 0.00916448 -0.12131673  0.10246517  0.0118351   0.06323933 -0.23376897\n",
      "  0.26657193  0.01405616 -0.34817989  0.29278105 -0.20239882 -0.25079765\n",
      "  0.0760767  -0.43581167]\n",
      "New theta_0 : [ 0.0091671  -0.12134161  0.10250769  0.01183577  0.06324928 -0.23389315\n",
      "  0.26654221  0.01406537 -0.34829317  0.29284327 -0.20241545 -0.25081399\n",
      "  0.07607034 -0.43580526]\n",
      "Training Error:  9.806162289690441\n",
      "====================================================================================================\n",
      "Iteration:  701\n",
      "Previous theta :  [ 0.0091671  -0.12134161  0.10250769  0.01183577  0.06324928 -0.23389315\n",
      "  0.26654221  0.01406537 -0.34829317  0.29284327 -0.20241545 -0.25081399\n",
      "  0.07607034 -0.43580526]\n",
      "New theta_0 : [ 0.00916971 -0.12136635  0.10254996  0.01183651  0.06325916 -0.23401663\n",
      "  0.2665127   0.01407453 -0.34840573  0.29290522 -0.2024321  -0.25083024\n",
      "  0.07606403 -0.43579885]\n",
      "Training Error:  9.806126387420013\n",
      "====================================================================================================\n",
      "Iteration:  702\n",
      "Previous theta :  [ 0.00916971 -0.12136635  0.10254996  0.01183651  0.06325916 -0.23401663\n",
      "  0.2665127   0.01407453 -0.34840573  0.29290522 -0.2024321  -0.25083024\n",
      "  0.07606403 -0.43579885]\n",
      "New theta_0 : [ 0.0091723  -0.12139095  0.10259197  0.01183733  0.06326898 -0.23413942\n",
      "  0.26648338  0.01408364 -0.34851759  0.29296693 -0.20244877 -0.25084641\n",
      "  0.07605775 -0.43579245]\n",
      "Training Error:  9.806090891197332\n",
      "====================================================================================================\n",
      "Iteration:  703\n",
      "Previous theta :  [ 0.0091723  -0.12139095  0.10259197  0.01183733  0.06326898 -0.23413942\n",
      "  0.26648338  0.01408364 -0.34851759  0.29296693 -0.20244877 -0.25084641\n",
      "  0.07605775 -0.43579245]\n",
      "New theta_0 : [ 0.00917488 -0.12141541  0.10263372  0.01183823  0.06327874 -0.23426151\n",
      "  0.26645426  0.01409269 -0.34862874  0.29302837 -0.20246546 -0.2508625\n",
      "  0.07605153 -0.43578605]\n",
      "Training Error:  9.806055796288419\n",
      "====================================================================================================\n",
      "Iteration:  704\n",
      "Previous theta :  [ 0.00917488 -0.12141541  0.10263372  0.01183823  0.06327874 -0.23426151\n",
      "  0.26645426  0.01409269 -0.34862874  0.29302837 -0.20246546 -0.2508625\n",
      "  0.07605153 -0.43578605]\n",
      "New theta_0 : [ 0.00917745 -0.12143974  0.10267522  0.01183921  0.06328843 -0.23438292\n",
      "  0.26642534  0.0141017  -0.3487392   0.29308957 -0.20248218 -0.25087851\n",
      "  0.07604534 -0.43577965]\n",
      "Training Error:  9.806021098015401\n",
      "====================================================================================================\n",
      "Iteration:  705\n",
      "Previous theta :  [ 0.00917745 -0.12143974  0.10267522  0.01183921  0.06328843 -0.23438292\n",
      "  0.26642534  0.0141017  -0.3487392   0.29308957 -0.20248218 -0.25087851\n",
      "  0.07604534 -0.43577965]\n",
      "New theta_0 : [ 0.00918    -0.12146393  0.10271647  0.01184026  0.06329807 -0.23450365\n",
      "  0.26639661  0.01411066 -0.34884897  0.29315051 -0.20249892 -0.25089444\n",
      "  0.0760392  -0.43577326]\n",
      "Training Error:  9.805986791755846\n",
      "====================================================================================================\n",
      "Iteration:  706\n",
      "Previous theta :  [ 0.00918    -0.12146393  0.10271647  0.01184026  0.06329807 -0.23450365\n",
      "  0.26639661  0.01411066 -0.34884897  0.29315051 -0.20249892 -0.25089444\n",
      "  0.0760392  -0.43577326]\n",
      "New theta_0 : [ 0.00918254 -0.12148799  0.10275747  0.01184139  0.06330765 -0.2346237\n",
      "  0.26636808  0.01411956 -0.34895806  0.2932112  -0.20251567 -0.25091029\n",
      "  0.0760331  -0.43576687]\n",
      "Training Error:  9.80595287294209\n",
      "====================================================================================================\n",
      "Iteration:  707\n",
      "Previous theta :  [ 0.00918254 -0.12148799  0.10275747  0.01184139  0.06330765 -0.2346237\n",
      "  0.26636808  0.01411956 -0.34895806  0.2932112  -0.20251567 -0.25091029\n",
      "  0.0760331  -0.43576687]\n",
      "New theta_0 : [ 0.00918506 -0.12151192  0.10279822  0.01184259  0.06331716 -0.23474307\n",
      "  0.26633973  0.01412842 -0.34906646  0.29327164 -0.20253245 -0.25092607\n",
      "  0.07602705 -0.43576048]\n",
      "Training Error:  9.805919337060589\n",
      "====================================================================================================\n",
      "Iteration:  708\n",
      "Previous theta :  [ 0.00918506 -0.12151192  0.10279822  0.01184259  0.06331716 -0.23474307\n",
      "  0.26633973  0.01412842 -0.34906646  0.29327164 -0.20253245 -0.25092607\n",
      "  0.07602705 -0.43576048]\n",
      "New theta_0 : [ 0.00918757 -0.12153571  0.10283872  0.01184387  0.06332662 -0.23486177\n",
      "  0.26631158  0.01413722 -0.34917418  0.29333183 -0.20254925 -0.25094177\n",
      "  0.07602103 -0.4357541 ]\n",
      "Training Error:  9.805886179651266\n",
      "====================================================================================================\n",
      "Iteration:  709\n",
      "Previous theta :  [ 0.00918757 -0.12153571  0.10283872  0.01184387  0.06332662 -0.23486177\n",
      "  0.26631158  0.01413722 -0.34917418  0.29333183 -0.20254925 -0.25094177\n",
      "  0.07602103 -0.4357541 ]\n",
      "New theta_0 : [ 0.00919007 -0.12155937  0.10287898  0.01184521  0.06333602 -0.2349798\n",
      "  0.26628362  0.01414598 -0.34928123  0.29339178 -0.20256607 -0.25095739\n",
      "  0.07601506 -0.43574773]\n",
      "Training Error:  9.805853396306876\n",
      "====================================================================================================\n",
      "Iteration:  710\n",
      "Previous theta :  [ 0.00919007 -0.12155937  0.10287898  0.01184521  0.06333602 -0.2349798\n",
      "  0.26628362  0.01414598 -0.34928123  0.29339178 -0.20256607 -0.25095739\n",
      "  0.07601506 -0.43574773]\n",
      "New theta_0 : [ 0.00919256 -0.1215829   0.10291899  0.01184663  0.06334536 -0.23509717\n",
      "  0.26625584  0.01415469 -0.3493876   0.29345148 -0.2025829  -0.25097294\n",
      "  0.07600913 -0.43574136]\n",
      "Training Error:  9.805820982672357\n",
      "====================================================================================================\n",
      "Iteration:  711\n",
      "Previous theta :  [ 0.00919256 -0.1215829   0.10291899  0.01184663  0.06334536 -0.23509717\n",
      "  0.26625584  0.01415469 -0.3493876   0.29345148 -0.2025829  -0.25097294\n",
      "  0.07600913 -0.43574136]\n",
      "New theta_0 : [ 0.00919503 -0.1216063   0.10295876  0.01184813  0.06335464 -0.23521388\n",
      "  0.26622825  0.01416335 -0.34949332  0.29351093 -0.20259976 -0.25098841\n",
      "  0.07600324 -0.43573499]\n",
      "Training Error:  9.805788934444223\n",
      "====================================================================================================\n",
      "Iteration:  712\n",
      "Previous theta :  [ 0.00919503 -0.1216063   0.10295876  0.01184813  0.06335464 -0.23521388\n",
      "  0.26622825  0.01416335 -0.34949332  0.29351093 -0.20259976 -0.25098841\n",
      "  0.07600324 -0.43573499]\n",
      "New theta_0 : [ 0.00919749 -0.12162957  0.10299829  0.01184969  0.06336386 -0.23532993\n",
      "  0.26620085  0.01417196 -0.34959837  0.29357014 -0.20261663 -0.2510038\n",
      "  0.07599739 -0.43572863]\n",
      "Training Error:  9.805757247369938\n",
      "====================================================================================================\n",
      "Iteration:  713\n",
      "Previous theta :  [ 0.00919749 -0.12162957  0.10299829  0.01184969  0.06336386 -0.23532993\n",
      "  0.26620085  0.01417196 -0.34959837  0.29357014 -0.20261663 -0.2510038\n",
      "  0.07599739 -0.43572863]\n",
      "New theta_0 : [ 0.00919993 -0.12165271  0.10303758  0.01185132  0.06337302 -0.23544532\n",
      "  0.26617363  0.01418053 -0.34970276  0.29362911 -0.20263352 -0.25101912\n",
      "  0.07599158 -0.43572227]\n",
      "Training Error:  9.8057259172473\n",
      "====================================================================================================\n",
      "Iteration:  714\n",
      "Previous theta :  [ 0.00919993 -0.12165271  0.10303758  0.01185132  0.06337302 -0.23544532\n",
      "  0.26617363  0.01418053 -0.34970276  0.29362911 -0.20263352 -0.25101912\n",
      "  0.07599158 -0.43572227]\n",
      "New theta_0 : [ 0.00920236 -0.12167572  0.10307663  0.01185302  0.06338213 -0.23556007\n",
      "  0.26614659  0.01418904 -0.3498065   0.29368784 -0.20265043 -0.25103436\n",
      "  0.07598582 -0.43571593]\n",
      "Training Error:  9.805694939923852\n",
      "====================================================================================================\n",
      "Iteration:  715\n",
      "Previous theta :  [ 0.00920236 -0.12167572  0.10307663  0.01185302  0.06338213 -0.23556007\n",
      "  0.26614659  0.01418904 -0.3498065   0.29368784 -0.20265043 -0.25103436\n",
      "  0.07598582 -0.43571593]\n",
      "New theta_0 : [ 0.00920478 -0.12169861  0.10311545  0.01185479  0.06339118 -0.23567417\n",
      "  0.26611973  0.01419751 -0.34990959  0.29374633 -0.20266736 -0.25104953\n",
      "  0.07598009 -0.43570958]\n",
      "Training Error:  9.805664311296272\n",
      "====================================================================================================\n",
      "Iteration:  716\n",
      "Previous theta :  [ 0.00920478 -0.12169861  0.10311545  0.01185479  0.06339118 -0.23567417\n",
      "  0.26611973  0.01419751 -0.34990959  0.29374633 -0.20266736 -0.25104953\n",
      "  0.07598009 -0.43570958]\n",
      "New theta_0 : [ 0.00920719 -0.12172136  0.10315403  0.01185662  0.06340018 -0.23578763\n",
      "  0.26609305  0.01420593 -0.35001203  0.29380458 -0.2026843  -0.25106463\n",
      "  0.07597441 -0.43570325]\n",
      "Training Error:  9.805634027309798\n",
      "====================================================================================================\n",
      "Iteration:  717\n",
      "Previous theta :  [ 0.00920719 -0.12172136  0.10315403  0.01185662  0.06340018 -0.23578763\n",
      "  0.26609305  0.01420593 -0.35001203  0.29380458 -0.2026843  -0.25106463\n",
      "  0.07597441 -0.43570325]\n",
      "New theta_0 : [ 0.00920959 -0.121744    0.10319237  0.01185853  0.06340911 -0.23590046\n",
      "  0.26606655  0.01421431 -0.35011383  0.2938626  -0.20270126 -0.25107965\n",
      "  0.07596876 -0.43569692]\n",
      "Training Error:  9.805604083957633\n",
      "====================================================================================================\n",
      "Iteration:  718\n",
      "Previous theta :  [ 0.00920959 -0.121744    0.10319237  0.01185853  0.06340911 -0.23590046\n",
      "  0.26606655  0.01421431 -0.35011383  0.2938626  -0.20270126 -0.25107965\n",
      "  0.07596876 -0.43569692]\n",
      "New theta_0 : [ 0.00921197 -0.1217665   0.10323048  0.01186049  0.06341799 -0.23601264\n",
      "  0.26604023  0.01422264 -0.350215    0.29392038 -0.20271824 -0.25109459\n",
      "  0.07596315 -0.4356906 ]\n",
      "Training Error:  9.80557447728038\n",
      "====================================================================================================\n",
      "Iteration:  719\n",
      "Previous theta :  [ 0.00921197 -0.1217665   0.10323048  0.01186049  0.06341799 -0.23601264\n",
      "  0.26604023  0.01422264 -0.350215    0.29392038 -0.20271824 -0.25109459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.07596315 -0.4356906 ]\n",
      "New theta_0 : [ 0.00921434 -0.12178888  0.10326837  0.01186252  0.06342682 -0.2361242\n",
      "  0.26601408  0.01423092 -0.35031553  0.29397792 -0.20273523 -0.25110947\n",
      "  0.07595758 -0.43568429]\n",
      "Training Error:  9.805545203365472\n",
      "====================================================================================================\n",
      "Iteration:  720\n",
      "Previous theta :  [ 0.00921434 -0.12178888  0.10326837  0.01186252  0.06342682 -0.2361242\n",
      "  0.26601408  0.01423092 -0.35031553  0.29397792 -0.20273523 -0.25110947\n",
      "  0.07595758 -0.43568429]\n",
      "New theta_0 : [ 0.00921669 -0.12181114  0.10330602  0.01186462  0.06343559 -0.23623512\n",
      "  0.26598811  0.01423915 -0.35041543  0.29403523 -0.20275224 -0.25112427\n",
      "  0.07595206 -0.43567798]\n",
      "Training Error:  9.805516258346614\n",
      "====================================================================================================\n",
      "Iteration:  721\n",
      "Previous theta :  [ 0.00921669 -0.12181114  0.10330602  0.01186462  0.06343559 -0.23623512\n",
      "  0.26598811  0.01423915 -0.35041543  0.29403523 -0.20275224 -0.25112427\n",
      "  0.07595206 -0.43567798]\n",
      "New theta_0 : [ 0.00921904 -0.12183328  0.10334344  0.01186678  0.0634443  -0.23634543\n",
      "  0.2659623   0.01424734 -0.3505147   0.29409231 -0.20276926 -0.251139\n",
      "  0.07594657 -0.43567168]\n",
      "Training Error:  9.805487638403221\n",
      "====================================================================================================\n",
      "Iteration:  722\n",
      "Previous theta :  [ 0.00921904 -0.12183328  0.10334344  0.01186678  0.0634443  -0.23634543\n",
      "  0.2659623   0.01424734 -0.3505147   0.29409231 -0.20276926 -0.251139\n",
      "  0.07594657 -0.43567168]\n",
      "New theta_0 : [ 0.00922137 -0.12185529  0.10338064  0.011869    0.06345296 -0.23645511\n",
      "  0.26593668  0.01425549 -0.35061336  0.29414916 -0.20278629 -0.25115366\n",
      "  0.07594111 -0.43566539]\n",
      "Training Error:  9.805459339759883\n",
      "====================================================================================================\n",
      "Iteration:  723\n",
      "Previous theta :  [ 0.00922137 -0.12185529  0.10338064  0.011869    0.06345296 -0.23645511\n",
      "  0.26593668  0.01425549 -0.35061336  0.29414916 -0.20278629 -0.25115366\n",
      "  0.07594111 -0.43566539]\n",
      "New theta_0 : [ 0.00922369 -0.12187718  0.10341761  0.01187129  0.06346157 -0.23656417\n",
      "  0.26591122  0.01426359 -0.3507114   0.29420577 -0.20280335 -0.25116825\n",
      "  0.0759357  -0.43565911]\n",
      "Training Error:  9.805431358685818\n",
      "====================================================================================================\n",
      "Iteration:  724\n",
      "Previous theta :  [ 0.00922369 -0.12187718  0.10341761  0.01187129  0.06346157 -0.23656417\n",
      "  0.26591122  0.01426359 -0.3507114   0.29420577 -0.20280335 -0.25116825\n",
      "  0.0759357  -0.43565911]\n",
      "New theta_0 : [ 0.00922599 -0.12189895  0.10345435  0.01187363  0.06347012 -0.23667262\n",
      "  0.26588593  0.01427164 -0.35080882  0.29426216 -0.20282041 -0.25118276\n",
      "  0.07593032 -0.43565284]\n",
      "Training Error:  9.805403691494332\n",
      "====================================================================================================\n",
      "Iteration:  725\n",
      "Previous theta :  [ 0.00922599 -0.12189895  0.10345435  0.01187363  0.06347012 -0.23667262\n",
      "  0.26588593  0.01427164 -0.35080882  0.29426216 -0.20282041 -0.25118276\n",
      "  0.07593032 -0.43565284]\n",
      "New theta_0 : [ 0.00922829 -0.12192059  0.10349088  0.01187604  0.06347861 -0.23678046\n",
      "  0.26586081  0.01427965 -0.35090563  0.29431832 -0.20283749 -0.25119721\n",
      "  0.07592499 -0.43564658]\n",
      "Training Error:  9.805376334542311\n",
      "====================================================================================================\n",
      "Iteration:  726\n",
      "Previous theta :  [ 0.00922829 -0.12192059  0.10349088  0.01187604  0.06347861 -0.23678046\n",
      "  0.26586081  0.01427965 -0.35090563  0.29431832 -0.20283749 -0.25119721\n",
      "  0.07592499 -0.43564658]\n",
      "New theta_0 : [ 0.00923057 -0.12194212  0.10352718  0.0118785   0.06348706 -0.23688769\n",
      "  0.26583586  0.01428762 -0.35100184  0.29437426 -0.20285458 -0.25121158\n",
      "  0.07591968 -0.43564032]\n",
      "Training Error:  9.805349284229681\n",
      "====================================================================================================\n",
      "Iteration:  727\n",
      "Previous theta :  [ 0.00923057 -0.12194212  0.10352718  0.0118785   0.06348706 -0.23688769\n",
      "  0.26583586  0.01428762 -0.35100184  0.29437426 -0.20285458 -0.25121158\n",
      "  0.07591968 -0.43564032]\n",
      "New theta_0 : [ 0.00923284 -0.12196353  0.10356326  0.01188102  0.06349545 -0.23699432\n",
      "  0.26581107  0.01429554 -0.35109744  0.29442997 -0.20287169 -0.25122589\n",
      "  0.07591442 -0.43563408]\n",
      "Training Error:  9.805322536998894\n",
      "====================================================================================================\n",
      "Iteration:  728\n",
      "Previous theta :  [ 0.00923284 -0.12196353  0.10356326  0.01188102  0.06349545 -0.23699432\n",
      "  0.26581107  0.01429554 -0.35109744  0.29442997 -0.20287169 -0.25122589\n",
      "  0.07591442 -0.43563408]\n",
      "New theta_0 : [ 0.00923509 -0.12198482  0.10359913  0.01188361  0.06350378 -0.23710035\n",
      "  0.26578645  0.01430342 -0.35119244  0.29448545 -0.20288881 -0.25124012\n",
      "  0.07590919 -0.43562784]\n",
      "Training Error:  9.805296089334432\n",
      "====================================================================================================\n",
      "Iteration:  729\n",
      "Previous theta :  [ 0.00923509 -0.12198482  0.10359913  0.01188361  0.06350378 -0.23710035\n",
      "  0.26578645  0.01430342 -0.35119244  0.29448545 -0.20288881 -0.25124012\n",
      "  0.07590919 -0.43562784]\n",
      "New theta_0 : [ 0.00923734 -0.122006    0.10363477  0.01188625  0.06351207 -0.23720578\n",
      "  0.26576199  0.01431125 -0.35128685  0.29454071 -0.20290594 -0.25125429\n",
      "  0.075904   -0.43562162]\n",
      "Training Error:  9.805269937762299\n",
      "====================================================================================================\n",
      "Iteration:  730\n",
      "Previous theta :  [ 0.00923734 -0.122006    0.10363477  0.01188625  0.06351207 -0.23720578\n",
      "  0.26576199  0.01431125 -0.35128685  0.29454071 -0.20290594 -0.25125429\n",
      "  0.075904   -0.43562162]\n",
      "New theta_0 : [ 0.00923957 -0.12202705  0.1036702   0.01188894  0.0635203  -0.23731062\n",
      "  0.26573769  0.01431904 -0.35138067  0.29459575 -0.20292308 -0.25126839\n",
      "  0.07589885 -0.4356154 ]\n",
      "Training Error:  9.805244078849526\n",
      "====================================================================================================\n",
      "Iteration:  731\n",
      "Previous theta :  [ 0.00923957 -0.12202705  0.1036702   0.01188894  0.0635203  -0.23731062\n",
      "  0.26573769  0.01431904 -0.35138067  0.29459575 -0.20292308 -0.25126839\n",
      "  0.07589885 -0.4356154 ]\n",
      "New theta_0 : [ 0.00924179 -0.12204799  0.10370542  0.01189169  0.06352848 -0.23741486\n",
      "  0.26571355  0.01432679 -0.3514739   0.29465057 -0.20294023 -0.25128242\n",
      "  0.07589373 -0.4356092 ]\n",
      "Training Error:  9.80521850920367\n",
      "====================================================================================================\n",
      "Iteration:  732\n",
      "Previous theta :  [ 0.00924179 -0.12204799  0.10370542  0.01189169  0.06352848 -0.23741486\n",
      "  0.26571355  0.01432679 -0.3514739   0.29465057 -0.20294023 -0.25128242\n",
      "  0.07589373 -0.4356092 ]\n",
      "New theta_0 : [ 0.009244   -0.12206882  0.10374042  0.0118945   0.06353661 -0.23751852\n",
      "  0.26568958  0.01433449 -0.35156655  0.29470517 -0.2029574  -0.25129638\n",
      "  0.07588865 -0.435603  ]\n",
      "Training Error:  9.805193225472348\n",
      "====================================================================================================\n",
      "Iteration:  733\n",
      "Previous theta :  [ 0.009244   -0.12206882  0.10374042  0.0118945   0.06353661 -0.23751852\n",
      "  0.26568958  0.01433449 -0.35156655  0.29470517 -0.2029574  -0.25129638\n",
      "  0.07588865 -0.435603  ]\n",
      "New theta_0 : [ 0.0092462  -0.12208953  0.10377521  0.01189737  0.06354469 -0.2376216\n",
      "  0.26566576  0.01434215 -0.35165862  0.29475955 -0.20297458 -0.25131027\n",
      "  0.0758836  -0.43559682]\n",
      "Training Error:  9.805168224342742\n",
      "====================================================================================================\n",
      "Iteration:  734\n",
      "Previous theta :  [ 0.0092462  -0.12208953  0.10377521  0.01189737  0.06354469 -0.2376216\n",
      "  0.26566576  0.01434215 -0.35165862  0.29475955 -0.20297458 -0.25131027\n",
      "  0.0758836  -0.43559682]\n",
      "New theta_0 : [ 0.00924839 -0.12211012  0.10380979  0.01190028  0.06355271 -0.23772409\n",
      "  0.2656421   0.01434977 -0.3517501   0.29481371 -0.20299176 -0.2513241\n",
      "  0.07587859 -0.43559064]\n",
      "Training Error:  9.805143502541135\n",
      "====================================================================================================\n",
      "Iteration:  735\n",
      "Previous theta :  [ 0.00924839 -0.12211012  0.10380979  0.01190028  0.06355271 -0.23772409\n",
      "  0.2656421   0.01434977 -0.3517501   0.29481371 -0.20299176 -0.2513241\n",
      "  0.07587859 -0.43559064]\n",
      "New theta_0 : [ 0.00925056 -0.1221306   0.10384416  0.01190325  0.06356069 -0.23782601\n",
      "  0.26561859  0.01435735 -0.35184102  0.29486766 -0.20300896 -0.25133786\n",
      "  0.07587362 -0.43558448]\n",
      "Training Error:  9.80511905683245\n",
      "====================================================================================================\n",
      "Iteration:  736\n",
      "Previous theta :  [ 0.00925056 -0.1221306   0.10384416  0.01190325  0.06356069 -0.23782601\n",
      "  0.26561859  0.01435735 -0.35184102  0.29486766 -0.20300896 -0.25133786\n",
      "  0.07587362 -0.43558448]\n",
      "New theta_0 : [ 0.00925272 -0.12215097  0.10387832  0.01190628  0.06356861 -0.23792735\n",
      "  0.26559525  0.01436489 -0.35193137  0.29492139 -0.20302617 -0.25135156\n",
      "  0.07586868 -0.43557833]\n",
      "Training Error:  9.805094884019768\n",
      "====================================================================================================\n",
      "Iteration:  737\n",
      "Previous theta :  [ 0.00925272 -0.12215097  0.10387832  0.01190628  0.06356861 -0.23792735\n",
      "  0.26559525  0.01436489 -0.35193137  0.29492139 -0.20302617 -0.25135156\n",
      "  0.07586868 -0.43557833]\n",
      "New theta_0 : [ 0.00925487 -0.12217122  0.10391227  0.01190935  0.06357649 -0.23802813\n",
      "  0.26557205  0.01437238 -0.35202115  0.2949749  -0.20304339 -0.25136518\n",
      "  0.07586377 -0.43557219]\n",
      "Training Error:  9.80507098094389\n",
      "====================================================================================================\n",
      "Iteration:  738\n",
      "Previous theta :  [ 0.00925487 -0.12217122  0.10391227  0.01190935  0.06357649 -0.23802813\n",
      "  0.26557205  0.01437238 -0.35202115  0.2949749  -0.20304339 -0.25136518\n",
      "  0.07586377 -0.43557219]\n",
      "New theta_0 : [ 0.00925701 -0.12219137  0.10394602  0.01191248  0.06358431 -0.23812833\n",
      "  0.26554901  0.01437983 -0.35211036  0.29502821 -0.20306061 -0.25137874\n",
      "  0.0758589  -0.43556606]\n",
      "Training Error:  9.805047344482889\n",
      "====================================================================================================\n",
      "Iteration:  739\n",
      "Previous theta :  [ 0.00925701 -0.12219137  0.10394602  0.01191248  0.06358431 -0.23812833\n",
      "  0.26554901  0.01437983 -0.35211036  0.29502821 -0.20306061 -0.25137874\n",
      "  0.0758589  -0.43556606]\n",
      "New theta_0 : [ 0.00925914 -0.1222114   0.10397956  0.01191566  0.06359209 -0.23822797\n",
      "  0.26552612  0.01438725 -0.35219902  0.2950813  -0.20307785 -0.25139224\n",
      "  0.07585406 -0.43555994]\n",
      "Training Error:  9.805023971551654\n",
      "====================================================================================================\n",
      "Iteration:  740\n",
      "Previous theta :  [ 0.00925914 -0.1222114   0.10397956  0.01191566  0.06359209 -0.23822797\n",
      "  0.26552612  0.01438725 -0.35219902  0.2950813  -0.20307785 -0.25139224\n",
      "  0.07585406 -0.43555994]\n",
      "New theta_0 : [ 0.00926126 -0.12223132  0.10401291  0.01191889  0.06359982 -0.23832705\n",
      "  0.26550338  0.01439462 -0.35228713  0.29513418 -0.20309509 -0.25140567\n",
      "  0.07584926 -0.43555384]\n",
      "Training Error:  9.805000859101447\n",
      "====================================================================================================\n",
      "Iteration:  741\n",
      "Previous theta :  [ 0.00926126 -0.12223132  0.10401291  0.01191889  0.06359982 -0.23832705\n",
      "  0.26550338  0.01439462 -0.35228713  0.29513418 -0.20309509 -0.25140567\n",
      "  0.07584926 -0.43555384]\n",
      "New theta_0 : [ 0.00926336 -0.12225113  0.10404604  0.01192216  0.06360749 -0.23842557\n",
      "  0.2654808   0.01440195 -0.35237468  0.29518685 -0.20311235 -0.25141904\n",
      "  0.07584449 -0.43554774]\n",
      "Training Error:  9.80497800411949\n",
      "====================================================================================================\n",
      "Iteration:  742\n",
      "Previous theta :  [ 0.00926336 -0.12225113  0.10404604  0.01192216  0.06360749 -0.23842557\n",
      "  0.2654808   0.01440195 -0.35237468  0.29518685 -0.20311235 -0.25141904\n",
      "  0.07584449 -0.43554774]\n",
      "New theta_0 : [ 0.00926546 -0.12227083  0.10407898  0.01192549  0.06361512 -0.23852354\n",
      "  0.26545836  0.01440924 -0.35246168  0.29523931 -0.20312961 -0.25143234\n",
      "  0.07583975 -0.43554166]\n",
      "Training Error:  9.804955403628512\n",
      "====================================================================================================\n",
      "Iteration:  743\n",
      "Previous theta :  [ 0.00926546 -0.12227083  0.10407898  0.01192549  0.06361512 -0.23852354\n",
      "  0.26545836  0.01440924 -0.35246168  0.29523931 -0.20312961 -0.25143234\n",
      "  0.07583975 -0.43554166]\n",
      "New theta_0 : [ 0.00926754 -0.12229043  0.10411172  0.01192887  0.0636227  -0.23862096\n",
      "  0.26543606  0.01441649 -0.35254814  0.29529156 -0.20314688 -0.25144558\n",
      "  0.07583505 -0.4355356 ]\n",
      "Training Error:  9.80493305468634\n",
      "====================================================================================================\n",
      "Iteration:  744\n",
      "Previous theta :  [ 0.00926754 -0.12229043  0.10411172  0.01192887  0.0636227  -0.23862096\n",
      "  0.26543606  0.01441649 -0.35254814  0.29529156 -0.20314688 -0.25144558\n",
      "  0.07583505 -0.4355356 ]\n",
      "New theta_0 : [ 0.00926961 -0.12230991  0.10414426  0.01193229  0.06363023 -0.23871782\n",
      "  0.26541392  0.0144237  -0.35263405  0.29534361 -0.20316416 -0.25145875\n",
      "  0.07583038 -0.43552954]\n",
      "Training Error:  9.804910954385479\n",
      "====================================================================================================\n",
      "Iteration:  745\n",
      "Previous theta :  [ 0.00926961 -0.12230991  0.10414426  0.01193229  0.06363023 -0.23871782\n",
      "  0.26541392  0.0144237  -0.35263405  0.29534361 -0.20316416 -0.25145875\n",
      "  0.07583038 -0.43552954]\n",
      "New theta_0 : [ 0.00927167 -0.12232929  0.1041766   0.01193576  0.06363772 -0.23881414\n",
      "  0.26539192  0.01443087 -0.35271943  0.29539545 -0.20318144 -0.25147186\n",
      "  0.07582574 -0.4355235 ]\n",
      "Training Error:  9.80488909985269\n",
      "====================================================================================================\n",
      "Iteration:  746\n",
      "Previous theta :  [ 0.00927167 -0.12232929  0.1041766   0.01193576  0.06363772 -0.23881414\n",
      "  0.26539192  0.01443087 -0.35271943  0.29539545 -0.20318144 -0.25147186\n",
      "  0.07582574 -0.4355235 ]\n",
      "New theta_0 : [ 0.00927372 -0.12234856  0.10420875  0.01193928  0.06364515 -0.23890992\n",
      "  0.26537007  0.014438   -0.35280427  0.29544708 -0.20319873 -0.25148491\n",
      "  0.07582114 -0.43551747]\n",
      "Training Error:  9.80486748824859\n",
      "====================================================================================================\n",
      "Iteration:  747\n",
      "Previous theta :  [ 0.00927372 -0.12234856  0.10420875  0.01193928  0.06364515 -0.23890992\n",
      "  0.26537007  0.014438   -0.35280427  0.29544708 -0.20319873 -0.25148491\n",
      "  0.07582114 -0.43551747]\n",
      "New theta_0 : [ 0.00927575 -0.12236773  0.1042407   0.01194284  0.06365254 -0.23900516\n",
      "  0.26534835  0.01444509 -0.35288858  0.29549851 -0.20321603 -0.25149789\n",
      "  0.07581657 -0.43551145]\n",
      "Training Error:  9.804846116767244\n",
      "====================================================================================================\n",
      "Iteration:  748\n",
      "Previous theta :  [ 0.00927575 -0.12236773  0.1042407   0.01194284  0.06365254 -0.23900516\n",
      "  0.26534835  0.01444509 -0.35288858  0.29549851 -0.20321603 -0.25149789\n",
      "  0.07581657 -0.43551145]\n",
      "New theta_0 : [ 0.00927778 -0.12238679  0.10427246  0.01194645  0.06365988 -0.23909986\n",
      "  0.26532679  0.01445215 -0.35297236  0.29554974 -0.20323334 -0.25151081\n",
      "  0.07581203 -0.43550544]\n",
      "Training Error:  9.804824982635774\n",
      "====================================================================================================\n",
      "Iteration:  749\n",
      "Previous theta :  [ 0.00927778 -0.12238679  0.10427246  0.01194645  0.06365988 -0.23909986\n",
      "  0.26532679  0.01445215 -0.35297236  0.29554974 -0.20323334 -0.25151081\n",
      "  0.07581203 -0.43550544]\n",
      "New theta_0 : [ 0.0092798  -0.12240574  0.10430403  0.0119501   0.06366718 -0.23919402\n",
      "  0.26530536  0.01445916 -0.35305561  0.29560077 -0.20325065 -0.25152367\n",
      "  0.07580752 -0.43549945]\n",
      "Training Error:  9.804804083113945\n",
      "====================================================================================================\n",
      "Iteration:  750\n",
      "Previous theta :  [ 0.0092798  -0.12240574  0.10430403  0.0119501   0.06366718 -0.23919402\n",
      "  0.26530536  0.01445916 -0.35305561  0.29560077 -0.20325065 -0.25152367\n",
      "  0.07580752 -0.43549945]\n",
      "New theta_0 : [ 0.0092818  -0.12242459  0.10433541  0.0119538   0.06367443 -0.23928766\n",
      "  0.26528407  0.01446614 -0.35313835  0.29565159 -0.20326796 -0.25153647\n",
      "  0.07580304 -0.43549347]\n",
      "Training Error:  9.804783415493803\n",
      "====================================================================================================\n",
      "Iteration:  751\n",
      "Previous theta :  [ 0.0092818  -0.12242459  0.10433541  0.0119538   0.06367443 -0.23928766\n",
      "  0.26528407  0.01446614 -0.35313835  0.29565159 -0.20326796 -0.25153647\n",
      "  0.07580304 -0.43549347]\n",
      "New theta_0 : [ 0.00928379 -0.12244333  0.10436659  0.01195754  0.06368163 -0.23938077\n",
      "  0.26526292  0.01447307 -0.35322056  0.29570222 -0.20328529 -0.2515492\n",
      "  0.0757986  -0.43548751]\n",
      "Training Error:  9.80476297709927\n",
      "====================================================================================================\n",
      "Iteration:  752\n",
      "Previous theta :  [ 0.00928379 -0.12244333  0.10436659  0.01195754  0.06368163 -0.23938077\n",
      "  0.26526292  0.01447307 -0.35322056  0.29570222 -0.20328529 -0.2515492\n",
      "  0.0757986  -0.43548751]\n",
      "New theta_0 : [ 0.00928578 -0.12246198  0.10439759  0.01196133  0.06368879 -0.23947335\n",
      "  0.26524191  0.01447997 -0.35330226  0.29575264 -0.20330261 -0.25156188\n",
      "  0.07579418 -0.43548156]\n",
      "Training Error:  9.80474276528577\n",
      "====================================================================================================\n",
      "Iteration:  753\n",
      "Previous theta :  [ 0.00928578 -0.12246198  0.10439759  0.01196133  0.06368879 -0.23947335\n",
      "  0.26524191  0.01447997 -0.35330226  0.29575264 -0.20330261 -0.25156188\n",
      "  0.07579418 -0.43548156]\n",
      "New theta_0 : [ 0.00928775 -0.12248052  0.1044284   0.01196515  0.0636959  -0.23956542\n",
      "  0.26522104  0.01448684 -0.35338345  0.29580287 -0.20331995 -0.25157449\n",
      "  0.0757898  -0.43547562]\n",
      "Training Error:  9.80472277743986\n",
      "====================================================================================================\n",
      "Iteration:  754\n",
      "Previous theta :  [ 0.00928775 -0.12248052  0.1044284   0.01196515  0.0636959  -0.23956542\n",
      "  0.26522104  0.01448684 -0.35338345  0.29580287 -0.20331995 -0.25157449\n",
      "  0.0757898  -0.43547562]\n",
      "New theta_0 : [ 0.00928971 -0.12249895  0.10445902  0.01196902  0.06370297 -0.23965696\n",
      "  0.26520031  0.01449366 -0.35346413  0.2958529  -0.20333729 -0.25158705\n",
      "  0.07578545 -0.4354697 ]\n",
      "Training Error:  9.804703010978846\n",
      "====================================================================================================\n",
      "Iteration:  755\n",
      "Previous theta :  [ 0.00928971 -0.12249895  0.10445902  0.01196902  0.06370297 -0.23965696\n",
      "  0.26520031  0.01449366 -0.35346413  0.2958529  -0.20333729 -0.25158705\n",
      "  0.07578545 -0.4354697 ]\n",
      "New theta_0 : [ 0.00929166 -0.12251729  0.10448946  0.01197293  0.06370999 -0.23974799\n",
      "  0.26517971  0.01450045 -0.3535443   0.29590274 -0.20335463 -0.25159954\n",
      "  0.07578113 -0.43546379]\n",
      "Training Error:  9.80468346335043\n",
      "====================================================================================================\n",
      "Iteration:  756\n",
      "Previous theta :  [ 0.00929166 -0.12251729  0.10448946  0.01197293  0.06370999 -0.23974799\n",
      "  0.26517971  0.01450045 -0.3535443   0.29590274 -0.20335463 -0.25159954\n",
      "  0.07578113 -0.43546379]\n",
      "New theta_0 : [ 0.0092936  -0.12253553  0.10451971  0.01197689  0.06371696 -0.2398385\n",
      "  0.26515924  0.0145072  -0.35362397  0.29595238 -0.20337197 -0.25161197\n",
      "  0.07577684 -0.4354579 ]\n",
      "Training Error:  9.80466413203234\n",
      "====================================================================================================\n",
      "Iteration:  757\n",
      "Previous theta :  [ 0.0092936  -0.12253553  0.10451971  0.01197689  0.06371696 -0.2398385\n",
      "  0.26515924  0.0145072  -0.35362397  0.29595238 -0.20337197 -0.25161197\n",
      "  0.07577684 -0.4354579 ]\n",
      "New theta_0 : [ 0.00929553 -0.12255366  0.10454979  0.01198088  0.06372389 -0.23992851\n",
      "  0.26513891  0.01451391 -0.35370314  0.29600182 -0.20338933 -0.25162435\n",
      "  0.07577258 -0.43545202]\n",
      "Training Error:  9.804645014531971\n",
      "====================================================================================================\n",
      "Iteration:  758\n",
      "Previous theta :  [ 0.00929553 -0.12255366  0.10454979  0.01198088  0.06372389 -0.23992851\n",
      "  0.26513891  0.01451391 -0.35370314  0.29600182 -0.20338933 -0.25162435\n",
      "  0.07577258 -0.43545202]\n",
      "New theta_0 : [ 0.00929745 -0.1225717   0.10457967  0.01198491  0.06373078 -0.24001801\n",
      "  0.26511872  0.01452059 -0.35378181  0.29605108 -0.20340668 -0.25163666\n",
      "  0.07576835 -0.43544615]\n",
      "Training Error:  9.804626108386044\n",
      "====================================================================================================\n",
      "Iteration:  759\n",
      "Previous theta :  [ 0.00929745 -0.1225717   0.10457967  0.01198491  0.06373078 -0.24001801\n",
      "  0.26511872  0.01452059 -0.35378181  0.29605108 -0.20340668 -0.25163666\n",
      "  0.07576835 -0.43544615]\n",
      "New theta_0 : [ 0.00929936 -0.12258963  0.10460938  0.01198898  0.06373762 -0.240107\n",
      "  0.26509865  0.01452723 -0.35385999  0.29610014 -0.20342404 -0.25164892\n",
      "  0.07576415 -0.4354403 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.80460741116024\n",
      "====================================================================================================\n",
      "Iteration:  760\n",
      "Previous theta :  [ 0.00929936 -0.12258963  0.10460938  0.01198898  0.06373762 -0.240107\n",
      "  0.26509865  0.01452723 -0.35385999  0.29610014 -0.20342404 -0.25164892\n",
      "  0.07576415 -0.4354403 ]\n",
      "New theta_0 : [ 0.00930126 -0.12260747  0.10463891  0.0119931   0.06374442 -0.24019549\n",
      "  0.26507871  0.01453384 -0.35393768  0.296149   -0.2034414  -0.25166111\n",
      "  0.07575998 -0.43543446]\n",
      "Training Error:  9.80458892044887\n",
      "====================================================================================================\n",
      "Iteration:  761\n",
      "Previous theta :  [ 0.00930126 -0.12260747  0.10463891  0.0119931   0.06374442 -0.24019549\n",
      "  0.26507871  0.01453384 -0.35393768  0.296149   -0.2034414  -0.25166111\n",
      "  0.07575998 -0.43543446]\n",
      "New theta_0 : [ 0.00930315 -0.12262521  0.10466826  0.01199724  0.06375118 -0.24028348\n",
      "  0.26505891  0.01454041 -0.35401488  0.29619768 -0.20345876 -0.25167325\n",
      "  0.07575584 -0.43542864]\n",
      "Training Error:  9.804570633874514\n",
      "====================================================================================================\n",
      "Iteration:  762\n",
      "Previous theta :  [ 0.00930315 -0.12262521  0.10466826  0.01199724  0.06375118 -0.24028348\n",
      "  0.26505891  0.01454041 -0.35401488  0.29619768 -0.20345876 -0.25167325\n",
      "  0.07575584 -0.43542864]\n",
      "New theta_0 : [ 0.00930502 -0.12264285  0.10469743  0.01200143  0.06375789 -0.24037098\n",
      "  0.26503923  0.01454694 -0.3540916   0.29624617 -0.20347613 -0.25168533\n",
      "  0.07575173 -0.43542283]\n",
      "Training Error:  9.804552549087719\n",
      "====================================================================================================\n",
      "Iteration:  763\n",
      "Previous theta :  [ 0.00930502 -0.12264285  0.10469743  0.01200143  0.06375789 -0.24037098\n",
      "  0.26503923  0.01454694 -0.3540916   0.29624617 -0.20347613 -0.25168533\n",
      "  0.07575173 -0.43542283]\n",
      "New theta_0 : [ 0.00930689 -0.12266039  0.10472643  0.01200566  0.06376456 -0.24045798\n",
      "  0.26501968  0.01455344 -0.35416783  0.29629447 -0.2034935  -0.25169736\n",
      "  0.07574764 -0.43541704]\n",
      "Training Error:  9.804534663766626\n",
      "====================================================================================================\n",
      "Iteration:  764\n",
      "Previous theta :  [ 0.00930689 -0.12266039  0.10472643  0.01200566  0.06376456 -0.24045798\n",
      "  0.26501968  0.01455344 -0.35416783  0.29629447 -0.2034935  -0.25169736\n",
      "  0.07574764 -0.43541704]\n",
      "New theta_0 : [ 0.00930875 -0.12267784  0.10475525  0.01200992  0.06377119 -0.2405445\n",
      "  0.26500026  0.0145599  -0.35424359  0.29634259 -0.20351087 -0.25170932\n",
      "  0.07574359 -0.43541126]\n",
      "Training Error:  9.804516975616673\n",
      "====================================================================================================\n",
      "Iteration:  765\n",
      "Previous theta :  [ 0.00930875 -0.12267784  0.10475525  0.01200992  0.06377119 -0.2405445\n",
      "  0.26500026  0.0145599  -0.35424359  0.29634259 -0.20351087 -0.25170932\n",
      "  0.07574359 -0.43541126]\n",
      "New theta_0 : [ 0.00931059 -0.12269519  0.1047839   0.01201422  0.06377777 -0.24063052\n",
      "  0.26498097  0.01456633 -0.35431887  0.29639051 -0.20352824 -0.25172123\n",
      "  0.07573956 -0.4354055 ]\n",
      "Training Error:  9.804499482370254\n",
      "====================================================================================================\n",
      "Iteration:  766\n",
      "Previous theta :  [ 0.00931059 -0.12269519  0.1047839   0.01201422  0.06377777 -0.24063052\n",
      "  0.26498097  0.01456633 -0.35431887  0.29639051 -0.20352824 -0.25172123\n",
      "  0.07573956 -0.4354055 ]\n",
      "New theta_0 : [ 0.00931243 -0.12271245  0.10481237  0.01201855  0.06378432 -0.24071606\n",
      "  0.2649618   0.01457272 -0.35439368  0.29643825 -0.20354562 -0.25173308\n",
      "  0.07573557 -0.43539975]\n",
      "Training Error:  9.8044821817864\n",
      "====================================================================================================\n",
      "Iteration:  767\n",
      "Previous theta :  [ 0.00931243 -0.12271245  0.10481237  0.01201855  0.06378432 -0.24071606\n",
      "  0.2649618   0.01457272 -0.35439368  0.29643825 -0.20354562 -0.25173308\n",
      "  0.07573557 -0.43539975]\n",
      "New theta_0 : [ 0.00931426 -0.12272961  0.10484067  0.01202292  0.06379082 -0.24080112\n",
      "  0.26494275  0.01457908 -0.35446802  0.29648581 -0.20356299 -0.25174487\n",
      "  0.0757316  -0.43539402]\n",
      "Training Error:  9.804465071650466\n",
      "====================================================================================================\n",
      "Iteration:  768\n",
      "Previous theta :  [ 0.00931426 -0.12272961  0.10484067  0.01202292  0.06379082 -0.24080112\n",
      "  0.26494275  0.01457908 -0.35446802  0.29648581 -0.20356299 -0.25174487\n",
      "  0.0757316  -0.43539402]\n",
      "New theta_0 : [ 0.00931607 -0.12274668  0.1048688   0.01202732  0.06379727 -0.2408857\n",
      "  0.26492383  0.0145854  -0.3545419   0.29653318 -0.20358037 -0.25175661\n",
      "  0.07572766 -0.4353883 ]\n",
      "Training Error:  9.804448149773819\n",
      "====================================================================================================\n",
      "Iteration:  769\n",
      "Previous theta :  [ 0.00931607 -0.12274668  0.1048688   0.01202732  0.06379727 -0.2408857\n",
      "  0.26492383  0.0145854  -0.3545419   0.29653318 -0.20358037 -0.25175661\n",
      "  0.07572766 -0.4353883 ]\n",
      "New theta_0 : [ 0.00931788 -0.12276365  0.10489676  0.01203176  0.06380369 -0.2409698\n",
      "  0.26490503  0.01459169 -0.35461531  0.29658037 -0.20359775 -0.25176829\n",
      "  0.07572375 -0.4353826 ]\n",
      "Training Error:  9.804431413993523\n",
      "====================================================================================================\n",
      "Iteration:  770\n",
      "Previous theta :  [ 0.00931788 -0.12276365  0.10489676  0.01203176  0.06380369 -0.2409698\n",
      "  0.26490503  0.01459169 -0.35461531  0.29658037 -0.20359775 -0.25176829\n",
      "  0.07572375 -0.4353826 ]\n",
      "New theta_0 : [ 0.00931968 -0.12278054  0.10492456  0.01203623  0.06381007 -0.24105343\n",
      "  0.26488635  0.01459795 -0.35468826  0.29662737 -0.20361513 -0.25177992\n",
      "  0.07571986 -0.43537692]\n",
      "Training Error:  9.804414862172042\n",
      "====================================================================================================\n",
      "Iteration:  771\n",
      "Previous theta :  [ 0.00931968 -0.12278054  0.10492456  0.01203623  0.06381007 -0.24105343\n",
      "  0.26488635  0.01459795 -0.35468826  0.29662737 -0.20361513 -0.25177992\n",
      "  0.07571986 -0.43537692]\n",
      "New theta_0 : [ 0.00932147 -0.12279732  0.10495218  0.01204074  0.0638164  -0.24113659\n",
      "  0.2648678   0.01460417 -0.35476075  0.2966742  -0.20363251 -0.25179149\n",
      "  0.075716   -0.43537125]\n",
      "Training Error:  9.804398492196922\n",
      "====================================================================================================\n",
      "Iteration:  772\n",
      "Previous theta :  [ 0.00932147 -0.12279732  0.10495218  0.01204074  0.0638164  -0.24113659\n",
      "  0.2648678   0.01460417 -0.35476075  0.2966742  -0.20363251 -0.25179149\n",
      "  0.075716   -0.43537125]\n",
      "New theta_0 : [ 0.00932324 -0.12281402  0.10497964  0.01204528  0.0638227  -0.24121928\n",
      "  0.26484936  0.01461036 -0.35483279  0.29672084 -0.20364989 -0.25180301\n",
      "  0.07571217 -0.43536559]\n",
      "Training Error:  9.804382301980517\n",
      "====================================================================================================\n",
      "Iteration:  773\n",
      "Previous theta :  [ 0.00932324 -0.12281402  0.10497964  0.01204528  0.0638227  -0.24121928\n",
      "  0.26484936  0.01461036 -0.35483279  0.29672084 -0.20364989 -0.25180301\n",
      "  0.07571217 -0.43536559]\n",
      "New theta_0 : [ 0.00932501 -0.12283062  0.10500693  0.01204985  0.06382895 -0.2413015\n",
      "  0.26483104  0.01461651 -0.35490437  0.2967673  -0.20366727 -0.25181447\n",
      "  0.07570837 -0.43535995]\n",
      "Training Error:  9.80436628945967\n",
      "====================================================================================================\n",
      "Iteration:  774\n",
      "Previous theta :  [ 0.00932501 -0.12283062  0.10500693  0.01204985  0.06382895 -0.2413015\n",
      "  0.26483104  0.01461651 -0.35490437  0.2967673  -0.20366727 -0.25181447\n",
      "  0.07570837 -0.43535995]\n",
      "New theta_0 : [ 0.00932677 -0.12284714  0.10503406  0.01205445  0.06383516 -0.24138326\n",
      "  0.26481285  0.01462264 -0.35497551  0.29681359 -0.20368464 -0.25182587\n",
      "  0.07570459 -0.43535433]\n",
      "Training Error:  9.804350452595436\n",
      "====================================================================================================\n",
      "Iteration:  775\n",
      "Previous theta :  [ 0.00932677 -0.12284714  0.10503406  0.01205445  0.06383516 -0.24138326\n",
      "  0.26481285  0.01462264 -0.35497551  0.29681359 -0.20368464 -0.25182587\n",
      "  0.07570459 -0.43535433]\n",
      "New theta_0 : [ 0.00932852 -0.12286356  0.10506102  0.01205909  0.06384134 -0.24146455\n",
      "  0.26479477  0.01462872 -0.3550462   0.2968597  -0.20370202 -0.25183722\n",
      "  0.07570085 -0.43534873]\n",
      "Training Error:  9.804334789372794\n",
      "====================================================================================================\n",
      "Iteration:  776\n",
      "Previous theta :  [ 0.00932852 -0.12286356  0.10506102  0.01205909  0.06384134 -0.24146455\n",
      "  0.26479477  0.01462872 -0.3550462   0.2968597  -0.20370202 -0.25183722\n",
      "  0.07570085 -0.43534873]\n",
      "New theta_0 : [ 0.00933026 -0.12287989  0.10508782  0.01206376  0.06384747 -0.24154539\n",
      "  0.2647768   0.01463478 -0.35511644  0.29690563 -0.2037194  -0.25184852\n",
      "  0.07569712 -0.43534314]\n",
      "Training Error:  9.804319297800351\n",
      "====================================================================================================\n",
      "Iteration:  777\n",
      "Previous theta :  [ 0.00933026 -0.12287989  0.10508782  0.01206376  0.06384747 -0.24154539\n",
      "  0.2647768   0.01463478 -0.35511644  0.29690563 -0.2037194  -0.25184852\n",
      "  0.07569712 -0.43534314]\n",
      "New theta_0 : [ 0.00933198 -0.12289614  0.10511446  0.01206845  0.06385357 -0.24162578\n",
      "  0.26475895  0.0146408  -0.35518624  0.29695138 -0.20373678 -0.25185976\n",
      "  0.07569343 -0.43533756]\n",
      "Training Error:  9.804303975910079\n",
      "====================================================================================================\n",
      "Iteration:  778\n",
      "Previous theta :  [ 0.00933198 -0.12289614  0.10511446  0.01206845  0.06385357 -0.24162578\n",
      "  0.26475895  0.0146408  -0.35518624  0.29695138 -0.20373678 -0.25185976\n",
      "  0.07569343 -0.43533756]\n",
      "New theta_0 : [ 0.0093337  -0.12291229  0.10514094  0.01207318  0.06385962 -0.24170571\n",
      "  0.26474122  0.0146468  -0.35525561  0.29699696 -0.20375416 -0.25187095\n",
      "  0.07568976 -0.435332  ]\n",
      "Training Error:  9.804288821757021\n",
      "====================================================================================================\n",
      "Iteration:  779\n",
      "Previous theta :  [ 0.0093337  -0.12291229  0.10514094  0.01207318  0.06385962 -0.24170571\n",
      "  0.26474122  0.0146468  -0.35525561  0.29699696 -0.20375416 -0.25187095\n",
      "  0.07568976 -0.435332  ]\n",
      "New theta_0 : [ 0.00933541 -0.12292836  0.10516725  0.01207794  0.06386564 -0.24178518\n",
      "  0.2647236   0.01465276 -0.35532454  0.29704236 -0.20377153 -0.25188209\n",
      "  0.07568611 -0.43532646]\n",
      "Training Error:  9.804273833419032\n",
      "====================================================================================================\n",
      "Iteration:  780\n",
      "Previous theta :  [ 0.00933541 -0.12292836  0.10516725  0.01207794  0.06386564 -0.24178518\n",
      "  0.2647236   0.01465276 -0.35532454  0.29704236 -0.20377153 -0.25188209\n",
      "  0.07568611 -0.43532646]\n",
      "New theta_0 : [ 0.00933711 -0.12294433  0.10519341  0.01208273  0.06387161 -0.24186422\n",
      "  0.2647061   0.01465868 -0.35539304  0.29708759 -0.2037889  -0.25189318\n",
      "  0.07568249 -0.43532094]\n",
      "Training Error:  9.80425900899649\n",
      "====================================================================================================\n",
      "Iteration:  781\n",
      "Previous theta :  [ 0.00933711 -0.12294433  0.10519341  0.01208273  0.06387161 -0.24186422\n",
      "  0.2647061   0.01465868 -0.35539304  0.29708759 -0.2037889  -0.25189318\n",
      "  0.07568249 -0.43532094]\n",
      "New theta_0 : [ 0.00933881 -0.12296023  0.10521942  0.01208754  0.06387755 -0.2419428\n",
      "  0.26468871  0.01466458 -0.3554611   0.29713265 -0.20380627 -0.25190421\n",
      "  0.0756789  -0.43531543]\n",
      "Training Error:  9.804244346612055\n",
      "====================================================================================================\n",
      "Iteration:  782\n",
      "Previous theta :  [ 0.00933881 -0.12296023  0.10521942  0.01208754  0.06387755 -0.2419428\n",
      "  0.26468871  0.01466458 -0.3554611   0.29713265 -0.20380627 -0.25190421\n",
      "  0.0756789  -0.43531543]\n",
      "New theta_0 : [ 0.00934049 -0.12297603  0.10524526  0.01209239  0.06388345 -0.24202094\n",
      "  0.26467143  0.01467044 -0.35552874  0.29717753 -0.20382364 -0.25191519\n",
      "  0.07567533 -0.43530994]\n",
      "Training Error:  9.804229844410367\n",
      "====================================================================================================\n",
      "Iteration:  783\n",
      "Previous theta :  [ 0.00934049 -0.12297603  0.10524526  0.01209239  0.06388345 -0.24202094\n",
      "  0.26467143  0.01467044 -0.35552874  0.29717753 -0.20382364 -0.25191519\n",
      "  0.07567533 -0.43530994]\n",
      "New theta_0 : [ 0.00934216 -0.12299175  0.10527095  0.01209726  0.06388931 -0.24209865\n",
      "  0.26465426  0.01467627 -0.35559596  0.29722225 -0.20384101 -0.25192611\n",
      "  0.07567179 -0.43530446]\n",
      "Training Error:  9.804215500557824\n",
      "====================================================================================================\n",
      "Iteration:  784\n",
      "Previous theta :  [ 0.00934216 -0.12299175  0.10527095  0.01209726  0.06388931 -0.24209865\n",
      "  0.26465426  0.01467627 -0.35559596  0.29722225 -0.20384101 -0.25192611\n",
      "  0.07567179 -0.43530446]\n",
      "New theta_0 : [ 0.00934382 -0.12300738  0.10529648  0.01210216  0.06389514 -0.24217591\n",
      "  0.2646372   0.01468208 -0.35566275  0.29726679 -0.20385837 -0.25193699\n",
      "  0.07566828 -0.435299  ]\n",
      "Training Error:  9.804201313242299\n",
      "====================================================================================================\n",
      "Iteration:  785\n",
      "Previous theta :  [ 0.00934382 -0.12300738  0.10529648  0.01210216  0.06389514 -0.24217591\n",
      "  0.2646372   0.01468208 -0.35566275  0.29726679 -0.20385837 -0.25193699\n",
      "  0.07566828 -0.435299  ]\n",
      "New theta_0 : [ 0.00934548 -0.12302292  0.10532186  0.01210709  0.06390092 -0.24225274\n",
      "  0.26462026  0.01468785 -0.35572912  0.29731117 -0.20387574 -0.25194781\n",
      "  0.07566479 -0.43529356]\n",
      "Training Error:  9.804187280672888\n",
      "====================================================================================================\n",
      "Iteration:  786\n",
      "Previous theta :  [ 0.00934548 -0.12302292  0.10532186  0.01210709  0.06390092 -0.24225274\n",
      "  0.26462026  0.01468785 -0.35572912  0.29731117 -0.20387574 -0.25194781\n",
      "  0.07566479 -0.43529356]\n",
      "New theta_0 : [ 0.00934712 -0.12303838  0.10534709  0.01211204  0.06390667 -0.24232913\n",
      "  0.26460342  0.01469359 -0.35579507  0.29735537 -0.20389309 -0.25195858\n",
      "  0.07566132 -0.43528813]\n",
      "Training Error:  9.80417340107967\n",
      "====================================================================================================\n",
      "Iteration:  787\n",
      "Previous theta :  [ 0.00934712 -0.12303838  0.10534709  0.01211204  0.06390667 -0.24232913\n",
      "  0.26460342  0.01469359 -0.35579507  0.29735537 -0.20389309 -0.25195858\n",
      "  0.07566132 -0.43528813]\n",
      "New theta_0 : [ 0.00934876 -0.12305376  0.10537217  0.01211703  0.06391239 -0.2424051\n",
      "  0.26458669  0.01469929 -0.35586062  0.29739941 -0.20391045 -0.2519693\n",
      "  0.07565788 -0.43528272]\n",
      "Training Error:  9.804159672713444\n",
      "====================================================================================================\n",
      "Iteration:  788\n",
      "Previous theta :  [ 0.00934876 -0.12305376  0.10537217  0.01211703  0.06391239 -0.2424051\n",
      "  0.26458669  0.01469929 -0.35586062  0.29739941 -0.20391045 -0.2519693\n",
      "  0.07565788 -0.43528272]\n",
      "New theta_0 : [ 0.00935039 -0.12306905  0.10539709  0.01212203  0.06391806 -0.24248063\n",
      "  0.26457006  0.01470497 -0.35592574  0.29744328 -0.2039278  -0.25197997\n",
      "  0.07565446 -0.43527733]\n",
      "Training Error:  9.8041460938455\n",
      "====================================================================================================\n",
      "Iteration:  789\n",
      "Previous theta :  [ 0.00935039 -0.12306905  0.10539709  0.01212203  0.06391806 -0.24248063\n",
      "  0.26457006  0.01470497 -0.35592574  0.29744328 -0.2039278  -0.25197997\n",
      "  0.07565446 -0.43527733]\n",
      "New theta_0 : [ 0.00935201 -0.12308426  0.10542187  0.01212707  0.0639237  -0.24255574\n",
      "  0.26455355  0.01471062 -0.35599046  0.29748698 -0.20394515 -0.25199059\n",
      "  0.07565107 -0.43527196]\n",
      "Training Error:  9.804132662767355\n",
      "====================================================================================================\n",
      "Iteration:  790\n",
      "Previous theta :  [ 0.00935201 -0.12308426  0.10542187  0.01212707  0.0639237  -0.24255574\n",
      "  0.26455355  0.01471062 -0.35599046  0.29748698 -0.20394515 -0.25199059\n",
      "  0.07565107 -0.43527196]\n",
      "New theta_0 : [ 0.00935361 -0.12309938  0.10544649  0.01213213  0.0639293  -0.24263043\n",
      "  0.26453713  0.01471624 -0.35605478  0.29753052 -0.2039625  -0.25200116\n",
      "  0.0756477  -0.4352666 ]\n",
      "Training Error:  9.80411937779052\n",
      "====================================================================================================\n",
      "Iteration:  791\n",
      "Previous theta :  [ 0.00935361 -0.12309938  0.10544649  0.01213213  0.0639293  -0.24263043\n",
      "  0.26453713  0.01471624 -0.35605478  0.29753052 -0.2039625  -0.25200116\n",
      "  0.0756477  -0.4352666 ]\n",
      "New theta_0 : [ 0.00935521 -0.12311442  0.10547097  0.01213721  0.06393487 -0.24270469\n",
      "  0.26452083  0.01472183 -0.35611869  0.29757389 -0.20397984 -0.25201168\n",
      "  0.07564435 -0.43526125]\n",
      "Training Error:  9.80410623724628\n",
      "====================================================================================================\n",
      "Iteration:  792\n",
      "Previous theta :  [ 0.00935521 -0.12311442  0.10547097  0.01213721  0.06393487 -0.24270469\n",
      "  0.26452083  0.01472183 -0.35611869  0.29757389 -0.20397984 -0.25201168\n",
      "  0.07564435 -0.43526125]\n",
      "New theta_0 : [ 0.00935681 -0.12312938  0.1054953   0.01214232  0.06394039 -0.24277854\n",
      "  0.26450463  0.01472739 -0.35618219  0.2976171  -0.20399717 -0.25202214\n",
      "  0.07564103 -0.43525593]\n",
      "Training Error:  9.804093239485432\n",
      "====================================================================================================\n",
      "Iteration:  793\n",
      "Previous theta :  [ 0.00935681 -0.12312938  0.1054953   0.01214232  0.06394039 -0.24277854\n",
      "  0.26450463  0.01472739 -0.35618219  0.2976171  -0.20399717 -0.25202214\n",
      "  0.07564103 -0.43525593]\n",
      "New theta_0 : [ 0.00935839 -0.12314426  0.10551948  0.01214745  0.06394589 -0.24285197\n",
      "  0.26448853  0.01473292 -0.3562453   0.29766014 -0.20401451 -0.25203256\n",
      "  0.07563773 -0.43525062]\n",
      "Training Error:  9.804080382878078\n",
      "====================================================================================================\n",
      "Iteration:  794\n",
      "Previous theta :  [ 0.00935839 -0.12314426  0.10551948  0.01214745  0.06394589 -0.24285197\n",
      "  0.26448853  0.01473292 -0.3562453   0.29766014 -0.20401451 -0.25203256\n",
      "  0.07563773 -0.43525062]\n",
      "New theta_0 : [ 0.00935996 -0.12315906  0.10554352  0.01215261  0.06395135 -0.24292498\n",
      "  0.26447254  0.01473842 -0.35630801  0.29770302 -0.20403184 -0.25204293\n",
      "  0.07563446 -0.43524533]\n",
      "Training Error:  9.804067665813381\n",
      "====================================================================================================\n",
      "Iteration:  795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous theta :  [ 0.00935996 -0.12315906  0.10554352  0.01215261  0.06395135 -0.24292498\n",
      "  0.26447254  0.01473842 -0.35630801  0.29770302 -0.20403184 -0.25204293\n",
      "  0.07563446 -0.43524533]\n",
      "New theta_0 : [ 0.00936153 -0.12317377  0.10556741  0.01215779  0.06395677 -0.24299759\n",
      "  0.26445664  0.01474389 -0.35637033  0.29774575 -0.20404916 -0.25205325\n",
      "  0.07563121 -0.43524006]\n",
      "Training Error:  9.804055086699343\n",
      "====================================================================================================\n",
      "Iteration:  796\n",
      "Previous theta :  [ 0.00936153 -0.12317377  0.10556741  0.01215779  0.06395677 -0.24299759\n",
      "  0.26445664  0.01474389 -0.35637033  0.29774575 -0.20404916 -0.25205325\n",
      "  0.07563121 -0.43524006]\n",
      "New theta_0 : [ 0.00936308 -0.12318841  0.10559116  0.012163    0.06396215 -0.24306978\n",
      "  0.26444085  0.01474933 -0.35643226  0.2977883  -0.20406648 -0.25206352\n",
      "  0.07562798 -0.4352348 ]\n",
      "Training Error:  9.804042643962578\n",
      "====================================================================================================\n",
      "Iteration:  797\n",
      "Previous theta :  [ 0.00936308 -0.12318841  0.10559116  0.012163    0.06396215 -0.24306978\n",
      "  0.26444085  0.01474933 -0.35643226  0.2977883  -0.20406648 -0.25206352\n",
      "  0.07562798 -0.4352348 ]\n",
      "New theta_0 : [ 0.00936463 -0.12320296  0.10561476  0.01216822  0.06396751 -0.24314157\n",
      "  0.26442516  0.01475474 -0.35649379  0.2978307  -0.20408379 -0.25207375\n",
      "  0.07562478 -0.43522956]\n",
      "Training Error:  9.804030336048108\n",
      "====================================================================================================\n",
      "Iteration:  798\n",
      "Previous theta :  [ 0.00936463 -0.12320296  0.10561476  0.01216822  0.06396751 -0.24314157\n",
      "  0.26442516  0.01475474 -0.35649379  0.2978307  -0.20408379 -0.25207375\n",
      "  0.07562478 -0.43522956]\n",
      "New theta_0 : [ 0.00936617 -0.12321744  0.10563823  0.01217347  0.06397282 -0.24321295\n",
      "  0.26440957  0.01476013 -0.35655494  0.29787294 -0.2041011  -0.25208392\n",
      "  0.0756216  -0.43522434]\n",
      "Training Error:  9.804018161419119\n",
      "====================================================================================================\n",
      "Iteration:  799\n",
      "Previous theta :  [ 0.00936617 -0.12321744  0.10563823  0.01217347  0.06397282 -0.24321295\n",
      "  0.26440957  0.01476013 -0.35655494  0.29787294 -0.2041011  -0.25208392\n",
      "  0.0756216  -0.43522434]\n",
      "New theta_0 : [ 0.0093677  -0.12323184  0.10566155  0.01217874  0.06397811 -0.24328393\n",
      "  0.26439408  0.01476548 -0.35661571  0.29791502 -0.2041184  -0.25209405\n",
      "  0.07561844 -0.43521913]\n",
      "Training Error:  9.804006118556767\n",
      "====================================================================================================\n",
      "Iteration:  800\n",
      "Previous theta :  [ 0.0093677  -0.12323184  0.10566155  0.01217874  0.06397811 -0.24328393\n",
      "  0.26439408  0.01476548 -0.35661571  0.29791502 -0.2041184  -0.25209405\n",
      "  0.07561844 -0.43521913]\n",
      "New theta_0 : [ 0.00936922 -0.12324616  0.10568473  0.01218403  0.06398335 -0.24335451\n",
      "  0.26437869  0.01477081 -0.35667609  0.29795695 -0.2041357  -0.25210413\n",
      "  0.0756153  -0.43521395]\n",
      "Training Error:  9.80399420595996\n",
      "====================================================================================================\n",
      "Iteration:  801\n",
      "Previous theta :  [ 0.00936922 -0.12324616  0.10568473  0.01218403  0.06398335 -0.24335451\n",
      "  0.26437869  0.01477081 -0.35667609  0.29795695 -0.2041357  -0.25210413\n",
      "  0.0756153  -0.43521395]\n",
      "New theta_0 : [ 0.00937074 -0.1232604   0.10570778  0.01218935  0.06398857 -0.24342469\n",
      "  0.2643634   0.01477611 -0.35673609  0.29799871 -0.20415299 -0.25211416\n",
      "  0.07561219 -0.43520878]\n",
      "Training Error:  9.803982422145129\n",
      "====================================================================================================\n",
      "Iteration:  802\n",
      "Previous theta :  [ 0.00937074 -0.1232604   0.10570778  0.01218935  0.06398857 -0.24342469\n",
      "  0.2643634   0.01477611 -0.35673609  0.29799871 -0.20415299 -0.25211416\n",
      "  0.07561219 -0.43520878]\n",
      "New theta_0 : [ 0.00937224 -0.12327456  0.10573068  0.01219468  0.06399375 -0.24349448\n",
      "  0.2643482   0.01478138 -0.35679572  0.29804032 -0.20417027 -0.25212414\n",
      "  0.07560909 -0.43520362]\n",
      "Training Error:  9.803970765646056\n",
      "====================================================================================================\n",
      "Iteration:  803\n",
      "Previous theta :  [ 0.00937224 -0.12327456  0.10573068  0.01219468  0.06399375 -0.24349448\n",
      "  0.2643482   0.01478138 -0.35679572  0.29804032 -0.20417027 -0.25212414\n",
      "  0.07560909 -0.43520362]\n",
      "New theta_0 : [ 0.00937374 -0.12328865  0.10575345  0.01220004  0.06399889 -0.24356387\n",
      "  0.26433311  0.01478662 -0.35685497  0.29808177 -0.20418755 -0.25213408\n",
      "  0.07560603 -0.43519849]\n",
      "Training Error:  9.803959235013643\n",
      "====================================================================================================\n",
      "Iteration:  804\n",
      "Previous theta :  [ 0.00937374 -0.12328865  0.10575345  0.01220004  0.06399889 -0.24356387\n",
      "  0.26433311  0.01478662 -0.35685497  0.29808177 -0.20418755 -0.25213408\n",
      "  0.07560603 -0.43519849]\n",
      "New theta_0 : [ 0.00937523 -0.12330266  0.10577608  0.01220542  0.06400401 -0.24363287\n",
      "  0.2643181   0.01479184 -0.35691384  0.29812307 -0.20420483 -0.25214396\n",
      "  0.07560298 -0.43519337]\n",
      "Training Error:  9.803947828815701\n",
      "====================================================================================================\n",
      "Iteration:  805\n",
      "Previous theta :  [ 0.00937523 -0.12330266  0.10577608  0.01220542  0.06400401 -0.24363287\n",
      "  0.2643181   0.01479184 -0.35691384  0.29812307 -0.20420483 -0.25214396\n",
      "  0.07560298 -0.43519337]\n",
      "New theta_0 : [ 0.00937671 -0.12331659  0.10579858  0.01221081  0.06400909 -0.24370148\n",
      "  0.2643032   0.01479703 -0.35697235  0.29816421 -0.20422209 -0.25215381\n",
      "  0.07559995 -0.43518827]\n",
      "Training Error:  9.803936545636788\n",
      "====================================================================================================\n",
      "Iteration:  806\n",
      "Previous theta :  [ 0.00937671 -0.12331659  0.10579858  0.01221081  0.06400909 -0.24370148\n",
      "  0.2643032   0.01479703 -0.35697235  0.29816421 -0.20422209 -0.25215381\n",
      "  0.07559995 -0.43518827]\n",
      "New theta_0 : [ 0.00937818 -0.12333045  0.10582094  0.01221623  0.06401413 -0.24376971\n",
      "  0.26428838  0.01480219 -0.35703049  0.2982052  -0.20423935 -0.2521636\n",
      "  0.07559695 -0.43518318]\n",
      "Training Error:  9.803925384077969\n",
      "====================================================================================================\n",
      "Iteration:  807\n",
      "Previous theta :  [ 0.00937818 -0.12333045  0.10582094  0.01221623  0.06401413 -0.24376971\n",
      "  0.26428838  0.01480219 -0.35703049  0.2982052  -0.20423935 -0.2521636\n",
      "  0.07559695 -0.43518318]\n",
      "New theta_0 : [ 0.00937964 -0.12334423  0.10584316  0.01222166  0.06401914 -0.24383755\n",
      "  0.26427366  0.01480733 -0.35708826  0.29824604 -0.2042566  -0.25217335\n",
      "  0.07559397 -0.43517812]\n",
      "Training Error:  9.80391434275664\n",
      "====================================================================================================\n",
      "Iteration:  808\n",
      "Previous theta :  [ 0.00937964 -0.12334423  0.10584316  0.01222166  0.06401914 -0.24383755\n",
      "  0.26427366  0.01480733 -0.35708826  0.29824604 -0.2042566  -0.25217335\n",
      "  0.07559397 -0.43517812]\n",
      "New theta_0 : [ 0.0093811  -0.12335793  0.10586525  0.01222712  0.06402412 -0.243905\n",
      "  0.26425904  0.01481243 -0.35714567  0.29828672 -0.20427385 -0.25218306\n",
      "  0.075591   -0.43517307]\n",
      "Training Error:  9.80390342030634\n",
      "====================================================================================================\n",
      "Iteration:  809\n",
      "Previous theta :  [ 0.0093811  -0.12335793  0.10586525  0.01222712  0.06402412 -0.243905\n",
      "  0.26425904  0.01481243 -0.35714567  0.29828672 -0.20427385 -0.25218306\n",
      "  0.075591   -0.43517307]\n",
      "New theta_0 : [ 0.00938255 -0.12337157  0.10588721  0.01223259  0.06402907 -0.24397208\n",
      "  0.26424451  0.01481752 -0.35720272  0.29832726 -0.20429108 -0.25219271\n",
      "  0.07558806 -0.43516804]\n",
      "Training Error:  9.80389261537655\n",
      "====================================================================================================\n",
      "Iteration:  810\n",
      "Previous theta :  [ 0.00938255 -0.12337157  0.10588721  0.01223259  0.06402907 -0.24397208\n",
      "  0.26424451  0.01481752 -0.35720272  0.29832726 -0.20429108 -0.25219271\n",
      "  0.07558806 -0.43516804]\n",
      "New theta_0 : [ 0.00938399 -0.12338512  0.10590904  0.01223808  0.06403399 -0.24403878\n",
      "  0.26423007  0.01482257 -0.35725941  0.29836764 -0.20430831 -0.25220232\n",
      "  0.07558515 -0.43516302]\n",
      "Training Error:  9.803881926632506\n",
      "====================================================================================================\n",
      "Iteration:  811\n",
      "Previous theta :  [ 0.00938399 -0.12338512  0.10590904  0.01223808  0.06403399 -0.24403878\n",
      "  0.26423007  0.01482257 -0.35725941  0.29836764 -0.20430831 -0.25220232\n",
      "  0.07558515 -0.43516302]\n",
      "New theta_0 : [ 0.00938542 -0.12339861  0.10593074  0.01224359  0.06403887 -0.2441051\n",
      "  0.26421572  0.0148276  -0.35731574  0.29840787 -0.20432554 -0.25221189\n",
      "  0.07558225 -0.43515803]\n",
      "Training Error:  9.803871352755014\n",
      "====================================================================================================\n",
      "Iteration:  812\n",
      "Previous theta :  [ 0.00938542 -0.12339861  0.10593074  0.01224359  0.06403887 -0.2441051\n",
      "  0.26421572  0.0148276  -0.35731574  0.29840787 -0.20432554 -0.25221189\n",
      "  0.07558225 -0.43515803]\n",
      "New theta_0 : [ 0.00938684 -0.12341202  0.1059523   0.01224912  0.06404372 -0.24417105\n",
      "  0.26420146  0.0148326  -0.35737172  0.29844795 -0.20434275 -0.25222141\n",
      "  0.07557937 -0.43515305]\n",
      "Training Error:  9.80386089244026\n",
      "====================================================================================================\n",
      "Iteration:  813\n",
      "Previous theta :  [ 0.00938684 -0.12341202  0.1059523   0.01224912  0.06404372 -0.24417105\n",
      "  0.26420146  0.0148326  -0.35737172  0.29844795 -0.20434275 -0.25222141\n",
      "  0.07557937 -0.43515305]\n",
      "New theta_0 : [ 0.00938826 -0.12342536  0.10597374  0.01225466  0.06404854 -0.24423663\n",
      "  0.26418729  0.01483758 -0.35742735  0.29848788 -0.20435996 -0.25223089\n",
      "  0.07557651 -0.43514809]\n",
      "Training Error:  9.803850544399646\n",
      "====================================================================================================\n",
      "Iteration:  814\n",
      "Previous theta :  [ 0.00938826 -0.12342536  0.10597374  0.01225466  0.06404854 -0.24423663\n",
      "  0.26418729  0.01483758 -0.35742735  0.29848788 -0.20435996 -0.25223089\n",
      "  0.07557651 -0.43514809]\n",
      "New theta_0 : [ 0.00938966 -0.12343862  0.10599505  0.01226023  0.06405333 -0.24430183\n",
      "  0.26417322  0.01484252 -0.35748262  0.29852767 -0.20437716 -0.25224032\n",
      "  0.07557368 -0.43514314]\n",
      "Training Error:  9.80384030735959\n",
      "====================================================================================================\n",
      "Iteration:  815\n",
      "Previous theta :  [ 0.00938966 -0.12343862  0.10599505  0.01226023  0.06405333 -0.24430183\n",
      "  0.26417322  0.01484252 -0.35748262  0.29852767 -0.20437716 -0.25224032\n",
      "  0.07557368 -0.43514314]\n",
      "New theta_0 : [ 0.00939106 -0.12345182  0.10601623  0.0122658   0.06405808 -0.24436667\n",
      "  0.26415923  0.01484745 -0.35753755  0.29856731 -0.20439435 -0.25224971\n",
      "  0.07557086 -0.43513822]\n",
      "Training Error:  9.803830180061352\n",
      "====================================================================================================\n",
      "Iteration:  816\n",
      "Previous theta :  [ 0.00939106 -0.12345182  0.10601623  0.0122658   0.06405808 -0.24436667\n",
      "  0.26415923  0.01484745 -0.35753755  0.29856731 -0.20439435 -0.25224971\n",
      "  0.07557086 -0.43513822]\n",
      "New theta_0 : [ 0.00939246 -0.12346494  0.10603728  0.0122714   0.06406281 -0.24443114\n",
      "  0.26414533  0.01485235 -0.35759213  0.2986068  -0.20441153 -0.25225905\n",
      "  0.07556807 -0.43513331]\n",
      "Training Error:  9.803820161260873\n",
      "====================================================================================================\n",
      "Iteration:  817\n",
      "Previous theta :  [ 0.00939246 -0.12346494  0.10603728  0.0122714   0.06406281 -0.24443114\n",
      "  0.26414533  0.01485235 -0.35759213  0.2986068  -0.20441153 -0.25225905\n",
      "  0.07556807 -0.43513331]\n",
      "New theta_0 : [ 0.00939384 -0.12347799  0.10605821  0.01227701  0.0640675  -0.24449525\n",
      "  0.26413152  0.01485722 -0.35764637  0.29864614 -0.2044287  -0.25226835\n",
      "  0.07556529 -0.43512842]\n",
      "Training Error:  9.803810249728578\n",
      "====================================================================================================\n",
      "Iteration:  818\n",
      "Previous theta :  [ 0.00939384 -0.12347799  0.10605821  0.01227701  0.0640675  -0.24449525\n",
      "  0.26413152  0.01485722 -0.35764637  0.29864614 -0.2044287  -0.25226835\n",
      "  0.07556529 -0.43512842]\n",
      "New theta_0 : [ 0.00939522 -0.12349097  0.10607901  0.01228264  0.06407217 -0.244559\n",
      "  0.26411779  0.01486207 -0.35770026  0.29868534 -0.20444586 -0.25227761\n",
      "  0.07556254 -0.43512354]\n",
      "Training Error:  9.80380044424923\n",
      "====================================================================================================\n",
      "Iteration:  819\n",
      "Previous theta :  [ 0.00939522 -0.12349097  0.10607901  0.01228264  0.06407217 -0.244559\n",
      "  0.26411779  0.01486207 -0.35770026  0.29868534 -0.20444586 -0.25227761\n",
      "  0.07556254 -0.43512354]\n",
      "New theta_0 : [ 0.00939658 -0.12350388  0.10609969  0.01228828  0.0640768  -0.24462239\n",
      "  0.26410415  0.01486689 -0.35775382  0.2987244  -0.20446302 -0.25228682\n",
      "  0.0755598  -0.43511869]\n",
      "Training Error:  9.803790743621741\n",
      "====================================================================================================\n",
      "Iteration:  820\n",
      "Previous theta :  [ 0.00939658 -0.12350388  0.10609969  0.01228828  0.0640768  -0.24462239\n",
      "  0.26410415  0.01486689 -0.35775382  0.2987244  -0.20446302 -0.25228682\n",
      "  0.0755598  -0.43511869]\n",
      "New theta_0 : [ 0.00939795 -0.12351671  0.10612025  0.01229394  0.0640814  -0.24468542\n",
      "  0.2640906   0.01487169 -0.35780704  0.29876331 -0.20448017 -0.25229599\n",
      "  0.07555708 -0.43511385]\n",
      "Training Error:  9.803781146659015\n",
      "====================================================================================================\n",
      "Iteration:  821\n",
      "Previous theta :  [ 0.00939795 -0.12351671  0.10612025  0.01229394  0.0640814  -0.24468542\n",
      "  0.2640906   0.01487169 -0.35780704  0.29876331 -0.20448017 -0.25229599\n",
      "  0.07555708 -0.43511385]\n",
      "New theta_0 : [ 0.0093993  -0.12352948  0.10614068  0.01229961  0.06408597 -0.24474809\n",
      "  0.26407713  0.01487646 -0.35785992  0.29880207 -0.2044973  -0.25230511\n",
      "  0.07555439 -0.43510903]\n",
      "Training Error:  9.803771652187777\n",
      "====================================================================================================\n",
      "Iteration:  822\n",
      "Previous theta :  [ 0.0093993  -0.12352948  0.10614068  0.01229961  0.06408597 -0.24474809\n",
      "  0.26407713  0.01487646 -0.35785992  0.29880207 -0.2044973  -0.25230511\n",
      "  0.07555439 -0.43510903]\n",
      "New theta_0 : [ 0.00940064 -0.12354218  0.10616099  0.0123053   0.06409051 -0.24481041\n",
      "  0.26406375  0.01488121 -0.35791248  0.2988407  -0.20451443 -0.25231419\n",
      "  0.07555171 -0.43510423]\n",
      "Training Error:  9.80376225904841\n",
      "====================================================================================================\n",
      "Iteration:  823\n",
      "Previous theta :  [ 0.00940064 -0.12354218  0.10616099  0.0123053   0.06409051 -0.24481041\n",
      "  0.26406375  0.01488121 -0.35791248  0.2988407  -0.20451443 -0.25231419\n",
      "  0.07555171 -0.43510423]\n",
      "New theta_0 : [ 0.00940198 -0.12355481  0.10618117  0.012311    0.06409503 -0.24487238\n",
      "  0.26405045  0.01488593 -0.3579647   0.29887918 -0.20453155 -0.25232323\n",
      "  0.07554905 -0.43509944]\n",
      "Training Error:  9.803752966094802\n",
      "====================================================================================================\n",
      "Iteration:  824\n",
      "Previous theta :  [ 0.00940198 -0.12355481  0.10618117  0.012311    0.06409503 -0.24487238\n",
      "  0.26405045  0.01488593 -0.3579647   0.29887918 -0.20453155 -0.25232323\n",
      "  0.07554905 -0.43509944]\n",
      "New theta_0 : [ 0.00940331 -0.12356738  0.10620124  0.01231672  0.06409951 -0.244934\n",
      "  0.26403724  0.01489063 -0.35801659  0.29891752 -0.20454865 -0.25233223\n",
      "  0.07554641 -0.43509467]\n",
      "Training Error:  9.80374377219418\n",
      "====================================================================================================\n",
      "Iteration:  825\n",
      "Previous theta :  [ 0.00940331 -0.12356738  0.10620124  0.01231672  0.06409951 -0.244934\n",
      "  0.26403724  0.01489063 -0.35801659  0.29891752 -0.20454865 -0.25233223\n",
      "  0.07554641 -0.43509467]\n",
      "New theta_0 : [ 0.00940464 -0.12357987  0.10622118  0.01232245  0.06410396 -0.24499528\n",
      "  0.26402411  0.0148953  -0.35806815  0.29895572 -0.20456575 -0.25234118\n",
      "  0.07554379 -0.43508992]\n",
      "Training Error:  9.803734676226943\n",
      "====================================================================================================\n",
      "Iteration:  826\n",
      "Previous theta :  [ 0.00940464 -0.12357987  0.10622118  0.01232245  0.06410396 -0.24499528\n",
      "  0.26402411  0.0148953  -0.35806815  0.29895572 -0.20456575 -0.25234118\n",
      "  0.07554379 -0.43508992]\n",
      "New theta_0 : [ 0.00940595 -0.1235923   0.10624101  0.01232819  0.06410838 -0.2450562\n",
      "  0.26401106  0.01489995 -0.35811939  0.29899378 -0.20458284 -0.2523501\n",
      "  0.07554119 -0.43508519]\n",
      "Training Error:  9.803725677086529\n",
      "====================================================================================================\n",
      "Iteration:  827\n",
      "Previous theta :  [ 0.00940595 -0.1235923   0.10624101  0.01232819  0.06410838 -0.2450562\n",
      "  0.26401106  0.01489995 -0.35811939  0.29899378 -0.20458284 -0.2523501\n",
      "  0.07554119 -0.43508519]\n",
      "New theta_0 : [ 0.00940726 -0.12360466  0.10626072  0.01233395  0.06411278 -0.24511679\n",
      "  0.2639981   0.01490458 -0.35817031  0.2990317  -0.20459992 -0.25235897\n",
      "  0.07553861 -0.43508048]\n",
      "Training Error:  9.803716773679236\n",
      "====================================================================================================\n",
      "Iteration:  828\n",
      "Previous theta :  [ 0.00940726 -0.12360466  0.10626072  0.01233395  0.06411278 -0.24511679\n",
      "  0.2639981   0.01490458 -0.35817031  0.2990317  -0.20459992 -0.25235897\n",
      "  0.07553861 -0.43508048]\n",
      "New theta_0 : [ 0.00940856 -0.12361695  0.10628031  0.01233972  0.06411714 -0.24517703\n",
      "  0.26398521  0.01490918 -0.3582209   0.29906948 -0.20461699 -0.25236779\n",
      "  0.07553605 -0.43507578]\n",
      "Training Error:  9.803707964924092\n",
      "====================================================================================================\n",
      "Iteration:  829\n",
      "Previous theta :  [ 0.00940856 -0.12361695  0.10628031  0.01233972  0.06411714 -0.24517703\n",
      "  0.26398521  0.01490918 -0.3582209   0.29906948 -0.20461699 -0.25236779\n",
      "  0.07553605 -0.43507578]\n",
      "New theta_0 : [ 0.00940985 -0.12362918  0.10629978  0.01234551  0.06412148 -0.24523693\n",
      "  0.26397241  0.01491376 -0.35827118  0.29910712 -0.20463404 -0.25237658\n",
      "  0.0755335  -0.4350711 ]\n",
      "Training Error:  9.803699249752686\n",
      "====================================================================================================\n",
      "Iteration:  830\n",
      "Previous theta :  [ 0.00940985 -0.12362918  0.10629978  0.01234551  0.06412148 -0.24523693\n",
      "  0.26397241  0.01491376 -0.35827118  0.29910712 -0.20463404 -0.25237658\n",
      "  0.0755335  -0.4350711 ]\n",
      "New theta_0 : [ 0.00941114 -0.12364134  0.10631914  0.0123513   0.06412579 -0.2452965\n",
      "  0.26395968  0.01491832 -0.35832114  0.29914463 -0.20465109 -0.25238533\n",
      "  0.07553098 -0.43506644]\n",
      "Training Error:  9.803690627109038\n",
      "====================================================================================================\n",
      "Iteration:  831\n",
      "Previous theta :  [ 0.00941114 -0.12364134  0.10631914  0.0123513   0.06412579 -0.2452965\n",
      "  0.26395968  0.01491832 -0.35832114  0.29914463 -0.20465109 -0.25238533\n",
      "  0.07553098 -0.43506644]\n",
      "New theta_0 : [ 0.00941242 -0.12365343  0.10633838  0.01235711  0.06413007 -0.24535572\n",
      "  0.26394704  0.01492285 -0.35837078  0.29918199 -0.20466813 -0.25239403\n",
      "  0.07552847 -0.43506179]\n",
      "Training Error:  9.803682095949435\n",
      "====================================================================================================\n",
      "Iteration:  832\n",
      "Previous theta :  [ 0.00941242 -0.12365343  0.10633838  0.01235711  0.06413007 -0.24535572\n",
      "  0.26394704  0.01492285 -0.35837078  0.29918199 -0.20466813 -0.25239403\n",
      "  0.07552847 -0.43506179]\n",
      "New theta_0 : [ 0.00941369 -0.12366546  0.10635751  0.01236293  0.06413432 -0.24541462\n",
      "  0.26393448  0.01492736 -0.35842011  0.29921923 -0.20468515 -0.2524027\n",
      "  0.07552598 -0.43505716]\n",
      "Training Error:  9.803673655242303\n",
      "====================================================================================================\n",
      "Iteration:  833\n",
      "Previous theta :  [ 0.00941369 -0.12366546  0.10635751  0.01236293  0.06413432 -0.24541462\n",
      "  0.26393448  0.01492736 -0.35842011  0.29921923 -0.20468515 -0.2524027\n",
      "  0.07552598 -0.43505716]\n",
      "New theta_0 : [ 0.00941496 -0.12367742  0.10637652  0.01236876  0.06413854 -0.24547318\n",
      "  0.26392199  0.01493185 -0.35846913  0.29925632 -0.20470216 -0.25241132\n",
      "  0.07552351 -0.43505255]\n",
      "Training Error:  9.803665303968039\n",
      "====================================================================================================\n",
      "Iteration:  834\n",
      "Previous theta :  [ 0.00941496 -0.12367742  0.10637652  0.01236876  0.06413854 -0.24547318\n",
      "  0.26392199  0.01493185 -0.35846913  0.29925632 -0.20470216 -0.25241132\n",
      "  0.07552351 -0.43505255]\n",
      "New theta_0 : [ 0.00941621 -0.12368932  0.10639542  0.01237461  0.06414273 -0.24553141\n",
      "  0.26390958  0.01493631 -0.35851784  0.29929328 -0.20471917 -0.2524199\n",
      "  0.07552105 -0.43504796]\n",
      "Training Error:  9.8036570411189\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  835\n",
      "Previous theta :  [ 0.00941621 -0.12368932  0.10639542  0.01237461  0.06414273 -0.24553141\n",
      "  0.26390958  0.01493631 -0.35851784  0.29929328 -0.20471917 -0.2524199\n",
      "  0.07552105 -0.43504796]\n",
      "New theta_0 : [ 0.00941747 -0.12370115  0.10641421  0.01238046  0.0641469  -0.24558932\n",
      "  0.26389725  0.01494075 -0.35856625  0.29933011 -0.20473616 -0.25242844\n",
      "  0.07551862 -0.43504339]\n",
      "Training Error:  9.803648865698843\n",
      "====================================================================================================\n",
      "Iteration:  836\n",
      "Previous theta :  [ 0.00941747 -0.12370115  0.10641421  0.01238046  0.0641469  -0.24558932\n",
      "  0.26389725  0.01494075 -0.35856625  0.29933011 -0.20473616 -0.25242844\n",
      "  0.07551862 -0.43504339]\n",
      "New theta_0 : [ 0.00941871 -0.12371293  0.10643288  0.01238633  0.06415104 -0.24564689\n",
      "  0.263885    0.01494517 -0.35861434  0.2993668  -0.20475314 -0.25243695\n",
      "  0.0755162  -0.43503883]\n",
      "Training Error:  9.803640776723396\n",
      "====================================================================================================\n",
      "Iteration:  837\n",
      "Previous theta :  [ 0.00941871 -0.12371293  0.10643288  0.01238633  0.06415104 -0.24564689\n",
      "  0.263885    0.01494517 -0.35861434  0.2993668  -0.20475314 -0.25243695\n",
      "  0.0755162  -0.43503883]\n",
      "New theta_0 : [ 0.00941995 -0.12372463  0.10645144  0.01239221  0.06415515 -0.24570414\n",
      "  0.26387283  0.01494956 -0.35866214  0.29940336 -0.2047701  -0.25244541\n",
      "  0.0755138  -0.43503429]\n",
      "Training Error:  9.80363277321951\n",
      "====================================================================================================\n",
      "Iteration:  838\n",
      "Previous theta :  [ 0.00941995 -0.12372463  0.10645144  0.01239221  0.06415515 -0.24570414\n",
      "  0.26387283  0.01494956 -0.35866214  0.29940336 -0.2047701  -0.25244541\n",
      "  0.0755138  -0.43503429]\n",
      "New theta_0 : [ 0.00942117 -0.12373628  0.10646989  0.01239809  0.06415923 -0.24576107\n",
      "  0.26386073  0.01495393 -0.35870963  0.29943978 -0.20478706 -0.25245383\n",
      "  0.07551141 -0.43502977]\n",
      "Training Error:  9.80362485422544\n",
      "====================================================================================================\n",
      "Iteration:  839\n",
      "Previous theta :  [ 0.00942117 -0.12373628  0.10646989  0.01239809  0.06415923 -0.24576107\n",
      "  0.26386073  0.01495393 -0.35870963  0.29943978 -0.20478706 -0.25245383\n",
      "  0.07551141 -0.43502977]\n",
      "New theta_0 : [ 0.0094224  -0.12374786  0.10648824  0.01240399  0.06416329 -0.24581768\n",
      "  0.2638487   0.01495828 -0.35875683  0.29947608 -0.204804   -0.25246221\n",
      "  0.07550905 -0.43502527]\n",
      "Training Error:  9.8036170187906\n",
      "====================================================================================================\n",
      "Iteration:  840\n",
      "Previous theta :  [ 0.0094224  -0.12374786  0.10648824  0.01240399  0.06416329 -0.24581768\n",
      "  0.2638487   0.01495828 -0.35875683  0.29947608 -0.204804   -0.25246221\n",
      "  0.07550905 -0.43502527]\n",
      "New theta_0 : [ 0.00942361 -0.12375937  0.10650647  0.0124099   0.06416732 -0.24587397\n",
      "  0.26383675  0.01496261 -0.35880372  0.29951224 -0.20482094 -0.25247056\n",
      "  0.0755067  -0.43502078]\n",
      "Training Error:  9.803609265975435\n",
      "====================================================================================================\n",
      "Iteration:  841\n",
      "Previous theta :  [ 0.00942361 -0.12375937  0.10650647  0.0124099   0.06416732 -0.24587397\n",
      "  0.26383675  0.01496261 -0.35880372  0.29951224 -0.20482094 -0.25247056\n",
      "  0.0755067  -0.43502078]\n",
      "New theta_0 : [ 0.00942482 -0.12377083  0.10652459  0.01241582  0.06417133 -0.24592994\n",
      "  0.26382488  0.01496692 -0.35885032  0.29954827 -0.20483786 -0.25247886\n",
      "  0.07550437 -0.43501631]\n",
      "Training Error:  9.803601594851296\n",
      "====================================================================================================\n",
      "Iteration:  842\n",
      "Previous theta :  [ 0.00942482 -0.12377083  0.10652459  0.01241582  0.06417133 -0.24592994\n",
      "  0.26382488  0.01496692 -0.35885032  0.29954827 -0.20483786 -0.25247886\n",
      "  0.07550437 -0.43501631]\n",
      "New theta_0 : [ 0.00942602 -0.12378222  0.10654261  0.01242175  0.0641753  -0.24598559\n",
      "  0.26381308  0.0149712  -0.35889663  0.29958417 -0.20485477 -0.25248713\n",
      "  0.07550205 -0.43501186]\n",
      "Training Error:  9.803594004500297\n",
      "====================================================================================================\n",
      "Iteration:  843\n",
      "Previous theta :  [ 0.00942602 -0.12378222  0.10654261  0.01242175  0.0641753  -0.24598559\n",
      "  0.26381308  0.0149712  -0.35889663  0.29958417 -0.20485477 -0.25248713\n",
      "  0.07550205 -0.43501186]\n",
      "New theta_0 : [ 0.00942722 -0.12379356  0.10656052  0.01242768  0.06417925 -0.24604094\n",
      "  0.26380135  0.01497546 -0.35894264  0.29961994 -0.20487166 -0.25249536\n",
      "  0.07549975 -0.43500742]\n",
      "Training Error:  9.80358649401521\n",
      "====================================================================================================\n",
      "Iteration:  844\n",
      "Previous theta :  [ 0.00942722 -0.12379356  0.10656052  0.01242768  0.06417925 -0.24604094\n",
      "  0.26380135  0.01497546 -0.35894264  0.29961994 -0.20487166 -0.25249536\n",
      "  0.07549975 -0.43500742]\n",
      "New theta_0 : [ 0.00942841 -0.12380483  0.10657832  0.01243363  0.06418318 -0.24609597\n",
      "  0.2637897   0.0149797  -0.35898837  0.29965558 -0.20488854 -0.25250354\n",
      "  0.07549747 -0.43500301]\n",
      "Training Error:  9.803579062499319\n",
      "====================================================================================================\n",
      "Iteration:  845\n",
      "Previous theta :  [ 0.00942841 -0.12380483  0.10657832  0.01243363  0.06418318 -0.24609597\n",
      "  0.2637897   0.0149797  -0.35898837  0.29965558 -0.20488854 -0.25250354\n",
      "  0.07549747 -0.43500301]\n",
      "New theta_0 : [ 0.00942959 -0.12381604  0.10659601  0.01243959  0.06418707 -0.24615068\n",
      "  0.26377811  0.01498392 -0.3590338   0.29969109 -0.20490541 -0.25251169\n",
      "  0.07549521 -0.43499861]\n",
      "Training Error:  9.803571709066304\n",
      "====================================================================================================\n",
      "Iteration:  846\n",
      "Previous theta :  [ 0.00942959 -0.12381604  0.10659601  0.01243959  0.06418707 -0.24615068\n",
      "  0.26377811  0.01498392 -0.3590338   0.29969109 -0.20490541 -0.25251169\n",
      "  0.07549521 -0.43499861]\n",
      "New theta_0 : [ 0.00943076 -0.12382719  0.10661361  0.01244555  0.06419095 -0.24620509\n",
      "  0.2637666   0.01498812 -0.35907895  0.29972648 -0.20492227 -0.2525198\n",
      "  0.07549296 -0.43499422]\n",
      "Training Error:  9.803564432840124\n",
      "====================================================================================================\n",
      "Iteration:  847\n",
      "Previous theta :  [ 0.00943076 -0.12382719  0.10661361  0.01244555  0.06419095 -0.24620509\n",
      "  0.2637666   0.01498812 -0.35907895  0.29972648 -0.20492227 -0.2525198\n",
      "  0.07549296 -0.43499422]\n",
      "New theta_0 : [ 0.00943193 -0.12383828  0.10663109  0.01245152  0.06419479 -0.2462592\n",
      "  0.26375517  0.0149923  -0.35912381  0.29976174 -0.20493912 -0.25252788\n",
      "  0.07549072 -0.43498986]\n",
      "Training Error:  9.803557232954885\n",
      "====================================================================================================\n",
      "Iteration:  848\n",
      "Previous theta :  [ 0.00943193 -0.12383828  0.10663109  0.01245152  0.06419479 -0.2462592\n",
      "  0.26375517  0.0149923  -0.35912381  0.29976174 -0.20493912 -0.25252788\n",
      "  0.07549072 -0.43498986]\n",
      "New theta_0 : [ 0.00943309 -0.12384931  0.10664847  0.0124575   0.06419861 -0.246313\n",
      "  0.2637438   0.01499645 -0.35916839  0.29979687 -0.20495595 -0.25253591\n",
      "  0.07548851 -0.43498551]\n",
      "Training Error:  9.803550108554731\n",
      "====================================================================================================\n",
      "Iteration:  849\n",
      "Previous theta :  [ 0.00943309 -0.12384931  0.10664847  0.0124575   0.06419861 -0.246313\n",
      "  0.2637438   0.01499645 -0.35916839  0.29979687 -0.20495595 -0.25253591\n",
      "  0.07548851 -0.43498551]\n",
      "New theta_0 : [ 0.00943425 -0.12386028  0.10666575  0.01246349  0.06420241 -0.24636649\n",
      "  0.2637325   0.01500059 -0.35921269  0.29983187 -0.20497277 -0.25254391\n",
      "  0.07548631 -0.43498118]\n",
      "Training Error:  9.80354305879372\n",
      "====================================================================================================\n",
      "Iteration:  850\n",
      "Previous theta :  [ 0.00943425 -0.12386028  0.10666575  0.01246349  0.06420241 -0.24636649\n",
      "  0.2637325   0.01500059 -0.35921269  0.29983187 -0.20497277 -0.25254391\n",
      "  0.07548631 -0.43498118]\n",
      "New theta_0 : [ 0.0094354  -0.12387119  0.10668293  0.01246949  0.06420618 -0.24641968\n",
      "  0.26372128  0.0150047  -0.35925671  0.29986675 -0.20498957 -0.25255187\n",
      "  0.07548412 -0.43497687]\n",
      "Training Error:  9.8035360828357\n",
      "====================================================================================================\n",
      "Iteration:  851\n",
      "Previous theta :  [ 0.0094354  -0.12387119  0.10668293  0.01246949  0.06420618 -0.24641968\n",
      "  0.26372128  0.0150047  -0.35925671  0.29986675 -0.20498957 -0.25255187\n",
      "  0.07548412 -0.43497687]\n",
      "New theta_0 : [ 0.00943654 -0.12388205  0.1067      0.01247549  0.06420992 -0.24647258\n",
      "  0.26371012  0.01500879 -0.35930045  0.2999015  -0.20500636 -0.2525598\n",
      "  0.07548196 -0.43497257]\n",
      "Training Error:  9.803529179854213\n",
      "====================================================================================================\n",
      "Iteration:  852\n",
      "Previous theta :  [ 0.00943654 -0.12388205  0.1067      0.01247549  0.06420992 -0.24647258\n",
      "  0.26371012  0.01500879 -0.35930045  0.2999015  -0.20500636 -0.2525598\n",
      "  0.07548196 -0.43497257]\n",
      "New theta_0 : [ 0.00943768 -0.12389284  0.10671697  0.01248151  0.06421364 -0.24652517\n",
      "  0.26369903  0.01501286 -0.35934391  0.29993613 -0.20502314 -0.25256768\n",
      "  0.0754798  -0.4349683 ]\n",
      "Training Error:  9.803522349032361\n",
      "====================================================================================================\n",
      "Iteration:  853\n",
      "Previous theta :  [ 0.00943768 -0.12389284  0.10671697  0.01248151  0.06421364 -0.24652517\n",
      "  0.26369903  0.01501286 -0.35934391  0.29993613 -0.20502314 -0.25256768\n",
      "  0.0754798  -0.4349683 ]\n",
      "New theta_0 : [ 0.0094388  -0.12390358  0.10673384  0.01248752  0.06421733 -0.24657747\n",
      "  0.26368802  0.01501692 -0.3593871   0.29997063 -0.20503991 -0.25257553\n",
      "  0.07547767 -0.43496403]\n",
      "Training Error:  9.803515589562712\n",
      "====================================================================================================\n",
      "Iteration:  854\n",
      "Previous theta :  [ 0.0094388  -0.12390358  0.10673384  0.01248752  0.06421733 -0.24657747\n",
      "  0.26368802  0.01501692 -0.3593871   0.29997063 -0.20503991 -0.25257553\n",
      "  0.07547767 -0.43496403]\n",
      "New theta_0 : [ 0.00943993 -0.12391426  0.10675061  0.01249355  0.064221   -0.24662947\n",
      "  0.26367707  0.01502095 -0.35943002  0.30000501 -0.20505666 -0.25258334\n",
      "  0.07547555 -0.43495979]\n",
      "Training Error:  9.80350890064717\n",
      "====================================================================================================\n",
      "Iteration:  855\n",
      "Previous theta :  [ 0.00943993 -0.12391426  0.10675061  0.01249355  0.064221   -0.24662947\n",
      "  0.26367707  0.01502095 -0.35943002  0.30000501 -0.20505666 -0.25258334\n",
      "  0.07547555 -0.43495979]\n",
      "New theta_0 : [ 0.00944104 -0.12392488  0.10676729  0.01249958  0.06422465 -0.24668118\n",
      "  0.26366618  0.01502496 -0.35947266  0.30003927 -0.2050734  -0.25259112\n",
      "  0.07547344 -0.43495556]\n",
      "Training Error:  9.803502281496868\n",
      "====================================================================================================\n",
      "Iteration:  856\n",
      "Previous theta :  [ 0.00944104 -0.12392488  0.10676729  0.01249958  0.06422465 -0.24668118\n",
      "  0.26366618  0.01502496 -0.35947266  0.30003927 -0.2050734  -0.25259112\n",
      "  0.07547344 -0.43495556]\n",
      "New theta_0 : [ 0.00944215 -0.12393544  0.10678386  0.01250562  0.06422827 -0.2467326\n",
      "  0.26365537  0.01502895 -0.35951504  0.3000734  -0.20509012 -0.25259886\n",
      "  0.07547135 -0.43495135]\n",
      "Training Error:  9.803495731332088\n",
      "====================================================================================================\n",
      "Iteration:  857\n",
      "Previous theta :  [ 0.00944215 -0.12393544  0.10678386  0.01250562  0.06422827 -0.2467326\n",
      "  0.26365537  0.01502895 -0.35951504  0.3000734  -0.20509012 -0.25259886\n",
      "  0.07547135 -0.43495135]\n",
      "New theta_0 : [ 0.00944326 -0.12394595  0.10680033  0.01251167  0.06423186 -0.24678373\n",
      "  0.26364462  0.01503292 -0.35955714  0.30010742 -0.20510683 -0.25260656\n",
      "  0.07546928 -0.43494716]\n",
      "Training Error:  9.803489249382103\n",
      "====================================================================================================\n",
      "Iteration:  858\n",
      "Previous theta :  [ 0.00944326 -0.12394595  0.10680033  0.01251167  0.06423186 -0.24678373\n",
      "  0.26364462  0.01503292 -0.35955714  0.30010742 -0.20510683 -0.25260656\n",
      "  0.07546928 -0.43494716]\n",
      "New theta_0 : [ 0.00944436 -0.1239564   0.10681671  0.01251772  0.06423544 -0.24683457\n",
      "  0.26363394  0.01503687 -0.35959899  0.30014131 -0.20512352 -0.25261423\n",
      "  0.07546722 -0.43494299]\n",
      "Training Error:  9.80348283488512\n",
      "====================================================================================================\n",
      "Iteration:  859\n",
      "Previous theta :  [ 0.00944436 -0.1239564   0.10681671  0.01251772  0.06423544 -0.24683457\n",
      "  0.26363394  0.01503687 -0.35959899  0.30014131 -0.20512352 -0.25261423\n",
      "  0.07546722 -0.43494299]\n",
      "New theta_0 : [ 0.00944545 -0.1239668   0.10683299  0.01252378  0.06423899 -0.24688512\n",
      "  0.26362332  0.0150408  -0.35964056  0.30017508 -0.2051402  -0.25262186\n",
      "  0.07546517 -0.43493883]\n",
      "Training Error:  9.803476487088137\n",
      "====================================================================================================\n",
      "Iteration:  860\n",
      "Previous theta :  [ 0.00944545 -0.1239668   0.10683299  0.01252378  0.06423899 -0.24688512\n",
      "  0.26362332  0.0150408  -0.35964056  0.30017508 -0.2051402  -0.25262186\n",
      "  0.07546517 -0.43493883]\n",
      "New theta_0 : [ 0.00944653 -0.12397714  0.10684917  0.01252984  0.06424251 -0.24693539\n",
      "  0.26361277  0.01504472 -0.35968188  0.30020873 -0.20515687 -0.25262946\n",
      "  0.07546314 -0.43493469]\n",
      "Training Error:  9.803470205246867\n",
      "====================================================================================================\n",
      "Iteration:  861\n",
      "Previous theta :  [ 0.00944653 -0.12397714  0.10684917  0.01252984  0.06424251 -0.24693539\n",
      "  0.26361277  0.01504472 -0.35968188  0.30020873 -0.20515687 -0.25262946\n",
      "  0.07546314 -0.43493469]\n",
      "New theta_0 : [ 0.00944761 -0.12398742  0.10686526  0.01253591  0.06424601 -0.24698537\n",
      "  0.26360229  0.01504861 -0.35972293  0.30024226 -0.20517352 -0.25263702\n",
      "  0.07546113 -0.43493056]\n",
      "Training Error:  9.803463988625625\n",
      "====================================================================================================\n",
      "Iteration:  862\n",
      "Previous theta :  [ 0.00944761 -0.12398742  0.10686526  0.01253591  0.06424601 -0.24698537\n",
      "  0.26360229  0.01504861 -0.35972293  0.30024226 -0.20517352 -0.25263702\n",
      "  0.07546113 -0.43493056]\n",
      "New theta_0 : [ 0.00944868 -0.12399765  0.10688125  0.01254199  0.06424949 -0.24703508\n",
      "  0.26359187  0.01505248 -0.35976372  0.30027567 -0.20519016 -0.25264454\n",
      "  0.07545913 -0.43492646]\n",
      "Training Error:  9.803457836497218\n",
      "====================================================================================================\n",
      "Iteration:  863\n",
      "Previous theta :  [ 0.00944868 -0.12399765  0.10688125  0.01254199  0.06424949 -0.24703508\n",
      "  0.26359187  0.01505248 -0.35976372  0.30027567 -0.20519016 -0.25264454\n",
      "  0.07545913 -0.43492646]\n",
      "New theta_0 : [ 0.00944975 -0.12400782  0.10689714  0.01254807  0.06425294 -0.2470845\n",
      "  0.26358151  0.01505633 -0.35980426  0.30030896 -0.20520678 -0.25265203\n",
      "  0.07545714 -0.43492237]\n",
      "Training Error:  9.803451748142855\n",
      "====================================================================================================\n",
      "Iteration:  864\n",
      "Previous theta :  [ 0.00944975 -0.12400782  0.10689714  0.01254807  0.06425294 -0.2470845\n",
      "  0.26358151  0.01505633 -0.35980426  0.30030896 -0.20520678 -0.25265203\n",
      "  0.07545714 -0.43492237]\n",
      "New theta_0 : [ 0.00945081 -0.12401794  0.10691295  0.01255416  0.06425637 -0.24713364\n",
      "  0.26357122  0.01506017 -0.35984454  0.30034213 -0.20522339 -0.25265949\n",
      "  0.07545517 -0.4349183 ]\n",
      "Training Error:  9.803445722852057\n",
      "====================================================================================================\n",
      "Iteration:  865\n",
      "Previous theta :  [ 0.00945081 -0.12401794  0.10691295  0.01255416  0.06425637 -0.24713364\n",
      "  0.26357122  0.01506017 -0.35984454  0.30034213 -0.20522339 -0.25265949\n",
      "  0.07545517 -0.4349183 ]\n",
      "New theta_0 : [ 0.00945186 -0.12402801  0.10692866  0.01256025  0.06425978 -0.24718251\n",
      "  0.26356099  0.01506398 -0.35988456  0.30037519 -0.20523998 -0.25266691\n",
      "  0.07545321 -0.43491424]\n",
      "Training Error:  9.80343975992254\n",
      "====================================================================================================\n",
      "Iteration:  866\n",
      "Previous theta :  [ 0.00945186 -0.12402801  0.10692866  0.01256025  0.06425978 -0.24718251\n",
      "  0.26356099  0.01506398 -0.35988456  0.30037519 -0.20523998 -0.25266691\n",
      "  0.07545321 -0.43491424]\n",
      "New theta_0 : [ 0.00945291 -0.12403802  0.10694427  0.01256634  0.06426316 -0.2472311\n",
      "  0.26355082  0.01506778 -0.35992433  0.30040813 -0.20525656 -0.25267429\n",
      "  0.07545127 -0.4349102 ]\n",
      "Training Error:  9.80343385866013\n",
      "====================================================================================================\n",
      "Iteration:  867\n",
      "Previous theta :  [ 0.00945291 -0.12403802  0.10694427  0.01256634  0.06426316 -0.2472311\n",
      "  0.26355082  0.01506778 -0.35992433  0.30040813 -0.20525656 -0.25267429\n",
      "  0.07545127 -0.4349102 ]\n",
      "New theta_0 : [ 0.00945395 -0.12404797  0.10695979  0.01257244  0.06426652 -0.24727942\n",
      "  0.26354072  0.01507156 -0.35996385  0.30044095 -0.20527312 -0.25268165\n",
      "  0.07544935 -0.43490618]\n",
      "Training Error:  9.80342801837866\n",
      "====================================================================================================\n",
      "Iteration:  868\n",
      "Previous theta :  [ 0.00945395 -0.12404797  0.10695979  0.01257244  0.06426652 -0.24727942\n",
      "  0.26354072  0.01507156 -0.35996385  0.30044095 -0.20527312 -0.25268165\n",
      "  0.07544935 -0.43490618]\n",
      "New theta_0 : [ 0.00945499 -0.12405788  0.10697523  0.01257855  0.06426986 -0.24732746\n",
      "  0.26353068  0.01507532 -0.36000312  0.30047365 -0.20528967 -0.25268896\n",
      "  0.07544743 -0.43490217]\n",
      "Training Error:  9.803422238399891\n",
      "====================================================================================================\n",
      "Iteration:  869\n",
      "Previous theta :  [ 0.00945499 -0.12405788  0.10697523  0.01257855  0.06426986 -0.24732746\n",
      "  0.26353068  0.01507532 -0.36000312  0.30047365 -0.20528967 -0.25268896\n",
      "  0.07544743 -0.43490217]\n",
      "New theta_0 : [ 0.00945602 -0.12406773  0.10699057  0.01258465  0.06427318 -0.24737524\n",
      "  0.2635207   0.01507906 -0.36004214  0.30050624 -0.2053062  -0.25269624\n",
      "  0.07544553 -0.43489818]\n",
      "Training Error:  9.803416518053401\n",
      "====================================================================================================\n",
      "Iteration:  870\n",
      "Previous theta :  [ 0.00945602 -0.12406773  0.10699057  0.01258465  0.06427318 -0.24737524\n",
      "  0.2635207   0.01507906 -0.36004214  0.30050624 -0.2053062  -0.25269624\n",
      "  0.07544553 -0.43489818]\n",
      "New theta_0 : [ 0.00945705 -0.12407753  0.10700581  0.01259077  0.06427647 -0.24742274\n",
      "  0.26351078  0.01508278 -0.36008091  0.30053872 -0.20532272 -0.25270349\n",
      "  0.07544365 -0.43489421]\n",
      "Training Error:  9.80341085667651\n",
      "====================================================================================================\n",
      "Iteration:  871\n",
      "Previous theta :  [ 0.00945705 -0.12407753  0.10700581  0.01259077  0.06427647 -0.24742274\n",
      "  0.26351078  0.01508278 -0.36008091  0.30053872 -0.20532272 -0.25270349\n",
      "  0.07544365 -0.43489421]\n",
      "New theta_0 : [ 0.00945807 -0.12408727  0.10702097  0.01259688  0.06427974 -0.24746998\n",
      "  0.26350092  0.01508648 -0.36011944  0.30057108 -0.20533922 -0.25271071\n",
      "  0.07544178 -0.43489026]\n",
      "Training Error:  9.803405253614168\n",
      "====================================================================================================\n",
      "Iteration:  872\n",
      "Previous theta :  [ 0.00945807 -0.12408727  0.10702097  0.01259688  0.06427974 -0.24746998\n",
      "  0.26350092  0.01508648 -0.36011944  0.30057108 -0.20533922 -0.25271071\n",
      "  0.07544178 -0.43489026]\n",
      "New theta_0 : [ 0.00945908 -0.12409697  0.10703604  0.012603    0.06428299 -0.24751695\n",
      "  0.26349113  0.01509017 -0.36015773  0.30060332 -0.2053557  -0.25271789\n",
      "  0.07543992 -0.43488632]\n",
      "Training Error:  9.803399708218887\n",
      "====================================================================================================\n",
      "Iteration:  873\n",
      "Previous theta :  [ 0.00945908 -0.12409697  0.10703604  0.012603    0.06428299 -0.24751695\n",
      "  0.26349113  0.01509017 -0.36015773  0.30060332 -0.2053557  -0.25271789\n",
      "  0.07543992 -0.43488632]\n",
      "New theta_0 : [ 0.00946009 -0.12410661  0.10705102  0.01260913  0.06428622 -0.24756365\n",
      "  0.26348139  0.01509383 -0.36019577  0.30063545 -0.20537217 -0.25272503\n",
      "  0.07543807 -0.4348824 ]\n",
      "Training Error:  9.80339421985064\n",
      "====================================================================================================\n",
      "Iteration:  874\n",
      "Previous theta :  [ 0.00946009 -0.12410661  0.10705102  0.01260913  0.06428622 -0.24756365\n",
      "  0.26348139  0.01509383 -0.36019577  0.30063545 -0.20537217 -0.25272503\n",
      "  0.07543807 -0.4348824 ]\n",
      "New theta_0 : [ 0.00946109 -0.1241162   0.10706592  0.01261525  0.06428942 -0.24761009\n",
      "  0.26347171  0.01509748 -0.36023357  0.30066747 -0.20538863 -0.25273215\n",
      "  0.07543624 -0.43487849]\n",
      "Training Error:  9.803388787876777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Iteration:  875\n",
      "Previous theta :  [ 0.00946109 -0.1241162   0.10706592  0.01261525  0.06428942 -0.24761009\n",
      "  0.26347171  0.01509748 -0.36023357  0.30066747 -0.20538863 -0.25273215\n",
      "  0.07543624 -0.43487849]\n",
      "New theta_0 : [ 0.00946208 -0.12412574  0.10708072  0.01262138  0.06429261 -0.24765627\n",
      "  0.2634621   0.01510111 -0.36027113  0.30069938 -0.20540506 -0.25273923\n",
      "  0.07543443 -0.4348746 ]\n",
      "Training Error:  9.803383411671938\n",
      "====================================================================================================\n",
      "Iteration:  876\n",
      "Previous theta :  [ 0.00946208 -0.12412574  0.10708072  0.01262138  0.06429261 -0.24765627\n",
      "  0.2634621   0.01510111 -0.36027113  0.30069938 -0.20540506 -0.25273923\n",
      "  0.07543443 -0.4348746 ]\n",
      "New theta_0 : [ 0.00946307 -0.12413523  0.10709544  0.01262752  0.06429577 -0.24770219\n",
      "  0.26345254  0.01510473 -0.36030845  0.30073117 -0.20542149 -0.25274628\n",
      "  0.07543262 -0.43487073]\n",
      "Training Error:  9.803378090617963\n",
      "====================================================================================================\n",
      "Iteration:  877\n",
      "Previous theta :  [ 0.00946307 -0.12413523  0.10709544  0.01262752  0.06429577 -0.24770219\n",
      "  0.26345254  0.01510473 -0.36030845  0.30073117 -0.20542149 -0.25274628\n",
      "  0.07543262 -0.43487073]\n",
      "New theta_0 : [ 0.00946406 -0.12414466  0.10711007  0.01263365  0.06429891 -0.24774785\n",
      "  0.26344304  0.01510832 -0.36034554  0.30076285 -0.20543789 -0.25275329\n",
      "  0.07543083 -0.43486688]\n",
      "Training Error:  9.803372824103814\n",
      "====================================================================================================\n",
      "Iteration:  878\n",
      "Previous theta :  [ 0.00946406 -0.12414466  0.10711007  0.01263365  0.06429891 -0.24774785\n",
      "  0.26344304  0.01510832 -0.36034554  0.30076285 -0.20543789 -0.25275329\n",
      "  0.07543083 -0.43486688]\n",
      "New theta_0 : [ 0.00946504 -0.12415405  0.10712461  0.01263979  0.06430203 -0.24779325\n",
      "  0.26343359  0.0151119  -0.36038239  0.30079442 -0.20545428 -0.25276027\n",
      "  0.07542905 -0.43486304]\n",
      "Training Error:  9.803367611525495\n",
      "====================================================================================================\n",
      "Iteration:  879\n",
      "Previous theta :  [ 0.00946504 -0.12415405  0.10712461  0.01263979  0.06430203 -0.24779325\n",
      "  0.26343359  0.0151119  -0.36038239  0.30079442 -0.20545428 -0.25276027\n",
      "  0.07542905 -0.43486304]\n",
      "New theta_0 : [ 0.00946601 -0.12416339  0.10713907  0.01264593  0.06430513 -0.2478384\n",
      "  0.26342421  0.01511546 -0.36041901  0.30082588 -0.20547066 -0.25276722\n",
      "  0.07542729 -0.43485922]\n",
      "Training Error:  9.80336245228595\n",
      "====================================================================================================\n",
      "Iteration:  880\n",
      "Previous theta :  [ 0.00946601 -0.12416339  0.10713907  0.01264593  0.06430513 -0.2478384\n",
      "  0.26342421  0.01511546 -0.36041901  0.30082588 -0.20547066 -0.25276722\n",
      "  0.07542729 -0.43485922]\n",
      "New theta_0 : [ 0.00946698 -0.12417267  0.10715344  0.01265207  0.0643082  -0.24788329\n",
      "  0.26341488  0.015119   -0.3604554   0.30085723 -0.20548701 -0.25277414\n",
      "  0.07542554 -0.43485541]\n",
      "Training Error:  9.80335734579501\n",
      "====================================================================================================\n",
      "Iteration:  881\n",
      "Previous theta :  [ 0.00946698 -0.12417267  0.10715344  0.01265207  0.0643082  -0.24788329\n",
      "  0.26341488  0.015119   -0.3604554   0.30085723 -0.20548701 -0.25277414\n",
      "  0.07542554 -0.43485541]\n",
      "New theta_0 : [ 0.00946794 -0.12418191  0.10716773  0.01265822  0.06431126 -0.24792793\n",
      "  0.26340561  0.01512253 -0.36049156  0.30088847 -0.20550335 -0.25278103\n",
      "  0.0754238  -0.43485162]\n",
      "Training Error:  9.803352291469285\n",
      "====================================================================================================\n",
      "Iteration:  882\n",
      "Previous theta :  [ 0.00946794 -0.12418191  0.10716773  0.01265822  0.06431126 -0.24792793\n",
      "  0.26340561  0.01512253 -0.36049156  0.30088847 -0.20550335 -0.25278103\n",
      "  0.0754238  -0.43485162]\n",
      "New theta_0 : [ 0.00946889 -0.1241911   0.10718193  0.01266437  0.0643143  -0.24797232\n",
      "  0.2633964   0.01512603 -0.36052748  0.3009196  -0.20551968 -0.25278788\n",
      "  0.07542208 -0.43484785]\n",
      "Training Error:  9.803347288732098\n",
      "====================================================================================================\n",
      "Iteration:  883\n",
      "Previous theta :  [ 0.00946889 -0.1241911   0.10718193  0.01266437  0.0643143  -0.24797232\n",
      "  0.2633964   0.01512603 -0.36052748  0.3009196  -0.20551968 -0.25278788\n",
      "  0.07542208 -0.43484785]\n",
      "New theta_0 : [ 0.00946985 -0.12420024  0.10719605  0.01267052  0.06431731 -0.24801646\n",
      "  0.26338724  0.01512952 -0.36056318  0.30095063 -0.20553598 -0.2527947\n",
      "  0.07542036 -0.43484409]\n",
      "Training Error:  9.803342337013413\n",
      "====================================================================================================\n",
      "Iteration:  884\n",
      "Previous theta :  [ 0.00946985 -0.12420024  0.10719605  0.01267052  0.06431731 -0.24801646\n",
      "  0.26338724  0.01512952 -0.36056318  0.30095063 -0.20553598 -0.2527947\n",
      "  0.07542036 -0.43484409]\n",
      "New theta_0 : [ 0.00947079 -0.12420933  0.10721009  0.01267667  0.0643203  -0.24806035\n",
      "  0.26337814  0.015133   -0.36059865  0.30098154 -0.20555227 -0.25280149\n",
      "  0.07541866 -0.43484035]\n",
      "Training Error:  9.803337435749741\n",
      "====================================================================================================\n",
      "Iteration:  885\n",
      "Previous theta :  [ 0.00947079 -0.12420933  0.10721009  0.01267667  0.0643203  -0.24806035\n",
      "  0.26337814  0.015133   -0.36059865  0.30098154 -0.20555227 -0.25280149\n",
      "  0.07541866 -0.43484035]\n",
      "New theta_0 : [ 0.00947173 -0.12421837  0.10722404  0.01268282  0.06432328 -0.24810399\n",
      "  0.26336909  0.01513646 -0.3606339   0.30101234 -0.20556855 -0.25280825\n",
      "  0.07541698 -0.43483663]\n",
      "Training Error:  9.803332584384076\n",
      "====================================================================================================\n",
      "Iteration:  886\n",
      "Previous theta :  [ 0.00947173 -0.12421837  0.10722404  0.01268282  0.06432328 -0.24810399\n",
      "  0.26336909  0.01513646 -0.3606339   0.30101234 -0.20556855 -0.25280825\n",
      "  0.07541698 -0.43483663]\n",
      "New theta_0 : [ 0.00947267 -0.12422736  0.10723791  0.01268898  0.06432623 -0.24814738\n",
      "  0.2633601   0.0151399  -0.36066893  0.30104304 -0.2055848  -0.25281497\n",
      "  0.0754153  -0.43483292]\n",
      "Training Error:  9.803327782365805\n",
      "====================================================================================================\n",
      "Iteration:  887\n",
      "Previous theta :  [ 0.00947267 -0.12422736  0.10723791  0.01268898  0.06432623 -0.24814738\n",
      "  0.2633601   0.0151399  -0.36066893  0.30104304 -0.2055848  -0.25281497\n",
      "  0.0754153  -0.43483292]\n",
      "New theta_0 : [ 0.0094736  -0.12423631  0.1072517   0.01269513  0.06432916 -0.24819053\n",
      "  0.26335116  0.01514332 -0.36070373  0.30107363 -0.20560104 -0.25282167\n",
      "  0.07541364 -0.43482923]\n",
      "Training Error:  9.803323029150656\n",
      "====================================================================================================\n",
      "Iteration:  888\n",
      "Previous theta :  [ 0.0094736  -0.12423631  0.1072517   0.01269513  0.06432916 -0.24819053\n",
      "  0.26335116  0.01514332 -0.36070373  0.30107363 -0.20560104 -0.25282167\n",
      "  0.07541364 -0.43482923]\n",
      "New theta_0 : [ 0.00947452 -0.12424521  0.10726541  0.01270129  0.06433208 -0.24823344\n",
      "  0.26334228  0.01514673 -0.36073831  0.30110412 -0.20561727 -0.25282833\n",
      "  0.07541199 -0.43482555]\n",
      "Training Error:  9.803318324200596\n",
      "====================================================================================================\n",
      "Iteration:  889\n",
      "Previous theta :  [ 0.00947452 -0.12424521  0.10726541  0.01270129  0.06433208 -0.24823344\n",
      "  0.26334228  0.01514673 -0.36073831  0.30110412 -0.20561727 -0.25282833\n",
      "  0.07541199 -0.43482555]\n",
      "New theta_0 : [ 0.00947544 -0.12425406  0.10727904  0.01270745  0.06433497 -0.24827611\n",
      "  0.26333345  0.01515012 -0.36077267  0.30113449 -0.20563347 -0.25283496\n",
      "  0.07541035 -0.43482189]\n",
      "Training Error:  9.803313666983783\n",
      "====================================================================================================\n",
      "Iteration:  890\n",
      "Previous theta :  [ 0.00947544 -0.12425406  0.10727904  0.01270745  0.06433497 -0.24827611\n",
      "  0.26333345  0.01515012 -0.36077267  0.30113449 -0.20563347 -0.25283496\n",
      "  0.07541035 -0.43482189]\n",
      "New theta_0 : [ 0.00947635 -0.12426286  0.10729259  0.01271361  0.06433784 -0.24831853\n",
      "  0.26332468  0.01515349 -0.36080682  0.30116477 -0.20564966 -0.25284156\n",
      "  0.07540873 -0.43481825]\n",
      "Training Error:  9.803309056974477\n",
      "====================================================================================================\n",
      "Iteration:  891\n",
      "Previous theta :  [ 0.00947635 -0.12426286  0.10729259  0.01271361  0.06433784 -0.24831853\n",
      "  0.26332468  0.01515349 -0.36080682  0.30116477 -0.20564966 -0.25284156\n",
      "  0.07540873 -0.43481825]\n",
      "New theta_0 : [ 0.00947726 -0.12427162  0.10730606  0.01271977  0.0643407  -0.24836072\n",
      "  0.26331596  0.01515685 -0.36084075  0.30119493 -0.20566583 -0.25284814\n",
      "  0.07540712 -0.43481462]\n",
      "Training Error:  9.803304493652968\n",
      "====================================================================================================\n",
      "Iteration:  892\n",
      "Previous theta :  [ 0.00947726 -0.12427162  0.10730606  0.01271977  0.0643407  -0.24836072\n",
      "  0.26331596  0.01515685 -0.36084075  0.30119493 -0.20566583 -0.25284814\n",
      "  0.07540712 -0.43481462]\n",
      "New theta_0 : [ 0.00947816 -0.12428033  0.10731945  0.01272593  0.06434353 -0.24840266\n",
      "  0.26330729  0.01516019 -0.36087446  0.301225   -0.20568199 -0.25285468\n",
      "  0.07540551 -0.43481101]\n",
      "Training Error:  9.80329997650552\n",
      "====================================================================================================\n",
      "Iteration:  893\n",
      "Previous theta :  [ 0.00947816 -0.12428033  0.10731945  0.01272593  0.06434353 -0.24840266\n",
      "  0.26330729  0.01516019 -0.36087446  0.301225   -0.20568199 -0.25285468\n",
      "  0.07540551 -0.43481101]\n",
      "New theta_0 : [ 0.00947906 -0.12428899  0.10733276  0.01273209  0.06434634 -0.24844438\n",
      "  0.26329867  0.01516351 -0.36090796  0.30125495 -0.20569812 -0.25286119\n",
      "  0.07540392 -0.43480741]\n",
      "Training Error:  9.803295505024291\n",
      "====================================================================================================\n",
      "Iteration:  894\n",
      "Previous theta :  [ 0.00947906 -0.12428899  0.10733276  0.01273209  0.06434634 -0.24844438\n",
      "  0.26329867  0.01516351 -0.36090796  0.30125495 -0.20569812 -0.25286119\n",
      "  0.07540392 -0.43480741]\n",
      "New theta_0 : [ 0.00947995 -0.12429761  0.10734599  0.01273825  0.06434914 -0.24848585\n",
      "  0.26329011  0.01516682 -0.36094124  0.30128481 -0.20571424 -0.25286767\n",
      "  0.07540235 -0.43480383]\n",
      "Training Error:  9.80329107870726\n",
      "====================================================================================================\n",
      "Iteration:  895\n",
      "Previous theta :  [ 0.00947995 -0.12429761  0.10734599  0.01273825  0.06434914 -0.24848585\n",
      "  0.26329011  0.01516682 -0.36094124  0.30128481 -0.20571424 -0.25286767\n",
      "  0.07540235 -0.43480383]\n",
      "New theta_0 : [ 0.00948084 -0.12430618  0.10735915  0.01274441  0.06435192 -0.24852709\n",
      "  0.2632816   0.01517011 -0.36097432  0.30131456 -0.20573034 -0.25287411\n",
      "  0.07540078 -0.43480027]\n",
      "Training Error:  9.803286697058166\n",
      "====================================================================================================\n",
      "Iteration:  896\n",
      "Previous theta :  [ 0.00948084 -0.12430618  0.10735915  0.01274441  0.06435192 -0.24852709\n",
      "  0.2632816   0.01517011 -0.36097432  0.30131456 -0.20573034 -0.25287411\n",
      "  0.07540078 -0.43480027]\n",
      "New theta_0 : [ 0.00948172 -0.12431471  0.10737223  0.01275057  0.06435467 -0.2485681\n",
      "  0.26327314  0.01517339 -0.36100718  0.30134421 -0.20574643 -0.25288053\n",
      "  0.07539923 -0.43479672]\n",
      "Training Error:  9.803282359586436\n",
      "====================================================================================================\n",
      "Iteration:  897\n",
      "Previous theta :  [ 0.00948172 -0.12431471  0.10737223  0.01275057  0.06435467 -0.2485681\n",
      "  0.26327314  0.01517339 -0.36100718  0.30134421 -0.20574643 -0.25288053\n",
      "  0.07539923 -0.43479672]\n",
      "New theta_0 : [ 0.0094826  -0.12432319  0.10738523  0.01275673  0.06435741 -0.24860888\n",
      "  0.26326473  0.01517665 -0.36103984  0.30137375 -0.20576249 -0.25288692\n",
      "  0.07539769 -0.43479319]\n",
      "Training Error:  9.803278065807127\n",
      "====================================================================================================\n",
      "Iteration:  898\n",
      "Previous theta :  [ 0.0094826  -0.12432319  0.10738523  0.01275673  0.06435741 -0.24860888\n",
      "  0.26326473  0.01517665 -0.36103984  0.30137375 -0.20576249 -0.25288692\n",
      "  0.07539769 -0.43479319]\n",
      "New theta_0 : [ 0.00948347 -0.12433163  0.10739815  0.01276289  0.06436013 -0.24864943\n",
      "  0.26325637  0.0151799  -0.36107228  0.30140319 -0.20577854 -0.25289328\n",
      "  0.07539615 -0.43478967]\n",
      "Training Error:  9.80327381524085\n",
      "====================================================================================================\n",
      "Iteration:  899\n",
      "Previous theta :  [ 0.00948347 -0.12433163  0.10739815  0.01276289  0.06436013 -0.24864943\n",
      "  0.26325637  0.0151799  -0.36107228  0.30140319 -0.20577854 -0.25289328\n",
      "  0.07539615 -0.43478967]\n",
      "New theta_0 : [ 0.00948434 -0.12434002  0.107411    0.01276905  0.06436283 -0.24868975\n",
      "  0.26324807  0.01518313 -0.36110453  0.30143253 -0.20579457 -0.25289961\n",
      "  0.07539464 -0.43478617]\n",
      "Training Error:  9.803269607413704\n",
      "====================================================================================================\n",
      "Iteration:  900\n",
      "Previous theta :  [ 0.00948434 -0.12434002  0.107411    0.01276905  0.06436283 -0.24868975\n",
      "  0.26324807  0.01518313 -0.36110453  0.30143253 -0.20579457 -0.25289961\n",
      "  0.07539464 -0.43478617]\n",
      "New theta_0 : [ 0.0094852  -0.12434837  0.10742377  0.01277522  0.06436551 -0.24872985\n",
      "  0.26323981  0.01518634 -0.36113656  0.30146177 -0.20581058 -0.25290591\n",
      "  0.07539313 -0.43478269]\n",
      "Training Error:  9.803265441857226\n",
      "====================================================================================================\n",
      "Iteration:  901\n",
      "Previous theta :  [ 0.0094852  -0.12434837  0.10742377  0.01277522  0.06436551 -0.24872985\n",
      "  0.26323981  0.01518634 -0.36113656  0.30146177 -0.20581058 -0.25290591\n",
      "  0.07539313 -0.43478269]\n",
      "New theta_0 : [ 0.00948606 -0.12435667  0.10743647  0.01278138  0.06436817 -0.24876971\n",
      "  0.2632316   0.01518954 -0.3611684   0.30149091 -0.20582658 -0.25291219\n",
      "  0.07539163 -0.43477922]\n",
      "Training Error:  9.803261318108312\n",
      "====================================================================================================\n",
      "Iteration:  902\n",
      "Previous theta :  [ 0.00948606 -0.12435667  0.10743647  0.01278138  0.06436817 -0.24876971\n",
      "  0.2632316   0.01518954 -0.3611684   0.30149091 -0.20582658 -0.25291219\n",
      "  0.07539163 -0.43477922]\n",
      "New theta_0 : [ 0.00948691 -0.12436493  0.1074491   0.01278754  0.06437082 -0.24880936\n",
      "  0.26322344  0.01519273 -0.36120003  0.30151995 -0.20584255 -0.25291843\n",
      "  0.07539014 -0.43477576]\n",
      "Training Error:  9.803257235709161\n",
      "====================================================================================================\n",
      "Iteration:  903\n",
      "Previous theta :  [ 0.00948691 -0.12436493  0.1074491   0.01278754  0.06437082 -0.24880936\n",
      "  0.26322344  0.01519273 -0.36120003  0.30151995 -0.20584255 -0.25291843\n",
      "  0.07539014 -0.43477576]\n",
      "New theta_0 : [ 0.00948776 -0.12437314  0.10746165  0.01279369  0.06437345 -0.24884877\n",
      "  0.26321533  0.01519589 -0.36123146  0.30154889 -0.20585851 -0.25292464\n",
      "  0.07538867 -0.43477233]\n",
      "Training Error:  9.803253194207212\n",
      "====================================================================================================\n",
      "Iteration:  904\n",
      "Previous theta :  [ 0.00948776 -0.12437314  0.10746165  0.01279369  0.06437345 -0.24884877\n",
      "  0.26321533  0.01519589 -0.36123146  0.30154889 -0.20585851 -0.25292464\n",
      "  0.07538867 -0.43477233]\n",
      "New theta_0 : [ 0.0094886  -0.12438132  0.10747413  0.01279985  0.06437605 -0.24888797\n",
      "  0.26320727  0.01519905 -0.36126269  0.30157773 -0.20587445 -0.25293083\n",
      "  0.07538721 -0.4347689 ]\n",
      "Training Error:  9.803249193155082\n",
      "====================================================================================================\n",
      "Iteration:  905\n",
      "Previous theta :  [ 0.0094886  -0.12438132  0.10747413  0.01279985  0.06437605 -0.24888797\n",
      "  0.26320727  0.01519905 -0.36126269  0.30157773 -0.20587445 -0.25293083\n",
      "  0.07538721 -0.4347689 ]\n",
      "New theta_0 : [ 0.00948944 -0.12438944  0.10748653  0.01280601  0.06437865 -0.24892695\n",
      "  0.26319926  0.01520218 -0.36129372  0.30160647 -0.20589037 -0.25293698\n",
      "  0.07538575 -0.4347655 ]\n",
      "Training Error:  9.80324523211051\n",
      "====================================================================================================\n",
      "Iteration:  906\n",
      "Previous theta :  [ 0.00948944 -0.12438944  0.10748653  0.01280601  0.06437865 -0.24892695\n",
      "  0.26319926  0.01520218 -0.36129372  0.30160647 -0.20589037 -0.25293698\n",
      "  0.07538575 -0.4347655 ]\n",
      "New theta_0 : [ 0.00949027 -0.12439753  0.10749886  0.01281216  0.06438122 -0.2489657\n",
      "  0.2631913   0.01520531 -0.36132456  0.30163511 -0.20590627 -0.25294311\n",
      "  0.07538431 -0.4347621 ]\n",
      "Training Error:  9.80324131063629\n",
      "====================================================================================================\n",
      "Iteration:  907\n",
      "Previous theta :  [ 0.00949027 -0.12439753  0.10749886  0.01281216  0.06438122 -0.2489657\n",
      "  0.2631913   0.01520531 -0.36132456  0.30163511 -0.20590627 -0.25294311\n",
      "  0.07538431 -0.4347621 ]\n",
      "New theta_0 : [ 0.0094911  -0.12440557  0.10751112  0.01281832  0.06438377 -0.24900424\n",
      "  0.26318339  0.01520842 -0.3613552   0.30166366 -0.20592216 -0.25294921\n",
      "  0.07538288 -0.43475873]\n",
      "Training Error:  9.803237428300221\n",
      "====================================================================================================\n",
      "Iteration:  908\n",
      "Previous theta :  [ 0.0094911  -0.12440557  0.10751112  0.01281832  0.06438377 -0.24900424\n",
      "  0.26318339  0.01520842 -0.3613552   0.30166366 -0.20592216 -0.25294921\n",
      "  0.07538288 -0.43475873]\n",
      "New theta_0 : [ 0.00949192 -0.12441357  0.10752331  0.01282447  0.06438631 -0.24904256\n",
      "  0.26317552  0.01521151 -0.36138564  0.3016921  -0.20593802 -0.25295528\n",
      "  0.07538146 -0.43475537]\n",
      "Training Error:  9.80323358467503\n",
      "====================================================================================================\n",
      "Iteration:  909\n",
      "Previous theta :  [ 0.00949192 -0.12441357  0.10752331  0.01282447  0.06438631 -0.24904256\n",
      "  0.26317552  0.01521151 -0.36138564  0.3016921  -0.20593802 -0.25295528\n",
      "  0.07538146 -0.43475537]\n",
      "New theta_0 : [ 0.00949274 -0.12442153  0.10753543  0.01283062  0.06438883 -0.24908067\n",
      "  0.2631677   0.01521459 -0.36141589  0.30172045 -0.20595387 -0.25296132\n",
      "  0.07538005 -0.43475202]\n",
      "Training Error:  9.80322977933834\n",
      "====================================================================================================\n",
      "Iteration:  910\n",
      "Previous theta :  [ 0.00949274 -0.12442153  0.10753543  0.01283062  0.06438883 -0.24908067\n",
      "  0.2631677   0.01521459 -0.36141589  0.30172045 -0.20595387 -0.25296132\n",
      "  0.07538005 -0.43475202]\n",
      "New theta_0 : [ 0.00949355 -0.12442944  0.10754747  0.01283677  0.06439133 -0.24911856\n",
      "  0.26315993  0.01521765 -0.36144595  0.3017487  -0.2059697  -0.25296734\n",
      "  0.07537866 -0.43474869]\n",
      "Training Error:  9.803226011872596\n",
      "====================================================================================================\n",
      "Iteration:  911\n",
      "Previous theta :  [ 0.00949355 -0.12442944  0.10754747  0.01283677  0.06439133 -0.24911856\n",
      "  0.26315993  0.01521765 -0.36144595  0.3017487  -0.2059697  -0.25296734\n",
      "  0.07537866 -0.43474869]\n",
      "New theta_0 : [ 0.00949436 -0.12443732  0.10755945  0.01284292  0.06439381 -0.24915623\n",
      "  0.2631522   0.0152207  -0.36147582  0.30177685 -0.20598551 -0.25297332\n",
      "  0.07537727 -0.43474537]\n",
      "Training Error:  9.803222281865011\n",
      "====================================================================================================\n",
      "Iteration:  912\n",
      "Previous theta :  [ 0.00949436 -0.12443732  0.10755945  0.01284292  0.06439381 -0.24915623\n",
      "  0.2631522   0.0152207  -0.36147582  0.30177685 -0.20598551 -0.25297332\n",
      "  0.07537727 -0.43474537]\n",
      "New theta_0 : [ 0.00949516 -0.12444515  0.10757136  0.01284907  0.06439628 -0.2491937\n",
      "  0.26314452  0.01522374 -0.36150549  0.30180491 -0.2060013  -0.25297928\n",
      "  0.07537589 -0.43474207]\n",
      "Training Error:  9.803218588907512\n",
      "====================================================================================================\n",
      "Iteration:  913\n",
      "Previous theta :  [ 0.00949516 -0.12444515  0.10757136  0.01284907  0.06439628 -0.2491937\n",
      "  0.26314452  0.01522374 -0.36150549  0.30180491 -0.2060013  -0.25297928\n",
      "  0.07537589 -0.43474207]\n",
      "New theta_0 : [ 0.00949596 -0.12445294  0.10758319  0.01285521  0.06439873 -0.24923095\n",
      "  0.26313689  0.01522676 -0.36153498  0.30183287 -0.20601707 -0.25298521\n",
      "  0.07537452 -0.43473879]\n",
      "Training Error:  9.803214932596687\n",
      "====================================================================================================\n",
      "Iteration:  914\n",
      "Previous theta :  [ 0.00949596 -0.12445294  0.10758319  0.01285521  0.06439873 -0.24923095\n",
      "  0.26313689  0.01522676 -0.36153498  0.30183287 -0.20601707 -0.25298521\n",
      "  0.07537452 -0.43473879]\n",
      "New theta_0 : [ 0.00949676 -0.12446069  0.10759496  0.01286135  0.06440116 -0.24926799\n",
      "  0.2631293   0.01522976 -0.36156428  0.30186074 -0.20603282 -0.25299111\n",
      "  0.07537317 -0.43473552]\n",
      "Training Error:  9.803211312533728\n",
      "====================================================================================================\n",
      "Iteration:  915\n",
      "Previous theta :  [ 0.00949676 -0.12446069  0.10759496  0.01286135  0.06440116 -0.24926799\n",
      "  0.2631293   0.01522976 -0.36156428  0.30186074 -0.20603282 -0.25299111\n",
      "  0.07537317 -0.43473552]\n",
      "New theta_0 : [ 0.00949755 -0.1244684   0.10760666  0.01286749  0.06440358 -0.24930483\n",
      "  0.26312176  0.01523276 -0.36159339  0.30188851 -0.20604856 -0.25299699\n",
      "  0.07537182 -0.43473226]\n",
      "Training Error:  9.803207728324377\n",
      "====================================================================================================\n",
      "Iteration:  916\n",
      "Previous theta :  [ 0.00949755 -0.1244684   0.10760666  0.01286749  0.06440358 -0.24930483\n",
      "  0.26312176  0.01523276 -0.36159339  0.30188851 -0.20604856 -0.25299699\n",
      "  0.07537182 -0.43473226]\n",
      "New theta_0 : [ 0.00949833 -0.12447607  0.10761829  0.01287363  0.06440598 -0.24934146\n",
      "  0.26311426  0.01523573 -0.36162232  0.30191619 -0.20606427 -0.25300284\n",
      "  0.07537048 -0.43472902]\n",
      "Training Error:  9.803204179578872\n",
      "====================================================================================================\n",
      "Iteration:  917\n",
      "Previous theta :  [ 0.00949833 -0.12447607  0.10761829  0.01287363  0.06440598 -0.24934146\n",
      "  0.26311426  0.01523573 -0.36162232  0.30191619 -0.20606427 -0.25300284\n",
      "  0.07537048 -0.43472902]\n",
      "New theta_0 : [ 0.00949911 -0.12448369  0.10762985  0.01287977  0.06440836 -0.24937788\n",
      "  0.26310681  0.0152387  -0.36165107  0.30194377 -0.20607997 -0.25300866\n",
      "  0.07536916 -0.43472579]\n",
      "Training Error:  9.803200665911895\n",
      "====================================================================================================\n",
      "Iteration:  918\n",
      "Previous theta :  [ 0.00949911 -0.12448369  0.10762985  0.01287977  0.06440836 -0.24937788\n",
      "  0.26310681  0.0152387  -0.36165107  0.30194377 -0.20607997 -0.25300866\n",
      "  0.07536916 -0.43472579]\n",
      "New theta_0 : [ 0.00949989 -0.12449128  0.10764135  0.0128859   0.06441073 -0.24941409\n",
      "  0.2630994   0.01524165 -0.36167963  0.30197126 -0.20609565 -0.25301446\n",
      "  0.07536784 -0.43472258]\n",
      "Training Error:  9.80319718694253\n",
      "====================================================================================================\n",
      "Iteration:  919\n",
      "Previous theta :  [ 0.00949989 -0.12449128  0.10764135  0.0128859   0.06441073 -0.24941409\n",
      "  0.2630994   0.01524165 -0.36167963  0.30197126 -0.20609565 -0.25301446\n",
      "  0.07536784 -0.43472258]\n",
      "New theta_0 : [ 0.00950066 -0.12449883  0.10765278  0.01289203  0.06441308 -0.2494501\n",
      "  0.26309204  0.01524458 -0.36170801  0.30199866 -0.20611131 -0.25302022\n",
      "  0.07536653 -0.43471939]\n",
      "Training Error:  9.803193742294194\n",
      "====================================================================================================\n",
      "Iteration:  920\n",
      "Previous theta :  [ 0.00950066 -0.12449883  0.10765278  0.01289203  0.06441308 -0.2494501\n",
      "  0.26309204  0.01524458 -0.36170801  0.30199866 -0.20611131 -0.25302022\n",
      "  0.07536653 -0.43471939]\n",
      "New theta_0 : [ 0.00950143 -0.12450634  0.10766414  0.01289816  0.06441541 -0.24948591\n",
      "  0.26308472  0.01524751 -0.36173621  0.30202596 -0.20612694 -0.25302596\n",
      "  0.07536524 -0.43471621]\n",
      "Training Error:  9.803190331594594\n",
      "====================================================================================================\n",
      "Iteration:  921\n",
      "Previous theta :  [ 0.00950143 -0.12450634  0.10766414  0.01289816  0.06441541 -0.24948591\n",
      "  0.26308472  0.01524751 -0.36173621  0.30202596 -0.20612694 -0.25302596\n",
      "  0.07536524 -0.43471621]\n",
      "New theta_0 : [ 0.00950219 -0.12451381  0.10767543  0.01290428  0.06441773 -0.24952152\n",
      "  0.26307744  0.01525041 -0.36176422  0.30205317 -0.20614256 -0.25303168\n",
      "  0.07536395 -0.43471304]\n",
      "Training Error:  9.803186954475686\n",
      "====================================================================================================\n",
      "Iteration:  922\n",
      "Previous theta :  [ 0.00950219 -0.12451381  0.10767543  0.01290428  0.06441773 -0.24952152\n",
      "  0.26307744  0.01525041 -0.36176422  0.30205317 -0.20614256 -0.25303168\n",
      "  0.07536395 -0.43471304]\n",
      "New theta_0 : [ 0.00950295 -0.12452123  0.10768666  0.01291041  0.06442003 -0.24955693\n",
      "  0.26307021  0.01525331 -0.36179207  0.30208029 -0.20615816 -0.25303737\n",
      "  0.07536267 -0.43470989]\n",
      "Training Error:  9.803183610573612\n",
      "====================================================================================================\n",
      "Iteration:  923\n",
      "Previous theta :  [ 0.00950295 -0.12452123  0.10768666  0.01291041  0.06442003 -0.24955693\n",
      "  0.26307021  0.01525331 -0.36179207  0.30208029 -0.20615816 -0.25303737\n",
      "  0.07536267 -0.43470989]\n",
      "New theta_0 : [ 0.00950371 -0.12452862  0.10769783  0.01291652  0.06442231 -0.24959213\n",
      "  0.26306302  0.01525619 -0.36181973  0.30210731 -0.20617374 -0.25304303\n",
      "  0.07536141 -0.43470675]\n",
      "Training Error:  9.803180299528655\n",
      "====================================================================================================\n",
      "Iteration:  924\n",
      "Previous theta :  [ 0.00950371 -0.12452862  0.10769783  0.01291652  0.06442231 -0.24959213\n",
      "  0.26306302  0.01525619 -0.36181973  0.30210731 -0.20617374 -0.25304303\n",
      "  0.07536141 -0.43470675]\n",
      "New theta_0 : [ 0.00950446 -0.12453597  0.10770893  0.01292264  0.06442458 -0.24962714\n",
      "  0.26305587  0.01525906 -0.36184721  0.30213424 -0.20618931 -0.25304866\n",
      "  0.07536015 -0.43470363]\n",
      "Training Error:  9.8031770209852\n",
      "====================================================================================================\n",
      "Iteration:  925\n",
      "Previous theta :  [ 0.00950446 -0.12453597  0.10770893  0.01292264  0.06442458 -0.24962714\n",
      "  0.26305587  0.01525906 -0.36184721  0.30213424 -0.20618931 -0.25304866\n",
      "  0.07536015 -0.43470363]\n",
      "New theta_0 : [ 0.0095052  -0.12454329  0.10771996  0.01292875  0.06442683 -0.24966195\n",
      "  0.26304877  0.01526191 -0.36187453  0.30216109 -0.20620485 -0.25305427\n",
      "  0.0753589  -0.43470052]\n",
      "Training Error:  9.803173774591672\n",
      "====================================================================================================\n",
      "Iteration:  926\n",
      "Previous theta :  [ 0.0095052  -0.12454329  0.10771996  0.01292875  0.06442683 -0.24966195\n",
      "  0.26304877  0.01526191 -0.36187453  0.30216109 -0.20620485 -0.25305427\n",
      "  0.0753589  -0.43470052]\n",
      "New theta_0 : [ 0.00950594 -0.12455056  0.10773094  0.01293486  0.06442907 -0.24969657\n",
      "  0.26304171  0.01526475 -0.36190166  0.30218784 -0.20622037 -0.25305986\n",
      "  0.07535766 -0.43469743]\n",
      "Training Error:  9.803170560000497\n",
      "====================================================================================================\n",
      "Iteration:  927\n",
      "Previous theta :  [ 0.00950594 -0.12455056  0.10773094  0.01293486  0.06442907 -0.24969657\n",
      "  0.26304171  0.01526475 -0.36190166  0.30218784 -0.20622037 -0.25305986\n",
      "  0.07535766 -0.43469743]\n",
      "New theta_0 : [ 0.00950668 -0.1245578   0.10774184  0.01294097  0.06443129 -0.24973099\n",
      "  0.26303469  0.01526758 -0.36192863  0.3022145  -0.20623587 -0.25306541\n",
      "  0.07535643 -0.43469435]\n",
      "Training Error:  9.803167376868055\n",
      "====================================================================================================\n",
      "Iteration:  928\n",
      "Previous theta :  [ 0.00950668 -0.1245578   0.10774184  0.01294097  0.06443129 -0.24973099\n",
      "  0.26303469  0.01526758 -0.36192863  0.3022145  -0.20623587 -0.25306541\n",
      "  0.07535643 -0.43469435]\n",
      "New theta_0 : [ 0.00950741 -0.12456499  0.10775269  0.01294707  0.06443349 -0.24976522\n",
      "  0.26302771  0.0152704  -0.36195542  0.30224107 -0.20625135 -0.25307094\n",
      "  0.07535521 -0.43469128]\n",
      "Training Error:  9.803164224854632\n",
      "====================================================================================================\n",
      "Iteration:  929\n",
      "Previous theta :  [ 0.00950741 -0.12456499  0.10775269  0.01294707  0.06443349 -0.24976522\n",
      "  0.26302771  0.0152704  -0.36195542  0.30224107 -0.20625135 -0.25307094\n",
      "  0.07535521 -0.43469128]\n",
      "New theta_0 : [ 0.00950814 -0.12457215  0.10776347  0.01295317  0.06443568 -0.24979925\n",
      "  0.26302078  0.0152732  -0.36198204  0.30226755 -0.20626682 -0.25307645\n",
      "  0.075354   -0.43468823]\n",
      "Training Error:  9.803161103624378\n",
      "====================================================================================================\n",
      "Iteration:  930\n",
      "Previous theta :  [ 0.00950814 -0.12457215  0.10776347  0.01295317  0.06443568 -0.24979925\n",
      "  0.26302078  0.0152732  -0.36198204  0.30226755 -0.20626682 -0.25307645\n",
      "  0.075354   -0.43468823]\n",
      "New theta_0 : [ 0.00950886 -0.12457927  0.10777419  0.01295927  0.06443786 -0.24983309\n",
      "  0.26301388  0.01527598 -0.36200849  0.30229395 -0.20628226 -0.25308193\n",
      "  0.0753528  -0.4346852 ]\n",
      "Training Error:  9.803158012845252\n",
      "====================================================================================================\n",
      "Iteration:  931\n",
      "Previous theta :  [ 0.00950886 -0.12457927  0.10777419  0.01295927  0.06443786 -0.24983309\n",
      "  0.26301388  0.01527598 -0.36200849  0.30229395 -0.20628226 -0.25308193\n",
      "  0.0753528  -0.4346852 ]\n",
      "New theta_0 : [ 0.00950958 -0.12458636  0.10778485  0.01296536  0.06444002 -0.24986674\n",
      "  0.26300703  0.01527876 -0.36203478  0.30232025 -0.20629768 -0.25308739\n",
      "  0.07535161 -0.43468217]\n",
      "Training Error:  9.803154952188994\n",
      "====================================================================================================\n",
      "Iteration:  932\n",
      "Previous theta :  [ 0.00950958 -0.12458636  0.10778485  0.01296536  0.06444002 -0.24986674\n",
      "  0.26300703  0.01527876 -0.36203478  0.30232025 -0.20629768 -0.25308739\n",
      "  0.07535161 -0.43468217]\n",
      "New theta_0 : [ 0.0095103  -0.12459341  0.10779544  0.01297145  0.06444216 -0.2499002\n",
      "  0.26300022  0.01528152 -0.36206089  0.30234646 -0.20631309 -0.25309282\n",
      "  0.07535043 -0.43467917]\n",
      "Training Error:  9.80315192133106\n",
      "====================================================================================================\n",
      "Iteration:  933\n",
      "Previous theta :  [ 0.0095103  -0.12459341  0.10779544  0.01297145  0.06444216 -0.2499002\n",
      "  0.26300022  0.01528152 -0.36206089  0.30234646 -0.20631309 -0.25309282\n",
      "  0.07535043 -0.43467917]\n",
      "New theta_0 : [ 0.00951101 -0.12460042  0.10780598  0.01297753  0.06444429 -0.24993348\n",
      "  0.26299344  0.01528427 -0.36208684  0.30237259 -0.20632847 -0.25309822\n",
      "  0.07534925 -0.43467617]\n",
      "Training Error:  9.803148919950608\n",
      "====================================================================================================\n",
      "Iteration:  934\n",
      "Previous theta :  [ 0.00951101 -0.12460042  0.10780598  0.01297753  0.06444429 -0.24993348\n",
      "  0.26299344  0.01528427 -0.36208684  0.30237259 -0.20632847 -0.25309822\n",
      "  0.07534925 -0.43467617]\n",
      "New theta_0 : [ 0.00951172 -0.12460739  0.10781645  0.01298362  0.0644464  -0.24996656\n",
      "  0.26298671  0.01528701 -0.36211262  0.30239863 -0.20634383 -0.2531036\n",
      "  0.07534809 -0.43467319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.80314594773042\n",
      "====================================================================================================\n",
      "Iteration:  935\n",
      "Previous theta :  [ 0.00951172 -0.12460739  0.10781645  0.01298362  0.0644464  -0.24996656\n",
      "  0.26298671  0.01528701 -0.36211262  0.30239863 -0.20634383 -0.2531036\n",
      "  0.07534809 -0.43467319]\n",
      "New theta_0 : [ 0.00951242 -0.12461433  0.10782686  0.01298969  0.0644485  -0.24999946\n",
      "  0.26298002  0.01528973 -0.36213824  0.30242458 -0.20635918 -0.25310896\n",
      "  0.07534693 -0.43467023]\n",
      "Training Error:  9.803143004356885\n",
      "====================================================================================================\n",
      "Iteration:  936\n",
      "Previous theta :  [ 0.00951242 -0.12461433  0.10782686  0.01298969  0.0644485  -0.24999946\n",
      "  0.26298002  0.01528973 -0.36213824  0.30242458 -0.20635918 -0.25310896\n",
      "  0.07534693 -0.43467023]\n",
      "New theta_0 : [ 0.00951312 -0.12462123  0.10783721  0.01299577  0.06445058 -0.25003218\n",
      "  0.26297337  0.01529244 -0.36216369  0.30245045 -0.2063745  -0.25311429\n",
      "  0.07534579 -0.43466728]\n",
      "Training Error:  9.803140089519948\n",
      "====================================================================================================\n",
      "Iteration:  937\n",
      "Previous theta :  [ 0.00951312 -0.12462123  0.10783721  0.01299577  0.06445058 -0.25003218\n",
      "  0.26297337  0.01529244 -0.36216369  0.30245045 -0.2063745  -0.25311429\n",
      "  0.07534579 -0.43466728]\n",
      "New theta_0 : [ 0.00951381 -0.12462809  0.10784751  0.01300183  0.06445265 -0.25006471\n",
      "  0.26296675  0.01529514 -0.36218899  0.30247622 -0.20638981 -0.25311959\n",
      "  0.07534465 -0.43466434]\n",
      "Training Error:  9.803137202913074\n",
      "====================================================================================================\n",
      "Iteration:  938\n",
      "Previous theta :  [ 0.00951381 -0.12462809  0.10784751  0.01300183  0.06445265 -0.25006471\n",
      "  0.26296675  0.01529514 -0.36218899  0.30247622 -0.20638981 -0.25311959\n",
      "  0.07534465 -0.43466434]\n",
      "New theta_0 : [ 0.00951451 -0.12463492  0.10785774  0.0130079   0.06445471 -0.25009706\n",
      "  0.26296018  0.01529783 -0.36221412  0.30250192 -0.20640509 -0.25312487\n",
      "  0.07534352 -0.43466142]\n",
      "Training Error:  9.803134344233198\n",
      "====================================================================================================\n",
      "Iteration:  939\n",
      "Previous theta :  [ 0.00951451 -0.12463492  0.10785774  0.0130079   0.06445471 -0.25009706\n",
      "  0.26296018  0.01529783 -0.36221412  0.30250192 -0.20640509 -0.25312487\n",
      "  0.07534352 -0.43466142]\n",
      "New theta_0 : [ 0.00951519 -0.12464171  0.10786791  0.01301396  0.06445675 -0.25012922\n",
      "  0.26295364  0.0153005  -0.36223909  0.30252752 -0.20642035 -0.25313013\n",
      "  0.0753424  -0.43465851]\n",
      "Training Error:  9.80313151318069\n",
      "====================================================================================================\n",
      "Iteration:  940\n",
      "Previous theta :  [ 0.00951519 -0.12464171  0.10786791  0.01301396  0.06445675 -0.25012922\n",
      "  0.26295364  0.0153005  -0.36223909  0.30252752 -0.20642035 -0.25313013\n",
      "  0.0753424  -0.43465851]\n",
      "New theta_0 : [ 0.00951587 -0.12464847  0.10787803  0.01302001  0.06445877 -0.25016121\n",
      "  0.26294715  0.01530316 -0.3622639   0.30255304 -0.20643559 -0.25313536\n",
      "  0.07534129 -0.43465561]\n",
      "Training Error:  9.803128709459312\n",
      "====================================================================================================\n",
      "Iteration:  941\n",
      "Previous theta :  [ 0.00951587 -0.12464847  0.10787803  0.01302001  0.06445877 -0.25016121\n",
      "  0.26294715  0.01530316 -0.3622639   0.30255304 -0.20643559 -0.25313536\n",
      "  0.07534129 -0.43465561]\n",
      "New theta_0 : [ 0.00951655 -0.12465519  0.10788808  0.01302606  0.06446078 -0.25019301\n",
      "  0.26294069  0.01530581 -0.36228855  0.30257847 -0.20645082 -0.25314057\n",
      "  0.07534018 -0.43465273]\n",
      "Training Error:  9.803125932776187\n",
      "====================================================================================================\n",
      "Iteration:  942\n",
      "Previous theta :  [ 0.00951655 -0.12465519  0.10788808  0.01302606  0.06446078 -0.25019301\n",
      "  0.26294069  0.01530581 -0.36228855  0.30257847 -0.20645082 -0.25314057\n",
      "  0.07534018 -0.43465273]\n",
      "New theta_0 : [ 0.00951723 -0.12466188  0.10789808  0.01303211  0.06446278 -0.25022463\n",
      "  0.26293427  0.01530845 -0.36231304  0.30260382 -0.20646602 -0.25314575\n",
      "  0.07533909 -0.43464986]\n",
      "Training Error:  9.803123182841755\n",
      "====================================================================================================\n",
      "Iteration:  943\n",
      "Previous theta :  [ 0.00951723 -0.12466188  0.10789808  0.01303211  0.06446278 -0.25022463\n",
      "  0.26293427  0.01530845 -0.36231304  0.30260382 -0.20646602 -0.25314575\n",
      "  0.07533909 -0.43464986]\n",
      "New theta_0 : [ 0.0095179  -0.12466853  0.10790802  0.01303815  0.06446476 -0.25025608\n",
      "  0.26292789  0.01531108 -0.36233738  0.30262909 -0.2064812  -0.25315091\n",
      "  0.075338   -0.43464701]\n",
      "Training Error:  9.803120459369723\n",
      "====================================================================================================\n",
      "Iteration:  944\n",
      "Previous theta :  [ 0.0095179  -0.12466853  0.10790802  0.01303815  0.06446476 -0.25025608\n",
      "  0.26292789  0.01531108 -0.36233738  0.30262909 -0.2064812  -0.25315091\n",
      "  0.075338   -0.43464701]\n",
      "New theta_0 : [ 0.00951857 -0.12467515  0.1079179   0.01304419  0.06446673 -0.25028735\n",
      "  0.26292154  0.01531369 -0.36236156  0.30265427 -0.20649636 -0.25315605\n",
      "  0.07533692 -0.43464417]\n",
      "Training Error:  9.803117762077047\n",
      "====================================================================================================\n",
      "Iteration:  945\n",
      "Previous theta :  [ 0.00951857 -0.12467515  0.1079179   0.01304419  0.06446673 -0.25028735\n",
      "  0.26292154  0.01531369 -0.36236156  0.30265427 -0.20649636 -0.25315605\n",
      "  0.07533692 -0.43464417]\n",
      "New theta_0 : [ 0.00951923 -0.12468173  0.10792773  0.01305022  0.06446868 -0.25031844\n",
      "  0.26291523  0.01531629 -0.36238559  0.30267937 -0.2065115  -0.25316116\n",
      "  0.07533585 -0.43464134]\n",
      "Training Error:  9.80311509068388\n",
      "====================================================================================================\n",
      "Iteration:  946\n",
      "Previous theta :  [ 0.00951923 -0.12468173  0.10792773  0.01305022  0.06446868 -0.25031844\n",
      "  0.26291523  0.01531629 -0.36238559  0.30267937 -0.2065115  -0.25316116\n",
      "  0.07533585 -0.43464134]\n",
      "New theta_0 : [ 0.00951989 -0.12468828  0.1079375   0.01305625  0.06447062 -0.25034936\n",
      "  0.26290896  0.01531888 -0.36240946  0.30270438 -0.20652662 -0.25316625\n",
      "  0.07533479 -0.43463853]\n",
      "Training Error:  9.803112444913541\n",
      "====================================================================================================\n",
      "Iteration:  947\n",
      "Previous theta :  [ 0.00951989 -0.12468828  0.1079375   0.01305625  0.06447062 -0.25034936\n",
      "  0.26290896  0.01531888 -0.36240946  0.30270438 -0.20652662 -0.25316625\n",
      "  0.07533479 -0.43463853]\n",
      "New theta_0 : [ 0.00952054 -0.1246948   0.10794721  0.01306227  0.06447255 -0.25038011\n",
      "  0.26290273  0.01532146 -0.36243319  0.30272931 -0.20654172 -0.25317131\n",
      "  0.07533374 -0.43463573]\n",
      "Training Error:  9.803109824492479\n",
      "====================================================================================================\n",
      "Iteration:  948\n",
      "Previous theta :  [ 0.00952054 -0.1246948   0.10794721  0.01306227  0.06447255 -0.25038011\n",
      "  0.26290273  0.01532146 -0.36243319  0.30272931 -0.20654172 -0.25317131\n",
      "  0.07533374 -0.43463573]\n",
      "New theta_0 : [ 0.00952119 -0.12470128  0.10795687  0.01306829  0.06447446 -0.25041068\n",
      "  0.26289653  0.01532402 -0.36245676  0.30275415 -0.2065568  -0.25317636\n",
      "  0.07533269 -0.43463294]\n",
      "Training Error:  9.80310722915023\n",
      "====================================================================================================\n",
      "Iteration:  949\n",
      "Previous theta :  [ 0.00952119 -0.12470128  0.10795687  0.01306829  0.06447446 -0.25041068\n",
      "  0.26289653  0.01532402 -0.36245676  0.30275415 -0.2065568  -0.25317636\n",
      "  0.07533269 -0.43463294]\n",
      "New theta_0 : [ 0.00952184 -0.12470772  0.10796647  0.0130743   0.06447636 -0.25044108\n",
      "  0.26289037  0.01532657 -0.36248017  0.30277892 -0.20657186 -0.25318138\n",
      "  0.07533166 -0.43463017]\n",
      "Training Error:  9.803104658619386\n",
      "====================================================================================================\n",
      "Iteration:  950\n",
      "Previous theta :  [ 0.00952184 -0.12470772  0.10796647  0.0130743   0.06447636 -0.25044108\n",
      "  0.26289037  0.01532657 -0.36248017  0.30277892 -0.20657186 -0.25318138\n",
      "  0.07533166 -0.43463017]\n",
      "New theta_0 : [ 0.00952249 -0.12471413  0.10797602  0.01308031  0.06447824 -0.25047131\n",
      "  0.26288425  0.01532912 -0.36250344  0.3028036  -0.2065869  -0.25318637\n",
      "  0.07533063 -0.43462741]\n",
      "Training Error:  9.803102112635564\n",
      "====================================================================================================\n",
      "Iteration:  951\n",
      "Previous theta :  [ 0.00952249 -0.12471413  0.10797602  0.01308031  0.06447824 -0.25047131\n",
      "  0.26288425  0.01532912 -0.36250344  0.3028036  -0.2065869  -0.25318637\n",
      "  0.07533063 -0.43462741]\n",
      "New theta_0 : [ 0.00952313 -0.12472051  0.10798551  0.01308631  0.06448012 -0.25050137\n",
      "  0.26287816  0.01533165 -0.36252656  0.3028282  -0.20660192 -0.25319134\n",
      "  0.07532961 -0.43462466]\n",
      "Training Error:  9.803099590937357\n",
      "====================================================================================================\n",
      "Iteration:  952\n",
      "Previous theta :  [ 0.00952313 -0.12472051  0.10798551  0.01308631  0.06448012 -0.25050137\n",
      "  0.26287816  0.01533165 -0.36252656  0.3028282  -0.20660192 -0.25319134\n",
      "  0.07532961 -0.43462466]\n",
      "New theta_0 : [ 0.00952376 -0.12472686  0.10799495  0.0130923   0.06448197 -0.25053126\n",
      "  0.26287211  0.01533416 -0.36254953  0.30285272 -0.20661691 -0.25319629\n",
      "  0.07532859 -0.43462193]\n",
      "Training Error:  9.803097093266315\n",
      "====================================================================================================\n",
      "Iteration:  953\n",
      "Previous theta :  [ 0.00952376 -0.12472686  0.10799495  0.0130923   0.06448197 -0.25053126\n",
      "  0.26287211  0.01533416 -0.36254953  0.30285272 -0.20661691 -0.25319629\n",
      "  0.07532859 -0.43462193]\n",
      "New theta_0 : [ 0.00952439 -0.12473317  0.10800433  0.0130983   0.06448382 -0.25056098\n",
      "  0.2628661   0.01533667 -0.36257236  0.30287715 -0.20663189 -0.25320122\n",
      "  0.07532759 -0.43461921]\n",
      "Training Error:  9.803094619366906\n",
      "====================================================================================================\n",
      "Iteration:  954\n",
      "Previous theta :  [ 0.00952439 -0.12473317  0.10800433  0.0130983   0.06448382 -0.25056098\n",
      "  0.2628661   0.01533667 -0.36257236  0.30287715 -0.20663189 -0.25320122\n",
      "  0.07532759 -0.43461921]\n",
      "New theta_0 : [ 0.00952502 -0.12473945  0.10801366  0.01310428  0.06448565 -0.25059053\n",
      "  0.26286011  0.01533917 -0.36259504  0.30290151 -0.20664685 -0.25320612\n",
      "  0.07532659 -0.4346165 ]\n",
      "Training Error:  9.803092168986472\n",
      "====================================================================================================\n",
      "Iteration:  955\n",
      "Previous theta :  [ 0.00952502 -0.12473945  0.10801366  0.01310428  0.06448565 -0.25059053\n",
      "  0.26286011  0.01533917 -0.36259504  0.30290151 -0.20664685 -0.25320612\n",
      "  0.07532659 -0.4346165 ]\n",
      "New theta_0 : [ 0.00952565 -0.1247457   0.10802294  0.01311026  0.06448747 -0.25061992\n",
      "  0.26285417  0.01534165 -0.36261757  0.30292578 -0.20666178 -0.253211\n",
      "  0.0753256  -0.4346138 ]\n",
      "Training Error:  9.803089741875208\n",
      "====================================================================================================\n",
      "Iteration:  956\n",
      "Previous theta :  [ 0.00952565 -0.1247457   0.10802294  0.01311026  0.06448747 -0.25061992\n",
      "  0.26285417  0.01534165 -0.36261757  0.30292578 -0.20666178 -0.253211\n",
      "  0.0753256  -0.4346138 ]\n",
      "New theta_0 : [ 0.00952627 -0.12475192  0.10803216  0.01311624  0.06448927 -0.25064914\n",
      "  0.26284826  0.01534412 -0.36263996  0.30294998 -0.20667669 -0.25321586\n",
      "  0.07532462 -0.43461112]\n",
      "Training Error:  9.80308733778613\n",
      "====================================================================================================\n",
      "Iteration:  957\n",
      "Previous theta :  [ 0.00952627 -0.12475192  0.10803216  0.01311624  0.06448927 -0.25064914\n",
      "  0.26284826  0.01534412 -0.36263996  0.30294998 -0.20667669 -0.25321586\n",
      "  0.07532462 -0.43461112]\n",
      "New theta_0 : [ 0.00952689 -0.1247581   0.10804133  0.0131222   0.06449107 -0.2506782\n",
      "  0.26284238  0.01534659 -0.3626622   0.30297409 -0.20669159 -0.2532207\n",
      "  0.07532364 -0.43460846]\n",
      "Training Error:  9.803084956475024\n",
      "====================================================================================================\n",
      "Iteration:  958\n",
      "Previous theta :  [ 0.00952689 -0.1247581   0.10804133  0.0131222   0.06449107 -0.2506782\n",
      "  0.26284238  0.01534659 -0.3626622   0.30297409 -0.20669159 -0.2532207\n",
      "  0.07532364 -0.43460846]\n",
      "New theta_0 : [ 0.0095275  -0.12476425  0.10805044  0.01312817  0.06449284 -0.25070709\n",
      "  0.26283654  0.01534904 -0.36268431  0.30299813 -0.20670646 -0.25322551\n",
      "  0.07532268 -0.4346058 ]\n",
      "Training Error:  9.803082597700437\n",
      "====================================================================================================\n",
      "Iteration:  959\n",
      "Previous theta :  [ 0.0095275  -0.12476425  0.10805044  0.01312817  0.06449284 -0.25070709\n",
      "  0.26283654  0.01534904 -0.36268431  0.30299813 -0.20670646 -0.25322551\n",
      "  0.07532268 -0.4346058 ]\n",
      "New theta_0 : [ 0.00952811 -0.12477037  0.10805951  0.01313412  0.06449461 -0.25073582\n",
      "  0.26283073  0.01535148 -0.36270627  0.30302209 -0.20672131 -0.2532303\n",
      "  0.07532172 -0.43460316]\n",
      "Training Error:  9.803080261223633\n",
      "====================================================================================================\n",
      "Iteration:  960\n",
      "Previous theta :  [ 0.00952811 -0.12477037  0.10805951  0.01313412  0.06449461 -0.25073582\n",
      "  0.26283073  0.01535148 -0.36270627  0.30302209 -0.20672131 -0.2532303\n",
      "  0.07532172 -0.43460316]\n",
      "New theta_0 : [ 0.00952872 -0.12477645  0.10806852  0.01314008  0.06449637 -0.25076439\n",
      "  0.26282496  0.01535391 -0.36272809  0.30304596 -0.20673614 -0.25323507\n",
      "  0.07532077 -0.43460053]\n",
      "Training Error:  9.803077946808555\n",
      "====================================================================================================\n",
      "Iteration:  961\n",
      "Previous theta :  [ 0.00952872 -0.12477645  0.10806852  0.01314008  0.06449637 -0.25076439\n",
      "  0.26282496  0.01535391 -0.36272809  0.30304596 -0.20673614 -0.25323507\n",
      "  0.07532077 -0.43460053]\n",
      "New theta_0 : [ 0.00952932 -0.12478251  0.10807748  0.01314602  0.06449811 -0.2507928\n",
      "  0.26281922  0.01535632 -0.36274977  0.30306976 -0.20675095 -0.25323982\n",
      "  0.07531982 -0.43459791]\n",
      "Training Error:  9.80307565422182\n",
      "====================================================================================================\n",
      "Iteration:  962\n",
      "Previous theta :  [ 0.00952932 -0.12478251  0.10807748  0.01314602  0.06449811 -0.2507928\n",
      "  0.26281922  0.01535632 -0.36274977  0.30306976 -0.20675095 -0.25323982\n",
      "  0.07531982 -0.43459791]\n",
      "New theta_0 : [ 0.00952992 -0.12478853  0.10808639  0.01315196  0.06449983 -0.25082105\n",
      "  0.26281351  0.01535873 -0.36277131  0.30309348 -0.20676573 -0.25324455\n",
      "  0.07531889 -0.43459531]\n",
      "Training Error:  9.803073383232652\n",
      "====================================================================================================\n",
      "Iteration:  963\n",
      "Previous theta :  [ 0.00952992 -0.12478853  0.10808639  0.01315196  0.06449983 -0.25082105\n",
      "  0.26281351  0.01535873 -0.36277131  0.30309348 -0.20676573 -0.25324455\n",
      "  0.07531889 -0.43459531]\n",
      "New theta_0 : [ 0.00953052 -0.12479453  0.10809525  0.0131579   0.06450155 -0.25084914\n",
      "  0.26280784  0.01536113 -0.36279272  0.30311712 -0.2067805  -0.25324925\n",
      "  0.07531796 -0.43459272]\n",
      "Training Error:  9.803071133612876\n",
      "====================================================================================================\n",
      "Iteration:  964\n",
      "Previous theta :  [ 0.00953052 -0.12479453  0.10809525  0.0131579   0.06450155 -0.25084914\n",
      "  0.26280784  0.01536113 -0.36279272  0.30311712 -0.2067805  -0.25324925\n",
      "  0.07531796 -0.43459272]\n",
      "New theta_0 : [ 0.00953111 -0.12480049  0.10810406  0.01316382  0.06450325 -0.25087708\n",
      "  0.2628022   0.01536351 -0.36281398  0.30314069 -0.20679525 -0.25325393\n",
      "  0.07531703 -0.43459014]\n",
      "Training Error:  9.803068905136888\n",
      "====================================================================================================\n",
      "Iteration:  965\n",
      "Previous theta :  [ 0.00953111 -0.12480049  0.10810406  0.01316382  0.06450325 -0.25087708\n",
      "  0.2628022   0.01536351 -0.36281398  0.30314069 -0.20679525 -0.25325393\n",
      "  0.07531703 -0.43459014]\n",
      "New theta_0 : [ 0.0095317  -0.12480642  0.10811282  0.01316974  0.06450494 -0.25090485\n",
      "  0.26279659  0.01536588 -0.36283511  0.30316417 -0.20680997 -0.25325859\n",
      "  0.07531612 -0.43458758]\n",
      "Training Error:  9.80306669758161\n",
      "====================================================================================================\n",
      "Iteration:  966\n",
      "Previous theta :  [ 0.0095317  -0.12480642  0.10811282  0.01316974  0.06450494 -0.25090485\n",
      "  0.26279659  0.01536588 -0.36283511  0.30316417 -0.20680997 -0.25325859\n",
      "  0.07531612 -0.43458758]\n",
      "New theta_0 : [ 0.00953229 -0.12481232  0.10812152  0.01317566  0.06450662 -0.25093247\n",
      "  0.26279101  0.01536825 -0.36285611  0.30318758 -0.20682467 -0.25326323\n",
      "  0.07531521 -0.43458503]\n",
      "Training Error:  9.803064510726474\n",
      "====================================================================================================\n",
      "Iteration:  967\n",
      "Previous theta :  [ 0.00953229 -0.12481232  0.10812152  0.01317566  0.06450662 -0.25093247\n",
      "  0.26279101  0.01536825 -0.36285611  0.30318758 -0.20682467 -0.25326323\n",
      "  0.07531521 -0.43458503]\n",
      "New theta_0 : [ 0.00953287 -0.12481819  0.10813018  0.01318157  0.06450829 -0.25095993\n",
      "  0.26278547  0.0153706  -0.36287696  0.30321092 -0.20683936 -0.25326785\n",
      "  0.07531431 -0.43458249]\n",
      "Training Error:  9.803062344353389\n",
      "====================================================================================================\n",
      "Iteration:  968\n",
      "Previous theta :  [ 0.00953287 -0.12481819  0.10813018  0.01318157  0.06450829 -0.25095993\n",
      "  0.26278547  0.0153706  -0.36287696  0.30321092 -0.20683936 -0.25326785\n",
      "  0.07531431 -0.43458249]\n",
      "New theta_0 : [ 0.00953345 -0.12482403  0.10813879  0.01318747  0.06450994 -0.25098724\n",
      "  0.26277996  0.01537294 -0.36289769  0.30323417 -0.20685402 -0.25327245\n",
      "  0.07531342 -0.43457996]\n",
      "Training Error:  9.80306019824671\n",
      "====================================================================================================\n",
      "Iteration:  969\n",
      "Previous theta :  [ 0.00953345 -0.12482403  0.10813879  0.01318747  0.06450994 -0.25098724\n",
      "  0.26277996  0.01537294 -0.36289769  0.30323417 -0.20685402 -0.25327245\n",
      "  0.07531342 -0.43457996]\n",
      "New theta_0 : [ 0.00953402 -0.12482983  0.10814735  0.01319337  0.06451159 -0.2510144\n",
      "  0.26277448  0.01537528 -0.36291828  0.30325735 -0.20686866 -0.25327702\n",
      "  0.07531253 -0.43457744]\n",
      "Training Error:  9.803058072193215\n",
      "====================================================================================================\n",
      "Iteration:  970\n",
      "Previous theta :  [ 0.00953402 -0.12482983  0.10814735  0.01319337  0.06451159 -0.2510144\n",
      "  0.26277448  0.01537528 -0.36291828  0.30325735 -0.20686866 -0.25327702\n",
      "  0.07531253 -0.43457744]\n",
      "New theta_0 : [ 0.00953459 -0.12483561  0.10815586  0.01319926  0.06451322 -0.2510414\n",
      "  0.26276904  0.0153776  -0.36293874  0.30328046 -0.20688327 -0.25328158\n",
      "  0.07531165 -0.43457494]\n",
      "Training Error:  9.803055965982066\n",
      "====================================================================================================\n",
      "Iteration:  971\n",
      "Previous theta :  [ 0.00953459 -0.12483561  0.10815586  0.01319926  0.06451322 -0.2510414\n",
      "  0.26276904  0.0153776  -0.36293874  0.30328046 -0.20688327 -0.25328158\n",
      "  0.07531165 -0.43457494]\n",
      "New theta_0 : [ 0.00953516 -0.12484136  0.10816432  0.01320514  0.06451484 -0.25106825\n",
      "  0.26276362  0.01537991 -0.36295907  0.30330348 -0.20689787 -0.25328611\n",
      "  0.07531078 -0.43457245]\n",
      "Training Error:  9.8030538794048\n",
      "====================================================================================================\n",
      "Iteration:  972\n",
      "Previous theta :  [ 0.00953516 -0.12484136  0.10816432  0.01320514  0.06451484 -0.25106825\n",
      "  0.26276362  0.01537991 -0.36295907  0.30330348 -0.20689787 -0.25328611\n",
      "  0.07531078 -0.43457245]\n",
      "New theta_0 : [ 0.00953573 -0.12484708  0.10817273  0.01321102  0.06451644 -0.25109495\n",
      "  0.26275824  0.01538221 -0.36297927  0.30332644 -0.20691245 -0.25329062\n",
      "  0.07530991 -0.43456997]\n",
      "Training Error:  9.803051812255287\n",
      "====================================================================================================\n",
      "Iteration:  973\n",
      "Previous theta :  [ 0.00953573 -0.12484708  0.10817273  0.01321102  0.06451644 -0.25109495\n",
      "  0.26275824  0.01538221 -0.36297927  0.30332644 -0.20691245 -0.25329062\n",
      "  0.07530991 -0.43456997]\n",
      "New theta_0 : [ 0.00953629 -0.12485277  0.1081811   0.01321689  0.06451804 -0.2511215\n",
      "  0.26275289  0.0153845  -0.36299934  0.30334932 -0.206927   -0.25329512\n",
      "  0.07530906 -0.43456751]\n",
      "Training Error:  9.803049764329694\n",
      "====================================================================================================\n",
      "Iteration:  974\n",
      "Previous theta :  [ 0.00953629 -0.12485277  0.1081811   0.01321689  0.06451804 -0.2511215\n",
      "  0.26275289  0.0153845  -0.36299934  0.30334932 -0.206927   -0.25329512\n",
      "  0.07530906 -0.43456751]\n",
      "New theta_0 : [ 0.00953685 -0.12485843  0.10818942  0.01322275  0.06451962 -0.2511479\n",
      "  0.26274757  0.01538678 -0.36301928  0.30337212 -0.20694153 -0.25329959\n",
      "  0.0753082  -0.43456505]\n",
      "Training Error:  9.803047735426489\n",
      "====================================================================================================\n",
      "Iteration:  975\n",
      "Previous theta :  [ 0.00953685 -0.12485843  0.10818942  0.01322275  0.06451962 -0.2511479\n",
      "  0.26274757  0.01538678 -0.36301928  0.30337212 -0.20694153 -0.25329959\n",
      "  0.0753082  -0.43456505]\n",
      "New theta_0 : [ 0.0095374  -0.12486406  0.10819769  0.01322861  0.06452119 -0.25117416\n",
      "  0.26274228  0.01538905 -0.36303909  0.30339485 -0.20695604 -0.25330404\n",
      "  0.07530736 -0.43456261]\n",
      "Training Error:  9.803045725346388\n",
      "====================================================================================================\n",
      "Iteration:  976\n",
      "Previous theta :  [ 0.0095374  -0.12486406  0.10819769  0.01322861  0.06452119 -0.25117416\n",
      "  0.26274228  0.01538905 -0.36303909  0.30339485 -0.20695604 -0.25330404\n",
      "  0.07530736 -0.43456261]\n",
      "New theta_0 : [ 0.00953796 -0.12486966  0.10820591  0.01323446  0.06452275 -0.25120026\n",
      "  0.26273702  0.01539131 -0.36305877  0.3034175  -0.20697053 -0.25330847\n",
      "  0.07530652 -0.43456018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  9.803043733892336\n",
      "====================================================================================================\n",
      "Iteration:  977\n",
      "Previous theta :  [ 0.00953796 -0.12486966  0.10820591  0.01323446  0.06452275 -0.25120026\n",
      "  0.26273702  0.01539131 -0.36305877  0.3034175  -0.20697053 -0.25330847\n",
      "  0.07530652 -0.43456018]\n",
      "New theta_0 : [ 0.0095385  -0.12487524  0.10821409  0.01324031  0.0645243  -0.25122622\n",
      "  0.26273179  0.01539356 -0.36307833  0.30344008 -0.206985   -0.25331288\n",
      "  0.07530569 -0.43455776]\n",
      "Training Error:  9.803041760869485\n",
      "====================================================================================================\n",
      "Iteration:  978\n",
      "Previous theta :  [ 0.0095385  -0.12487524  0.10821409  0.01324031  0.0645243  -0.25122622\n",
      "  0.26273179  0.01539356 -0.36307833  0.30344008 -0.206985   -0.25331288\n",
      "  0.07530569 -0.43455776]\n",
      "New theta_0 : [ 0.00953905 -0.12488078  0.10822222  0.01324614  0.06452584 -0.25125203\n",
      "  0.26272659  0.0153958  -0.36309776  0.30346259 -0.20699945 -0.25331727\n",
      "  0.07530486 -0.43455536]\n",
      "Training Error:  9.80303980608517\n",
      "====================================================================================================\n",
      "Iteration:  979\n",
      "Previous theta :  [ 0.00953905 -0.12488078  0.10822222  0.01324614  0.06452584 -0.25125203\n",
      "  0.26272659  0.0153958  -0.36309776  0.30346259 -0.20699945 -0.25331727\n",
      "  0.07530486 -0.43455536]\n",
      "New theta_0 : [ 0.00953959 -0.1248863   0.1082303   0.01325197  0.06452736 -0.2512777\n",
      "  0.26272143  0.01539803 -0.36311707  0.30348503 -0.20701387 -0.25332164\n",
      "  0.07530405 -0.43455297]\n",
      "Training Error:  9.80303786934887\n",
      "====================================================================================================\n",
      "Iteration:  980\n",
      "Previous theta :  [ 0.00953959 -0.1248863   0.1082303   0.01325197  0.06452736 -0.2512777\n",
      "  0.26272143  0.01539803 -0.36311707  0.30348503 -0.20701387 -0.25332164\n",
      "  0.07530405 -0.43455297]\n",
      "New theta_0 : [ 0.00954013 -0.12489178  0.10823834  0.0132578   0.06452888 -0.25130322\n",
      "  0.26271629  0.01540025 -0.36313625  0.30350739 -0.20702828 -0.25332599\n",
      "  0.07530323 -0.43455059]\n",
      "Training Error:  9.8030359504722\n",
      "====================================================================================================\n",
      "Iteration:  981\n",
      "Previous theta :  [ 0.00954013 -0.12489178  0.10823834  0.0132578   0.06452888 -0.25130322\n",
      "  0.26271629  0.01540025 -0.36313625  0.30350739 -0.20702828 -0.25332599\n",
      "  0.07530323 -0.43455059]\n",
      "New theta_0 : [ 0.00954067 -0.12489724  0.10824633  0.01326361  0.06453038 -0.2513286\n",
      "  0.26271118  0.01540246 -0.36315531  0.30352968 -0.20704266 -0.25333031\n",
      "  0.07530243 -0.43454822]\n",
      "Training Error:  9.803034049268879\n",
      "====================================================================================================\n",
      "Iteration:  982\n",
      "Previous theta :  [ 0.00954067 -0.12489724  0.10824633  0.01326361  0.06453038 -0.2513286\n",
      "  0.26271118  0.01540246 -0.36315531  0.30352968 -0.20704266 -0.25333031\n",
      "  0.07530243 -0.43454822]\n",
      "New theta_0 : [ 0.0095412  -0.12490267  0.10825428  0.01326942  0.06453188 -0.25135384\n",
      "  0.2627061   0.01540466 -0.36317424  0.30355189 -0.20705702 -0.25333462\n",
      "  0.07530163 -0.43454586]\n",
      "Training Error:  9.803032165554706\n",
      "====================================================================================================\n",
      "Iteration:  983\n",
      "Previous theta :  [ 0.0095412  -0.12490267  0.10825428  0.01326942  0.06453188 -0.25135384\n",
      "  0.2627061   0.01540466 -0.36317424  0.30355189 -0.20705702 -0.25333462\n",
      "  0.07530163 -0.43454586]\n",
      "New theta_0 : [ 0.00954173 -0.12490807  0.10826218  0.01327522  0.06453336 -0.25137893\n",
      "  0.26270105  0.01540685 -0.36319306  0.30357404 -0.20707136 -0.25333891\n",
      "  0.07530084 -0.43454351]\n",
      "Training Error:  9.80303029914753\n",
      "====================================================================================================\n",
      "Iteration:  984\n",
      "Previous theta :  [ 0.00954173 -0.12490807  0.10826218  0.01327522  0.06453336 -0.25137893\n",
      "  0.26270105  0.01540685 -0.36319306  0.30357404 -0.20707136 -0.25333891\n",
      "  0.07530084 -0.43454351]\n",
      "New theta_0 : [ 0.00954226 -0.12491345  0.10827004  0.01328102  0.06453483 -0.25140389\n",
      "  0.26269603  0.01540903 -0.36321175  0.30359611 -0.20708568 -0.25334318\n",
      "  0.07530005 -0.43454118]\n",
      "Training Error:  9.803028449867245\n",
      "====================================================================================================\n",
      "Iteration:  985\n",
      "Previous theta :  [ 0.00954226 -0.12491345  0.10827004  0.01328102  0.06453483 -0.25140389\n",
      "  0.26269603  0.01540903 -0.36321175  0.30359611 -0.20708568 -0.25334318\n",
      "  0.07530005 -0.43454118]\n",
      "New theta_0 : [ 0.00954278 -0.1249188   0.10827785  0.01328681  0.06453629 -0.2514287\n",
      "  0.26269104  0.0154112  -0.36323032  0.30361811 -0.20709997 -0.25334743\n",
      "  0.07529927 -0.43453886]\n",
      "Training Error:  9.803026617535746\n",
      "====================================================================================================\n",
      "Iteration:  986\n",
      "Previous theta :  [ 0.00954278 -0.1249188   0.10827785  0.01328681  0.06453629 -0.2514287\n",
      "  0.26269104  0.0154112  -0.36323032  0.30361811 -0.20709997 -0.25334743\n",
      "  0.07529927 -0.43453886]\n",
      "New theta_0 : [ 0.0095433  -0.12492412  0.10828562  0.01329259  0.06453774 -0.25145337\n",
      "  0.26268607  0.01541336 -0.36324878  0.30364004 -0.20711425 -0.25335166\n",
      "  0.0752985  -0.43453655]\n",
      "Training Error:  9.803024801976907\n",
      "====================================================================================================\n",
      "Iteration:  987\n",
      "Previous theta :  [ 0.0095433  -0.12492412  0.10828562  0.01329259  0.06453774 -0.25145337\n",
      "  0.26268607  0.01541336 -0.36324878  0.30364004 -0.20711425 -0.25335166\n",
      "  0.0752985  -0.43453655]\n",
      "New theta_0 : [ 0.00954382 -0.12492941  0.10829335  0.01329836  0.06453917 -0.25147791\n",
      "  0.26268114  0.01541551 -0.36326711  0.3036619  -0.2071285  -0.25335588\n",
      "  0.07529773 -0.43453425]\n",
      "Training Error:  9.803023003016579\n",
      "====================================================================================================\n",
      "Iteration:  988\n",
      "Previous theta :  [ 0.00954382 -0.12492941  0.10829335  0.01329836  0.06453917 -0.25147791\n",
      "  0.26268114  0.01541551 -0.36326711  0.3036619  -0.2071285  -0.25335588\n",
      "  0.07529773 -0.43453425]\n",
      "New theta_0 : [ 0.00954433 -0.12493467  0.10830103  0.01330413  0.0645406  -0.25150231\n",
      "  0.26267623  0.01541766 -0.36328533  0.30368369 -0.20714273 -0.25336007\n",
      "  0.07529697 -0.43453196]\n",
      "Training Error:  9.803021220482542\n",
      "====================================================================================================\n",
      "Iteration:  989\n",
      "Previous theta :  [ 0.00954433 -0.12493467  0.10830103  0.01330413  0.0645406  -0.25150231\n",
      "  0.26267623  0.01541766 -0.36328533  0.30368369 -0.20714273 -0.25336007\n",
      "  0.07529697 -0.43453196]\n",
      "New theta_0 : [ 0.00954484 -0.12493991  0.10830866  0.01330989  0.06454202 -0.25152657\n",
      "  0.26267136  0.01541979 -0.36330343  0.3037054  -0.20715694 -0.25336424\n",
      "  0.07529621 -0.43452968]\n",
      "Training Error:  9.803019454204499\n",
      "====================================================================================================\n",
      "Iteration:  990\n",
      "Previous theta :  [ 0.00954484 -0.12493991  0.10830866  0.01330989  0.06454202 -0.25152657\n",
      "  0.26267136  0.01541979 -0.36330343  0.3037054  -0.20715694 -0.25336424\n",
      "  0.07529621 -0.43452968]\n",
      "New theta_0 : [ 0.00954535 -0.12494512  0.10831626  0.01331564  0.06454342 -0.25155069\n",
      "  0.26266651  0.01542191 -0.36332141  0.30372705 -0.20717113 -0.25336839\n",
      "  0.07529546 -0.43452742]\n",
      "Training Error:  9.80301770401405\n",
      "====================================================================================================\n",
      "Iteration:  991\n",
      "Previous theta :  [ 0.00954535 -0.12494512  0.10831626  0.01331564  0.06454342 -0.25155069\n",
      "  0.26266651  0.01542191 -0.36332141  0.30372705 -0.20717113 -0.25336839\n",
      "  0.07529546 -0.43452742]\n",
      "New theta_0 : [ 0.00954585 -0.12495031  0.10832381  0.01332139  0.06454482 -0.25157468\n",
      "  0.26266168  0.01542403 -0.36333927  0.30374863 -0.20718529 -0.25337253\n",
      "  0.07529472 -0.43452517]\n",
      "Training Error:  9.803015969744662\n",
      "====================================================================================================\n",
      "Iteration:  992\n",
      "Previous theta :  [ 0.00954585 -0.12495031  0.10832381  0.01332139  0.06454482 -0.25157468\n",
      "  0.26266168  0.01542403 -0.36333927  0.30374863 -0.20718529 -0.25337253\n",
      "  0.07529472 -0.43452517]\n",
      "New theta_0 : [ 0.00954635 -0.12495547  0.10833132  0.01332712  0.0645462  -0.25159853\n",
      "  0.26265689  0.01542613 -0.36335703  0.30377014 -0.20719944 -0.25337664\n",
      "  0.07529398 -0.43452292]\n",
      "Training Error:  9.803014251231664\n",
      "====================================================================================================\n",
      "Iteration:  993\n",
      "Previous theta :  [ 0.00954635 -0.12495547  0.10833132  0.01332712  0.0645462  -0.25159853\n",
      "  0.26265689  0.01542613 -0.36335703  0.30377014 -0.20719944 -0.25337664\n",
      "  0.07529398 -0.43452292]\n",
      "New theta_0 : [ 0.00954685 -0.1249606   0.10833878  0.01333285  0.06454758 -0.25162225\n",
      "  0.26265212  0.01542823 -0.36337466  0.30379158 -0.20721356 -0.25338074\n",
      "  0.07529325 -0.43452069]\n",
      "Training Error:  9.803012548312207\n",
      "====================================================================================================\n",
      "Iteration:  994\n",
      "Previous theta :  [ 0.00954685 -0.1249606   0.10833878  0.01333285  0.06454758 -0.25162225\n",
      "  0.26265212  0.01542823 -0.36337466  0.30379158 -0.20721356 -0.25338074\n",
      "  0.07529325 -0.43452069]\n",
      "New theta_0 : [ 0.00954735 -0.1249657   0.10834621  0.01333857  0.06454894 -0.25164584\n",
      "  0.26264738  0.01543031 -0.36339218  0.30381295 -0.20722766 -0.25338482\n",
      "  0.07529253 -0.43451848]\n",
      "Training Error:  9.803010860825257\n",
      "====================================================================================================\n",
      "Iteration:  995\n",
      "Previous theta :  [ 0.00954735 -0.1249657   0.10834621  0.01333857  0.06454894 -0.25164584\n",
      "  0.26264738  0.01543031 -0.36339218  0.30381295 -0.20722766 -0.25338482\n",
      "  0.07529253 -0.43451848]\n",
      "New theta_0 : [ 0.00954784 -0.12497078  0.10835359  0.01334429  0.0645503  -0.25166929\n",
      "  0.26264267  0.01543239 -0.36340959  0.30383425 -0.20724174 -0.25338888\n",
      "  0.07529181 -0.43451627]\n",
      "Training Error:  9.803009188611565\n",
      "====================================================================================================\n",
      "Iteration:  996\n",
      "Previous theta :  [ 0.00954784 -0.12497078  0.10835359  0.01334429  0.0645503  -0.25166929\n",
      "  0.26264267  0.01543239 -0.36340959  0.30383425 -0.20724174 -0.25338888\n",
      "  0.07529181 -0.43451627]\n",
      "New theta_0 : [ 0.00954833 -0.12497584  0.10836093  0.01335     0.06455164 -0.25169262\n",
      "  0.26263799  0.01543446 -0.36342689  0.30385548 -0.20725579 -0.25339292\n",
      "  0.07529109 -0.43451407]\n",
      "Training Error:  9.803007531513654\n",
      "====================================================================================================\n",
      "Iteration:  997\n",
      "Previous theta :  [ 0.00954833 -0.12497584  0.10836093  0.01335     0.06455164 -0.25169262\n",
      "  0.26263799  0.01543446 -0.36342689  0.30385548 -0.20725579 -0.25339292\n",
      "  0.07529109 -0.43451407]\n",
      "New theta_0 : [ 0.00954882 -0.12498086  0.10836823  0.0133557   0.06455298 -0.25171581\n",
      "  0.26263333  0.01543652 -0.36344408  0.30387664 -0.20726983 -0.25339694\n",
      "  0.07529039 -0.43451189]\n",
      "Training Error:  9.803005889375793\n",
      "====================================================================================================\n",
      "Iteration:  998\n",
      "Previous theta :  [ 0.00954882 -0.12498086  0.10836823  0.0133557   0.06455298 -0.25171581\n",
      "  0.26263333  0.01543652 -0.36344408  0.30387664 -0.20726983 -0.25339694\n",
      "  0.07529039 -0.43451189]\n",
      "New theta_0 : [ 0.0095493  -0.12498587  0.10837549  0.01336139  0.0645543  -0.25173887\n",
      "  0.2626287   0.01543857 -0.36346115  0.30389774 -0.20728384 -0.25340094\n",
      "  0.07528968 -0.43450971]\n",
      "Training Error:  9.803004262043983\n",
      "====================================================================================================\n",
      "Iteration:  999\n",
      "Previous theta :  [ 0.0095493  -0.12498587  0.10837549  0.01336139  0.0645543  -0.25173887\n",
      "  0.2626287   0.01543857 -0.36346115  0.30389774 -0.20728384 -0.25340094\n",
      "  0.07528968 -0.43450971]\n",
      "New theta_0 : [ 0.00954978 -0.12499084  0.1083827   0.01336707  0.06455562 -0.2517618\n",
      "  0.26262409  0.01544061 -0.36347812  0.30391877 -0.20729783 -0.25340493\n",
      "  0.07528899 -0.43450755]\n",
      "Training Error:  9.803002649365922\n",
      "====================================================================================================\n",
      "Iteration:  1000\n",
      "Previous theta :  [ 0.00954978 -0.12499084  0.1083827   0.01336707  0.06455562 -0.2517618\n",
      "  0.26262409  0.01544061 -0.36347812  0.30391877 -0.20729783 -0.25340493\n",
      "  0.07528899 -0.43450755]\n",
      "New theta_0 : [ 0.00955026 -0.12499579  0.10838988  0.01337275  0.06455692 -0.2517846\n",
      "  0.26261951  0.01544264 -0.36349497  0.30393973 -0.2073118  -0.25340889\n",
      "  0.0752883  -0.4345054 ]\n",
      "Training Error:  9.803001051191007\n",
      "====================================================================================================\n",
      "Iteration:  1001\n",
      "Previous theta :  [ 0.00955026 -0.12499579  0.10838988  0.01337275  0.06455692 -0.2517846\n",
      "  0.26261951  0.01544264 -0.36349497  0.30393973 -0.2073118  -0.25340889\n",
      "  0.0752883  -0.4345054 ]\n",
      "New theta_0 : [ 0.00955074 -0.12500072  0.10839702  0.01337842  0.06455821 -0.25180728\n",
      "  0.26261496  0.01544467 -0.36351172  0.30396062 -0.20732575 -0.25341284\n",
      "  0.07528761 -0.43450325]\n",
      "Training Error:  9.802999467370302\n",
      "====================================================================================================\n",
      "Iteration:  1002\n",
      "Previous theta :  [ 0.00955074 -0.12500072  0.10839702  0.01337842  0.06455821 -0.25180728\n",
      "  0.26261496  0.01544467 -0.36351172  0.30396062 -0.20732575 -0.25341284\n",
      "  0.07528761 -0.43450325]\n",
      "New theta_0 : [ 0.00955121 -0.12500562  0.10840411  0.01338408  0.0645595  -0.25182982\n",
      "  0.26261043  0.01544668 -0.36352835  0.30398145 -0.20733968 -0.25341677\n",
      "  0.07528693 -0.43450112]\n",
      "Training Error:  9.80299789775652\n",
      "====================================================================================================\n",
      "Iteration:  1003\n",
      "Previous theta :  [ 0.00955121 -0.12500562  0.10840411  0.01338408  0.0645595  -0.25182982\n",
      "  0.26261043  0.01544668 -0.36352835  0.30398145 -0.20733968 -0.25341677\n",
      "  0.07528693 -0.43450112]\n",
      "New theta_0 : [ 0.00955168 -0.12501049  0.10841117  0.01338973  0.06456077 -0.25185225\n",
      "  0.26260593  0.01544869 -0.36354488  0.30400221 -0.20735358 -0.25342069\n",
      "  0.07528626 -0.434499  ]\n",
      "Training Error:  9.802996342204\n",
      "====================================================================================================\n",
      "Iteration:  1004\n",
      "Previous theta :  [ 0.00955168 -0.12501049  0.10841117  0.01338973  0.06456077 -0.25185225\n",
      "  0.26260593  0.01544869 -0.36354488  0.30400221 -0.20735358 -0.25342069\n",
      "  0.07528626 -0.434499  ]\n",
      "New theta_0 : [ 0.00955215 -0.12501534  0.10841818  0.01339538  0.06456204 -0.25187454\n",
      "  0.26260146  0.01545068 -0.36356131  0.3040229  -0.20736746 -0.25342458\n",
      "  0.07528559 -0.43449689]\n",
      "Training Error:  9.8029948005687\n",
      "====================================================================================================\n",
      "Iteration:  1005\n",
      "Previous theta :  [ 0.00955215 -0.12501534  0.10841818  0.01339538  0.06456204 -0.25187454\n",
      "  0.26260146  0.01545068 -0.36356131  0.3040229  -0.20736746 -0.25342458\n",
      "  0.07528559 -0.43449689]\n",
      "New theta_0 : [ 0.00955261 -0.12502017  0.10842516  0.01340101  0.0645633  -0.25189671\n",
      "  0.26259701  0.01545267 -0.36357762  0.30404353 -0.20738132 -0.25342846\n",
      "  0.07528493 -0.4344948 ]\n",
      "Training Error:  9.802993272708166\n",
      "====================================================================================================\n",
      "Iteration:  1006\n",
      "Previous theta :  [ 0.00955261 -0.12502017  0.10842516  0.01340101  0.0645633  -0.25189671\n",
      "  0.26259701  0.01545267 -0.36357762  0.30404353 -0.20738132 -0.25342846\n",
      "  0.07528493 -0.4344948 ]\n",
      "New theta_0 : [ 0.00955307 -0.12502497  0.1084321   0.01340664  0.06456454 -0.25191875\n",
      "  0.26259258  0.01545465 -0.36359384  0.30406409 -0.20739516 -0.25343232\n",
      "  0.07528427 -0.43449271]\n",
      "Training Error:  9.802991758481522\n",
      "====================================================================================================\n",
      "Iteration:  1007\n",
      "Previous theta :  [ 0.00955307 -0.12502497  0.1084321   0.01340664  0.06456454 -0.25191875\n",
      "  0.26259258  0.01545465 -0.36359384  0.30406409 -0.20739516 -0.25343232\n",
      "  0.07528427 -0.43449271]\n",
      "New theta_0 : [ 0.00955353 -0.12502975  0.108439    0.01341227  0.06456578 -0.25194068\n",
      "  0.26258818  0.01545662 -0.36360994  0.30408459 -0.20740897 -0.25343616\n",
      "  0.07528362 -0.43449063]\n",
      "Training Error:  9.802990257749446\n",
      "====================================================================================================\n",
      "Iteration:  1008\n",
      "Previous theta :  [ 0.00955353 -0.12502975  0.108439    0.01341227  0.06456578 -0.25194068\n",
      "  0.26258818  0.01545662 -0.36360994  0.30408459 -0.20740897 -0.25343616\n",
      "  0.07528362 -0.43449063]\n",
      "New theta_0 : [ 0.00955399 -0.1250345   0.10844586  0.01341788  0.06456701 -0.25196247\n",
      "  0.26258381  0.01545859 -0.36362594  0.30410502 -0.20742277 -0.25343998\n",
      "  0.07528297 -0.43448857]\n",
      "Training Error:  9.80298877037416\n",
      "====================================================================================================\n",
      "Iteration:  1009\n",
      "Previous theta :  [ 0.00955399 -0.1250345   0.10844586  0.01341788  0.06456701 -0.25196247\n",
      "  0.26258381  0.01545859 -0.36362594  0.30410502 -0.20742277 -0.25343998\n",
      "  0.07528297 -0.43448857]\n",
      "New theta_0 : [ 0.00955444 -0.12503922  0.10845268  0.01342349  0.06456822 -0.25198415\n",
      "  0.26257946  0.01546054 -0.36364184  0.30412538 -0.20743654 -0.25344379\n",
      "  0.07528233 -0.43448651]\n",
      "Training Error:  9.802987296219408\n",
      "====================================================================================================\n",
      "Iteration:  1010\n",
      "Previous theta :  [ 0.00955444 -0.12503922  0.10845268  0.01342349  0.06456822 -0.25198415\n",
      "  0.26257946  0.01546054 -0.36364184  0.30412538 -0.20743654 -0.25344379\n",
      "  0.07528233 -0.43448651]\n",
      "New theta_0 : [ 0.00955489 -0.12504393  0.10845946  0.01342908  0.06456943 -0.25200571\n",
      "  0.26257514  0.01546249 -0.36365764  0.30414568 -0.20745029 -0.25344758\n",
      "  0.07528169 -0.43448447]\n",
      "Training Error:  9.802985835150428\n",
      "====================================================================================================\n",
      "Iteration:  1011\n",
      "Previous theta :  [ 0.00955489 -0.12504393  0.10845946  0.01342908  0.06456943 -0.25200571\n",
      "  0.26257514  0.01546249 -0.36365764  0.30414568 -0.20745029 -0.25344758\n",
      "  0.07528169 -0.43448447]\n",
      "New theta_0 : [ 0.00955534 -0.12504861  0.10846621  0.01343467  0.06457063 -0.25202714\n",
      "  0.26257084  0.01546443 -0.36367333  0.30416592 -0.20746402 -0.25345135\n",
      "  0.07528106 -0.43448243]\n",
      "Training Error:  9.802984387033955\n",
      "====================================================================================================\n",
      "Iteration:  1012\n",
      "Previous theta :  [ 0.00955534 -0.12504861  0.10846621  0.01343467  0.06457063 -0.25202714\n",
      "  0.26257084  0.01546443 -0.36367333  0.30416592 -0.20746402 -0.25345135\n",
      "  0.07528106 -0.43448243]\n",
      "New theta_0 : [ 0.00955578 -0.12505326  0.10847292  0.01344025  0.06457182 -0.25204845\n",
      "  0.26256656  0.01546635 -0.36368892  0.30418609 -0.20747772 -0.2534551\n",
      "  0.07528044 -0.43448041]\n",
      "Training Error:  9.80298295173819\n",
      "====================================================================================================\n",
      "Iteration:  1013\n",
      "Previous theta :  [ 0.00955578 -0.12505326  0.10847292  0.01344025  0.06457182 -0.25204845\n",
      "  0.26256656  0.01546635 -0.36368892  0.30418609 -0.20747772 -0.2534551\n",
      "  0.07528044 -0.43448041]\n",
      "New theta_0 : [ 0.00955623 -0.1250579   0.10847959  0.01344583  0.06457301 -0.25206965\n",
      "  0.26256231  0.01546828 -0.36370441  0.3042062  -0.20749141 -0.25345884\n",
      "  0.07527982 -0.4344784 ]\n",
      "Training Error:  9.802981529132785\n",
      "====================================================================================================\n",
      "Iteration:  1014\n",
      "Previous theta :  [ 0.00955623 -0.1250579   0.10847959  0.01344583  0.06457301 -0.25206965\n",
      "  0.26256231  0.01546828 -0.36370441  0.3042062  -0.20749141 -0.25345884\n",
      "  0.07527982 -0.4344784 ]\n",
      "New theta_0 : [ 0.00955667 -0.12506251  0.10848622  0.01345139  0.06457418 -0.25209072\n",
      "  0.26255808  0.01547019 -0.36371981  0.30422624 -0.20750507 -0.25346256\n",
      "  0.0752792  -0.43447639]\n",
      "Training Error:  9.802980119088836\n",
      "====================================================================================================\n",
      "Iteration:  1015\n",
      "Previous theta :  [ 0.00955667 -0.12506251  0.10848622  0.01345139  0.06457418 -0.25209072\n",
      "  0.26255808  0.01547019 -0.36371981  0.30422624 -0.20750507 -0.25346256\n",
      "  0.0752792  -0.43447639]\n",
      "New theta_0 : [ 0.0095571  -0.12506709  0.10849281  0.01345695  0.06457534 -0.25211168\n",
      "  0.26255388  0.01547209 -0.3637351   0.30424622 -0.20751871 -0.25346626\n",
      "  0.07527859 -0.4344744 ]\n",
      "Training Error:  9.802978721478846\n",
      "====================================================================================================\n",
      "Iteration:  1016\n",
      "Previous theta :  [ 0.0095571  -0.12506709  0.10849281  0.01345695  0.06457534 -0.25211168\n",
      "  0.26255388  0.01547209 -0.3637351   0.30424622 -0.20751871 -0.25346626\n",
      "  0.07527859 -0.4344744 ]\n",
      "New theta_0 : [ 0.00955754 -0.12507165  0.10849937  0.0134625   0.0645765  -0.25213252\n",
      "  0.2625497   0.01547399 -0.36375029  0.30426614 -0.20753232 -0.25346995\n",
      "  0.07527799 -0.43447242]\n",
      "Training Error:  9.802977336176728\n",
      "====================================================================================================\n",
      "Iteration:  1017\n",
      "Previous theta :  [ 0.00955754 -0.12507165  0.10849937  0.0134625   0.0645765  -0.25213252\n",
      "  0.2625497   0.01547399 -0.36375029  0.30426614 -0.20753232 -0.25346995\n",
      "  0.07527799 -0.43447242]\n",
      "New theta_0 : [ 0.00955797 -0.12507619  0.1085059   0.01346804  0.06457764 -0.25215324\n",
      "  0.26254555  0.01547588 -0.36376538  0.30428599 -0.20754592 -0.25347362\n",
      "  0.07527739 -0.43447045]\n",
      "Training Error:  9.802975963057788\n",
      "====================================================================================================\n",
      "Iteration:  1018\n",
      "Previous theta :  [ 0.00955797 -0.12507619  0.1085059   0.01346804  0.06457764 -0.25215324\n",
      "  0.26254555  0.01547588 -0.36376538  0.30428599 -0.20754592 -0.25347362\n",
      "  0.07527739 -0.43447045]\n",
      "New theta_0 : [ 0.0095584  -0.12508071  0.10851238  0.01347357  0.06457878 -0.25217384\n",
      "  0.26254141  0.01547776 -0.36378038  0.30430578 -0.20755949 -0.25347727\n",
      "  0.07527679 -0.43446848]\n",
      "Training Error:  9.802974601998695\n",
      "====================================================================================================\n",
      "Iteration:  1019\n",
      "Previous theta :  [ 0.0095584  -0.12508071  0.10851238  0.01347357  0.06457878 -0.25217384\n",
      "  0.26254141  0.01547776 -0.36378038  0.30430578 -0.20755949 -0.25347727\n",
      "  0.07527679 -0.43446848]\n",
      "New theta_0 : [ 0.00955883 -0.1250852   0.10851883  0.0134791   0.06457991 -0.25219433\n",
      "  0.2625373   0.01547963 -0.36379527  0.30432551 -0.20757304 -0.25348091\n",
      "  0.0752762  -0.43446653]\n",
      "Training Error:  9.802973252877472\n",
      "====================================================================================================\n",
      "Iteration:  1020\n",
      "Previous theta :  [ 0.00955883 -0.1250852   0.10851883  0.0134791   0.06457991 -0.25219433\n",
      "  0.2625373   0.01547963 -0.36379527  0.30432551 -0.20757304 -0.25348091\n",
      "  0.0752762  -0.43446653]\n",
      "New theta_0 : [ 0.00955925 -0.12508967  0.10852525  0.01348461  0.06458103 -0.25221471\n",
      "  0.26253322  0.01548149 -0.36381008  0.30434518 -0.20758657 -0.25348453\n",
      "  0.07527562 -0.43446459]\n",
      "Training Error:  9.80297191557349\n",
      "====================================================================================================\n",
      "Iteration:  1021\n",
      "Previous theta :  [ 0.00955925 -0.12508967  0.10852525  0.01348461  0.06458103 -0.25221471\n",
      "  0.26253322  0.01548149 -0.36381008  0.30434518 -0.20758657 -0.25348453\n",
      "  0.07527562 -0.43446459]\n",
      "New theta_0 : [ 0.00955967 -0.12509412  0.10853162  0.01349012  0.06458214 -0.25223497\n",
      "  0.26252916  0.01548335 -0.36382478  0.30436478 -0.20760008 -0.25348813\n",
      "  0.07527504 -0.43446266]\n",
      "Training Error:  9.802970589967442\n",
      "====================================================================================================\n",
      "Iteration:  1022\n",
      "Previous theta :  [ 0.00955967 -0.12509412  0.10853162  0.01349012  0.06458214 -0.25223497\n",
      "  0.26252916  0.01548335 -0.36382478  0.30436478 -0.20760008 -0.25348813\n",
      "  0.07527504 -0.43446266]\n",
      "New theta_0 : [ 0.00956009 -0.12509854  0.10853797  0.01349562  0.06458324 -0.25225512\n",
      "  0.26252512  0.0154852  -0.36383939  0.30438432 -0.20761357 -0.25349172\n",
      "  0.07527446 -0.43446074]\n",
      "Training Error:  9.80296927594133\n",
      "====================================================================================================\n",
      "Iteration:  1023\n",
      "Previous theta :  [ 0.00956009 -0.12509854  0.10853797  0.01349562  0.06458324 -0.25225512\n",
      "  0.26252512  0.0154852  -0.36383939  0.30438432 -0.20761357 -0.25349172\n",
      "  0.07527446 -0.43446074]\n",
      "New theta_0 : [ 0.00956051 -0.12510295  0.10854427  0.01350111  0.06458433 -0.25227515\n",
      "  0.2625211   0.01548704 -0.36385391  0.3044038  -0.20762703 -0.25349529\n",
      "  0.07527389 -0.43445883]\n",
      "Training Error:  9.802967973378449\n",
      "====================================================================================================\n",
      "Iteration:  1024\n",
      "Previous theta :  [ 0.00956051 -0.12510295  0.10854427  0.01350111  0.06458433 -0.25227515\n",
      "  0.2625211   0.01548704 -0.36385391  0.3044038  -0.20762703 -0.25349529\n",
      "  0.07527389 -0.43445883]\n",
      "New theta_0 : [ 0.00956092 -0.12510733  0.10855055  0.01350659  0.06458542 -0.25229507\n",
      "  0.26251711  0.01548887 -0.36386833  0.30442322 -0.20764047 -0.25349884\n",
      "  0.07527333 -0.43445692]\n",
      "Training Error:  9.802966682163373\n",
      "====================================================================================================\n",
      "Iteration:  1025\n",
      "Previous theta :  [ 0.00956092 -0.12510733  0.10855055  0.01350659  0.06458542 -0.25229507\n",
      "  0.26251711  0.01548887 -0.36386833  0.30442322 -0.20764047 -0.25349884\n",
      "  0.07527333 -0.43445692]\n",
      "New theta_0 : [ 0.00956133 -0.12511169  0.10855678  0.01351207  0.06458649 -0.25231488\n",
      "  0.26251313  0.01549069 -0.36388265  0.30444257 -0.20765389 -0.25350238\n",
      "  0.07527277 -0.43445503]\n",
      "Training Error:  9.802965402181945\n",
      "====================================================================================================\n",
      "Iteration:  1026\n",
      "Previous theta :  [ 0.00956133 -0.12511169  0.10855678  0.01351207  0.06458649 -0.25231488\n",
      "  0.26251313  0.01549069 -0.36388265  0.30444257 -0.20765389 -0.25350238\n",
      "  0.07527277 -0.43445503]\n",
      "New theta_0 : [ 0.00956174 -0.12511602  0.10856299  0.01351753  0.06458756 -0.25233458\n",
      "  0.26250919  0.01549251 -0.36389689  0.30446187 -0.20766729 -0.2535059\n",
      "  0.07527221 -0.43445315]\n",
      "Training Error:  9.80296413332126\n",
      "====================================================================================================\n",
      "Iteration:  1027\n",
      "Previous theta :  [ 0.00956174 -0.12511602  0.10856299  0.01351753  0.06458756 -0.25233458\n",
      "  0.26250919  0.01549251 -0.36389689  0.30446187 -0.20766729 -0.2535059\n",
      "  0.07527221 -0.43445315]\n",
      "New theta_0 : [ 0.00956215 -0.12512034  0.10856915  0.01352299  0.06458862 -0.25235417\n",
      "  0.26250526  0.01549432 -0.36391103  0.3044811  -0.20768066 -0.2535094\n",
      "  0.07527166 -0.43445128]\n",
      "Training Error:  9.80296287546964\n",
      "====================================================================================================\n",
      "Iteration:  1028\n",
      "Previous theta :  [ 0.00956215 -0.12512034  0.10856915  0.01352299  0.06458862 -0.25235417\n",
      "  0.26250526  0.01549432 -0.36391103  0.3044811  -0.20768066 -0.2535094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.07527166 -0.43445128]\n",
      "New theta_0 : [ 0.00956255 -0.12512463  0.10857529  0.01352844  0.06458967 -0.25237365\n",
      "  0.26250135  0.01549612 -0.36392508  0.30450028 -0.20769401 -0.25351289\n",
      "  0.07527111 -0.43444942]\n",
      "Training Error:  9.802961628516643\n",
      "====================================================================================================\n",
      "Iteration:  1029\n",
      "Previous theta :  [ 0.00956255 -0.12512463  0.10857529  0.01352844  0.06458967 -0.25237365\n",
      "  0.26250135  0.01549612 -0.36392508  0.30450028 -0.20769401 -0.25351289\n",
      "  0.07527111 -0.43444942]\n",
      "New theta_0 : [ 0.00956295 -0.1251289   0.10858139  0.01353388  0.06459072 -0.25239302\n",
      "  0.26249747  0.01549791 -0.36393904  0.30451939 -0.20770734 -0.25351637\n",
      "  0.07527057 -0.43444756]\n",
      "Training Error:  9.802960392353022\n",
      "====================================================================================================\n",
      "Iteration:  1030\n",
      "Previous theta :  [ 0.00956295 -0.1251289   0.10858139  0.01353388  0.06459072 -0.25239302\n",
      "  0.26249747  0.01549791 -0.36393904  0.30451939 -0.20770734 -0.25351637\n",
      "  0.07527057 -0.43444756]\n",
      "New theta_0 : [ 0.00956335 -0.12513315  0.10858745  0.01353931  0.06459175 -0.25241228\n",
      "  0.26249361  0.0154997  -0.36395291  0.30453844 -0.20772065 -0.25351982\n",
      "  0.07527003 -0.43444572]\n",
      "Training Error:  9.802959166870734\n",
      "====================================================================================================\n",
      "Iteration:  1031\n",
      "Previous theta :  [ 0.00956335 -0.12513315  0.10858745  0.01353931  0.06459175 -0.25241228\n",
      "  0.26249361  0.0154997  -0.36395291  0.30453844 -0.20772065 -0.25351982\n",
      "  0.07527003 -0.43444572]\n",
      "New theta_0 : [ 0.00956375 -0.12513738  0.10859349  0.01354473  0.06459278 -0.25243143\n",
      "  0.26248977  0.01550148 -0.36396668  0.30455744 -0.20773394 -0.25352327\n",
      "  0.0752695  -0.43444389]\n",
      "Training Error:  9.80295795196291\n",
      "====================================================================================================\n",
      "Iteration:  1032\n",
      "Previous theta :  [ 0.00956375 -0.12513738  0.10859349  0.01354473  0.06459278 -0.25243143\n",
      "  0.26248977  0.01550148 -0.36396668  0.30455744 -0.20773394 -0.25352327\n",
      "  0.0752695  -0.43444389]\n",
      "New theta_0 : [ 0.00956415 -0.12514158  0.10859949  0.01355015  0.0645938  -0.25245048\n",
      "  0.26248595  0.01550325 -0.36398037  0.30457637 -0.2077472  -0.25352669\n",
      "  0.07526897 -0.43444206]\n",
      "Training Error:  9.802956747523849\n",
      "====================================================================================================\n",
      "Iteration:  1033\n",
      "Previous theta :  [ 0.00956415 -0.12514158  0.10859949  0.01355015  0.0645938  -0.25245048\n",
      "  0.26248595  0.01550325 -0.36398037  0.30457637 -0.2077472  -0.25352669\n",
      "  0.07526897 -0.43444206]\n",
      "New theta_0 : [ 0.00956454 -0.12514577  0.10860545  0.01355555  0.06459481 -0.25246942\n",
      "  0.26248216  0.01550501 -0.36399397  0.30459525 -0.20776044 -0.2535301\n",
      "  0.07526845 -0.43444025]\n",
      "Training Error:  9.802955553449015\n",
      "====================================================================================================\n",
      "Iteration:  1034\n",
      "Previous theta :  [ 0.00956454 -0.12514577  0.10860545  0.01355555  0.06459481 -0.25246942\n",
      "  0.26248216  0.01550501 -0.36399397  0.30459525 -0.20776044 -0.2535301\n",
      "  0.07526845 -0.43444025]\n",
      "New theta_0 : [ 0.00956493 -0.12514993  0.10861138  0.01356095  0.06459582 -0.25248825\n",
      "  0.26247838  0.01550677 -0.36400748  0.30461406 -0.20777366 -0.2535335\n",
      "  0.07526793 -0.43443844]\n",
      "Training Error:  9.802954369635\n",
      "====================================================================================================\n",
      "Iteration:  1035\n",
      "Previous theta :  [ 0.00956493 -0.12514993  0.10861138  0.01356095  0.06459582 -0.25248825\n",
      "  0.26247838  0.01550677 -0.36400748  0.30461406 -0.20777366 -0.2535335\n",
      "  0.07526793 -0.43443844]\n",
      "New theta_0 : [ 0.00956531 -0.12515408  0.10861728  0.01356634  0.06459681 -0.25250698\n",
      "  0.26247463  0.01550852 -0.3640209   0.30463282 -0.20778686 -0.25353688\n",
      "  0.07526741 -0.43443665]\n",
      "Training Error:  9.802953195979525\n",
      "====================================================================================================\n",
      "Iteration:  1036\n",
      "Previous theta :  [ 0.00956531 -0.12515408  0.10861728  0.01356634  0.06459681 -0.25250698\n",
      "  0.26247463  0.01550852 -0.3640209   0.30463282 -0.20778686 -0.25353688\n",
      "  0.07526741 -0.43443665]\n",
      "New theta_0 : [ 0.0095657  -0.1251582   0.10862315  0.01357172  0.0645978  -0.2525256\n",
      "  0.26247089  0.01551026 -0.36403424  0.30465152 -0.20780004 -0.25354024\n",
      "  0.0752669  -0.43443486]\n",
      "Training Error:  9.802952032381429\n",
      "====================================================================================================\n",
      "Iteration:  1037\n",
      "Previous theta :  [ 0.0095657  -0.1251582   0.10862315  0.01357172  0.0645978  -0.2525256\n",
      "  0.26247089  0.01551026 -0.36403424  0.30465152 -0.20780004 -0.25354024\n",
      "  0.0752669  -0.43443486]\n",
      "New theta_0 : [ 0.00956608 -0.1251623   0.10862899  0.01357709  0.06459878 -0.25254412\n",
      "  0.26246718  0.01551199 -0.36404748  0.30467015 -0.20781319 -0.25354359\n",
      "  0.07526639 -0.43443309]\n",
      "Training Error:  9.802950878740653\n",
      "====================================================================================================\n",
      "Iteration:  1038\n",
      "Previous theta :  [ 0.00956608 -0.1251623   0.10862899  0.01357709  0.06459878 -0.25254412\n",
      "  0.26246718  0.01551199 -0.36404748  0.30467015 -0.20781319 -0.25354359\n",
      "  0.07526639 -0.43443309]\n",
      "New theta_0 : [ 0.00956646 -0.12516638  0.10863479  0.01358245  0.06459975 -0.25256253\n",
      "  0.26246349  0.01551372 -0.36406064  0.30468874 -0.20782632 -0.25354692\n",
      "  0.07526589 -0.43443132]\n",
      "Training Error:  9.802949734958231\n",
      "====================================================================================================\n",
      "Iteration:  1039\n",
      "Previous theta :  [ 0.00956646 -0.12516638  0.10863479  0.01358245  0.06459975 -0.25256253\n",
      "  0.26246349  0.01551372 -0.36406064  0.30468874 -0.20782632 -0.25354692\n",
      "  0.07526589 -0.43443132]\n",
      "New theta_0 : [ 0.00956684 -0.12517044  0.10864056  0.01358781  0.06460072 -0.25258084\n",
      "  0.26245982  0.01551544 -0.36407372  0.30470726 -0.20783943 -0.25355024\n",
      "  0.07526539 -0.43442956]\n",
      "Training Error:  9.802948600936269\n",
      "====================================================================================================\n",
      "Iteration:  1040\n",
      "Previous theta :  [ 0.00956684 -0.12517044  0.10864056  0.01358781  0.06460072 -0.25258084\n",
      "  0.26245982  0.01551544 -0.36407372  0.30470726 -0.20783943 -0.25355024\n",
      "  0.07526539 -0.43442956]\n",
      "New theta_0 : [ 0.00956722 -0.12517448  0.1086463   0.01359315  0.06460167 -0.25259905\n",
      "  0.26245617  0.01551715 -0.36408671  0.30472572 -0.20785252 -0.25355354\n",
      "  0.0752649  -0.43442781]\n",
      "Training Error:  9.802947476577938\n",
      "====================================================================================================\n",
      "Iteration:  1041\n",
      "Previous theta :  [ 0.00956722 -0.12517448  0.1086463   0.01359315  0.06460167 -0.25259905\n",
      "  0.26245617  0.01551715 -0.36408671  0.30472572 -0.20785252 -0.25355354\n",
      "  0.0752649  -0.43442781]\n",
      "New theta_0 : [ 0.00956759 -0.1251785   0.10865201  0.01359849  0.06460262 -0.25261716\n",
      "  0.26245254  0.01551885 -0.36409962  0.30474413 -0.20786558 -0.25355683\n",
      "  0.07526441 -0.43442607]\n",
      "Training Error:  9.802946361787466\n",
      "====================================================================================================\n",
      "Iteration:  1042\n",
      "Previous theta :  [ 0.00956759 -0.1251785   0.10865201  0.01359849  0.06460262 -0.25261716\n",
      "  0.26245254  0.01551885 -0.36409962  0.30474413 -0.20786558 -0.25355683\n",
      "  0.07526441 -0.43442607]\n",
      "New theta_0 : [ 0.00956796 -0.1251825   0.10865768  0.01360382  0.06460356 -0.25263516\n",
      "  0.26244893  0.01552055 -0.36411244  0.30476248 -0.20787862 -0.25356011\n",
      "  0.07526393 -0.43442434]\n",
      "Training Error:  9.802945256470117\n",
      "====================================================================================================\n",
      "Iteration:  1043\n",
      "Previous theta :  [ 0.00956796 -0.1251825   0.10865768  0.01360382  0.06460356 -0.25263516\n",
      "  0.26244893  0.01552055 -0.36411244  0.30476248 -0.20787862 -0.25356011\n",
      "  0.07526393 -0.43442434]\n",
      "New theta_0 : [ 0.00956833 -0.12518648  0.10866333  0.01360914  0.0646045  -0.25265306\n",
      "  0.26244534  0.01552224 -0.36412518  0.30478077 -0.20789164 -0.25356336\n",
      "  0.07526345 -0.43442262]\n",
      "Training Error:  9.802944160532187\n",
      "====================================================================================================\n",
      "Iteration:  1044\n",
      "Previous theta :  [ 0.00956833 -0.12518648  0.10866333  0.01360914  0.0646045  -0.25265306\n",
      "  0.26244534  0.01552224 -0.36412518  0.30478077 -0.20789164 -0.25356336\n",
      "  0.07526345 -0.43442262]\n",
      "New theta_0 : [ 0.0095687  -0.12519044  0.10866894  0.01361445  0.06460543 -0.25267087\n",
      "  0.26244177  0.01552393 -0.36413783  0.30479901 -0.20790464 -0.25356661\n",
      "  0.07526297 -0.43442091]\n",
      "Training Error:  9.802943073880986\n",
      "====================================================================================================\n",
      "Iteration:  1045\n",
      "Previous theta :  [ 0.0095687  -0.12519044  0.10866894  0.01361445  0.06460543 -0.25267087\n",
      "  0.26244177  0.01552393 -0.36413783  0.30479901 -0.20790464 -0.25356661\n",
      "  0.07526297 -0.43442091]\n",
      "New theta_0 : [ 0.00956906 -0.12519438  0.10867452  0.01361975  0.06460634 -0.25268857\n",
      "  0.26243822  0.0155256  -0.3641504   0.30481719 -0.20791762 -0.25356984\n",
      "  0.0752625  -0.43441921]\n",
      "Training Error:  9.802941996424837\n",
      "====================================================================================================\n",
      "Iteration:  1046\n",
      "Previous theta :  [ 0.00956906 -0.12519438  0.10867452  0.01361975  0.06460634 -0.25268857\n",
      "  0.26243822  0.0155256  -0.3641504   0.30481719 -0.20791762 -0.25356984\n",
      "  0.0752625  -0.43441921]\n",
      "New theta_0 : [ 0.00956942 -0.1251983   0.10868007  0.01362504  0.06460726 -0.25270618\n",
      "  0.26243469  0.01552727 -0.36416289  0.30483531 -0.20793057 -0.25357305\n",
      "  0.07526203 -0.43441751]\n",
      "Training Error:  9.802940928073049\n",
      "====================================================================================================\n",
      "Iteration:  1047\n",
      "Previous theta :  [ 0.00956942 -0.1251983   0.10868007  0.01362504  0.06460726 -0.25270618\n",
      "  0.26243469  0.01552727 -0.36416289  0.30483531 -0.20793057 -0.25357305\n",
      "  0.07526203 -0.43441751]\n",
      "New theta_0 : [ 0.00956978 -0.1252022   0.1086856   0.01363033  0.06460816 -0.25272368\n",
      "  0.26243118  0.01552893 -0.3641753   0.30485337 -0.2079435  -0.25357625\n",
      "  0.07526157 -0.43441583]\n",
      "Training Error:  9.802939868735914\n",
      "====================================================================================================\n",
      "Iteration:  1048\n",
      "Previous theta :  [ 0.00956978 -0.1252022   0.1086856   0.01363033  0.06460816 -0.25272368\n",
      "  0.26243118  0.01552893 -0.3641753   0.30485337 -0.2079435  -0.25357625\n",
      "  0.07526157 -0.43441583]\n",
      "New theta_0 : [ 0.00957014 -0.12520608  0.10869109  0.0136356   0.06460906 -0.25274109\n",
      "  0.26242769  0.01553059 -0.36418763  0.30487138 -0.20795641 -0.25357943\n",
      "  0.0752611  -0.43441415]\n",
      "Training Error:  9.802938818324705\n",
      "====================================================================================================\n",
      "Iteration:  1049\n",
      "Previous theta :  [ 0.00957014 -0.12520608  0.10869109  0.0136356   0.06460906 -0.25274109\n",
      "  0.26242769  0.01553059 -0.36418763  0.30487138 -0.20795641 -0.25357943\n",
      "  0.0752611  -0.43441415]\n",
      "New theta_0 : [ 0.0095705  -0.12520994  0.10869655  0.01364087  0.06460995 -0.2527584\n",
      "  0.26242422  0.01553224 -0.36419988  0.30488934 -0.2079693  -0.2535826\n",
      "  0.07526065 -0.43441249]\n",
      "Training Error:  9.802937776751643\n",
      "====================================================================================================\n",
      "Iteration:  1050\n",
      "Previous theta :  [ 0.0095705  -0.12520994  0.10869655  0.01364087  0.06460995 -0.2527584\n",
      "  0.26242422  0.01553224 -0.36419988  0.30488934 -0.2079693  -0.2535826\n",
      "  0.07526065 -0.43441249]\n",
      "New theta_0 : [ 0.00957085 -0.12521379  0.10870198  0.01364613  0.06461083 -0.25277562\n",
      "  0.26242077  0.01553388 -0.36421204  0.30490723 -0.20798217 -0.25358576\n",
      "  0.0752602  -0.43441083]\n",
      "Training Error:  9.802936743929909\n",
      "====================================================================================================\n",
      "Iteration:  1051\n",
      "Previous theta :  [ 0.00957085 -0.12521379  0.10870198  0.01364613  0.06461083 -0.25277562\n",
      "  0.26242077  0.01553388 -0.36421204  0.30490723 -0.20798217 -0.25358576\n",
      "  0.0752602  -0.43441083]\n",
      "New theta_0 : [ 0.0095712  -0.12521761  0.10870738  0.01365137  0.06461171 -0.25279273\n",
      "  0.26241733  0.01553551 -0.36422413  0.30492507 -0.20799501 -0.2535889\n",
      "  0.07525975 -0.43440918]\n",
      "Training Error:  9.802935719773618\n",
      "====================================================================================================\n",
      "Iteration:  1052\n",
      "Previous theta :  [ 0.0095712  -0.12521761  0.10870738  0.01365137  0.06461171 -0.25279273\n",
      "  0.26241733  0.01553551 -0.36422413  0.30492507 -0.20799501 -0.2535889\n",
      "  0.07525975 -0.43440918]\n",
      "New theta_0 : [ 0.00957155 -0.12522141  0.10871275  0.01365661  0.06461258 -0.25280975\n",
      "  0.26241392  0.01553714 -0.36423614  0.30494286 -0.20800783 -0.25359203\n",
      "  0.0752593  -0.43440754]\n",
      "Training Error:  9.802934704197812\n",
      "====================================================================================================\n",
      "Iteration:  1053\n",
      "Previous theta :  [ 0.00957155 -0.12522141  0.10871275  0.01365661  0.06461258 -0.25280975\n",
      "  0.26241392  0.01553714 -0.36423614  0.30494286 -0.20800783 -0.25359203\n",
      "  0.0752593  -0.43440754]\n",
      "New theta_0 : [ 0.0095719  -0.1252252   0.10871809  0.01366184  0.06461344 -0.25282668\n",
      "  0.26241052  0.01553876 -0.36424807  0.30496059 -0.20802063 -0.25359514\n",
      "  0.07525886 -0.43440591]\n",
      "Training Error:  9.802933697118455\n",
      "====================================================================================================\n",
      "Iteration:  1054\n",
      "Previous theta :  [ 0.0095719  -0.1252252   0.10871809  0.01366184  0.06461344 -0.25282668\n",
      "  0.26241052  0.01553876 -0.36424807  0.30496059 -0.20802063 -0.25359514\n",
      "  0.07525886 -0.43440591]\n",
      "New theta_0 : [ 0.00957224 -0.12522896  0.10872341  0.01366707  0.0646143  -0.25284351\n",
      "  0.26240715  0.01554038 -0.36425992  0.30497827 -0.20803341 -0.25359824\n",
      "  0.07525843 -0.43440428]\n",
      "Training Error:  9.802932698452418\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = test_train_split(X, y, validation_sample5)\n",
    "learning_rate = 0.01\n",
    "train_error5, valid_error5, theta5 = linear_regression(X_train, y_train, X_test, y_test, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Second Sample')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(train_error5))], train_error5, label='Training error')\n",
    "plt.plot([i for i in range(len(valid_error5))], valid_error5, label='Validation error')\n",
    "plt.gca().legend(('Training error','Validation error'))\n",
    "plt.title('Second Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
